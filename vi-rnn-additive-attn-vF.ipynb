{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "from data_processing import generate_vocab, process_data, create_dataloaders\n",
    "from model import get_pretrained_emb, EncoderRNN, DecoderRNN, DecoderAttnRNN, EncoderDecoder, EncoderDecoderAttn\n",
    "from train_eval import evaluate, train_and_eval, summarize_results, plot_single_learning_curve, load_experiment_log\n",
    "import pickle as pkl \n",
    "from datetime import datetime\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params required for generating data loaders \n",
    "\n",
    "SRC_LANG = 'vi'\n",
    "TARG_LANG = 'en'\n",
    "\n",
    "SRC_MAX_SENTENCE_LEN = 10\n",
    "TARG_MAX_SENTENCE_LEN = 10\n",
    "SRC_VOCAB_SIZE = 30000 \n",
    "TARG_VOCAB_SIZE = 30000 \n",
    "\n",
    "BATCH_SIZE = 64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a long time to process, save to pickle for reimport in future \n",
    "# vocab = generate_vocab(SRC_LANG, TARG_LANG, SRC_VOCAB_SIZE, TARG_VOCAB_SIZE)\n",
    "# vocab_filename = \"{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n",
    "# pkl.dump(vocab, open(vocab_filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload from pickle \n",
    "vocab_filename = \"{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n",
    "vocab = pkl.load(open(vocab_filename, \"rb\"))\n",
    "data = process_data(SRC_LANG, TARG_LANG, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, vocab, filter_long=False)\n",
    "data_minibatch = process_data(SRC_LANG, TARG_LANG, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, vocab, sample_limit=BATCH_SIZE, filter_long=False) \n",
    "data_minitrain = process_data(SRC_LANG, TARG_LANG, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, vocab, sample_limit=1000, filter_long=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders \n",
    "loaders_full = create_dataloaders(data, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)\n",
    "loaders_minibatch = create_dataloaders(data_minibatch, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)\n",
    "loaders_minitrain = create_dataloaders(data_minitrain, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architecture params \n",
    "NETWORK_TYPE = 'rnn'\n",
    "RNN_CELL_TYPE = 'gru'\n",
    "NUM_LAYERS = 2 \n",
    "ENC_HIDDEN_DIM = 512\n",
    "DEC_HIDDEN_DIM = 2 * ENC_HIDDEN_DIM \n",
    "TEACHER_FORCING_RATIO = 1\n",
    "CLIP_GRAD_MAX_NORM = 1\n",
    "ENC_DROPOUT = 0 \n",
    "DEC_DROPOUT = 0  \n",
    "ATTENTION_TYPE = 'additive'\n",
    "\n",
    "# training params  \n",
    "NUM_EPOCHS = 10 \n",
    "LR = 0.00015 \n",
    "OPTIMIZER = 'Adam'\n",
    "LAZY_TRAIN = False\n",
    "\n",
    "# name the model and experiment \n",
    "if NETWORK_TYPE == 'rnn': \n",
    "    EXPERIMENT_NAME = '{}-rnn-{}-attn'.format(SRC_LANG, ATTENTION_TYPE)\n",
    "elif NETWORK_TYPE == 'cnn': \n",
    "    EXPERIMENT_NAME = '{}-cnn'.format(SRC_LANG)\n",
    "MODEL_NAME = '{}-{}'.format(EXPERIMENT_NAME, datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store as dict to save to results later \n",
    "params = {'experiment_name': EXPERIMENT_NAME,'model_name': MODEL_NAME, 'src_lang': SRC_LANG, 'targ_lang': TARG_LANG, \n",
    "          'rnn_cell_type': RNN_CELL_TYPE, 'src_max_sentence_len': SRC_MAX_SENTENCE_LEN, \n",
    "          'targ_max_sentence_len': TARG_MAX_SENTENCE_LEN, 'src_vocab_size': SRC_VOCAB_SIZE, \n",
    "          'targ_vocab_size': TARG_VOCAB_SIZE, 'num_layers': NUM_LAYERS, 'enc_hidden_dim': ENC_HIDDEN_DIM, \n",
    "          'dec_hidden_dim': DEC_HIDDEN_DIM, 'teacher_forcing_ratio': TEACHER_FORCING_RATIO, \n",
    "          'clip_grad_max_norm': CLIP_GRAD_MAX_NORM, 'enc_dropout': ENC_DROPOUT, 'dec_dropout': DEC_DROPOUT, \n",
    "          'attention_type': ATTENTION_TYPE, 'batch_size': BATCH_SIZE, 'num_epochs': NUM_EPOCHS, \n",
    "          'learning_rate': LR, 'optimizer': OPTIMIZER, 'lazy_train': LAZY_TRAIN} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model \n",
    "\n",
    "encoder = EncoderRNN(rnn_cell_type=RNN_CELL_TYPE, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, \n",
    "                     src_max_sentence_len=SRC_MAX_SENTENCE_LEN, enc_dropout=ENC_DROPOUT, \n",
    "                     pretrained_word2vec=get_pretrained_emb(vocab[SRC_LANG]['word2vec'], vocab[SRC_LANG]['token2id']))\n",
    "\n",
    "if ATTENTION_TYPE == 'without': \n",
    "    # without attention \n",
    "    decoder = DecoderRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS,\n",
    "                         targ_vocab_size=TARG_VOCAB_SIZE, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "                         pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], \n",
    "                                                                vocab[TARG_LANG]['token2id']))\n",
    "    model = EncoderDecoder(encoder, decoder, vocab[TARG_LANG]['token2id']).to(device)\n",
    "    \n",
    "else: \n",
    "    # with attention \n",
    "    decoder = DecoderAttnRNN(rnn_cell_type=RNN_CELL_TYPE, dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, \n",
    "                             num_layers=NUM_LAYERS, targ_vocab_size=TARG_VOCAB_SIZE, \n",
    "                             src_max_sentence_len=SRC_MAX_SENTENCE_LEN, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "                             dec_dropout=DEC_DROPOUT, attention_type=ATTENTION_TYPE,\n",
    "                             pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], \n",
    "                                                                    vocab[TARG_LANG]['token2id']))\n",
    "    model = EncoderDecoderAttn(encoder, decoder, vocab[TARG_LANG]['token2id']).to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.00, Train Loss: 0.00, Val Loss: 10.27, Train BLEU: 0.00, Val BLEU: 0.05, Minutes Elapsed: 0.09\n",
      "Sampling from val predictions...\n",
      "Source: \" trước_khi tôi chết , tôi muốn được hát cho\n",
      "Reference: &quot; before i die , i want to sing\n",
      "Model: <SOS> and and and the the the the leftovers edits\n",
      "Attention Weights: tensor([[0.1003, 0.1006, 0.1004, 0.0999, 0.1002, 0.1001, 0.0999, 0.0997, 0.0995,\n",
      "         0.0994],\n",
      "        [0.1003, 0.1006, 0.1004, 0.0999, 0.1002, 0.1001, 0.0999, 0.0997, 0.0995,\n",
      "         0.0994],\n",
      "        [0.1003, 0.1006, 0.1004, 0.0999, 0.1002, 0.1001, 0.0999, 0.0997, 0.0995,\n",
      "         0.0994],\n",
      "        [0.1003, 0.1006, 0.1004, 0.0999, 0.1002, 0.1001, 0.0999, 0.0997, 0.0995,\n",
      "         0.0994],\n",
      "        [0.1003, 0.1006, 0.1004, 0.0999, 0.1002, 0.1001, 0.0999, 0.0997, 0.0995,\n",
      "         0.0994],\n",
      "        [0.1003, 0.1006, 0.1004, 0.0999, 0.1002, 0.1001, 0.0999, 0.0997, 0.0995,\n",
      "         0.0994],\n",
      "        [0.1003, 0.1006, 0.1004, 0.0999, 0.1002, 0.1001, 0.0999, 0.0997, 0.0995,\n",
      "         0.0994],\n",
      "        [0.1003, 0.1006, 0.1004, 0.0999, 0.1002, 0.1001, 0.0999, 0.0997, 0.0995,\n",
      "         0.0994],\n",
      "        [0.1003, 0.1006, 0.1004, 0.0999, 0.1002, 0.1001, 0.0999, 0.0997, 0.0995,\n",
      "         0.0994]])\n",
      "\n",
      "Source: tôi thấy rằng người mỹ thấy sự yếu_ớt , dễ\n",
      "Reference: i find that americans see the fragility in changes\n",
      "Model: <SOS> and and you of the the edits edits edits\n",
      "Attention Weights: tensor([[0.1009, 0.1002, 0.1001, 0.1002, 0.0999, 0.0997, 0.0997, 0.0992, 0.0999,\n",
      "         0.1002],\n",
      "        [0.1009, 0.1002, 0.1001, 0.1002, 0.0999, 0.0997, 0.0997, 0.0992, 0.0999,\n",
      "         0.1001],\n",
      "        [0.1009, 0.1002, 0.1001, 0.1002, 0.0999, 0.0997, 0.0997, 0.0992, 0.0999,\n",
      "         0.1001],\n",
      "        [0.1009, 0.1002, 0.1001, 0.1002, 0.0999, 0.0997, 0.0997, 0.0992, 0.0999,\n",
      "         0.1001],\n",
      "        [0.1009, 0.1002, 0.1001, 0.1002, 0.0999, 0.0997, 0.0997, 0.0992, 0.0999,\n",
      "         0.1001],\n",
      "        [0.1009, 0.1002, 0.1001, 0.1002, 0.0999, 0.0997, 0.0997, 0.0992, 0.0999,\n",
      "         0.1001],\n",
      "        [0.1009, 0.1002, 0.1001, 0.1002, 0.0999, 0.0997, 0.0997, 0.0992, 0.0999,\n",
      "         0.1001],\n",
      "        [0.1009, 0.1002, 0.1001, 0.1002, 0.0999, 0.0997, 0.0997, 0.0992, 0.0999,\n",
      "         0.1002],\n",
      "        [0.1009, 0.1002, 0.1001, 0.1002, 0.0999, 0.0997, 0.0997, 0.0992, 0.0999,\n",
      "         0.1002]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.24, Train Loss: 0.00, Val Loss: 6.08, Train BLEU: 0.00, Val BLEU: 1.09, Minutes Elapsed: 10.24\n",
      "Sampling from val predictions...\n",
      "Source: không có ngày nào mà tôi không nghĩ về những\n",
      "Reference: there is not a day that goes by that\n",
      "Model: <SOS> so i , , , , , , ,\n",
      "Attention Weights: tensor([[4.1895e-04, 1.9566e-03, 1.3848e-02, 6.9876e-02, 1.6222e-01, 2.1904e-01,\n",
      "         2.1429e-01, 1.7136e-01, 1.0192e-01, 4.5056e-02],\n",
      "        [4.9025e-04, 2.7970e-03, 1.9008e-02, 8.6537e-02, 1.7913e-01, 2.2559e-01,\n",
      "         2.1030e-01, 1.6227e-01, 8.5675e-02, 2.8200e-02],\n",
      "        [4.9962e-06, 3.8118e-05, 3.6232e-04, 4.5243e-03, 1.9264e-02, 4.3134e-02,\n",
      "         4.8139e-02, 6.2703e-02, 1.5846e-01, 6.6337e-01],\n",
      "        [4.8725e-06, 1.5331e-05, 7.2079e-05, 5.7044e-04, 2.5014e-03, 6.5581e-03,\n",
      "         7.8418e-03, 1.1418e-02, 4.6065e-02, 9.2495e-01],\n",
      "        [1.8995e-05, 4.5451e-05, 1.5927e-04, 8.3482e-04, 2.9062e-03, 6.8550e-03,\n",
      "         8.2354e-03, 1.1725e-02, 4.2915e-02, 9.2630e-01],\n",
      "        [4.9109e-05, 1.0586e-04, 3.2819e-04, 1.3910e-03, 4.1703e-03, 9.0265e-03,\n",
      "         1.0782e-02, 1.4973e-02, 4.9064e-02, 9.1011e-01],\n",
      "        [8.9859e-05, 1.8454e-04, 5.3890e-04, 2.0369e-03, 5.5815e-03, 1.1418e-02,\n",
      "         1.3556e-02, 1.8475e-02, 5.5804e-02, 8.9232e-01],\n",
      "        [1.3809e-04, 2.7540e-04, 7.7495e-04, 2.7232e-03, 7.0176e-03, 1.3783e-02,\n",
      "         1.6280e-02, 2.1861e-02, 6.2023e-02, 8.7512e-01],\n",
      "        [1.9064e-04, 3.7272e-04, 1.0222e-03, 3.4150e-03, 8.4160e-03, 1.6029e-02,\n",
      "         1.8849e-02, 2.5013e-02, 6.7535e-02, 8.5916e-01]])\n",
      "\n",
      "Source: không_khí rất vui_vẻ , và họ chia_sẻ những câu_chuyện về\n",
      "Reference: it was cool , and they just shared the\n",
      "Model: <SOS> but , , , , , , , ,\n",
      "Attention Weights: tensor([[0.0006, 0.0053, 0.0412, 0.1107, 0.1471, 0.1913, 0.1881, 0.1575, 0.1099,\n",
      "         0.0483],\n",
      "        [0.0007, 0.0072, 0.0521, 0.1235, 0.1669, 0.1906, 0.1803, 0.1466, 0.0973,\n",
      "         0.0347],\n",
      "        [0.0000, 0.0002, 0.0027, 0.0123, 0.0391, 0.0444, 0.0530, 0.0481, 0.1376,\n",
      "         0.6626],\n",
      "        [0.0000, 0.0001, 0.0006, 0.0024, 0.0089, 0.0105, 0.0138, 0.0127, 0.0523,\n",
      "         0.8987],\n",
      "        [0.0000, 0.0002, 0.0010, 0.0032, 0.0099, 0.0116, 0.0154, 0.0144, 0.0530,\n",
      "         0.8913],\n",
      "        [0.0001, 0.0004, 0.0017, 0.0047, 0.0128, 0.0150, 0.0196, 0.0187, 0.0614,\n",
      "         0.8657],\n",
      "        [0.0002, 0.0006, 0.0024, 0.0063, 0.0157, 0.0184, 0.0237, 0.0229, 0.0692,\n",
      "         0.8404],\n",
      "        [0.0003, 0.0008, 0.0032, 0.0079, 0.0186, 0.0217, 0.0277, 0.0269, 0.0762,\n",
      "         0.8166],\n",
      "        [0.0004, 0.0011, 0.0041, 0.0095, 0.0213, 0.0247, 0.0313, 0.0306, 0.0823,\n",
      "         0.7948]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.48, Train Loss: 0.00, Val Loss: 5.64, Train BLEU: 0.00, Val BLEU: 2.87, Minutes Elapsed: 21.52\n",
      "Sampling from val predictions...\n",
      "Source: anh ta muốn biết mọi thứ về gia_đình tôi và\n",
      "Reference: he wanted to know everything about my family and\n",
      "Model: <SOS> but you you you you to to , the\n",
      "Attention Weights: tensor([[3.1109e-04, 1.9979e-01, 3.8555e-01, 4.0228e-01, 1.1098e-02, 5.9669e-04,\n",
      "         1.2836e-04, 9.8545e-05, 1.0473e-04, 4.7753e-05],\n",
      "        [4.2920e-03, 3.6434e-01, 4.3543e-01, 1.9047e-01, 4.6220e-03, 3.4344e-04,\n",
      "         1.2107e-04, 1.0986e-04, 1.5247e-04, 1.1085e-04],\n",
      "        [2.1252e-03, 1.9112e-01, 5.0596e-01, 2.9625e-01, 4.2569e-03, 1.2129e-04,\n",
      "         2.7962e-05, 3.0423e-05, 7.1564e-05, 4.0404e-05],\n",
      "        [1.7459e-04, 2.3621e-03, 2.6055e-02, 7.6073e-01, 2.0352e-01, 5.8913e-03,\n",
      "         3.8653e-04, 2.6143e-04, 5.1153e-04, 1.1170e-04],\n",
      "        [1.7504e-05, 8.1017e-05, 6.7531e-04, 6.5596e-02, 5.2210e-01, 2.6483e-01,\n",
      "         5.4118e-02, 3.3394e-02, 5.2769e-02, 6.4239e-03],\n",
      "        [1.0814e-06, 4.0148e-06, 2.3099e-05, 1.1712e-03, 2.3900e-02, 7.9077e-02,\n",
      "         1.4435e-01, 2.3001e-01, 4.2889e-01, 9.2578e-02],\n",
      "        [2.0143e-07, 6.8454e-07, 3.1784e-06, 9.4945e-05, 1.5679e-03, 8.5751e-03,\n",
      "         5.1996e-02, 2.0280e-01, 5.2240e-01, 2.1256e-01],\n",
      "        [1.1620e-07, 3.9127e-07, 1.7264e-06, 4.1376e-05, 5.1833e-04, 2.6995e-03,\n",
      "         2.4004e-02, 1.6300e-01, 5.2918e-01, 2.8056e-01],\n",
      "        [9.1855e-08, 3.2745e-07, 1.4471e-06, 3.2498e-05, 3.5295e-04, 1.6512e-03,\n",
      "         1.5621e-02, 1.4199e-01, 5.3598e-01, 3.0437e-01]])\n",
      "\n",
      "Source: nam_nữ thanh_niên đứng_đầu chiến_tuyến đòi lật_đổ chính_quyền , giơ cao\n",
      "Reference: young libyan women and men were at the forefront\n",
      "Model: <SOS> we , the we the , , , ,\n",
      "Attention Weights: tensor([[4.1714e-02, 5.1408e-01, 4.2173e-01, 1.7169e-02, 4.8397e-03, 2.9773e-04,\n",
      "         6.6933e-05, 4.3665e-05, 3.1627e-05, 2.3062e-05],\n",
      "        [5.0207e-02, 7.6998e-01, 1.6543e-01, 9.5938e-03, 4.1289e-03, 3.5145e-04,\n",
      "         9.0678e-05, 1.0896e-04, 5.9805e-05, 4.5365e-05],\n",
      "        [3.5417e-03, 9.6595e-01, 2.4484e-02, 3.1882e-03, 2.7687e-03, 5.7852e-05,\n",
      "         4.0829e-06, 5.7741e-06, 1.6627e-06, 1.0984e-06],\n",
      "        [3.2420e-04, 6.7894e-01, 1.3101e-01, 5.0843e-02, 1.3243e-01, 5.9746e-03,\n",
      "         2.3638e-04, 1.9339e-04, 3.5038e-05, 1.8299e-05],\n",
      "        [1.7642e-05, 1.7688e-02, 6.1458e-02, 4.6350e-02, 6.1029e-01, 1.9191e-01,\n",
      "         3.0059e-02, 3.3281e-02, 6.1318e-03, 2.8152e-03],\n",
      "        [7.1468e-06, 2.0311e-03, 1.2471e-02, 1.1493e-02, 3.1647e-01, 2.1567e-01,\n",
      "         1.0052e-01, 2.2223e-01, 7.4975e-02, 4.4138e-02],\n",
      "        [4.9789e-06, 8.0012e-04, 5.1040e-03, 4.8368e-03, 1.5736e-01, 1.3548e-01,\n",
      "         9.7538e-02, 3.1780e-01, 1.6278e-01, 1.1829e-01],\n",
      "        [4.1909e-06, 5.2665e-04, 3.2004e-03, 3.0545e-03, 1.0194e-01, 9.5020e-02,\n",
      "         8.2182e-02, 3.2867e-01, 2.1123e-01, 1.7417e-01],\n",
      "        [3.8247e-06, 4.1506e-04, 2.4488e-03, 2.3146e-03, 7.6343e-02, 7.3413e-02,\n",
      "         7.0589e-02, 3.1935e-01, 2.3995e-01, 2.1518e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.72, Train Loss: 0.00, Val Loss: 5.28, Train BLEU: 0.00, Val BLEU: 5.45, Minutes Elapsed: 32.51\n",
      "Sampling from val predictions...\n",
      "Source: vậy điều gì đã xảy_ra ? <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: so what happened ? <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> what what what do ? ? ? ? ?\n",
      "Attention Weights: tensor([[0.5941, 0.3611, 0.0336, 0.0027, 0.0016, 0.0065, 0.0005, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0799, 0.7678, 0.1463, 0.0038, 0.0007, 0.0013, 0.0002, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0009, 0.0934, 0.8466, 0.0460, 0.0042, 0.0081, 0.0008, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0018, 0.5157, 0.3615, 0.0400, 0.0789, 0.0022, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0052, 0.1497, 0.1688, 0.6440, 0.0323, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0002, 0.0105, 0.0562, 0.7998, 0.1333, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0002, 0.0060, 0.0373, 0.7568, 0.1997, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0005, 0.0113, 0.0590, 0.7216, 0.2076, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0006, 0.0128, 0.0701, 0.7404, 0.1761, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Source: tất_cả chúng_tôi đều biết đang mạo_hiểm tính_mạng của chính mình\n",
      "Reference: we all knew we were risking our lives --\n",
      "Model: <SOS> so we we the the the the the the\n",
      "Attention Weights: tensor([[5.5079e-02, 9.2807e-01, 1.0443e-02, 5.3033e-03, 2.9382e-04, 2.6989e-04,\n",
      "         1.3424e-04, 1.7482e-04, 1.0908e-04, 1.2159e-04],\n",
      "        [1.7466e-02, 8.1207e-01, 1.5181e-01, 1.7471e-02, 5.7299e-04, 2.7764e-04,\n",
      "         1.1062e-04, 1.1454e-04, 5.6626e-05, 4.5823e-05],\n",
      "        [9.6586e-04, 2.4061e-01, 6.1269e-01, 1.4270e-01, 2.3666e-03, 4.7857e-04,\n",
      "         8.1399e-05, 6.9335e-05, 2.1954e-05, 1.6331e-05],\n",
      "        [2.7234e-06, 7.2054e-04, 9.7779e-02, 8.0291e-01, 8.4680e-02, 1.2140e-02,\n",
      "         1.0246e-03, 6.1185e-04, 8.6158e-05, 4.2629e-05],\n",
      "        [7.3324e-07, 8.1507e-05, 7.2800e-03, 5.0752e-01, 3.2537e-01, 1.4022e-01,\n",
      "         1.2593e-02, 6.1501e-03, 5.7936e-04, 2.1230e-04],\n",
      "        [7.8472e-08, 4.7931e-06, 2.7582e-04, 2.9550e-02, 1.3220e-01, 3.5412e-01,\n",
      "         2.0296e-01, 2.0853e-01, 4.9342e-02, 2.3022e-02],\n",
      "        [4.3777e-08, 1.0896e-06, 2.0690e-05, 1.9448e-03, 1.7546e-02, 1.3252e-01,\n",
      "         1.7174e-01, 4.1398e-01, 1.3813e-01, 1.2412e-01],\n",
      "        [2.2834e-07, 2.6134e-06, 2.3431e-05, 1.4844e-03, 1.0039e-02, 9.6072e-02,\n",
      "         1.3534e-01, 4.3425e-01, 1.4826e-01, 1.7454e-01],\n",
      "        [1.0344e-07, 1.6629e-06, 1.9271e-05, 9.1476e-04, 4.5934e-03, 4.4058e-02,\n",
      "         8.7048e-02, 2.9246e-01, 2.0232e-01, 3.6859e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.96, Train Loss: 0.00, Val Loss: 5.04, Train BLEU: 0.00, Val BLEU: 6.89, Minutes Elapsed: 43.30\n",
      "Sampling from val predictions...\n",
      "Source: trên hết , <UNK> bị bệnh lao , nhưng vẫn\n",
      "Reference: on top of that , <UNK> has tuberculosis ,\n",
      "Model: <SOS> in , , , , , , , ,\n",
      "Attention Weights: tensor([[5.0448e-01, 3.3756e-01, 7.2861e-02, 1.8516e-02, 1.3856e-02, 8.1272e-03,\n",
      "         7.5959e-03, 1.3434e-02, 6.5314e-03, 1.7042e-02],\n",
      "        [2.1620e-01, 6.1080e-01, 1.3397e-01, 2.6025e-02, 7.2920e-03, 2.6447e-03,\n",
      "         1.1039e-03, 8.1176e-04, 5.8066e-04, 5.6614e-04],\n",
      "        [1.1313e-02, 1.7110e-01, 4.9989e-01, 2.5816e-01, 4.9426e-02, 7.7674e-03,\n",
      "         1.1508e-03, 4.7936e-04, 3.8641e-04, 3.2345e-04],\n",
      "        [7.3994e-05, 3.4393e-03, 1.8018e-01, 5.7542e-01, 1.9884e-01, 3.5656e-02,\n",
      "         3.8139e-03, 1.2295e-03, 7.8800e-04, 5.5332e-04],\n",
      "        [1.6353e-06, 9.5483e-05, 1.1623e-02, 3.9134e-01, 4.6819e-01, 1.1666e-01,\n",
      "         9.1985e-03, 1.5871e-03, 8.4743e-04, 4.5152e-04],\n",
      "        [1.1913e-06, 5.5463e-05, 5.8466e-03, 1.6882e-01, 5.3860e-01, 2.3395e-01,\n",
      "         3.6950e-02, 9.1612e-03, 4.1704e-03, 2.4405e-03],\n",
      "        [1.2977e-07, 7.6917e-06, 9.4900e-04, 4.4106e-02, 3.1625e-01, 3.3874e-01,\n",
      "         1.2946e-01, 7.1576e-02, 6.2840e-02, 3.6077e-02],\n",
      "        [5.0280e-07, 2.2143e-05, 9.5796e-04, 2.8217e-02, 1.6608e-01, 2.4397e-01,\n",
      "         1.1525e-01, 1.1312e-01, 1.9658e-01, 1.3581e-01],\n",
      "        [3.2054e-08, 9.4968e-07, 1.9873e-04, 3.4204e-03, 3.9341e-02, 8.1098e-02,\n",
      "         7.8535e-02, 2.1209e-01, 3.3042e-01, 2.5490e-01]])\n",
      "\n",
      "Source: đó là lý_do tại_sao sau 10 năm che dấu danh_tính\n",
      "Reference: that &apos;s why , after 10 years of hiding\n",
      "Model: <SOS> that &apos;s the the : 10 10 in in\n",
      "Attention Weights: tensor([[2.9882e-02, 9.6279e-01, 7.0277e-03, 2.2245e-04, 2.2472e-05, 4.1596e-05,\n",
      "         9.8941e-06, 2.0348e-06, 2.4629e-06, 6.7222e-07],\n",
      "        [3.3711e-03, 8.0941e-01, 1.8300e-01, 4.0456e-03, 1.2824e-04, 2.4453e-05,\n",
      "         9.0498e-06, 2.7944e-06, 2.2822e-06, 9.5991e-07],\n",
      "        [8.1331e-05, 4.9838e-02, 6.8667e-01, 2.3648e-01, 2.3548e-02, 2.7716e-03,\n",
      "         5.2012e-04, 5.8797e-05, 2.8954e-05, 6.3111e-06],\n",
      "        [1.7348e-06, 6.2287e-04, 1.3356e-01, 6.0112e-01, 2.4388e-01, 1.9030e-02,\n",
      "         1.6587e-03, 8.7897e-05, 3.6054e-05, 6.4969e-06],\n",
      "        [3.5848e-07, 3.6305e-05, 1.2810e-02, 3.1824e-01, 6.0031e-01, 6.4010e-02,\n",
      "         4.4386e-03, 1.1672e-04, 3.4696e-05, 4.3170e-06],\n",
      "        [1.3001e-08, 1.5672e-06, 2.8412e-04, 1.0010e-02, 2.4373e-01, 4.4729e-01,\n",
      "         2.8156e-01, 1.4716e-02, 2.3620e-03, 4.0835e-05],\n",
      "        [5.1479e-09, 5.6285e-07, 6.9709e-05, 1.1546e-03, 3.7719e-02, 2.4466e-01,\n",
      "         5.0821e-01, 1.3691e-01, 6.9127e-02, 2.1513e-03],\n",
      "        [4.3459e-09, 1.4412e-07, 1.4258e-05, 2.6543e-04, 1.3041e-02, 1.6151e-01,\n",
      "         5.2078e-01, 1.8490e-01, 1.1409e-01, 5.4035e-03],\n",
      "        [2.4556e-09, 7.7503e-08, 5.1415e-06, 7.4074e-05, 2.6721e-03, 3.8627e-02,\n",
      "         2.7435e-01, 2.8366e-01, 3.5485e-01, 4.5761e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1.00, Train Loss: 0.00, Val Loss: 5.04, Train BLEU: 0.00, Val BLEU: 7.27, Minutes Elapsed: 45.20\n",
      "Sampling from val predictions...\n",
      "Source: ở trường , chúng_tôi dành rất nhiều thời_gian để học\n",
      "Reference: in school , we spent a lot of time\n",
      "Model: <SOS> in , , we we a to of to\n",
      "Attention Weights: tensor([[2.1911e-01, 4.3436e-01, 3.0398e-01, 4.1566e-02, 2.9119e-04, 1.8882e-04,\n",
      "         4.1314e-05, 2.2313e-05, 2.9036e-04, 1.5379e-04],\n",
      "        [6.2296e-02, 2.7693e-01, 4.3900e-01, 1.8985e-01, 2.0682e-02, 6.3884e-03,\n",
      "         1.6057e-03, 6.5357e-04, 1.6536e-03, 9.4328e-04],\n",
      "        [5.2712e-03, 2.6712e-02, 2.5174e-01, 6.5273e-01, 5.6282e-02, 6.2013e-03,\n",
      "         5.2060e-04, 1.1413e-04, 3.1005e-04, 1.1416e-04],\n",
      "        [8.7959e-04, 6.8886e-03, 2.7033e-01, 6.6883e-01, 4.7484e-02, 5.0833e-03,\n",
      "         2.3292e-04, 3.0168e-05, 1.9868e-04, 4.5547e-05],\n",
      "        [7.2143e-05, 4.0986e-04, 2.2137e-02, 5.0913e-01, 4.1142e-01, 5.4652e-02,\n",
      "         1.8350e-03, 8.2324e-05, 2.2915e-04, 3.5902e-05],\n",
      "        [1.1463e-04, 4.5124e-04, 9.5252e-03, 2.4158e-01, 4.2054e-01, 2.7893e-01,\n",
      "         3.5760e-02, 3.2298e-03, 8.2712e-03, 1.5924e-03],\n",
      "        [5.9982e-06, 2.4751e-05, 8.7829e-04, 2.7609e-02, 1.7263e-01, 4.7996e-01,\n",
      "         1.9609e-01, 3.8815e-02, 6.6188e-02, 1.7804e-02],\n",
      "        [1.0906e-05, 3.9783e-05, 1.4419e-03, 3.5934e-02, 1.5149e-01, 4.5819e-01,\n",
      "         1.7393e-01, 3.8785e-02, 1.1219e-01, 2.7980e-02],\n",
      "        [1.8768e-05, 5.5761e-05, 2.0833e-03, 3.9341e-02, 6.4584e-02, 2.0811e-01,\n",
      "         9.9772e-02, 4.5637e-02, 4.3484e-01, 1.0556e-01]])\n",
      "\n",
      "Source: nếu bạn không phải là thợ làm_vườn thì bạn không_phải\n",
      "Reference: if you ain &apos;t a gardener , you ain\n",
      "Model: <SOS> if you don &apos;t know if , you can\n",
      "Attention Weights: tensor([[1.5991e-01, 8.3808e-01, 1.8444e-03, 5.9915e-05, 4.5749e-05, 1.4353e-05,\n",
      "         7.5666e-06, 1.4843e-05, 2.2014e-05, 2.1103e-06],\n",
      "        [4.7411e-03, 7.6082e-01, 2.3180e-01, 2.3557e-03, 2.2738e-04, 3.4378e-05,\n",
      "         9.9208e-06, 5.3675e-06, 4.1153e-06, 1.3849e-06],\n",
      "        [6.3083e-05, 6.1132e-02, 8.7255e-01, 6.0059e-02, 5.7209e-03, 4.1984e-04,\n",
      "         4.0447e-05, 9.2970e-06, 5.0663e-06, 1.0603e-06],\n",
      "        [1.1858e-05, 1.6612e-02, 7.0793e-01, 2.1350e-01, 5.4569e-02, 6.4656e-03,\n",
      "         7.1811e-04, 1.3474e-04, 5.5199e-05, 8.6917e-06],\n",
      "        [2.5840e-06, 8.8503e-04, 4.4946e-02, 2.5445e-01, 4.7435e-01, 1.7654e-01,\n",
      "         4.0403e-02, 6.2470e-03, 2.0246e-03, 1.5733e-04],\n",
      "        [3.5276e-07, 1.0969e-04, 8.9282e-03, 5.9665e-02, 1.6033e-01, 3.3859e-01,\n",
      "         2.5465e-01, 1.1879e-01, 5.3007e-02, 5.9334e-03],\n",
      "        [2.7254e-07, 4.0670e-05, 2.1727e-03, 1.6251e-02, 5.7634e-02, 2.7327e-01,\n",
      "         3.2126e-01, 2.1175e-01, 1.0484e-01, 1.2775e-02],\n",
      "        [7.3134e-07, 4.8104e-05, 7.4839e-04, 3.0573e-03, 1.2068e-02, 9.8710e-02,\n",
      "         1.4590e-01, 3.6341e-01, 3.4421e-01, 3.1854e-02],\n",
      "        [3.4959e-07, 3.0830e-05, 7.0575e-04, 3.2569e-03, 6.4418e-03, 3.3109e-02,\n",
      "         7.7753e-02, 2.7434e-01, 4.6272e-01, 1.4164e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1.24, Train Loss: 0.00, Val Loss: 4.87, Train BLEU: 0.00, Val BLEU: 8.79, Minutes Elapsed: 56.03\n",
      "Sampling from val predictions...\n",
      "Source: ít_hơn một tháng rồi , ông và con_gái ông đang\n",
      "Reference: less than a month ago , he and his\n",
      "Model: <SOS> there a , , , and and and and\n",
      "Attention Weights: tensor([[9.6667e-01, 3.2346e-02, 6.5517e-04, 2.3073e-04, 3.3588e-05, 1.7924e-05,\n",
      "         2.3568e-05, 2.0977e-06, 1.2134e-05, 7.1022e-06],\n",
      "        [4.3897e-01, 4.8109e-01, 7.3699e-02, 5.8290e-03, 2.0132e-04, 1.0833e-04,\n",
      "         7.3203e-05, 6.9691e-06, 1.3156e-05, 6.0089e-06],\n",
      "        [1.0274e-02, 6.0512e-02, 3.9560e-01, 4.9466e-01, 2.6222e-02, 1.0718e-02,\n",
      "         1.7908e-03, 6.7190e-05, 1.3160e-04, 2.2971e-05],\n",
      "        [3.1197e-04, 3.0582e-03, 5.9663e-02, 6.5807e-01, 1.5870e-01, 9.9901e-02,\n",
      "         1.7830e-02, 7.4837e-04, 1.4943e-03, 2.2813e-04],\n",
      "        [3.8427e-05, 3.8285e-04, 7.4162e-03, 1.4312e-01, 2.2126e-01, 5.0135e-01,\n",
      "         1.0982e-01, 6.5087e-03, 8.7778e-03, 1.3164e-03],\n",
      "        [1.8247e-05, 1.0283e-04, 1.1452e-03, 6.1080e-02, 2.1573e-01, 5.3838e-01,\n",
      "         1.5779e-01, 7.2734e-03, 1.6002e-02, 2.4902e-03],\n",
      "        [5.5011e-06, 4.5809e-05, 4.1397e-04, 4.8352e-03, 2.8809e-02, 4.8545e-01,\n",
      "         2.8827e-01, 7.3921e-02, 1.0272e-01, 1.5529e-02],\n",
      "        [2.5743e-06, 2.4653e-05, 2.2635e-04, 2.5318e-03, 1.5030e-02, 2.8547e-01,\n",
      "         2.3604e-01, 1.2597e-01, 2.7786e-01, 5.6849e-02],\n",
      "        [1.6568e-06, 3.2877e-05, 3.4665e-04, 1.2180e-03, 4.0489e-03, 6.9735e-02,\n",
      "         5.9344e-02, 1.1701e-01, 5.4291e-01, 2.0536e-01]])\n",
      "\n",
      "Source: tôi đã có cơ_hội đi đến đây bằng máy_bay lần\n",
      "Reference: i got a chance to come by plane for\n",
      "Model: <SOS> i i a a of a a the to\n",
      "Attention Weights: tensor([[9.9100e-01, 8.6251e-03, 3.2486e-04, 3.5361e-05, 7.0015e-06, 2.8931e-06,\n",
      "         1.3702e-06, 6.4941e-07, 2.5422e-07, 4.2588e-07],\n",
      "        [9.7183e-02, 7.4497e-01, 1.5255e-01, 4.9810e-03, 2.2041e-04, 5.2061e-05,\n",
      "         2.2734e-05, 1.5237e-05, 6.2560e-06, 4.8957e-06],\n",
      "        [3.1321e-03, 8.0328e-02, 7.5812e-01, 1.4795e-01, 9.0997e-03, 1.1134e-03,\n",
      "         1.9932e-04, 4.1872e-05, 6.4147e-06, 4.9720e-06],\n",
      "        [5.7519e-05, 1.1232e-03, 1.5038e-01, 6.5287e-01, 1.6205e-01, 2.8684e-02,\n",
      "         4.1053e-03, 6.2354e-04, 6.5890e-05, 3.5456e-05],\n",
      "        [2.9734e-05, 1.1752e-04, 1.0739e-02, 2.7502e-01, 4.0161e-01, 2.3838e-01,\n",
      "         5.7819e-02, 1.3989e-02, 1.5012e-03, 7.9402e-04],\n",
      "        [5.9670e-05, 7.1151e-05, 1.6430e-03, 4.1444e-02, 1.5134e-01, 3.5971e-01,\n",
      "         2.6159e-01, 1.4089e-01, 2.2734e-02, 2.0513e-02],\n",
      "        [5.8037e-08, 5.9150e-07, 3.5642e-05, 2.2105e-03, 1.2131e-02, 7.8235e-02,\n",
      "         2.0294e-01, 3.4584e-01, 1.9039e-01, 1.6821e-01],\n",
      "        [8.8782e-08, 3.4858e-07, 7.8507e-06, 5.1023e-04, 3.1914e-03, 2.7886e-02,\n",
      "         1.1176e-01, 2.9936e-01, 2.4276e-01, 3.1452e-01],\n",
      "        [3.4902e-07, 6.6790e-07, 6.9348e-06, 3.0891e-04, 1.9733e-03, 1.8404e-02,\n",
      "         8.7723e-02, 2.5134e-01, 2.3273e-01, 4.0751e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1.48, Train Loss: 0.00, Val Loss: 4.75, Train BLEU: 0.00, Val BLEU: 9.24, Minutes Elapsed: 67.40\n",
      "Sampling from val predictions...\n",
      "Source: tôi muốn nó được biết đến bởi công_chúng . <EOS>\n",
      "Reference: i want to make them public . <EOS> <PAD>\n",
      "Model: <SOS> i want to to to . . . <EOS>\n",
      "Attention Weights: tensor([[9.9420e-01, 5.7906e-03, 2.2460e-06, 1.4440e-06, 7.4632e-07, 1.7974e-07,\n",
      "         6.8389e-08, 4.1479e-08, 6.6968e-08, 2.5515e-08],\n",
      "        [4.1085e-03, 9.9522e-01, 5.1466e-04, 1.2767e-04, 2.2893e-05, 2.7911e-06,\n",
      "         9.3116e-07, 2.2692e-07, 1.7056e-07, 1.2627e-07],\n",
      "        [2.2006e-03, 7.9614e-01, 1.3934e-01, 4.8737e-02, 1.2652e-02, 8.1392e-04,\n",
      "         9.8372e-05, 8.6334e-06, 3.4152e-06, 1.5942e-06],\n",
      "        [1.0529e-03, 7.7154e-02, 1.7503e-01, 3.6277e-01, 3.3914e-01, 3.9575e-02,\n",
      "         4.9292e-03, 2.7277e-04, 5.8295e-05, 2.0106e-05],\n",
      "        [9.1510e-06, 1.0690e-03, 1.8939e-02, 1.3235e-01, 4.9674e-01, 2.5234e-01,\n",
      "         9.3601e-02, 4.4905e-03, 3.8161e-04, 7.4998e-05],\n",
      "        [2.7027e-06, 1.3194e-04, 2.1195e-03, 2.9385e-02, 2.5215e-01, 3.5310e-01,\n",
      "         3.1991e-01, 3.9187e-02, 3.3386e-03, 6.7691e-04],\n",
      "        [4.2001e-06, 7.0202e-05, 4.7518e-04, 5.6025e-03, 9.5645e-02, 3.0373e-01,\n",
      "         4.3251e-01, 1.3136e-01, 2.4135e-02, 6.4701e-03],\n",
      "        [4.1846e-07, 2.2631e-05, 2.1367e-04, 2.3409e-03, 2.8115e-02, 1.2724e-01,\n",
      "         3.8195e-01, 3.4899e-01, 7.9277e-02, 3.1853e-02],\n",
      "        [6.4973e-06, 1.2714e-04, 6.1977e-04, 3.6587e-03, 3.1190e-02, 1.0863e-01,\n",
      "         2.6171e-01, 3.8192e-01, 1.2791e-01, 8.4230e-02]])\n",
      "\n",
      "Source: và vì_thế các động_vật ăn_thịt như sư_tử theo sau chúng\n",
      "Reference: so predators like lions follow them , and this\n",
      "Model: <SOS> and so the the , , , the we\n",
      "Attention Weights: tensor([[1.7371e-02, 7.5648e-01, 1.2441e-01, 2.9338e-02, 3.1733e-03, 2.1796e-02,\n",
      "         3.4721e-02, 5.2421e-03, 4.5243e-03, 2.9443e-03],\n",
      "        [2.1750e-03, 7.7130e-01, 2.0659e-01, 1.9789e-02, 9.6458e-05, 2.5165e-05,\n",
      "         1.6455e-05, 4.8450e-06, 2.9549e-06, 2.6329e-06],\n",
      "        [2.9764e-04, 1.1859e-02, 1.4429e-01, 8.1196e-01, 3.1047e-02, 4.6735e-04,\n",
      "         1.4136e-05, 4.0557e-05, 1.3867e-05, 1.2692e-05],\n",
      "        [2.5373e-05, 3.0903e-03, 5.3390e-02, 5.5829e-01, 3.4464e-01, 3.4343e-02,\n",
      "         1.4088e-03, 4.0520e-03, 5.0142e-04, 2.5955e-04],\n",
      "        [1.2496e-07, 4.1433e-06, 9.3328e-05, 3.1215e-03, 7.4381e-02, 3.0330e-01,\n",
      "         8.5769e-02, 3.4379e-01, 1.4068e-01, 4.8872e-02],\n",
      "        [4.5986e-09, 1.3023e-07, 4.2224e-06, 1.0678e-04, 2.6314e-03, 2.3832e-02,\n",
      "         2.2435e-02, 2.1432e-01, 4.6426e-01, 2.7241e-01],\n",
      "        [1.4450e-09, 4.8720e-08, 1.4409e-06, 2.4956e-05, 4.8193e-04, 3.1641e-03,\n",
      "         3.1255e-03, 6.1670e-02, 3.9950e-01, 5.3203e-01],\n",
      "        [1.9734e-09, 7.1932e-08, 2.3478e-06, 3.8248e-05, 5.5007e-04, 2.1805e-03,\n",
      "         1.6518e-03, 3.4113e-02, 2.9116e-01, 6.7030e-01],\n",
      "        [1.6644e-09, 9.4010e-08, 3.1156e-06, 5.3294e-05, 8.7507e-04, 2.5313e-03,\n",
      "         1.4085e-03, 4.0297e-02, 2.5513e-01, 6.9970e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1.96, Train Loss: 0.00, Val Loss: 4.55, Train BLEU: 0.00, Val BLEU: 10.39, Minutes Elapsed: 90.76\n",
      "Sampling from val predictions...\n",
      "Source: bạn sẽ kết_luận được gì từ những mẫu này ?\n",
      "Reference: what are you going to get out of those\n",
      "Model: <SOS> do you you you to this this ? ?\n",
      "Attention Weights: tensor([[9.8774e-01, 1.0317e-02, 2.0967e-04, 4.0014e-04, 4.5431e-04, 1.2998e-04,\n",
      "         4.1852e-05, 1.3556e-04, 2.5601e-04, 3.1591e-04],\n",
      "        [1.2853e-01, 8.5254e-01, 1.7124e-02, 1.3461e-03, 3.0450e-04, 8.6342e-05,\n",
      "         3.7459e-05, 1.9689e-05, 8.1277e-06, 5.5860e-06],\n",
      "        [3.9271e-02, 5.5683e-01, 2.9514e-01, 9.4012e-02, 1.3017e-02, 1.2351e-03,\n",
      "         3.6718e-04, 1.0015e-04, 1.7092e-05, 1.2333e-05],\n",
      "        [9.2682e-03, 2.7147e-01, 3.7502e-01, 2.7337e-01, 6.2054e-02, 6.5098e-03,\n",
      "         1.7900e-03, 4.4421e-04, 4.4870e-05, 3.1666e-05],\n",
      "        [6.8176e-04, 2.9317e-03, 3.8648e-02, 2.3446e-01, 5.1100e-01, 1.5413e-01,\n",
      "         4.4314e-02, 1.2911e-02, 6.4015e-04, 2.7901e-04],\n",
      "        [1.1069e-04, 5.0662e-04, 1.7174e-02, 1.1759e-01, 3.7811e-01, 2.8741e-01,\n",
      "         1.4482e-01, 5.0085e-02, 2.9712e-03, 1.2130e-03],\n",
      "        [2.7542e-05, 1.4207e-04, 7.1980e-03, 5.8983e-02, 2.5854e-01, 3.1501e-01,\n",
      "         2.2416e-01, 1.1860e-01, 1.1914e-02, 5.4245e-03],\n",
      "        [4.0780e-05, 6.7772e-05, 2.1042e-03, 1.7879e-02, 1.1184e-01, 2.7909e-01,\n",
      "         2.9289e-01, 2.3715e-01, 3.5199e-02, 2.3737e-02],\n",
      "        [5.0089e-05, 3.9128e-05, 6.6577e-04, 7.0770e-03, 5.0190e-02, 1.6696e-01,\n",
      "         2.5964e-01, 3.3514e-01, 9.0123e-02, 9.0113e-02]])\n",
      "\n",
      "Source: ít_hơn 6 % phụ_nữ tuổi_tôi được học sau trung_học phổ_thông\n",
      "Reference: fewer than six percent of women my age have\n",
      "Model: <SOS> six percent percent percent of the , in ,\n",
      "Attention Weights: tensor([[9.2642e-01, 2.8265e-03, 5.2975e-02, 2.7680e-03, 8.1709e-04, 4.7729e-03,\n",
      "         5.0692e-03, 3.2609e-03, 6.5680e-04, 4.3372e-04],\n",
      "        [7.1425e-02, 3.8655e-02, 8.5102e-01, 3.6223e-02, 1.9117e-03, 4.5357e-04,\n",
      "         1.7885e-04, 1.0442e-04, 1.6458e-05, 8.7146e-06],\n",
      "        [1.8470e-03, 8.5512e-03, 7.8136e-01, 1.7113e-01, 2.5590e-02, 8.5706e-03,\n",
      "         2.3522e-03, 5.5710e-04, 3.5498e-05, 1.1575e-05],\n",
      "        [4.6124e-05, 8.8343e-04, 2.1789e-01, 3.5871e-01, 1.5895e-01, 1.7745e-01,\n",
      "         7.1501e-02, 1.3709e-02, 7.2019e-04, 1.3395e-04],\n",
      "        [1.6413e-05, 1.2687e-04, 2.6896e-02, 1.0022e-01, 1.0201e-01, 3.9218e-01,\n",
      "         2.7044e-01, 1.0014e-01, 6.5519e-03, 1.4217e-03],\n",
      "        [2.5186e-06, 2.4713e-05, 3.2665e-03, 2.2787e-02, 3.1571e-02, 2.3562e-01,\n",
      "         2.6395e-01, 3.3885e-01, 6.5314e-02, 3.8611e-02],\n",
      "        [6.9675e-07, 1.9339e-05, 1.2720e-03, 1.2154e-02, 2.1597e-02, 1.5237e-01,\n",
      "         1.7703e-01, 3.1409e-01, 1.4731e-01, 1.7415e-01],\n",
      "        [7.7334e-06, 1.2522e-05, 8.6364e-04, 7.2967e-03, 9.6327e-03, 1.6648e-01,\n",
      "         1.7750e-01, 3.3396e-01, 1.3961e-01, 1.6464e-01],\n",
      "        [3.1483e-07, 1.2272e-05, 1.1108e-03, 4.5629e-03, 1.0008e-02, 7.9102e-02,\n",
      "         1.0898e-01, 2.6833e-01, 2.1716e-01, 3.1074e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2.00, Train Loss: 0.00, Val Loss: 4.59, Train BLEU: 0.00, Val BLEU: 9.84, Minutes Elapsed: 92.81\n",
      "Sampling from val predictions...\n",
      "Source: quân_cảnh không giúp ngăn_chặn sự lây_lan của bệnh_tật . <EOS>\n",
      "Reference: mps do not help to prevent the spread of\n",
      "Model: <SOS> it &apos;s &apos;t work the the the of of\n",
      "Attention Weights: tensor([[8.1926e-01, 1.5307e-01, 8.3508e-03, 7.9221e-04, 1.5917e-03, 2.2907e-04,\n",
      "         6.5635e-03, 3.8017e-03, 4.8734e-03, 1.4708e-03],\n",
      "        [2.6547e-01, 6.7194e-01, 5.7956e-02, 3.5603e-03, 7.3159e-04, 9.5703e-05,\n",
      "         1.8828e-04, 3.7181e-05, 1.0837e-05, 4.9104e-06],\n",
      "        [1.4337e-01, 4.5997e-01, 2.3770e-01, 7.6306e-02, 5.1307e-02, 9.0983e-03,\n",
      "         1.8221e-02, 3.7371e-03, 2.2958e-04, 5.9899e-05],\n",
      "        [2.4639e-03, 2.3536e-02, 2.1919e-01, 3.0266e-01, 2.5961e-01, 6.6156e-02,\n",
      "         9.7986e-02, 2.6960e-02, 1.2818e-03, 1.6240e-04],\n",
      "        [1.0097e-04, 3.5534e-03, 7.3458e-02, 1.6465e-01, 3.5569e-01, 8.8614e-02,\n",
      "         2.3033e-01, 7.7635e-02, 5.1325e-03, 8.2575e-04],\n",
      "        [2.7693e-05, 1.1933e-03, 2.4963e-02, 9.3919e-02, 2.8207e-01, 1.3993e-01,\n",
      "         2.8585e-01, 1.5328e-01, 1.6099e-02, 2.6748e-03],\n",
      "        [9.8119e-06, 3.4884e-04, 8.4281e-03, 3.6280e-02, 1.7973e-01, 1.3946e-01,\n",
      "         3.2722e-01, 2.6537e-01, 3.6201e-02, 6.9507e-03],\n",
      "        [7.5762e-06, 1.3282e-04, 4.0112e-03, 2.5643e-02, 1.4206e-01, 1.9244e-01,\n",
      "         3.1001e-01, 2.7953e-01, 3.9756e-02, 6.4154e-03],\n",
      "        [1.5004e-05, 2.0390e-04, 2.1843e-03, 7.0440e-03, 6.4497e-02, 1.0316e-01,\n",
      "         2.9385e-01, 4.2892e-01, 8.0753e-02, 1.9372e-02]])\n",
      "\n",
      "Source: vậy điều gì đã xảy_ra ? <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: so what happened ? <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> what what what we <EOS> <EOS> <EOS> ? ?\n",
      "Attention Weights: tensor([[0.7839, 0.1585, 0.0481, 0.0038, 0.0002, 0.0054, 0.0002, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2833, 0.4534, 0.2358, 0.0248, 0.0014, 0.0012, 0.0002, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0776, 0.2810, 0.2870, 0.2178, 0.0918, 0.0397, 0.0052, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0344, 0.1563, 0.2399, 0.2028, 0.2102, 0.1228, 0.0337, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0008, 0.0148, 0.1096, 0.2150, 0.3709, 0.2376, 0.0511, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0006, 0.0128, 0.0999, 0.3545, 0.3670, 0.1651, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0010, 0.0196, 0.1139, 0.3339, 0.2954, 0.2361, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0056, 0.0604, 0.1859, 0.3510, 0.2058, 0.1911, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0015, 0.0147, 0.1042, 0.1900, 0.3138, 0.2138, 0.1620, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2.24, Train Loss: 0.00, Val Loss: 4.50, Train BLEU: 0.00, Val BLEU: 11.28, Minutes Elapsed: 103.35\n",
      "Sampling from val predictions...\n",
      "Source: một trát hầu_toà vì trồng cây trên mảnh đất mà\n",
      "Reference: a warrant for planting food on a piece of\n",
      "Model: <SOS> a &apos;s thing because , in the , ,\n",
      "Attention Weights: tensor([[9.7639e-01, 1.9796e-02, 2.5145e-03, 7.6359e-04, 9.8056e-05, 1.9116e-04,\n",
      "         3.0097e-05, 2.1513e-05, 4.1488e-05, 1.5818e-04],\n",
      "        [2.0960e-02, 6.9705e-01, 2.6724e-01, 1.3307e-02, 1.2329e-03, 1.3970e-04,\n",
      "         4.3469e-05, 1.2116e-05, 5.4991e-06, 5.4061e-06],\n",
      "        [2.9599e-02, 2.0620e-01, 5.2333e-01, 2.0550e-01, 2.5154e-02, 8.7486e-03,\n",
      "         1.2925e-03, 1.2639e-04, 2.1904e-05, 2.6456e-05],\n",
      "        [3.1687e-03, 1.6688e-02, 2.8960e-01, 4.5052e-01, 1.5846e-01, 6.9506e-02,\n",
      "         1.0373e-02, 1.0137e-03, 2.4453e-04, 4.2508e-04],\n",
      "        [1.9802e-06, 1.7353e-04, 3.8425e-02, 1.4227e-01, 3.5442e-01, 3.5027e-01,\n",
      "         1.0266e-01, 9.8438e-03, 1.0082e-03, 9.2603e-04],\n",
      "        [2.7059e-06, 4.7863e-05, 5.0720e-03, 3.2641e-02, 1.5187e-01, 4.3971e-01,\n",
      "         2.8251e-01, 5.4680e-02, 1.4305e-02, 1.9149e-02],\n",
      "        [1.4135e-08, 1.0334e-06, 8.8645e-05, 7.6466e-04, 9.5229e-03, 8.4743e-02,\n",
      "         2.5570e-01, 1.9793e-01, 1.5768e-01, 2.9357e-01],\n",
      "        [1.6977e-08, 1.8019e-06, 9.2799e-05, 5.5302e-04, 4.4207e-03, 3.1013e-02,\n",
      "         9.9151e-02, 1.1174e-01, 1.5137e-01, 6.0165e-01],\n",
      "        [2.2266e-07, 4.3794e-06, 1.7876e-04, 8.0796e-04, 2.5697e-03, 1.8369e-02,\n",
      "         3.9321e-02, 4.7541e-02, 1.0640e-01, 7.8481e-01]])\n",
      "\n",
      "Source: và cuối_cùng , tôi đã có một thoả_thuận với họ\n",
      "Reference: so at the end , i had a settlement\n",
      "Model: <SOS> and finally finally , , i had a a\n",
      "Attention Weights: tensor([[1.4663e-03, 9.0207e-01, 3.4282e-02, 6.0945e-02, 7.5316e-04, 1.9242e-04,\n",
      "         4.4049e-05, 6.3475e-06, 1.5507e-04, 8.5467e-05],\n",
      "        [6.3418e-04, 9.8659e-01, 1.0040e-02, 2.6114e-03, 9.0400e-05, 2.4642e-05,\n",
      "         5.1322e-06, 9.1152e-07, 2.1101e-06, 9.5670e-07],\n",
      "        [3.2947e-04, 4.2452e-01, 3.0879e-01, 1.9206e-01, 6.6059e-02, 7.7222e-03,\n",
      "         3.8959e-04, 4.9677e-05, 5.5531e-05, 2.2576e-05],\n",
      "        [1.1224e-06, 2.5811e-03, 3.1120e-02, 2.5633e-01, 6.0601e-01, 1.0219e-01,\n",
      "         1.6692e-03, 5.1119e-05, 3.2861e-05, 7.6662e-06],\n",
      "        [6.5046e-07, 8.2285e-04, 6.4974e-02, 5.1838e-01, 3.1162e-01, 9.7002e-02,\n",
      "         6.6937e-03, 2.0956e-04, 2.5596e-04, 4.1922e-05],\n",
      "        [1.9577e-06, 8.1666e-04, 9.3575e-02, 6.2147e-01, 2.2613e-01, 5.2570e-02,\n",
      "         4.7701e-03, 2.4569e-04, 3.5155e-04, 6.7636e-05],\n",
      "        [7.3039e-08, 7.0932e-05, 5.6636e-03, 2.5827e-01, 4.9499e-01, 2.1984e-01,\n",
      "         1.8892e-02, 1.1923e-03, 9.1944e-04, 1.5748e-04],\n",
      "        [7.2975e-08, 3.2615e-05, 4.3438e-04, 2.8363e-03, 1.3766e-01, 7.0759e-01,\n",
      "         1.3747e-01, 8.0196e-03, 5.2318e-03, 7.3101e-04],\n",
      "        [1.1360e-08, 6.3039e-06, 8.9544e-05, 3.6597e-04, 1.9654e-03, 2.3259e-02,\n",
      "         2.9172e-01, 3.8079e-01, 2.7147e-01, 3.0331e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2.48, Train Loss: 0.00, Val Loss: 4.44, Train BLEU: 0.00, Val BLEU: 11.23, Minutes Elapsed: 111.76\n",
      "Sampling from val predictions...\n",
      "Source: tôi cùng_với nhóm của tôi , những mảnh_đất xanh l.\n",
      "Reference: so me and my group , l.a. green grounds\n",
      "Model: <SOS> i was my my , , the , of\n",
      "Attention Weights: tensor([[9.8508e-01, 8.5669e-03, 1.1303e-03, 3.6798e-03, 1.5252e-03, 1.4290e-05,\n",
      "         1.8553e-06, 1.4194e-06, 5.2284e-07, 3.4240e-07],\n",
      "        [2.2354e-02, 9.2326e-01, 4.6965e-02, 6.9513e-03, 3.8887e-04, 2.9697e-05,\n",
      "         2.7524e-05, 1.5697e-05, 6.5979e-06, 1.8540e-06],\n",
      "        [1.9649e-02, 3.6568e-01, 3.8433e-01, 2.1318e-01, 1.5906e-02, 9.3315e-04,\n",
      "         1.9474e-04, 1.0463e-04, 2.1080e-05, 5.1352e-06],\n",
      "        [1.9346e-02, 4.5190e-01, 3.1397e-01, 1.9081e-01, 2.0598e-02, 2.4435e-03,\n",
      "         6.2416e-04, 2.5440e-04, 4.8571e-05, 9.0200e-06],\n",
      "        [6.4529e-04, 4.5919e-02, 2.8047e-01, 3.3092e-01, 2.2421e-01, 7.4735e-02,\n",
      "         3.4592e-02, 7.3935e-03, 9.9797e-04, 1.1527e-04],\n",
      "        [6.1946e-04, 2.1851e-02, 5.9465e-02, 7.7081e-02, 8.4881e-02, 3.4815e-01,\n",
      "         2.8160e-01, 1.0048e-01, 2.3093e-02, 2.7770e-03],\n",
      "        [4.6028e-05, 3.2905e-04, 1.6595e-03, 3.6073e-03, 9.4403e-03, 8.7157e-02,\n",
      "         6.6433e-01, 1.7976e-01, 4.6447e-02, 7.2247e-03],\n",
      "        [6.2204e-06, 4.5022e-05, 4.7806e-04, 1.2290e-03, 4.3144e-03, 2.0952e-02,\n",
      "         4.4985e-01, 4.0267e-01, 1.0022e-01, 2.0230e-02],\n",
      "        [1.2480e-05, 1.6901e-04, 1.1291e-03, 1.1228e-03, 2.2039e-03, 7.9310e-03,\n",
      "         1.1007e-01, 3.4080e-01, 3.7890e-01, 1.5766e-01]])\n",
      "\n",
      "Source: họ sẽ bị <UNK> trong phân ngựa . <EOS> <PAD>\n",
      "Reference: they were already drowning in manure . <EOS> <PAD>\n",
      "Model: <SOS> they will going to the <EOS> . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9674, 0.0325, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0021, 0.9849, 0.0128, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0038, 0.2788, 0.6913, 0.0222, 0.0030, 0.0009, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0048, 0.4601, 0.2652, 0.1793, 0.0747, 0.0149, 0.0005, 0.0001,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0009, 0.0201, 0.0299, 0.3674, 0.4780, 0.0987, 0.0041, 0.0008,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0002, 0.0016, 0.0025, 0.1810, 0.6061, 0.1932, 0.0126, 0.0028,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0001, 0.0010, 0.0013, 0.0397, 0.4660, 0.3524, 0.0835, 0.0560,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0004, 0.0012, 0.0008, 0.0171, 0.2593, 0.3106, 0.2284, 0.1821,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0006, 0.0032, 0.0036, 0.0398, 0.3439, 0.3079, 0.1268, 0.1741,\n",
      "         0.0000]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2.96, Train Loss: 0.00, Val Loss: 4.32, Train BLEU: 0.00, Val BLEU: 12.31, Minutes Elapsed: 128.64\n",
      "Sampling from val predictions...\n",
      "Source: nhựa_đường xốp là vật_liệu chúng_tôi hiện đang dùng để xây_dựng\n",
      "Reference: porous asphalt , a material that we use now\n",
      "Model: <SOS> the &apos;s the the &apos;re of we &apos;re to\n",
      "Attention Weights: tensor([[8.5090e-01, 8.4259e-02, 1.8020e-02, 5.2035e-03, 3.7847e-02, 3.3947e-04,\n",
      "         3.9729e-04, 8.3862e-04, 1.6893e-03, 5.0781e-04],\n",
      "        [1.4527e-01, 7.3810e-01, 7.3073e-02, 3.4752e-02, 8.0176e-03, 6.0270e-04,\n",
      "         9.9990e-05, 4.5536e-05, 2.1207e-05, 1.2839e-05],\n",
      "        [8.8965e-02, 1.8898e-01, 3.1554e-01, 2.4292e-01, 1.5217e-01, 8.1848e-03,\n",
      "         2.8096e-03, 3.7955e-04, 3.9963e-05, 1.1966e-05],\n",
      "        [3.5673e-04, 1.8287e-03, 1.1159e-02, 4.6652e-01, 3.6004e-01, 9.8635e-02,\n",
      "         4.5893e-02, 1.3393e-02, 1.8369e-03, 3.4674e-04],\n",
      "        [1.4270e-06, 1.3954e-04, 1.8173e-03, 1.7576e-01, 1.4336e-01, 2.0525e-01,\n",
      "         2.7353e-01, 1.6203e-01, 2.9428e-02, 8.6867e-03],\n",
      "        [1.7777e-04, 2.5930e-03, 7.8849e-03, 7.9437e-02, 1.1979e-01, 1.9408e-01,\n",
      "         4.9297e-01, 8.5946e-02, 1.0654e-02, 6.4763e-03],\n",
      "        [2.3465e-04, 4.6742e-04, 1.0070e-02, 8.9975e-02, 3.4694e-01, 1.6964e-01,\n",
      "         2.5518e-01, 1.0299e-01, 2.0177e-02, 4.3257e-03],\n",
      "        [3.3719e-06, 7.6492e-05, 5.9840e-04, 2.5684e-02, 7.3397e-02, 1.8467e-01,\n",
      "         4.4824e-01, 1.8741e-01, 4.6984e-02, 3.2933e-02],\n",
      "        [1.7886e-06, 1.0667e-04, 9.9298e-04, 3.0417e-02, 7.0790e-02, 1.1605e-01,\n",
      "         5.1292e-01, 2.0882e-01, 2.5991e-02, 3.3899e-02]])\n",
      "\n",
      "Source: và tất_nhiên , mọi thứ tại châu phi đều phát_triển\n",
      "Reference: and of course , everything in africa grew beautifully\n",
      "Model: <SOS> and of course , the course is is is\n",
      "Attention Weights: tensor([[6.5992e-04, 9.9621e-01, 2.3881e-03, 4.2377e-04, 9.7863e-05, 8.5459e-05,\n",
      "         5.3876e-05, 1.6988e-05, 4.1170e-05, 1.7773e-05],\n",
      "        [2.1128e-03, 9.9716e-01, 6.0539e-04, 9.9145e-05, 1.3255e-05, 3.4120e-06,\n",
      "         1.8239e-06, 7.8348e-07, 8.3049e-07, 4.8897e-07],\n",
      "        [8.5141e-04, 9.4575e-01, 2.8146e-02, 2.0423e-02, 3.9610e-03, 5.3323e-04,\n",
      "         2.3449e-04, 6.2178e-05, 2.8239e-05, 1.4525e-05],\n",
      "        [5.2300e-04, 2.6755e-01, 9.8027e-02, 5.2083e-01, 8.0106e-02, 2.0514e-02,\n",
      "         9.2075e-03, 1.9429e-03, 9.9985e-04, 3.0232e-04],\n",
      "        [2.4178e-04, 3.8670e-02, 4.4435e-02, 8.2662e-01, 6.0030e-02, 1.4703e-02,\n",
      "         9.6937e-03, 3.0193e-03, 2.0184e-03, 5.6839e-04],\n",
      "        [4.6329e-06, 6.5886e-03, 1.2095e-02, 3.2443e-01, 3.9915e-01, 1.3362e-01,\n",
      "         8.5044e-02, 2.4187e-02, 1.0747e-02, 4.1462e-03],\n",
      "        [7.3258e-06, 9.1257e-03, 1.0095e-02, 5.9579e-02, 2.6203e-01, 2.7042e-01,\n",
      "         2.8389e-01, 6.6803e-02, 2.6287e-02, 1.1761e-02],\n",
      "        [8.7565e-08, 2.3172e-04, 5.7421e-04, 1.1533e-02, 1.1152e-01, 2.4702e-01,\n",
      "         2.5566e-01, 1.5244e-01, 1.3505e-01, 8.5972e-02],\n",
      "        [8.5318e-07, 1.7694e-04, 1.4750e-03, 2.0873e-02, 3.9681e-02, 8.7706e-02,\n",
      "         2.1605e-01, 1.6480e-01, 2.9582e-01, 1.7342e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3.24, Train Loss: 0.00, Val Loss: 4.29, Train BLEU: 0.00, Val BLEU: 12.76, Minutes Elapsed: 138.51\n",
      "Sampling from val predictions...\n",
      "Source: chúng_tôi đã có khoảng 50 người tới tham_gia đào_bới ,\n",
      "Reference: we &apos;ve had , like , 50 people come\n",
      "Model: <SOS> we had been 50 50 people people people ,\n",
      "Attention Weights: tensor([[9.6301e-01, 3.5258e-02, 1.7129e-03, 7.6419e-06, 2.8455e-06, 4.2943e-06,\n",
      "         2.7513e-07, 7.5126e-08, 4.8994e-07, 6.4402e-07],\n",
      "        [1.3666e-02, 7.7198e-01, 2.1359e-01, 5.2180e-04, 1.1010e-04, 1.0561e-04,\n",
      "         1.5675e-05, 2.3573e-06, 2.4005e-06, 4.3456e-07],\n",
      "        [1.9794e-02, 1.9673e-01, 4.9509e-01, 2.2584e-01, 4.1194e-02, 2.0233e-02,\n",
      "         9.6293e-04, 7.2864e-05, 7.7072e-05, 4.6811e-06],\n",
      "        [4.8456e-05, 7.4751e-05, 1.4955e-03, 1.5467e-01, 4.5179e-01, 3.6416e-01,\n",
      "         2.3184e-02, 2.1949e-03, 2.3423e-03, 4.1216e-05],\n",
      "        [2.3526e-05, 3.6009e-05, 7.0272e-04, 3.9228e-02, 3.0399e-01, 5.9947e-01,\n",
      "         4.5775e-02, 4.4825e-03, 6.1944e-03, 1.0445e-04],\n",
      "        [6.4875e-06, 5.7322e-06, 8.0378e-05, 1.9201e-03, 5.8742e-02, 7.5006e-01,\n",
      "         1.4769e-01, 1.4821e-02, 2.6055e-02, 6.1387e-04],\n",
      "        [1.2300e-06, 1.8575e-06, 3.1578e-05, 9.4816e-05, 4.2808e-03, 3.3664e-01,\n",
      "         2.9471e-01, 9.9342e-02, 2.6118e-01, 3.7256e-03],\n",
      "        [3.9980e-07, 5.2386e-07, 6.7983e-06, 2.7885e-05, 7.2632e-04, 7.8968e-02,\n",
      "         1.6270e-01, 9.5492e-02, 6.0557e-01, 5.6508e-02],\n",
      "        [1.3942e-06, 4.5354e-06, 1.0061e-04, 7.8769e-05, 4.9015e-04, 1.2444e-02,\n",
      "         7.2893e-02, 1.0356e-01, 7.3057e-01, 7.9858e-02]])\n",
      "\n",
      "Source: chúng_tôi có cơ_hội để bắt_đầu tìm_kiếm những dấu_ấn sinh_học ban_đầu\n",
      "Reference: we have the opportunity to start to search for\n",
      "Model: <SOS> we have a opportunity to start with the the\n",
      "Attention Weights: tensor([[9.5837e-01, 4.1451e-02, 1.4617e-04, 2.2562e-05, 3.9180e-06, 6.6783e-07,\n",
      "         1.3312e-07, 2.5513e-07, 4.1371e-08, 6.0585e-08],\n",
      "        [9.6594e-03, 9.8717e-01, 3.1174e-03, 3.3652e-05, 1.2753e-05, 1.1530e-06,\n",
      "         3.9929e-07, 2.9454e-07, 1.1529e-07, 5.6326e-08],\n",
      "        [1.5963e-02, 4.7532e-01, 4.7624e-01, 2.2026e-02, 9.9301e-03, 4.0762e-04,\n",
      "         5.9446e-05, 4.3481e-05, 3.5375e-06, 1.9794e-06],\n",
      "        [1.3614e-03, 2.2412e-02, 6.7703e-01, 1.8793e-01, 1.0615e-01, 4.2930e-03,\n",
      "         5.4492e-04, 2.4712e-04, 2.3747e-05, 1.8311e-05],\n",
      "        [4.7871e-04, 9.2369e-03, 1.3541e-01, 4.0051e-01, 3.8134e-01, 6.3994e-02,\n",
      "         6.5738e-03, 2.2161e-03, 1.5334e-04, 8.6758e-05],\n",
      "        [1.9914e-04, 2.0509e-03, 1.5686e-02, 1.7146e-01, 4.3620e-01, 2.8423e-01,\n",
      "         6.2695e-02, 2.5330e-02, 1.2745e-03, 8.7617e-04],\n",
      "        [7.1256e-07, 1.8614e-05, 9.0446e-04, 5.0830e-03, 2.2248e-01, 3.9120e-01,\n",
      "         1.7464e-01, 1.7530e-01, 1.5823e-02, 1.4552e-02],\n",
      "        [4.4426e-07, 6.4987e-06, 2.3086e-04, 2.0236e-03, 7.7272e-02, 2.9017e-01,\n",
      "         2.8367e-01, 2.6486e-01, 4.8282e-02, 3.3483e-02],\n",
      "        [3.7144e-07, 6.9445e-06, 3.4680e-04, 1.9717e-03, 4.8237e-02, 2.2362e-01,\n",
      "         2.8797e-01, 3.4904e-01, 5.5644e-02, 3.3156e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3.48, Train Loss: 0.00, Val Loss: 4.26, Train BLEU: 0.00, Val BLEU: 13.03, Minutes Elapsed: 146.79\n",
      "Sampling from val predictions...\n",
      "Source: đây là tôi với đội bóng_đá trong tạp_chí v. <EOS>\n",
      "Reference: here &apos;s me on the soccer team and in\n",
      "Model: <SOS> this is me with the of of . <EOS>\n",
      "Attention Weights: tensor([[9.7096e-01, 2.3775e-02, 5.2528e-03, 7.3146e-06, 1.0659e-06, 1.1493e-06,\n",
      "         2.8383e-07, 3.0526e-07, 2.6148e-07, 1.0483e-06],\n",
      "        [1.0329e-01, 2.7834e-01, 6.0511e-01, 1.2637e-02, 4.0231e-04, 1.1849e-04,\n",
      "         3.8892e-05, 1.9721e-05, 1.5481e-05, 2.7105e-05],\n",
      "        [1.2570e-02, 7.9463e-02, 7.0221e-01, 1.9357e-01, 9.1459e-03, 2.3836e-03,\n",
      "         4.4583e-04, 1.1052e-04, 5.5148e-05, 4.3653e-05],\n",
      "        [5.5809e-05, 8.5695e-04, 4.7953e-02, 6.9137e-01, 1.9455e-01, 5.6976e-02,\n",
      "         5.0903e-03, 2.3872e-03, 5.9305e-04, 1.6508e-04],\n",
      "        [5.9945e-05, 7.8498e-04, 3.0004e-02, 1.4654e-01, 2.6317e-01, 3.8175e-01,\n",
      "         1.1250e-01, 5.4117e-02, 8.2693e-03, 2.7975e-03],\n",
      "        [1.4280e-07, 2.5322e-06, 3.7222e-04, 1.2203e-02, 1.9706e-01, 4.4422e-01,\n",
      "         1.4474e-01, 1.5019e-01, 3.4536e-02, 1.6685e-02],\n",
      "        [2.6489e-06, 3.8045e-05, 8.8159e-04, 1.6165e-03, 1.9884e-02, 1.4499e-01,\n",
      "         2.0168e-01, 3.7572e-01, 1.3115e-01, 1.2404e-01],\n",
      "        [2.5333e-06, 2.2031e-05, 5.9389e-04, 4.4843e-04, 2.9574e-03, 2.4003e-02,\n",
      "         1.0728e-01, 4.2123e-01, 2.2046e-01, 2.2301e-01],\n",
      "        [6.8534e-08, 7.5141e-07, 4.7809e-05, 4.1837e-04, 4.0541e-03, 2.1537e-02,\n",
      "         3.5334e-02, 2.8084e-01, 3.8872e-01, 2.6905e-01]])\n",
      "\n",
      "Source: chúng_tôi còn vật mẫu ở đây . nó còn khá\n",
      "Reference: so we still have the specimen here . it\n",
      "Model: <SOS> we we was still here . . it it\n",
      "Attention Weights: tensor([[9.8579e-01, 1.1888e-02, 1.8249e-03, 3.8827e-04, 3.0385e-05, 5.7502e-05,\n",
      "         2.2852e-05, 1.5315e-06, 8.6811e-07, 2.4988e-07],\n",
      "        [1.3942e-02, 9.6814e-01, 1.1531e-02, 6.1445e-03, 1.4769e-04, 5.7260e-05,\n",
      "         1.7217e-05, 7.4080e-06, 1.2673e-05, 3.1801e-06],\n",
      "        [1.4902e-02, 4.0849e-01, 1.8945e-01, 3.3944e-01, 3.1706e-02, 1.3935e-02,\n",
      "         1.9294e-03, 5.9196e-05, 7.1845e-05, 1.7713e-05],\n",
      "        [2.3719e-02, 5.1206e-01, 1.4358e-01, 2.6033e-01, 3.9500e-02, 1.7350e-02,\n",
      "         3.1028e-03, 1.4267e-04, 1.7484e-04, 4.1122e-05],\n",
      "        [1.7490e-04, 2.0262e-03, 1.8258e-02, 4.4913e-01, 2.7573e-01, 2.2287e-01,\n",
      "         3.0429e-02, 8.0133e-04, 4.2468e-04, 1.5542e-04],\n",
      "        [3.7397e-04, 2.8797e-03, 1.0110e-02, 1.2407e-01, 1.5101e-01, 3.5876e-01,\n",
      "         2.8121e-01, 4.3203e-02, 2.3496e-02, 4.8791e-03],\n",
      "        [6.1864e-05, 2.6747e-04, 2.0888e-03, 2.0109e-02, 5.1166e-02, 2.3417e-01,\n",
      "         3.8980e-01, 1.8343e-01, 1.0088e-01, 1.8039e-02],\n",
      "        [2.2673e-04, 2.3711e-04, 6.1065e-04, 2.8388e-03, 1.5461e-02, 6.5056e-02,\n",
      "         2.3704e-01, 5.1659e-01, 1.4551e-01, 1.6434e-02],\n",
      "        [2.0868e-05, 1.6368e-04, 4.6136e-04, 2.2026e-03, 4.1782e-03, 1.4352e-02,\n",
      "         6.9881e-02, 1.1045e-01, 7.2232e-01, 7.5975e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3.72, Train Loss: 0.00, Val Loss: 4.22, Train BLEU: 0.00, Val BLEU: 13.65, Minutes Elapsed: 155.02\n",
      "Sampling from val predictions...\n",
      "Source: tôi đã sai_lầm khi nghĩ rằng tôi là trường_hợp duy_nhất\n",
      "Reference: i was mistaken in thinking that i was unique\n",
      "Model: <SOS> i i heard that think that i &apos;m the\n",
      "Attention Weights: tensor([[9.1610e-01, 7.2778e-02, 8.9262e-03, 2.0041e-03, 1.2644e-04, 3.1989e-05,\n",
      "         3.4783e-05, 1.2036e-06, 1.1888e-07, 1.6390e-07],\n",
      "        [6.2451e-03, 6.6377e-01, 2.4508e-01, 7.3891e-02, 1.0731e-02, 2.5588e-04,\n",
      "         1.3501e-05, 1.3553e-05, 1.3373e-06, 5.8238e-07],\n",
      "        [4.2951e-03, 1.0458e-01, 8.8478e-02, 3.7005e-01, 3.3200e-01, 9.3942e-02,\n",
      "         5.4185e-03, 1.1501e-03, 6.4562e-05, 2.2213e-05],\n",
      "        [2.2694e-04, 2.3959e-04, 4.1149e-03, 5.0971e-02, 4.5328e-01, 4.1325e-01,\n",
      "         7.2922e-02, 4.5473e-03, 2.9682e-04, 1.5352e-04],\n",
      "        [8.0154e-04, 2.6699e-04, 5.7734e-03, 4.3581e-02, 5.7842e-01, 2.5773e-01,\n",
      "         9.7445e-02, 1.4411e-02, 1.0258e-03, 5.4288e-04],\n",
      "        [1.0797e-05, 2.6377e-05, 2.7524e-04, 2.3094e-03, 1.4996e-01, 2.4871e-01,\n",
      "         2.7054e-01, 2.9006e-01, 2.9458e-02, 8.6595e-03],\n",
      "        [7.5595e-05, 1.0101e-04, 7.6696e-04, 5.4858e-03, 8.8049e-02, 2.3065e-01,\n",
      "         3.5255e-01, 2.4957e-01, 5.6498e-02, 1.6245e-02],\n",
      "        [1.8311e-06, 2.0291e-05, 9.6630e-05, 4.9344e-04, 2.3022e-02, 4.4710e-02,\n",
      "         4.5515e-02, 6.9732e-01, 1.5696e-01, 3.1861e-02],\n",
      "        [7.1921e-07, 7.7853e-06, 7.9207e-05, 4.6014e-04, 1.4322e-02, 4.0678e-02,\n",
      "         3.7606e-02, 3.7550e-01, 4.3773e-01, 9.3616e-02]])\n",
      "\n",
      "Source: những cành cây gãy tụ vào hồ volta thường vướng\n",
      "Reference: the skeletal tree limbs submerged in lake volta often\n",
      "Model: <SOS> the the <UNK> the the the the , ,\n",
      "Attention Weights: tensor([[3.3757e-01, 5.5017e-01, 9.0115e-02, 1.2474e-02, 3.8179e-03, 3.4302e-03,\n",
      "         9.6265e-04, 1.2885e-04, 8.6709e-04, 4.7168e-04],\n",
      "        [5.5767e-02, 5.9957e-01, 3.1756e-01, 1.8980e-02, 6.9467e-03, 9.5964e-04,\n",
      "         1.9341e-04, 5.0485e-06, 1.1361e-05, 2.6200e-06],\n",
      "        [1.3896e-02, 7.1981e-02, 2.8131e-01, 3.1099e-01, 2.0547e-01, 8.9888e-02,\n",
      "         2.5158e-02, 1.7630e-04, 9.8690e-04, 1.4637e-04],\n",
      "        [2.8236e-03, 2.9862e-02, 2.5937e-01, 3.4049e-01, 2.6681e-01, 7.6935e-02,\n",
      "         2.2421e-02, 1.8114e-04, 9.3457e-04, 1.7880e-04],\n",
      "        [1.4421e-03, 1.5052e-02, 1.1260e-01, 1.6384e-01, 4.0067e-01, 1.5325e-01,\n",
      "         1.2429e-01, 4.5585e-03, 1.9883e-02, 4.4077e-03],\n",
      "        [3.5087e-05, 6.4492e-04, 1.3446e-02, 3.5775e-02, 2.4056e-01, 2.2884e-01,\n",
      "         3.4002e-01, 1.9040e-02, 9.0283e-02, 3.1367e-02],\n",
      "        [2.0436e-06, 3.8122e-05, 6.3632e-04, 1.9281e-03, 1.4778e-02, 4.8556e-02,\n",
      "         3.3261e-01, 5.2252e-02, 3.5596e-01, 1.9323e-01],\n",
      "        [1.1010e-05, 1.7128e-04, 1.5456e-03, 2.3789e-03, 8.0754e-03, 1.3711e-02,\n",
      "         6.6367e-02, 2.7421e-02, 3.2981e-01, 5.5051e-01],\n",
      "        [1.4835e-05, 1.3033e-04, 1.0548e-03, 2.2749e-03, 7.2164e-03, 2.0550e-02,\n",
      "         6.5821e-02, 2.3950e-02, 3.2803e-01, 5.5096e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3.96, Train Loss: 0.00, Val Loss: 4.19, Train BLEU: 0.00, Val BLEU: 13.41, Minutes Elapsed: 163.31\n",
      "Sampling from val predictions...\n",
      "Source: gần 200 tổ_chức được thiết_lập tại benghazi trong suốt thời_gian\n",
      "Reference: almost 200 organizations were established in benghazi during and\n",
      "Model: <SOS> there 200 200 , were in in in the\n",
      "Attention Weights: tensor([[9.9835e-01, 1.5926e-03, 4.5996e-05, 2.2891e-06, 3.8680e-07, 2.4728e-06,\n",
      "         2.1301e-07, 2.5075e-07, 6.1271e-07, 3.5962e-07],\n",
      "        [7.3028e-01, 2.2844e-01, 4.0631e-02, 5.6749e-04, 6.9121e-05, 8.7864e-06,\n",
      "         2.8025e-06, 4.8415e-07, 3.3791e-07, 1.8469e-07],\n",
      "        [9.1786e-02, 3.2337e-01, 5.2763e-01, 4.7962e-02, 7.9538e-03, 1.0628e-03,\n",
      "         1.7288e-04, 4.4920e-05, 1.1425e-05, 6.2989e-06],\n",
      "        [1.0335e-03, 6.0230e-02, 3.7887e-01, 3.5517e-01, 1.5806e-01, 3.9520e-02,\n",
      "         5.4592e-03, 1.1982e-03, 3.1343e-04, 1.4710e-04],\n",
      "        [1.4950e-04, 1.3160e-02, 6.7486e-02, 3.4123e-01, 1.3376e-01, 3.6393e-01,\n",
      "         5.0444e-02, 1.7395e-02, 8.7724e-03, 3.6661e-03],\n",
      "        [6.7636e-07, 1.3001e-04, 2.7631e-03, 3.1633e-02, 1.3039e-01, 5.0598e-01,\n",
      "         8.0549e-02, 8.1857e-02, 9.1299e-02, 7.5396e-02],\n",
      "        [1.3680e-07, 8.4960e-06, 2.0225e-04, 2.6622e-03, 2.6486e-02, 3.5822e-01,\n",
      "         1.4276e-01, 1.7006e-01, 1.8253e-01, 1.1707e-01],\n",
      "        [7.2375e-07, 5.2263e-05, 6.2905e-04, 3.6696e-03, 1.6047e-02, 1.4231e-01,\n",
      "         6.0329e-02, 1.2297e-01, 3.8712e-01, 2.6687e-01],\n",
      "        [1.7074e-06, 5.8258e-05, 4.3203e-04, 3.1042e-03, 3.0293e-03, 7.8307e-02,\n",
      "         2.5560e-02, 1.4896e-01, 4.7582e-01, 2.6474e-01]])\n",
      "\n",
      "Source: giây thanh_quản này khoẻ_mạnh và ai đó đang nói ,\n",
      "Reference: now , this is healthy and this is somebody\n",
      "Model: <SOS> now this this &apos;s of and and and and\n",
      "Attention Weights: tensor([[2.3422e-01, 1.0317e-01, 3.2455e-01, 9.6753e-03, 2.1147e-01, 7.2411e-02,\n",
      "         3.7505e-02, 1.1194e-03, 1.5347e-03, 4.3492e-03],\n",
      "        [1.3982e-01, 8.4798e-01, 9.2565e-03, 2.4836e-03, 3.1148e-04, 9.6399e-05,\n",
      "         2.3893e-05, 1.2367e-05, 7.9567e-06, 2.5623e-06],\n",
      "        [9.0651e-02, 4.5475e-01, 1.9006e-01, 2.3832e-01, 1.8626e-02, 5.7146e-03,\n",
      "         1.1719e-03, 4.9949e-04, 1.8529e-04, 1.9885e-05],\n",
      "        [9.0078e-02, 3.4849e-01, 1.2175e-01, 3.9124e-01, 3.2909e-02, 1.1783e-02,\n",
      "         2.1106e-03, 1.1302e-03, 4.6790e-04, 4.2677e-05],\n",
      "        [9.3028e-02, 3.4325e-01, 1.3027e-01, 3.7284e-01, 3.7964e-02, 1.5097e-02,\n",
      "         3.6189e-03, 2.8973e-03, 9.4060e-04, 8.8537e-05],\n",
      "        [2.6684e-02, 1.1392e-01, 5.6695e-02, 6.9154e-01, 6.0439e-02, 4.2145e-02,\n",
      "         3.9773e-03, 3.0882e-03, 1.3115e-03, 1.9213e-04],\n",
      "        [3.1486e-02, 1.6928e-01, 5.9396e-02, 5.6504e-01, 1.2193e-01, 4.7273e-02,\n",
      "         2.3689e-03, 2.1643e-03, 8.7152e-04, 1.8933e-04],\n",
      "        [3.3548e-04, 6.0930e-03, 6.4685e-03, 3.4307e-01, 2.5798e-01, 3.2602e-01,\n",
      "         2.0835e-02, 2.4421e-02, 1.2825e-02, 1.9537e-03],\n",
      "        [1.9637e-04, 2.0232e-03, 5.0764e-03, 2.1983e-01, 2.7291e-01, 3.6563e-01,\n",
      "         4.0122e-02, 5.5502e-02, 3.3523e-02, 5.1838e-03]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4.00, Train Loss: 0.00, Val Loss: 4.24, Train BLEU: 0.00, Val BLEU: 13.26, Minutes Elapsed: 164.75\n",
      "Sampling from val predictions...\n",
      "Source: câu_hỏi đầu_tiên là : gì cơ ? <EOS> <PAD> <PAD>\n",
      "Reference: first question to answer for us : so what\n",
      "Model: <SOS> the the the the question what ? <EOS> ?\n",
      "Attention Weights: tensor([[0.6701, 0.0638, 0.0810, 0.0186, 0.1155, 0.0188, 0.0310, 0.0012, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4176, 0.5760, 0.0058, 0.0002, 0.0003, 0.0002, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.6160, 0.2991, 0.0739, 0.0025, 0.0059, 0.0022, 0.0002, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1743, 0.2810, 0.2548, 0.0611, 0.1573, 0.0680, 0.0028, 0.0008, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0159, 0.0330, 0.0510, 0.0568, 0.5554, 0.2705, 0.0117, 0.0056, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0007, 0.0039, 0.0165, 0.0614, 0.6827, 0.2238, 0.0079, 0.0030, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0011, 0.0017, 0.0128, 0.3074, 0.6486, 0.0215, 0.0066, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0002, 0.0013, 0.0189, 0.3401, 0.5239, 0.0572, 0.0583, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0010, 0.0010, 0.0107, 0.2160, 0.7067, 0.0420, 0.0224, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Source: trong những năm taliban , tôi nhớ rằng có những\n",
      "Reference: during taliban years , i remember there were times\n",
      "Model: <SOS> in the the , i remember that there two\n",
      "Attention Weights: tensor([[1.5601e-02, 9.7204e-03, 2.3167e-02, 9.6824e-03, 3.3485e-01, 6.0300e-01,\n",
      "         1.2950e-03, 8.1287e-04, 1.7864e-03, 8.5987e-05],\n",
      "        [8.8250e-02, 4.3057e-01, 3.7200e-01, 1.0247e-01, 4.8249e-03, 1.1636e-03,\n",
      "         6.1812e-04, 5.9689e-05, 2.9249e-05, 1.1375e-05],\n",
      "        [7.6005e-03, 1.9800e-01, 5.4443e-01, 2.1356e-01, 2.0793e-02, 4.8872e-03,\n",
      "         1.0211e-02, 4.1930e-04, 7.7623e-05, 2.2036e-05],\n",
      "        [3.5198e-04, 1.8875e-02, 2.7404e-01, 2.6753e-01, 1.9732e-01, 1.9606e-01,\n",
      "         3.9436e-02, 5.1197e-03, 1.1744e-03, 9.3733e-05],\n",
      "        [7.9107e-06, 5.1688e-04, 1.0055e-02, 2.9426e-02, 3.5018e-02, 3.8653e-01,\n",
      "         3.8014e-01, 8.7896e-02, 6.1956e-02, 8.4542e-03],\n",
      "        [5.9044e-06, 3.6098e-04, 3.7849e-03, 1.1359e-02, 1.1614e-02, 1.6928e-01,\n",
      "         5.3913e-01, 1.3307e-01, 1.0274e-01, 2.8655e-02],\n",
      "        [1.5716e-05, 6.6307e-04, 1.6494e-03, 1.4214e-03, 9.8051e-04, 5.5576e-03,\n",
      "         2.9754e-01, 5.4406e-01, 1.1477e-01, 3.3345e-02],\n",
      "        [1.4199e-06, 1.0537e-04, 1.8201e-03, 4.0121e-03, 8.0345e-04, 3.6815e-03,\n",
      "         6.4280e-02, 2.5014e-01, 4.0011e-01, 2.7505e-01],\n",
      "        [9.6060e-07, 3.7324e-05, 1.5912e-03, 1.7990e-03, 1.2449e-03, 1.9092e-02,\n",
      "         8.1212e-02, 1.1016e-01, 4.2138e-01, 3.6349e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4.24, Train Loss: 0.00, Val Loss: 4.18, Train BLEU: 0.00, Val BLEU: 13.98, Minutes Elapsed: 172.99\n",
      "Sampling from val predictions...\n",
      "Source: tôi tới đây không có ý_định truyền cảm_hứng cho bạn\n",
      "Reference: i am here today not at all to inspire\n",
      "Model: <SOS> i i this there i i have to to\n",
      "Attention Weights: tensor([[9.9568e-01, 3.5031e-03, 5.9715e-04, 1.6340e-04, 3.0879e-05, 1.2694e-06,\n",
      "         1.6883e-06, 3.7765e-06, 7.9850e-06, 6.3583e-06],\n",
      "        [5.2521e-03, 9.8301e-01, 1.0309e-02, 1.3178e-03, 9.8393e-05, 6.9310e-06,\n",
      "         3.4248e-06, 8.4442e-07, 2.8309e-07, 2.4202e-07],\n",
      "        [4.7030e-03, 1.0512e-01, 7.3598e-01, 1.4110e-01, 1.0618e-02, 1.3824e-03,\n",
      "         8.6566e-04, 1.7898e-04, 3.6566e-05, 2.3973e-05],\n",
      "        [9.2872e-04, 7.1194e-03, 1.8684e-01, 6.3221e-01, 1.3966e-01, 1.9314e-02,\n",
      "         9.5310e-03, 3.7225e-03, 4.8506e-04, 1.8623e-04],\n",
      "        [3.4047e-03, 3.3370e-03, 5.6624e-02, 4.3360e-01, 3.2797e-01, 8.1589e-02,\n",
      "         5.8724e-02, 2.8067e-02, 5.5102e-03, 1.1740e-03],\n",
      "        [1.7954e-04, 4.0482e-03, 7.3253e-02, 4.2606e-01, 2.3654e-01, 1.1019e-01,\n",
      "         8.2581e-02, 3.5501e-02, 1.8416e-02, 1.3230e-02],\n",
      "        [1.9928e-04, 6.0887e-03, 4.0920e-02, 2.6809e-01, 2.8290e-01, 1.5588e-01,\n",
      "         7.8073e-02, 5.3554e-02, 4.6272e-02, 6.8020e-02],\n",
      "        [5.0248e-06, 2.0611e-04, 2.1944e-02, 2.4056e-01, 1.2497e-01, 1.1648e-01,\n",
      "         1.7912e-01, 1.2766e-01, 8.8625e-02, 1.0042e-01],\n",
      "        [2.6760e-05, 6.3145e-05, 2.9420e-03, 1.3499e-01, 1.1754e-01, 5.1214e-02,\n",
      "         7.7671e-02, 1.4461e-01, 2.1888e-01, 2.5207e-01]])\n",
      "\n",
      "Source: xã_hội của chúng_tôi cần những sự đại_diện có phẩm_chất từ\n",
      "Reference: our society needs the qualitative representation of the feminine\n",
      "Model: <SOS> our society need to the of is the from\n",
      "Attention Weights: tensor([[2.1424e-01, 7.2601e-01, 5.7474e-02, 1.1285e-03, 3.7928e-05, 1.3755e-04,\n",
      "         8.0175e-05, 6.0060e-04, 3.7416e-05, 2.5019e-04],\n",
      "        [7.0943e-01, 2.6282e-01, 1.5994e-02, 1.1080e-02, 3.1746e-04, 1.6027e-04,\n",
      "         1.2417e-04, 6.1394e-05, 1.0145e-05, 3.7054e-06],\n",
      "        [2.0591e-02, 5.9343e-02, 6.3994e-02, 8.3512e-01, 1.5809e-02, 3.1649e-03,\n",
      "         1.4564e-03, 4.6835e-04, 4.2202e-05, 1.2722e-05],\n",
      "        [5.5631e-04, 3.4535e-03, 1.6156e-02, 7.5960e-01, 1.3069e-01, 5.8402e-02,\n",
      "         2.4592e-02, 5.8500e-03, 5.9396e-04, 1.0485e-04],\n",
      "        [2.9028e-04, 8.9499e-04, 1.2010e-03, 1.0886e-01, 3.4491e-01, 2.8616e-01,\n",
      "         1.7734e-01, 5.5850e-02, 1.9005e-02, 5.4853e-03],\n",
      "        [3.8255e-05, 1.0968e-04, 1.2462e-04, 8.9951e-03, 1.1254e-01, 3.0486e-01,\n",
      "         3.3986e-01, 1.1960e-01, 7.7165e-02, 3.6705e-02],\n",
      "        [2.5695e-05, 1.7628e-04, 1.0619e-03, 1.1919e-02, 2.2786e-02, 9.3063e-02,\n",
      "         2.4998e-01, 3.7422e-01, 1.5477e-01, 9.1995e-02],\n",
      "        [2.0360e-06, 1.3471e-05, 1.2858e-04, 4.0956e-03, 7.5256e-03, 2.0699e-02,\n",
      "         1.0010e-01, 3.2564e-01, 3.8748e-01, 1.5432e-01],\n",
      "        [4.0258e-06, 7.5712e-06, 2.6377e-05, 8.5196e-04, 6.4971e-03, 1.8424e-02,\n",
      "         1.2132e-01, 1.9097e-01, 4.5774e-01, 2.0416e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4.48, Train Loss: 0.00, Val Loss: 4.15, Train BLEU: 0.00, Val BLEU: 14.13, Minutes Elapsed: 181.19\n",
      "Sampling from val predictions...\n",
      "Source: chúng_tôi đã rất sợ , nhưng dù vậy , chúng_tôi\n",
      "Reference: we were scared , but still , school was\n",
      "Model: <SOS> we we very , but we we we &apos;ve\n",
      "Attention Weights: tensor([[9.3834e-01, 4.5159e-02, 1.3981e-02, 2.4786e-03, 2.9259e-05, 2.5918e-06,\n",
      "         5.9413e-06, 5.5245e-06, 1.9593e-06, 4.2726e-07],\n",
      "        [5.7835e-03, 3.2044e-01, 6.2468e-01, 4.8836e-02, 1.7982e-04, 2.0331e-05,\n",
      "         2.6450e-05, 2.3268e-05, 3.2232e-06, 8.1703e-07],\n",
      "        [2.8041e-03, 4.4181e-02, 4.3901e-01, 4.9177e-01, 1.6087e-02, 7.3267e-04,\n",
      "         1.5066e-03, 3.6244e-03, 2.7405e-04, 1.3098e-05],\n",
      "        [3.5048e-04, 5.3534e-04, 2.3566e-02, 4.6863e-01, 2.5723e-01, 1.6326e-01,\n",
      "         3.0116e-02, 4.1874e-02, 1.2480e-02, 1.9546e-03],\n",
      "        [7.4479e-04, 1.4892e-04, 3.7569e-04, 1.6777e-02, 1.2133e-01, 7.4573e-01,\n",
      "         5.7509e-02, 3.2225e-02, 2.0524e-02, 4.6354e-03],\n",
      "        [4.5202e-04, 1.5956e-04, 3.4904e-04, 1.8761e-03, 2.7527e-03, 9.4805e-02,\n",
      "         5.2680e-01, 2.8614e-01, 4.5031e-02, 4.1635e-02],\n",
      "        [3.3825e-04, 9.1507e-04, 2.7272e-03, 2.5427e-03, 1.1440e-03, 8.4510e-03,\n",
      "         1.9090e-01, 4.4490e-01, 2.7201e-01, 7.6076e-02],\n",
      "        [1.5714e-05, 1.8853e-04, 1.3934e-03, 2.7098e-03, 9.7756e-04, 6.2614e-03,\n",
      "         6.1137e-02, 2.5246e-01, 4.4891e-01, 2.2595e-01],\n",
      "        [2.8034e-05, 3.0802e-04, 4.1835e-03, 6.5567e-03, 1.6734e-03, 6.1749e-03,\n",
      "         5.2561e-02, 1.7603e-01, 3.6310e-01, 3.8938e-01]])\n",
      "\n",
      "Source: nhưng ngoài cơn phẫn_nộ và bực_dọc và việc hiếu động\n",
      "Reference: yet beyond the tantrums and the frustration and the\n",
      "Model: <SOS> but the the and and and and and the\n",
      "Attention Weights: tensor([[2.6648e-03, 9.8679e-01, 2.9178e-03, 5.5217e-04, 1.2080e-03, 7.7147e-04,\n",
      "         1.9156e-03, 9.5409e-04, 8.3004e-04, 1.3977e-03],\n",
      "        [3.0488e-03, 9.7665e-01, 1.8058e-02, 1.3945e-03, 7.7906e-04, 3.3531e-05,\n",
      "         2.9062e-05, 1.6272e-06, 5.9930e-07, 4.5810e-07],\n",
      "        [5.2257e-03, 2.1900e-01, 2.9668e-01, 3.4487e-01, 9.9115e-02, 2.8091e-02,\n",
      "         6.5137e-03, 3.4776e-04, 1.1514e-04, 3.7357e-05],\n",
      "        [3.3124e-04, 4.3065e-03, 1.8793e-02, 2.5784e-01, 3.9759e-01, 2.4836e-01,\n",
      "         6.3705e-02, 5.5910e-03, 2.2033e-03, 1.2767e-03],\n",
      "        [9.7168e-05, 8.7159e-04, 3.4914e-03, 9.9674e-02, 1.0915e-01, 6.7915e-01,\n",
      "         5.7896e-02, 3.8864e-02, 7.6635e-03, 3.1497e-03],\n",
      "        [4.1463e-05, 4.8548e-04, 1.9872e-03, 8.9655e-02, 1.9115e-01, 5.3814e-01,\n",
      "         1.0014e-01, 6.4345e-02, 8.9989e-03, 5.0541e-03],\n",
      "        [6.7358e-07, 1.4216e-04, 8.0413e-04, 1.5694e-02, 4.7750e-02, 2.8466e-01,\n",
      "         1.5605e-01, 1.7371e-01, 1.8815e-01, 1.3304e-01],\n",
      "        [3.8057e-07, 4.6706e-05, 2.3050e-04, 5.3872e-03, 8.5740e-03, 6.3123e-02,\n",
      "         4.9173e-02, 1.6936e-01, 2.5186e-01, 4.5224e-01],\n",
      "        [1.8049e-06, 7.2322e-05, 2.3564e-04, 6.3850e-03, 2.1213e-02, 5.9485e-02,\n",
      "         1.1686e-01, 2.0397e-01, 2.0372e-01, 3.8806e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4.72, Train Loss: 0.00, Val Loss: 4.13, Train BLEU: 0.00, Val BLEU: 14.86, Minutes Elapsed: 189.39\n",
      "Sampling from val predictions...\n",
      "Source: chà , tôi không_thể phủ_nhận rằng đã có một_vài khoảnh_khắc\n",
      "Reference: now , i cannot deny that there have been\n",
      "Model: <SOS> well , i can &apos;t that there there a\n",
      "Attention Weights: tensor([[9.3178e-01, 5.8254e-02, 9.9511e-03, 1.4863e-05, 3.5572e-07, 2.7817e-07,\n",
      "         8.0223e-07, 1.7089e-07, 1.8960e-08, 9.5050e-09],\n",
      "        [1.0916e-02, 2.2243e-01, 6.8431e-01, 8.0030e-02, 2.1957e-03, 6.9872e-05,\n",
      "         3.1163e-05, 1.3398e-05, 1.6951e-06, 6.0257e-07],\n",
      "        [6.0481e-04, 2.4327e-02, 6.9777e-01, 2.6082e-01, 1.5110e-02, 7.9821e-04,\n",
      "         4.5816e-04, 9.8282e-05, 6.4037e-06, 1.1268e-06],\n",
      "        [1.1914e-05, 1.2494e-03, 4.3788e-02, 8.6014e-01, 9.2356e-02, 2.0193e-03,\n",
      "         3.1104e-04, 1.1744e-04, 6.3950e-06, 8.7979e-07],\n",
      "        [4.6318e-05, 8.8373e-04, 3.4058e-02, 7.4825e-01, 1.9607e-01, 1.7623e-02,\n",
      "         2.0605e-03, 8.9225e-04, 1.0340e-04, 1.3310e-05],\n",
      "        [6.1634e-06, 2.0677e-04, 2.9547e-03, 3.8057e-02, 6.7681e-01, 2.2690e-01,\n",
      "         4.2153e-02, 1.1144e-02, 1.5478e-03, 2.1611e-04],\n",
      "        [2.1290e-08, 5.9069e-07, 6.2927e-05, 9.8710e-04, 2.8626e-02, 4.9035e-01,\n",
      "         3.7771e-01, 7.5996e-02, 2.2822e-02, 3.4459e-03],\n",
      "        [3.6070e-08, 1.2410e-06, 2.7013e-04, 4.2165e-03, 5.2652e-03, 2.7921e-02,\n",
      "         3.7346e-01, 3.8020e-01, 1.7841e-01, 3.0258e-02],\n",
      "        [2.8047e-08, 4.8624e-07, 1.0283e-04, 1.3337e-02, 9.9345e-03, 2.3709e-02,\n",
      "         1.0298e-01, 2.6712e-01, 4.6712e-01, 1.1570e-01]])\n",
      "\n",
      "Source: khi tôi nhìn qua các bức ảnh , có một_số\n",
      "Reference: as i looked through the photos , there were\n",
      "Model: <SOS> when i i at the the , there &apos;s\n",
      "Attention Weights: tensor([[9.8036e-01, 1.9629e-02, 5.2329e-06, 1.2578e-06, 1.5029e-07, 2.0406e-07,\n",
      "         4.4515e-07, 4.2528e-06, 1.7304e-06, 8.6942e-08],\n",
      "        [2.4250e-01, 7.3919e-01, 1.7179e-02, 1.0674e-03, 3.1206e-05, 1.9388e-05,\n",
      "         4.7239e-06, 5.1228e-07, 4.9053e-07, 2.1458e-07],\n",
      "        [2.3603e-02, 1.3735e-01, 7.5012e-01, 8.5744e-02, 2.0434e-03, 9.8428e-04,\n",
      "         1.3493e-04, 5.5160e-06, 4.6246e-06, 2.3983e-06],\n",
      "        [9.2152e-03, 4.4187e-02, 3.5560e-01, 5.0177e-01, 5.5787e-02, 2.8746e-02,\n",
      "         4.3409e-03, 2.3895e-04, 8.5279e-05, 2.2412e-05],\n",
      "        [3.5656e-04, 3.5517e-03, 4.2772e-03, 3.2980e-01, 1.8168e-01, 3.4029e-01,\n",
      "         1.3611e-01, 2.9062e-03, 8.4699e-04, 1.8625e-04],\n",
      "        [6.8727e-05, 5.2071e-04, 7.6084e-04, 2.9522e-02, 1.0748e-01, 5.3057e-01,\n",
      "         2.9722e-01, 2.0666e-02, 1.1074e-02, 2.1155e-03],\n",
      "        [3.3252e-05, 1.4276e-04, 6.8286e-05, 2.9831e-04, 2.4360e-03, 3.7146e-02,\n",
      "         6.3119e-02, 3.8130e-01, 5.0238e-01, 1.3080e-02],\n",
      "        [1.2926e-05, 1.1653e-04, 2.7779e-05, 5.5763e-05, 5.6034e-04, 1.0994e-02,\n",
      "         1.5787e-02, 1.1465e-01, 8.4160e-01, 1.6203e-02],\n",
      "        [2.6291e-06, 5.6272e-05, 2.7337e-04, 2.3520e-03, 7.8705e-03, 3.4390e-02,\n",
      "         4.1105e-02, 1.7082e-02, 4.2195e-01, 4.7492e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4.96, Train Loss: 0.00, Val Loss: 4.12, Train BLEU: 0.00, Val BLEU: 14.37, Minutes Elapsed: 197.58\n",
      "Sampling from val predictions...\n",
      "Source: thực ra , hầu_hết chúng đều được chụp bởi những\n",
      "Reference: in fact , most of them were taken by\n",
      "Model: <SOS> in fact , they they they , were by\n",
      "Attention Weights: tensor([[9.8791e-01, 1.1070e-02, 4.9300e-04, 4.3714e-04, 8.7775e-05, 7.2312e-07,\n",
      "         3.1268e-07, 1.9808e-07, 4.1334e-07, 1.4867e-07],\n",
      "        [3.0391e-01, 2.6052e-01, 3.5525e-01, 6.5931e-02, 1.3443e-02, 7.8196e-04,\n",
      "         1.2898e-04, 2.1893e-05, 6.1986e-06, 1.3885e-06],\n",
      "        [2.1914e-02, 2.4422e-02, 8.0200e-02, 7.1854e-01, 1.0787e-01, 2.9253e-02,\n",
      "         1.1999e-02, 4.1880e-03, 1.3620e-03, 2.5647e-04],\n",
      "        [3.4914e-03, 8.0385e-03, 3.3043e-02, 9.2000e-01, 2.7595e-02, 3.7536e-03,\n",
      "         2.3829e-03, 8.3596e-04, 6.7755e-04, 1.8021e-04],\n",
      "        [1.5044e-04, 6.9740e-04, 4.5542e-03, 6.0624e-01, 2.3175e-01, 1.0745e-01,\n",
      "         3.7816e-02, 8.5710e-03, 2.3736e-03, 4.0118e-04],\n",
      "        [4.8554e-05, 6.7106e-04, 2.0927e-03, 1.5646e-02, 9.3948e-02, 2.7844e-01,\n",
      "         3.9950e-01, 1.7137e-01, 3.6171e-02, 2.1027e-03],\n",
      "        [1.1336e-05, 1.0422e-04, 1.0832e-03, 3.1518e-02, 9.9017e-02, 2.4131e-01,\n",
      "         3.1186e-01, 1.9813e-01, 9.4805e-02, 2.2161e-02],\n",
      "        [2.8248e-05, 1.8361e-04, 2.0607e-03, 2.2911e-02, 8.2238e-02, 1.0420e-01,\n",
      "         3.3120e-01, 2.6567e-01, 1.6238e-01, 2.9129e-02],\n",
      "        [6.3847e-07, 5.2775e-06, 2.2980e-04, 2.1416e-03, 3.7028e-03, 3.8139e-02,\n",
      "         1.0026e-01, 2.2718e-01, 5.1994e-01, 1.0840e-01]])\n",
      "\n",
      "Source: đờ_đẫn bởi sự đơn_điệu và kiệt_sức , họ câm_lặng làm_việc\n",
      "Reference: <UNK> by <UNK> and exhaustion , they work silently\n",
      "Model: <SOS> they got and , they , they decided to\n",
      "Attention Weights: tensor([[9.8021e-01, 1.8284e-02, 2.8863e-04, 5.0895e-04, 5.2808e-04, 4.3516e-05,\n",
      "         1.2290e-04, 1.4156e-05, 2.6789e-06, 5.6516e-07],\n",
      "        [1.8443e-02, 8.5488e-01, 7.4716e-02, 4.3207e-02, 8.2048e-03, 5.3119e-04,\n",
      "         1.6706e-05, 6.2038e-07, 2.2477e-06, 5.2697e-07],\n",
      "        [3.7400e-03, 1.4746e-01, 2.9616e-01, 4.5332e-01, 8.7782e-02, 1.0522e-02,\n",
      "         9.6055e-04, 1.5621e-05, 4.1220e-05, 4.9087e-06],\n",
      "        [3.8305e-05, 3.1365e-04, 2.4026e-03, 4.2567e-02, 4.5511e-01, 4.4503e-01,\n",
      "         4.2224e-02, 7.7240e-03, 4.4197e-03, 1.6355e-04],\n",
      "        [5.8083e-05, 3.4934e-05, 9.9808e-05, 2.4223e-03, 2.3121e-01, 4.1357e-01,\n",
      "         1.1581e-01, 2.1638e-01, 1.9921e-02, 5.0053e-04],\n",
      "        [9.1256e-06, 3.5275e-05, 4.5637e-05, 2.1904e-04, 6.1311e-03, 4.4104e-02,\n",
      "         1.0133e-01, 1.8021e-01, 6.5258e-01, 1.5333e-02],\n",
      "        [1.9178e-06, 1.1589e-05, 2.6259e-05, 1.6822e-04, 2.1187e-03, 1.1744e-02,\n",
      "         6.7178e-02, 2.8054e-01, 5.8960e-01, 4.8605e-02],\n",
      "        [4.2794e-07, 1.0735e-05, 3.8160e-05, 2.4737e-04, 1.3648e-03, 5.2309e-03,\n",
      "         9.5542e-03, 4.9844e-02, 8.7294e-01, 6.0769e-02],\n",
      "        [3.8938e-06, 2.1284e-04, 4.5630e-04, 6.3401e-04, 5.7442e-04, 1.9626e-03,\n",
      "         5.8416e-03, 2.5348e-02, 6.6976e-01, 2.9520e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5.00, Train Loss: 0.00, Val Loss: 4.17, Train BLEU: 0.00, Val BLEU: 13.90, Minutes Elapsed: 199.00\n",
      "Sampling from val predictions...\n",
      "Source: và tôi đứng trên sân_khấu này bởi_vì tôi là một\n",
      "Reference: and i am on this stage because i am\n",
      "Model: <SOS> and i i this this this , because &apos;m\n",
      "Attention Weights: tensor([[2.5565e-02, 9.6720e-01, 6.2491e-03, 3.9416e-05, 2.8678e-05, 6.0519e-04,\n",
      "         6.4001e-05, 2.4373e-04, 1.7588e-06, 5.0448e-07],\n",
      "        [1.2982e-02, 3.3235e-01, 6.5133e-01, 3.1553e-03, 1.5248e-04, 2.7775e-05,\n",
      "         2.6595e-06, 1.8046e-06, 2.0239e-07, 5.9114e-08],\n",
      "        [6.7491e-06, 4.2819e-03, 8.7979e-01, 1.1329e-01, 2.5843e-03, 4.4702e-05,\n",
      "         3.4023e-06, 1.9220e-07, 7.6169e-08, 1.7622e-08],\n",
      "        [8.5141e-05, 7.4008e-03, 3.6022e-01, 5.1175e-01, 1.0790e-01, 1.1015e-02,\n",
      "         1.4718e-03, 1.0278e-04, 4.0421e-05, 1.1621e-05],\n",
      "        [1.7504e-06, 6.8906e-05, 3.0214e-03, 2.2557e-01, 7.0635e-01, 4.2453e-02,\n",
      "         2.1529e-02, 7.1670e-04, 1.9370e-04, 9.5425e-05],\n",
      "        [2.3338e-06, 2.3414e-04, 2.5841e-03, 6.7264e-02, 8.2825e-01, 2.6981e-02,\n",
      "         7.1586e-02, 2.3625e-03, 4.7841e-04, 2.6181e-04],\n",
      "        [7.1614e-06, 9.4715e-04, 7.7379e-04, 1.2445e-02, 9.0179e-02, 6.3795e-02,\n",
      "         7.7540e-01, 4.9305e-02, 5.4532e-03, 1.6997e-03],\n",
      "        [6.3222e-06, 4.6448e-04, 2.8252e-04, 2.1782e-03, 5.2606e-02, 3.2720e-02,\n",
      "         7.9721e-01, 9.1888e-02, 1.5933e-02, 6.7092e-03],\n",
      "        [3.4624e-08, 1.6128e-05, 8.9896e-04, 3.7363e-03, 4.8216e-02, 1.2029e-02,\n",
      "         5.5667e-01, 1.9157e-01, 1.4330e-01, 4.3565e-02]])\n",
      "\n",
      "Source: thế nên ngay bây_giờ bạn đang tái dựng lại christchurch\n",
      "Reference: so now you &apos;re rebuilding christchurch without knowing what\n",
      "Model: <SOS> so , you you in to the the middle\n",
      "Attention Weights: tensor([[3.4427e-01, 5.5833e-01, 7.1943e-02, 2.3643e-02, 1.8070e-03, 1.6173e-06,\n",
      "         3.2323e-06, 1.9433e-06, 2.5355e-06, 1.3338e-06],\n",
      "        [9.6256e-03, 1.0593e-01, 5.9491e-01, 2.7495e-01, 1.4193e-02, 3.2730e-04,\n",
      "         4.4687e-05, 6.6630e-06, 3.6095e-06, 2.3532e-06],\n",
      "        [4.7088e-03, 3.9406e-02, 1.6356e-01, 5.3034e-01, 1.7031e-01, 7.2760e-02,\n",
      "         1.5674e-02, 2.4742e-03, 6.2192e-04, 1.4184e-04],\n",
      "        [2.6881e-03, 1.1669e-02, 4.9805e-02, 2.9501e-01, 2.7404e-01, 2.6875e-01,\n",
      "         7.9767e-02, 1.4233e-02, 3.0833e-03, 9.4605e-04],\n",
      "        [1.7211e-03, 6.4372e-03, 3.6971e-02, 2.3140e-01, 2.6067e-01, 3.0634e-01,\n",
      "         1.2557e-01, 2.3120e-02, 5.2486e-03, 2.5268e-03],\n",
      "        [8.0063e-05, 2.0267e-04, 4.6769e-03, 2.1892e-02, 2.3300e-02, 9.8027e-02,\n",
      "         3.8938e-01, 3.2993e-01, 8.5797e-02, 4.6712e-02],\n",
      "        [3.8462e-05, 6.4795e-05, 2.2854e-03, 2.5212e-02, 5.3271e-02, 1.0879e-01,\n",
      "         2.2780e-01, 3.2480e-01, 1.7519e-01, 8.2542e-02],\n",
      "        [7.6340e-07, 1.4869e-06, 4.1617e-05, 3.4362e-03, 1.7647e-02, 2.3729e-02,\n",
      "         1.4412e-01, 3.1149e-01, 3.1616e-01, 1.8338e-01],\n",
      "        [7.3369e-07, 5.0847e-06, 9.8981e-05, 5.1085e-03, 4.2101e-02, 5.5326e-02,\n",
      "         1.1952e-01, 1.0843e-01, 3.4766e-01, 3.2175e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5.24, Train Loss: 0.00, Val Loss: 4.13, Train BLEU: 0.00, Val BLEU: 14.47, Minutes Elapsed: 207.19\n",
      "Sampling from val predictions...\n",
      "Source: khi sắp tới sinh_nhật lần thứ 3 của con gái\n",
      "Reference: approaching my daughter &apos;s third birthday , my wife\n",
      "Model: <SOS> when i was was three third of his was\n",
      "Attention Weights: tensor([[7.8787e-01, 2.1087e-01, 1.7848e-04, 1.3239e-04, 1.7798e-04, 1.3497e-04,\n",
      "         7.8375e-06, 2.8623e-04, 4.1427e-05, 3.0622e-04],\n",
      "        [4.2824e-03, 9.6205e-01, 3.1681e-02, 1.6307e-03, 2.0013e-04, 6.6430e-05,\n",
      "         3.9404e-05, 4.2826e-05, 3.0939e-06, 2.2002e-06],\n",
      "        [2.7811e-03, 3.8320e-01, 5.1011e-01, 8.9893e-02, 7.2006e-03, 3.9675e-03,\n",
      "         1.7483e-03, 1.0703e-03, 1.9798e-05, 1.1894e-05],\n",
      "        [1.5776e-03, 3.0444e-02, 8.9886e-02, 3.4698e-01, 2.9950e-01, 1.6356e-01,\n",
      "         2.6006e-02, 3.7814e-02, 2.3308e-03, 1.9057e-03],\n",
      "        [4.5540e-05, 9.9926e-04, 5.7455e-03, 4.7703e-02, 3.4181e-01, 3.8105e-01,\n",
      "         5.5146e-02, 1.2057e-01, 2.2382e-02, 2.4554e-02],\n",
      "        [1.4351e-07, 1.5217e-05, 3.1845e-04, 3.6099e-02, 1.0159e-01, 4.7751e-01,\n",
      "         9.9846e-02, 2.5645e-01, 1.4080e-02, 1.4091e-02],\n",
      "        [3.5358e-07, 1.6564e-05, 2.1839e-04, 5.0175e-03, 4.1363e-02, 2.3010e-01,\n",
      "         8.4776e-02, 3.7060e-01, 1.0459e-01, 1.6331e-01],\n",
      "        [4.1206e-07, 6.6044e-06, 2.6292e-05, 2.3660e-04, 3.6791e-03, 5.5050e-02,\n",
      "         7.0770e-02, 1.9020e-01, 2.0591e-01, 4.7413e-01],\n",
      "        [7.5521e-08, 5.6427e-06, 2.9125e-05, 3.3368e-04, 4.0855e-03, 5.1004e-02,\n",
      "         6.5082e-02, 1.2784e-01, 1.1741e-01, 6.3421e-01]])\n",
      "\n",
      "Source: làm ý_tưởng mình dễ_hiểu không phải là hạ_thấp chúng .\n",
      "Reference: and making your ideas accessible is not the same\n",
      "Model: <SOS> it the &apos;s idea is not not . .\n",
      "Attention Weights: tensor([[9.5292e-01, 4.1275e-02, 1.6854e-03, 1.7685e-03, 7.4256e-04, 7.5737e-04,\n",
      "         5.1803e-04, 6.6344e-05, 6.1183e-05, 2.0987e-04],\n",
      "        [4.5066e-01, 3.2813e-01, 9.4898e-02, 1.1430e-01, 7.1501e-03, 4.6693e-03,\n",
      "         1.5973e-04, 2.4385e-05, 1.3605e-05, 3.1243e-06],\n",
      "        [2.1254e-01, 1.8633e-01, 1.1469e-01, 3.1534e-01, 6.8025e-02, 8.0248e-02,\n",
      "         1.5399e-02, 4.6743e-03, 2.4104e-03, 3.4303e-04],\n",
      "        [2.4836e-01, 2.7027e-01, 7.5316e-02, 2.9015e-01, 5.8448e-02, 4.6604e-02,\n",
      "         7.7666e-03, 2.0384e-03, 9.1860e-04, 1.1627e-04],\n",
      "        [1.2458e-01, 1.1507e-01, 5.6681e-02, 3.3581e-01, 1.8513e-01, 1.3334e-01,\n",
      "         2.9210e-02, 1.5506e-02, 4.1047e-03, 5.5779e-04],\n",
      "        [2.8285e-03, 1.0464e-02, 1.7731e-02, 3.3727e-01, 2.1708e-01, 2.4463e-01,\n",
      "         7.3761e-02, 6.4424e-02, 2.7256e-02, 4.5473e-03],\n",
      "        [2.0617e-04, 1.5803e-03, 1.3172e-02, 1.7843e-01, 9.6396e-02, 2.5405e-01,\n",
      "         1.7463e-01, 2.0537e-01, 5.9622e-02, 1.6540e-02],\n",
      "        [2.3232e-05, 1.1353e-04, 5.0525e-04, 1.7396e-02, 3.1264e-02, 1.0683e-01,\n",
      "         9.6999e-02, 3.8732e-01, 2.5980e-01, 9.9748e-02],\n",
      "        [5.8828e-06, 6.2644e-05, 2.6589e-04, 8.3545e-03, 1.9700e-02, 6.8007e-02,\n",
      "         4.4953e-02, 3.3983e-01, 3.9032e-01, 1.2851e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5.48, Train Loss: 0.00, Val Loss: 4.09, Train BLEU: 0.00, Val BLEU: 14.68, Minutes Elapsed: 215.39\n",
      "Sampling from val predictions...\n",
      "Source: bời vì việc vượt_biên từ bắc sang nam triều_tiên gần_như_là\n",
      "Reference: it &apos;s almost impossible to cross the border between\n",
      "Model: <SOS> because because from to from from from the to\n",
      "Attention Weights: tensor([[6.7960e-01, 3.1755e-01, 9.0807e-04, 1.6598e-03, 1.5018e-04, 2.7746e-05,\n",
      "         1.3671e-05, 4.4365e-06, 1.0988e-05, 7.9975e-05],\n",
      "        [1.4278e-01, 2.3163e-01, 4.9282e-01, 1.2646e-01, 5.7693e-03, 3.3892e-04,\n",
      "         1.1514e-04, 4.7396e-05, 2.1908e-05, 1.8587e-05],\n",
      "        [1.0946e-02, 5.6226e-02, 4.5694e-01, 4.0357e-01, 5.1849e-02, 1.8032e-02,\n",
      "         1.7936e-03, 5.2326e-04, 9.8894e-05, 2.2471e-05],\n",
      "        [1.6997e-02, 3.3736e-02, 9.2587e-02, 3.1639e-01, 9.1328e-02, 3.3604e-01,\n",
      "         5.2518e-02, 3.5074e-02, 2.2373e-02, 2.9612e-03],\n",
      "        [2.7057e-02, 4.4461e-02, 1.1342e-01, 1.5253e-01, 1.2061e-01, 4.1983e-01,\n",
      "         5.9441e-02, 3.4621e-02, 2.5882e-02, 2.1478e-03],\n",
      "        [5.4158e-04, 1.9822e-03, 1.2115e-02, 2.6418e-02, 7.0507e-02, 4.5028e-01,\n",
      "         1.2086e-01, 1.8243e-01, 1.2223e-01, 1.2632e-02],\n",
      "        [1.7255e-06, 1.9086e-05, 3.9129e-04, 2.2212e-03, 1.6649e-02, 2.3587e-01,\n",
      "         1.0442e-01, 3.0564e-01, 3.1364e-01, 2.1141e-02],\n",
      "        [2.7059e-07, 2.1199e-06, 3.4922e-05, 1.1056e-04, 1.9586e-03, 7.0032e-02,\n",
      "         5.3397e-02, 2.7339e-01, 5.4478e-01, 5.6292e-02],\n",
      "        [5.8506e-08, 3.8703e-07, 9.8846e-06, 3.6279e-05, 4.4441e-04, 1.3463e-02,\n",
      "         2.3646e-02, 2.8795e-01, 5.8197e-01, 9.2480e-02]])\n",
      "\n",
      "Source: một chuyên_ngành mới như một bác sỹ gia_đình cho doanh_nghiệp\n",
      "Reference: the profession is the family doctor of enterprise ,\n",
      "Model: <SOS> a is of like a of a the family\n",
      "Attention Weights: tensor([[7.6049e-01, 1.6844e-02, 2.0789e-01, 1.2578e-02, 1.7501e-03, 7.3305e-05,\n",
      "         7.7910e-05, 2.7083e-05, 2.3712e-04, 4.1298e-05],\n",
      "        [2.6363e-02, 2.7499e-01, 6.1435e-01, 7.6743e-02, 3.6689e-03, 9.6385e-04,\n",
      "         2.4091e-03, 4.2497e-04, 5.2166e-05, 3.8170e-05],\n",
      "        [1.0191e-02, 1.3751e-01, 6.1536e-01, 1.8963e-01, 1.6002e-02, 6.2642e-03,\n",
      "         1.2879e-02, 8.1987e-03, 2.7521e-03, 1.2082e-03],\n",
      "        [7.3046e-03, 2.7780e-02, 4.0106e-01, 4.5807e-01, 6.2995e-02, 1.2099e-02,\n",
      "         1.8169e-02, 8.5077e-03, 3.1167e-03, 8.9830e-04],\n",
      "        [1.4261e-04, 1.2767e-03, 1.4113e-02, 1.4760e-01, 3.5864e-01, 1.1264e-01,\n",
      "         1.6328e-01, 1.2709e-01, 3.8289e-02, 3.6929e-02],\n",
      "        [2.3839e-05, 4.1018e-03, 1.9425e-02, 1.4631e-01, 2.0566e-01, 8.9477e-02,\n",
      "         3.0853e-01, 1.7745e-01, 3.2030e-02, 1.6993e-02],\n",
      "        [3.6631e-05, 3.3260e-04, 5.4493e-03, 5.5460e-02, 1.7727e-01, 6.1939e-02,\n",
      "         1.4176e-01, 2.7018e-01, 1.9099e-01, 9.6587e-02],\n",
      "        [8.8484e-08, 1.8702e-05, 1.7760e-04, 9.0056e-03, 6.6649e-02, 8.0133e-02,\n",
      "         1.9663e-01, 3.0477e-01, 1.1925e-01, 2.2337e-01],\n",
      "        [2.1421e-08, 5.0938e-06, 9.2390e-05, 1.0937e-03, 8.3923e-03, 1.1269e-02,\n",
      "         4.1327e-02, 1.1860e-01, 7.7293e-02, 7.4193e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5.72, Train Loss: 0.00, Val Loss: 4.09, Train BLEU: 0.00, Val BLEU: 15.55, Minutes Elapsed: 223.53\n",
      "Sampling from val predictions...\n",
      "Source: nơi đây em đang tắm ở giếng , dội những\n",
      "Reference: here he &apos;s seen taking a bath at the\n",
      "Model: <SOS> so here are in in , , , the\n",
      "Attention Weights: tensor([[7.5873e-01, 2.4122e-01, 4.8596e-05, 5.9472e-07, 1.9448e-07, 1.3648e-06,\n",
      "         5.5408e-07, 1.2173e-06, 2.0563e-07, 2.3762e-08],\n",
      "        [3.9417e-02, 9.0820e-01, 3.8769e-02, 1.1992e-02, 1.4965e-03, 1.1063e-04,\n",
      "         1.0652e-05, 7.3612e-07, 7.8260e-07, 3.2222e-07],\n",
      "        [2.2380e-02, 3.6039e-01, 1.6437e-01, 3.4032e-01, 1.0106e-01, 9.9127e-03,\n",
      "         1.5095e-03, 4.0747e-05, 1.2026e-05, 3.4637e-06],\n",
      "        [4.9707e-04, 1.0277e-02, 1.2206e-01, 4.8976e-01, 3.2318e-01, 4.6741e-02,\n",
      "         7.1095e-03, 2.3120e-04, 7.5948e-05, 7.4616e-05],\n",
      "        [1.4346e-05, 2.5240e-04, 6.8852e-03, 1.9547e-02, 5.2111e-01, 3.6960e-01,\n",
      "         7.8862e-02, 3.2978e-03, 3.2967e-04, 9.9445e-05],\n",
      "        [7.3454e-06, 1.2297e-04, 7.7176e-03, 3.3389e-03, 3.1372e-02, 1.9693e-01,\n",
      "         6.8424e-01, 4.6380e-02, 2.8202e-02, 1.6848e-03],\n",
      "        [1.2098e-06, 1.7693e-05, 4.7424e-04, 1.1273e-03, 3.5274e-03, 3.8964e-02,\n",
      "         4.7706e-01, 7.3528e-02, 3.8107e-01, 2.4232e-02],\n",
      "        [5.0288e-07, 4.8714e-06, 2.4867e-05, 4.4996e-05, 1.7453e-04, 4.9056e-03,\n",
      "         8.2857e-02, 5.5540e-02, 8.2749e-01, 2.8961e-02],\n",
      "        [6.5250e-07, 4.5264e-06, 1.4542e-05, 1.3726e-05, 2.1148e-05, 6.5923e-04,\n",
      "         1.5147e-02, 4.6123e-02, 9.1919e-01, 1.8828e-02]])\n",
      "\n",
      "Source: tôi sống ở vùng trung nam . <EOS> <PAD> <PAD>\n",
      "Reference: i live in south central . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> i live in the middle . . <EOS> in\n",
      "Attention Weights: tensor([[0.9965, 0.0034, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0015, 0.9947, 0.0035, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0053, 0.5727, 0.3502, 0.0655, 0.0057, 0.0006, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0025, 0.0103, 0.1174, 0.6092, 0.2042, 0.0548, 0.0013, 0.0002, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0021, 0.0032, 0.0156, 0.4226, 0.4042, 0.1412, 0.0087, 0.0024, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0038, 0.0007, 0.0051, 0.1507, 0.3193, 0.3349, 0.1187, 0.0669, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0009, 0.0004, 0.0019, 0.0384, 0.1463, 0.3538, 0.2025, 0.2559, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0016, 0.0003, 0.0011, 0.0167, 0.0637, 0.2054, 0.3145, 0.3968, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0029, 0.0523, 0.0905, 0.2940, 0.2920, 0.1675, 0.0218, 0.0791, 0.0000,\n",
      "         0.0000]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5.96, Train Loss: 0.00, Val Loss: 4.09, Train BLEU: 0.00, Val BLEU: 14.50, Minutes Elapsed: 231.71\n",
      "Sampling from val predictions...\n",
      "Source: bạn có_thể trở_thành tổng_thống nước mỹ , hoặc người phát_minh\n",
      "Reference: you could be the president of the united states\n",
      "Model: <SOS> you can become the in of the , ,\n",
      "Attention Weights: tensor([[9.8658e-01, 1.3389e-02, 2.9901e-05, 5.9810e-07, 2.9849e-07, 8.1716e-07,\n",
      "         1.2346e-07, 4.4638e-08, 4.0664e-08, 1.2877e-08],\n",
      "        [2.6362e-01, 7.1107e-01, 2.5214e-02, 7.7631e-05, 7.8567e-06, 8.0717e-06,\n",
      "         1.2177e-07, 1.4787e-07, 1.2994e-07, 3.6959e-08],\n",
      "        [3.6041e-02, 1.6274e-01, 7.5656e-01, 3.6778e-02, 4.6560e-03, 3.1835e-03,\n",
      "         2.3447e-05, 9.8589e-06, 6.8880e-06, 2.5869e-06],\n",
      "        [1.1088e-03, 1.3482e-03, 8.3956e-02, 4.5194e-01, 3.1223e-01, 1.4703e-01,\n",
      "         1.5428e-03, 6.6860e-04, 1.3849e-04, 4.3258e-05],\n",
      "        [9.6214e-04, 5.9661e-04, 1.8881e-02, 3.0218e-01, 2.8822e-01, 3.8140e-01,\n",
      "         5.0204e-03, 2.3746e-03, 2.7477e-04, 8.8720e-05],\n",
      "        [6.4232e-03, 8.9851e-04, 9.0327e-03, 9.0309e-02, 2.7457e-01, 5.5788e-01,\n",
      "         4.4045e-02, 1.6091e-02, 6.5159e-04, 9.3901e-05],\n",
      "        [8.3696e-03, 1.2368e-03, 1.3135e-03, 1.7433e-02, 2.1032e-01, 7.0720e-01,\n",
      "         4.2015e-02, 1.1483e-02, 5.7846e-04, 4.6659e-05],\n",
      "        [3.1056e-05, 3.6520e-05, 1.9786e-04, 3.3898e-03, 4.9553e-02, 7.8662e-01,\n",
      "         5.1803e-02, 5.0973e-02, 3.4383e-02, 2.3016e-02],\n",
      "        [9.8986e-05, 1.0384e-04, 5.0065e-05, 5.1020e-04, 1.3416e-02, 2.1249e-01,\n",
      "         9.5564e-02, 6.1784e-01, 5.5397e-02, 4.5366e-03]])\n",
      "\n",
      "Source: với tôi , đó là câu_hỏi buồn và đau_đớn nhất\n",
      "Reference: to me , this is the saddest and most\n",
      "Model: <SOS> for me , it &apos;s a and and and\n",
      "Attention Weights: tensor([[9.9543e-01, 4.5656e-03, 1.0547e-06, 2.8596e-07, 8.5364e-09, 1.4365e-09,\n",
      "         7.2206e-10, 1.4180e-08, 8.4412e-10, 7.7256e-10],\n",
      "        [6.0492e-01, 3.9041e-01, 3.2174e-03, 1.0829e-03, 3.3443e-04, 3.3758e-05,\n",
      "         2.6480e-06, 4.3380e-07, 1.8060e-07, 6.8418e-08],\n",
      "        [1.3924e-01, 1.2525e-01, 2.1103e-01, 2.3871e-01, 1.5207e-01, 1.2698e-01,\n",
      "         6.2100e-03, 4.4521e-04, 4.7577e-05, 2.3891e-05],\n",
      "        [2.3579e-01, 1.6660e-01, 2.5700e-02, 4.3784e-01, 7.0683e-02, 5.2944e-02,\n",
      "         8.4746e-03, 1.3135e-03, 5.3890e-04, 1.1523e-04],\n",
      "        [6.0616e-02, 6.5981e-02, 5.5849e-02, 1.0708e-01, 3.5591e-01, 3.0367e-01,\n",
      "         4.1078e-02, 4.8593e-03, 4.2638e-03, 6.8417e-04],\n",
      "        [9.6588e-03, 9.8166e-03, 1.4853e-02, 8.6650e-03, 6.0303e-02, 5.9708e-01,\n",
      "         2.8207e-01, 1.4109e-02, 1.9723e-03, 1.4723e-03],\n",
      "        [6.8120e-04, 1.0314e-03, 4.8720e-04, 8.6021e-04, 6.6068e-03, 3.6533e-01,\n",
      "         5.5726e-01, 4.3867e-02, 1.9760e-02, 4.1163e-03],\n",
      "        [3.0274e-04, 6.6874e-04, 7.5774e-04, 2.4132e-03, 4.8921e-03, 1.2023e-01,\n",
      "         1.6338e-01, 5.3786e-01, 1.5005e-01, 1.9450e-02],\n",
      "        [1.7979e-04, 3.0050e-04, 3.2603e-04, 2.1850e-03, 2.9494e-03, 2.3800e-02,\n",
      "         3.3905e-02, 5.9271e-01, 3.2428e-01, 1.9358e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6.00, Train Loss: 0.00, Val Loss: 4.13, Train BLEU: 0.00, Val BLEU: 14.40, Minutes Elapsed: 233.13\n",
      "Sampling from val predictions...\n",
      "Source: khi người cảnh_sát trung_quốc đến gần họ , tôi đã\n",
      "Reference: as the chinese officer approached my family , i\n",
      "Model: <SOS> when the as of in in the , ,\n",
      "Attention Weights: tensor([[7.6633e-01, 2.1525e-03, 7.5623e-04, 2.4773e-03, 7.2250e-03, 2.1825e-03,\n",
      "         8.6903e-04, 3.2070e-02, 1.8551e-01, 4.3379e-04],\n",
      "        [6.3084e-02, 5.9213e-01, 2.6683e-01, 7.4816e-02, 2.7200e-03, 2.8862e-04,\n",
      "         6.9061e-05, 3.0003e-05, 2.9907e-05, 4.5972e-06],\n",
      "        [1.1298e-02, 2.6373e-01, 3.9757e-01, 3.1465e-01, 1.0926e-02, 1.6767e-03,\n",
      "         1.1916e-04, 2.0153e-05, 3.2133e-06, 4.1529e-06],\n",
      "        [5.6483e-03, 3.4098e-02, 3.2075e-01, 4.8757e-01, 1.3592e-01, 1.4166e-02,\n",
      "         1.4270e-03, 3.0877e-04, 7.2804e-05, 3.4266e-05],\n",
      "        [2.2391e-03, 2.7257e-02, 2.0855e-01, 5.0159e-01, 2.3476e-01, 2.4050e-02,\n",
      "         1.1267e-03, 2.8901e-04, 9.9858e-05, 3.9484e-05],\n",
      "        [7.1854e-05, 1.2239e-02, 7.0251e-02, 2.4402e-01, 3.6828e-01, 2.6640e-01,\n",
      "         2.7535e-02, 8.5830e-03, 1.8838e-03, 7.3175e-04],\n",
      "        [1.8906e-06, 2.8810e-03, 4.7944e-02, 2.1075e-01, 2.5493e-01, 4.0982e-01,\n",
      "         4.7284e-02, 1.4878e-02, 7.9549e-03, 3.5544e-03],\n",
      "        [3.9109e-06, 2.0296e-03, 2.1375e-02, 1.2578e-01, 2.2540e-01, 5.0033e-01,\n",
      "         6.7526e-02, 1.5808e-02, 3.7619e-02, 4.1261e-03],\n",
      "        [1.1093e-06, 1.7269e-04, 1.2383e-03, 9.7431e-03, 6.7721e-02, 1.7817e-01,\n",
      "         5.5556e-02, 1.0802e-01, 5.4813e-01, 3.1249e-02]])\n",
      "\n",
      "Source: khi tôi nhìn qua các bức ảnh , có một_số\n",
      "Reference: as i looked through the photos , there were\n",
      "Model: <SOS> when i i at the the , the the\n",
      "Attention Weights: tensor([[9.8446e-01, 1.5480e-02, 1.4643e-05, 3.9312e-06, 6.7320e-07, 7.9546e-07,\n",
      "         3.5960e-06, 2.9799e-05, 7.9679e-06, 3.5859e-07],\n",
      "        [1.6231e-01, 7.7904e-01, 5.6013e-02, 2.2193e-03, 1.8693e-04, 1.7529e-04,\n",
      "         4.4116e-05, 2.7892e-06, 1.9404e-06, 6.7152e-07],\n",
      "        [9.5176e-03, 5.5551e-02, 8.4632e-01, 8.2129e-02, 3.3214e-03, 2.5433e-03,\n",
      "         5.9933e-04, 1.0874e-05, 5.9533e-06, 4.3838e-06],\n",
      "        [1.1616e-02, 4.1205e-02, 2.6289e-01, 4.9888e-01, 1.0470e-01, 6.6555e-02,\n",
      "         1.3514e-02, 4.1654e-04, 1.7906e-04, 4.6064e-05],\n",
      "        [8.0254e-04, 5.2597e-03, 7.9998e-03, 3.3274e-01, 1.3678e-01, 3.2579e-01,\n",
      "         1.8848e-01, 1.5784e-03, 4.4901e-04, 1.2469e-04],\n",
      "        [3.4976e-04, 3.4604e-03, 7.7503e-03, 1.0900e-01, 1.6166e-01, 4.9520e-01,\n",
      "         2.0862e-01, 7.3845e-03, 5.4799e-03, 1.0978e-03],\n",
      "        [1.0322e-04, 1.1334e-03, 8.4846e-04, 5.5287e-03, 3.1510e-02, 3.8124e-01,\n",
      "         3.2461e-01, 9.9782e-02, 1.4648e-01, 8.7627e-03],\n",
      "        [1.4315e-04, 1.2379e-03, 8.8068e-04, 1.2990e-03, 1.0296e-02, 2.2169e-01,\n",
      "         2.1612e-01, 2.1050e-01, 3.2097e-01, 1.6864e-02],\n",
      "        [2.7951e-06, 1.1433e-04, 5.1830e-04, 4.8260e-03, 4.7644e-02, 3.1728e-01,\n",
      "         3.1240e-01, 3.7718e-02, 1.4261e-01, 1.3688e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6.24, Train Loss: 0.00, Val Loss: 4.12, Train BLEU: 0.00, Val BLEU: 14.56, Minutes Elapsed: 241.42\n",
      "Sampling from val predictions...\n",
      "Source: và chúng_tôi tiếp_tục đi cho tới biên_giới lào , nhung\n",
      "Reference: we made it all the way to the border\n",
      "Model: <SOS> and we to to to to to the the\n",
      "Attention Weights: tensor([[6.4434e-03, 9.9232e-01, 9.5806e-04, 2.5545e-04, 1.4502e-05, 4.7428e-07,\n",
      "         2.3890e-06, 2.2582e-06, 7.8138e-06, 4.4001e-07],\n",
      "        [3.7122e-03, 8.9124e-01, 1.0480e-01, 2.4846e-04, 4.6681e-06, 3.4021e-07,\n",
      "         2.1063e-07, 8.5951e-08, 3.1111e-08, 1.5300e-08],\n",
      "        [6.6404e-08, 1.3596e-03, 9.9543e-01, 3.1704e-03, 3.1357e-05, 4.5563e-06,\n",
      "         1.3083e-06, 1.2342e-07, 1.9621e-08, 1.6215e-08],\n",
      "        [4.3323e-06, 6.4721e-03, 2.5236e-01, 6.5766e-01, 6.4221e-02, 1.1313e-02,\n",
      "         6.8056e-03, 1.0534e-03, 9.9057e-05, 1.1939e-05],\n",
      "        [3.3392e-04, 7.3593e-02, 1.7443e-01, 4.0752e-01, 2.2560e-01, 5.9611e-02,\n",
      "         4.3585e-02, 1.3625e-02, 1.3935e-03, 3.1338e-04],\n",
      "        [4.0697e-05, 2.8672e-02, 8.5504e-02, 1.3623e-01, 1.8175e-01, 2.7220e-01,\n",
      "         2.2992e-01, 6.0787e-02, 3.9516e-03, 9.4804e-04],\n",
      "        [2.3418e-07, 5.1732e-04, 5.9730e-03, 4.4601e-02, 9.7967e-02, 2.0564e-01,\n",
      "         4.3105e-01, 1.9311e-01, 1.8984e-02, 2.1586e-03],\n",
      "        [1.5405e-06, 2.6694e-03, 8.6640e-03, 3.6652e-02, 1.4529e-01, 1.4548e-01,\n",
      "         2.2599e-01, 2.6294e-01, 1.4050e-01, 3.1816e-02],\n",
      "        [3.8559e-09, 6.7268e-06, 1.1128e-04, 6.0885e-03, 2.1939e-02, 1.3922e-01,\n",
      "         3.8177e-01, 3.0126e-01, 1.3118e-01, 1.8420e-02]])\n",
      "\n",
      "Source: một trát hầu_toà vì trồng cây trên mảnh đất mà\n",
      "Reference: a warrant for planting food on a piece of\n",
      "Model: <SOS> a &apos;s thing because because because the land of\n",
      "Attention Weights: tensor([[9.5730e-01, 4.1397e-02, 1.0915e-03, 2.0654e-04, 2.8329e-06, 2.6644e-06,\n",
      "         2.2186e-07, 1.1485e-07, 2.3300e-07, 1.2592e-06],\n",
      "        [1.4552e-02, 8.0034e-01, 1.6821e-01, 1.3907e-02, 2.8304e-03, 1.5725e-04,\n",
      "         5.9749e-06, 1.7858e-06, 3.2113e-07, 1.3949e-07],\n",
      "        [1.1917e-01, 3.9846e-01, 3.2628e-01, 1.4725e-01, 5.8048e-03, 2.7832e-03,\n",
      "         2.1172e-04, 3.3497e-05, 4.3258e-06, 2.9157e-06],\n",
      "        [4.1760e-03, 4.0249e-02, 3.1551e-01, 5.7698e-01, 4.9251e-02, 1.2768e-02,\n",
      "         9.5539e-04, 7.7662e-05, 6.4932e-06, 1.9741e-05],\n",
      "        [3.7498e-05, 1.5494e-03, 4.7700e-02, 3.3350e-01, 4.6438e-01, 1.4683e-01,\n",
      "         5.1973e-03, 6.7793e-04, 8.0719e-05, 3.8524e-05],\n",
      "        [4.6505e-05, 1.1413e-03, 2.1801e-02, 2.7429e-01, 4.9042e-01, 1.8599e-01,\n",
      "         2.2278e-02, 3.2490e-03, 3.7718e-04, 4.1381e-04],\n",
      "        [3.8106e-07, 2.5094e-05, 5.2973e-04, 7.9941e-03, 2.4918e-01, 4.2314e-01,\n",
      "         1.9162e-01, 8.0216e-02, 2.8732e-02, 1.8563e-02],\n",
      "        [2.1749e-08, 1.0477e-05, 1.6916e-04, 8.8204e-04, 5.9050e-02, 1.6445e-01,\n",
      "         2.8203e-01, 2.3953e-01, 1.6079e-01, 9.3086e-02],\n",
      "        [5.8493e-07, 6.2256e-05, 8.3890e-04, 1.3904e-02, 5.6322e-02, 2.1923e-01,\n",
      "         2.3705e-01, 1.2033e-01, 8.8558e-02, 2.6371e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6.48, Train Loss: 0.00, Val Loss: 4.07, Train BLEU: 0.00, Val BLEU: 14.88, Minutes Elapsed: 249.74\n",
      "Sampling from val predictions...\n",
      "Source: nhưng sau đó tôi đã nói , tôi muốn có\n",
      "Reference: but then i said , i want to have\n",
      "Model: <SOS> but then i said , i want to have\n",
      "Attention Weights: tensor([[7.9724e-02, 2.0580e-01, 6.9977e-01, 1.2043e-02, 6.9123e-04, 6.1802e-04,\n",
      "         1.1398e-03, 2.1513e-04, 1.4802e-06, 1.5067e-06],\n",
      "        [2.9702e-03, 3.3993e-01, 6.4132e-01, 1.5405e-02, 3.2465e-04, 4.3775e-05,\n",
      "         3.7464e-06, 2.8007e-06, 1.3956e-07, 8.3418e-09],\n",
      "        [8.1456e-04, 3.9495e-02, 1.9948e-01, 5.7187e-01, 1.2758e-01, 5.7750e-02,\n",
      "         2.5495e-03, 3.2028e-04, 1.3545e-04, 4.3888e-06],\n",
      "        [4.4870e-04, 4.5733e-03, 1.2434e-02, 1.3413e-02, 2.7058e-01, 6.4101e-01,\n",
      "         3.3990e-02, 2.5207e-03, 2.0561e-02, 4.6308e-04],\n",
      "        [2.3907e-04, 1.3374e-03, 7.6671e-03, 1.3106e-02, 1.3298e-01, 3.5896e-01,\n",
      "         4.1954e-01, 1.0299e-02, 3.1315e-02, 2.4553e-02],\n",
      "        [2.6892e-06, 4.8198e-05, 5.8697e-05, 1.3039e-04, 2.2336e-04, 5.3992e-03,\n",
      "         2.3260e-01, 5.5862e-01, 6.9740e-02, 1.3318e-01],\n",
      "        [8.6457e-10, 8.4821e-08, 2.4273e-07, 8.2351e-07, 3.6491e-06, 4.8915e-05,\n",
      "         3.5408e-04, 4.3545e-03, 9.0894e-01, 8.6293e-02],\n",
      "        [2.3987e-08, 1.2458e-06, 3.8260e-06, 5.9900e-05, 1.4764e-04, 2.1450e-03,\n",
      "         4.9711e-04, 7.8929e-04, 6.5408e-01, 3.4228e-01],\n",
      "        [1.9012e-09, 2.0496e-07, 5.2271e-07, 1.1249e-06, 9.8351e-06, 3.0975e-04,\n",
      "         8.7841e-04, 3.5952e-04, 3.8432e-02, 9.6001e-01]])\n",
      "\n",
      "Source: và cái chúng_tôi làm là trở_thành bạn của nhau ,\n",
      "Reference: and what we do , we become friends ,\n",
      "Model: <SOS> and what we did is is &apos;re the ,\n",
      "Attention Weights: tensor([[1.9880e-04, 9.9653e-01, 3.2436e-03, 8.9392e-06, 6.5087e-06, 1.3890e-06,\n",
      "         5.7851e-06, 1.5197e-06, 1.1983e-08, 1.7785e-07],\n",
      "        [1.0745e-04, 9.6961e-01, 3.0198e-02, 7.9730e-05, 3.6712e-06, 4.3085e-07,\n",
      "         3.1386e-07, 8.0479e-08, 5.9380e-09, 4.7124e-09],\n",
      "        [2.1164e-05, 1.3896e-01, 7.4646e-01, 1.1363e-01, 8.2717e-04, 7.6419e-05,\n",
      "         2.8548e-05, 4.2044e-06, 3.5632e-07, 2.5799e-07],\n",
      "        [1.0797e-05, 2.7165e-02, 1.0415e-01, 8.3655e-01, 2.2982e-02, 7.0531e-03,\n",
      "         1.9541e-03, 1.1979e-04, 8.6990e-06, 2.2080e-06],\n",
      "        [2.3537e-07, 3.0353e-04, 3.0556e-03, 2.8948e-01, 4.3221e-01, 1.6369e-01,\n",
      "         9.4816e-02, 1.4086e-02, 2.0357e-03, 3.2865e-04],\n",
      "        [2.5110e-07, 1.8360e-05, 3.5848e-05, 1.1474e-03, 7.2511e-02, 6.5919e-01,\n",
      "         1.8824e-01, 5.6887e-02, 1.5301e-02, 6.6673e-03],\n",
      "        [1.7951e-08, 7.5409e-06, 4.7102e-05, 6.2689e-04, 2.2109e-02, 4.2062e-01,\n",
      "         3.1798e-01, 1.6776e-01, 4.3719e-02, 2.7134e-02],\n",
      "        [7.6591e-08, 5.8911e-05, 6.2671e-04, 2.2106e-02, 6.7504e-02, 2.0115e-01,\n",
      "         4.6962e-01, 1.7117e-01, 4.4024e-02, 2.3741e-02],\n",
      "        [1.2922e-10, 8.1010e-08, 2.6186e-07, 1.4767e-05, 5.7387e-03, 4.0066e-01,\n",
      "         3.2446e-01, 1.3879e-01, 7.3035e-02, 5.7308e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6.72, Train Loss: 0.00, Val Loss: 4.09, Train BLEU: 0.00, Val BLEU: 15.91, Minutes Elapsed: 258.05\n",
      "Sampling from val predictions...\n",
      "Source: nhưng thay_vì hỏi sao họ lại chẳng trồng bất_cứ thứ\n",
      "Reference: but instead of asking them how come they were\n",
      "Model: <SOS> but instead of why they they they they ,\n",
      "Attention Weights: tensor([[5.7129e-04, 8.0074e-01, 1.4784e-01, 4.9809e-02, 8.1109e-04, 8.9289e-06,\n",
      "         7.2344e-05, 2.6343e-05, 7.4426e-05, 4.5069e-05],\n",
      "        [1.4224e-04, 9.5879e-01, 4.0753e-02, 3.0795e-04, 8.6546e-06, 1.4570e-07,\n",
      "         2.2000e-07, 4.0975e-08, 5.6262e-08, 2.7960e-08],\n",
      "        [7.9481e-05, 4.4674e-01, 5.3186e-01, 2.0902e-02, 3.7697e-04, 3.2427e-05,\n",
      "         9.8212e-06, 6.3554e-07, 3.3101e-07, 9.5854e-08],\n",
      "        [3.3925e-04, 1.0233e-01, 4.2168e-01, 3.7875e-01, 8.6183e-02, 4.5609e-03,\n",
      "         5.0968e-03, 6.9929e-04, 3.0108e-04, 5.3639e-05],\n",
      "        [1.7830e-04, 6.5032e-02, 1.2227e-01, 3.2072e-01, 4.5392e-01, 8.5216e-03,\n",
      "         2.4002e-02, 3.8770e-03, 1.2877e-03, 1.9663e-04],\n",
      "        [2.6292e-05, 3.2087e-02, 2.2815e-01, 5.2046e-01, 1.3925e-01, 2.4468e-02,\n",
      "         5.1165e-02, 2.3344e-03, 1.8304e-03, 2.2884e-04],\n",
      "        [3.5047e-06, 1.6565e-03, 5.1727e-03, 1.2755e-01, 6.6141e-01, 2.3601e-02,\n",
      "         1.1997e-01, 3.6905e-02, 2.0694e-02, 3.0325e-03],\n",
      "        [2.2677e-08, 1.2224e-04, 3.9502e-04, 8.8249e-03, 2.0815e-02, 1.0886e-01,\n",
      "         6.8509e-01, 1.0172e-01, 5.8426e-02, 1.5735e-02],\n",
      "        [2.9640e-08, 1.1853e-04, 3.6957e-04, 1.3937e-03, 1.4495e-03, 1.2516e-02,\n",
      "         9.0182e-01, 5.2847e-02, 2.2629e-02, 6.8595e-03]])\n",
      "\n",
      "Source: tôi đến từ đâu ? và tôi là ai ?\n",
      "Reference: where am i from ? who am i ?\n",
      "Model: <SOS> what i i from and and and i ?\n",
      "Attention Weights: tensor([[9.6101e-01, 3.8749e-02, 1.5468e-04, 4.0697e-05, 2.7325e-05, 8.5448e-06,\n",
      "         5.8265e-06, 2.0385e-07, 8.1817e-08, 7.7293e-08],\n",
      "        [1.2752e-02, 9.7456e-01, 1.2349e-02, 2.2393e-04, 1.0462e-04, 8.9803e-06,\n",
      "         2.1706e-06, 5.6107e-07, 6.4571e-08, 3.3363e-08],\n",
      "        [3.5292e-02, 8.3876e-01, 1.0448e-01, 1.1788e-02, 8.0728e-03, 1.3789e-03,\n",
      "         1.6017e-04, 5.4026e-05, 1.1951e-05, 3.1640e-06],\n",
      "        [3.5702e-02, 9.1161e-01, 4.2719e-02, 4.9979e-03, 4.0654e-03, 7.5513e-04,\n",
      "         1.1364e-04, 2.6827e-05, 5.0145e-06, 9.8882e-07],\n",
      "        [1.9791e-02, 4.8281e-02, 3.9668e-02, 8.4486e-02, 3.6397e-02, 6.7911e-01,\n",
      "         9.0718e-02, 1.0977e-03, 3.6281e-04, 8.9825e-05],\n",
      "        [3.0162e-03, 8.7254e-03, 2.3576e-02, 9.3922e-02, 6.4244e-02, 6.9033e-01,\n",
      "         1.1410e-01, 1.6124e-03, 3.1876e-04, 1.4798e-04],\n",
      "        [3.6167e-05, 4.0852e-04, 3.6298e-04, 3.8854e-03, 7.9721e-03, 8.4233e-01,\n",
      "         1.3907e-01, 5.5042e-03, 2.6446e-04, 1.6264e-04],\n",
      "        [2.1975e-04, 1.1860e-02, 7.5761e-03, 2.2464e-02, 4.1005e-02, 6.8522e-02,\n",
      "         6.0773e-01, 2.2692e-01, 5.4534e-03, 8.2452e-03],\n",
      "        [1.9142e-05, 1.4107e-02, 7.0609e-03, 1.3272e-02, 7.4530e-02, 2.9995e-02,\n",
      "         1.0844e-01, 5.9736e-01, 4.1735e-02, 1.1349e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6.96, Train Loss: 0.00, Val Loss: 4.10, Train BLEU: 0.00, Val BLEU: 14.18, Minutes Elapsed: 266.39\n",
      "Sampling from val predictions...\n",
      "Source: thật ra , trong 10 năm . <EOS> <PAD> <PAD>\n",
      "Reference: actually , for 10 years . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> in , in years years . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9814, 0.0183, 0.0003, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2212, 0.4050, 0.2984, 0.0649, 0.0086, 0.0019, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0699, 0.1176, 0.1341, 0.3577, 0.1479, 0.1452, 0.0232, 0.0043, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0005, 0.0020, 0.0735, 0.2220, 0.6708, 0.0248, 0.0062, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0020, 0.0024, 0.0314, 0.1340, 0.7735, 0.0466, 0.0097, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0001, 0.0005, 0.0113, 0.0677, 0.7467, 0.0984, 0.0754, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0002, 0.0060, 0.0334, 0.4381, 0.1792, 0.3431, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0001, 0.0003, 0.0106, 0.0912, 0.5808, 0.0864, 0.2306, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0006, 0.0021, 0.0047, 0.0868, 0.7845, 0.0425, 0.0788, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Source: rồi nếu lái_xe lên chỗ đường đó , bạn sẽ\n",
      "Reference: then if you drive over the road , you\n",
      "Model: <SOS> and if you drive that the , , you\n",
      "Attention Weights: tensor([[9.8915e-01, 1.0709e-02, 5.6911e-06, 6.9614e-05, 6.9562e-06, 1.1014e-05,\n",
      "         2.0155e-05, 1.6429e-05, 7.2533e-06, 8.2782e-08],\n",
      "        [5.9385e-02, 9.1723e-01, 2.1102e-02, 1.9626e-03, 2.2934e-04, 8.1011e-05,\n",
      "         1.2280e-05, 1.0217e-06, 1.1090e-06, 1.5871e-07],\n",
      "        [7.5850e-04, 1.7417e-01, 7.2194e-01, 7.7556e-02, 1.6981e-02, 7.7709e-03,\n",
      "         7.9034e-04, 2.0360e-05, 8.6847e-06, 4.0885e-06],\n",
      "        [4.5544e-04, 1.2457e-01, 3.1625e-01, 3.9231e-01, 9.0556e-02, 7.1407e-02,\n",
      "         4.3235e-03, 1.0458e-04, 1.2531e-05, 1.2568e-05],\n",
      "        [7.4006e-04, 2.8777e-02, 4.5349e-02, 3.6502e-01, 2.7946e-01, 2.6258e-01,\n",
      "         1.5659e-02, 1.9779e-03, 2.8569e-04, 1.5811e-04],\n",
      "        [1.8270e-04, 4.8477e-03, 7.6161e-02, 2.2152e-01, 2.0540e-01, 3.9420e-01,\n",
      "         8.8169e-02, 9.0053e-03, 4.3410e-04, 8.1383e-05],\n",
      "        [3.6176e-06, 7.3157e-04, 1.5125e-02, 1.6874e-02, 1.1972e-01, 5.7802e-01,\n",
      "         1.9859e-01, 5.2793e-02, 1.5377e-02, 2.7627e-03],\n",
      "        [4.9812e-07, 3.3148e-04, 1.1523e-03, 2.3119e-03, 2.6049e-02, 1.7368e-01,\n",
      "         1.1384e-01, 5.2427e-01, 1.4866e-01, 9.6990e-03],\n",
      "        [3.7215e-07, 5.7613e-04, 4.2498e-04, 2.9798e-03, 3.1368e-02, 8.1822e-02,\n",
      "         1.1434e-01, 4.4776e-01, 3.1024e-01, 1.0485e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7.00, Train Loss: 0.00, Val Loss: 4.14, Train BLEU: 0.00, Val BLEU: 14.41, Minutes Elapsed: 267.85\n",
      "Sampling from val predictions...\n",
      "Source: tôi sống ở vùng trung nam . <EOS> <PAD> <PAD>\n",
      "Reference: i live in south central . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> i live in the middle . . <EOS> in\n",
      "Attention Weights: tensor([[0.9839, 0.0160, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0005, 0.9942, 0.0046, 0.0007, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0047, 0.4060, 0.4137, 0.1638, 0.0104, 0.0012, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0154, 0.0943, 0.6664, 0.1797, 0.0424, 0.0012, 0.0003, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0004, 0.0039, 0.0158, 0.4775, 0.3690, 0.1256, 0.0052, 0.0025, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0010, 0.0014, 0.0125, 0.5406, 0.2870, 0.1308, 0.0168, 0.0099, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0003, 0.0010, 0.1422, 0.3742, 0.3450, 0.0825, 0.0546, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0001, 0.0004, 0.0563, 0.1814, 0.3839, 0.1916, 0.1863, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0004, 0.0204, 0.0352, 0.5011, 0.2299, 0.1502, 0.0190, 0.0438, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Source: tôi sẽ nói cho bạn biết tại_sao . <EOS> <PAD>\n",
      "Reference: and i &apos;ll tell you why . <EOS> <PAD>\n",
      "Model: <SOS> i &apos;m &apos;m tell you why why . .\n",
      "Attention Weights: tensor([[0.9686, 0.0308, 0.0003, 0.0002, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0054, 0.9568, 0.0352, 0.0019, 0.0005, 0.0002, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0233, 0.3718, 0.2348, 0.2069, 0.1039, 0.0475, 0.0108, 0.0008, 0.0003,\n",
      "         0.0000],\n",
      "        [0.0366, 0.3475, 0.2288, 0.1768, 0.1442, 0.0503, 0.0151, 0.0007, 0.0002,\n",
      "         0.0000],\n",
      "        [0.0005, 0.0017, 0.0462, 0.6287, 0.2283, 0.0567, 0.0358, 0.0017, 0.0003,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0001, 0.0026, 0.1267, 0.1237, 0.3609, 0.3539, 0.0244, 0.0077,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0001, 0.0008, 0.0126, 0.0540, 0.1594, 0.4968, 0.1952, 0.0810,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0005, 0.0108, 0.0271, 0.0626, 0.4120, 0.2367, 0.2502,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0003, 0.0018, 0.0359, 0.0750, 0.1118, 0.2847, 0.1376, 0.3530,\n",
      "         0.0000]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7.24, Train Loss: 0.00, Val Loss: 4.10, Train BLEU: 0.00, Val BLEU: 15.16, Minutes Elapsed: 276.14\n",
      "Sampling from val predictions...\n",
      "Source: <UNK> <UNK> . theo ngôn_ngữ của tôi , nó có\n",
      "Reference: <UNK> <UNK> . it means in my language ,\n",
      "Model: <SOS> <UNK> <UNK> . my my my my language ,\n",
      "Attention Weights: tensor([[8.3246e-01, 1.5081e-01, 3.5213e-03, 3.6179e-04, 2.3929e-05, 2.5202e-03,\n",
      "         1.0225e-02, 5.0934e-05, 1.6618e-05, 3.8041e-06],\n",
      "        [1.1794e-01, 8.0368e-01, 6.7585e-02, 5.8625e-03, 2.4972e-03, 1.8516e-03,\n",
      "         5.4890e-04, 3.4545e-05, 9.8574e-07, 6.7607e-07],\n",
      "        [6.4105e-02, 3.2945e-01, 3.9267e-01, 1.5885e-01, 2.1159e-02, 1.9319e-02,\n",
      "         1.2756e-02, 1.3602e-03, 2.4122e-04, 9.6964e-05],\n",
      "        [1.4892e-03, 6.5424e-03, 5.2874e-02, 4.7650e-01, 3.5208e-01, 4.6816e-02,\n",
      "         4.4705e-02, 1.6502e-02, 2.0691e-03, 4.2167e-04],\n",
      "        [5.0334e-04, 6.0520e-03, 4.3357e-02, 2.3335e-01, 6.1019e-01, 6.5139e-02,\n",
      "         2.5618e-02, 1.0070e-02, 3.6417e-03, 2.0711e-03],\n",
      "        [1.0529e-03, 1.0839e-02, 6.6369e-02, 3.5004e-01, 1.9658e-01, 3.7987e-02,\n",
      "         6.8196e-02, 1.6270e-01, 6.6164e-02, 4.0065e-02],\n",
      "        [2.0424e-05, 1.3753e-03, 5.9085e-02, 3.5196e-01, 3.7545e-01, 1.1307e-01,\n",
      "         7.5798e-02, 1.4199e-02, 6.5494e-03, 2.4960e-03],\n",
      "        [3.7181e-06, 2.1538e-04, 1.5989e-02, 3.2996e-01, 3.4002e-01, 4.3119e-02,\n",
      "         3.2627e-02, 7.9773e-02, 1.1433e-01, 4.3956e-02],\n",
      "        [9.9323e-06, 1.0012e-04, 6.9128e-03, 2.1729e-01, 5.3713e-02, 4.9589e-02,\n",
      "         3.8542e-01, 9.6935e-02, 1.7578e-01, 1.4250e-02]])\n",
      "\n",
      "Source: lái_xe trên đường ở ghana , cũng những đồng_nghiệp trong\n",
      "Reference: driving down a road in ghana with partners of\n",
      "Model: <SOS> the in the the in in , the ,\n",
      "Attention Weights: tensor([[8.9151e-01, 9.2594e-02, 9.1893e-03, 2.0654e-03, 1.5299e-03, 2.6186e-03,\n",
      "         3.9803e-04, 3.5665e-05, 3.8614e-05, 1.8586e-05],\n",
      "        [1.3000e-01, 7.8831e-01, 7.4134e-02, 5.7750e-03, 1.6640e-03, 1.0336e-04,\n",
      "         8.8178e-06, 3.3569e-06, 1.4197e-06, 1.8157e-07],\n",
      "        [6.8165e-02, 2.1014e-01, 6.1634e-01, 3.3701e-02, 6.6842e-02, 3.5174e-03,\n",
      "         7.9222e-04, 1.3171e-04, 3.4673e-04, 1.9257e-05],\n",
      "        [9.8075e-03, 6.8685e-02, 5.6384e-01, 9.2743e-02, 2.2032e-01, 3.2448e-02,\n",
      "         1.0019e-02, 8.6934e-04, 1.1716e-03, 9.0758e-05],\n",
      "        [2.0242e-03, 2.0638e-02, 3.3340e-01, 1.6318e-01, 4.1013e-01, 4.7668e-02,\n",
      "         1.8550e-02, 1.7053e-03, 2.4876e-03, 2.1811e-04],\n",
      "        [4.1975e-04, 3.5764e-03, 7.7694e-02, 1.3761e-01, 6.6529e-01, 7.5588e-02,\n",
      "         3.8364e-02, 7.8366e-04, 4.9800e-04, 1.7974e-04],\n",
      "        [1.1801e-04, 2.4643e-03, 6.3673e-02, 1.3603e-01, 5.3689e-01, 1.8613e-01,\n",
      "         6.0427e-02, 4.9144e-03, 8.7380e-03, 6.0820e-04],\n",
      "        [2.1232e-05, 6.4253e-05, 1.2745e-03, 5.3722e-03, 4.5687e-02, 8.2767e-02,\n",
      "         8.5850e-01, 4.3784e-03, 1.3499e-03, 5.8463e-04],\n",
      "        [3.5174e-05, 3.6977e-04, 5.2752e-03, 9.2501e-03, 1.9381e-02, 3.0199e-02,\n",
      "         4.6372e-01, 2.9542e-01, 1.5878e-01, 1.7573e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7.48, Train Loss: 0.00, Val Loss: 4.07, Train BLEU: 0.00, Val BLEU: 14.97, Minutes Elapsed: 284.47\n",
      "Sampling from val predictions...\n",
      "Source: vì_vậy tôi phát vỡ sự yên_lặng . <EOS> <PAD> <PAD>\n",
      "Reference: so i broke the silence . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> so i i a . . <EOS> was broke\n",
      "Attention Weights: tensor([[0.9950, 0.0050, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1750, 0.8072, 0.0164, 0.0011, 0.0002, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0008, 0.0015, 0.8983, 0.0855, 0.0062, 0.0070, 0.0005, 0.0003, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0166, 0.0150, 0.2099, 0.3936, 0.2009, 0.1518, 0.0090, 0.0031, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0024, 0.0005, 0.0116, 0.4065, 0.3252, 0.1911, 0.0569, 0.0058, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0027, 0.0008, 0.0018, 0.0430, 0.2079, 0.4552, 0.1643, 0.1243, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0104, 0.0085, 0.0011, 0.0066, 0.1129, 0.3841, 0.2017, 0.2748, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0046, 0.0066, 0.0048, 0.0515, 0.1322, 0.2990, 0.1215, 0.3799, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0026, 0.0026, 0.3425, 0.3152, 0.1060, 0.1374, 0.0092, 0.0845, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Source: nhưng để tôi thử xem . <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: but i will do a trial . <EOS> <PAD>\n",
      "Model: <SOS> but let me try see . . <EOS> .\n",
      "Attention Weights: tensor([[0.0244, 0.9734, 0.0021, 0.0000, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0144, 0.9693, 0.0152, 0.0009, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0036, 0.2226, 0.2173, 0.5369, 0.0171, 0.0017, 0.0007, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0016, 0.0332, 0.0367, 0.6519, 0.1849, 0.0670, 0.0247, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0009, 0.0173, 0.0350, 0.3272, 0.4111, 0.1432, 0.0653, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0006, 0.0101, 0.0159, 0.0890, 0.4217, 0.3118, 0.1509, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0069, 0.0120, 0.0964, 0.2164, 0.3392, 0.3290, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0004, 0.0274, 0.0615, 0.1904, 0.2682, 0.2304, 0.2217, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0026, 0.0115, 0.0724, 0.0933, 0.1902, 0.6300, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7.72, Train Loss: 0.00, Val Loss: 4.11, Train BLEU: 0.00, Val BLEU: 15.78, Minutes Elapsed: 292.81\n",
      "Sampling from val predictions...\n",
      "Source: bạn phải học cách khiến những người này tìm đến\n",
      "Reference: you have to learn how to get these people\n",
      "Model: <SOS> you have to learn to these to together to\n",
      "Attention Weights: tensor([[8.5240e-01, 1.4341e-01, 4.1377e-03, 1.8930e-05, 2.5313e-05, 9.6258e-07,\n",
      "         1.5623e-06, 1.6445e-06, 6.5753e-08, 2.1647e-08],\n",
      "        [8.6531e-03, 9.3178e-01, 5.8691e-02, 7.6045e-04, 7.6022e-05, 2.4241e-05,\n",
      "         1.4078e-05, 1.4222e-06, 2.2368e-07, 3.1482e-08],\n",
      "        [1.4922e-02, 4.9190e-01, 4.1747e-01, 5.3853e-02, 1.4753e-02, 3.6410e-03,\n",
      "         3.1515e-03, 2.2082e-04, 8.0619e-05, 7.4782e-06],\n",
      "        [1.5741e-03, 2.8948e-03, 8.2374e-01, 1.4608e-01, 1.8650e-02, 3.4951e-03,\n",
      "         3.2798e-03, 1.8932e-04, 7.4655e-05, 2.5957e-05],\n",
      "        [3.5357e-05, 7.2047e-05, 8.0393e-02, 3.2434e-01, 3.6959e-01, 7.4612e-02,\n",
      "         1.2733e-01, 6.6583e-03, 1.4394e-02, 2.5690e-03],\n",
      "        [4.6538e-06, 2.1338e-06, 1.2616e-03, 5.0252e-02, 1.8083e-01, 1.3405e-01,\n",
      "         5.3462e-01, 1.7500e-02, 6.5859e-02, 1.5625e-02],\n",
      "        [1.7103e-07, 1.6795e-07, 1.7327e-05, 5.7086e-04, 3.1741e-03, 1.5907e-02,\n",
      "         3.9904e-01, 1.8215e-02, 2.0011e-01, 3.6296e-01],\n",
      "        [7.9595e-07, 6.8197e-06, 1.2223e-03, 4.2357e-03, 8.7063e-03, 8.3723e-03,\n",
      "         1.1820e-01, 3.8152e-02, 4.2657e-01, 3.9453e-01],\n",
      "        [1.3324e-07, 3.4257e-08, 4.8671e-06, 2.3323e-04, 9.1320e-04, 2.2403e-03,\n",
      "         8.8310e-02, 2.4883e-03, 5.8564e-02, 8.4725e-01]])\n",
      "\n",
      "Source: tôi thấy những người trẻ_tuổi muốn được làm_việc , nhưng\n",
      "Reference: i see young people and they want to work\n",
      "Model: <SOS> i see people people want to , to do\n",
      "Attention Weights: tensor([[9.9876e-01, 1.2071e-03, 9.0465e-06, 2.2430e-05, 5.1464e-06, 1.8577e-07,\n",
      "         6.6613e-09, 4.1968e-09, 1.6835e-09, 2.5082e-10],\n",
      "        [1.3436e-03, 9.8523e-01, 9.0258e-03, 3.6496e-03, 7.1356e-04, 3.1740e-05,\n",
      "         1.5935e-06, 1.2973e-07, 1.6512e-09, 1.3283e-09],\n",
      "        [1.0180e-02, 1.9478e-01, 2.5636e-01, 4.7297e-01, 5.6675e-02, 6.4865e-03,\n",
      "         2.2052e-03, 3.3912e-04, 6.6914e-06, 4.5620e-07],\n",
      "        [4.4264e-05, 4.7399e-04, 1.4919e-02, 1.5079e-01, 6.2406e-01, 1.9954e-01,\n",
      "         8.6672e-03, 1.4341e-03, 7.2473e-05, 3.0834e-06],\n",
      "        [5.2690e-06, 5.4179e-04, 6.3808e-04, 2.3929e-02, 1.3767e-01, 6.9246e-01,\n",
      "         1.2630e-01, 1.8146e-02, 3.0495e-04, 1.1512e-05],\n",
      "        [1.0743e-06, 1.8121e-04, 3.0210e-04, 1.3029e-03, 3.0963e-02, 3.7346e-01,\n",
      "         3.4286e-01, 2.3200e-01, 1.3128e-02, 5.8036e-03],\n",
      "        [3.0293e-08, 4.2655e-06, 2.8564e-04, 2.7140e-03, 5.5438e-03, 2.8264e-02,\n",
      "         1.3537e-01, 6.1615e-01, 1.8150e-01, 3.0176e-02],\n",
      "        [1.7251e-06, 5.6497e-05, 9.4982e-04, 8.0906e-03, 2.5356e-02, 2.9268e-01,\n",
      "         3.7032e-01, 1.4919e-01, 4.4955e-02, 1.0841e-01],\n",
      "        [6.1257e-08, 2.3501e-06, 1.9396e-04, 2.9355e-03, 1.0754e-02, 3.8210e-02,\n",
      "         1.1242e-01, 6.2613e-01, 1.2399e-01, 8.5359e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7.96, Train Loss: 0.00, Val Loss: 4.14, Train BLEU: 0.00, Val BLEU: 13.99, Minutes Elapsed: 301.15\n",
      "Sampling from val predictions...\n",
      "Source: vào tháng 11 năm 2011 , đang theo_dõi tình hình\n",
      "Reference: on march 11 , 2011 , i watched from\n",
      "Model: <SOS> in november 2011 2011 2011 in the expedition the\n",
      "Attention Weights: tensor([[6.8330e-01, 3.1445e-01, 5.6429e-04, 1.4593e-03, 1.0942e-04, 8.6118e-05,\n",
      "         2.5235e-06, 1.2959e-06, 1.1188e-05, 1.1862e-05],\n",
      "        [1.5472e-02, 5.7725e-01, 3.1021e-01, 9.6232e-02, 7.7058e-04, 5.3820e-05,\n",
      "         2.2382e-06, 2.5430e-06, 1.2151e-06, 6.0823e-07],\n",
      "        [1.2497e-03, 1.5169e-01, 2.0367e-01, 6.2670e-01, 1.4424e-02, 2.1469e-03,\n",
      "         1.9922e-05, 5.9643e-05, 2.7622e-05, 7.0425e-06],\n",
      "        [1.1837e-04, 8.7869e-03, 3.6734e-02, 6.8249e-01, 1.5980e-01, 1.0572e-01,\n",
      "         3.5233e-03, 1.4848e-03, 9.0728e-04, 4.3424e-04],\n",
      "        [2.2950e-06, 5.9256e-05, 1.1169e-03, 5.4439e-02, 5.8223e-01, 2.4156e-01,\n",
      "         6.4268e-02, 4.2797e-02, 9.6098e-03, 3.9140e-03],\n",
      "        [1.8680e-07, 3.2076e-05, 1.3051e-04, 5.9668e-03, 9.2675e-02, 1.5099e-01,\n",
      "         3.2621e-01, 3.5815e-01, 5.1071e-02, 1.4783e-02],\n",
      "        [5.0781e-09, 3.4060e-06, 1.4129e-05, 4.4915e-04, 7.8947e-04, 1.3174e-02,\n",
      "         1.4847e-01, 2.4420e-01, 4.3164e-01, 1.6126e-01],\n",
      "        [1.3439e-10, 7.9968e-08, 6.2840e-06, 2.6170e-04, 3.8719e-04, 1.3193e-03,\n",
      "         1.0711e-02, 2.2628e-01, 4.6977e-01, 2.9126e-01],\n",
      "        [8.8708e-09, 5.2407e-06, 2.7172e-05, 4.3459e-04, 5.8358e-04, 8.8044e-03,\n",
      "         1.7825e-01, 1.5551e-01, 4.5930e-01, 1.9708e-01]])\n",
      "\n",
      "Source: và mỗi ngày , mỗi ngày chúng_tôi thức_dậy với luật_lệ\n",
      "Reference: and every day , every day we wake up\n",
      "Model: <SOS> and every every , every every days every a\n",
      "Attention Weights: tensor([[3.4871e-05, 9.9979e-01, 1.6351e-04, 3.5981e-06, 6.5646e-06, 6.3096e-07,\n",
      "         1.2098e-06, 5.6264e-09, 1.4076e-08, 4.8938e-10],\n",
      "        [6.1162e-04, 9.8820e-01, 1.0870e-02, 2.1604e-04, 8.0727e-05, 1.8105e-05,\n",
      "         1.1294e-06, 8.6783e-09, 3.7500e-09, 1.0665e-09],\n",
      "        [1.2281e-04, 5.3650e-01, 4.0175e-01, 3.6037e-02, 1.8618e-02, 6.6578e-03,\n",
      "         2.8058e-04, 3.1883e-05, 1.9234e-06, 9.1259e-07],\n",
      "        [1.9327e-04, 4.5390e-01, 2.6142e-01, 4.9096e-02, 1.6789e-01, 5.4687e-02,\n",
      "         1.0676e-02, 1.8991e-03, 1.8781e-04, 5.0697e-05],\n",
      "        [3.2245e-05, 6.1490e-02, 1.3582e-01, 4.6946e-02, 6.0806e-01, 8.3265e-02,\n",
      "         5.4554e-02, 5.8954e-03, 2.1382e-03, 1.8031e-03],\n",
      "        [1.4706e-06, 2.5003e-02, 2.8962e-02, 1.3964e-02, 5.4676e-01, 2.7290e-01,\n",
      "         9.4043e-02, 1.5321e-02, 1.5882e-03, 1.4575e-03],\n",
      "        [1.9195e-07, 3.9146e-03, 1.1674e-02, 5.6784e-03, 1.7539e-01, 3.6235e-01,\n",
      "         2.1211e-01, 1.9255e-01, 2.7108e-02, 9.2197e-03],\n",
      "        [6.1244e-08, 1.1241e-04, 2.2511e-03, 8.3894e-03, 5.9334e-01, 1.1033e-01,\n",
      "         1.4048e-01, 7.8725e-02, 4.5047e-02, 2.1328e-02],\n",
      "        [1.9750e-09, 1.7891e-05, 1.8738e-04, 2.5297e-04, 1.5535e-01, 1.2452e-01,\n",
      "         1.1852e-01, 3.2979e-01, 1.1770e-01, 1.5367e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8.00, Train Loss: 0.00, Val Loss: 4.16, Train BLEU: 0.00, Val BLEU: 14.56, Minutes Elapsed: 302.59\n",
      "Sampling from val predictions...\n",
      "Source: tôi dẫn_đầu một sáng_kiến của <UNK> phụ_nữ libya vì hoà_bình\n",
      "Reference: i led an initiative by the libyan women &apos;s\n",
      "Model: <SOS> i started with a of the national who <UNK>\n",
      "Attention Weights: tensor([[9.8621e-01, 1.3783e-02, 1.1737e-06, 2.2839e-07, 8.9039e-07, 1.2543e-08,\n",
      "         6.7250e-09, 1.6227e-08, 8.0359e-09, 7.3013e-10],\n",
      "        [3.7471e-03, 9.9519e-01, 8.7841e-04, 1.5201e-04, 3.1098e-05, 1.2742e-06,\n",
      "         1.3066e-06, 5.6149e-08, 5.2283e-09, 3.6496e-09],\n",
      "        [3.0259e-03, 9.1261e-01, 6.5033e-02, 1.4885e-02, 3.9704e-03, 2.5593e-04,\n",
      "         2.0566e-04, 1.3710e-05, 2.4162e-06, 6.6340e-07],\n",
      "        [1.7878e-03, 2.9846e-02, 7.8747e-02, 7.6108e-01, 7.6530e-02, 2.1672e-02,\n",
      "         2.4569e-02, 5.1388e-03, 5.4070e-04, 8.7886e-05],\n",
      "        [2.9501e-05, 1.6739e-03, 3.4779e-03, 7.3252e-01, 9.2644e-02, 5.9372e-02,\n",
      "         7.3335e-02, 3.3319e-02, 3.2108e-03, 4.1636e-04],\n",
      "        [5.4030e-05, 2.3292e-04, 8.0180e-04, 2.4254e-02, 1.1541e-01, 1.6468e-01,\n",
      "         5.1977e-01, 1.3180e-01, 4.0512e-02, 2.4843e-03],\n",
      "        [7.4411e-08, 4.8908e-06, 1.2105e-04, 1.2391e-02, 6.6689e-03, 3.6301e-02,\n",
      "         5.4256e-01, 2.2251e-01, 1.6275e-01, 1.6687e-02],\n",
      "        [1.2551e-06, 8.1302e-05, 1.4052e-03, 2.2827e-03, 7.3131e-03, 3.6678e-02,\n",
      "         2.3997e-01, 2.1520e-01, 4.5387e-01, 4.3198e-02],\n",
      "        [2.1434e-05, 2.6811e-04, 3.7408e-03, 2.1853e-03, 1.6179e-02, 1.2270e-01,\n",
      "         3.5098e-01, 1.4362e-01, 3.3939e-01, 2.0924e-02]])\n",
      "\n",
      "Source: nơi đây cũng là nơi mà trung_tâm di_tản đã thu_thập\n",
      "Reference: this happened to also be a place in the\n",
      "Model: <SOS> now this also the the the the that the\n",
      "Attention Weights: tensor([[9.5081e-01, 4.5590e-02, 3.3922e-03, 9.5896e-05, 7.6781e-05, 9.8295e-06,\n",
      "         8.6709e-06, 1.0099e-07, 1.4126e-05, 3.6461e-07],\n",
      "        [2.7868e-01, 3.0163e-01, 4.1256e-01, 6.3133e-03, 7.1197e-04, 5.1123e-05,\n",
      "         5.3549e-05, 1.3454e-06, 5.0935e-07, 1.1960e-07],\n",
      "        [1.5036e-01, 1.2220e-01, 5.9383e-01, 8.7931e-02, 4.0152e-02, 2.4784e-03,\n",
      "         2.9194e-03, 1.0182e-04, 2.5058e-05, 4.9831e-06],\n",
      "        [7.1009e-03, 8.1439e-03, 1.1792e-01, 1.9262e-01, 5.0955e-01, 7.5437e-02,\n",
      "         7.7180e-02, 1.0804e-02, 9.9596e-04, 2.4766e-04],\n",
      "        [3.3525e-04, 7.7519e-04, 1.4428e-02, 3.5915e-02, 3.2232e-01, 1.5575e-01,\n",
      "         4.2113e-01, 3.9087e-02, 8.1130e-03, 2.1546e-03],\n",
      "        [7.3784e-05, 1.7234e-04, 2.6589e-03, 2.0143e-02, 3.1883e-01, 1.4866e-01,\n",
      "         3.7537e-01, 1.1952e-01, 1.0722e-02, 3.8526e-03],\n",
      "        [8.7199e-06, 5.8452e-05, 2.3876e-03, 9.3758e-03, 6.6099e-02, 1.2204e-01,\n",
      "         5.0403e-01, 2.1052e-01, 5.9520e-02, 2.5955e-02],\n",
      "        [5.7168e-06, 1.2689e-05, 2.2113e-04, 2.4893e-03, 1.3292e-01, 1.1196e-01,\n",
      "         4.1133e-01, 2.5420e-01, 4.8910e-02, 3.7954e-02],\n",
      "        [8.6476e-06, 1.0870e-05, 2.3586e-04, 2.0730e-03, 6.9610e-02, 1.8104e-01,\n",
      "         4.6217e-01, 1.4880e-01, 1.1548e-01, 2.0572e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8.24, Train Loss: 0.00, Val Loss: 4.11, Train BLEU: 0.00, Val BLEU: 14.70, Minutes Elapsed: 310.88\n",
      "Sampling from val predictions...\n",
      "Source: từ_đó chúng_tôi bắt_đầu nhờ khách du_lịch qua_đường chụp_ảnh <EOS> <PAD>\n",
      "Reference: this is when we started asking passing tourists to\n",
      "Model: <SOS> from we , we started the the the the\n",
      "Attention Weights: tensor([[0.9716, 0.0282, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0978, 0.7319, 0.1683, 0.0016, 0.0003, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0309, 0.2364, 0.6693, 0.0394, 0.0227, 0.0011, 0.0001, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0195, 0.2191, 0.5580, 0.1033, 0.0816, 0.0144, 0.0029, 0.0012, 0.0001,\n",
      "         0.0000],\n",
      "        [0.0229, 0.3434, 0.3815, 0.1169, 0.1081, 0.0201, 0.0055, 0.0014, 0.0002,\n",
      "         0.0000],\n",
      "        [0.0013, 0.0429, 0.5169, 0.0931, 0.3063, 0.0241, 0.0094, 0.0051, 0.0009,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0035, 0.1407, 0.2039, 0.3330, 0.1501, 0.1148, 0.0483, 0.0057,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0016, 0.0798, 0.0797, 0.3537, 0.2621, 0.1034, 0.1087, 0.0109,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0026, 0.0697, 0.1030, 0.3217, 0.2577, 0.0876, 0.1461, 0.0116,\n",
      "         0.0000]])\n",
      "\n",
      "Source: tôi sống ở new_york , và năm vừa_rồi , trong\n",
      "Reference: i live in new york , and last year\n",
      "Model: <SOS> i live in new york , and and year\n",
      "Attention Weights: tensor([[9.9725e-01, 2.7142e-03, 3.2905e-05, 2.1304e-06, 7.6327e-07, 1.4558e-07,\n",
      "         4.9924e-08, 8.2688e-10, 8.9786e-10, 1.0431e-10],\n",
      "        [1.0554e-03, 9.9378e-01, 5.0471e-03, 1.1705e-04, 4.0323e-07, 2.6670e-08,\n",
      "         2.3568e-08, 6.4935e-09, 1.9143e-10, 3.4328e-11],\n",
      "        [1.0318e-03, 2.1955e-01, 7.2255e-01, 5.6566e-02, 2.9003e-04, 9.7363e-06,\n",
      "         3.4552e-06, 3.5504e-06, 4.0326e-07, 7.6794e-09],\n",
      "        [7.3434e-05, 6.8437e-03, 6.0876e-02, 9.3009e-01, 2.0328e-03, 3.4773e-05,\n",
      "         2.8304e-05, 2.3149e-05, 1.0716e-06, 1.1964e-07],\n",
      "        [2.7586e-04, 3.9595e-03, 6.7433e-02, 8.6724e-01, 6.0396e-02, 4.6219e-04,\n",
      "         1.7102e-04, 5.8347e-05, 1.4254e-06, 1.2402e-07],\n",
      "        [1.1494e-04, 2.7252e-04, 2.6003e-02, 2.9022e-01, 6.3139e-01, 4.6295e-02,\n",
      "         5.1405e-03, 4.7462e-04, 7.7838e-05, 1.1514e-05],\n",
      "        [3.0919e-05, 6.6635e-05, 1.8392e-03, 1.0292e-01, 5.1758e-01, 3.3896e-01,\n",
      "         3.5456e-02, 2.2761e-03, 5.3659e-04, 3.3407e-04],\n",
      "        [2.2702e-05, 7.4848e-05, 3.0441e-04, 2.0722e-02, 4.1813e-02, 1.5692e-01,\n",
      "         7.2178e-01, 5.7797e-02, 3.5533e-04, 2.1585e-04],\n",
      "        [5.5313e-06, 3.5691e-04, 1.3563e-03, 3.4585e-02, 8.3266e-03, 2.2040e-03,\n",
      "         5.6863e-01, 3.8169e-01, 2.5485e-03, 2.9756e-04]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8.48, Train Loss: 0.00, Val Loss: 4.07, Train BLEU: 0.00, Val BLEU: 15.39, Minutes Elapsed: 319.21\n",
      "Sampling from val predictions...\n",
      "Source: xin chào . tôi là cameron russell , và trong\n",
      "Reference: hi . my name is cameron russell , and\n",
      "Model: <SOS> hi . i was , , , and and\n",
      "Attention Weights: tensor([[5.2800e-02, 8.2454e-01, 9.7572e-02, 2.4320e-02, 6.2425e-04, 8.3255e-05,\n",
      "         1.4293e-05, 3.9989e-05, 6.5114e-06, 9.0603e-08],\n",
      "        [1.3102e-02, 3.5016e-01, 6.0242e-01, 2.4046e-02, 8.1946e-03, 1.5894e-03,\n",
      "         4.7545e-04, 1.6676e-05, 1.4062e-06, 7.1477e-08],\n",
      "        [1.0779e-04, 9.8853e-03, 5.7119e-02, 4.0650e-01, 2.3342e-01, 2.5048e-01,\n",
      "         3.7451e-02, 3.9574e-03, 1.0478e-03, 3.5325e-05],\n",
      "        [2.4082e-05, 2.0967e-03, 4.4473e-02, 2.2129e-01, 4.0320e-01, 2.8086e-01,\n",
      "         4.6037e-02, 1.9554e-03, 5.2745e-05, 1.1076e-06],\n",
      "        [1.4087e-07, 5.1782e-05, 1.6561e-04, 3.2570e-03, 1.1186e-01, 7.2513e-01,\n",
      "         1.3575e-01, 1.9164e-02, 4.1683e-03, 4.4644e-04],\n",
      "        [3.0368e-07, 9.0496e-07, 6.9977e-04, 1.7851e-02, 1.1295e-02, 1.6943e-01,\n",
      "         8.8858e-02, 4.8286e-01, 2.2719e-01, 1.8119e-03],\n",
      "        [1.5904e-06, 2.3646e-06, 4.3802e-04, 1.9931e-03, 5.9374e-03, 7.2152e-02,\n",
      "         3.2698e-02, 4.3538e-02, 7.7408e-01, 6.9159e-02],\n",
      "        [1.6544e-06, 1.2071e-06, 2.3487e-04, 1.3506e-02, 2.8034e-03, 1.0272e-01,\n",
      "         9.6394e-02, 6.1007e-02, 6.6180e-01, 6.1540e-02],\n",
      "        [6.8083e-07, 8.5908e-06, 8.8438e-04, 6.2854e-03, 1.2766e-02, 4.9730e-02,\n",
      "         1.8319e-02, 5.2415e-02, 1.8004e-01, 6.7955e-01]])\n",
      "\n",
      "Source: tôi không biết anh ta đang bạo_hành tôi . <EOS>\n",
      "Reference: i didn &apos;t know he was abusing me .\n",
      "Model: <SOS> i didn &apos;t know he he going . <EOS>\n",
      "Attention Weights: tensor([[9.6582e-01, 3.3930e-02, 2.1513e-04, 2.9305e-05, 2.7451e-06, 2.1081e-07,\n",
      "         2.8302e-08, 9.4176e-08, 9.4635e-09, 5.1486e-10],\n",
      "        [2.5098e-03, 9.3085e-01, 6.5547e-02, 9.9029e-04, 2.2772e-05, 8.3074e-05,\n",
      "         1.6312e-06, 4.6946e-08, 5.5497e-08, 2.5138e-08],\n",
      "        [3.4750e-03, 6.4034e-01, 3.0478e-01, 4.5318e-02, 2.0526e-03, 3.6771e-03,\n",
      "         3.0134e-04, 1.6591e-05, 2.2140e-05, 8.0475e-06],\n",
      "        [1.3074e-04, 9.2435e-03, 9.1243e-01, 6.7502e-02, 1.0574e-03, 8.5423e-03,\n",
      "         1.0345e-03, 2.8027e-05, 1.4715e-05, 1.5128e-05],\n",
      "        [5.1484e-06, 5.2631e-04, 3.9897e-02, 7.4891e-01, 9.1390e-02, 8.8879e-02,\n",
      "         2.6655e-02, 2.5644e-03, 9.3361e-04, 2.3559e-04],\n",
      "        [4.6058e-06, 3.1882e-04, 6.5423e-03, 6.6223e-02, 1.6788e-01, 7.0440e-01,\n",
      "         4.5433e-02, 3.4147e-03, 3.9153e-03, 1.8707e-03],\n",
      "        [5.2482e-09, 3.0029e-05, 1.1852e-03, 2.5391e-03, 1.2248e-02, 7.7930e-01,\n",
      "         1.7201e-01, 3.8297e-03, 9.8428e-03, 1.9018e-02],\n",
      "        [1.5697e-09, 5.1638e-07, 8.6616e-05, 6.9196e-04, 1.1507e-03, 1.1393e-02,\n",
      "         5.2687e-01, 2.8136e-01, 9.9352e-02, 7.9098e-02],\n",
      "        [4.7633e-07, 8.3847e-07, 1.0505e-04, 5.1219e-03, 1.3124e-02, 2.6022e-02,\n",
      "         1.8994e-01, 2.3025e-01, 2.4494e-01, 2.9049e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8.72, Train Loss: 0.00, Val Loss: 4.10, Train BLEU: 0.00, Val BLEU: 15.55, Minutes Elapsed: 327.54\n",
      "Sampling from val predictions...\n",
      "Source: gần 200 tổ_chức được thiết_lập tại benghazi trong suốt thời_gian\n",
      "Reference: almost 200 organizations were established in benghazi during and\n",
      "Model: <SOS> over &apos;s 200 , have with the in a\n",
      "Attention Weights: tensor([[9.9991e-01, 8.7102e-05, 7.3780e-07, 2.5370e-08, 2.0169e-09, 2.5215e-08,\n",
      "         1.2058e-09, 4.2105e-09, 1.0511e-08, 2.5401e-09],\n",
      "        [8.6365e-01, 1.2882e-01, 7.2453e-03, 1.3744e-04, 1.1540e-04, 2.5030e-05,\n",
      "         1.6288e-06, 1.5364e-07, 6.6929e-08, 2.2766e-08],\n",
      "        [8.7442e-02, 3.6780e-01, 4.4203e-01, 5.0815e-02, 3.3811e-02, 1.3875e-02,\n",
      "         3.6286e-03, 3.0881e-04, 1.7477e-04, 1.1342e-04],\n",
      "        [6.2694e-03, 1.6902e-01, 3.4946e-01, 2.4648e-01, 1.8231e-01, 4.1519e-02,\n",
      "         4.1100e-03, 5.2796e-04, 1.8630e-04, 1.2301e-04],\n",
      "        [3.7218e-04, 3.7501e-02, 4.4575e-02, 2.5015e-01, 1.9662e-01, 3.8748e-01,\n",
      "         6.4728e-02, 8.0958e-03, 6.1222e-03, 4.3495e-03],\n",
      "        [8.0349e-08, 9.6416e-05, 3.0893e-03, 1.8701e-02, 7.5244e-02, 7.7986e-01,\n",
      "         5.7879e-02, 2.6057e-02, 1.7214e-02, 2.1865e-02],\n",
      "        [1.3597e-08, 1.6785e-06, 9.3330e-05, 1.1556e-03, 8.3692e-03, 2.6362e-01,\n",
      "         2.2818e-01, 1.1302e-01, 2.7228e-01, 1.1328e-01],\n",
      "        [6.3103e-08, 1.1679e-05, 3.0278e-04, 2.6907e-03, 9.9584e-03, 1.4492e-01,\n",
      "         7.2970e-02, 1.6391e-01, 4.6104e-01, 1.4419e-01],\n",
      "        [8.1587e-08, 7.3587e-06, 2.6509e-04, 2.8284e-03, 5.9968e-03, 4.6314e-02,\n",
      "         1.4831e-02, 4.3167e-02, 6.1981e-01, 2.6678e-01]])\n",
      "\n",
      "Source: vậy_nên cái mà tôi làm trong năm đầu_tiên tại <UNK>\n",
      "Reference: and so what i did in <UNK> that first\n",
      "Model: <SOS> so what i i did in the year in\n",
      "Attention Weights: tensor([[9.9612e-01, 3.8437e-03, 2.9469e-05, 3.3480e-06, 3.2230e-09, 2.7420e-10,\n",
      "         1.7827e-09, 2.8054e-10, 2.8805e-10, 9.5488e-12],\n",
      "        [1.2943e-01, 7.0905e-01, 1.4383e-01, 1.7541e-02, 1.3925e-04, 5.5085e-06,\n",
      "         5.0999e-06, 4.0047e-06, 8.5215e-08, 5.6760e-09],\n",
      "        [2.5391e-02, 1.8127e-01, 2.7366e-01, 4.4124e-01, 7.0077e-02, 3.2096e-03,\n",
      "         3.1526e-03, 1.9425e-03, 5.8095e-05, 2.2985e-06],\n",
      "        [1.8566e-02, 1.6615e-01, 4.4716e-01, 1.4193e-01, 2.1459e-01, 6.9109e-03,\n",
      "         2.2436e-03, 2.3866e-03, 5.9476e-05, 5.9577e-06],\n",
      "        [1.5200e-02, 9.2320e-02, 2.6049e-01, 2.0397e-01, 3.1015e-01, 7.2209e-02,\n",
      "         2.9917e-02, 1.5133e-02, 5.7705e-04, 3.6139e-05],\n",
      "        [9.6095e-04, 5.3940e-03, 2.7104e-02, 1.7529e-02, 4.8147e-01, 3.8661e-01,\n",
      "         6.6027e-02, 1.4002e-02, 8.3600e-04, 6.2063e-05],\n",
      "        [5.6915e-06, 2.4958e-05, 6.0043e-04, 6.1981e-03, 8.6661e-02, 1.8159e-01,\n",
      "         5.0796e-01, 2.0336e-01, 1.2637e-02, 9.5384e-04],\n",
      "        [5.0128e-05, 2.8402e-04, 3.7011e-03, 2.1662e-02, 2.4390e-01, 1.9904e-01,\n",
      "         2.9755e-01, 2.0957e-01, 2.1809e-02, 2.4377e-03],\n",
      "        [2.7312e-05, 8.5104e-05, 1.0725e-03, 7.0699e-03, 2.8465e-01, 1.2964e-01,\n",
      "         2.3704e-01, 8.4213e-02, 2.1845e-01, 3.7750e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8.96, Train Loss: 0.00, Val Loss: 4.11, Train BLEU: 0.00, Val BLEU: 14.78, Minutes Elapsed: 335.86\n",
      "Sampling from val predictions...\n",
      "Source: em có_một trí_nhớ cực hoàn_hảo . <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: he has the most <UNK> memory . <EOS> <PAD>\n",
      "Model: <SOS> i had a a woman . . <EOS> .\n",
      "Attention Weights: tensor([[0.9975, 0.0025, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0335, 0.9619, 0.0043, 0.0002, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0189, 0.8753, 0.0876, 0.0081, 0.0091, 0.0007, 0.0003, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0005, 0.0557, 0.7237, 0.0544, 0.1621, 0.0026, 0.0009, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0385, 0.5872, 0.2632, 0.1021, 0.0070, 0.0018, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0017, 0.0407, 0.1072, 0.0808, 0.2152, 0.4029, 0.1515, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0046, 0.0096, 0.0515, 0.2003, 0.3453, 0.3887, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0086, 0.0115, 0.0220, 0.1775, 0.2436, 0.5367, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0439, 0.0672, 0.1448, 0.3541, 0.1417, 0.2481, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Source: tên bà là joan , và bà là một người\n",
      "Reference: her name was joan , and she was a\n",
      "Model: <SOS> his name was barnaby , and she &apos;s a\n",
      "Attention Weights: tensor([[6.2550e-01, 3.6568e-01, 5.2818e-03, 1.9779e-04, 1.2948e-03, 5.6008e-04,\n",
      "         8.4529e-04, 4.7146e-04, 1.6215e-04, 5.5360e-06],\n",
      "        [3.5838e-01, 5.3162e-01, 1.0139e-01, 7.7610e-03, 8.0400e-04, 3.1109e-05,\n",
      "         8.3183e-06, 3.5886e-06, 1.2215e-06, 1.3281e-07],\n",
      "        [2.3692e-02, 7.5161e-02, 7.8713e-01, 1.0544e-01, 8.1706e-03, 1.8891e-04,\n",
      "         1.2963e-04, 7.1373e-05, 1.2642e-05, 4.7949e-07],\n",
      "        [1.0543e-03, 7.5041e-03, 9.2946e-02, 8.7878e-01, 1.8241e-02, 9.9932e-04,\n",
      "         2.4538e-04, 1.0857e-04, 1.0748e-04, 1.2403e-05],\n",
      "        [6.6379e-05, 1.4042e-03, 9.8062e-03, 2.6277e-01, 7.2526e-01, 3.8071e-04,\n",
      "         1.4430e-04, 7.3582e-05, 6.8695e-05, 2.3765e-05],\n",
      "        [3.5276e-05, 5.2186e-04, 1.1605e-02, 9.1069e-02, 5.3393e-01, 3.3819e-01,\n",
      "         1.8924e-02, 3.6122e-03, 1.9134e-03, 1.9998e-04],\n",
      "        [1.1052e-06, 1.5325e-05, 9.0218e-05, 3.6820e-04, 1.4174e-03, 1.1641e-01,\n",
      "         8.2705e-01, 4.0796e-02, 1.2212e-02, 1.6337e-03],\n",
      "        [7.9130e-07, 4.1269e-05, 8.8707e-04, 1.9781e-03, 1.3638e-03, 2.9923e-03,\n",
      "         3.4355e-01, 5.5402e-01, 8.7919e-02, 7.2489e-03],\n",
      "        [7.3654e-08, 5.3388e-06, 1.3351e-04, 8.5390e-04, 4.4918e-04, 1.0116e-03,\n",
      "         3.1374e-02, 2.9240e-01, 5.9026e-01, 8.3505e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9.00, Train Loss: 0.00, Val Loss: 4.12, Train BLEU: 0.00, Val BLEU: 15.09, Minutes Elapsed: 337.32\n",
      "Sampling from val predictions...\n",
      "Source: <UNK> tiếp tuc đánh tôi một đến hai lần mỗi\n",
      "Reference: <UNK> proceeded to beat me once or twice a\n",
      "Model: <SOS> <UNK> is journey me me a three three different\n",
      "Attention Weights: tensor([[4.6422e-01, 3.3166e-01, 3.3851e-03, 9.3941e-03, 1.9108e-01, 1.9577e-04,\n",
      "         1.8141e-05, 6.5787e-07, 4.0304e-06, 4.5325e-05],\n",
      "        [6.1694e-02, 8.1139e-01, 7.4681e-02, 5.1687e-02, 5.0263e-04, 2.8055e-05,\n",
      "         1.1062e-05, 2.2275e-06, 1.5212e-07, 4.9295e-08],\n",
      "        [9.3003e-03, 1.9465e-01, 2.4727e-01, 3.9596e-01, 1.3309e-01, 1.1745e-02,\n",
      "         6.2854e-03, 1.4723e-03, 1.5444e-04, 6.3702e-05],\n",
      "        [1.2514e-04, 3.0808e-03, 2.9843e-02, 4.2168e-01, 3.6713e-01, 9.0252e-02,\n",
      "         7.8346e-02, 6.6230e-03, 2.1387e-03, 7.7357e-04],\n",
      "        [1.6848e-04, 1.7923e-03, 3.6425e-02, 2.9880e-01, 1.8402e-01, 8.8590e-02,\n",
      "         2.5155e-01, 1.1287e-01, 1.9044e-02, 6.7409e-03],\n",
      "        [2.4591e-05, 9.1243e-04, 3.7843e-02, 2.0233e-01, 1.0130e-01, 3.7180e-02,\n",
      "         2.5478e-01, 3.0462e-01, 4.7505e-02, 1.3506e-02],\n",
      "        [7.0841e-07, 1.2596e-05, 2.8226e-03, 4.4234e-02, 6.2754e-02, 5.7510e-02,\n",
      "         2.1989e-01, 3.1990e-01, 2.0484e-01, 8.8039e-02],\n",
      "        [1.8477e-07, 5.3886e-06, 1.2093e-03, 2.1469e-02, 2.7833e-02, 3.0056e-02,\n",
      "         2.0731e-01, 3.6209e-01, 2.0523e-01, 1.4480e-01],\n",
      "        [1.2198e-07, 9.6309e-06, 5.0163e-04, 6.2916e-03, 1.7501e-02, 1.2868e-02,\n",
      "         9.8418e-02, 1.3593e-01, 3.3081e-01, 3.9767e-01]])\n",
      "\n",
      "Source: và tôi nói rằng : \" được . mang tới\n",
      "Reference: and i was like , &quot; cool . bring\n",
      "Model: <SOS> and i said , , &quot; yeah . please\n",
      "Attention Weights: tensor([[3.0701e-03, 9.9655e-01, 3.3597e-04, 3.9778e-05, 5.2822e-07, 3.8823e-08,\n",
      "         2.0872e-08, 1.3351e-08, 1.0750e-09, 3.6118e-10],\n",
      "        [1.0164e-02, 9.5886e-01, 2.7256e-02, 3.6831e-03, 3.6336e-05, 2.7550e-06,\n",
      "         1.6060e-06, 1.8753e-07, 1.0146e-08, 5.5655e-09],\n",
      "        [7.8896e-06, 8.7142e-03, 6.2853e-01, 3.5416e-01, 7.3044e-03, 6.9553e-04,\n",
      "         5.5654e-04, 3.7995e-05, 3.6826e-07, 6.4091e-07],\n",
      "        [4.0825e-06, 3.5004e-03, 8.0790e-02, 8.0026e-01, 8.9130e-02, 1.2581e-02,\n",
      "         1.1265e-02, 2.1426e-03, 1.9201e-04, 1.3240e-04],\n",
      "        [2.1162e-05, 2.5367e-04, 7.4313e-04, 8.5294e-02, 7.1107e-01, 1.3132e-01,\n",
      "         6.7510e-02, 2.4320e-03, 1.1644e-03, 1.8866e-04],\n",
      "        [2.0491e-04, 3.2598e-03, 2.2637e-03, 6.7168e-02, 7.1164e-01, 9.7398e-02,\n",
      "         1.1599e-01, 1.3531e-03, 5.7160e-04, 1.4650e-04],\n",
      "        [2.5679e-06, 2.3091e-04, 2.1256e-03, 2.3758e-02, 2.2555e-01, 9.6921e-02,\n",
      "         6.3230e-01, 1.5056e-02, 3.2689e-03, 7.9050e-04],\n",
      "        [5.9356e-09, 7.3221e-06, 4.1163e-04, 5.4069e-04, 2.1946e-03, 2.0389e-02,\n",
      "         5.1493e-01, 4.0697e-01, 3.5455e-02, 1.9104e-02],\n",
      "        [1.4789e-08, 8.4037e-07, 2.0854e-05, 1.2526e-04, 2.4011e-04, 1.4911e-03,\n",
      "         4.1409e-02, 2.5259e-02, 8.6483e-01, 6.6627e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9.24, Train Loss: 0.00, Val Loss: 4.12, Train BLEU: 0.00, Val BLEU: 14.95, Minutes Elapsed: 345.65\n",
      "Sampling from val predictions...\n",
      "Source: có mấy người đàn_ông , họ giúp tôi dỡ đồ\n",
      "Reference: these are the guys , they helped me <UNK>\n",
      "Model: <SOS> there are people people , they they help me\n",
      "Attention Weights: tensor([[9.6736e-01, 3.2162e-02, 3.9325e-04, 7.2735e-05, 9.9995e-06, 3.9552e-06,\n",
      "         3.5606e-07, 3.8221e-07, 4.5326e-10, 1.7696e-09],\n",
      "        [1.6022e-01, 6.4823e-01, 1.3048e-01, 5.5428e-02, 3.8843e-03, 9.3377e-04,\n",
      "         8.1628e-04, 6.8548e-06, 1.1345e-06, 1.3892e-07],\n",
      "        [4.7965e-02, 5.4830e-01, 2.1014e-01, 1.7399e-01, 1.0217e-02, 1.9292e-03,\n",
      "         6.9824e-03, 3.9531e-04, 6.8271e-05, 1.8480e-05],\n",
      "        [3.2464e-04, 2.4488e-02, 2.8315e-01, 3.7522e-01, 2.5046e-01, 2.7984e-02,\n",
      "         3.5336e-02, 2.6199e-03, 3.1226e-04, 9.5493e-05],\n",
      "        [2.6929e-05, 1.0530e-02, 9.0915e-02, 7.6269e-02, 6.9246e-01, 7.0619e-02,\n",
      "         5.6660e-02, 2.3969e-03, 9.0611e-05, 3.0734e-05],\n",
      "        [1.2711e-04, 1.1639e-02, 7.5046e-02, 1.5966e-01, 5.0664e-01, 1.9717e-01,\n",
      "         4.8672e-02, 9.1317e-04, 1.0735e-04, 2.8684e-05],\n",
      "        [2.8384e-05, 3.1276e-03, 2.2984e-02, 2.0723e-01, 2.2181e-01, 1.4216e-01,\n",
      "         4.0111e-01, 1.4466e-03, 8.9016e-05, 9.0866e-06],\n",
      "        [3.3606e-07, 1.5373e-04, 5.2902e-04, 5.2502e-03, 2.5622e-03, 4.8287e-02,\n",
      "         8.4402e-01, 7.2947e-02, 2.4353e-02, 1.8967e-03],\n",
      "        [1.1414e-08, 3.2558e-06, 1.2531e-03, 4.9175e-03, 5.5597e-03, 3.0332e-02,\n",
      "         3.2118e-02, 3.2415e-01, 4.8722e-01, 1.1444e-01]])\n",
      "\n",
      "Source: trong số những người tài_năng đáng kinh_ngạc tôi gặp ở\n",
      "Reference: amongst all the astonishing people i met there ,\n",
      "Model: <SOS> in in the people of i i in in\n",
      "Attention Weights: tensor([[1.2379e-01, 1.0149e-01, 6.9809e-03, 3.3994e-02, 9.5768e-03, 8.9615e-03,\n",
      "         2.2212e-02, 6.8849e-01, 4.0433e-03, 4.6850e-04],\n",
      "        [4.2065e-02, 6.7985e-01, 1.0164e-01, 1.0859e-01, 5.7811e-02, 8.2536e-03,\n",
      "         1.7377e-03, 4.8156e-05, 8.5263e-06, 1.1006e-06],\n",
      "        [3.3655e-02, 2.7603e-01, 7.9334e-02, 2.9630e-01, 1.6330e-01, 5.8962e-02,\n",
      "         8.6929e-02, 5.1432e-03, 3.2095e-04, 2.5414e-05],\n",
      "        [3.9253e-04, 5.5357e-03, 1.6054e-02, 4.5417e-01, 1.9267e-01, 8.0475e-02,\n",
      "         1.2231e-01, 1.2545e-01, 2.5952e-03, 3.5552e-04],\n",
      "        [1.7332e-04, 2.3278e-03, 1.5687e-02, 1.5609e-01, 1.8270e-01, 1.6402e-01,\n",
      "         1.3277e-01, 3.1219e-01, 3.0390e-02, 3.6532e-03],\n",
      "        [1.4565e-04, 1.2228e-03, 1.0239e-02, 6.1055e-02, 7.3688e-02, 1.3512e-01,\n",
      "         1.3342e-01, 4.9000e-01, 8.9536e-02, 5.5776e-03],\n",
      "        [7.8107e-06, 1.2903e-04, 3.9789e-03, 2.9269e-02, 6.3188e-02, 1.4445e-01,\n",
      "         1.9297e-01, 2.4241e-01, 3.1466e-01, 8.9283e-03],\n",
      "        [9.7922e-07, 1.3991e-05, 3.1559e-04, 3.4138e-03, 1.1848e-02, 3.2865e-02,\n",
      "         4.5892e-02, 6.2196e-02, 6.8732e-01, 1.5613e-01],\n",
      "        [4.6248e-07, 8.9852e-06, 8.5298e-05, 9.9322e-04, 2.5184e-03, 4.1742e-03,\n",
      "         2.5599e-02, 6.6011e-03, 1.0793e-01, 8.5209e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9.48, Train Loss: 0.00, Val Loss: 4.10, Train BLEU: 0.00, Val BLEU: 16.04, Minutes Elapsed: 353.98\n",
      "Sampling from val predictions...\n",
      "Source: nhưng bạn có_thể thấy cách mà chúng_ta giao_tiếp với nhau\n",
      "Reference: but you can see how your people are communicating\n",
      "Model: <SOS> but you can see how way communicate is other\n",
      "Attention Weights: tensor([[1.2158e-02, 9.8386e-01, 3.7032e-03, 1.5576e-04, 4.2081e-05, 7.2630e-05,\n",
      "         6.2311e-06, 3.0742e-07, 6.3144e-07, 1.0935e-08],\n",
      "        [2.7493e-02, 9.6282e-01, 9.5169e-03, 1.6127e-04, 4.2321e-06, 1.5811e-06,\n",
      "         7.9261e-07, 7.4336e-08, 9.7351e-09, 4.4257e-10],\n",
      "        [5.0494e-03, 3.6478e-01, 4.5520e-01, 1.7364e-01, 9.0739e-04, 7.4286e-05,\n",
      "         8.1173e-05, 2.5184e-04, 1.9560e-06, 6.7983e-08],\n",
      "        [1.5448e-03, 8.4719e-03, 4.2038e-02, 9.3168e-01, 1.2993e-02, 8.6663e-04,\n",
      "         4.1003e-04, 1.8962e-03, 9.7836e-05, 8.3772e-07],\n",
      "        [7.5960e-04, 5.7904e-04, 7.8519e-04, 8.3333e-02, 7.1551e-01, 1.6787e-01,\n",
      "         1.8672e-02, 8.5285e-03, 3.6515e-03, 3.1124e-04],\n",
      "        [6.4878e-04, 5.9219e-04, 5.2399e-04, 5.2695e-03, 2.1079e-01, 2.0172e-01,\n",
      "         2.0767e-01, 3.5019e-01, 2.1950e-02, 6.4413e-04],\n",
      "        [4.1648e-06, 5.4955e-05, 2.7314e-04, 8.9489e-04, 1.0621e-02, 3.6137e-02,\n",
      "         1.4526e-01, 7.4759e-01, 5.7694e-02, 1.4674e-03],\n",
      "        [1.4603e-11, 1.9220e-09, 1.1889e-06, 1.8480e-05, 1.2043e-04, 4.0983e-04,\n",
      "         9.9075e-04, 1.4050e-01, 8.4263e-01, 1.5335e-02],\n",
      "        [8.1233e-10, 9.8907e-09, 9.0872e-08, 3.9835e-05, 2.1231e-03, 3.8118e-03,\n",
      "         8.4896e-04, 4.7834e-02, 8.2485e-01, 1.2049e-01]])\n",
      "\n",
      "Source: cảm_ơn <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: thank you . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> thank you . <EOS> . you . is is\n",
      "Attention Weights: tensor([[0.0238, 0.9762, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.7822, 0.2178, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1242, 0.8758, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2210, 0.7790, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1816, 0.8184, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0681, 0.9319, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0106, 0.9894, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1030, 0.8970, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0955, 0.9045, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9.72, Train Loss: 0.00, Val Loss: 4.11, Train BLEU: 0.00, Val BLEU: 15.19, Minutes Elapsed: 362.30\n",
      "Sampling from val predictions...\n",
      "Source: cửa_hàng rượu , đồ_ăn nhanh , <UNK> . <EOS> <PAD>\n",
      "Reference: <UNK> stores , fast food , vacant lots .\n",
      "Model: <SOS> the , , fast , <EOS> <EOS> . <EOS>\n",
      "Attention Weights: tensor([[0.8916, 0.1077, 0.0002, 0.0003, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.3260, 0.5407, 0.1162, 0.0090, 0.0062, 0.0018, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1307, 0.0838, 0.1127, 0.5614, 0.0931, 0.0165, 0.0017, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0023, 0.0057, 0.0022, 0.5452, 0.3730, 0.0528, 0.0159, 0.0026, 0.0002,\n",
      "         0.0000],\n",
      "        [0.0005, 0.0012, 0.0009, 0.4497, 0.3313, 0.1298, 0.0637, 0.0211, 0.0020,\n",
      "         0.0000],\n",
      "        [0.0005, 0.0009, 0.0006, 0.0817, 0.0639, 0.1775, 0.2164, 0.2125, 0.2458,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0004, 0.0020, 0.0656, 0.0472, 0.1233, 0.2842, 0.3289, 0.1482,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0007, 0.0065, 0.1333, 0.0458, 0.0789, 0.1582, 0.4231, 0.1533,\n",
      "         0.0000],\n",
      "        [0.0036, 0.0020, 0.0054, 0.1475, 0.0967, 0.1863, 0.0923, 0.2311, 0.2351,\n",
      "         0.0000]])\n",
      "\n",
      "Source: cảm_ơn . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: thank you . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> thank you . <EOS> you you . is is\n",
      "Attention Weights: tensor([[0.0056, 0.9940, 0.0004, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0223, 0.9658, 0.0119, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0058, 0.7048, 0.2894, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0488, 0.3297, 0.6214, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0282, 0.3667, 0.6052, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0071, 0.2519, 0.7410, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0035, 0.3203, 0.6762, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0080, 0.1662, 0.8258, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0058, 0.2205, 0.7738, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9.96, Train Loss: 0.00, Val Loss: 4.12, Train BLEU: 0.00, Val BLEU: 15.26, Minutes Elapsed: 370.69\n",
      "Sampling from val predictions...\n",
      "Source: tôi đã rất <UNK> . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: and i was distraught . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> i was was so . <EOS> course was was\n",
      "Attention Weights: tensor([[0.9970, 0.0029, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0011, 0.0842, 0.9054, 0.0093, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0039, 0.0530, 0.8211, 0.1119, 0.0083, 0.0018, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0182, 0.0625, 0.8241, 0.0803, 0.0138, 0.0010, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0007, 0.0015, 0.0806, 0.6300, 0.2479, 0.0393, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0061, 0.0130, 0.0643, 0.2727, 0.4232, 0.2207, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0007, 0.0040, 0.0240, 0.1256, 0.8455, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0122, 0.0478, 0.2750, 0.0834, 0.0655, 0.5160, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0070, 0.0224, 0.5092, 0.2462, 0.0641, 0.1511, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Source: chúng_tôi không_thể chỉnh sửa nếu ảnh không được làm sạch\n",
      "Reference: we couldn &apos;t <UNK> the photo unless it was\n",
      "Model: <SOS> we couldn &apos;t wait if if of we can\n",
      "Attention Weights: tensor([[9.9038e-01, 9.6056e-03, 1.1668e-05, 1.2925e-06, 5.9359e-08, 1.4032e-09,\n",
      "         4.7104e-09, 3.9693e-10, 4.1231e-10, 3.6337e-11],\n",
      "        [6.6415e-03, 9.8835e-01, 4.9671e-03, 2.7621e-05, 1.1265e-05, 6.0487e-06,\n",
      "         5.9220e-07, 6.4019e-08, 2.0374e-08, 2.0958e-09],\n",
      "        [8.6779e-03, 9.4453e-01, 4.5681e-02, 9.0108e-04, 1.1685e-04, 5.7425e-05,\n",
      "         3.1986e-05, 2.5944e-06, 6.7096e-07, 7.9204e-08],\n",
      "        [4.1188e-04, 6.8927e-02, 8.8386e-01, 4.0078e-02, 5.2170e-03, 1.0902e-03,\n",
      "         3.4494e-04, 5.1343e-05, 1.0626e-05, 3.5660e-06],\n",
      "        [1.7327e-04, 1.1290e-03, 2.3454e-01, 6.4871e-01, 8.7704e-02, 1.5620e-02,\n",
      "         8.2202e-03, 2.3257e-03, 1.0056e-03, 5.7312e-04],\n",
      "        [1.2126e-03, 8.1075e-03, 2.5182e-01, 4.3286e-01, 2.2478e-01, 6.5537e-02,\n",
      "         1.4162e-02, 1.1114e-03, 2.4317e-04, 1.6989e-04],\n",
      "        [3.1909e-03, 6.4683e-04, 1.6429e-03, 9.7835e-03, 2.4713e-01, 4.8713e-01,\n",
      "         1.8193e-01, 4.8322e-02, 1.4195e-02, 6.0367e-03],\n",
      "        [5.9295e-04, 4.0895e-04, 5.5516e-04, 5.8732e-03, 1.4415e-01, 5.2775e-01,\n",
      "         1.7436e-01, 1.1837e-01, 1.8725e-02, 9.2109e-03],\n",
      "        [3.1438e-04, 3.0216e-04, 3.9884e-04, 2.7373e-03, 7.3755e-02, 3.2469e-01,\n",
      "         2.5180e-01, 2.0828e-01, 7.3535e-02, 6.4184e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10.00, Train Loss: 0.00, Val Loss: 4.13, Train BLEU: 0.00, Val BLEU: 15.05, Minutes Elapsed: 372.13\n",
      "Sampling from val predictions...\n",
      "Source: thật_ra tôi trở_thành người_mẫu bởi_vì tôi thắng giải xổ_số di_truyền\n",
      "Reference: the real way that i became a model is\n",
      "Model: <SOS> i actually , became i was become with because\n",
      "Attention Weights: tensor([[9.5510e-01, 4.4824e-02, 7.4868e-05, 2.0991e-07, 5.9964e-07, 3.1244e-06,\n",
      "         1.6150e-09, 5.2429e-10, 3.0378e-09, 1.5256e-10],\n",
      "        [3.9010e-01, 4.8473e-01, 1.1731e-01, 6.8177e-03, 9.4513e-04, 5.3714e-05,\n",
      "         3.7490e-05, 1.0917e-06, 3.8844e-07, 1.1667e-07],\n",
      "        [5.3684e-02, 4.3967e-01, 3.9033e-01, 9.6620e-02, 1.2904e-02, 3.7842e-03,\n",
      "         2.6262e-03, 2.5391e-04, 1.0691e-04, 2.3205e-05],\n",
      "        [3.2706e-02, 3.7479e-01, 5.4356e-01, 3.8196e-02, 9.4827e-03, 6.1379e-04,\n",
      "         5.7507e-04, 5.2594e-05, 1.4775e-05, 4.3846e-06],\n",
      "        [1.0848e-02, 1.8726e-01, 5.9398e-01, 1.7992e-01, 2.0424e-02, 2.5834e-03,\n",
      "         4.0552e-03, 5.9010e-04, 2.7969e-04, 5.0906e-05],\n",
      "        [1.1940e-02, 9.8138e-02, 5.9160e-01, 2.6079e-01, 3.1531e-02, 1.8289e-03,\n",
      "         3.5735e-03, 3.8817e-04, 1.6535e-04, 5.0553e-05],\n",
      "        [1.8520e-02, 5.5602e-02, 6.5882e-01, 2.0446e-01, 4.2646e-02, 3.9107e-03,\n",
      "         1.0563e-02, 2.8950e-03, 2.2390e-03, 3.4373e-04],\n",
      "        [1.5266e-04, 2.9432e-03, 3.4580e-02, 5.8361e-01, 3.1131e-01, 2.6162e-02,\n",
      "         1.9435e-02, 9.3162e-03, 9.0081e-03, 3.4878e-03],\n",
      "        [8.2223e-03, 3.9206e-02, 1.1534e-01, 3.7530e-01, 2.5974e-01, 7.5138e-02,\n",
      "         1.0184e-01, 1.2752e-02, 7.4985e-03, 4.9657e-03]])\n",
      "\n",
      "Source: họ biết hình của họ sẽ được xem bởi những\n",
      "Reference: they knew their image would be seen by you\n",
      "Model: <SOS> they they their their would be to by the\n",
      "Attention Weights: tensor([[8.8457e-01, 1.0159e-01, 6.0132e-03, 7.7082e-03, 9.1579e-05, 2.8140e-05,\n",
      "         4.6032e-07, 2.4455e-07, 2.6540e-08, 3.9648e-09],\n",
      "        [5.4433e-03, 9.4714e-01, 4.5544e-02, 5.5885e-04, 5.3955e-05, 1.2360e-03,\n",
      "         2.0652e-05, 1.2789e-06, 9.5266e-08, 2.2303e-08],\n",
      "        [1.4349e-03, 1.2174e-01, 7.6113e-01, 7.1212e-02, 1.7956e-03, 2.7188e-02,\n",
      "         1.3339e-02, 2.0132e-03, 1.3373e-04, 1.4424e-05],\n",
      "        [7.3714e-04, 1.8338e-02, 8.0745e-01, 5.7460e-02, 8.0023e-03, 9.7840e-02,\n",
      "         9.5853e-03, 4.8978e-04, 8.8121e-05, 4.0122e-06],\n",
      "        [1.6095e-04, 3.8443e-03, 1.4507e-01, 2.4983e-02, 3.7853e-02, 6.1317e-01,\n",
      "         1.3749e-01, 2.8113e-02, 8.1731e-03, 1.1446e-03],\n",
      "        [9.4256e-06, 2.7845e-03, 2.5315e-02, 7.3090e-03, 1.4172e-02, 6.5768e-01,\n",
      "         2.1552e-01, 5.6284e-02, 1.7742e-02, 3.1813e-03],\n",
      "        [4.5802e-07, 6.6867e-05, 3.3996e-02, 2.3053e-02, 4.7591e-03, 2.6161e-02,\n",
      "         1.0808e-01, 2.3425e-01, 4.4605e-01, 1.2359e-01],\n",
      "        [2.1543e-07, 1.7099e-06, 6.8766e-03, 3.2410e-03, 3.9554e-04, 1.1950e-03,\n",
      "         1.5398e-02, 1.9283e-01, 6.3140e-01, 1.4866e-01],\n",
      "        [9.7453e-07, 3.5242e-06, 6.2615e-03, 2.1394e-02, 1.1858e-02, 2.3366e-02,\n",
      "         2.8770e-02, 1.1237e-01, 3.0608e-01, 4.8989e-01]])\n",
      "\n",
      "Model training completed in 372 minutes with 4.07 best validation loss and 16.04 best validation BLEU.\n"
     ]
    }
   ],
   "source": [
    "model, results = train_and_eval(\n",
    "    model=model, loaders_full=loaders_full, loaders_minibatch=loaders_minibatch, loaders_minitrain=loaders_minitrain, \n",
    "    params=params, vocab=vocab, print_intermediate=500, save_checkpoint=True, save_to_log=True, \n",
    "    lazy_eval=True, print_attn=True, inspect_samples=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_results = load_experiment_log(experiment_name=EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_single_learning_curve(experiment_results[0]['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>best_val_loss</th>\n",
       "      <th>best_val_bleu</th>\n",
       "      <th>runtime</th>\n",
       "      <th>total_params</th>\n",
       "      <th>trainable_params</th>\n",
       "      <th>dt_created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vi-rnn-additive-attn-2018-12-12 19:04:50</td>\n",
       "      <td>4.067476</td>\n",
       "      <td>16.03673</td>\n",
       "      <td>372.135028</td>\n",
       "      <td>71591344.0</td>\n",
       "      <td>53591344.0</td>\n",
       "      <td>2018-12-13 01:17:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model_name  best_val_loss  best_val_bleu  \\\n",
       "0  vi-rnn-additive-attn-2018-12-12 19:04:50       4.067476       16.03673   \n",
       "\n",
       "      runtime  total_params  trainable_params           dt_created  \n",
       "0  372.135028    71591344.0        53591344.0  2018-12-13 01:17:03  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_results(experiment_results)[['model_name', 'best_val_loss', 'best_val_bleu', 'runtime', \n",
    "                                       'total_params', 'trainable_params', 'dt_created']].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload model \n",
    "MODEL_NAME_TO_RELOAD = 'vi-rnn-additive-attn-2018-12-12 19:04:50'\n",
    "checkpoint = torch.load('model_checkpoints/{}.pth.tar'.format(MODEL_NAME_TO_RELOAD), map_location=device)\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation BLEU: 16.04 | Validation Loss: 4.10\n"
     ]
    }
   ],
   "source": [
    "# check performance on validation set \n",
    "val_loss, val_bleu, val_hyp_idxs, val_ref_idxs, val_source_idxs, val_hyp_tokens, val_ref_tokens, val_source_tokens,\\\n",
    "val_attn = evaluate(model=model, loader=loaders_full['dev'], \n",
    "                    src_id2token=vocab[SRC_LANG]['id2token'], targ_id2token=vocab[TARG_LANG]['id2token'])\n",
    "print(\"Validation BLEU: {:.2f} | Validation Loss: {:.2f}\".format(val_bleu, val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test BLEU: 16.37 | Test Loss: 4.10\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set \n",
    "test_loss, test_bleu, test_hyp_idxs, test_ref_idxs, test_source_idxs, test_hyp_tokens, test_ref_tokens, test_source_tokens,\\\n",
    "test_attn = evaluate(model=model, loader=loaders_full['test'], \n",
    "                     src_id2token=vocab[SRC_LANG]['id2token'], targ_id2token=vocab[TARG_LANG]['id2token'])\n",
    "print(\"Test BLEU: {:.2f} | Test Loss: {:.2f}\".format(test_bleu, test_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
