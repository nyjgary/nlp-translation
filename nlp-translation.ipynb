{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from io import open\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "import unicodedata\n",
    "import re\n",
    "from torch.autograd import Variable\n",
    "from gensim.models import KeyedVectors\n",
    "import sacrebleu\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pickle as pkl\n",
    "import string\n",
    "import os\n",
    "from os import listdir \n",
    "from ast import literal_eval\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.style\n",
    "import matplotlib as mpl\n",
    "\n",
    "pd.set_option('max_colwidth',100)\n",
    "mpl.style.use('bmh')\n",
    "%matplotlib inline\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESERVED_TOKENS = {'<SOS>': 0, '<EOS>': 1, '<PAD>': 2, '<UNK>': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2tokens(raw_text_fp, lang_type): \n",
    "    \"\"\" Takes filepath to raw text and outputs a list of lists, each representing a sentence of words (tokens) \"\"\"\n",
    "    with open(raw_text_fp) as f:\n",
    "        tokens_data = [line.lower().split() for line in f.readlines()]\n",
    "        if lang_type == 'source': \n",
    "            tokens_data = [datum + ['<EOS>'] for datum in tokens_data]\n",
    "        elif lang_type == 'target': \n",
    "            tokens_data = [['<SOS'] + datum + ['<EOS>'] for datum in tokens_data]\n",
    "    return tokens_data \n",
    "\n",
    "def load_word2vec(lang): \n",
    "    \"\"\" Loads pretrained vectors for a given language \"\"\"\n",
    "    filepath = \"data/pretrained_word2vec/wiki.zh.vec\".format(lang)\n",
    "    word2vec = KeyedVectors.load_word2vec_format(filepath)\n",
    "    return word2vec\n",
    "\n",
    "def build_vocab(token_lists, max_vocab_size, word2vec): \n",
    "    \"\"\" Takes lists of tokens (representing sentences of words), max_vocab_size, word2vec model and returns: \n",
    "        - id2token: list of tokens, where id2token[i] returns token that corresponds to i-th token \n",
    "        - token2id: dictionary where keys represent tokens and corresponding values represent their indices\n",
    "        Note that the vocab will comprise N=max_vocab_size-len(RESERVED_TOKENS) tokens that are in word2vec model \n",
    "    \"\"\"\n",
    "    num_vocab = max_vocab_size - len(RESERVED_TOKENS)\n",
    "    all_tokens = [token for sublist in token_lists for token in sublist]\n",
    "    token_counter = Counter(all_tokens)\n",
    "    token_counter_filtered = Counter({token: token_counter[token] for token in token_counter if token in word2vec})\n",
    "    vocab, count = zip(*token_counter_filtered.most_common(num_vocab))\n",
    "    id2token = list(RESERVED_TOKENS.keys()) + list(vocab)\n",
    "    token2id = dict(zip(id2token, range(max_vocab_size)))\n",
    "    return token2id, id2token \n",
    "\n",
    "def tokens2indices(tokens_data, token2id): \n",
    "    \"\"\" Takes tokenized data and token2id dictionary and returns indexed data \"\"\"\n",
    "    indices_data = [] \n",
    "    for datum in tokens_data: \n",
    "        indices_datum = [token2id[token] if token in token2id else RESERVED_TOKENS['<UNK>'] for token in datum ]\n",
    "        indices_data.append(indices_datum)    \n",
    "    return indices_data\n",
    "\n",
    "def get_filepath(split, src_lang, targ_lang, lang_type): \n",
    "    \"\"\" Locates data filepath given data split type (train/dev/test), translation pairs (src_lang -> targ_lang), \n",
    "        and the language type (source or target)\n",
    "    \"\"\"\n",
    "    folder_name = \"data/iwslt-{}-{}/\".format(src_lang, targ_lang)\n",
    "    if lang_type == 'source': \n",
    "        file_name = \"{}.tok.{}\".format(split, src_lang)\n",
    "    elif lang_type == 'target': \n",
    "        file_name = \"{}.tok.{}\".format(split, targ_lang)\n",
    "    return folder_name + file_name \n",
    "\n",
    "def get_filepaths(src_lang, targ_lang): \n",
    "    \"\"\" Takes language names to be translated from and to (in_lang and out_lang respectively) as inputs, \n",
    "        returns a nested dictionary containing the filepaths for input/output data for train/dev/test sets  \n",
    "    \"\"\"\n",
    "    fps = {} \n",
    "    for split in ['train', 'dev', 'test']: \n",
    "        fps[split] = {} \n",
    "        for lang_type in ['source', 'target']: \n",
    "            fps[split][lang_type] = {} \n",
    "            fps[split][lang_type]['filepath'] = get_filepath(split, src_lang, targ_lang, lang_type)\n",
    "    return fps \n",
    "\n",
    "def process_data(src_lang, targ_lang, src_max_vocab_size, targ_max_vocab_size): \n",
    "    \"\"\" Takes source language and target language names and respective max vocab sizes as inputs \n",
    "        and returns as a nested dictionary containing: \n",
    "        - train_indices, val_indices, test_indices (as lists of source-target tuples)\n",
    "        - train_tokens, val_tokens, test_tokens (as lists of source-target tuples)\n",
    "        - source language's token2id and id2token \n",
    "        - target language's token2id and id2token\n",
    "    \"\"\"\n",
    "    \n",
    "    # get filepaths \n",
    "    data = get_filepaths(src_lang, targ_lang)\n",
    "    \n",
    "    # attach vocab sizes and word2vec models \n",
    "    data['train']['source']['max_vocab_size'] = src_max_vocab_size\n",
    "    data['train']['target']['max_vocab_size'] = targ_max_vocab_size \n",
    "    data['train']['source']['word2vec'] = load_word2vec(src_lang) \n",
    "    data['train']['target']['word2vec'] = load_word2vec(targ_lang) \n",
    "    \n",
    "    # loop through each file, read in text, convert to tokens, then to indices \n",
    "    for split in ['train', 'dev', 'test']: \n",
    "        for lang_type in ['source', 'target']: \n",
    "            \n",
    "            # read in tokens \n",
    "            data[split][lang_type]['tokens'] = text2tokens(data[split][lang_type]['filepath'], lang_type)\n",
    "            \n",
    "            # build vocab from training data\n",
    "            if split == 'train': \n",
    "                data['train'][lang_type]['token2id'], data['train'][lang_type]['id2token'] = build_vocab(\n",
    "                    token_lists = data['train'][lang_type]['tokens'], \n",
    "                    max_vocab_size = data['train'][lang_type]['max_vocab_size'], \n",
    "                    word2vec = data['train'][lang_type]['word2vec']) \n",
    "                \n",
    "            # convert tokens to indices \n",
    "            data[split][lang_type]['indices'] = tokens2indices(\n",
    "                data[split][lang_type]['tokens'], data['train'][lang_type]['token2id'])\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_LANG = 'zh'\n",
    "TARG_LANG = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_VOCAB_SIZE = 1000\n",
    "TARG_VOCAB_SIZE = 1000\n",
    "ENC_EMBED_DIM = 300 \n",
    "DEC_EMBED_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = process_data(SRC_LANG, TARG_LANG, src_max_vocab_size=SRC_VOCAB_SIZE, targ_max_vocab_size=TARG_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Source: ['你', '现在', '可以', '去', '个', '真正', '的', '学校', '念书', '了', '他', '说', '<EOS>']\n",
      "Example Target: ['<SOS', '&quot;', 'you', 'can', 'go', 'to', 'a', 'real', 'school', 'now', ',', '&quot;', 'he', 'said', '.', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "# print example for sanity check  \n",
    "print(\"Example Source: {}\".format(data['train']['source']['tokens'][5]))\n",
    "print(\"Example Target: {}\".format(data['train']['target']['tokens'][5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check distribution of source sentence lengths \n",
    "pd.Series(np.array([len(l) for l in data['train']['source']['indices']])).hist(bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check distribution of target sentence lengths \n",
    "pd.Series(np.array([len(l) for l in data['train']['target']['indices']])).hist(bins=100); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset): \n",
    "    \"\"\" \n",
    "    Class that represents a train/validation/test/dataset that's readable for Pytorch. \n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "    def __init__(self, src_indices, targ_indices, src_max_sentence_len, targ_max_sentence_len):\n",
    "        \"\"\" \n",
    "        Initialize dataset by passing in a list of input indices and a list of output indices \n",
    "        \"\"\"\n",
    "        self.src_indices = src_indices\n",
    "        self.targ_indices = targ_indices\n",
    "        self.src_max_sentence_len = src_max_sentence_len\n",
    "        self.targ_max_sentence_len = targ_max_sentence_len\n",
    "        assert (len(self.src_indices) == len(self.targ_indices))\n",
    "        \n",
    "    def __len__(self): \n",
    "        return len(self.src_indices)\n",
    "    \n",
    "    def __getitem__(self, key): \n",
    "        \"\"\" \n",
    "        Triggered when dataset[i] is called, outputs lists of input and output indices, as well as their \n",
    "        respective lengths\n",
    "        \"\"\"\n",
    "        src_idx = self.src_indices[key][:self.src_max_sentence_len]\n",
    "        src_len = len(src_idx)\n",
    "        targ_idx = self.targ_indices[key][:self.targ_max_sentence_len]\n",
    "        targ_len = len(targ_idx)\n",
    "        return [src_idx, targ_idx, src_len, targ_len]\n",
    "    \n",
    "def collate_func(src_max_sentence_len, targ_max_sentence_len, batch): \n",
    "    \"\"\" Customized function for DataLoader that dynamically pads the batch so that all data have the same length\"\"\"\n",
    "    \n",
    "    src_idxs = [] \n",
    "    targ_idxs = [] \n",
    "    src_lens = [] \n",
    "    targ_lens = [] \n",
    "    \n",
    "    for datum in batch: \n",
    "        # append original lengths of sequences \n",
    "        src_lens.append(datum[2]) \n",
    "        targ_lens.append(datum[3])\n",
    "        \n",
    "        # pad sequences before appending \n",
    "        src_idx_padded = np.pad(array=np.array(datum[0]), pad_width = ((0, src_max_sentence_len - datum[2])), \n",
    "                                mode='constant', constant_values=RESERVED_TOKENS['<PAD>'])\n",
    "        targ_idx_padded = np.pad(array=np.array(datum[1]), pad_width = ((0, targ_max_sentence_len - datum[3])),\n",
    "                                 mode='constant', constant_values=RESERVED_TOKENS['<PAD>'])\n",
    "        src_idxs.append(src_idx_padded)\n",
    "        targ_idxs.append(targ_idx_padded)\n",
    "    \n",
    "    return [torch.from_numpy(np.array(src_idxs)), torch.from_numpy(np.array(targ_idxs)), \n",
    "            torch.LongTensor(src_lens), torch.LongTensor(targ_lens)]\n",
    "\n",
    "def create_dataloaders(processed_data, src_max_sentence_len, targ_max_sentence_len, batch_size): \n",
    "    \"\"\" Takes processed_data as dictionary output from process_data func, maximum sentence lengths, \n",
    "        and outputs train_loader, dev_loader, and test_loaders \n",
    "    \"\"\"\n",
    "    loaders = {} \n",
    "    for split in ['train', 'dev', 'test']: \n",
    "        dataset = TranslationDataset(data[split]['source']['indices'], data[split]['target']['indices'], \n",
    "                                     src_max_sentence_len, targ_max_sentence_len)\n",
    "        loaders[split] = DataLoader(dataset, batch_size=batch_size, shuffle=False, \n",
    "                                    collate_fn=partial(collate_func, src_max_sentence_len, targ_max_sentence_len))\n",
    "    return loaders['train'], loaders['dev'], loaders['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "SRC_MAX_SENTENCE_LEN = 40 \n",
    "TARG_MAX_SENTENCE_LEN = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, dev_loader, test_loader = create_dataloaders(data, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)\n",
    "#train_loader_, dev_loader_, test_loader_ = create_dataloaders(data, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([32, 40])\n",
      "tensor([[  5,   3, 171,  ...,   2,   2,   2],\n",
      "        [  5,   4, 199,  ...,   2,   2,   2],\n",
      "        [ 13,   3,   3,  ...,   2,   2,   2],\n",
      "        ...,\n",
      "        [ 51,  13, 204,  ...,   2,   2,   2],\n",
      "        [  7,   3,   3,  ...,   2,   2,   2],\n",
      "        [  5,  37,  92,  ...,   2,   2,   2]])\n",
      "tensor([16, 15, 21,  9, 17, 13,  7,  5, 16, 28, 11, 18, 18, 17,  8, 18, 13,  9,\n",
      "         6,  7, 10, 16, 13, 36, 13,  4, 23, 19, 23, 15, 25, 28])\n",
      "torch.Size([32, 40])\n",
      "tensor([[  3,  50,   9,  ...,   2,   2,   2],\n",
      "        [  3,  19, 217,  ...,   2,   2,   2],\n",
      "        [  3,  54,  20,  ...,   2,   2,   2],\n",
      "        ...,\n",
      "        [  3,   8, 111,  ...,   2,   2,   2],\n",
      "        [  3, 339, 436,  ...,   2,   2,   2],\n",
      "        [  3,   9,  76,  ...,   2,   2,   2]])\n",
      "tensor([22, 16, 22, 13, 23, 16, 10,  6, 25, 35, 13, 21, 20, 21, 13, 20, 21, 11,\n",
      "         7,  9, 17, 21, 12, 35, 10,  6, 24, 23, 26, 15, 29, 32])\n"
     ]
    }
   ],
   "source": [
    "# check that loader works \n",
    "for i, (src_idxs, targ_idxs, src_lens, targ_lens) in enumerate(train_loader):\n",
    "    print(i)\n",
    "    print(src_idxs.size())\n",
    "    print(src_idxs)\n",
    "    print(src_lens)\n",
    "    print(targ_idxs.size())\n",
    "    print(targ_idxs)\n",
    "    print(targ_lens)\n",
    "    break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_emb(word2vec, token2id): \n",
    "    \"\"\" Given word2vec model and the vocab's token2id, extract pretrained word embeddings \"\"\"\n",
    "    pretrained_emb = np.zeros((len(token2id), 300)) \n",
    "    for token in token2id: \n",
    "        try: \n",
    "            pretrained_emb[token2id[token]] = word2vec[token]\n",
    "        except: \n",
    "            pretrained_emb[token2id[token]] = np.random.normal(size=(300,))\n",
    "    return torch.from_numpy(pretrained_emb.astype(np.float32)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, enc_input_dim, enc_embed_dim, enc_hidden_dim, num_layers, pretrained_word2vec): \n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.enc_input_dim = enc_input_dim \n",
    "        self.enc_embed_dim = enc_embed_dim \n",
    "        self.enc_hidden_dim = enc_hidden_dim \n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_word2vec, freeze=True)\n",
    "        self.gru = nn.GRU(input_size=enc_embed_dim, hidden_size=enc_hidden_dim, num_layers=num_layers, \n",
    "                          batch_first=True, bidirectional=True)\n",
    "    \n",
    "    def forward(self, enc_input, enc_input_lens):\n",
    "        batch_size = enc_input.size()[0]\n",
    "        _, idx_sort = torch.sort(enc_input_lens, dim=0, descending=True)\n",
    "        _, idx_unsort = torch.sort(idx_sort, dim=0)\n",
    "        enc_input, enc_input_lens = enc_input.index_select(0, idx_sort), enc_input_lens.index_select(0, idx_sort)\n",
    "        embedded = self.embedding(enc_input)\n",
    "        embedded = torch.nn.utils.rnn.pack_padded_sequence(embedded, enc_input_lens, batch_first=True)\n",
    "        hidden = self.initHidden(batch_size).to(device)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        output, _ = torch.nn.utils.rnn.pad_packed_sequence(output, batch_first=True, \n",
    "                                                           total_length=SRC_MAX_SENTENCE_LEN,\n",
    "                                                           padding_value=RESERVED_TOKENS['<PAD>'])\n",
    "        output = output.index_select(0, idx_unsort)\n",
    "        hidden = hidden.index_select(1, idx_unsort).transpose(0, 1).contiguous().view(self.num_layers, batch_size, -1)\n",
    "#        print(\"now hidden size is {}\".format(hidden.size()))\n",
    "#         final_hidden = torch.cat([output[:, -1, :self.enc_hidden_dim], \n",
    "#                                   output[:, 0, self.enc_hidden_dim:]], dim=1).unsqueeze(0) \n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(2*self.num_layers, batch_size, self.enc_hidden_dim, device=device)\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, dec_input_dim, dec_embed_dim, dec_hidden_dim, enc_hidden_dim, num_layers, pretrained_word2vec):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.dec_input_dim = dec_input_dim\n",
    "        self.dec_embed_dim = dec_embed_dim\n",
    "        self.dec_hidden_dim = dec_hidden_dim \n",
    "        self.enc_hidden_dim = enc_hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_word2vec, freeze=True)\n",
    "        self.gru = nn.GRU(dec_embed_dim + 2 * enc_hidden_dim, dec_hidden_dim, num_layers=num_layers)\n",
    "        self.out = nn.Linear(dec_hidden_dim, dec_input_dim)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, dec_input, dec_hidden, enc_outputs): \n",
    "        batch_size = dec_input.size()[0]\n",
    "        embedded = self.embedding(dec_input).view(1, batch_size, -1)\n",
    "        context = torch.cat([enc_outputs[:, -1, :self.enc_hidden_dim], \n",
    "                             enc_outputs[:, 0, self.enc_hidden_dim:]], dim=1).unsqueeze(0)\n",
    "        concat = torch.cat([embedded, context], 2)\n",
    "        output, hidden = self.gru(concat, dec_hidden)\n",
    "        output = self.softmax(self.out(output[0]))    \n",
    "        return output, hidden\n",
    "        \n",
    "class EncoderDecoder(nn.Module): \n",
    "    def __init__(self, encoder, decoder, decoder_token2id): \n",
    "        super(EncoderDecoder, self).__init__() \n",
    "        self.encoder = encoder \n",
    "        self.decoder = decoder \n",
    "        self.output_dim = self.decoder.dec_input_dim\n",
    "        self.output_seq_len = TARG_MAX_SENTENCE_LEN\n",
    "\n",
    "    def forward(self, src_idx, targ_idx, src_lens, targ_lens, teacher_forcing_ratio): \n",
    "        batch_size = src_idx.size()[0]\n",
    "        enc_outputs, enc_hidden = self.encoder(src_idx, src_lens)\n",
    "        dec_hidden = enc_hidden \n",
    "        dec_outputs = Variable(torch.zeros(self.output_seq_len, batch_size, self.output_dim))\n",
    "        hypotheses = Variable(torch.zeros(self.output_seq_len, batch_size))\n",
    "        dec_output = targ_idx[:, 0] # initialize with <SOS>\n",
    "        for di in range(1, self.output_seq_len): \n",
    "            dec_output, dec_hidden = self.decoder(dec_output, dec_hidden, enc_outputs)\n",
    "            dec_outputs[di] = dec_output \n",
    "            teacher_labels = targ_idx[:, di-1] \n",
    "            greedy_labels = dec_output.data.max(1)[1]\n",
    "            dec_output = teacher_labels if random.random() < teacher_forcing_ratio else greedy_labels \n",
    "            hypotheses[di] = greedy_labels\n",
    "\n",
    "        return dec_outputs, hypotheses.transpose(0,1)\n",
    "    \n",
    "class Attention(nn.Module): \n",
    "    \n",
    "    \"\"\" Implements the attention mechanism by Bahdanau et al. (2015) \"\"\"\n",
    "    \n",
    "    def __init__(self, enc_hidden_dim, dec_hidden_dim, num_annotations, num_layers): \n",
    "        super(Attention, self).__init__() \n",
    "        self.num_annotations = num_annotations\n",
    "        self.input_dim = enc_hidden_dim * 2 + dec_hidden_dim\n",
    "        self.attn = nn.Linear(self.input_dim, self.num_annotations)\n",
    "        self.v = nn.Parameter(torch.rand(self.num_annotations))\n",
    "        self.num_layers = num_layers \n",
    "        nn.init.normal_(self.v)\n",
    "        \n",
    "    def forward(self, encoder_outputs, last_dec_hidden): \n",
    "        batch_size = encoder_outputs.size()[0]\n",
    "        last_dec_hidden = last_dec_hidden.transpose(0, 1)[:, -1, :].unsqueeze(1) \n",
    "#         print(\"encoder_outputs size is {}\".format(encoder_outputs.size()))\n",
    "#        print(\"last_dec_hidden size is {}\".format(last_dec_hidden.size()))\n",
    "        hidden_broadcast = last_dec_hidden.repeat(1, self.num_annotations, 1)\n",
    "#         print(\"hidden_broadcast size is {}\".format(hidden_broadcast.size()))\n",
    "        v_broadcast = self.v.repeat(batch_size, 1, 1)\n",
    "#         print(\"v_broadcast size is {}\".format(v_broadcast.size()))\n",
    "#         print(\"encoder_outputs size is {}, hidden_broadcast size is {}\".format(encoder_outputs.size(), \n",
    "#                                                                                hidden_broadcast.size()))\n",
    "        concat = torch.cat([encoder_outputs, hidden_broadcast], dim=2)\n",
    "#         print(\"concat size is {}\".format(concat.size()))\n",
    "        energies = v_broadcast.bmm(torch.tanh(self.attn(concat)))\n",
    "#         print(\"after attention energies size is {}\".format(energies.size()))\n",
    "        attn_weights = F.softmax(energies, dim=2).squeeze(1)\n",
    "        return attn_weights\n",
    "\n",
    "class DecoderAttnRNN(nn.Module):\n",
    "    def __init__(self, dec_input_dim, dec_embed_dim, dec_hidden_dim, enc_hidden_dim, num_layers, pretrained_word2vec):\n",
    "        super(DecoderAttnRNN, self).__init__()\n",
    "        self.dec_input_dim = dec_input_dim\n",
    "        self.dec_embed_dim = dec_embed_dim\n",
    "        self.dec_hidden_dim = dec_hidden_dim \n",
    "        self.enc_hidden_dim = enc_hidden_dim\n",
    "        self.num_layers = num_layers \n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_word2vec, freeze=True)\n",
    "        self.attn = Attention(enc_hidden_dim, dec_hidden_dim, num_annotations=SRC_MAX_SENTENCE_LEN, num_layers=num_layers)\n",
    "        self.gru = nn.GRU(dec_embed_dim + 2 * enc_hidden_dim, dec_hidden_dim, num_layers=num_layers)\n",
    "        self.out = nn.Linear(dec_hidden_dim, dec_input_dim)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, dec_input, dec_hidden, enc_outputs): \n",
    "        batch_size = dec_input.size()[0]\n",
    "        \n",
    "        embedded = self.embedding(dec_input).view(1, batch_size, -1)\n",
    "#        print(\"embedded size is {}\".format(embedded.size()))\n",
    "        attn_weights = self.attn(encoder_outputs=enc_outputs, last_dec_hidden=dec_hidden).unsqueeze(1)\n",
    "#         print(\"enc_outputs size is {}\".format(enc_outputs.size()))\n",
    "#         print(\"last_dec_hidden size is {}\".format(dec_hidden.size()))\n",
    "#         print(\"attn_weights size is {}\".format(attn_weights.size()))\n",
    "        context = attn_weights.bmm(enc_outputs).transpose(0, 1)\n",
    "#        print(\"context size is {}\".format(context.size()))\n",
    "#         context = torch.cat([enc_outputs[:, -1, :self.enc_hidden_dim], \n",
    "#                              enc_outputs[:, 0, self.enc_hidden_dim:]], dim=1).unsqueeze(0)\n",
    "        concat = torch.cat([embedded, context], 2)\n",
    "#         print(\"concat size is {}\".format(concat.size()))\n",
    "#         print(\"dec_hidden is {}\".format(dec_hidden.size()))\n",
    "        output, hidden = self.gru(concat, dec_hidden)\n",
    "        output = self.softmax(self.out(output[0]))    \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor2corpus(tensor, id2token): \n",
    "    \"\"\" Takes a tensor (num_sentences x max_sentence_length) representing the corpus, \n",
    "        returns its string equivalent \n",
    "    \"\"\"\n",
    "    tensor = tensor.view(-1)\n",
    "    ignored_idx = [RESERVED_TOKENS[token] for token in ['<SOS>', '<EOS>', '<PAD>']] \n",
    "    filtered_list = [id2token[idx] for idx in tensor.numpy().astype(int).tolist() if idx not in ignored_idx] \n",
    "    corpus = ' '.join(filtered_list)\n",
    "    return corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, id2token): \n",
    "    \"\"\" \n",
    "    Helper function that tests the model's performance on a given dataset \n",
    "    @param: loader = data loader for the dataset to test against \n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval() \n",
    "    criterion = nn.NLLLoss()\n",
    "    total_loss = 0 \n",
    "    reference_corpus = []\n",
    "    hypothesis_corpus = [] \n",
    "    \n",
    "    for i, (src_idxs, targ_idxs, src_lens, targ_lens) in enumerate(loader): \n",
    "        batch_size = src_idxs.size()[0]\n",
    "        outputs, hypotheses = model(src_idxs, targ_idxs, src_lens, targ_lens, teacher_forcing_ratio=0.0)\n",
    "        outputs = outputs[1:].view(-1, TARG_VOCAB_SIZE)\n",
    "        targets = targ_idxs[:,1:]\n",
    "        hypothesis_corpus.append(hypotheses)\n",
    "        reference_corpus.append(targets)\n",
    " \n",
    "        loss = F.nll_loss(outputs.view(-1, TARG_VOCAB_SIZE), targets.contiguous().view(-1), \n",
    "                          ignore_index=RESERVED_TOKENS['<PAD>'])\n",
    "        total_loss += loss.item()  \n",
    "\n",
    "    # reconstruct corpus and compute bleu score \n",
    "    hypothesis_corpus = torch.cat(hypothesis_corpus, dim=0) \n",
    "    reference_corpus = torch.cat(reference_corpus, dim=0)\n",
    "    hypothesis_corpus = tensor2corpus(hypothesis_corpus, id2token)\n",
    "    reference_corpus = tensor2corpus(reference_corpus, id2token)\n",
    "    bleu_score = sacrebleu.corpus_bleu(hypothesis_corpus, reference_corpus).score\n",
    "    \n",
    "    return total_loss / len(loader), bleu_score, hypothesis_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, dev_loader, id2token, learning_rate, num_epochs, \n",
    "          print_intermediate=True, save_checkpoint=False, model_name='default'): \n",
    "    \n",
    "    # initialize optimizer and criterion \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss(ignore_index=RESERVED_TOKENS['<PAD>'])\n",
    "    results = [] \n",
    "    \n",
    "    # loop through train data in batches and train \n",
    "    for epoch in range(num_epochs): \n",
    "        train_loss = 0 \n",
    "        for batch, (src_idxs, targ_idxs, src_lens, targ_lens) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            final_outputs, hypotheses = model(src_idxs, targ_idxs, src_lens, targ_lens, teacher_forcing_ratio=0.5) \n",
    "            loss = criterion(final_outputs[1:].view(-1, TARG_VOCAB_SIZE), targ_idxs[:,1:].contiguous().view(-1))\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch % 100 == 0 or ((epoch==num_epochs-1) & (batch==len(train_loader)-1)):\n",
    "                result = {} \n",
    "                result['epoch'] = epoch + batch / len(train_loader)\n",
    "#                result['train_loss'], result['train_bleu'], train_hypotheses = 0, 0, None\n",
    "                result['train_loss'], result['train_bleu'], train_hypotheses = evaluate(model, train_loader, id2token) \n",
    "                result['val_loss'], result['val_bleu'], val_hypotheses = evaluate(model, dev_loader, id2token)\n",
    "                results.append(result)\n",
    "                \n",
    "                if print_intermediate: \n",
    "                    print('Epoch: {:.2f}, Train Loss: {:.2f}, Val Loss: {:.2f}, Train BLEU: {:.2f}, Val BLEU: {:.2f}'\\\n",
    "                          .format(result['epoch'], result['train_loss'], result['val_loss'], \n",
    "                                  result['train_bleu'], result['val_bleu']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions to save results to and load results from a pkl logfile \n",
    "\n",
    "RESULTS_LOG = 'experiment_results/experiment_results_log.pkl'\n",
    "\n",
    "def append_to_log(hyperparams, results, runtime, experiment_name, dt_created, filename=RESULTS_LOG): \n",
    "    \"\"\" Appends results and details of a single experiment to a log file \"\"\"\n",
    "    \n",
    "    # create directory if doesn't already exist \n",
    "    if not os.path.exists(os.path.dirname(filename)):\n",
    "        os.makedirs(os.path.dirname(filename))\n",
    "        \n",
    "    # store experiment details in a dictionary \n",
    "    new_result = {'experiment_name': experiment_name, 'hyperparams': hyperparams, 'results': results, \n",
    "                  'runtime': runtime, 'dt_created': dt_created}\n",
    "    \n",
    "    # if log already exists, append to log \n",
    "    try: \n",
    "        results_log = pkl.load(open(filename, \"rb\"))\n",
    "        results_log.append(new_result)\n",
    "\n",
    "    # if log doesn't exists, initialize first result as the log \n",
    "    except (OSError, IOError) as e:\n",
    "        results_log = [new_result]\n",
    "    \n",
    "    # save to pickle \n",
    "    pkl.dump(results_log, open(filename, \"wb\"))\n",
    "\n",
    "# def append_to_log(hyperparams, results, runtime, experiment_name, filename=RESULTS_LOG): \n",
    "#     \"\"\" Appends results and details of a single experiment to a log file \"\"\"\n",
    "    \n",
    "#     # create directory if doesn't already exist \n",
    "#     if not os.path.exists(os.path.dirname(filename)):\n",
    "#         os.makedirs(os.path.dirname(filename))\n",
    "        \n",
    "#     # store experiment details in a dictionary \n",
    "#     new_result = {'experiment_name': experiment_name, 'hyperparams': hyperparams, 'results': results, \n",
    "#                   'runtime': runtime, 'dt_created': datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "    \n",
    "#     # if log already exists, append to log \n",
    "#     try: \n",
    "#         results_log = pkl.load(open(filename, \"rb\"))\n",
    "#         results_log.append(new_result)\n",
    "\n",
    "#     # if log doesn't exists, initialize first result as the log \n",
    "#     except (OSError, IOError) as e:\n",
    "#         results_log = [new_result]\n",
    "    \n",
    "#     # save to pickle \n",
    "#     pkl.dump(results_log, open(filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_experiment_log(experiment_name=None, filename=RESULTS_LOG): \n",
    "    \"\"\" Loads experiment log, with option to filter for a specific experiment_name \"\"\"\n",
    "    \n",
    "    results_log = pkl.load(open(filename, \"rb\"))\n",
    "    \n",
    "    if experiment_name is not None: \n",
    "        results_log = [r for r in results_log if r['experiment_name'] == experiment_name]\n",
    "        \n",
    "    return results_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(model, train_loader, dev_loader, id2token, learning_rate, num_epochs, \n",
    "                   print_intermediate=True, save_checkpoint=False, model_name='NA'): \n",
    "    \n",
    "    # initialize optimizer and criterion \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss(ignore_index=RESERVED_TOKENS['<PAD>'])\n",
    "    results = [] \n",
    "    \n",
    "    # loop through train data in batches and train \n",
    "    for epoch in range(num_epochs): \n",
    "        train_loss = 0 \n",
    "        for batch, (src_idxs, targ_idxs, src_lens, targ_lens) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            final_outputs, hypotheses = model(src_idxs, targ_idxs, src_lens, targ_lens, teacher_forcing_ratio=0.5) \n",
    "            loss = criterion(final_outputs[1:].view(-1, TARG_VOCAB_SIZE), targ_idxs[:,1:].contiguous().view(-1))\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch % 100 == 0 or ((epoch==num_epochs-1) & (batch==len(train_loader)-1)):\n",
    "                result = {} \n",
    "                result['epoch'] = epoch + batch / len(train_loader)\n",
    "#                result['train_loss'], result['train_bleu'], train_hypotheses = 0, 0, None\n",
    "                result['train_loss'], result['train_bleu'], train_hypotheses = evaluate(model, train_loader, id2token) \n",
    "                result['val_loss'], result['val_bleu'], val_hypotheses = evaluate(model, dev_loader, id2token)\n",
    "                results.append(result)\n",
    "                \n",
    "                if print_intermediate: \n",
    "                    print('Epoch: {:.2f}, Train Loss: {:.2f}, Val Loss: {:.2f}, Train BLEU: {:.2f}, Val BLEU: {:.2f}'\\\n",
    "                          .format(result['epoch'], result['train_loss'], result['val_loss'], \n",
    "                                  result['train_bleu'], result['val_bleu']))\n",
    "                    \n",
    "                if save_checkpoint: #TODO: handle creation of directory if not exist \n",
    "                    if result['val_loss'] == pd.DataFrame.from_dict(results)['val_loss'].min(): \n",
    "                        checkpoint_fp = 'model_checkpoints/{}.pth.tar'.format(model_name)\n",
    "                        torch.save(model.state_dict(), checkpoint_fp)\n",
    "                \n",
    "    return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(train_loader, dev_loader, model_type, num_epochs=10, learning_rate=0.0005, num_layers=2,\n",
    "                   enc_hidden_dim=300, dec_hidden_dim=2*300, experiment_name='NA', model_name='NA',\n",
    "                   save_to_log=True, save_checkpoint=False, print_summary=True, print_intermediate=True):  \n",
    "    \n",
    "    \"\"\" Wraps all processing, training and evaluation steps in a function to facilitate hyperparam tuning. \n",
    "        Note that the function takes as input tokenized data rather than raw data since there's significant \n",
    "        lag time in generating tokens.  \n",
    "    \"\"\"\n",
    "    \n",
    "    start_time = time.time() \n",
    "    \n",
    "    # TODO: try dropout and optimization algorithms. for now use as default: \n",
    "    optimizer = 'Adam' \n",
    "    enc_dropout = 0 \n",
    "    dec_dropout = 0 \n",
    "    \n",
    "    # instantiate model and optimizer \n",
    "    if model_type == 'without_attention': \n",
    "        encoder = EncoderRNN(enc_input_dim=SRC_VOCAB_SIZE, enc_embed_dim=ENC_EMBED_DIM, enc_hidden_dim=enc_hidden_dim, \n",
    "                             num_layers=num_layers, pretrained_word2vec=get_pretrained_emb(\n",
    "                                 data['train']['source']['word2vec'], data['train']['source']['token2id']))\n",
    "        decoder = DecoderRNN(dec_input_dim=TARG_VOCAB_SIZE, dec_embed_dim=DEC_EMBED_DIM, dec_hidden_dim=dec_hidden_dim, \n",
    "                             enc_hidden_dim=enc_hidden_dim, num_layers=num_layers, \n",
    "                             pretrained_word2vec=get_pretrained_emb(data['train']['target']['word2vec'], \n",
    "                                                                    data['train']['target']['token2id']))\n",
    "        model = EncoderDecoder(encoder, decoder, data['train']['target']['token2id'])\n",
    "        \n",
    "    elif model_type == 'attention_bahdanau': \n",
    "        encoder = EncoderRNN(enc_input_dim=SRC_VOCAB_SIZE, enc_embed_dim=ENC_EMBED_DIM, enc_hidden_dim=enc_hidden_dim, \n",
    "                             num_layers=num_layers, pretrained_word2vec=get_pretrained_emb(\n",
    "                                 data['train']['source']['word2vec'], data['train']['source']['token2id']))\n",
    "        decoder = DecoderAttnRNN(dec_input_dim=TARG_VOCAB_SIZE, dec_embed_dim=DEC_EMBED_DIM, \n",
    "                                 dec_hidden_dim=dec_hidden_dim, enc_hidden_dim=enc_hidden_dim, num_layers=num_layers, \n",
    "                                 pretrained_word2vec=get_pretrained_emb(data['train']['target']['word2vec'], \n",
    "                                                                        data['train']['target']['token2id']))\n",
    "        model = EncoderDecoder(encoder, decoder, data['train']['target']['token2id'])\n",
    "        \n",
    "    else: \n",
    "        raise ValueError(\"Invalid model_type. Must be either 'without_attention' or 'attention_bahdanau'\")\n",
    "        \n",
    "    # train and evaluate \n",
    "    results = train_and_eval(model, train_loader, dev_loader, id2token=data['train']['target']['id2token'], \n",
    "                             num_epochs=num_epochs, learning_rate=learning_rate, \n",
    "                             print_intermediate=print_intermediate, save_checkpoint=save_checkpoint)\n",
    "    \n",
    "    # store, print, and save results \n",
    "    runtime = (time.time() - start_time) / 60 \n",
    "    dt_created = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    hyperparams = {'model_type': model_type, 'num_epochs': num_epochs, 'learning_rate': learning_rate, \n",
    "                   'enc_hidden_dim': enc_hidden_dim, 'dec_hidden_dim': dec_hidden_dim, 'num_layers': num_layers, \n",
    "                   'enc_embed_dim': ENC_EMBED_DIM,  'dec_embed_dim': DEC_EMBED_DIM, \n",
    "                   'optimizer': optimizer, 'enc_dropout': enc_dropout, 'dec_dropout': dec_dropout, \n",
    "                   'batch_size': BATCH_SIZE, 'src_lang': SRC_LANG, 'targ_lang': TARG_LANG, \n",
    "                   'src_vocab_size': SRC_VOCAB_SIZE, 'targ_vocab_size': TARG_VOCAB_SIZE, \n",
    "                   'src_max_sentence_len': SRC_MAX_SENTENCE_LEN, 'targ_max_sentence_len': TARG_MAX_SENTENCE_LEN}  \n",
    "        \n",
    "    if save_to_log: \n",
    "        append_to_log(hyperparams, results, runtime, experiment_name, dt_created)\n",
    "    if print_summary: \n",
    "        print(\"Experiment completed in {} minutes with {:.2f} validation loss and {:.2f} validation BLEU.\".format(\n",
    "            int(runtime), pd.DataFrame.from_dict(results)['val_loss'].min(), \n",
    "            pd.DataFrame.from_dict(results)['val_bleu'].max()))\n",
    "        \n",
    "    return results, hyperparams, runtime, model, train_loader, dev_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper methods to summarize, evaluate, and plot results \n",
    "\n",
    "def summarize_results(results_log): \n",
    "    \"\"\" Summarizes results_log (list) into a dataframe, splitting hyperparameters string into columns, and reducing \n",
    "        the val_acc dict into the best validation accuracy obtained amongst all the epochs logged \"\"\"\n",
    "    results_df = pd.DataFrame.from_dict(results_log)\n",
    "    results_df = pd.concat([results_df, results_df['hyperparams'].apply(pd.Series)], axis=1)\n",
    "    results_df['val_loss'] = results_df['results'].apply(lambda d: pd.DataFrame.from_dict(d)['val_loss'].min())\n",
    "    return results_df.sort_values(by='val_loss', ascending=True) \n",
    "\n",
    "def plot_multiple_learning_curves(results_df, plot_variable, figsize=(8, 5), legend_loc='best'):\n",
    "    \"\"\" Plots learning curves of MULTIPLE experiments, includes only validation accuracy \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    for index, row in results_df.iterrows():\n",
    "        val_loss_hist = pd.DataFrame.from_dict(row['results']).set_index('epoch')['val_loss'] \n",
    "        plt.plot(val_loss_hist, label=\"{} ({}%)\".format(row[plot_variable], val_loss_hist.max()))\n",
    "    plt.legend(title=plot_variable, loc=legend_loc)    \n",
    "    plt.ylabel('Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "\n",
    "def plot_single_learning_curve(results, figsize=(8, 5)): \n",
    "    \"\"\" Plots learning curve of a SINGLE experiment, includes both train and validation accuracy \"\"\"\n",
    "    results_df = pd.DataFrame.from_dict(results)\n",
    "    results_df = results_df.set_index('epoch')\n",
    "    results_df.plot(figsize=figsize)\n",
    "    plt.ylabel('Validation Lossy')\n",
    "    plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to count parameters \n",
    "def count_parameters(model): \n",
    "    all_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return all_params, trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.00, Train Loss: 6.44, Val Loss: 6.27, Train BLEU: 3.93, Val BLEU: 4.96\n",
      "Epoch: 1.00, Train Loss: 4.90, Val Loss: 4.59, Train BLEU: 3.89, Val BLEU: 4.94\n",
      "Epoch: 1.98, Train Loss: 4.87, Val Loss: 4.56, Train BLEU: 3.89, Val BLEU: 4.94\n",
      "Experiment completed in 6 minutes with 4.56 validation loss and 4.96 validation BLEU.\n"
     ]
    }
   ],
   "source": [
    "results, hyperparams, runtime, model, train_loader, dev_loader = \\\n",
    "    run_experiment(train_loader, dev_loader, model_type='attention_bahdanau', num_epochs=2, learning_rate=0.0005, \n",
    "               num_layers=2, enc_hidden_dim=300, dec_hidden_dim=2*300, experiment_name='test_run', model_name='test_run',\n",
    "               save_to_log=True, save_checkpoint=True, print_summary=True, print_intermediate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt_created</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>hyperparams</th>\n",
       "      <th>results</th>\n",
       "      <th>runtime</th>\n",
       "      <th>model_type</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>enc_hidden_dim</th>\n",
       "      <th>dec_hidden_dim</th>\n",
       "      <th>...</th>\n",
       "      <th>enc_dropout</th>\n",
       "      <th>dec_dropout</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>src_lang</th>\n",
       "      <th>targ_lang</th>\n",
       "      <th>src_vocab_size</th>\n",
       "      <th>targ_vocab_size</th>\n",
       "      <th>src_max_sentence_len</th>\n",
       "      <th>targ_max_sentence_len</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-25 02:38:58</td>\n",
       "      <td>test_run</td>\n",
       "      <td>{'model_type': 'attention_bahdanau', 'num_epochs': 2, 'learning_rate': 0.0005, 'enc_hidden_dim':...</td>\n",
       "      <td>[{'epoch': 0.0, 'train_loss': 6.49982488155365, 'train_bleu': 4.887123794512932, 'val_loss': 6.3...</td>\n",
       "      <td>6.441831</td>\n",
       "      <td>attention_bahdanau</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>zh</td>\n",
       "      <td>en</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>4.553896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-25 02:27:18</td>\n",
       "      <td>test_run</td>\n",
       "      <td>{'model_type': 'attention_bahdanau', 'num_epochs': 2, 'learning_rate': 0.0005, 'enc_hidden_dim':...</td>\n",
       "      <td>[{'epoch': 0.0, 'train_loss': 6.59386328458786, 'train_bleu': 4.278570546021468, 'val_loss': 6.5...</td>\n",
       "      <td>6.343195</td>\n",
       "      <td>attention_bahdanau</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>zh</td>\n",
       "      <td>en</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>4.557455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            dt_created experiment_name  \\\n",
       "1  2018-11-25 02:38:58        test_run   \n",
       "0  2018-11-25 02:27:18        test_run   \n",
       "\n",
       "                                                                                           hyperparams  \\\n",
       "1  {'model_type': 'attention_bahdanau', 'num_epochs': 2, 'learning_rate': 0.0005, 'enc_hidden_dim':...   \n",
       "0  {'model_type': 'attention_bahdanau', 'num_epochs': 2, 'learning_rate': 0.0005, 'enc_hidden_dim':...   \n",
       "\n",
       "                                                                                               results  \\\n",
       "1  [{'epoch': 0.0, 'train_loss': 6.49982488155365, 'train_bleu': 4.887123794512932, 'val_loss': 6.3...   \n",
       "0  [{'epoch': 0.0, 'train_loss': 6.59386328458786, 'train_bleu': 4.278570546021468, 'val_loss': 6.5...   \n",
       "\n",
       "    runtime          model_type  num_epochs  learning_rate  enc_hidden_dim  \\\n",
       "1  6.441831  attention_bahdanau           2         0.0005             300   \n",
       "0  6.343195  attention_bahdanau           2         0.0005             300   \n",
       "\n",
       "   dec_hidden_dim    ...     enc_dropout  dec_dropout  batch_size src_lang  \\\n",
       "1             600    ...               0            0          32       zh   \n",
       "0             600    ...               0            0          32       zh   \n",
       "\n",
       "   targ_lang  src_vocab_size  targ_vocab_size src_max_sentence_len  \\\n",
       "1         en            1000             1000                   40   \n",
       "0         en            1000             1000                   40   \n",
       "\n",
       "  targ_max_sentence_len  val_loss  \n",
       "1                    40  4.553896  \n",
       "0                    40  4.557455  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results = summarize_results(load_experiment_log(experiment_name='test_run', filename=RESULTS_LOG))\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Split BLEU and Loss \n",
    "plot_single_learning_curve(all_results.iloc[1]['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.00, Train Loss: 6.65, Val Loss: 6.53, Train BLEU: 4.48, Val BLEU: 5.46\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-179-28065489e1d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#model = EncoderDecoder(encoder, decoder, data['train']['target']['token2id'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoderDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_attn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token2id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id2token'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-154-2b4fa4c08273>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, dev_loader, id2token, learning_rate, num_epochs, print_intermediate, save_checkpoint, model_name)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mfinal_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypotheses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTARG_VOCAB_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg_idxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/nlpclass/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/nlpclass/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "encoder = EncoderRNN(enc_input_dim=SRC_VOCAB_SIZE, enc_embed_dim=300, enc_hidden_dim=300, num_layers=2, \n",
    "                     pretrained_word2vec=get_pretrained_emb(data['train']['source']['word2vec'],\n",
    "                                                            data['train']['source']['token2id']))\n",
    "\n",
    "decoder = DecoderRNN(dec_input_dim=TARG_VOCAB_SIZE, dec_embed_dim=300, dec_hidden_dim=2*300, \n",
    "                     enc_hidden_dim=300, num_layers=2, \n",
    "                     pretrained_word2vec=get_pretrained_emb(data['train']['target']['word2vec'], \n",
    "                                                            data['train']['target']['token2id']))\n",
    "\n",
    "decoder_attn = DecoderAttnRNN(dec_input_dim=TARG_VOCAB_SIZE, dec_embed_dim=300, dec_hidden_dim=2*300, \n",
    "                              enc_hidden_dim=300, num_layers=2, \n",
    "                              pretrained_word2vec=get_pretrained_emb(data['train']['target']['word2vec'], \n",
    "                                                                     data['train']['target']['token2id']))\n",
    "\n",
    "#model = EncoderDecoder(encoder, decoder, data['train']['target']['token2id'])\n",
    "model = EncoderDecoder(encoder, decoder_attn, data['train']['target']['token2id'])\n",
    "train(model, train_loader, dev_loader, data['train']['target']['id2token'], num_epochs=20, learning_rate=0.0005) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden shape is torch.Size([2, 32, 300])\n",
      "output shape is torch.Size([32, 40, 600])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "index out of range at /Users/soumith/miniconda2/conda-bld/pytorch_1532623076075/work/aten/src/TH/generic/THTensorMath.cpp:352",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-528dc9d76ff9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg_lens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0menc_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_final_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menc_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dec_hidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menc_final_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"attn weights are: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/nlpclass/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-450d2c609a4e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, enc_input, enc_input_lens)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hidden shape is {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output shape is {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_unsort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_unsort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         final_hidden = torch.cat([output[:, -1, :self.enc_hidden_dim], \n",
      "\u001b[0;31mRuntimeError\u001b[0m: index out of range at /Users/soumith/miniconda2/conda-bld/pytorch_1532623076075/work/aten/src/TH/generic/THTensorMath.cpp:352"
     ]
    }
   ],
   "source": [
    "encoder = EncoderRNN(enc_input_dim=SRC_VOCAB_SIZE, enc_embed_dim=300, enc_hidden_dim=300, \n",
    "                     pretrained_word2vec=get_pretrained_emb(data['train']['source']['word2vec'],\n",
    "                                                            data['train']['source']['token2id']))\n",
    "attention = Attention(enc_hidden_dim=300, dec_hidden_dim=600, num_annotations=SRC_MAX_SENTENCE_LEN)\n",
    "\n",
    "for i, (src_idxs, targ_idxs, src_lens, targ_lens) in enumerate(train_loader): \n",
    "    enc_outputs, enc_final_hidden = encoder(src_idxs, src_lens)\n",
    "    attn_weights = attention(encoder_outputs=enc_outputs, last_dec_hidden=enc_final_hidden)\n",
    "    print(\"attn weights are: {}\".format(attn_weights.size()))\n",
    "    print(\"example: {}\".format(attn_weights[0].sum()))\n",
    "#     print(\"enc_outputs size is {}\".format(enc_outputs.size()))\n",
    "#     print(\"enc_final_hidden size is {}\".format(enc_final_hidden.size()))\n",
    "    \n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
