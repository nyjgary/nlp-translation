{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from data_processing import generate_vocab, process_data, create_dataloaders \n",
    "from model import get_pretrained_emb, EncoderDecoder, EncoderRNN, DecoderRNN, EncoderDecoderAttn, DecoderAttnRNN\n",
    "from train_eval import count_parameters, summarize_results, plot_single_learning_curve, load_experiment_log\n",
    "from train_eval import train_and_eval\n",
    "import importlib\n",
    "import pickle as pkl \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model identification\n",
    "MODEL_NAME = 'zh-seq2seq-rnn-attn'\n",
    "SRC_LANG = 'zh'\n",
    "TARG_LANG = 'en'\n",
    "\n",
    "# data processing params  \n",
    "SRC_MAX_SENTENCE_LEN = 20\n",
    "TARG_MAX_SENTENCE_LEN = 20\n",
    "SRC_VOCAB_SIZE = 30000 #30000\n",
    "TARG_VOCAB_SIZE = 30000 #30000\n",
    "\n",
    "# model architecture params \n",
    "RNN_CELL_TYPE = 'gru'\n",
    "NUM_LAYERS = 2 #2 \n",
    "ENC_HIDDEN_DIM = 256 #512\n",
    "DEC_HIDDEN_DIM = 2 * ENC_HIDDEN_DIM #2 * ENC_HIDDEN_DIM \n",
    "TEACHER_FORCING_RATIO = 1\n",
    "CLIP_GRAD_MAX_NORM = 1\n",
    "ENC_DROPOUT = 0.2 # to actually implement\n",
    "DEC_DROPOUT = 0.2 # to actually implement\n",
    "USE_ATTN = False\n",
    "\n",
    "# training params  \n",
    "BATCH_SIZE = 64 #32\n",
    "NUM_EPOCHS = 20\n",
    "LR = 0.0003 # 0.0005\n",
    "OPTIMIZER = 'Adam'\n",
    "LAZY_TRAIN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store as dict to save to results later \n",
    "params = {'model_name': MODEL_NAME, 'src_lang': SRC_LANG, 'targ_lang': TARG_LANG, 'rnn_cell_type': RNN_CELL_TYPE, \n",
    "          'src_max_sentence_len': SRC_MAX_SENTENCE_LEN, 'targ_max_sentence_len': TARG_MAX_SENTENCE_LEN, \n",
    "          'src_vocab_size': SRC_VOCAB_SIZE, 'targ_vocab_size': TARG_VOCAB_SIZE, \n",
    "          'num_layers': NUM_LAYERS, 'enc_hidden_dim': ENC_HIDDEN_DIM, 'dec_hidden_dim': DEC_HIDDEN_DIM,\n",
    "          'teacher_forcing_ratio': TEACHER_FORCING_RATIO, 'clip_grad_max_norm': CLIP_GRAD_MAX_NORM,\n",
    "          'enc_dropout': ENC_DROPOUT, 'dec_dropout': DEC_DROPOUT, 'use_attn': USE_ATTN, \n",
    "          'batch_size': BATCH_SIZE, 'num_epochs': NUM_EPOCHS, 'learning_rate': LR, 'optimizer': OPTIMIZER, \n",
    "          'lazy_train': LAZY_TRAIN} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # takes a long time to process, save to pickle for reimport in future \n",
    "# vocab = generate_vocab(SRC_LANG, TARG_LANG, SRC_VOCAB_SIZE, TARG_VOCAB_SIZE)\n",
    "# vocab_filename = \"{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n",
    "# pkl.dump(vocab, open(vocab_filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload from pickle \n",
    "vocab_filename = \"{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n",
    "vocab = pkl.load(open(vocab_filename, \"rb\"))\n",
    "data = process_data(SRC_LANG, TARG_LANG, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, vocab)\n",
    "data_minibatch = process_data(SRC_LANG, TARG_LANG, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, vocab, sample_limit=BATCH_SIZE) \n",
    "data_minitrain = process_data(SRC_LANG, TARG_LANG, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, vocab, sample_limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders \n",
    "loaders_full = create_dataloaders(data, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)\n",
    "loaders_minibatch = create_dataloaders(data_minibatch, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)\n",
    "loaders_minitrain = create_dataloaders(data_minitrain, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model \n",
    "\n",
    "encoder = EncoderRNN(rnn_cell_type=RNN_CELL_TYPE, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, \n",
    "                     src_max_sentence_len=SRC_MAX_SENTENCE_LEN, enc_dropout=ENC_DROPOUT, \n",
    "                     pretrained_word2vec=get_pretrained_emb(vocab[SRC_LANG]['word2vec'], vocab[SRC_LANG]['token2id']))\n",
    "\n",
    "# without attention \n",
    "# decoder = DecoderRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS,\n",
    "#                      targ_vocab_size=TARG_VOCAB_SIZE, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "#                      pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "# model = EncoderDecoder(encoder, decoder, vocab[TARG_LANG]['token2id'])\n",
    "\n",
    "# with attention \n",
    "decoder = DecoderAttnRNN(rnn_cell_type=RNN_CELL_TYPE, dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, \n",
    "                         num_layers=NUM_LAYERS, targ_vocab_size=TARG_VOCAB_SIZE, src_max_sentence_len=SRC_MAX_SENTENCE_LEN, \n",
    "                         targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, dec_dropout=DEC_DROPOUT, \n",
    "                         pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "model = EncoderDecoderAttn(encoder, decoder, vocab[TARG_LANG]['token2id']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.00, Train Loss: 0.00, Val Loss: 10.23, Train BLEU: 0.00, Val BLEU: 0.07, Minutes Elapsed: 0.17\n",
      "Sampling from val predictions...\n",
      "Source: 超过 70 的 家庭 家庭暴力 暴力 谋杀 发生 生在 受害 受害者 结束 这段 关系 后 在 她 离开 之后 因为\n",
      "Reference: over 70 percent of domestic violence murders happen after the victim has ended the relationship , after she &apos;s\n",
      "Model: <SOS> soaring soaring soaring the the sleeper <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0409, 0.0424, 0.0447, 0.0474, 0.0460, 0.0486, 0.0511, 0.0518, 0.0488,\n",
      "         0.0495, 0.0511, 0.0521, 0.0505, 0.0494, 0.0515, 0.0537, 0.0556, 0.0557,\n",
      "         0.0550, 0.0544],\n",
      "        [0.0409, 0.0424, 0.0447, 0.0474, 0.0459, 0.0485, 0.0511, 0.0518, 0.0488,\n",
      "         0.0495, 0.0511, 0.0521, 0.0505, 0.0494, 0.0515, 0.0537, 0.0556, 0.0557,\n",
      "         0.0550, 0.0544],\n",
      "        [0.0409, 0.0424, 0.0447, 0.0474, 0.0459, 0.0485, 0.0511, 0.0518, 0.0488,\n",
      "         0.0495, 0.0510, 0.0521, 0.0505, 0.0494, 0.0515, 0.0537, 0.0556, 0.0557,\n",
      "         0.0550, 0.0544],\n",
      "        [0.0409, 0.0424, 0.0447, 0.0474, 0.0459, 0.0485, 0.0511, 0.0518, 0.0488,\n",
      "         0.0495, 0.0511, 0.0521, 0.0505, 0.0494, 0.0515, 0.0537, 0.0556, 0.0557,\n",
      "         0.0550, 0.0544],\n",
      "        [0.0409, 0.0424, 0.0447, 0.0474, 0.0459, 0.0485, 0.0511, 0.0518, 0.0488,\n",
      "         0.0495, 0.0511, 0.0521, 0.0505, 0.0494, 0.0515, 0.0537, 0.0556, 0.0557,\n",
      "         0.0550, 0.0544],\n",
      "        [0.0409, 0.0424, 0.0447, 0.0474, 0.0459, 0.0485, 0.0511, 0.0518, 0.0488,\n",
      "         0.0495, 0.0511, 0.0521, 0.0505, 0.0493, 0.0514, 0.0537, 0.0556, 0.0557,\n",
      "         0.0550, 0.0545],\n",
      "        [0.0409, 0.0424, 0.0447, 0.0475, 0.0459, 0.0485, 0.0510, 0.0518, 0.0488,\n",
      "         0.0495, 0.0511, 0.0521, 0.0505, 0.0493, 0.0514, 0.0537, 0.0556, 0.0558,\n",
      "         0.0550, 0.0545],\n",
      "        [0.0409, 0.0424, 0.0447, 0.0475, 0.0459, 0.0485, 0.0510, 0.0517, 0.0488,\n",
      "         0.0495, 0.0511, 0.0521, 0.0505, 0.0493, 0.0514, 0.0537, 0.0556, 0.0558,\n",
      "         0.0550, 0.0545],\n",
      "        [0.0409, 0.0425, 0.0447, 0.0475, 0.0459, 0.0485, 0.0510, 0.0517, 0.0488,\n",
      "         0.0495, 0.0511, 0.0521, 0.0505, 0.0493, 0.0514, 0.0537, 0.0556, 0.0558,\n",
      "         0.0550, 0.0545],\n",
      "        [0.0409, 0.0425, 0.0447, 0.0475, 0.0459, 0.0485, 0.0510, 0.0517, 0.0488,\n",
      "         0.0495, 0.0511, 0.0521, 0.0505, 0.0493, 0.0514, 0.0537, 0.0556, 0.0558,\n",
      "         0.0550, 0.0545],\n",
      "        [0.0409, 0.0425, 0.0447, 0.0475, 0.0459, 0.0485, 0.0510, 0.0517, 0.0488,\n",
      "         0.0495, 0.0511, 0.0521, 0.0505, 0.0493, 0.0514, 0.0537, 0.0556, 0.0558,\n",
      "         0.0550, 0.0545],\n",
      "        [0.0409, 0.0425, 0.0447, 0.0475, 0.0459, 0.0485, 0.0510, 0.0517, 0.0488,\n",
      "         0.0495, 0.0511, 0.0521, 0.0505, 0.0493, 0.0514, 0.0537, 0.0556, 0.0558,\n",
      "         0.0550, 0.0545],\n",
      "        [0.0409, 0.0425, 0.0447, 0.0475, 0.0459, 0.0485, 0.0510, 0.0517, 0.0488,\n",
      "         0.0495, 0.0511, 0.0521, 0.0505, 0.0493, 0.0514, 0.0537, 0.0556, 0.0558,\n",
      "         0.0550, 0.0545],\n",
      "        [0.0409, 0.0425, 0.0447, 0.0475, 0.0459, 0.0485, 0.0510, 0.0517, 0.0488,\n",
      "         0.0495, 0.0511, 0.0521, 0.0505, 0.0493, 0.0514, 0.0537, 0.0556, 0.0558,\n",
      "         0.0550, 0.0545],\n",
      "        [0.0409, 0.0425, 0.0447, 0.0475, 0.0459, 0.0485, 0.0510, 0.0517, 0.0488,\n",
      "         0.0495, 0.0511, 0.0521, 0.0505, 0.0493, 0.0514, 0.0537, 0.0556, 0.0558,\n",
      "         0.0550, 0.0545],\n",
      "        [0.0410, 0.0425, 0.0447, 0.0475, 0.0459, 0.0485, 0.0510, 0.0517, 0.0488,\n",
      "         0.0495, 0.0511, 0.0521, 0.0505, 0.0493, 0.0514, 0.0537, 0.0556, 0.0558,\n",
      "         0.0550, 0.0545],\n",
      "        [0.0410, 0.0425, 0.0447, 0.0475, 0.0459, 0.0485, 0.0510, 0.0517, 0.0488,\n",
      "         0.0495, 0.0511, 0.0521, 0.0505, 0.0493, 0.0514, 0.0537, 0.0556, 0.0558,\n",
      "         0.0550, 0.0545],\n",
      "        [0.0409, 0.0425, 0.0447, 0.0475, 0.0459, 0.0485, 0.0510, 0.0517, 0.0488,\n",
      "         0.0495, 0.0511, 0.0521, 0.0505, 0.0493, 0.0514, 0.0537, 0.0556, 0.0558,\n",
      "         0.0550, 0.0545],\n",
      "        [0.0410, 0.0425, 0.0447, 0.0475, 0.0459, 0.0485, 0.0510, 0.0517, 0.0488,\n",
      "         0.0495, 0.0511, 0.0521, 0.0505, 0.0493, 0.0514, 0.0537, 0.0556, 0.0558,\n",
      "         0.0550, 0.0545]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 0.05, Train Loss: 0.00, Val Loss: 6.34, Train BLEU: 0.00, Val BLEU: 0.30, Minutes Elapsed: 5.22\n",
      "Sampling from val predictions...\n",
      "Source: 我 在 埃斯 <UNK> 兰斯 的 第一 第一年 一年 只是 出去 遛 街 在 那些 日子 里 我 有 了\n",
      "Reference: and so what i did in <UNK> that first year was to just walk the streets , and in\n",
      "Model: <SOS> and , , , , , , , , . . . . . <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0014, 0.0101, 0.0151, 0.0247, 0.0529, 0.0661, 0.0697, 0.0631, 0.0799,\n",
      "         0.0851, 0.0865, 0.0891, 0.0854, 0.0780, 0.0669, 0.0534, 0.0386, 0.0227,\n",
      "         0.0095, 0.0016],\n",
      "        [0.0021, 0.0107, 0.0165, 0.0268, 0.0527, 0.0652, 0.0696, 0.0652, 0.0803,\n",
      "         0.0853, 0.0867, 0.0887, 0.0848, 0.0772, 0.0659, 0.0521, 0.0369, 0.0216,\n",
      "         0.0095, 0.0023],\n",
      "        [0.0023, 0.0112, 0.0174, 0.0279, 0.0530, 0.0651, 0.0695, 0.0657, 0.0798,\n",
      "         0.0845, 0.0859, 0.0876, 0.0838, 0.0765, 0.0657, 0.0521, 0.0372, 0.0221,\n",
      "         0.0100, 0.0026],\n",
      "        [0.0024, 0.0113, 0.0176, 0.0282, 0.0531, 0.0651, 0.0695, 0.0658, 0.0797,\n",
      "         0.0843, 0.0856, 0.0873, 0.0836, 0.0764, 0.0656, 0.0522, 0.0373, 0.0223,\n",
      "         0.0101, 0.0027],\n",
      "        [0.0024, 0.0114, 0.0177, 0.0282, 0.0531, 0.0651, 0.0695, 0.0659, 0.0797,\n",
      "         0.0843, 0.0856, 0.0873, 0.0835, 0.0763, 0.0656, 0.0522, 0.0373, 0.0222,\n",
      "         0.0101, 0.0027],\n",
      "        [0.0025, 0.0114, 0.0176, 0.0282, 0.0531, 0.0651, 0.0695, 0.0659, 0.0797,\n",
      "         0.0843, 0.0856, 0.0873, 0.0835, 0.0763, 0.0656, 0.0521, 0.0372, 0.0222,\n",
      "         0.0100, 0.0027],\n",
      "        [0.0025, 0.0113, 0.0176, 0.0282, 0.0531, 0.0651, 0.0695, 0.0660, 0.0798,\n",
      "         0.0844, 0.0857, 0.0874, 0.0836, 0.0763, 0.0655, 0.0520, 0.0372, 0.0221,\n",
      "         0.0100, 0.0027],\n",
      "        [0.0025, 0.0113, 0.0176, 0.0282, 0.0531, 0.0651, 0.0696, 0.0660, 0.0798,\n",
      "         0.0844, 0.0858, 0.0874, 0.0836, 0.0763, 0.0655, 0.0520, 0.0371, 0.0220,\n",
      "         0.0100, 0.0027],\n",
      "        [0.0025, 0.0113, 0.0176, 0.0282, 0.0531, 0.0651, 0.0696, 0.0661, 0.0799,\n",
      "         0.0845, 0.0858, 0.0875, 0.0836, 0.0763, 0.0655, 0.0519, 0.0369, 0.0219,\n",
      "         0.0099, 0.0027],\n",
      "        [0.0025, 0.0114, 0.0176, 0.0282, 0.0531, 0.0651, 0.0696, 0.0662, 0.0800,\n",
      "         0.0846, 0.0859, 0.0875, 0.0837, 0.0763, 0.0654, 0.0517, 0.0368, 0.0218,\n",
      "         0.0099, 0.0027],\n",
      "        [0.0026, 0.0114, 0.0177, 0.0283, 0.0531, 0.0651, 0.0696, 0.0662, 0.0801,\n",
      "         0.0847, 0.0860, 0.0876, 0.0836, 0.0762, 0.0653, 0.0516, 0.0366, 0.0217,\n",
      "         0.0099, 0.0028],\n",
      "        [0.0027, 0.0115, 0.0178, 0.0284, 0.0531, 0.0651, 0.0697, 0.0663, 0.0801,\n",
      "         0.0847, 0.0860, 0.0875, 0.0835, 0.0761, 0.0651, 0.0514, 0.0365, 0.0217,\n",
      "         0.0099, 0.0029],\n",
      "        [0.0029, 0.0118, 0.0180, 0.0286, 0.0532, 0.0651, 0.0696, 0.0663, 0.0800,\n",
      "         0.0846, 0.0858, 0.0873, 0.0833, 0.0759, 0.0649, 0.0513, 0.0365, 0.0217,\n",
      "         0.0101, 0.0030],\n",
      "        [0.0031, 0.0121, 0.0183, 0.0289, 0.0532, 0.0651, 0.0695, 0.0663, 0.0799,\n",
      "         0.0843, 0.0856, 0.0870, 0.0830, 0.0756, 0.0647, 0.0512, 0.0365, 0.0219,\n",
      "         0.0104, 0.0032],\n",
      "        [0.0033, 0.0125, 0.0187, 0.0293, 0.0533, 0.0650, 0.0694, 0.0662, 0.0796,\n",
      "         0.0840, 0.0852, 0.0866, 0.0827, 0.0753, 0.0646, 0.0512, 0.0367, 0.0222,\n",
      "         0.0107, 0.0035],\n",
      "        [0.0036, 0.0129, 0.0192, 0.0297, 0.0535, 0.0650, 0.0693, 0.0661, 0.0793,\n",
      "         0.0836, 0.0848, 0.0862, 0.0822, 0.0750, 0.0644, 0.0512, 0.0368, 0.0225,\n",
      "         0.0110, 0.0037],\n",
      "        [0.0038, 0.0133, 0.0196, 0.0300, 0.0536, 0.0649, 0.0691, 0.0661, 0.0790,\n",
      "         0.0833, 0.0844, 0.0857, 0.0818, 0.0747, 0.0642, 0.0513, 0.0371, 0.0229,\n",
      "         0.0114, 0.0040],\n",
      "        [0.0040, 0.0136, 0.0199, 0.0304, 0.0537, 0.0648, 0.0690, 0.0660, 0.0787,\n",
      "         0.0829, 0.0840, 0.0853, 0.0815, 0.0744, 0.0641, 0.0513, 0.0373, 0.0232,\n",
      "         0.0117, 0.0042],\n",
      "        [0.0042, 0.0139, 0.0203, 0.0307, 0.0537, 0.0647, 0.0688, 0.0659, 0.0785,\n",
      "         0.0826, 0.0836, 0.0849, 0.0811, 0.0742, 0.0640, 0.0514, 0.0375, 0.0235,\n",
      "         0.0120, 0.0044]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 0.11, Train Loss: 0.00, Val Loss: 6.30, Train BLEU: 0.00, Val BLEU: 0.76, Minutes Elapsed: 10.27\n",
      "Sampling from val predictions...\n",
      "Source: 这 也 就是 为什么 什么 在 非洲 白人 被称作 称作 <UNK> 也 就是 老板 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: that &apos;s why the white people in africa are called &quot; <UNK> , &quot; boss . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> and , , , , , , , , . . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0296, 0.1289, 0.1699, 0.1786, 0.1830, 0.1516, 0.0910, 0.0432, 0.0074,\n",
      "         0.0042, 0.0039, 0.0066, 0.0017, 0.0003, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0474, 0.1344, 0.1662, 0.1716, 0.1677, 0.1376, 0.0891, 0.0471, 0.0121,\n",
      "         0.0079, 0.0074, 0.0082, 0.0026, 0.0006, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0513, 0.1305, 0.1598, 0.1656, 0.1624, 0.1363, 0.0925, 0.0521, 0.0153,\n",
      "         0.0102, 0.0096, 0.0102, 0.0035, 0.0009, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0536, 0.1284, 0.1557, 0.1615, 0.1588, 0.1351, 0.0944, 0.0552, 0.0174,\n",
      "         0.0118, 0.0111, 0.0117, 0.0041, 0.0011, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0547, 0.1276, 0.1539, 0.1596, 0.1570, 0.1343, 0.0951, 0.0566, 0.0184,\n",
      "         0.0126, 0.0119, 0.0124, 0.0045, 0.0012, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0544, 0.1276, 0.1543, 0.1601, 0.1574, 0.1345, 0.0950, 0.0564, 0.0182,\n",
      "         0.0125, 0.0118, 0.0123, 0.0044, 0.0012, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0537, 0.1278, 0.1553, 0.1613, 0.1585, 0.1350, 0.0947, 0.0556, 0.0176,\n",
      "         0.0121, 0.0114, 0.0118, 0.0042, 0.0011, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0523, 0.1283, 0.1571, 0.1634, 0.1606, 0.1359, 0.0940, 0.0541, 0.0165,\n",
      "         0.0112, 0.0106, 0.0111, 0.0038, 0.0010, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0506, 0.1290, 0.1596, 0.1664, 0.1633, 0.1369, 0.0928, 0.0519, 0.0151,\n",
      "         0.0102, 0.0096, 0.0101, 0.0034, 0.0009, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0503, 0.1293, 0.1603, 0.1671, 0.1639, 0.1370, 0.0923, 0.0513, 0.0148,\n",
      "         0.0099, 0.0094, 0.0099, 0.0034, 0.0009, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0487, 0.1306, 0.1634, 0.1702, 0.1668, 0.1377, 0.0904, 0.0485, 0.0133,\n",
      "         0.0089, 0.0084, 0.0090, 0.0031, 0.0008, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0486, 0.1315, 0.1646, 0.1712, 0.1675, 0.1375, 0.0892, 0.0473, 0.0129,\n",
      "         0.0086, 0.0082, 0.0088, 0.0030, 0.0009, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0484, 0.1329, 0.1662, 0.1723, 0.1682, 0.1370, 0.0876, 0.0458, 0.0125,\n",
      "         0.0084, 0.0080, 0.0086, 0.0031, 0.0010, 0.0002, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0485, 0.1333, 0.1665, 0.1724, 0.1681, 0.1366, 0.0870, 0.0454, 0.0125,\n",
      "         0.0085, 0.0081, 0.0087, 0.0032, 0.0010, 0.0002, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0490, 0.1344, 0.1671, 0.1721, 0.1674, 0.1355, 0.0857, 0.0448, 0.0127,\n",
      "         0.0088, 0.0084, 0.0091, 0.0035, 0.0012, 0.0003, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0493, 0.1338, 0.1663, 0.1716, 0.1671, 0.1357, 0.0864, 0.0454, 0.0129,\n",
      "         0.0089, 0.0084, 0.0092, 0.0035, 0.0012, 0.0003, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0495, 0.1343, 0.1665, 0.1714, 0.1668, 0.1351, 0.0858, 0.0451, 0.0130,\n",
      "         0.0090, 0.0086, 0.0094, 0.0037, 0.0013, 0.0003, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0499, 0.1345, 0.1663, 0.1710, 0.1662, 0.1346, 0.0856, 0.0452, 0.0133,\n",
      "         0.0093, 0.0089, 0.0096, 0.0039, 0.0014, 0.0004, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0499, 0.1343, 0.1661, 0.1709, 0.1662, 0.1348, 0.0859, 0.0454, 0.0133,\n",
      "         0.0092, 0.0088, 0.0096, 0.0039, 0.0014, 0.0004, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.16, Train Loss: 0.00, Val Loss: 6.20, Train BLEU: 0.00, Val BLEU: 2.34, Minutes Elapsed: 15.32\n",
      "Sampling from val predictions...\n",
      "Source: 我们 是 一个 自由 的 组织 由来 来自 不同 同行 <UNK> 行业 不同 <UNK> 城市 的 <UNK> 组成 大家 全都\n",
      "Reference: what we do , we &apos;re a <UNK> kind of group , where it &apos;s composed of gardeners from\n",
      "Model: <SOS> and &apos;s , , , , , , , the the , . , . . . <EOS> .\n",
      "Attention Weights: tensor([[0.0273, 0.0744, 0.0804, 0.0872, 0.0982, 0.0917, 0.0893, 0.0834, 0.0736,\n",
      "         0.0551, 0.0095, 0.0618, 0.0473, 0.0074, 0.0478, 0.0354, 0.0038, 0.0190,\n",
      "         0.0069, 0.0005],\n",
      "        [0.0373, 0.0652, 0.0718, 0.0765, 0.0811, 0.0799, 0.0792, 0.0766, 0.0715,\n",
      "         0.0611, 0.0226, 0.0649, 0.0549, 0.0188, 0.0526, 0.0415, 0.0108, 0.0227,\n",
      "         0.0099, 0.0014],\n",
      "        [0.0402, 0.0608, 0.0665, 0.0702, 0.0732, 0.0731, 0.0729, 0.0715, 0.0683,\n",
      "         0.0614, 0.0303, 0.0640, 0.0570, 0.0264, 0.0547, 0.0458, 0.0172, 0.0284,\n",
      "         0.0150, 0.0031],\n",
      "        [0.0413, 0.0599, 0.0652, 0.0685, 0.0711, 0.0711, 0.0710, 0.0699, 0.0671,\n",
      "         0.0613, 0.0326, 0.0635, 0.0573, 0.0288, 0.0550, 0.0468, 0.0194, 0.0299,\n",
      "         0.0166, 0.0038],\n",
      "        [0.0425, 0.0593, 0.0641, 0.0670, 0.0691, 0.0692, 0.0692, 0.0682, 0.0659,\n",
      "         0.0608, 0.0347, 0.0627, 0.0573, 0.0311, 0.0550, 0.0476, 0.0216, 0.0316,\n",
      "         0.0184, 0.0048],\n",
      "        [0.0427, 0.0592, 0.0639, 0.0667, 0.0688, 0.0689, 0.0689, 0.0679, 0.0657,\n",
      "         0.0608, 0.0351, 0.0626, 0.0573, 0.0315, 0.0550, 0.0478, 0.0220, 0.0317,\n",
      "         0.0187, 0.0050],\n",
      "        [0.0430, 0.0589, 0.0635, 0.0662, 0.0681, 0.0683, 0.0683, 0.0674, 0.0652,\n",
      "         0.0606, 0.0359, 0.0623, 0.0573, 0.0323, 0.0550, 0.0480, 0.0229, 0.0322,\n",
      "         0.0193, 0.0054],\n",
      "        [0.0428, 0.0591, 0.0638, 0.0666, 0.0686, 0.0688, 0.0687, 0.0678, 0.0656,\n",
      "         0.0608, 0.0355, 0.0626, 0.0574, 0.0318, 0.0549, 0.0477, 0.0223, 0.0316,\n",
      "         0.0186, 0.0050],\n",
      "        [0.0421, 0.0595, 0.0646, 0.0676, 0.0697, 0.0699, 0.0698, 0.0688, 0.0664,\n",
      "         0.0612, 0.0343, 0.0631, 0.0575, 0.0305, 0.0549, 0.0472, 0.0209, 0.0305,\n",
      "         0.0173, 0.0043],\n",
      "        [0.0428, 0.0591, 0.0638, 0.0665, 0.0685, 0.0687, 0.0686, 0.0678, 0.0655,\n",
      "         0.0609, 0.0357, 0.0625, 0.0574, 0.0320, 0.0549, 0.0477, 0.0224, 0.0315,\n",
      "         0.0186, 0.0050],\n",
      "        [0.0392, 0.0616, 0.0680, 0.0720, 0.0751, 0.0751, 0.0749, 0.0733, 0.0697,\n",
      "         0.0623, 0.0288, 0.0649, 0.0572, 0.0247, 0.0540, 0.0443, 0.0152, 0.0253,\n",
      "         0.0122, 0.0022],\n",
      "        [0.0403, 0.0614, 0.0674, 0.0710, 0.0738, 0.0738, 0.0736, 0.0722, 0.0689,\n",
      "         0.0620, 0.0302, 0.0644, 0.0572, 0.0261, 0.0541, 0.0449, 0.0164, 0.0264,\n",
      "         0.0133, 0.0026],\n",
      "        [0.0417, 0.0606, 0.0660, 0.0691, 0.0715, 0.0716, 0.0715, 0.0703, 0.0674,\n",
      "         0.0616, 0.0327, 0.0636, 0.0573, 0.0287, 0.0544, 0.0460, 0.0189, 0.0283,\n",
      "         0.0152, 0.0034],\n",
      "        [0.0398, 0.0625, 0.0688, 0.0726, 0.0756, 0.0755, 0.0751, 0.0734, 0.0697,\n",
      "         0.0621, 0.0284, 0.0647, 0.0567, 0.0243, 0.0535, 0.0437, 0.0148, 0.0247,\n",
      "         0.0118, 0.0021],\n",
      "        [0.0417, 0.0608, 0.0663, 0.0695, 0.0719, 0.0720, 0.0718, 0.0706, 0.0676,\n",
      "         0.0617, 0.0324, 0.0637, 0.0573, 0.0284, 0.0542, 0.0457, 0.0185, 0.0278,\n",
      "         0.0148, 0.0033],\n",
      "        [0.0399, 0.0634, 0.0698, 0.0736, 0.0767, 0.0764, 0.0759, 0.0741, 0.0700,\n",
      "         0.0619, 0.0274, 0.0647, 0.0563, 0.0233, 0.0530, 0.0428, 0.0140, 0.0238,\n",
      "         0.0111, 0.0019],\n",
      "        [0.0409, 0.0630, 0.0689, 0.0724, 0.0751, 0.0750, 0.0746, 0.0729, 0.0692,\n",
      "         0.0617, 0.0290, 0.0643, 0.0565, 0.0248, 0.0533, 0.0436, 0.0153, 0.0250,\n",
      "         0.0122, 0.0023],\n",
      "        [0.0409, 0.0640, 0.0700, 0.0735, 0.0763, 0.0760, 0.0755, 0.0735, 0.0695,\n",
      "         0.0616, 0.0277, 0.0643, 0.0560, 0.0236, 0.0528, 0.0428, 0.0143, 0.0241,\n",
      "         0.0115, 0.0021],\n",
      "        [0.0391, 0.0671, 0.0738, 0.0779, 0.0815, 0.0804, 0.0794, 0.0767, 0.0713,\n",
      "         0.0608, 0.0229, 0.0644, 0.0541, 0.0189, 0.0510, 0.0395, 0.0106, 0.0205,\n",
      "         0.0087, 0.0013]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 0.22, Train Loss: 0.00, Val Loss: 6.15, Train BLEU: 0.00, Val BLEU: 2.91, Minutes Elapsed: 20.39\n",
      "Sampling from val predictions...\n",
      "Source: 那些 枪 对 我 来说 是 一个 明显 的 信号 尽管 他 并 没有 拿起 枪 指着 我 我 已经\n",
      "Reference: but those guns were really a message for me , and even though he hadn &apos;t raised a hand\n",
      "Model: <SOS> so &apos;s the the the the the , the , , , , the . . . . .\n",
      "Attention Weights: tensor([[0.0628, 0.1038, 0.0978, 0.0939, 0.0711, 0.0708, 0.0581, 0.0627, 0.0631,\n",
      "         0.0508, 0.0542, 0.0567, 0.0499, 0.0375, 0.0273, 0.0188, 0.0054, 0.0113,\n",
      "         0.0038, 0.0002],\n",
      "        [0.0511, 0.0695, 0.0712, 0.0718, 0.0651, 0.0659, 0.0604, 0.0632, 0.0636,\n",
      "         0.0574, 0.0594, 0.0608, 0.0572, 0.0498, 0.0423, 0.0346, 0.0168, 0.0252,\n",
      "         0.0129, 0.0018],\n",
      "        [0.0498, 0.0622, 0.0641, 0.0649, 0.0613, 0.0620, 0.0587, 0.0606, 0.0609,\n",
      "         0.0571, 0.0585, 0.0595, 0.0572, 0.0522, 0.0469, 0.0410, 0.0249, 0.0330,\n",
      "         0.0206, 0.0048],\n",
      "        [0.0496, 0.0597, 0.0614, 0.0623, 0.0594, 0.0601, 0.0575, 0.0590, 0.0593,\n",
      "         0.0562, 0.0574, 0.0583, 0.0565, 0.0526, 0.0484, 0.0436, 0.0292, 0.0367,\n",
      "         0.0253, 0.0076],\n",
      "        [0.0499, 0.0600, 0.0615, 0.0623, 0.0594, 0.0600, 0.0573, 0.0588, 0.0592,\n",
      "         0.0561, 0.0572, 0.0582, 0.0564, 0.0525, 0.0484, 0.0436, 0.0293, 0.0368,\n",
      "         0.0254, 0.0076],\n",
      "        [0.0503, 0.0614, 0.0630, 0.0638, 0.0603, 0.0609, 0.0579, 0.0596, 0.0599,\n",
      "         0.0564, 0.0577, 0.0587, 0.0567, 0.0523, 0.0477, 0.0423, 0.0270, 0.0350,\n",
      "         0.0230, 0.0060],\n",
      "        [0.0507, 0.0606, 0.0619, 0.0625, 0.0595, 0.0600, 0.0573, 0.0588, 0.0591,\n",
      "         0.0560, 0.0571, 0.0581, 0.0563, 0.0523, 0.0482, 0.0434, 0.0290, 0.0367,\n",
      "         0.0252, 0.0074],\n",
      "        [0.0509, 0.0633, 0.0648, 0.0655, 0.0613, 0.0620, 0.0584, 0.0603, 0.0607,\n",
      "         0.0566, 0.0581, 0.0593, 0.0570, 0.0519, 0.0467, 0.0407, 0.0246, 0.0330,\n",
      "         0.0205, 0.0045],\n",
      "        [0.0509, 0.0594, 0.0605, 0.0610, 0.0584, 0.0589, 0.0566, 0.0578, 0.0581,\n",
      "         0.0554, 0.0564, 0.0572, 0.0557, 0.0524, 0.0488, 0.0447, 0.0316, 0.0386,\n",
      "         0.0280, 0.0095],\n",
      "        [0.0511, 0.0654, 0.0671, 0.0678, 0.0627, 0.0634, 0.0591, 0.0614, 0.0618,\n",
      "         0.0569, 0.0587, 0.0601, 0.0573, 0.0513, 0.0453, 0.0386, 0.0215, 0.0302,\n",
      "         0.0173, 0.0031],\n",
      "        [0.0516, 0.0627, 0.0639, 0.0644, 0.0606, 0.0612, 0.0579, 0.0597, 0.0600,\n",
      "         0.0563, 0.0576, 0.0587, 0.0566, 0.0520, 0.0472, 0.0416, 0.0262, 0.0344,\n",
      "         0.0221, 0.0054],\n",
      "        [0.0516, 0.0634, 0.0646, 0.0652, 0.0611, 0.0616, 0.0582, 0.0600, 0.0603,\n",
      "         0.0564, 0.0578, 0.0590, 0.0567, 0.0518, 0.0468, 0.0410, 0.0251, 0.0335,\n",
      "         0.0210, 0.0048],\n",
      "        [0.0514, 0.0610, 0.0622, 0.0627, 0.0595, 0.0600, 0.0573, 0.0588, 0.0590,\n",
      "         0.0559, 0.0571, 0.0580, 0.0562, 0.0522, 0.0481, 0.0432, 0.0288, 0.0366,\n",
      "         0.0249, 0.0072],\n",
      "        [0.0518, 0.0636, 0.0649, 0.0654, 0.0612, 0.0618, 0.0583, 0.0601, 0.0605,\n",
      "         0.0565, 0.0579, 0.0590, 0.0567, 0.0518, 0.0466, 0.0407, 0.0248, 0.0331,\n",
      "         0.0206, 0.0046],\n",
      "        [0.0526, 0.0689, 0.0702, 0.0706, 0.0642, 0.0648, 0.0597, 0.0623, 0.0627,\n",
      "         0.0570, 0.0590, 0.0605, 0.0571, 0.0502, 0.0432, 0.0357, 0.0183, 0.0269,\n",
      "         0.0141, 0.0021],\n",
      "        [0.0533, 0.0725, 0.0736, 0.0737, 0.0658, 0.0664, 0.0602, 0.0633, 0.0637,\n",
      "         0.0569, 0.0592, 0.0609, 0.0569, 0.0488, 0.0409, 0.0326, 0.0151, 0.0235,\n",
      "         0.0112, 0.0014],\n",
      "        [0.0533, 0.0689, 0.0699, 0.0701, 0.0639, 0.0644, 0.0595, 0.0620, 0.0623,\n",
      "         0.0568, 0.0587, 0.0601, 0.0569, 0.0502, 0.0435, 0.0361, 0.0189, 0.0275,\n",
      "         0.0147, 0.0023],\n",
      "        [0.0539, 0.0791, 0.0799, 0.0796, 0.0685, 0.0691, 0.0608, 0.0647, 0.0651,\n",
      "         0.0564, 0.0592, 0.0612, 0.0559, 0.0459, 0.0366, 0.0274, 0.0107, 0.0181,\n",
      "         0.0073, 0.0007],\n",
      "        [0.0541, 0.0747, 0.0755, 0.0754, 0.0666, 0.0672, 0.0604, 0.0636, 0.0640,\n",
      "         0.0567, 0.0591, 0.0608, 0.0565, 0.0479, 0.0396, 0.0310, 0.0138, 0.0219,\n",
      "         0.0100, 0.0012]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 0.27, Train Loss: 0.00, Val Loss: 6.09, Train BLEU: 0.00, Val BLEU: 1.82, Minutes Elapsed: 25.44\n",
      "Sampling from val predictions...\n",
      "Source: 他们 能 消灭 所有 尸体 上 的 细菌 他们 能 吸收 炭疽 <UNK> 病毒 阻止 病毒 的 传播 与 扩散\n",
      "Reference: they help to kill all the bacteria . they help absorb anthrax that would otherwise spread and cause huge\n",
      "Model: <SOS> and , , the , , , , the , , the the <EOS> . . <EOS> <EOS> .\n",
      "Attention Weights: tensor([[0.0690, 0.1691, 0.0954, 0.0928, 0.0884, 0.1093, 0.0766, 0.0421, 0.0600,\n",
      "         0.0594, 0.0198, 0.0084, 0.0028, 0.0205, 0.0294, 0.0180, 0.0229, 0.0102,\n",
      "         0.0054, 0.0004],\n",
      "        [0.0483, 0.0809, 0.0679, 0.0713, 0.0736, 0.0837, 0.0728, 0.0561, 0.0675,\n",
      "         0.0680, 0.0393, 0.0247, 0.0125, 0.0408, 0.0501, 0.0402, 0.0465, 0.0310,\n",
      "         0.0211, 0.0035],\n",
      "        [0.0488, 0.0696, 0.0626, 0.0649, 0.0665, 0.0723, 0.0661, 0.0559, 0.0632,\n",
      "         0.0633, 0.0443, 0.0326, 0.0206, 0.0459, 0.0525, 0.0453, 0.0498, 0.0380,\n",
      "         0.0293, 0.0085],\n",
      "        [0.0495, 0.0625, 0.0585, 0.0600, 0.0610, 0.0643, 0.0609, 0.0549, 0.0592,\n",
      "         0.0594, 0.0476, 0.0392, 0.0289, 0.0483, 0.0526, 0.0480, 0.0508, 0.0428,\n",
      "         0.0361, 0.0155],\n",
      "        [0.0489, 0.0618, 0.0578, 0.0594, 0.0604, 0.0640, 0.0607, 0.0545, 0.0590,\n",
      "         0.0594, 0.0475, 0.0391, 0.0287, 0.0483, 0.0528, 0.0484, 0.0517, 0.0439,\n",
      "         0.0375, 0.0163],\n",
      "        [0.0496, 0.0585, 0.0557, 0.0567, 0.0574, 0.0597, 0.0575, 0.0534, 0.0564,\n",
      "         0.0567, 0.0486, 0.0425, 0.0342, 0.0491, 0.0523, 0.0492, 0.0516, 0.0461,\n",
      "         0.0415, 0.0232],\n",
      "        [0.0486, 0.0612, 0.0572, 0.0587, 0.0598, 0.0635, 0.0602, 0.0541, 0.0587,\n",
      "         0.0592, 0.0473, 0.0390, 0.0287, 0.0483, 0.0530, 0.0488, 0.0524, 0.0449,\n",
      "         0.0389, 0.0174],\n",
      "        [0.0489, 0.0598, 0.0563, 0.0577, 0.0586, 0.0618, 0.0589, 0.0537, 0.0576,\n",
      "         0.0581, 0.0477, 0.0403, 0.0308, 0.0486, 0.0528, 0.0492, 0.0524, 0.0458,\n",
      "         0.0406, 0.0201],\n",
      "        [0.0491, 0.0585, 0.0555, 0.0566, 0.0574, 0.0601, 0.0577, 0.0532, 0.0566,\n",
      "         0.0571, 0.0482, 0.0417, 0.0330, 0.0489, 0.0526, 0.0494, 0.0523, 0.0467,\n",
      "         0.0422, 0.0232],\n",
      "        [0.0475, 0.0633, 0.0579, 0.0600, 0.0615, 0.0665, 0.0621, 0.0542, 0.0602,\n",
      "         0.0610, 0.0457, 0.0358, 0.0246, 0.0474, 0.0536, 0.0485, 0.0536, 0.0444,\n",
      "         0.0378, 0.0143],\n",
      "        [0.0492, 0.0614, 0.0572, 0.0586, 0.0597, 0.0632, 0.0599, 0.0538, 0.0584,\n",
      "         0.0588, 0.0470, 0.0387, 0.0287, 0.0481, 0.0529, 0.0488, 0.0526, 0.0453,\n",
      "         0.0396, 0.0181],\n",
      "        [0.0485, 0.0593, 0.0557, 0.0571, 0.0582, 0.0614, 0.0586, 0.0533, 0.0574,\n",
      "         0.0579, 0.0476, 0.0403, 0.0310, 0.0486, 0.0530, 0.0495, 0.0530, 0.0466,\n",
      "         0.0418, 0.0213],\n",
      "        [0.0470, 0.0644, 0.0583, 0.0606, 0.0623, 0.0681, 0.0630, 0.0541, 0.0610,\n",
      "         0.0619, 0.0447, 0.0340, 0.0225, 0.0468, 0.0539, 0.0484, 0.0544, 0.0443,\n",
      "         0.0373, 0.0130],\n",
      "        [0.0456, 0.0709, 0.0611, 0.0644, 0.0669, 0.0759, 0.0677, 0.0541, 0.0643,\n",
      "         0.0656, 0.0409, 0.0277, 0.0157, 0.0439, 0.0539, 0.0461, 0.0548, 0.0408,\n",
      "         0.0321, 0.0076],\n",
      "        [0.0436, 0.0792, 0.0642, 0.0686, 0.0719, 0.0853, 0.0727, 0.0534, 0.0674,\n",
      "         0.0692, 0.0363, 0.0216, 0.0106, 0.0400, 0.0527, 0.0426, 0.0540, 0.0362,\n",
      "         0.0263, 0.0042],\n",
      "        [0.0465, 0.0687, 0.0601, 0.0629, 0.0649, 0.0727, 0.0656, 0.0538, 0.0627,\n",
      "         0.0638, 0.0419, 0.0297, 0.0179, 0.0449, 0.0540, 0.0471, 0.0552, 0.0428,\n",
      "         0.0350, 0.0099],\n",
      "        [0.0463, 0.0699, 0.0606, 0.0635, 0.0657, 0.0740, 0.0664, 0.0537, 0.0632,\n",
      "         0.0644, 0.0412, 0.0285, 0.0168, 0.0443, 0.0540, 0.0467, 0.0553, 0.0422,\n",
      "         0.0341, 0.0091],\n",
      "        [0.0426, 0.0847, 0.0658, 0.0707, 0.0744, 0.0908, 0.0750, 0.0523, 0.0686,\n",
      "         0.0706, 0.0335, 0.0188, 0.0087, 0.0376, 0.0516, 0.0405, 0.0533, 0.0338,\n",
      "         0.0236, 0.0033],\n",
      "        [0.0402, 0.0933, 0.0681, 0.0741, 0.0787, 0.1004, 0.0790, 0.0509, 0.0705,\n",
      "         0.0728, 0.0297, 0.0152, 0.0065, 0.0340, 0.0492, 0.0367, 0.0506, 0.0291,\n",
      "         0.0188, 0.0020]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.33, Train Loss: 0.00, Val Loss: 6.09, Train BLEU: 0.00, Val BLEU: 1.80, Minutes Elapsed: 30.47\n",
      "Sampling from val predictions...\n",
      "Source: 我们 用 的 就是 清洁 <UNK> 用 的 钢丝 <UNK> 钢丝 <UNK> 可以 <UNK> 很小 小块 我们 把 这些 些小\n",
      "Reference: so what we can do is use steel wool just to clean <UNK> , and the steel wool we\n",
      "Model: <SOS> and , , a a , , , , , the the . <EOS> <EOS> . . . <EOS>\n",
      "Attention Weights: tensor([[0.3186, 0.1996, 0.0811, 0.0643, 0.0076, 0.0012, 0.0447, 0.0184, 0.0035,\n",
      "         0.0005, 0.0025, 0.0005, 0.0083, 0.0006, 0.0138, 0.0017, 0.1391, 0.0703,\n",
      "         0.0215, 0.0022],\n",
      "        [0.1303, 0.1314, 0.0921, 0.0866, 0.0243, 0.0071, 0.0808, 0.0480, 0.0162,\n",
      "         0.0040, 0.0129, 0.0041, 0.0280, 0.0047, 0.0374, 0.0087, 0.1388, 0.0940,\n",
      "         0.0429, 0.0078],\n",
      "        [0.1058, 0.1088, 0.0859, 0.0829, 0.0335, 0.0134, 0.0798, 0.0548, 0.0248,\n",
      "         0.0086, 0.0209, 0.0088, 0.0372, 0.0096, 0.0456, 0.0153, 0.1157, 0.0866,\n",
      "         0.0485, 0.0136],\n",
      "        [0.0817, 0.0847, 0.0748, 0.0739, 0.0426, 0.0226, 0.0735, 0.0590, 0.0356,\n",
      "         0.0165, 0.0318, 0.0168, 0.0465, 0.0179, 0.0528, 0.0251, 0.0913, 0.0771,\n",
      "         0.0540, 0.0220],\n",
      "        [0.0690, 0.0714, 0.0657, 0.0658, 0.0440, 0.0272, 0.0672, 0.0579, 0.0400,\n",
      "         0.0220, 0.0371, 0.0225, 0.0501, 0.0241, 0.0558, 0.0322, 0.0829, 0.0748,\n",
      "         0.0593, 0.0309],\n",
      "        [0.0577, 0.0595, 0.0571, 0.0576, 0.0462, 0.0351, 0.0594, 0.0550, 0.0450,\n",
      "         0.0320, 0.0435, 0.0328, 0.0517, 0.0344, 0.0555, 0.0411, 0.0694, 0.0661,\n",
      "         0.0590, 0.0418],\n",
      "        [0.0561, 0.0580, 0.0558, 0.0564, 0.0453, 0.0347, 0.0586, 0.0544, 0.0447,\n",
      "         0.0321, 0.0434, 0.0331, 0.0518, 0.0349, 0.0559, 0.0420, 0.0701, 0.0673,\n",
      "         0.0608, 0.0445],\n",
      "        [0.0583, 0.0601, 0.0572, 0.0577, 0.0444, 0.0324, 0.0601, 0.0549, 0.0434,\n",
      "         0.0294, 0.0418, 0.0303, 0.0517, 0.0323, 0.0565, 0.0402, 0.0736, 0.0701,\n",
      "         0.0623, 0.0433],\n",
      "        [0.0544, 0.0560, 0.0542, 0.0548, 0.0454, 0.0362, 0.0571, 0.0536, 0.0453,\n",
      "         0.0342, 0.0443, 0.0352, 0.0518, 0.0371, 0.0555, 0.0437, 0.0677, 0.0656,\n",
      "         0.0606, 0.0472],\n",
      "        [0.0550, 0.0569, 0.0547, 0.0553, 0.0441, 0.0337, 0.0581, 0.0538, 0.0439,\n",
      "         0.0315, 0.0427, 0.0326, 0.0518, 0.0347, 0.0565, 0.0424, 0.0720, 0.0695,\n",
      "         0.0635, 0.0474],\n",
      "        [0.0626, 0.0647, 0.0595, 0.0599, 0.0396, 0.0247, 0.0636, 0.0548, 0.0376,\n",
      "         0.0211, 0.0354, 0.0220, 0.0497, 0.0242, 0.0579, 0.0340, 0.0910, 0.0855,\n",
      "         0.0711, 0.0410],\n",
      "        [0.0673, 0.0697, 0.0624, 0.0624, 0.0373, 0.0208, 0.0664, 0.0548, 0.0341,\n",
      "         0.0169, 0.0315, 0.0176, 0.0475, 0.0195, 0.0570, 0.0291, 0.1021, 0.0941,\n",
      "         0.0735, 0.0360],\n",
      "        [0.0640, 0.0664, 0.0604, 0.0606, 0.0386, 0.0231, 0.0645, 0.0547, 0.0361,\n",
      "         0.0194, 0.0337, 0.0202, 0.0487, 0.0223, 0.0575, 0.0321, 0.0956, 0.0896,\n",
      "         0.0729, 0.0396],\n",
      "        [0.0542, 0.0559, 0.0537, 0.0542, 0.0428, 0.0327, 0.0575, 0.0531, 0.0428,\n",
      "         0.0307, 0.0418, 0.0320, 0.0515, 0.0343, 0.0569, 0.0427, 0.0743, 0.0724,\n",
      "         0.0663, 0.0501],\n",
      "        [0.0667, 0.0691, 0.0620, 0.0618, 0.0376, 0.0213, 0.0654, 0.0544, 0.0344,\n",
      "         0.0174, 0.0318, 0.0181, 0.0470, 0.0200, 0.0565, 0.0297, 0.1010, 0.0942,\n",
      "         0.0743, 0.0376],\n",
      "        [0.0739, 0.0781, 0.0675, 0.0666, 0.0347, 0.0165, 0.0698, 0.0545, 0.0300,\n",
      "         0.0126, 0.0267, 0.0130, 0.0433, 0.0145, 0.0539, 0.0232, 0.1150, 0.1035,\n",
      "         0.0737, 0.0292],\n",
      "        [0.0674, 0.0692, 0.0617, 0.0615, 0.0371, 0.0211, 0.0650, 0.0539, 0.0340,\n",
      "         0.0173, 0.0315, 0.0181, 0.0471, 0.0201, 0.0568, 0.0300, 0.1009, 0.0939,\n",
      "         0.0746, 0.0388],\n",
      "        [0.0642, 0.0660, 0.0600, 0.0599, 0.0386, 0.0235, 0.0634, 0.0540, 0.0361,\n",
      "         0.0199, 0.0338, 0.0207, 0.0483, 0.0229, 0.0572, 0.0329, 0.0943, 0.0891,\n",
      "         0.0735, 0.0419],\n",
      "        [0.0621, 0.0638, 0.0585, 0.0586, 0.0395, 0.0252, 0.0619, 0.0537, 0.0375,\n",
      "         0.0219, 0.0354, 0.0229, 0.0489, 0.0251, 0.0572, 0.0351, 0.0897, 0.0857,\n",
      "         0.0727, 0.0447]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 0.38, Train Loss: 0.00, Val Loss: 6.04, Train BLEU: 0.00, Val BLEU: 2.02, Minutes Elapsed: 35.50\n",
      "Sampling from val predictions...\n",
      "Source: 新一代 一代 的 创业 创业者 业者 们 皆 因 <UNK> <UNK> 而 一事 <UNK> 无成 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: there is a new generation of entrepreneurs who are dying of solitude . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> the the the the of , the , the the . . . <EOS> <EOS> . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0177, 0.3939, 0.2242, 0.0048, 0.0005, 0.0157, 0.3123, 0.0221, 0.0014,\n",
      "         0.0001, 0.0001, 0.0060, 0.0012, 0.0000, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0261, 0.2681, 0.2041, 0.0145, 0.0032, 0.0391, 0.3621, 0.0516, 0.0064,\n",
      "         0.0005, 0.0009, 0.0177, 0.0046, 0.0003, 0.0005, 0.0003, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0405, 0.2156, 0.1787, 0.0328, 0.0125, 0.0651, 0.2782, 0.0760, 0.0213,\n",
      "         0.0046, 0.0065, 0.0394, 0.0182, 0.0037, 0.0043, 0.0027, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0329, 0.1789, 0.1752, 0.0359, 0.0124, 0.0755, 0.3169, 0.0866, 0.0205,\n",
      "         0.0035, 0.0050, 0.0362, 0.0143, 0.0022, 0.0024, 0.0015, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0320, 0.1030, 0.1207, 0.0529, 0.0290, 0.1029, 0.2238, 0.1280, 0.0528,\n",
      "         0.0117, 0.0158, 0.0749, 0.0363, 0.0061, 0.0064, 0.0037, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0325, 0.0933, 0.1099, 0.0544, 0.0332, 0.1010, 0.1985, 0.1266, 0.0605,\n",
      "         0.0159, 0.0210, 0.0841, 0.0452, 0.0089, 0.0094, 0.0056, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0260, 0.0893, 0.1072, 0.0413, 0.0221, 0.0923, 0.2680, 0.1381, 0.0493,\n",
      "         0.0092, 0.0133, 0.0899, 0.0399, 0.0053, 0.0058, 0.0032, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0263, 0.0886, 0.1020, 0.0358, 0.0177, 0.0823, 0.3121, 0.1364, 0.0408,\n",
      "         0.0065, 0.0098, 0.0966, 0.0361, 0.0034, 0.0037, 0.0018, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0238, 0.0697, 0.0851, 0.0402, 0.0262, 0.0875, 0.2114, 0.1368, 0.0652,\n",
      "         0.0163, 0.0232, 0.1173, 0.0650, 0.0117, 0.0132, 0.0076, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0281, 0.0845, 0.0954, 0.0369, 0.0197, 0.0800, 0.2782, 0.1359, 0.0465,\n",
      "         0.0083, 0.0126, 0.1160, 0.0464, 0.0046, 0.0048, 0.0023, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0220, 0.0572, 0.0672, 0.0318, 0.0215, 0.0682, 0.1994, 0.1303, 0.0629,\n",
      "         0.0162, 0.0244, 0.1631, 0.0925, 0.0153, 0.0184, 0.0098, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0195, 0.0473, 0.0559, 0.0295, 0.0220, 0.0615, 0.1530, 0.1154, 0.0681,\n",
      "         0.0224, 0.0337, 0.1644, 0.1152, 0.0304, 0.0381, 0.0235, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0264, 0.0632, 0.0714, 0.0352, 0.0242, 0.0663, 0.1765, 0.1171, 0.0604,\n",
      "         0.0182, 0.0265, 0.1638, 0.0974, 0.0187, 0.0225, 0.0123, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0201, 0.0480, 0.0558, 0.0291, 0.0217, 0.0585, 0.1520, 0.1109, 0.0640,\n",
      "         0.0217, 0.0323, 0.1697, 0.1179, 0.0311, 0.0411, 0.0261, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0330, 0.0815, 0.0896, 0.0425, 0.0267, 0.0761, 0.1904, 0.1183, 0.0575,\n",
      "         0.0160, 0.0229, 0.1369, 0.0753, 0.0128, 0.0137, 0.0068, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0285, 0.0723, 0.0806, 0.0375, 0.0237, 0.0736, 0.2136, 0.1251, 0.0565,\n",
      "         0.0147, 0.0217, 0.1461, 0.0759, 0.0116, 0.0125, 0.0061, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0275, 0.0691, 0.0775, 0.0368, 0.0237, 0.0721, 0.2073, 0.1241, 0.0577,\n",
      "         0.0156, 0.0229, 0.1500, 0.0806, 0.0132, 0.0145, 0.0074, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0333, 0.0899, 0.0979, 0.0428, 0.0244, 0.0801, 0.2128, 0.1221, 0.0534,\n",
      "         0.0124, 0.0183, 0.1275, 0.0635, 0.0086, 0.0088, 0.0041, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0336, 0.0916, 0.1000, 0.0433, 0.0247, 0.0806, 0.2090, 0.1215, 0.0540,\n",
      "         0.0126, 0.0186, 0.1252, 0.0634, 0.0088, 0.0089, 0.0041, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 0.44, Train Loss: 0.00, Val Loss: 5.91, Train BLEU: 0.00, Val BLEU: 2.83, Minutes Elapsed: 40.53\n",
      "Sampling from val predictions...\n",
      "Source: 当 她们 走出 矿井 时 全身 <UNK> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: when they came out of the shaft , they were <UNK> wet from their own sweat . <EOS> <PAD>\n",
      "Model: <SOS> this &apos;s a the the the . . <EOS> . . . <EOS> <EOS> . . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9475, 0.0461, 0.0042, 0.0010, 0.0012, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.8168, 0.1477, 0.0231, 0.0058, 0.0057, 0.0006, 0.0002, 0.0002, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.5229, 0.2743, 0.1006, 0.0458, 0.0361, 0.0109, 0.0052, 0.0041, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.3523, 0.2939, 0.1812, 0.0948, 0.0654, 0.0082, 0.0025, 0.0017, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1295, 0.1474, 0.1808, 0.2191, 0.2390, 0.0608, 0.0155, 0.0080, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1128, 0.1049, 0.1171, 0.1833, 0.3277, 0.1052, 0.0312, 0.0178, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1324, 0.1146, 0.1135, 0.1523, 0.2995, 0.1161, 0.0429, 0.0286, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1207, 0.1059, 0.1067, 0.1452, 0.2843, 0.1306, 0.0600, 0.0466, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1610, 0.1343, 0.1246, 0.1421, 0.2490, 0.1057, 0.0470, 0.0361, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2568, 0.1902, 0.1516, 0.1350, 0.1821, 0.0544, 0.0183, 0.0116, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1756, 0.1416, 0.1271, 0.1459, 0.2569, 0.0915, 0.0357, 0.0257, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1277, 0.1173, 0.1165, 0.1409, 0.2267, 0.1325, 0.0748, 0.0637, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1354, 0.1247, 0.1224, 0.1384, 0.1984, 0.1273, 0.0807, 0.0727, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2430, 0.1854, 0.1533, 0.1396, 0.1793, 0.0620, 0.0227, 0.0147, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2174, 0.1732, 0.1498, 0.1428, 0.1864, 0.0765, 0.0320, 0.0221, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1910, 0.1594, 0.1439, 0.1429, 0.1883, 0.0926, 0.0463, 0.0356, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1972, 0.1631, 0.1459, 0.1432, 0.1874, 0.0887, 0.0427, 0.0319, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1888, 0.1593, 0.1446, 0.1440, 0.1873, 0.0940, 0.0468, 0.0353, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2326, 0.1811, 0.1527, 0.1415, 0.1797, 0.0682, 0.0266, 0.0176, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.49, Train Loss: 0.00, Val Loss: 5.89, Train BLEU: 0.00, Val BLEU: 4.00, Minutes Elapsed: 45.58\n",
      "Sampling from val predictions...\n",
      "Source: 你 可以 以是 是非 非凡 的 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: you can be extraordinary . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> i i &apos;t a . . <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9983, 0.0016, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.9873, 0.0112, 0.0007, 0.0005, 0.0001, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.8697, 0.0973, 0.0163, 0.0093, 0.0032, 0.0028, 0.0013, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2408, 0.3183, 0.2589, 0.1528, 0.0193, 0.0078, 0.0021, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0753, 0.1064, 0.1965, 0.3325, 0.1746, 0.0928, 0.0220, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0484, 0.0598, 0.1021, 0.2501, 0.2353, 0.2212, 0.0831, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1708, 0.1375, 0.1263, 0.2185, 0.1507, 0.1587, 0.0374, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2026, 0.1384, 0.1230, 0.2400, 0.1370, 0.1302, 0.0288, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2515, 0.1546, 0.1320, 0.2534, 0.1090, 0.0834, 0.0161, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.3222, 0.2023, 0.1431, 0.1723, 0.0784, 0.0677, 0.0141, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.3243, 0.2100, 0.1477, 0.1637, 0.0752, 0.0645, 0.0146, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.3219, 0.2117, 0.1496, 0.1622, 0.0752, 0.0642, 0.0152, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.3198, 0.2122, 0.1505, 0.1618, 0.0756, 0.0643, 0.0157, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.3185, 0.2125, 0.1512, 0.1616, 0.0759, 0.0643, 0.0160, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.3177, 0.2127, 0.1516, 0.1615, 0.0761, 0.0642, 0.0162, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.3174, 0.2130, 0.1520, 0.1613, 0.0761, 0.0640, 0.0162, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.3172, 0.2132, 0.1523, 0.1612, 0.0761, 0.0638, 0.0163, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.3171, 0.2134, 0.1525, 0.1611, 0.0760, 0.0636, 0.0163, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.3172, 0.2136, 0.1527, 0.1610, 0.0759, 0.0634, 0.0163, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 0.55, Train Loss: 0.00, Val Loss: 5.82, Train BLEU: 0.00, Val BLEU: 2.67, Minutes Elapsed: 50.64\n",
      "Sampling from val predictions...\n",
      "Source: 他们 得到 了 他们 要 的 体面 头衔 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: they got their title of respectability . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> and &apos;s the to , . . <EOS> <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.7838, 0.1666, 0.0357, 0.0053, 0.0065, 0.0006, 0.0004, 0.0008, 0.0003,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.6962, 0.2314, 0.0558, 0.0078, 0.0064, 0.0009, 0.0005, 0.0007, 0.0003,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.4889, 0.2864, 0.0951, 0.0523, 0.0322, 0.0142, 0.0123, 0.0115, 0.0071,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2479, 0.3346, 0.1859, 0.1331, 0.0673, 0.0119, 0.0090, 0.0070, 0.0033,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0567, 0.1421, 0.2066, 0.3114, 0.2359, 0.0264, 0.0134, 0.0059, 0.0017,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0404, 0.0954, 0.1653, 0.3147, 0.3141, 0.0398, 0.0206, 0.0078, 0.0018,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0416, 0.0650, 0.1175, 0.2810, 0.3638, 0.0740, 0.0421, 0.0128, 0.0021,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0273, 0.0471, 0.0972, 0.2605, 0.3841, 0.0935, 0.0654, 0.0216, 0.0033,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0562, 0.0676, 0.0865, 0.2108, 0.3389, 0.1159, 0.0893, 0.0307, 0.0042,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0328, 0.0386, 0.0541, 0.1564, 0.2995, 0.1500, 0.1660, 0.0873, 0.0154,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0407, 0.0476, 0.0648, 0.1760, 0.3269, 0.1382, 0.1359, 0.0603, 0.0096,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0694, 0.0757, 0.0751, 0.1356, 0.2419, 0.1309, 0.1627, 0.0932, 0.0155,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0747, 0.0820, 0.0790, 0.1223, 0.1986, 0.1217, 0.1771, 0.1222, 0.0225,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0760, 0.0838, 0.0806, 0.1179, 0.1827, 0.1174, 0.1806, 0.1348, 0.0263,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0766, 0.0845, 0.0814, 0.1157, 0.1750, 0.1153, 0.1818, 0.1412, 0.0285,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0770, 0.0850, 0.0820, 0.1145, 0.1703, 0.1141, 0.1823, 0.1449, 0.0300,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0773, 0.0853, 0.0823, 0.1137, 0.1672, 0.1133, 0.1825, 0.1474, 0.0310,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0775, 0.0855, 0.0826, 0.1132, 0.1650, 0.1127, 0.1825, 0.1491, 0.0318,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0777, 0.0857, 0.0829, 0.1128, 0.1633, 0.1123, 0.1826, 0.1504, 0.0324,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 0.60, Train Loss: 0.00, Val Loss: 5.80, Train BLEU: 0.00, Val BLEU: 2.60, Minutes Elapsed: 55.69\n",
      "Sampling from val predictions...\n",
      "Source: 那 是 我 人生 中 最低 低落 的 时刻 之一 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: this was one of the lowest points in my life . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> and , i , i , , i <EOS> . . <EOS> <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.7537, 0.0352, 0.2108, 0.0001, 0.0001, 0.0000, 0.0000, 0.0000, 0.0001,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.7221, 0.0440, 0.2335, 0.0001, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0632, 0.0428, 0.8803, 0.0059, 0.0036, 0.0010, 0.0007, 0.0011, 0.0008,\n",
      "         0.0003, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0132, 0.0121, 0.9566, 0.0076, 0.0044, 0.0015, 0.0012, 0.0015, 0.0013,\n",
      "         0.0004, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0121, 0.0119, 0.9386, 0.0181, 0.0085, 0.0028, 0.0023, 0.0023, 0.0025,\n",
      "         0.0006, 0.0003, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0229, 0.0207, 0.8920, 0.0316, 0.0173, 0.0046, 0.0033, 0.0031, 0.0036,\n",
      "         0.0007, 0.0003, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0214, 0.0208, 0.8401, 0.0505, 0.0346, 0.0109, 0.0077, 0.0051, 0.0072,\n",
      "         0.0011, 0.0005, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0281, 0.0265, 0.8037, 0.0554, 0.0429, 0.0150, 0.0105, 0.0065, 0.0095,\n",
      "         0.0013, 0.0006, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0749, 0.0675, 0.6667, 0.0611, 0.0602, 0.0266, 0.0186, 0.0105, 0.0122,\n",
      "         0.0011, 0.0004, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1005, 0.0961, 0.4967, 0.0684, 0.0714, 0.0452, 0.0452, 0.0327, 0.0412,\n",
      "         0.0019, 0.0006, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0495, 0.0534, 0.2467, 0.0571, 0.0662, 0.0657, 0.1007, 0.1129, 0.2374,\n",
      "         0.0083, 0.0022, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0557, 0.0594, 0.1805, 0.0592, 0.0627, 0.0596, 0.0866, 0.1196, 0.2962,\n",
      "         0.0167, 0.0038, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0889, 0.0905, 0.2540, 0.0727, 0.0690, 0.0555, 0.0670, 0.0823, 0.1991,\n",
      "         0.0168, 0.0041, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0630, 0.0645, 0.1905, 0.0580, 0.0572, 0.0507, 0.0649, 0.0948, 0.2960,\n",
      "         0.0453, 0.0150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0646, 0.0655, 0.2552, 0.0586, 0.0551, 0.0480, 0.0623, 0.0858, 0.2676,\n",
      "         0.0288, 0.0086, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1089, 0.1041, 0.3246, 0.0692, 0.0629, 0.0482, 0.0541, 0.0599, 0.1445,\n",
      "         0.0177, 0.0058, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1189, 0.1134, 0.3311, 0.0708, 0.0652, 0.0490, 0.0537, 0.0569, 0.1199,\n",
      "         0.0160, 0.0053, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1223, 0.1167, 0.3336, 0.0716, 0.0662, 0.0494, 0.0538, 0.0559, 0.1106,\n",
      "         0.0151, 0.0050, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1239, 0.1183, 0.3349, 0.0722, 0.0668, 0.0496, 0.0538, 0.0554, 0.1056,\n",
      "         0.0146, 0.0048, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.66, Train Loss: 0.00, Val Loss: 5.80, Train BLEU: 0.00, Val BLEU: 3.34, Minutes Elapsed: 60.73\n",
      "Sampling from val predictions...\n",
      "Source: 事实 实是 康 纳 在 一个 周五 的 晚上 回到 家 告诉 我 他 辞掉 了 他 的 工作 他\n",
      "Reference: instead , <UNK> came home one friday evening and he told me that he had quit his job that\n",
      "Model: <SOS> and , the , i i i , i i , to . . . . . <EOS> .\n",
      "Attention Weights: tensor([[7.3082e-01, 9.8949e-03, 1.8067e-02, 1.6319e-02, 9.7914e-02, 4.6987e-02,\n",
      "         3.4414e-03, 1.8736e-02, 1.1331e-03, 1.5048e-03, 5.5812e-04, 3.8547e-03,\n",
      "         5.0632e-02, 8.3380e-05, 1.2204e-05, 1.9021e-05, 1.5853e-05, 2.0359e-06,\n",
      "         8.4031e-07, 2.3728e-06],\n",
      "        [3.6100e-01, 2.2830e-02, 6.7364e-02, 5.7900e-02, 2.1157e-01, 9.9073e-02,\n",
      "         1.5521e-02, 4.7642e-02, 5.7081e-03, 6.1564e-03, 2.1261e-03, 6.2002e-03,\n",
      "         9.5707e-02, 6.6784e-04, 1.2931e-04, 1.6424e-04, 1.6261e-04, 3.2094e-05,\n",
      "         1.3005e-05, 3.2296e-05],\n",
      "        [6.0216e-02, 3.5948e-02, 9.0614e-02, 8.9853e-02, 1.5982e-01, 1.2850e-01,\n",
      "         6.1948e-02, 8.5215e-02, 4.0072e-02, 3.8647e-02, 1.6021e-02, 3.4684e-02,\n",
      "         1.4145e-01, 8.2076e-03, 2.7505e-03, 2.1909e-03, 2.2027e-03, 7.1818e-04,\n",
      "         3.2727e-04, 6.2087e-04],\n",
      "        [9.0021e-03, 6.0173e-03, 2.3153e-02, 3.1614e-02, 7.0028e-02, 9.0130e-02,\n",
      "         4.7085e-02, 7.6193e-02, 4.7427e-02, 5.5310e-02, 2.2500e-02, 9.7047e-02,\n",
      "         3.9530e-01, 1.6168e-02, 4.7805e-03, 3.0357e-03, 3.3768e-03, 7.4656e-04,\n",
      "         3.4179e-04, 7.4826e-04],\n",
      "        [1.0372e-02, 7.5209e-03, 2.3485e-02, 3.2093e-02, 5.9408e-02, 7.8083e-02,\n",
      "         4.8594e-02, 7.3094e-02, 5.3594e-02, 6.3301e-02, 3.4593e-02, 1.1711e-01,\n",
      "         3.5041e-01, 2.7072e-02, 8.8513e-03, 5.1017e-03, 5.2175e-03, 9.7482e-04,\n",
      "         3.9663e-04, 7.2374e-04],\n",
      "        [2.8817e-03, 1.7133e-03, 4.3177e-03, 6.2660e-03, 1.4273e-02, 2.9135e-02,\n",
      "         1.5215e-02, 3.2200e-02, 2.5021e-02, 3.9470e-02, 1.9325e-02, 1.2581e-01,\n",
      "         6.3645e-01, 2.6736e-02, 8.5535e-03, 4.8226e-03, 5.6760e-03, 9.1499e-04,\n",
      "         3.7845e-04, 8.3817e-04],\n",
      "        [2.6490e-03, 1.7246e-03, 3.4831e-03, 4.5965e-03, 9.6306e-03, 1.9848e-02,\n",
      "         1.1682e-02, 2.4637e-02, 2.2838e-02, 3.9213e-02, 2.3743e-02, 1.5741e-01,\n",
      "         5.4540e-01, 6.2781e-02, 2.7369e-02, 1.6384e-02, 2.0080e-02, 3.0426e-03,\n",
      "         1.2691e-03, 2.2226e-03],\n",
      "        [2.3823e-03, 1.5547e-03, 2.5239e-03, 3.0440e-03, 5.3025e-03, 9.6224e-03,\n",
      "         6.0728e-03, 1.1455e-02, 1.1358e-02, 2.0392e-02, 1.3312e-02, 1.1815e-01,\n",
      "         6.1903e-01, 6.3289e-02, 3.4799e-02, 2.4831e-02, 3.8726e-02, 6.0273e-03,\n",
      "         2.8791e-03, 5.2504e-03],\n",
      "        [2.9881e-03, 2.0821e-03, 3.0376e-03, 3.4497e-03, 5.5605e-03, 8.9978e-03,\n",
      "         6.0899e-03, 1.0574e-02, 1.0672e-02, 1.8208e-02, 1.2888e-02, 9.7484e-02,\n",
      "         5.1482e-01, 7.8455e-02, 5.2574e-02, 4.6371e-02, 8.2572e-02, 1.7177e-02,\n",
      "         9.7305e-03, 1.6269e-02],\n",
      "        [5.2044e-03, 3.4906e-03, 4.6953e-03, 5.2236e-03, 7.4752e-03, 1.0456e-02,\n",
      "         7.4830e-03, 1.0880e-02, 1.0717e-02, 1.5941e-02, 1.1773e-02, 7.2644e-02,\n",
      "         4.7468e-01, 5.8423e-02, 4.4370e-02, 4.8558e-02, 1.1162e-01, 3.0289e-02,\n",
      "         2.0243e-02, 4.5835e-02],\n",
      "        [7.3945e-03, 5.0396e-03, 6.5105e-03, 7.1198e-03, 9.6575e-03, 1.2591e-02,\n",
      "         9.4043e-03, 1.2533e-02, 1.2364e-02, 1.6900e-02, 1.2894e-02, 6.5665e-02,\n",
      "         3.8059e-01, 4.8535e-02, 3.9726e-02, 4.6287e-02, 1.2188e-01, 4.1919e-02,\n",
      "         3.6558e-02, 1.0643e-01],\n",
      "        [4.4477e-03, 3.3366e-03, 4.2485e-03, 4.5679e-03, 6.2434e-03, 8.2602e-03,\n",
      "         6.3080e-03, 8.6274e-03, 8.8769e-03, 1.2595e-02, 9.8216e-03, 5.6690e-02,\n",
      "         3.1922e-01, 4.6520e-02, 3.9851e-02, 4.8685e-02, 1.3020e-01, 5.4866e-02,\n",
      "         5.9782e-02, 1.6686e-01],\n",
      "        [6.3533e-03, 5.1201e-03, 6.0630e-03, 6.2701e-03, 8.4505e-03, 1.0632e-02,\n",
      "         8.3678e-03, 1.1230e-02, 1.0978e-02, 1.4118e-02, 1.1845e-02, 3.3129e-02,\n",
      "         1.1582e-01, 4.2752e-02, 4.1429e-02, 5.6626e-02, 1.3742e-01, 9.6211e-02,\n",
      "         1.1105e-01, 2.6613e-01],\n",
      "        [1.0124e-02, 7.9393e-03, 8.9464e-03, 9.2689e-03, 1.1729e-02, 1.4104e-02,\n",
      "         1.1351e-02, 1.4043e-02, 1.3735e-02, 1.6540e-02, 1.4053e-02, 3.8033e-02,\n",
      "         1.1470e-01, 3.2918e-02, 3.0657e-02, 3.8484e-02, 9.2594e-02, 6.4192e-02,\n",
      "         8.6338e-02, 3.7025e-01],\n",
      "        [1.7791e-02, 1.4203e-02, 1.5623e-02, 1.6101e-02, 1.9750e-02, 2.3098e-02,\n",
      "         1.8949e-02, 2.2566e-02, 2.1754e-02, 2.4891e-02, 2.1773e-02, 4.5969e-02,\n",
      "         9.9334e-02, 3.7478e-02, 3.5150e-02, 4.0401e-02, 7.4935e-02, 5.8079e-02,\n",
      "         7.3642e-02, 3.1851e-01],\n",
      "        [2.0640e-02, 1.6839e-02, 1.8223e-02, 1.8577e-02, 2.2673e-02, 2.6052e-02,\n",
      "         2.1731e-02, 2.5663e-02, 2.4915e-02, 2.8248e-02, 2.4829e-02, 5.0639e-02,\n",
      "         1.0194e-01, 4.0692e-02, 3.7808e-02, 4.1847e-02, 7.0718e-02, 5.5022e-02,\n",
      "         6.9355e-02, 2.8359e-01],\n",
      "        [2.5720e-02, 2.1312e-02, 2.3018e-02, 2.3445e-02, 2.8316e-02, 3.2157e-02,\n",
      "         2.7064e-02, 3.1559e-02, 3.0378e-02, 3.3786e-02, 3.0150e-02, 5.4795e-02,\n",
      "         9.4813e-02, 4.5269e-02, 4.2466e-02, 4.5629e-02, 6.8340e-02, 5.5362e-02,\n",
      "         6.5980e-02, 2.2044e-01],\n",
      "        [2.8892e-02, 2.2661e-02, 2.4114e-02, 2.4777e-02, 2.9917e-02, 3.5033e-02,\n",
      "         2.8861e-02, 3.3380e-02, 3.2575e-02, 3.6466e-02, 3.2090e-02, 6.5000e-02,\n",
      "         1.0999e-01, 4.5973e-02, 4.3520e-02, 4.5195e-02, 6.3766e-02, 5.1178e-02,\n",
      "         6.1847e-02, 1.8477e-01],\n",
      "        [3.6294e-02, 2.8401e-02, 3.0517e-02, 3.1910e-02, 3.7366e-02, 4.3070e-02,\n",
      "         3.6124e-02, 4.0883e-02, 4.0010e-02, 4.4313e-02, 3.9280e-02, 7.2554e-02,\n",
      "         1.1361e-01, 5.0650e-02, 4.7066e-02, 4.7531e-02, 5.8984e-02, 4.6134e-02,\n",
      "         5.1898e-02, 1.0341e-01]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 0.71, Train Loss: 0.00, Val Loss: 5.81, Train BLEU: 0.00, Val BLEU: 2.91, Minutes Elapsed: 65.80\n",
      "Sampling from val predictions...\n",
      "Source: 我 曾经 <UNK> 以为 只有 我 一个 个人 有 这样 的 遭遇 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: i was mistaken in thinking that i was unique and alone in this situation . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> i i , , i , i i a . . . <EOS> . . <EOS> <EOS> . <EOS>\n",
      "Attention Weights: tensor([[0.9511, 0.0175, 0.0002, 0.0308, 0.0001, 0.0003, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.9114, 0.0317, 0.0007, 0.0512, 0.0003, 0.0046, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2927, 0.1624, 0.0521, 0.2852, 0.0276, 0.1610, 0.0053, 0.0042, 0.0028,\n",
      "         0.0036, 0.0016, 0.0008, 0.0007, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0330, 0.0655, 0.0915, 0.2802, 0.1406, 0.3203, 0.0364, 0.0175, 0.0056,\n",
      "         0.0064, 0.0018, 0.0007, 0.0004, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0315, 0.0432, 0.0570, 0.3029, 0.1051, 0.4130, 0.0229, 0.0125, 0.0041,\n",
      "         0.0053, 0.0014, 0.0006, 0.0004, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0201, 0.0087, 0.0094, 0.1270, 0.0429, 0.7547, 0.0192, 0.0112, 0.0022,\n",
      "         0.0038, 0.0005, 0.0002, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0185, 0.0063, 0.0065, 0.0823, 0.0323, 0.7933, 0.0277, 0.0212, 0.0036,\n",
      "         0.0071, 0.0008, 0.0003, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0160, 0.0042, 0.0034, 0.0351, 0.0109, 0.8527, 0.0268, 0.0327, 0.0050,\n",
      "         0.0120, 0.0007, 0.0002, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0129, 0.0070, 0.0065, 0.0335, 0.0189, 0.5900, 0.0999, 0.1372, 0.0320,\n",
      "         0.0575, 0.0033, 0.0008, 0.0004, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0037, 0.0046, 0.0051, 0.0120, 0.0118, 0.1406, 0.1333, 0.2326, 0.1643,\n",
      "         0.2299, 0.0496, 0.0097, 0.0031, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0052, 0.0049, 0.0046, 0.0114, 0.0093, 0.1647, 0.0767, 0.1905, 0.1377,\n",
      "         0.3260, 0.0566, 0.0096, 0.0028, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0151, 0.0068, 0.0061, 0.0207, 0.0104, 0.1756, 0.0237, 0.0909, 0.0627,\n",
      "         0.5290, 0.0499, 0.0072, 0.0018, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0224, 0.0080, 0.0073, 0.0259, 0.0119, 0.1632, 0.0180, 0.0679, 0.0496,\n",
      "         0.5317, 0.0730, 0.0167, 0.0046, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0352, 0.0184, 0.0163, 0.0456, 0.0247, 0.1684, 0.0225, 0.0510, 0.0387,\n",
      "         0.4759, 0.0717, 0.0234, 0.0081, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0408, 0.0148, 0.0140, 0.0451, 0.0227, 0.1378, 0.0211, 0.0496, 0.0407,\n",
      "         0.4408, 0.1031, 0.0481, 0.0215, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0655, 0.0330, 0.0302, 0.0790, 0.0430, 0.2100, 0.0332, 0.0559, 0.0405,\n",
      "         0.2905, 0.0655, 0.0348, 0.0189, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0790, 0.0443, 0.0397, 0.0949, 0.0560, 0.2225, 0.0420, 0.0611, 0.0451,\n",
      "         0.2059, 0.0562, 0.0328, 0.0206, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0812, 0.0447, 0.0407, 0.0930, 0.0528, 0.2337, 0.0396, 0.0580, 0.0421,\n",
      "         0.1860, 0.0538, 0.0400, 0.0343, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0933, 0.0364, 0.0328, 0.0990, 0.0470, 0.2662, 0.0308, 0.0508, 0.0347,\n",
      "         0.1992, 0.0511, 0.0337, 0.0249, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.77, Train Loss: 0.00, Val Loss: 5.87, Train BLEU: 0.00, Val BLEU: 3.74, Minutes Elapsed: 70.88\n",
      "Sampling from val predictions...\n",
      "Source: 我 能够 结束 自己 疯狂 的 爱 的 故事 靠 的 是 打破 沉默 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: i was able to end my own crazy love story by breaking the silence . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> i &apos;m to to to to the , , the the <EOS> . <EOS> . <EOS> <EOS> . <EOS>\n",
      "Attention Weights: tensor([[0.9941, 0.0058, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.9393, 0.0595, 0.0009, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2786, 0.5369, 0.0942, 0.0605, 0.0094, 0.0046, 0.0035, 0.0024, 0.0010,\n",
      "         0.0021, 0.0019, 0.0020, 0.0008, 0.0012, 0.0011, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0271, 0.1464, 0.2135, 0.3389, 0.1365, 0.0563, 0.0315, 0.0207, 0.0074,\n",
      "         0.0085, 0.0054, 0.0042, 0.0015, 0.0013, 0.0007, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0126, 0.0728, 0.1240, 0.3731, 0.1827, 0.0854, 0.0581, 0.0360, 0.0140,\n",
      "         0.0167, 0.0101, 0.0078, 0.0030, 0.0025, 0.0012, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0094, 0.0289, 0.0498, 0.2772, 0.2125, 0.1291, 0.1215, 0.0706, 0.0259,\n",
      "         0.0348, 0.0178, 0.0129, 0.0043, 0.0038, 0.0016, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0073, 0.0193, 0.0317, 0.1915, 0.1968, 0.1450, 0.1569, 0.0992, 0.0406,\n",
      "         0.0525, 0.0266, 0.0187, 0.0064, 0.0054, 0.0021, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0108, 0.0157, 0.0191, 0.1152, 0.1451, 0.1294, 0.2032, 0.1308, 0.0587,\n",
      "         0.0915, 0.0388, 0.0255, 0.0074, 0.0068, 0.0020, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0116, 0.0146, 0.0156, 0.0804, 0.1170, 0.1149, 0.2045, 0.1422, 0.0731,\n",
      "         0.1173, 0.0514, 0.0346, 0.0105, 0.0097, 0.0025, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0107, 0.0128, 0.0122, 0.0480, 0.0815, 0.0930, 0.1892, 0.1512, 0.0911,\n",
      "         0.1533, 0.0738, 0.0508, 0.0152, 0.0137, 0.0033, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0208, 0.0181, 0.0132, 0.0366, 0.0533, 0.0636, 0.1615, 0.1392, 0.0989,\n",
      "         0.1860, 0.0995, 0.0712, 0.0184, 0.0166, 0.0030, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0222, 0.0193, 0.0139, 0.0284, 0.0326, 0.0382, 0.1117, 0.1104, 0.0960,\n",
      "         0.1918, 0.1373, 0.1205, 0.0386, 0.0339, 0.0054, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0356, 0.0290, 0.0226, 0.0372, 0.0338, 0.0354, 0.0896, 0.0892, 0.0819,\n",
      "         0.1720, 0.1372, 0.1357, 0.0499, 0.0446, 0.0063, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0393, 0.0276, 0.0188, 0.0328, 0.0286, 0.0287, 0.0709, 0.0738, 0.0749,\n",
      "         0.1600, 0.1427, 0.1527, 0.0692, 0.0684, 0.0115, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0563, 0.0471, 0.0383, 0.0541, 0.0429, 0.0398, 0.0634, 0.0603, 0.0571,\n",
      "         0.1157, 0.1152, 0.1406, 0.0728, 0.0820, 0.0143, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0616, 0.0434, 0.0303, 0.0483, 0.0379, 0.0335, 0.0614, 0.0576, 0.0585,\n",
      "         0.1198, 0.1168, 0.1410, 0.0785, 0.0933, 0.0181, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0747, 0.0632, 0.0516, 0.0694, 0.0542, 0.0487, 0.0646, 0.0563, 0.0507,\n",
      "         0.0885, 0.0876, 0.1118, 0.0676, 0.0900, 0.0211, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0743, 0.0647, 0.0499, 0.0647, 0.0513, 0.0430, 0.0594, 0.0493, 0.0462,\n",
      "         0.0765, 0.0779, 0.1075, 0.0747, 0.1177, 0.0428, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0974, 0.0720, 0.0492, 0.0740, 0.0509, 0.0405, 0.0615, 0.0478, 0.0436,\n",
      "         0.0800, 0.0779, 0.1067, 0.0688, 0.0994, 0.0303, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 0.82, Train Loss: 0.00, Val Loss: 5.69, Train BLEU: 0.00, Val BLEU: 3.34, Minutes Elapsed: 75.94\n",
      "Sampling from val predictions...\n",
      "Source: 神经 神经学 经学 测试 是 无 创 性 的 而且 他们 都 使用 现有 的 基础 设备 <EOS> <PAD> <PAD>\n",
      "Reference: the neurologist &apos;s test is non-invasive . they both use existing infrastructure . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> the is of the , the the , &apos;s a to to the <EOS> the . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0007, 0.0004, 0.0177, 0.1157, 0.8421, 0.0147, 0.0016, 0.0021, 0.0036,\n",
      "         0.0007, 0.0005, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0020, 0.0010, 0.0327, 0.1462, 0.7927, 0.0173, 0.0022, 0.0022, 0.0030,\n",
      "         0.0003, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0082, 0.0096, 0.1027, 0.2066, 0.4203, 0.1423, 0.0325, 0.0296, 0.0210,\n",
      "         0.0096, 0.0085, 0.0027, 0.0010, 0.0018, 0.0013, 0.0008, 0.0006, 0.0010,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0054, 0.0090, 0.1018, 0.1641, 0.3822, 0.2037, 0.0446, 0.0385, 0.0237,\n",
      "         0.0101, 0.0100, 0.0025, 0.0009, 0.0013, 0.0009, 0.0005, 0.0003, 0.0004,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0021, 0.0044, 0.0583, 0.0911, 0.2938, 0.2845, 0.0823, 0.0840, 0.0515,\n",
      "         0.0197, 0.0246, 0.0021, 0.0004, 0.0006, 0.0003, 0.0002, 0.0001, 0.0001,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0013, 0.0031, 0.0508, 0.0820, 0.2923, 0.2880, 0.0789, 0.0867, 0.0563,\n",
      "         0.0244, 0.0320, 0.0024, 0.0004, 0.0007, 0.0003, 0.0001, 0.0001, 0.0001,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0016, 0.0031, 0.0282, 0.0420, 0.1407, 0.2205, 0.1011, 0.1398, 0.1115,\n",
      "         0.0684, 0.1335, 0.0069, 0.0008, 0.0011, 0.0004, 0.0001, 0.0001, 0.0001,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0015, 0.0027, 0.0147, 0.0200, 0.0562, 0.1119, 0.0843, 0.1281, 0.1218,\n",
      "         0.1290, 0.2873, 0.0308, 0.0054, 0.0046, 0.0012, 0.0005, 0.0001, 0.0001,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0021, 0.0036, 0.0149, 0.0186, 0.0429, 0.0823, 0.0621, 0.0972, 0.0919,\n",
      "         0.1089, 0.4143, 0.0438, 0.0081, 0.0066, 0.0017, 0.0007, 0.0002, 0.0001,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0017, 0.0025, 0.0095, 0.0117, 0.0259, 0.0518, 0.0450, 0.0757, 0.0797,\n",
      "         0.1175, 0.4091, 0.1083, 0.0311, 0.0239, 0.0047, 0.0014, 0.0003, 0.0002,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0014, 0.0020, 0.0055, 0.0063, 0.0118, 0.0202, 0.0216, 0.0359, 0.0398,\n",
      "         0.0690, 0.3511, 0.1918, 0.1078, 0.1006, 0.0250, 0.0084, 0.0014, 0.0005,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0013, 0.0017, 0.0041, 0.0046, 0.0076, 0.0109, 0.0108, 0.0170, 0.0192,\n",
      "         0.0347, 0.2824, 0.1962, 0.1434, 0.1830, 0.0574, 0.0220, 0.0030, 0.0009,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0021, 0.0028, 0.0057, 0.0062, 0.0092, 0.0118, 0.0110, 0.0156, 0.0173,\n",
      "         0.0277, 0.2288, 0.1683, 0.1393, 0.2318, 0.0829, 0.0346, 0.0040, 0.0010,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0041, 0.0055, 0.0107, 0.0118, 0.0157, 0.0181, 0.0156, 0.0201, 0.0218,\n",
      "         0.0309, 0.1727, 0.1280, 0.1203, 0.2501, 0.1098, 0.0571, 0.0064, 0.0014,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0109, 0.0145, 0.0316, 0.0342, 0.0441, 0.0460, 0.0342, 0.0431, 0.0466,\n",
      "         0.0566, 0.1679, 0.0989, 0.0771, 0.1632, 0.0778, 0.0451, 0.0065, 0.0016,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0095, 0.0113, 0.0205, 0.0217, 0.0251, 0.0280, 0.0217, 0.0264, 0.0263,\n",
      "         0.0347, 0.1396, 0.0799, 0.0795, 0.2045, 0.1238, 0.1158, 0.0251, 0.0064,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0098, 0.0125, 0.0282, 0.0304, 0.0387, 0.0418, 0.0301, 0.0368, 0.0382,\n",
      "         0.0507, 0.1450, 0.0789, 0.0694, 0.1571, 0.1034, 0.0978, 0.0240, 0.0072,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0153, 0.0207, 0.0522, 0.0605, 0.0834, 0.0774, 0.0533, 0.0642, 0.0702,\n",
      "         0.0764, 0.1355, 0.0689, 0.0443, 0.0798, 0.0488, 0.0363, 0.0095, 0.0034,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0172, 0.0227, 0.0570, 0.0677, 0.0937, 0.0829, 0.0568, 0.0684, 0.0754,\n",
      "         0.0806, 0.1282, 0.0652, 0.0387, 0.0632, 0.0392, 0.0304, 0.0090, 0.0037,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 0.88, Train Loss: 0.00, Val Loss: 5.69, Train BLEU: 0.00, Val BLEU: 3.43, Minutes Elapsed: 81.04\n",
      "Sampling from val predictions...\n",
      "Source: 但 如果 病人 能 在家 完成 这个 测试 呢 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: but what if patients could do this test at home ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> but you can do do the the ? ? <EOS> ? <EOS> <EOS> ? <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.1890, 0.8062, 0.0005, 0.0012, 0.0000, 0.0000, 0.0005, 0.0000, 0.0022,\n",
      "         0.0003, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0531, 0.9249, 0.0038, 0.0070, 0.0003, 0.0003, 0.0025, 0.0005, 0.0057,\n",
      "         0.0017, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0425, 0.9048, 0.0161, 0.0214, 0.0008, 0.0007, 0.0049, 0.0008, 0.0058,\n",
      "         0.0023, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0257, 0.5656, 0.1522, 0.2259, 0.0090, 0.0033, 0.0093, 0.0016, 0.0051,\n",
      "         0.0023, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0147, 0.1762, 0.1231, 0.6017, 0.0422, 0.0095, 0.0230, 0.0022, 0.0057,\n",
      "         0.0017, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0060, 0.0444, 0.0508, 0.5569, 0.1831, 0.0508, 0.0931, 0.0050, 0.0085,\n",
      "         0.0014, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0083, 0.0366, 0.0210, 0.2212, 0.1271, 0.0761, 0.4527, 0.0142, 0.0391,\n",
      "         0.0037, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0044, 0.0152, 0.0106, 0.0578, 0.0600, 0.0704, 0.6522, 0.0361, 0.0882,\n",
      "         0.0052, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0038, 0.0127, 0.0089, 0.0303, 0.0320, 0.0471, 0.5401, 0.0807, 0.2335,\n",
      "         0.0109, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0102, 0.0305, 0.0180, 0.0459, 0.0359, 0.0463, 0.5030, 0.0655, 0.2363,\n",
      "         0.0085, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0133, 0.0405, 0.0187, 0.0463, 0.0258, 0.0326, 0.4383, 0.0572, 0.3167,\n",
      "         0.0105, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0091, 0.0264, 0.0142, 0.0341, 0.0237, 0.0310, 0.3878, 0.0748, 0.3797,\n",
      "         0.0192, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0216, 0.0559, 0.0262, 0.0549, 0.0283, 0.0319, 0.3405, 0.0612, 0.3621,\n",
      "         0.0173, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0149, 0.0427, 0.0213, 0.0424, 0.0231, 0.0244, 0.2599, 0.0659, 0.4449,\n",
      "         0.0605, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0172, 0.0618, 0.0253, 0.0584, 0.0273, 0.0268, 0.3070, 0.0608, 0.3867,\n",
      "         0.0287, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0306, 0.0839, 0.0348, 0.0744, 0.0326, 0.0320, 0.2627, 0.0544, 0.3659,\n",
      "         0.0286, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0355, 0.0972, 0.0382, 0.0819, 0.0338, 0.0331, 0.2453, 0.0525, 0.3532,\n",
      "         0.0292, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0381, 0.1028, 0.0402, 0.0851, 0.0347, 0.0338, 0.2351, 0.0517, 0.3478,\n",
      "         0.0307, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0398, 0.1066, 0.0416, 0.0875, 0.0354, 0.0345, 0.2285, 0.0512, 0.3431,\n",
      "         0.0318, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.93, Train Loss: 0.00, Val Loss: 5.75, Train BLEU: 0.00, Val BLEU: 3.65, Minutes Elapsed: 86.12\n",
      "Sampling from val predictions...\n",
      "Source: 27 岁 时 我 做出 一个 决定 只 基于 人们 的 需求 提供 提供援助 援助 我 创立 了 一套 工作\n",
      "Reference: i decided when i was 27 years old to only respond to people , and i invented a system\n",
      "Model: <SOS> i i to to the to , and , , , . . . <EOS> . . . <EOS>\n",
      "Attention Weights: tensor([[5.3005e-04, 7.5433e-03, 1.8679e-01, 8.0422e-01, 5.1440e-04, 1.8013e-04,\n",
      "         1.0196e-04, 5.6642e-05, 8.9066e-06, 4.0099e-05, 1.8845e-06, 9.5221e-07,\n",
      "         4.8574e-07, 7.0377e-07, 1.6002e-06, 1.0179e-05, 9.0752e-08, 1.6808e-07,\n",
      "         1.3340e-07, 1.8132e-07],\n",
      "        [1.6853e-03, 2.0949e-02, 2.1279e-01, 7.6274e-01, 1.0953e-03, 3.8615e-04,\n",
      "         1.7814e-04, 1.0795e-04, 1.2660e-05, 4.1695e-05, 3.2854e-06, 1.0662e-06,\n",
      "         5.9550e-07, 7.4261e-07, 1.9921e-06, 7.6480e-06, 1.4341e-07, 2.5923e-07,\n",
      "         1.3801e-07, 1.4697e-07],\n",
      "        [4.5900e-03, 2.0091e-02, 7.2747e-02, 7.0222e-01, 7.6994e-02, 3.1610e-02,\n",
      "         4.3340e-02, 2.3647e-02, 5.1096e-03, 1.4814e-02, 1.3291e-03, 4.9273e-04,\n",
      "         2.1447e-04, 2.2385e-04, 5.0955e-04, 1.9299e-03, 3.5935e-05, 7.0877e-05,\n",
      "         2.2289e-05, 1.2652e-05],\n",
      "        [5.0402e-03, 8.1620e-03, 1.5967e-02, 1.2388e-01, 1.2133e-01, 1.4098e-01,\n",
      "         1.4517e-01, 1.3659e-01, 7.2720e-02, 1.4284e-01, 3.3561e-02, 1.4078e-02,\n",
      "         5.5773e-03, 3.8797e-03, 6.1792e-03, 2.1210e-02, 1.2279e-03, 1.0737e-03,\n",
      "         3.6837e-04, 1.7270e-04],\n",
      "        [1.2585e-03, 1.8231e-03, 3.3023e-03, 4.2432e-02, 2.6660e-02, 4.4230e-02,\n",
      "         6.9023e-02, 8.4115e-02, 8.7128e-02, 3.0306e-01, 7.5201e-02, 5.9889e-02,\n",
      "         2.4215e-02, 1.6338e-02, 2.4738e-02, 1.2687e-01, 4.4907e-03, 3.5246e-03,\n",
      "         1.1577e-03, 5.4033e-04],\n",
      "        [7.5815e-04, 9.9157e-04, 1.6683e-03, 1.5393e-02, 7.9639e-03, 1.2578e-02,\n",
      "         2.1735e-02, 2.9000e-02, 4.5014e-02, 2.3851e-01, 6.5567e-02, 1.0127e-01,\n",
      "         5.8012e-02, 4.2537e-02, 5.1659e-02, 2.7863e-01, 1.3985e-02, 1.0210e-02,\n",
      "         3.1384e-03, 1.3730e-03],\n",
      "        [7.7204e-04, 9.5477e-04, 1.4884e-03, 1.0245e-02, 7.2727e-03, 1.1594e-02,\n",
      "         1.7030e-02, 2.3897e-02, 3.8615e-02, 2.0340e-01, 6.6541e-02, 1.0311e-01,\n",
      "         6.7144e-02, 4.9271e-02, 4.9314e-02, 2.9340e-01, 2.7643e-02, 2.0348e-02,\n",
      "         5.8523e-03, 2.1078e-03],\n",
      "        [6.4652e-04, 8.4121e-04, 1.4530e-03, 6.8158e-03, 3.6218e-03, 4.3538e-03,\n",
      "         7.1249e-03, 9.0167e-03, 1.4824e-02, 1.2458e-01, 2.9032e-02, 7.7387e-02,\n",
      "         6.3660e-02, 5.2505e-02, 4.9795e-02, 4.4355e-01, 4.4921e-02, 4.2989e-02,\n",
      "         1.5478e-02, 7.4075e-03],\n",
      "        [8.0003e-04, 1.0932e-03, 1.9779e-03, 9.5430e-03, 3.0639e-03, 2.9177e-03,\n",
      "         5.2125e-03, 5.6148e-03, 6.9950e-03, 7.0175e-02, 1.1365e-02, 3.8096e-02,\n",
      "         3.5447e-02, 3.4249e-02, 3.5299e-02, 5.7327e-01, 4.8034e-02, 7.2963e-02,\n",
      "         2.9166e-02, 1.4717e-02],\n",
      "        [9.8642e-04, 1.3779e-03, 2.5865e-03, 1.1312e-02, 3.1024e-03, 2.6648e-03,\n",
      "         5.0128e-03, 4.9183e-03, 5.2785e-03, 4.1501e-02, 7.1988e-03, 2.5662e-02,\n",
      "         2.5948e-02, 2.5912e-02, 2.7078e-02, 5.0319e-01, 5.8290e-02, 1.0881e-01,\n",
      "         7.5893e-02, 6.3280e-02],\n",
      "        [1.4782e-03, 2.0466e-03, 3.7312e-03, 1.5248e-02, 4.1517e-03, 3.4496e-03,\n",
      "         6.3016e-03, 5.9867e-03, 5.8000e-03, 3.2486e-02, 6.8915e-03, 2.0100e-02,\n",
      "         2.0164e-02, 2.0343e-02, 2.1887e-02, 4.1825e-01, 5.1530e-02, 1.1158e-01,\n",
      "         1.0920e-01, 1.3937e-01],\n",
      "        [1.7476e-03, 2.0034e-03, 3.0388e-03, 9.7069e-03, 5.3660e-03, 4.9906e-03,\n",
      "         6.8859e-03, 7.0633e-03, 7.3441e-03, 2.5389e-02, 8.9381e-03, 1.8914e-02,\n",
      "         1.9209e-02, 1.8014e-02, 1.5115e-02, 2.6218e-01, 6.1134e-02, 1.2662e-01,\n",
      "         1.6459e-01, 2.3175e-01],\n",
      "        [2.8611e-03, 3.3681e-03, 5.1926e-03, 1.8333e-02, 7.7320e-03, 6.8545e-03,\n",
      "         1.0308e-02, 1.0023e-02, 9.8100e-03, 3.0536e-02, 1.0725e-02, 2.1111e-02,\n",
      "         2.0699e-02, 2.0286e-02, 2.0054e-02, 2.2880e-01, 4.7137e-02, 9.6348e-02,\n",
      "         1.4418e-01, 2.8564e-01],\n",
      "        [5.8602e-03, 6.9821e-03, 1.0852e-02, 3.8692e-02, 1.4495e-02, 1.2832e-02,\n",
      "         1.8421e-02, 1.7578e-02, 1.6843e-02, 4.4435e-02, 1.6834e-02, 2.7614e-02,\n",
      "         2.5793e-02, 2.5796e-02, 2.8085e-02, 1.9082e-01, 4.2381e-02, 7.9218e-02,\n",
      "         1.1841e-01, 2.5805e-01],\n",
      "        [7.2393e-03, 7.5547e-03, 1.0510e-02, 3.3143e-02, 1.9321e-02, 1.8160e-02,\n",
      "         2.2766e-02, 2.2783e-02, 2.2312e-02, 4.6788e-02, 2.3344e-02, 3.3174e-02,\n",
      "         3.0754e-02, 2.9028e-02, 2.8217e-02, 1.5084e-01, 4.6579e-02, 7.7029e-02,\n",
      "         1.1906e-01, 2.5139e-01],\n",
      "        [1.1692e-02, 1.2944e-02, 1.9019e-02, 7.0026e-02, 2.8277e-02, 2.5759e-02,\n",
      "         3.3056e-02, 3.1053e-02, 3.0573e-02, 6.9834e-02, 2.8706e-02, 3.9579e-02,\n",
      "         3.6014e-02, 3.6769e-02, 3.8101e-02, 1.7404e-01, 3.9848e-02, 5.8786e-02,\n",
      "         7.4631e-02, 1.4129e-01],\n",
      "        [1.2570e-02, 1.3278e-02, 1.8670e-02, 6.1981e-02, 2.7187e-02, 2.5173e-02,\n",
      "         3.2917e-02, 3.0139e-02, 3.1601e-02, 6.7093e-02, 2.8983e-02, 4.3826e-02,\n",
      "         3.9730e-02, 4.0254e-02, 4.2155e-02, 1.7548e-01, 4.1130e-02, 5.6224e-02,\n",
      "         7.2291e-02, 1.3932e-01],\n",
      "        [1.4145e-02, 1.6722e-02, 2.5273e-02, 8.7731e-02, 2.7962e-02, 2.3009e-02,\n",
      "         3.6048e-02, 3.0986e-02, 3.1437e-02, 7.3574e-02, 2.7188e-02, 4.5407e-02,\n",
      "         4.0878e-02, 4.3520e-02, 5.0474e-02, 1.9032e-01, 3.5066e-02, 4.5623e-02,\n",
      "         5.3950e-02, 1.0069e-01],\n",
      "        [1.0343e-02, 1.0587e-02, 1.5027e-02, 4.7042e-02, 3.8645e-02, 3.8177e-02,\n",
      "         4.1086e-02, 4.4029e-02, 4.1974e-02, 7.4071e-02, 4.6877e-02, 5.5396e-02,\n",
      "         4.9268e-02, 4.2950e-02, 3.8683e-02, 1.1976e-01, 5.5971e-02, 6.8382e-02,\n",
      "         7.0743e-02, 9.0989e-02]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 0.99, Train Loss: 0.00, Val Loss: 5.67, Train BLEU: 0.00, Val BLEU: 3.84, Minutes Elapsed: 91.21\n",
      "Sampling from val predictions...\n",
      "Source: 肯尼 肯尼亚 尼亚 生长 着 八种 <UNK> 其中 的 六种 正 濒临 濒临灭绝 灭绝 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: we have eight species of <UNK> that occur in kenya , of which six are highly threatened with extinction\n",
      "Model: <SOS> the <UNK> a a the the of the the the . . . . . . . . <EOS>\n",
      "Attention Weights: tensor([[0.0003, 0.0023, 0.0068, 0.0236, 0.8202, 0.0015, 0.0051, 0.0733, 0.0416,\n",
      "         0.0056, 0.0023, 0.0015, 0.0010, 0.0050, 0.0098, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0006, 0.0045, 0.0110, 0.0358, 0.8725, 0.0013, 0.0034, 0.0408, 0.0173,\n",
      "         0.0022, 0.0010, 0.0007, 0.0005, 0.0022, 0.0062, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0025, 0.0124, 0.0246, 0.0645, 0.6925, 0.0037, 0.0099, 0.0744, 0.0400,\n",
      "         0.0085, 0.0046, 0.0033, 0.0028, 0.0145, 0.0419, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0007, 0.0033, 0.0125, 0.0338, 0.3124, 0.0361, 0.0819, 0.2819, 0.1740,\n",
      "         0.0388, 0.0123, 0.0061, 0.0022, 0.0024, 0.0016, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0002, 0.0009, 0.0031, 0.0091, 0.1273, 0.0270, 0.0828, 0.3134, 0.2981,\n",
      "         0.0845, 0.0286, 0.0133, 0.0044, 0.0046, 0.0026, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0003, 0.0012, 0.0039, 0.0113, 0.1079, 0.0346, 0.0988, 0.2362, 0.3175,\n",
      "         0.1234, 0.0394, 0.0140, 0.0043, 0.0050, 0.0021, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0002, 0.0008, 0.0022, 0.0060, 0.0512, 0.0245, 0.0754, 0.1833, 0.3398,\n",
      "         0.2023, 0.0726, 0.0253, 0.0066, 0.0073, 0.0023, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0004, 0.0014, 0.0040, 0.0107, 0.0698, 0.0327, 0.0923, 0.1766, 0.3044,\n",
      "         0.1936, 0.0745, 0.0241, 0.0065, 0.0067, 0.0021, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0009, 0.0026, 0.0053, 0.0116, 0.0516, 0.0279, 0.0736, 0.1255, 0.2473,\n",
      "         0.2449, 0.1249, 0.0506, 0.0139, 0.0152, 0.0040, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0005, 0.0012, 0.0024, 0.0046, 0.0220, 0.0122, 0.0360, 0.0825, 0.1904,\n",
      "         0.2625, 0.1858, 0.1192, 0.0385, 0.0340, 0.0083, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0007, 0.0016, 0.0032, 0.0061, 0.0272, 0.0122, 0.0346, 0.0755, 0.1638,\n",
      "         0.2364, 0.1868, 0.1377, 0.0527, 0.0493, 0.0120, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0011, 0.0028, 0.0053, 0.0102, 0.0346, 0.0204, 0.0509, 0.0873, 0.1709,\n",
      "         0.2366, 0.1805, 0.1141, 0.0409, 0.0357, 0.0087, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0027, 0.0061, 0.0103, 0.0179, 0.0507, 0.0248, 0.0524, 0.0834, 0.1480,\n",
      "         0.1948, 0.1608, 0.1201, 0.0571, 0.0576, 0.0134, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0011, 0.0026, 0.0046, 0.0083, 0.0237, 0.0123, 0.0285, 0.0483, 0.1022,\n",
      "         0.1829, 0.1632, 0.1692, 0.1028, 0.1204, 0.0296, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0013, 0.0035, 0.0065, 0.0129, 0.0385, 0.0190, 0.0454, 0.0689, 0.1304,\n",
      "         0.1890, 0.1633, 0.1368, 0.0762, 0.0873, 0.0209, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0016, 0.0038, 0.0070, 0.0134, 0.0414, 0.0176, 0.0392, 0.0634, 0.1126,\n",
      "         0.1627, 0.1491, 0.1430, 0.0939, 0.1182, 0.0331, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0027, 0.0063, 0.0107, 0.0189, 0.0490, 0.0236, 0.0479, 0.0708, 0.1201,\n",
      "         0.1649, 0.1481, 0.1293, 0.0821, 0.0989, 0.0264, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0022, 0.0048, 0.0080, 0.0134, 0.0359, 0.0179, 0.0333, 0.0544, 0.0863,\n",
      "         0.1263, 0.1267, 0.1471, 0.1194, 0.1644, 0.0599, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0039, 0.0083, 0.0134, 0.0218, 0.0515, 0.0255, 0.0435, 0.0642, 0.0954,\n",
      "         0.1317, 0.1249, 0.1298, 0.1012, 0.1376, 0.0474, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1.00, Train Loss: 0.00, Val Loss: 5.76, Train BLEU: 0.00, Val BLEU: 4.17, Minutes Elapsed: 92.34\n",
      "Sampling from val predictions...\n",
      "Source: 在 西藏 <UNK> <UNK> 文化 中 <UNK> 尤其 显得 重要 <UNK> 在 那些 类似 西藏 的 地方 既 没有 条件\n",
      "Reference: in tibetan culture , they are performing very important sky burials . in places like tibet , there are\n",
      "Model: <SOS> the the of , the the &apos;t , , , . . <EOS> <EOS> . <EOS> . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.4050, 0.0118, 0.0006, 0.0017, 0.1365, 0.2564, 0.0089, 0.1258, 0.0204,\n",
      "         0.0119, 0.0008, 0.0072, 0.0117, 0.0003, 0.0001, 0.0004, 0.0001, 0.0003,\n",
      "         0.0001, 0.0000],\n",
      "        [0.3590, 0.0299, 0.0026, 0.0050, 0.1582, 0.2812, 0.0139, 0.0826, 0.0231,\n",
      "         0.0190, 0.0021, 0.0086, 0.0116, 0.0010, 0.0004, 0.0009, 0.0003, 0.0004,\n",
      "         0.0001, 0.0000],\n",
      "        [0.0246, 0.0226, 0.0122, 0.0224, 0.1302, 0.2213, 0.0495, 0.1429, 0.0890,\n",
      "         0.0891, 0.0197, 0.0434, 0.1059, 0.0128, 0.0037, 0.0050, 0.0025, 0.0021,\n",
      "         0.0008, 0.0003],\n",
      "        [0.0068, 0.0110, 0.0088, 0.0188, 0.0969, 0.1516, 0.0507, 0.1385, 0.0881,\n",
      "         0.0815, 0.0258, 0.0636, 0.2223, 0.0145, 0.0051, 0.0063, 0.0041, 0.0037,\n",
      "         0.0013, 0.0005],\n",
      "        [0.0016, 0.0023, 0.0030, 0.0073, 0.0393, 0.0619, 0.0249, 0.0808, 0.0774,\n",
      "         0.1114, 0.0311, 0.0838, 0.4071, 0.0327, 0.0090, 0.0123, 0.0065, 0.0058,\n",
      "         0.0015, 0.0004],\n",
      "        [0.0011, 0.0009, 0.0011, 0.0024, 0.0103, 0.0153, 0.0085, 0.0248, 0.0328,\n",
      "         0.0786, 0.0274, 0.0642, 0.5182, 0.0784, 0.0292, 0.0478, 0.0273, 0.0247,\n",
      "         0.0057, 0.0012],\n",
      "        [0.0009, 0.0007, 0.0008, 0.0018, 0.0072, 0.0108, 0.0064, 0.0168, 0.0252,\n",
      "         0.0667, 0.0291, 0.0507, 0.3592, 0.1063, 0.0563, 0.0855, 0.0669, 0.0729,\n",
      "         0.0283, 0.0073],\n",
      "        [0.0013, 0.0008, 0.0007, 0.0014, 0.0050, 0.0079, 0.0037, 0.0094, 0.0144,\n",
      "         0.0498, 0.0174, 0.0216, 0.2110, 0.1570, 0.0809, 0.1100, 0.0823, 0.1060,\n",
      "         0.0769, 0.0424],\n",
      "        [0.0015, 0.0011, 0.0010, 0.0015, 0.0044, 0.0061, 0.0033, 0.0064, 0.0093,\n",
      "         0.0291, 0.0125, 0.0132, 0.1679, 0.1146, 0.0710, 0.0887, 0.0818, 0.1426,\n",
      "         0.1359, 0.1082],\n",
      "        [0.0020, 0.0017, 0.0016, 0.0023, 0.0047, 0.0057, 0.0039, 0.0062, 0.0070,\n",
      "         0.0137, 0.0090, 0.0105, 0.0902, 0.0415, 0.0382, 0.0469, 0.0624, 0.1770,\n",
      "         0.2119, 0.2638],\n",
      "        [0.0029, 0.0029, 0.0026, 0.0035, 0.0064, 0.0069, 0.0054, 0.0071, 0.0077,\n",
      "         0.0124, 0.0097, 0.0101, 0.0585, 0.0292, 0.0319, 0.0328, 0.0444, 0.1310,\n",
      "         0.1980, 0.3967],\n",
      "        [0.0056, 0.0053, 0.0049, 0.0064, 0.0116, 0.0129, 0.0098, 0.0133, 0.0135,\n",
      "         0.0186, 0.0146, 0.0173, 0.0646, 0.0293, 0.0295, 0.0320, 0.0414, 0.1050,\n",
      "         0.1560, 0.4085],\n",
      "        [0.0100, 0.0108, 0.0099, 0.0128, 0.0206, 0.0210, 0.0182, 0.0223, 0.0219,\n",
      "         0.0263, 0.0232, 0.0260, 0.0684, 0.0337, 0.0363, 0.0372, 0.0456, 0.0915,\n",
      "         0.1246, 0.3395],\n",
      "        [0.0147, 0.0153, 0.0137, 0.0177, 0.0288, 0.0293, 0.0260, 0.0322, 0.0307,\n",
      "         0.0331, 0.0313, 0.0374, 0.0840, 0.0368, 0.0399, 0.0415, 0.0519, 0.0895,\n",
      "         0.1048, 0.2413],\n",
      "        [0.0175, 0.0144, 0.0129, 0.0161, 0.0263, 0.0293, 0.0229, 0.0323, 0.0331,\n",
      "         0.0359, 0.0290, 0.0355, 0.0918, 0.0396, 0.0353, 0.0394, 0.0488, 0.0863,\n",
      "         0.1065, 0.2472],\n",
      "        [0.0148, 0.0146, 0.0128, 0.0161, 0.0261, 0.0264, 0.0233, 0.0300, 0.0311,\n",
      "         0.0357, 0.0312, 0.0355, 0.0823, 0.0437, 0.0426, 0.0427, 0.0525, 0.0837,\n",
      "         0.1058, 0.2490],\n",
      "        [0.0227, 0.0208, 0.0183, 0.0225, 0.0363, 0.0385, 0.0316, 0.0412, 0.0417,\n",
      "         0.0465, 0.0390, 0.0445, 0.0879, 0.0496, 0.0458, 0.0491, 0.0561, 0.0788,\n",
      "         0.0879, 0.1414],\n",
      "        [0.0243, 0.0251, 0.0219, 0.0258, 0.0402, 0.0409, 0.0326, 0.0389, 0.0423,\n",
      "         0.0547, 0.0418, 0.0394, 0.0877, 0.0611, 0.0534, 0.0510, 0.0501, 0.0656,\n",
      "         0.0779, 0.1253],\n",
      "        [0.0265, 0.0263, 0.0226, 0.0272, 0.0428, 0.0427, 0.0365, 0.0438, 0.0448,\n",
      "         0.0514, 0.0430, 0.0449, 0.0833, 0.0542, 0.0510, 0.0510, 0.0530, 0.0686,\n",
      "         0.0757, 0.1107]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 1.05, Train Loss: 0.00, Val Loss: 5.62, Train BLEU: 0.00, Val BLEU: 3.30, Minutes Elapsed: 97.41\n",
      "Sampling from val predictions...\n",
      "Source: 这些 人 一无所有 无所 所有 他们 吓坏 了 他们 想要 放弃 但是 照片 片中 中间 这位 女士 团结 众人 坚持\n",
      "Reference: i mean , these people had nothing , and they were so petrified , they wanted to give up\n",
      "Model: <SOS> they they to they they they they to they they they to to and they they to . .\n",
      "Attention Weights: tensor([[7.6287e-01, 1.1226e-01, 2.6755e-02, 1.0809e-03, 2.3007e-02, 6.5876e-02,\n",
      "         3.2991e-03, 1.4195e-03, 3.2260e-03, 1.5750e-04, 3.7306e-05, 8.2569e-06,\n",
      "         1.2534e-06, 8.5658e-07, 8.8149e-07, 8.7203e-07, 5.9187e-08, 2.7883e-07,\n",
      "         4.0886e-07, 2.4678e-07],\n",
      "        [4.1850e-01, 1.3585e-01, 1.0545e-01, 6.3466e-03, 5.1498e-02, 2.2693e-01,\n",
      "         2.4682e-02, 9.3908e-03, 1.8601e-02, 1.7273e-03, 6.7669e-04, 2.1246e-04,\n",
      "         3.9566e-05, 2.9254e-05, 2.6833e-05, 2.5320e-05, 2.2420e-06, 5.6489e-06,\n",
      "         6.1889e-06, 4.6123e-06],\n",
      "        [3.1527e-02, 3.8152e-02, 1.0979e-01, 2.8976e-02, 1.2900e-01, 3.3001e-01,\n",
      "         9.1530e-02, 4.8117e-02, 1.3706e-01, 3.1804e-02, 1.5485e-02, 5.8698e-03,\n",
      "         9.2293e-04, 6.2238e-04, 5.1436e-04, 3.9498e-04, 3.8902e-05, 7.3007e-05,\n",
      "         5.8588e-05, 5.1404e-05],\n",
      "        [6.5208e-03, 9.6286e-03, 5.7489e-02, 2.8128e-02, 6.4890e-02, 2.7190e-01,\n",
      "         1.1432e-01, 6.3528e-02, 2.1134e-01, 6.9008e-02, 5.0598e-02, 3.0409e-02,\n",
      "         8.0616e-03, 5.3316e-03, 3.9783e-03, 3.4568e-03, 3.8736e-04, 4.9350e-04,\n",
      "         2.6554e-04, 2.6636e-04],\n",
      "        [3.3579e-03, 3.9484e-03, 1.7565e-02, 9.4633e-03, 3.1159e-02, 2.2353e-01,\n",
      "         9.6762e-02, 5.6389e-02, 2.9030e-01, 1.0972e-01, 8.2111e-02, 4.4077e-02,\n",
      "         1.0058e-02, 7.4131e-03, 6.5483e-03, 5.6833e-03, 3.7392e-04, 7.1625e-04,\n",
      "         4.5818e-04, 3.6289e-04],\n",
      "        [4.7248e-03, 5.1634e-03, 2.1403e-02, 1.0611e-02, 3.8181e-02, 2.3166e-01,\n",
      "         9.7813e-02, 6.1113e-02, 2.7779e-01, 1.1148e-01, 7.6201e-02, 3.8639e-02,\n",
      "         7.9963e-03, 5.8526e-03, 5.5902e-03, 4.5853e-03, 1.9453e-04, 4.6204e-04,\n",
      "         3.2342e-04, 2.0610e-04],\n",
      "        [2.3259e-03, 2.7133e-03, 8.5201e-03, 5.2369e-03, 1.7248e-02, 1.2517e-01,\n",
      "         6.0677e-02, 4.0382e-02, 2.9458e-01, 1.7090e-01, 1.2302e-01, 7.3814e-02,\n",
      "         1.9653e-02, 1.5650e-02, 1.5677e-02, 1.6480e-02, 1.1731e-03, 2.7751e-03,\n",
      "         2.3675e-03, 1.6381e-03],\n",
      "        [3.4128e-03, 3.5142e-03, 8.2565e-03, 4.7268e-03, 1.4260e-02, 8.2583e-02,\n",
      "         4.1166e-02, 2.7890e-02, 2.3945e-01, 1.2432e-01, 1.1806e-01, 1.0089e-01,\n",
      "         3.8116e-02, 4.1157e-02, 5.2466e-02, 7.2510e-02, 4.2127e-03, 1.0340e-02,\n",
      "         7.3301e-03, 5.3462e-03],\n",
      "        [2.8904e-03, 3.0115e-03, 6.6444e-03, 4.5238e-03, 8.7396e-03, 3.8669e-02,\n",
      "         2.3393e-02, 1.6469e-02, 1.2182e-01, 7.6403e-02, 8.5856e-02, 1.0416e-01,\n",
      "         6.1002e-02, 7.3065e-02, 1.0112e-01, 1.8147e-01, 1.5989e-02, 3.3802e-02,\n",
      "         2.2680e-02, 1.8284e-02],\n",
      "        [3.3422e-03, 3.3096e-03, 6.3710e-03, 4.2135e-03, 8.3874e-03, 2.8005e-02,\n",
      "         1.6181e-02, 1.2159e-02, 6.7565e-02, 4.6281e-02, 4.8131e-02, 5.5466e-02,\n",
      "         3.4251e-02, 4.9732e-02, 8.8434e-02, 2.8755e-01, 2.6760e-02, 8.0404e-02,\n",
      "         7.0480e-02, 6.2973e-02],\n",
      "        [2.3784e-03, 2.3573e-03, 4.8189e-03, 2.9008e-03, 8.0705e-03, 3.6447e-02,\n",
      "         1.8543e-02, 1.4125e-02, 1.0213e-01, 6.9165e-02, 6.4234e-02, 6.3967e-02,\n",
      "         3.5433e-02, 4.9486e-02, 8.9859e-02, 2.0021e-01, 2.5733e-02, 7.9491e-02,\n",
      "         7.5468e-02, 5.5183e-02],\n",
      "        [1.8376e-03, 1.8437e-03, 3.8268e-03, 2.2174e-03, 7.0013e-03, 3.5693e-02,\n",
      "         1.6215e-02, 1.1655e-02, 1.0372e-01, 7.2952e-02, 6.0921e-02, 5.7478e-02,\n",
      "         3.0006e-02, 4.2451e-02, 7.7378e-02, 1.8338e-01, 2.9270e-02, 8.3240e-02,\n",
      "         1.1296e-01, 6.5953e-02],\n",
      "        [1.5743e-03, 1.7574e-03, 4.0111e-03, 2.9403e-03, 4.5765e-03, 1.2472e-02,\n",
      "         8.6815e-03, 7.1803e-03, 2.5967e-02, 2.0979e-02, 2.5932e-02, 3.8494e-02,\n",
      "         3.0514e-02, 4.3570e-02, 6.9938e-02, 2.4539e-01, 5.9780e-02, 1.2069e-01,\n",
      "         1.1311e-01, 1.6244e-01],\n",
      "        [1.8654e-03, 1.9777e-03, 4.1672e-03, 3.0483e-03, 4.1505e-03, 8.5960e-03,\n",
      "         6.3026e-03, 5.2438e-03, 1.3646e-02, 1.1085e-02, 1.2798e-02, 1.7236e-02,\n",
      "         1.5254e-02, 1.9863e-02, 2.9566e-02, 1.4498e-01, 4.0724e-02, 1.0510e-01,\n",
      "         1.5747e-01, 3.9692e-01],\n",
      "        [2.5533e-03, 2.4234e-03, 4.0596e-03, 3.0875e-03, 4.6918e-03, 9.2835e-03,\n",
      "         6.2176e-03, 5.1996e-03, 1.3077e-02, 1.1241e-02, 1.0405e-02, 1.0487e-02,\n",
      "         8.2664e-03, 1.0443e-02, 1.5803e-02, 6.7197e-02, 2.2923e-02, 7.1820e-02,\n",
      "         1.6958e-01, 5.5124e-01],\n",
      "        [8.3423e-03, 6.9122e-03, 1.0169e-02, 7.0382e-03, 1.2752e-02, 2.8804e-02,\n",
      "         1.5728e-02, 1.2517e-02, 3.5257e-02, 2.7343e-02, 2.1499e-02, 1.6570e-02,\n",
      "         1.0071e-02, 1.2200e-02, 1.7832e-02, 5.5731e-02, 1.5217e-02, 5.5648e-02,\n",
      "         1.3796e-01, 4.9241e-01],\n",
      "        [3.2046e-03, 2.9974e-03, 4.6265e-03, 3.3380e-03, 6.2164e-03, 1.4254e-02,\n",
      "         7.7294e-03, 6.5822e-03, 2.1801e-02, 1.8500e-02, 1.3985e-02, 1.1238e-02,\n",
      "         6.2100e-03, 7.8813e-03, 1.1911e-02, 4.5793e-02, 1.2263e-02, 5.3594e-02,\n",
      "         1.6520e-01, 5.8267e-01],\n",
      "        [8.7816e-03, 9.1612e-03, 2.2038e-02, 1.6808e-02, 1.9749e-02, 3.4466e-02,\n",
      "         2.8578e-02, 2.5183e-02, 4.1599e-02, 3.5614e-02, 4.7058e-02, 6.4450e-02,\n",
      "         5.4617e-02, 5.4796e-02, 5.0836e-02, 8.7607e-02, 4.3645e-02, 5.0980e-02,\n",
      "         6.3535e-02, 2.4050e-01],\n",
      "        [1.3545e-02, 1.3692e-02, 3.0476e-02, 2.3368e-02, 2.7051e-02, 4.7168e-02,\n",
      "         3.8074e-02, 3.2385e-02, 5.3743e-02, 4.5398e-02, 5.5820e-02, 6.9845e-02,\n",
      "         6.3324e-02, 6.3072e-02, 5.9695e-02, 8.5753e-02, 5.3061e-02, 5.5015e-02,\n",
      "         5.2079e-02, 1.1744e-01]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1.11, Train Loss: 0.00, Val Loss: 5.64, Train BLEU: 0.00, Val BLEU: 3.59, Minutes Elapsed: 102.48\n",
      "Sampling from val predictions...\n",
      "Source: 而 如今 我 已经 是 一名 自豪 的 <UNK> 学院 的 毕业 毕业生 业生 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: instead , i stand here a proud graduate of <UNK> college . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> and , i i a a a of a a . . <EOS> <EOS> . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.1747, 0.1829, 0.6396, 0.0024, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0662, 0.1060, 0.8254, 0.0022, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0219, 0.1080, 0.7765, 0.0857, 0.0059, 0.0005, 0.0007, 0.0002, 0.0000,\n",
      "         0.0001, 0.0001, 0.0000, 0.0000, 0.0001, 0.0002, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0104, 0.0414, 0.6126, 0.2805, 0.0394, 0.0054, 0.0060, 0.0015, 0.0004,\n",
      "         0.0006, 0.0006, 0.0002, 0.0002, 0.0002, 0.0006, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0135, 0.0441, 0.4355, 0.3811, 0.0949, 0.0140, 0.0119, 0.0024, 0.0005,\n",
      "         0.0006, 0.0005, 0.0002, 0.0002, 0.0002, 0.0004, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0034, 0.0077, 0.0438, 0.2175, 0.3038, 0.1635, 0.1834, 0.0512, 0.0108,\n",
      "         0.0071, 0.0041, 0.0014, 0.0008, 0.0007, 0.0008, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0012, 0.0026, 0.0269, 0.0479, 0.1323, 0.1472, 0.4014, 0.1574, 0.0385,\n",
      "         0.0245, 0.0128, 0.0033, 0.0014, 0.0011, 0.0014, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0008, 0.0015, 0.0123, 0.0163, 0.0413, 0.0576, 0.3739, 0.2438, 0.0984,\n",
      "         0.0894, 0.0478, 0.0092, 0.0030, 0.0021, 0.0024, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0013, 0.0031, 0.0659, 0.0253, 0.0504, 0.0745, 0.4459, 0.1615, 0.0723,\n",
      "         0.0604, 0.0295, 0.0054, 0.0015, 0.0012, 0.0017, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0012, 0.0025, 0.0265, 0.0098, 0.0115, 0.0163, 0.2312, 0.1546, 0.1222,\n",
      "         0.2149, 0.1706, 0.0276, 0.0049, 0.0027, 0.0035, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0029, 0.0057, 0.0509, 0.0135, 0.0092, 0.0074, 0.0701, 0.0513, 0.0573,\n",
      "         0.2419, 0.3672, 0.0921, 0.0142, 0.0069, 0.0094, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0023, 0.0050, 0.0429, 0.0069, 0.0051, 0.0067, 0.0767, 0.0542, 0.0854,\n",
      "         0.2595, 0.3159, 0.1111, 0.0154, 0.0061, 0.0067, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0202, 0.0393, 0.1838, 0.0463, 0.0231, 0.0170, 0.0698, 0.0376, 0.0382,\n",
      "         0.1323, 0.1992, 0.1121, 0.0344, 0.0210, 0.0258, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0253, 0.0471, 0.1936, 0.0724, 0.0385, 0.0236, 0.0745, 0.0433, 0.0284,\n",
      "         0.0773, 0.1244, 0.0844, 0.0503, 0.0476, 0.0691, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0182, 0.0349, 0.1548, 0.0489, 0.0298, 0.0175, 0.0556, 0.0386, 0.0278,\n",
      "         0.0762, 0.1405, 0.1125, 0.0703, 0.0698, 0.1047, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0165, 0.0336, 0.1456, 0.0405, 0.0250, 0.0151, 0.0517, 0.0376, 0.0300,\n",
      "         0.0816, 0.1409, 0.1211, 0.0746, 0.0736, 0.1126, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0395, 0.0736, 0.2325, 0.0795, 0.0405, 0.0235, 0.0731, 0.0429, 0.0250,\n",
      "         0.0537, 0.0858, 0.0519, 0.0382, 0.0478, 0.0923, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0479, 0.0861, 0.2528, 0.0857, 0.0432, 0.0258, 0.0730, 0.0424, 0.0242,\n",
      "         0.0479, 0.0723, 0.0426, 0.0328, 0.0432, 0.0803, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0498, 0.0884, 0.2555, 0.0879, 0.0443, 0.0275, 0.0741, 0.0423, 0.0253,\n",
      "         0.0481, 0.0682, 0.0413, 0.0316, 0.0414, 0.0744, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 1.16, Train Loss: 0.00, Val Loss: 5.63, Train BLEU: 0.00, Val BLEU: 3.35, Minutes Elapsed: 107.58\n",
      "Sampling from val predictions...\n",
      "Source: 而且 速度 也 快 最多 多只 只要 30 秒 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: they &apos;re high-speed , take about 30 seconds at most . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> and , the to of , the . . <EOS> . . <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9757, 0.0221, 0.0021, 0.0000, 0.0000, 0.0000, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.7007, 0.2314, 0.0580, 0.0043, 0.0030, 0.0003, 0.0017, 0.0004, 0.0001,\n",
      "         0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1708, 0.2881, 0.4217, 0.0627, 0.0370, 0.0034, 0.0119, 0.0026, 0.0009,\n",
      "         0.0011, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0129, 0.0460, 0.3730, 0.1795, 0.2293, 0.0159, 0.1247, 0.0150, 0.0025,\n",
      "         0.0012, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0098, 0.0319, 0.2342, 0.1631, 0.3223, 0.0192, 0.1856, 0.0288, 0.0037,\n",
      "         0.0015, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0103, 0.0196, 0.1251, 0.0822, 0.2072, 0.0204, 0.4890, 0.0419, 0.0034,\n",
      "         0.0009, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0046, 0.0072, 0.0513, 0.0434, 0.1709, 0.0381, 0.5989, 0.0783, 0.0062,\n",
      "         0.0010, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0147, 0.0180, 0.0565, 0.0362, 0.0976, 0.0399, 0.5129, 0.1939, 0.0260,\n",
      "         0.0044, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0230, 0.0238, 0.0660, 0.0373, 0.0832, 0.0434, 0.4786, 0.2000, 0.0378,\n",
      "         0.0069, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0589, 0.0557, 0.1172, 0.0544, 0.0853, 0.0396, 0.3993, 0.1501, 0.0311,\n",
      "         0.0084, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0740, 0.0661, 0.1267, 0.0602, 0.0848, 0.0401, 0.3529, 0.1412, 0.0405,\n",
      "         0.0134, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0510, 0.0542, 0.1027, 0.0619, 0.0891, 0.0509, 0.2974, 0.1815, 0.0837,\n",
      "         0.0277, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0666, 0.0696, 0.1246, 0.0638, 0.0861, 0.0430, 0.3318, 0.1479, 0.0515,\n",
      "         0.0151, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0915, 0.0697, 0.1259, 0.0615, 0.0818, 0.0430, 0.3080, 0.1321, 0.0594,\n",
      "         0.0271, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0786, 0.0613, 0.1205, 0.0619, 0.0839, 0.0480, 0.2977, 0.1404, 0.0747,\n",
      "         0.0331, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0892, 0.0763, 0.1541, 0.0736, 0.0976, 0.0472, 0.2916, 0.1096, 0.0403,\n",
      "         0.0206, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0927, 0.0799, 0.1550, 0.0744, 0.0984, 0.0460, 0.2893, 0.1070, 0.0371,\n",
      "         0.0201, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0948, 0.0844, 0.1552, 0.0756, 0.0984, 0.0453, 0.2848, 0.1060, 0.0361,\n",
      "         0.0194, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0959, 0.0879, 0.1556, 0.0769, 0.0987, 0.0451, 0.2804, 0.1050, 0.0357,\n",
      "         0.0189, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 1.22, Train Loss: 0.00, Val Loss: 5.63, Train BLEU: 0.00, Val BLEU: 4.32, Minutes Elapsed: 112.69\n",
      "Sampling from val predictions...\n",
      "Source: 政府 指责 我 给 了 我 张 告 票 通知 我 必须 移除 我 的 花园 之后 告 票 变成\n",
      "Reference: the city came down on me , and basically gave me a citation saying that i had to remove\n",
      "Model: <SOS> i i i i i i i i i i i i to of . <EOS> . . .\n",
      "Attention Weights: tensor([[1.9889e-02, 5.8459e-03, 9.6812e-01, 4.4574e-03, 2.6655e-04, 1.3538e-03,\n",
      "         3.4552e-06, 3.4527e-06, 2.5813e-06, 2.5237e-06, 5.0011e-05, 3.7013e-06,\n",
      "         1.4773e-07, 7.4757e-07, 1.0465e-08, 3.6394e-09, 1.2712e-08, 7.7584e-09,\n",
      "         4.3666e-09, 1.4703e-08],\n",
      "        [7.6122e-02, 3.4805e-02, 8.0247e-01, 6.4003e-02, 4.4290e-03, 1.7376e-02,\n",
      "         1.4797e-04, 1.2272e-04, 7.4913e-05, 4.2256e-05, 3.4439e-04, 5.0485e-05,\n",
      "         2.6726e-06, 1.3125e-05, 3.4100e-07, 1.1014e-07, 2.9581e-07, 2.1888e-07,\n",
      "         1.1528e-07, 1.3630e-07],\n",
      "        [4.2234e-02, 7.3511e-02, 4.4246e-01, 1.9246e-01, 5.9008e-02, 1.4435e-01,\n",
      "         1.2428e-02, 9.7865e-03, 5.1903e-03, 3.5924e-03, 7.4028e-03, 6.7597e-03,\n",
      "         2.6955e-04, 4.1067e-04, 5.0200e-05, 1.7322e-05, 3.2532e-05, 1.9086e-05,\n",
      "         1.0877e-05, 1.1862e-05],\n",
      "        [2.1246e-02, 4.2306e-02, 2.7871e-01, 1.7040e-01, 7.6463e-02, 2.7127e-01,\n",
      "         3.2397e-02, 2.6541e-02, 1.3376e-02, 1.2125e-02, 2.5821e-02, 2.6494e-02,\n",
      "         9.7776e-04, 1.4659e-03, 1.5449e-04, 5.7343e-05, 9.8828e-05, 4.7616e-05,\n",
      "         2.3655e-05, 3.0777e-05],\n",
      "        [1.1743e-02, 1.7883e-02, 1.2606e-01, 7.3351e-02, 4.6738e-02, 3.3020e-01,\n",
      "         5.7440e-02, 5.0123e-02, 2.8337e-02, 3.4231e-02, 1.0270e-01, 1.0874e-01,\n",
      "         4.1103e-03, 7.4641e-03, 5.1571e-04, 1.0150e-04, 1.6528e-04, 5.3715e-05,\n",
      "         2.0930e-05, 2.6746e-05],\n",
      "        [6.4172e-03, 6.7391e-03, 2.9610e-02, 3.0449e-02, 2.9454e-02, 1.6817e-01,\n",
      "         7.8139e-02, 7.5676e-02, 5.2065e-02, 6.8389e-02, 1.3600e-01, 2.5103e-01,\n",
      "         2.8609e-02, 3.2704e-02, 3.8629e-03, 8.6169e-04, 1.1907e-03, 3.6929e-04,\n",
      "         1.3913e-04, 1.3715e-04],\n",
      "        [3.8834e-03, 3.4976e-03, 2.2398e-02, 1.7300e-02, 1.6416e-02, 1.0556e-01,\n",
      "         5.0381e-02, 5.2582e-02, 3.9753e-02, 5.9508e-02, 1.5004e-01, 3.1132e-01,\n",
      "         5.3288e-02, 9.0838e-02, 1.3829e-02, 3.3181e-03, 4.2902e-03, 1.1184e-03,\n",
      "         3.4132e-04, 3.2992e-04],\n",
      "        [1.7142e-03, 1.8675e-03, 1.5530e-02, 6.3287e-03, 5.7963e-03, 6.3436e-02,\n",
      "         1.8835e-02, 2.2920e-02, 1.7744e-02, 4.9248e-02, 1.7833e-01, 3.0182e-01,\n",
      "         8.2158e-02, 1.8001e-01, 2.2688e-02, 7.6592e-03, 1.7996e-02, 4.0942e-03,\n",
      "         8.2596e-04, 1.0036e-03],\n",
      "        [1.5638e-03, 1.0982e-03, 5.8238e-03, 5.5007e-03, 4.8837e-03, 4.1317e-02,\n",
      "         1.9279e-02, 1.9914e-02, 1.6696e-02, 2.4374e-02, 7.4936e-02, 1.9096e-01,\n",
      "         6.3278e-02, 2.7241e-01, 1.0135e-01, 5.8682e-02, 6.9333e-02, 1.8496e-02,\n",
      "         4.8222e-03, 5.2725e-03],\n",
      "        [9.1911e-04, 8.3452e-04, 6.9451e-03, 5.7701e-03, 5.6925e-03, 5.1464e-02,\n",
      "         1.7827e-02, 1.9781e-02, 1.7454e-02, 3.0843e-02, 1.0533e-01, 2.1283e-01,\n",
      "         8.0060e-02, 2.5366e-01, 8.2709e-02, 3.2522e-02, 5.3389e-02, 1.4352e-02,\n",
      "         3.8340e-03, 3.7775e-03],\n",
      "        [1.0366e-03, 1.1461e-03, 1.1384e-02, 6.3743e-03, 6.4534e-03, 4.1305e-02,\n",
      "         1.1002e-02, 1.2790e-02, 1.1962e-02, 2.6062e-02, 1.2023e-01, 1.8074e-01,\n",
      "         7.2695e-02, 2.7854e-01, 8.2877e-02, 3.1291e-02, 6.7798e-02, 2.2247e-02,\n",
      "         6.7372e-03, 7.3323e-03],\n",
      "        [1.1762e-03, 1.0923e-03, 9.0745e-03, 4.7001e-03, 4.1123e-03, 3.0919e-02,\n",
      "         7.5065e-03, 8.4260e-03, 7.5008e-03, 1.6362e-02, 6.5592e-02, 9.4923e-02,\n",
      "         4.1772e-02, 2.6273e-01, 7.7147e-02, 6.0230e-02, 1.7417e-01, 6.3276e-02,\n",
      "         2.3017e-02, 4.6271e-02],\n",
      "        [5.9608e-04, 4.9254e-04, 2.0044e-03, 2.0146e-03, 1.8843e-03, 1.5575e-02,\n",
      "         4.3425e-03, 4.6907e-03, 4.4319e-03, 6.5171e-03, 2.4011e-02, 4.2130e-02,\n",
      "         2.1371e-02, 1.5840e-01, 7.3664e-02, 8.8677e-02, 1.9997e-01, 1.0235e-01,\n",
      "         6.1775e-02, 1.8510e-01],\n",
      "        [7.0027e-04, 5.5123e-04, 1.3088e-03, 1.5236e-03, 1.4152e-03, 7.3690e-03,\n",
      "         4.8279e-03, 4.3021e-03, 3.6139e-03, 3.0164e-03, 9.8314e-03, 2.2519e-02,\n",
      "         1.1472e-02, 1.3350e-01, 1.0716e-01, 1.1400e-01, 1.6971e-01, 8.3942e-02,\n",
      "         5.9348e-02, 2.5989e-01],\n",
      "        [1.2345e-03, 9.0456e-04, 2.7554e-03, 1.9394e-03, 1.6926e-03, 8.2324e-03,\n",
      "         2.9930e-03, 3.4807e-03, 3.0696e-03, 4.9580e-03, 2.3415e-02, 2.6623e-02,\n",
      "         1.0812e-02, 1.3026e-01, 2.8168e-02, 4.7496e-02, 1.7135e-01, 8.9137e-02,\n",
      "         5.2467e-02, 3.8902e-01],\n",
      "        [2.8015e-03, 1.9192e-03, 6.6852e-03, 5.4012e-03, 4.5058e-03, 2.1135e-02,\n",
      "         7.9376e-03, 7.9493e-03, 7.0474e-03, 8.3045e-03, 3.9531e-02, 3.8077e-02,\n",
      "         1.3990e-02, 1.1877e-01, 3.1337e-02, 3.7504e-02, 1.0732e-01, 5.1286e-02,\n",
      "         3.5088e-02, 4.5341e-01],\n",
      "        [3.7322e-03, 2.5933e-03, 7.2334e-03, 8.5735e-03, 7.2598e-03, 3.1950e-02,\n",
      "         1.5509e-02, 1.4820e-02, 1.2683e-02, 1.2932e-02, 3.9351e-02, 5.2207e-02,\n",
      "         2.2831e-02, 1.4210e-01, 5.0174e-02, 4.6517e-02, 9.8890e-02, 5.2713e-02,\n",
      "         3.9916e-02, 3.3801e-01],\n",
      "        [4.8633e-03, 3.3545e-03, 7.7675e-03, 1.0708e-02, 9.3470e-03, 3.5761e-02,\n",
      "         2.0433e-02, 1.9702e-02, 1.7039e-02, 1.6612e-02, 4.0234e-02, 5.6791e-02,\n",
      "         2.8956e-02, 1.4262e-01, 5.3499e-02, 5.0701e-02, 9.5589e-02, 5.6117e-02,\n",
      "         4.3810e-02, 2.8610e-01],\n",
      "        [7.5676e-03, 5.8919e-03, 1.2773e-02, 1.2842e-02, 1.1318e-02, 3.3061e-02,\n",
      "         3.1089e-02, 2.6504e-02, 2.1399e-02, 1.5320e-02, 2.6816e-02, 4.6887e-02,\n",
      "         3.0239e-02, 1.3011e-01, 1.3323e-01, 1.0425e-01, 9.1048e-02, 5.9292e-02,\n",
      "         5.0718e-02, 1.4965e-01]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1.27, Train Loss: 0.00, Val Loss: 5.61, Train BLEU: 0.00, Val BLEU: 4.22, Minutes Elapsed: 117.80\n",
      "Sampling from val predictions...\n",
      "Source: 还 不算 毁坏 得 太严 严重 但是 被 <UNK> <UNK> 的 地方 导致 照片 片中 中小 小女 小女孩 女孩 的\n",
      "Reference: not terribly damaged , but where the water had caused that <UNK> on the girl &apos;s face had to\n",
      "Model: <SOS> it &apos;s , , , , , , , , , , <UNK> . . . <EOS> . <EOS>\n",
      "Attention Weights: tensor([[9.4284e-01, 5.5886e-02, 7.4071e-04, 3.1587e-04, 1.8037e-05, 1.1719e-04,\n",
      "         7.4198e-05, 9.6756e-06, 2.8357e-07, 2.3391e-07, 8.7274e-07, 6.1466e-07,\n",
      "         2.5165e-07, 6.1795e-08, 4.1738e-08, 4.7329e-08, 9.1714e-09, 7.6305e-09,\n",
      "         4.9439e-08, 6.6408e-08],\n",
      "        [2.3586e-01, 3.7974e-01, 2.2887e-01, 8.9015e-02, 1.0557e-02, 2.5798e-02,\n",
      "         1.9728e-02, 8.0094e-03, 3.5064e-04, 2.7392e-04, 7.2933e-04, 5.6149e-04,\n",
      "         2.3814e-04, 7.0466e-05, 4.9845e-05, 5.3822e-05, 1.0173e-05, 8.4716e-06,\n",
      "         3.7362e-05, 3.8998e-05],\n",
      "        [2.7285e-02, 1.2134e-01, 2.2525e-01, 2.3789e-01, 5.1084e-02, 1.2164e-01,\n",
      "         1.4612e-01, 5.4743e-02, 2.3335e-03, 1.5612e-03, 4.0020e-03, 3.5054e-03,\n",
      "         1.8219e-03, 4.2037e-04, 3.1706e-04, 2.5890e-04, 5.6786e-05, 4.7242e-05,\n",
      "         1.4840e-04, 1.8017e-04],\n",
      "        [2.5158e-03, 7.6444e-03, 8.2749e-02, 9.5376e-02, 5.2822e-02, 1.4952e-01,\n",
      "         2.9252e-01, 2.2878e-01, 1.4756e-02, 9.5532e-03, 1.8262e-02, 2.4918e-02,\n",
      "         1.2749e-02, 2.7429e-03, 1.8990e-03, 1.6072e-03, 2.2826e-04, 1.5590e-04,\n",
      "         6.8925e-04, 5.1650e-04],\n",
      "        [1.9728e-03, 2.3269e-03, 1.2113e-02, 1.5237e-02, 1.2351e-02, 4.5840e-02,\n",
      "         1.7613e-01, 4.2170e-01, 2.8991e-02, 2.3141e-02, 5.0152e-02, 1.1209e-01,\n",
      "         6.6022e-02, 1.0489e-02, 8.4073e-03, 7.2671e-03, 5.9135e-04, 3.1557e-04,\n",
      "         2.9611e-03, 1.9002e-03],\n",
      "        [2.1649e-03, 1.9810e-03, 5.9387e-03, 7.6413e-03, 5.7687e-03, 1.7342e-02,\n",
      "         6.8550e-02, 2.2201e-01, 3.0296e-02, 3.0592e-02, 5.7464e-02, 2.0158e-01,\n",
      "         1.8542e-01, 3.8096e-02, 4.1177e-02, 4.1811e-02, 3.4202e-03, 1.7303e-03,\n",
      "         2.2387e-02, 1.4632e-02],\n",
      "        [5.9920e-04, 1.1858e-03, 3.0501e-03, 4.5951e-03, 4.0325e-03, 1.4850e-02,\n",
      "         6.0596e-02, 1.5956e-01, 3.1141e-02, 3.5064e-02, 7.5246e-02, 2.0342e-01,\n",
      "         1.9835e-01, 5.6281e-02, 5.7607e-02, 5.2753e-02, 4.6887e-03, 2.6590e-03,\n",
      "         1.9939e-02, 1.4380e-02],\n",
      "        [3.2957e-04, 7.0267e-04, 1.7354e-03, 2.5029e-03, 2.2301e-03, 6.3501e-03,\n",
      "         2.3202e-02, 8.0664e-02, 2.3570e-02, 2.6757e-02, 4.6354e-02, 1.6524e-01,\n",
      "         2.1374e-01, 8.3225e-02, 1.0880e-01, 1.1025e-01, 1.4757e-02, 8.9158e-03,\n",
      "         4.8967e-02, 3.1712e-02],\n",
      "        [3.5340e-04, 8.0798e-04, 1.6483e-03, 2.3059e-03, 1.7970e-03, 3.9711e-03,\n",
      "         1.1818e-02, 3.6665e-02, 1.2571e-02, 1.3967e-02, 2.1753e-02, 8.5664e-02,\n",
      "         1.4608e-01, 7.4109e-02, 1.3491e-01, 1.9916e-01, 3.0558e-02, 1.8696e-02,\n",
      "         1.1208e-01, 9.1083e-02],\n",
      "        [1.1843e-03, 1.2129e-03, 2.6294e-03, 3.1099e-03, 2.5085e-03, 5.4656e-03,\n",
      "         1.3415e-02, 3.7386e-02, 1.3922e-02, 1.6556e-02, 1.9992e-02, 8.4351e-02,\n",
      "         1.2299e-01, 6.2448e-02, 1.1015e-01, 1.8588e-01, 3.5362e-02, 2.1144e-02,\n",
      "         1.6968e-01, 9.0616e-02],\n",
      "        [2.9442e-03, 2.9303e-03, 5.5592e-03, 7.0655e-03, 4.4080e-03, 9.2016e-03,\n",
      "         2.3484e-02, 3.7943e-02, 1.0497e-02, 1.2202e-02, 1.7709e-02, 4.7862e-02,\n",
      "         6.4212e-02, 3.2936e-02, 6.3669e-02, 1.3788e-01, 3.0078e-02, 1.9495e-02,\n",
      "         2.1579e-01, 2.5414e-01],\n",
      "        [5.0598e-04, 1.2603e-03, 2.6332e-03, 3.4430e-03, 2.6178e-03, 4.6527e-03,\n",
      "         8.7945e-03, 1.7609e-02, 7.3027e-03, 7.9783e-03, 1.1444e-02, 2.9171e-02,\n",
      "         4.7031e-02, 3.4111e-02, 6.9424e-02, 1.7507e-01, 5.0339e-02, 3.6428e-02,\n",
      "         1.9536e-01, 2.9482e-01],\n",
      "        [1.9761e-03, 3.0580e-03, 6.3790e-03, 7.5687e-03, 5.6344e-03, 9.6209e-03,\n",
      "         1.7280e-02, 2.7471e-02, 1.1223e-02, 1.2253e-02, 1.6112e-02, 3.4389e-02,\n",
      "         4.5836e-02, 3.2207e-02, 5.8831e-02, 1.3609e-01, 5.3524e-02, 4.0994e-02,\n",
      "         1.9422e-01, 2.8533e-01],\n",
      "        [1.6665e-03, 3.9837e-03, 7.6724e-03, 9.3398e-03, 7.1663e-03, 1.1649e-02,\n",
      "         1.9104e-02, 3.1920e-02, 1.2929e-02, 1.3718e-02, 1.9835e-02, 3.8698e-02,\n",
      "         4.8572e-02, 3.4635e-02, 6.1345e-02, 1.2821e-01, 5.5264e-02, 4.3811e-02,\n",
      "         1.6897e-01, 2.8152e-01],\n",
      "        [9.8502e-03, 1.3723e-02, 2.9214e-02, 3.0492e-02, 2.1989e-02, 3.5357e-02,\n",
      "         6.1003e-02, 7.8186e-02, 2.6545e-02, 2.8820e-02, 4.2249e-02, 6.3174e-02,\n",
      "         6.3607e-02, 3.7008e-02, 5.1665e-02, 7.4381e-02, 3.4560e-02, 2.9208e-02,\n",
      "         1.1863e-01, 1.5034e-01],\n",
      "        [1.4424e-02, 1.3214e-02, 2.6679e-02, 2.7380e-02, 2.1274e-02, 3.5377e-02,\n",
      "         5.4948e-02, 6.6125e-02, 2.7496e-02, 3.0709e-02, 4.0166e-02, 6.3020e-02,\n",
      "         6.1802e-02, 3.9692e-02, 5.1252e-02, 7.6940e-02, 3.7474e-02, 3.4927e-02,\n",
      "         1.1550e-01, 1.6160e-01],\n",
      "        [2.0940e-02, 1.5401e-02, 2.8977e-02, 2.8160e-02, 2.2646e-02, 3.4496e-02,\n",
      "         5.5561e-02, 6.8484e-02, 3.0791e-02, 3.3462e-02, 3.3781e-02, 5.9902e-02,\n",
      "         5.4925e-02, 3.9055e-02, 4.9455e-02, 8.4487e-02, 4.7261e-02, 4.0346e-02,\n",
      "         1.2711e-01, 1.2477e-01],\n",
      "        [1.8802e-02, 2.0962e-02, 4.2945e-02, 4.0269e-02, 3.1755e-02, 4.6097e-02,\n",
      "         7.3297e-02, 8.5401e-02, 3.5527e-02, 3.8295e-02, 4.8856e-02, 6.8890e-02,\n",
      "         6.5743e-02, 4.1878e-02, 5.0572e-02, 6.1992e-02, 3.0047e-02, 2.7190e-02,\n",
      "         8.4195e-02, 8.7287e-02],\n",
      "        [1.9292e-02, 1.6807e-02, 3.5400e-02, 3.2545e-02, 2.8582e-02, 4.1193e-02,\n",
      "         5.9401e-02, 7.0662e-02, 3.7134e-02, 3.9874e-02, 4.2659e-02, 6.4278e-02,\n",
      "         6.3203e-02, 4.4304e-02, 5.2718e-02, 7.3167e-02, 4.0816e-02, 3.7613e-02,\n",
      "         9.9181e-02, 1.0117e-01]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 1.33, Train Loss: 0.00, Val Loss: 5.66, Train BLEU: 0.00, Val BLEU: 3.71, Minutes Elapsed: 122.90\n",
      "Sampling from val predictions...\n",
      "Source: 在 洛杉矶 <UNK> 人们 死于 可 治愈 的 疾病 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: people are dying from curable diseases in south central los angeles . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> and the the , , , the <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.8021, 0.0207, 0.0019, 0.1415, 0.0331, 0.0004, 0.0002, 0.0001, 0.0000,\n",
      "         0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.5466, 0.0989, 0.0150, 0.2222, 0.1062, 0.0048, 0.0023, 0.0021, 0.0008,\n",
      "         0.0011, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0353, 0.0227, 0.0314, 0.3929, 0.3148, 0.0792, 0.0389, 0.0470, 0.0172,\n",
      "         0.0206, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0016, 0.0008, 0.0027, 0.3304, 0.4617, 0.0907, 0.0737, 0.0294, 0.0060,\n",
      "         0.0029, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0031, 0.0015, 0.0037, 0.1314, 0.3867, 0.1644, 0.2122, 0.0754, 0.0174,\n",
      "         0.0043, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0060, 0.0026, 0.0045, 0.1459, 0.4010, 0.1431, 0.2316, 0.0504, 0.0126,\n",
      "         0.0023, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0054, 0.0023, 0.0044, 0.1277, 0.3420, 0.1503, 0.3057, 0.0465, 0.0133,\n",
      "         0.0023, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0164, 0.0071, 0.0083, 0.1709, 0.3765, 0.1175, 0.2455, 0.0419, 0.0124,\n",
      "         0.0036, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0179, 0.0051, 0.0065, 0.1211, 0.2482, 0.1223, 0.3365, 0.1091, 0.0246,\n",
      "         0.0088, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0178, 0.0072, 0.0110, 0.1170, 0.2120, 0.1201, 0.3278, 0.1224, 0.0547,\n",
      "         0.0101, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0346, 0.0164, 0.0192, 0.2238, 0.2735, 0.0963, 0.2030, 0.0873, 0.0344,\n",
      "         0.0114, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0354, 0.0151, 0.0177, 0.2184, 0.2726, 0.0944, 0.1797, 0.0998, 0.0485,\n",
      "         0.0183, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0380, 0.0183, 0.0222, 0.1966, 0.2583, 0.0998, 0.1747, 0.0979, 0.0677,\n",
      "         0.0265, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0387, 0.0189, 0.0218, 0.2157, 0.2698, 0.0962, 0.1551, 0.0935, 0.0609,\n",
      "         0.0293, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0232, 0.0056, 0.0100, 0.1558, 0.2382, 0.0928, 0.1443, 0.1428, 0.0961,\n",
      "         0.0913, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0158, 0.0038, 0.0082, 0.1232, 0.1869, 0.0943, 0.1533, 0.1784, 0.1230,\n",
      "         0.1130, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0280, 0.0085, 0.0130, 0.2316, 0.2857, 0.0911, 0.1338, 0.1000, 0.0647,\n",
      "         0.0434, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0297, 0.0104, 0.0146, 0.2344, 0.2889, 0.0898, 0.1329, 0.0953, 0.0640,\n",
      "         0.0399, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0318, 0.0128, 0.0167, 0.2394, 0.2894, 0.0897, 0.1333, 0.0895, 0.0618,\n",
      "         0.0357, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1.38, Train Loss: 0.00, Val Loss: 5.61, Train BLEU: 0.00, Val BLEU: 3.38, Minutes Elapsed: 127.98\n",
      "Sampling from val predictions...\n",
      "Source: 当 他 长大 了 他 变得 更加 独特 这些 特别 别的 地方 更加 明显 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: and as he grew older , he grew more different , and the differences became more obvious . <EOS>\n",
      "Model: <SOS> and he he , , , , , , to , . the &apos;s . . . . <EOS>\n",
      "Attention Weights: tensor([[0.0284, 0.9607, 0.0032, 0.0010, 0.0066, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0030, 0.9505, 0.0251, 0.0023, 0.0185, 0.0004, 0.0001, 0.0000, 0.0001,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0038, 0.4543, 0.1896, 0.0415, 0.2765, 0.0253, 0.0030, 0.0010, 0.0018,\n",
      "         0.0007, 0.0008, 0.0003, 0.0003, 0.0003, 0.0007, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0036, 0.2326, 0.2031, 0.0717, 0.4312, 0.0480, 0.0037, 0.0010, 0.0018,\n",
      "         0.0007, 0.0008, 0.0004, 0.0004, 0.0004, 0.0006, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0013, 0.1004, 0.0871, 0.0359, 0.6965, 0.0679, 0.0047, 0.0010, 0.0025,\n",
      "         0.0006, 0.0010, 0.0003, 0.0003, 0.0003, 0.0003, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0013, 0.0139, 0.0372, 0.0241, 0.5161, 0.3201, 0.0465, 0.0118, 0.0179,\n",
      "         0.0036, 0.0035, 0.0012, 0.0013, 0.0010, 0.0006, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0014, 0.0092, 0.0200, 0.0122, 0.3701, 0.3299, 0.1134, 0.0398, 0.0751,\n",
      "         0.0110, 0.0109, 0.0024, 0.0023, 0.0016, 0.0008, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0010, 0.0063, 0.0072, 0.0040, 0.0950, 0.0951, 0.1095, 0.0989, 0.4195,\n",
      "         0.0617, 0.0789, 0.0105, 0.0079, 0.0037, 0.0009, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0004, 0.0035, 0.0046, 0.0030, 0.1049, 0.1461, 0.1839, 0.1166, 0.3059,\n",
      "         0.0537, 0.0598, 0.0094, 0.0058, 0.0021, 0.0005, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0002, 0.0006, 0.0009, 0.0007, 0.0035, 0.0114, 0.0367, 0.1114, 0.3796,\n",
      "         0.1520, 0.1828, 0.0590, 0.0414, 0.0181, 0.0016, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0002, 0.0006, 0.0008, 0.0006, 0.0030, 0.0072, 0.0222, 0.0756, 0.3566,\n",
      "         0.1411, 0.2122, 0.0838, 0.0631, 0.0312, 0.0017, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0003, 0.0009, 0.0011, 0.0007, 0.0034, 0.0050, 0.0123, 0.0429, 0.2565,\n",
      "         0.1229, 0.2851, 0.1183, 0.0968, 0.0518, 0.0021, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0004, 0.0017, 0.0020, 0.0011, 0.0056, 0.0059, 0.0099, 0.0275, 0.1804,\n",
      "         0.0968, 0.3242, 0.1437, 0.1246, 0.0737, 0.0026, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0001, 0.0005, 0.0007, 0.0004, 0.0028, 0.0030, 0.0056, 0.0182, 0.1538,\n",
      "         0.0970, 0.3247, 0.1630, 0.1523, 0.0761, 0.0016, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0002, 0.0014, 0.0016, 0.0010, 0.0063, 0.0047, 0.0065, 0.0136, 0.1024,\n",
      "         0.0715, 0.2870, 0.1727, 0.2059, 0.1225, 0.0027, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0007, 0.0053, 0.0035, 0.0021, 0.0166, 0.0074, 0.0096, 0.0156, 0.1343,\n",
      "         0.0617, 0.3586, 0.1239, 0.1633, 0.0950, 0.0025, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0008, 0.0041, 0.0045, 0.0025, 0.0126, 0.0103, 0.0111, 0.0155, 0.0925,\n",
      "         0.0469, 0.2356, 0.1138, 0.2136, 0.2256, 0.0108, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0013, 0.0041, 0.0060, 0.0035, 0.0119, 0.0148, 0.0168, 0.0246, 0.0834,\n",
      "         0.0498, 0.1537, 0.0974, 0.2022, 0.2976, 0.0329, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0018, 0.0050, 0.0071, 0.0043, 0.0126, 0.0157, 0.0192, 0.0293, 0.0791,\n",
      "         0.0520, 0.1391, 0.1044, 0.2075, 0.2814, 0.0416, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 1.44, Train Loss: 0.00, Val Loss: 5.53, Train BLEU: 0.00, Val BLEU: 3.82, Minutes Elapsed: 133.09\n",
      "Sampling from val predictions...\n",
      "Source: 你 不能 有 任何 <UNK> 否则 结果 将 一团 一团糟 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: you don &apos;t get a chance to mess it up . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> you can &apos;t know to to of you to . <EOS> . <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9956, 0.0044, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.4355, 0.5232, 0.0198, 0.0205, 0.0003, 0.0003, 0.0001, 0.0001, 0.0000,\n",
      "         0.0000, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1975, 0.5903, 0.0620, 0.1378, 0.0035, 0.0039, 0.0013, 0.0009, 0.0006,\n",
      "         0.0007, 0.0015, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0106, 0.0522, 0.0670, 0.7981, 0.0337, 0.0138, 0.0062, 0.0050, 0.0037,\n",
      "         0.0043, 0.0054, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0047, 0.0146, 0.0345, 0.8104, 0.0669, 0.0330, 0.0126, 0.0075, 0.0046,\n",
      "         0.0053, 0.0058, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0067, 0.0121, 0.0211, 0.6562, 0.1371, 0.0672, 0.0285, 0.0240, 0.0151,\n",
      "         0.0171, 0.0148, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0037, 0.0057, 0.0125, 0.3229, 0.1866, 0.1558, 0.1129, 0.0934, 0.0454,\n",
      "         0.0434, 0.0177, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0118, 0.0095, 0.0076, 0.2180, 0.1568, 0.4168, 0.1013, 0.0508, 0.0125,\n",
      "         0.0099, 0.0050, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0118, 0.0087, 0.0049, 0.0634, 0.0649, 0.4132, 0.1921, 0.1730, 0.0375,\n",
      "         0.0252, 0.0054, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0011, 0.0018, 0.0025, 0.0169, 0.0321, 0.0736, 0.1559, 0.4174, 0.1804,\n",
      "         0.1067, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0048, 0.0050, 0.0047, 0.0216, 0.0216, 0.0563, 0.0938, 0.3495, 0.2036,\n",
      "         0.1942, 0.0449, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0034, 0.0042, 0.0050, 0.0204, 0.0207, 0.0257, 0.0598, 0.2665, 0.2653,\n",
      "         0.2766, 0.0523, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0042, 0.0043, 0.0049, 0.0181, 0.0181, 0.0220, 0.0457, 0.2071, 0.2492,\n",
      "         0.3228, 0.1035, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0034, 0.0050, 0.0047, 0.0204, 0.0145, 0.0425, 0.0639, 0.2808, 0.2507,\n",
      "         0.2734, 0.0407, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0076, 0.0100, 0.0066, 0.0283, 0.0192, 0.0609, 0.0623, 0.2262, 0.2093,\n",
      "         0.3047, 0.0649, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0391, 0.0220, 0.0146, 0.0499, 0.0271, 0.0846, 0.0699, 0.1833, 0.1444,\n",
      "         0.2511, 0.1140, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0635, 0.0315, 0.0190, 0.0666, 0.0319, 0.0945, 0.0706, 0.1789, 0.1246,\n",
      "         0.2086, 0.1103, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0802, 0.0387, 0.0225, 0.0783, 0.0349, 0.0980, 0.0673, 0.1718, 0.1124,\n",
      "         0.1864, 0.1095, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0903, 0.0437, 0.0249, 0.0858, 0.0371, 0.1000, 0.0654, 0.1635, 0.1047,\n",
      "         0.1742, 0.1103, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 1.49, Train Loss: 0.00, Val Loss: 5.56, Train BLEU: 0.00, Val BLEU: 4.36, Minutes Elapsed: 138.19\n",
      "Sampling from val predictions...\n",
      "Source: 自己 种 食物 就 好像 自己 印 钱 似的 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: growing your own food is like printing your own money . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> and &apos;s , , , <EOS> . . <EOS> . . <EOS> <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9382, 0.0283, 0.0086, 0.0214, 0.0032, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.7116, 0.2096, 0.0419, 0.0193, 0.0126, 0.0017, 0.0004, 0.0004, 0.0011,\n",
      "         0.0016, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2150, 0.2975, 0.1994, 0.1305, 0.1088, 0.0205, 0.0045, 0.0043, 0.0098,\n",
      "         0.0095, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0259, 0.0150, 0.1753, 0.2997, 0.3549, 0.1104, 0.0047, 0.0045, 0.0070,\n",
      "         0.0025, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0090, 0.0063, 0.0741, 0.2033, 0.3298, 0.3463, 0.0117, 0.0099, 0.0083,\n",
      "         0.0014, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0105, 0.0064, 0.0378, 0.0651, 0.1717, 0.6231, 0.0347, 0.0286, 0.0203,\n",
      "         0.0019, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0090, 0.0041, 0.0127, 0.0427, 0.1248, 0.6860, 0.0346, 0.0358, 0.0472,\n",
      "         0.0031, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0089, 0.0058, 0.0115, 0.0162, 0.0534, 0.6555, 0.0889, 0.0883, 0.0674,\n",
      "         0.0041, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0121, 0.0097, 0.0138, 0.0168, 0.0511, 0.5434, 0.1143, 0.1205, 0.1086,\n",
      "         0.0098, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0313, 0.0170, 0.0250, 0.0428, 0.0761, 0.4473, 0.0742, 0.1039, 0.1568,\n",
      "         0.0256, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0239, 0.0187, 0.0236, 0.0257, 0.0513, 0.3470, 0.1287, 0.1722, 0.1723,\n",
      "         0.0366, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0277, 0.0249, 0.0281, 0.0239, 0.0469, 0.2924, 0.1389, 0.1757, 0.1888,\n",
      "         0.0527, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0391, 0.0280, 0.0317, 0.0322, 0.0605, 0.2908, 0.1073, 0.1430, 0.2071,\n",
      "         0.0603, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0326, 0.0224, 0.0268, 0.0509, 0.0742, 0.2838, 0.0840, 0.1319, 0.2306,\n",
      "         0.0628, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0188, 0.0154, 0.0200, 0.0443, 0.0676, 0.3011, 0.0816, 0.1389, 0.2521,\n",
      "         0.0602, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0471, 0.0257, 0.0377, 0.0718, 0.0987, 0.2868, 0.0649, 0.1135, 0.2017,\n",
      "         0.0522, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0634, 0.0338, 0.0479, 0.0832, 0.1103, 0.2765, 0.0583, 0.0964, 0.1810,\n",
      "         0.0491, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0740, 0.0389, 0.0552, 0.0874, 0.1124, 0.2682, 0.0565, 0.0909, 0.1689,\n",
      "         0.0475, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0804, 0.0423, 0.0605, 0.0900, 0.1135, 0.2597, 0.0560, 0.0885, 0.1615,\n",
      "         0.0474, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1.55, Train Loss: 0.00, Val Loss: 5.50, Train BLEU: 0.00, Val BLEU: 3.94, Minutes Elapsed: 143.29\n",
      "Sampling from val predictions...\n",
      "Source: 我 原本 以为 世界 上 只有 我 一个 个人 会 继续 留在 一个 一个打 我 的 男人 人身 身边 但是\n",
      "Reference: i would have told you myself that i was the last person on earth who would stay with a\n",
      "Model: <SOS> i i a my my my my my my my my , , my , <EOS> . . <EOS>\n",
      "Attention Weights: tensor([[9.2633e-01, 8.4187e-03, 3.1097e-02, 2.6569e-02, 4.4943e-03, 1.0225e-03,\n",
      "         1.8527e-03, 5.9032e-05, 1.2667e-04, 1.5741e-05, 1.9457e-06, 2.1723e-06,\n",
      "         1.7177e-06, 5.3046e-07, 6.4603e-06, 2.5326e-07, 4.4308e-07, 2.3778e-07,\n",
      "         1.7695e-07, 1.1698e-07],\n",
      "        [1.0911e-01, 9.9887e-02, 4.9030e-01, 2.3672e-01, 2.9422e-02, 1.0896e-02,\n",
      "         1.4888e-02, 2.5293e-03, 4.2254e-03, 7.4227e-04, 2.3138e-04, 2.9212e-04,\n",
      "         1.4735e-04, 7.4046e-05, 2.4914e-04, 7.2767e-05, 1.1744e-04, 5.8948e-05,\n",
      "         3.0135e-05, 1.2053e-05],\n",
      "        [4.9277e-02, 6.6026e-02, 4.5769e-01, 2.4680e-01, 5.3100e-02, 3.4363e-02,\n",
      "         6.0202e-02, 9.8871e-03, 1.5151e-02, 2.4608e-03, 1.2685e-03, 1.1544e-03,\n",
      "         5.0434e-04, 2.3464e-04, 8.7399e-04, 2.4086e-04, 3.2047e-04, 1.7880e-04,\n",
      "         1.7048e-04, 9.8760e-05],\n",
      "        [3.4904e-03, 5.5173e-03, 1.2097e-01, 3.4441e-01, 3.9115e-02, 3.2378e-02,\n",
      "         2.1212e-01, 7.6993e-02, 1.0709e-01, 1.4187e-02, 9.6492e-03, 1.0587e-02,\n",
      "         6.7919e-03, 2.2886e-03, 7.6539e-03, 2.0079e-03, 3.0680e-03, 1.0351e-03,\n",
      "         4.5014e-04, 1.9555e-04],\n",
      "        [1.9009e-03, 1.5894e-03, 4.9200e-02, 2.5869e-01, 2.7224e-02, 2.6682e-02,\n",
      "         2.9898e-01, 9.7477e-02, 1.3295e-01, 2.0300e-02, 1.8547e-02, 2.2564e-02,\n",
      "         1.2928e-02, 4.0787e-03, 1.6220e-02, 3.3298e-03, 4.9030e-03, 1.5337e-03,\n",
      "         6.7134e-04, 2.3231e-04],\n",
      "        [1.3530e-03, 7.8714e-04, 1.7953e-02, 1.3833e-01, 1.4114e-02, 1.6498e-02,\n",
      "         2.8937e-01, 9.5747e-02, 1.6429e-01, 4.3064e-02, 4.7036e-02, 5.6612e-02,\n",
      "         3.1987e-02, 1.0123e-02, 4.6575e-02, 7.9449e-03, 1.2366e-02, 3.6707e-03,\n",
      "         1.6565e-03, 5.2641e-04],\n",
      "        [1.7794e-03, 6.3833e-04, 8.3658e-03, 5.6349e-02, 8.4531e-03, 1.1957e-02,\n",
      "         1.8631e-01, 6.4002e-02, 1.5877e-01, 8.8747e-02, 1.0249e-01, 1.0189e-01,\n",
      "         4.8964e-02, 2.0787e-02, 8.2607e-02, 1.5464e-02, 2.6798e-02, 1.0019e-02,\n",
      "         4.6120e-03, 9.9616e-04],\n",
      "        [3.5819e-04, 3.0149e-04, 3.5118e-03, 2.4266e-02, 2.5474e-03, 3.0110e-03,\n",
      "         9.8273e-02, 5.0147e-02, 8.6848e-02, 3.0825e-02, 8.3510e-02, 1.2944e-01,\n",
      "         1.1695e-01, 4.6723e-02, 1.8282e-01, 4.3363e-02, 6.7831e-02, 1.9714e-02,\n",
      "         8.0534e-03, 1.5074e-03],\n",
      "        [3.3559e-04, 2.3123e-04, 1.8250e-03, 8.4266e-03, 1.3460e-03, 1.6359e-03,\n",
      "         5.1809e-02, 1.6170e-02, 3.6259e-02, 2.0288e-02, 7.3562e-02, 1.2028e-01,\n",
      "         1.0897e-01, 5.1284e-02, 2.7185e-01, 6.1147e-02, 1.0092e-01, 4.1244e-02,\n",
      "         2.7398e-02, 5.0067e-03],\n",
      "        [5.3844e-04, 2.7238e-04, 1.4581e-03, 3.9463e-03, 1.0148e-03, 1.6013e-03,\n",
      "         3.3311e-02, 7.6940e-03, 2.7727e-02, 2.4641e-02, 9.2769e-02, 1.2630e-01,\n",
      "         6.2710e-02, 4.5904e-02, 2.3253e-01, 5.7792e-02, 1.1684e-01, 7.4759e-02,\n",
      "         7.5895e-02, 1.2295e-02],\n",
      "        [3.0899e-04, 2.1992e-04, 1.6866e-03, 5.6888e-03, 9.4103e-04, 1.0507e-03,\n",
      "         1.9978e-02, 1.3502e-02, 1.9738e-02, 8.0163e-03, 3.6722e-02, 8.5188e-02,\n",
      "         1.1590e-01, 4.8808e-02, 2.8595e-01, 8.4291e-02, 1.5738e-01, 6.0219e-02,\n",
      "         4.2311e-02, 1.2098e-02],\n",
      "        [3.1525e-04, 1.3370e-04, 9.2158e-04, 3.4395e-03, 6.4703e-04, 7.3528e-04,\n",
      "         1.9599e-02, 4.5154e-03, 1.1752e-02, 7.5068e-03, 3.6944e-02, 7.9231e-02,\n",
      "         6.2862e-02, 2.9907e-02, 4.0078e-01, 5.1256e-02, 1.2944e-01, 6.3274e-02,\n",
      "         7.5565e-02, 2.1177e-02],\n",
      "        [1.3745e-03, 2.0705e-04, 7.3854e-04, 1.6296e-03, 5.9452e-04, 1.0319e-03,\n",
      "         1.9876e-02, 1.1780e-03, 8.5950e-03, 1.1792e-02, 4.1518e-02, 5.5921e-02,\n",
      "         1.6422e-02, 1.2107e-02, 3.5645e-01, 2.1074e-02, 1.0773e-01, 8.6310e-02,\n",
      "         1.9896e-01, 5.6492e-02],\n",
      "        [2.4362e-03, 3.5238e-04, 1.0339e-03, 1.5816e-03, 6.9269e-04, 1.2337e-03,\n",
      "         1.4665e-02, 9.5060e-04, 6.5510e-03, 8.9963e-03, 2.6046e-02, 3.4706e-02,\n",
      "         1.0675e-02, 8.4476e-03, 2.7526e-01, 1.6158e-02, 1.0213e-01, 9.3657e-02,\n",
      "         2.8223e-01, 1.1220e-01],\n",
      "        [3.0920e-03, 5.8625e-04, 2.1646e-03, 2.4085e-03, 1.0940e-03, 1.5049e-03,\n",
      "         1.4705e-02, 1.5904e-03, 5.3183e-03, 5.6159e-03, 1.4040e-02, 1.8100e-02,\n",
      "         8.7432e-03, 6.4233e-03, 1.9252e-01, 1.2566e-02, 7.9196e-02, 7.2562e-02,\n",
      "         3.4671e-01, 2.1106e-01],\n",
      "        [4.9343e-03, 8.2161e-04, 2.3008e-03, 3.1198e-03, 1.7544e-03, 2.8813e-03,\n",
      "         1.2351e-02, 1.5547e-03, 6.1533e-03, 8.0497e-03, 1.3190e-02, 1.5087e-02,\n",
      "         6.9572e-03, 6.2978e-03, 1.5172e-01, 9.4572e-03, 5.8571e-02, 6.5568e-02,\n",
      "         3.0290e-01, 3.2633e-01],\n",
      "        [1.7156e-02, 3.2070e-03, 9.0123e-03, 1.0956e-02, 5.4162e-03, 7.3293e-03,\n",
      "         4.0773e-02, 5.3992e-03, 1.9149e-02, 1.7777e-02, 2.6057e-02, 2.6090e-02,\n",
      "         1.2868e-02, 1.0042e-02, 2.1138e-01, 1.1524e-02, 6.4675e-02, 5.5306e-02,\n",
      "         2.5154e-01, 1.9433e-01],\n",
      "        [3.5412e-03, 2.4605e-03, 1.6205e-02, 2.0732e-02, 5.5839e-03, 5.6009e-03,\n",
      "         4.5406e-02, 1.8027e-02, 2.2002e-02, 1.3594e-02, 3.3341e-02, 4.2812e-02,\n",
      "         3.2462e-02, 2.1739e-02, 1.9083e-01, 3.2310e-02, 6.6128e-02, 4.6285e-02,\n",
      "         1.5131e-01, 2.2963e-01],\n",
      "        [6.2221e-03, 4.2343e-03, 2.2790e-02, 4.2376e-02, 8.8921e-03, 7.9861e-03,\n",
      "         5.6093e-02, 4.6335e-02, 3.2141e-02, 1.2771e-02, 3.0281e-02, 5.7046e-02,\n",
      "         9.4253e-02, 4.4917e-02, 1.8150e-01, 6.4800e-02, 9.4540e-02, 4.7203e-02,\n",
      "         5.9886e-02, 8.5732e-02]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 1.60, Train Loss: 0.00, Val Loss: 5.49, Train BLEU: 0.00, Val BLEU: 4.56, Minutes Elapsed: 148.38\n",
      "Sampling from val predictions...\n",
      "Source: 奴隶 奴隶制 奴隶制度 制度 存在 在于 世上 的 几乎 每 一个 一个角 角落 即使 它 无论 在 何处 都 是\n",
      "Reference: slavery exists everywhere , nearly , in the world , and yet it is illegal everywhere in the world\n",
      "Model: <SOS> and are is the the is , &apos;s , , , is &apos;s it . . <EOS> <EOS> .\n",
      "Attention Weights: tensor([[6.5469e-02, 1.3759e-03, 1.0067e-02, 1.9398e-01, 6.8025e-01, 4.0980e-02,\n",
      "         6.8818e-03, 5.3152e-05, 1.3792e-04, 6.7776e-06, 6.8296e-06, 4.3260e-06,\n",
      "         3.8068e-04, 1.9155e-04, 1.8568e-04, 1.7717e-05, 2.0164e-07, 5.8410e-06,\n",
      "         2.8349e-07, 3.0727e-07],\n",
      "        [1.1581e-01, 1.5132e-02, 5.7581e-02, 2.3166e-01, 4.2383e-01, 9.7243e-02,\n",
      "         4.4199e-02, 2.2113e-03, 5.9765e-03, 4.5488e-04, 2.8978e-04, 1.9267e-04,\n",
      "         2.4604e-03, 1.3996e-03, 1.1298e-03, 3.1615e-04, 1.5843e-05, 7.9260e-05,\n",
      "         1.1771e-05, 6.7336e-06],\n",
      "        [3.4515e-02, 9.2485e-03, 3.7525e-02, 1.5181e-01, 3.7414e-01, 1.8324e-01,\n",
      "         1.2122e-01, 1.1364e-02, 4.4502e-02, 3.1799e-03, 2.4057e-03, 1.0276e-03,\n",
      "         9.0534e-03, 8.8788e-03, 4.9521e-03, 1.9979e-03, 1.9382e-04, 5.2082e-04,\n",
      "         1.2793e-04, 9.5810e-05],\n",
      "        [5.4558e-02, 1.1007e-02, 3.0895e-02, 6.7283e-02, 1.6262e-01, 1.8077e-01,\n",
      "         2.5371e-01, 2.1610e-02, 1.1450e-01, 8.9583e-03, 7.4675e-03, 2.6890e-03,\n",
      "         2.8056e-02, 2.5895e-02, 2.1781e-02, 6.3927e-03, 2.3394e-04, 1.3600e-03,\n",
      "         1.2042e-04, 8.4560e-05],\n",
      "        [2.1775e-02, 7.6469e-03, 1.5351e-02, 2.0756e-02, 4.9566e-02, 1.1759e-01,\n",
      "         3.0217e-01, 3.2479e-02, 2.4288e-01, 2.7857e-02, 3.2601e-02, 1.0653e-02,\n",
      "         5.2533e-02, 2.4150e-02, 2.6791e-02, 1.2502e-02, 5.1244e-04, 1.8394e-03,\n",
      "         1.9025e-04, 1.5625e-04],\n",
      "        [4.8759e-03, 1.2968e-03, 2.1698e-03, 2.5961e-03, 6.2410e-03, 2.4062e-02,\n",
      "         1.3956e-01, 9.2187e-03, 1.8814e-01, 2.3312e-02, 5.6266e-02, 3.3256e-02,\n",
      "         1.2672e-01, 8.4119e-02, 1.8256e-01, 9.2492e-02, 3.4852e-03, 1.7501e-02,\n",
      "         1.2126e-03, 9.1869e-04],\n",
      "        [2.3331e-03, 1.7683e-03, 2.8599e-03, 4.1762e-03, 1.0458e-02, 2.9614e-02,\n",
      "         8.5043e-02, 1.5507e-02, 1.3861e-01, 3.3471e-02, 7.0556e-02, 4.7745e-02,\n",
      "         9.2850e-02, 1.2080e-01, 1.5153e-01, 1.3980e-01, 1.1810e-02, 3.4961e-02,\n",
      "         4.1398e-03, 1.9684e-03],\n",
      "        [1.4026e-03, 3.8262e-04, 6.3531e-04, 8.8740e-04, 1.6287e-03, 4.4175e-03,\n",
      "         2.1105e-02, 1.7851e-03, 4.2148e-02, 6.1015e-03, 1.9115e-02, 2.2345e-02,\n",
      "         7.6215e-02, 1.0885e-01, 3.2060e-01, 2.1844e-01, 1.5511e-02, 1.2360e-01,\n",
      "         9.4819e-03, 5.3412e-03],\n",
      "        [8.0543e-04, 6.0583e-04, 9.7988e-04, 1.4167e-03, 3.3979e-03, 9.0781e-03,\n",
      "         2.9944e-02, 5.0882e-03, 6.2489e-02, 1.3646e-02, 4.3826e-02, 4.2242e-02,\n",
      "         6.7714e-02, 1.0015e-01, 1.8247e-01, 2.2092e-01, 3.5500e-02, 1.3770e-01,\n",
      "         2.6222e-02, 1.5805e-02],\n",
      "        [1.1902e-03, 2.4474e-04, 4.2498e-04, 7.5587e-04, 1.0496e-03, 1.8647e-03,\n",
      "         6.3845e-03, 5.4216e-04, 1.1299e-02, 1.9562e-03, 5.0388e-03, 9.7560e-03,\n",
      "         5.4711e-02, 1.3270e-01, 3.2737e-01, 1.6014e-01, 1.4274e-02, 2.2987e-01,\n",
      "         2.4051e-02, 1.6383e-02],\n",
      "        [1.1061e-03, 2.6127e-04, 4.5444e-04, 7.7570e-04, 9.7360e-04, 1.4272e-03,\n",
      "         4.1420e-03, 5.0325e-04, 7.8005e-03, 1.4888e-03, 3.8776e-03, 7.6509e-03,\n",
      "         3.5218e-02, 9.3005e-02, 3.2133e-01, 1.5115e-01, 1.5214e-02, 2.8961e-01,\n",
      "         3.5050e-02, 2.8958e-02],\n",
      "        [6.3677e-04, 1.7840e-04, 3.0443e-04, 4.8057e-04, 7.8964e-04, 1.2181e-03,\n",
      "         3.1076e-03, 4.9381e-04, 5.0691e-03, 8.6060e-04, 2.3422e-03, 3.6348e-03,\n",
      "         1.0782e-02, 2.8736e-02, 1.8971e-01, 1.6057e-01, 1.2429e-02, 4.1555e-01,\n",
      "         6.2233e-02, 1.0087e-01],\n",
      "        [5.3552e-04, 3.6994e-04, 5.8186e-04, 8.2436e-04, 1.6527e-03, 2.7529e-03,\n",
      "         6.6226e-03, 1.5936e-03, 1.1782e-02, 2.5894e-03, 7.8840e-03, 9.6595e-03,\n",
      "         1.6013e-02, 3.1828e-02, 9.2973e-02, 1.5060e-01, 2.5793e-02, 2.9935e-01,\n",
      "         1.0536e-01, 2.3124e-01],\n",
      "        [7.7536e-04, 5.9114e-04, 9.6729e-04, 1.4277e-03, 2.4617e-03, 3.4008e-03,\n",
      "         6.6497e-03, 1.9615e-03, 9.2625e-03, 2.6276e-03, 5.7555e-03, 6.6457e-03,\n",
      "         1.1948e-02, 2.6569e-02, 8.2677e-02, 1.1238e-01, 2.0722e-02, 2.9020e-01,\n",
      "         1.0902e-01, 3.0396e-01],\n",
      "        [4.8397e-03, 3.0564e-03, 3.6263e-03, 3.3492e-03, 4.2327e-03, 8.3497e-03,\n",
      "         2.4252e-02, 6.6581e-03, 3.1509e-02, 1.2060e-02, 2.0249e-02, 2.0024e-02,\n",
      "         1.9975e-02, 1.2754e-02, 5.3141e-02, 9.1694e-02, 2.2734e-02, 2.1512e-01,\n",
      "         7.5415e-02, 3.6696e-01],\n",
      "        [1.1785e-02, 9.4189e-03, 9.8469e-03, 8.3428e-03, 9.5859e-03, 1.7843e-02,\n",
      "         5.1272e-02, 1.9384e-02, 6.7309e-02, 3.7594e-02, 7.4240e-02, 5.2826e-02,\n",
      "         3.0590e-02, 1.6213e-02, 4.5128e-02, 7.9940e-02, 3.3917e-02, 1.1360e-01,\n",
      "         6.5020e-02, 2.4614e-01],\n",
      "        [1.7477e-02, 1.5100e-02, 1.3973e-02, 1.0868e-02, 1.1446e-02, 2.1493e-02,\n",
      "         5.5298e-02, 2.4035e-02, 6.5745e-02, 4.3552e-02, 6.7359e-02, 6.2341e-02,\n",
      "         3.6724e-02, 1.7067e-02, 4.8800e-02, 8.1720e-02, 3.7541e-02, 1.2480e-01,\n",
      "         5.8295e-02, 1.8637e-01],\n",
      "        [3.0299e-02, 1.7689e-02, 1.7447e-02, 1.5212e-02, 1.7335e-02, 2.9606e-02,\n",
      "         6.3439e-02, 2.6978e-02, 6.9687e-02, 4.1187e-02, 6.4152e-02, 5.5597e-02,\n",
      "         4.3125e-02, 2.3272e-02, 7.1452e-02, 8.5226e-02, 3.6404e-02, 1.2742e-01,\n",
      "         4.7244e-02, 1.1723e-01],\n",
      "        [3.7333e-02, 1.6953e-02, 1.7673e-02, 1.6758e-02, 2.1418e-02, 3.3973e-02,\n",
      "         6.7671e-02, 2.4664e-02, 6.7799e-02, 3.3847e-02, 5.0088e-02, 4.4526e-02,\n",
      "         5.0704e-02, 3.0511e-02, 8.7759e-02, 9.0393e-02, 3.5215e-02, 1.3910e-01,\n",
      "         4.3144e-02, 9.0477e-02]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1.66, Train Loss: 0.00, Val Loss: 5.49, Train BLEU: 0.00, Val BLEU: 4.19, Minutes Elapsed: 153.50\n",
      "Sampling from val predictions...\n",
      "Source: 食物 是 问题 食物 也 是 解决 解决方案 方案 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: food is the problem and food is the solution . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> the is is a of the is <EOS> . . <EOS> <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9762, 0.0225, 0.0013, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.8917, 0.0854, 0.0218, 0.0008, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1872, 0.2940, 0.4490, 0.0410, 0.0138, 0.0046, 0.0026, 0.0017, 0.0031,\n",
      "         0.0029, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0299, 0.0391, 0.3695, 0.3642, 0.1542, 0.0224, 0.0133, 0.0022, 0.0038,\n",
      "         0.0013, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0152, 0.0060, 0.1134, 0.5559, 0.1982, 0.0420, 0.0444, 0.0088, 0.0131,\n",
      "         0.0030, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0543, 0.0163, 0.0949, 0.4672, 0.2636, 0.0515, 0.0319, 0.0066, 0.0106,\n",
      "         0.0033, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0089, 0.0054, 0.0353, 0.2548, 0.3426, 0.1399, 0.1457, 0.0245, 0.0380,\n",
      "         0.0050, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0064, 0.0056, 0.0312, 0.1408, 0.2191, 0.1753, 0.2681, 0.0668, 0.0767,\n",
      "         0.0100, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0177, 0.0121, 0.0388, 0.1267, 0.1427, 0.1303, 0.2707, 0.0941, 0.1369,\n",
      "         0.0300, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0135, 0.0066, 0.0271, 0.0930, 0.0597, 0.0753, 0.2968, 0.1668, 0.2186,\n",
      "         0.0427, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0696, 0.0133, 0.0503, 0.3081, 0.1178, 0.0781, 0.1646, 0.0676, 0.0992,\n",
      "         0.0314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0822, 0.0314, 0.0761, 0.1889, 0.1185, 0.0864, 0.1706, 0.0758, 0.1226,\n",
      "         0.0476, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0128, 0.0167, 0.0384, 0.0653, 0.0816, 0.0925, 0.2208, 0.1528, 0.2307,\n",
      "         0.0882, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0169, 0.0160, 0.0363, 0.0786, 0.0752, 0.0818, 0.2116, 0.1578, 0.2189,\n",
      "         0.1070, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0424, 0.0402, 0.0708, 0.1032, 0.1299, 0.0982, 0.1582, 0.0878, 0.1666,\n",
      "         0.1027, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0498, 0.0450, 0.0827, 0.1060, 0.1302, 0.0949, 0.1440, 0.0791, 0.1675,\n",
      "         0.1006, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0608, 0.0499, 0.0914, 0.1125, 0.1273, 0.0918, 0.1356, 0.0736, 0.1616,\n",
      "         0.0956, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0701, 0.0538, 0.0978, 0.1171, 0.1254, 0.0894, 0.1290, 0.0696, 0.1553,\n",
      "         0.0926, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0768, 0.0565, 0.1019, 0.1201, 0.1241, 0.0877, 0.1241, 0.0670, 0.1506,\n",
      "         0.0913, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 1.71, Train Loss: 0.00, Val Loss: 5.51, Train BLEU: 0.00, Val BLEU: 4.12, Minutes Elapsed: 158.60\n",
      "Sampling from val predictions...\n",
      "Source: 几乎 没人 遵守 一夫 一夫一妻 <UNK> <UNK> 制度 掌声 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: they are hardly monogamous . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> and &apos;s &apos;t , , . , . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.8643, 0.1327, 0.0027, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1901, 0.6418, 0.1499, 0.0044, 0.0051, 0.0008, 0.0011, 0.0027, 0.0011,\n",
      "         0.0030, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0607, 0.6393, 0.2710, 0.0074, 0.0077, 0.0017, 0.0023, 0.0041, 0.0022,\n",
      "         0.0037, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0021, 0.0592, 0.6819, 0.1017, 0.0837, 0.0117, 0.0141, 0.0242, 0.0123,\n",
      "         0.0090, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0010, 0.0203, 0.3495, 0.1322, 0.2264, 0.0368, 0.0516, 0.1061, 0.0426,\n",
      "         0.0335, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0014, 0.0113, 0.1530, 0.1425, 0.4149, 0.0591, 0.0684, 0.0960, 0.0370,\n",
      "         0.0164, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0020, 0.0091, 0.0616, 0.0929, 0.4790, 0.0763, 0.0908, 0.1234, 0.0494,\n",
      "         0.0156, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0015, 0.0094, 0.0421, 0.0356, 0.3303, 0.1041, 0.1642, 0.2251, 0.0742,\n",
      "         0.0137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0016, 0.0075, 0.0165, 0.0125, 0.1458, 0.0819, 0.1865, 0.3582, 0.1593,\n",
      "         0.0301, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0100, 0.0333, 0.0372, 0.0125, 0.0899, 0.0414, 0.1037, 0.3412, 0.2181,\n",
      "         0.1128, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0196, 0.0539, 0.0573, 0.0164, 0.0922, 0.0420, 0.0968, 0.3024, 0.1818,\n",
      "         0.1376, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0237, 0.0615, 0.0683, 0.0179, 0.0895, 0.0397, 0.0892, 0.2892, 0.1693,\n",
      "         0.1518, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0261, 0.0655, 0.0759, 0.0189, 0.0874, 0.0379, 0.0845, 0.2812, 0.1636,\n",
      "         0.1591, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0277, 0.0684, 0.0816, 0.0197, 0.0863, 0.0368, 0.0818, 0.2740, 0.1607,\n",
      "         0.1630, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0290, 0.0708, 0.0861, 0.0205, 0.0858, 0.0363, 0.0804, 0.2669, 0.1590,\n",
      "         0.1653, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0301, 0.0729, 0.0896, 0.0212, 0.0856, 0.0360, 0.0796, 0.2603, 0.1578,\n",
      "         0.1668, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0310, 0.0748, 0.0925, 0.0220, 0.0857, 0.0360, 0.0791, 0.2541, 0.1570,\n",
      "         0.1678, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0318, 0.0765, 0.0949, 0.0228, 0.0859, 0.0360, 0.0787, 0.2485, 0.1564,\n",
      "         0.1685, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0326, 0.0780, 0.0970, 0.0235, 0.0861, 0.0361, 0.0783, 0.2434, 0.1559,\n",
      "         0.1691, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 1.77, Train Loss: 0.00, Val Loss: 5.62, Train BLEU: 0.00, Val BLEU: 4.42, Minutes Elapsed: 163.72\n",
      "Sampling from val predictions...\n",
      "Source: 但是 我 那 受过 教育 的 母亲 成为 为了 一名 名教 教师 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: but my educated mother became a teacher . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> but i i , , the to of . <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0978, 0.8995, 0.0023, 0.0000, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0167, 0.9231, 0.0458, 0.0011, 0.0114, 0.0010, 0.0005, 0.0000, 0.0001,\n",
      "         0.0000, 0.0000, 0.0001, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0309, 0.5442, 0.3074, 0.0246, 0.0541, 0.0145, 0.0126, 0.0020, 0.0024,\n",
      "         0.0009, 0.0009, 0.0016, 0.0040, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0235, 0.3420, 0.2585, 0.0522, 0.1621, 0.0343, 0.0741, 0.0091, 0.0169,\n",
      "         0.0033, 0.0039, 0.0084, 0.0116, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0089, 0.0505, 0.0301, 0.0269, 0.2809, 0.0630, 0.4155, 0.0344, 0.0492,\n",
      "         0.0083, 0.0079, 0.0139, 0.0105, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0066, 0.0483, 0.0165, 0.0057, 0.0942, 0.0295, 0.3743, 0.0734, 0.2022,\n",
      "         0.0365, 0.0315, 0.0497, 0.0316, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0056, 0.0373, 0.0107, 0.0026, 0.0277, 0.0148, 0.1664, 0.0709, 0.4079,\n",
      "         0.0778, 0.0661, 0.0806, 0.0316, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0037, 0.0274, 0.0110, 0.0034, 0.0191, 0.0115, 0.0689, 0.0398, 0.4143,\n",
      "         0.1259, 0.1178, 0.1238, 0.0333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0049, 0.0242, 0.0092, 0.0049, 0.0341, 0.0146, 0.0980, 0.0399, 0.4614,\n",
      "         0.1111, 0.0828, 0.0987, 0.0163, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0085, 0.0549, 0.0328, 0.0083, 0.0279, 0.0257, 0.0521, 0.0415, 0.3361,\n",
      "         0.1248, 0.1220, 0.1301, 0.0353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0039, 0.0254, 0.0174, 0.0036, 0.0108, 0.0106, 0.0200, 0.0232, 0.2402,\n",
      "         0.1121, 0.2052, 0.2654, 0.0620, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0045, 0.0189, 0.0127, 0.0027, 0.0094, 0.0104, 0.0145, 0.0228, 0.1593,\n",
      "         0.0773, 0.1877, 0.3541, 0.1257, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0222, 0.1084, 0.0567, 0.0072, 0.0279, 0.0425, 0.0439, 0.0584, 0.2140,\n",
      "         0.0527, 0.0846, 0.1717, 0.1099, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0303, 0.1643, 0.0812, 0.0104, 0.0418, 0.0546, 0.0570, 0.0568, 0.1880,\n",
      "         0.0431, 0.0623, 0.1279, 0.0824, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0317, 0.1797, 0.0868, 0.0128, 0.0502, 0.0560, 0.0646, 0.0545, 0.1749,\n",
      "         0.0416, 0.0563, 0.1141, 0.0766, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0336, 0.1884, 0.0897, 0.0148, 0.0569, 0.0574, 0.0713, 0.0534, 0.1646,\n",
      "         0.0402, 0.0519, 0.1038, 0.0741, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0351, 0.1929, 0.0918, 0.0165, 0.0619, 0.0584, 0.0762, 0.0528, 0.1568,\n",
      "         0.0391, 0.0490, 0.0969, 0.0727, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0359, 0.1941, 0.0931, 0.0177, 0.0655, 0.0590, 0.0797, 0.0525, 0.1519,\n",
      "         0.0385, 0.0473, 0.0928, 0.0720, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0363, 0.1939, 0.0940, 0.0186, 0.0680, 0.0594, 0.0822, 0.0524, 0.1489,\n",
      "         0.0382, 0.0463, 0.0903, 0.0716, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1.82, Train Loss: 0.00, Val Loss: 5.46, Train BLEU: 0.00, Val BLEU: 4.12, Minutes Elapsed: 168.83\n",
      "Sampling from val predictions...\n",
      "Source: 这个 个人 还 得 去 <UNK> 条约 和 接见 <UNK> <UNK> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: this guy has to go and sign treaties and meet foreign <UNK> . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> and &apos;s of they to to the and the <EOS> . <EOS> <EOS> <EOS> <EOS> . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9836, 0.0163, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1393, 0.8301, 0.0274, 0.0018, 0.0007, 0.0001, 0.0003, 0.0001, 0.0000,\n",
      "         0.0000, 0.0001, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0822, 0.7056, 0.1707, 0.0226, 0.0100, 0.0010, 0.0028, 0.0007, 0.0007,\n",
      "         0.0005, 0.0009, 0.0022, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0437, 0.4317, 0.2522, 0.0633, 0.1050, 0.0118, 0.0441, 0.0070, 0.0090,\n",
      "         0.0049, 0.0095, 0.0178, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0301, 0.1802, 0.2591, 0.1050, 0.2102, 0.0335, 0.1129, 0.0143, 0.0168,\n",
      "         0.0077, 0.0127, 0.0176, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0102, 0.0266, 0.0522, 0.0334, 0.2183, 0.0527, 0.4090, 0.0455, 0.0618,\n",
      "         0.0243, 0.0366, 0.0292, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0090, 0.0174, 0.0305, 0.0245, 0.1827, 0.0553, 0.4831, 0.0487, 0.0686,\n",
      "         0.0249, 0.0344, 0.0208, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0088, 0.0088, 0.0144, 0.0113, 0.0888, 0.0491, 0.6208, 0.0526, 0.0851,\n",
      "         0.0191, 0.0249, 0.0162, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0050, 0.0043, 0.0101, 0.0069, 0.0528, 0.0391, 0.5208, 0.1114, 0.1698,\n",
      "         0.0333, 0.0342, 0.0124, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0213, 0.0101, 0.0147, 0.0070, 0.0310, 0.0254, 0.4766, 0.0764, 0.2089,\n",
      "         0.0459, 0.0561, 0.0265, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0717, 0.0336, 0.0386, 0.0146, 0.0390, 0.0233, 0.3297, 0.0718, 0.2051,\n",
      "         0.0549, 0.0728, 0.0450, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0188, 0.0129, 0.0208, 0.0142, 0.0392, 0.0266, 0.2352, 0.0761, 0.1911,\n",
      "         0.1221, 0.1777, 0.0653, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0199, 0.0136, 0.0170, 0.0137, 0.0400, 0.0300, 0.2366, 0.0717, 0.2057,\n",
      "         0.1146, 0.1686, 0.0687, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0581, 0.0330, 0.0379, 0.0234, 0.0573, 0.0279, 0.1839, 0.0690, 0.1574,\n",
      "         0.0922, 0.1491, 0.1109, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1636, 0.0959, 0.0811, 0.0370, 0.0601, 0.0228, 0.1469, 0.0551, 0.1097,\n",
      "         0.0515, 0.0813, 0.0949, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0434, 0.0338, 0.0621, 0.0379, 0.0795, 0.0320, 0.1285, 0.0588, 0.1175,\n",
      "         0.0887, 0.1619, 0.1558, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0294, 0.0224, 0.0500, 0.0347, 0.0617, 0.0255, 0.1124, 0.0558, 0.1139,\n",
      "         0.1000, 0.1883, 0.2057, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1891, 0.0807, 0.0929, 0.0385, 0.0614, 0.0171, 0.0907, 0.0515, 0.0900,\n",
      "         0.0460, 0.0916, 0.1504, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2241, 0.1104, 0.0933, 0.0392, 0.0603, 0.0148, 0.1007, 0.0485, 0.0811,\n",
      "         0.0374, 0.0750, 0.1150, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 1.88, Train Loss: 0.00, Val Loss: 5.49, Train BLEU: 0.00, Val BLEU: 3.85, Minutes Elapsed: 173.95\n",
      "Sampling from val predictions...\n",
      "Source: 在 死 之前 我 想 在 上百 上百万 百万 的 观众 面前 唱歌 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: &quot; before i die , i want to sing for millions . &quot; <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> and i , i to to i to to the the . . <EOS> . . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0552, 0.8321, 0.0472, 0.0648, 0.0004, 0.0000, 0.0000, 0.0000, 0.0001,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0176, 0.8825, 0.0337, 0.0519, 0.0104, 0.0004, 0.0010, 0.0003, 0.0014,\n",
      "         0.0001, 0.0002, 0.0001, 0.0001, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0105, 0.4069, 0.0916, 0.2738, 0.1820, 0.0073, 0.0096, 0.0028, 0.0076,\n",
      "         0.0010, 0.0018, 0.0009, 0.0012, 0.0030, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0046, 0.1371, 0.0709, 0.3881, 0.3493, 0.0141, 0.0146, 0.0033, 0.0086,\n",
      "         0.0010, 0.0024, 0.0013, 0.0015, 0.0030, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0026, 0.0598, 0.0638, 0.4517, 0.3680, 0.0118, 0.0160, 0.0032, 0.0136,\n",
      "         0.0009, 0.0028, 0.0014, 0.0016, 0.0030, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0012, 0.0075, 0.0103, 0.0685, 0.5189, 0.0823, 0.1428, 0.0363, 0.0735,\n",
      "         0.0087, 0.0226, 0.0088, 0.0109, 0.0075, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0009, 0.0023, 0.0031, 0.0363, 0.3119, 0.1104, 0.2294, 0.0599, 0.1529,\n",
      "         0.0156, 0.0384, 0.0153, 0.0149, 0.0086, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0005, 0.0019, 0.0031, 0.0422, 0.4225, 0.1067, 0.1756, 0.0409, 0.1416,\n",
      "         0.0097, 0.0311, 0.0120, 0.0095, 0.0026, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0003, 0.0004, 0.0006, 0.0040, 0.0760, 0.0710, 0.2649, 0.0842, 0.3085,\n",
      "         0.0276, 0.0930, 0.0291, 0.0339, 0.0065, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0003, 0.0003, 0.0006, 0.0030, 0.0400, 0.0609, 0.2630, 0.0828, 0.3464,\n",
      "         0.0301, 0.0927, 0.0319, 0.0427, 0.0053, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0002, 0.0003, 0.0004, 0.0013, 0.0172, 0.0332, 0.2063, 0.0900, 0.4038,\n",
      "         0.0281, 0.1383, 0.0343, 0.0414, 0.0053, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0002, 0.0003, 0.0003, 0.0012, 0.0142, 0.0220, 0.1437, 0.0831, 0.4103,\n",
      "         0.0377, 0.1638, 0.0570, 0.0579, 0.0083, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0006, 0.0010, 0.0008, 0.0027, 0.0088, 0.0088, 0.0686, 0.0548, 0.3771,\n",
      "         0.0356, 0.2139, 0.1210, 0.0938, 0.0123, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0010, 0.0016, 0.0013, 0.0035, 0.0082, 0.0086, 0.0534, 0.0403, 0.2940,\n",
      "         0.0254, 0.2134, 0.1316, 0.1799, 0.0378, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0007, 0.0011, 0.0016, 0.0070, 0.0175, 0.0095, 0.0256, 0.0160, 0.1284,\n",
      "         0.0200, 0.2003, 0.2498, 0.2836, 0.0389, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0002, 0.0003, 0.0009, 0.0046, 0.0120, 0.0052, 0.0143, 0.0099, 0.0820,\n",
      "         0.0136, 0.2353, 0.2783, 0.3197, 0.0236, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0007, 0.0011, 0.0031, 0.0125, 0.0239, 0.0086, 0.0166, 0.0108, 0.0509,\n",
      "         0.0126, 0.1569, 0.2255, 0.3611, 0.1157, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0042, 0.0053, 0.0084, 0.0415, 0.0329, 0.0150, 0.0311, 0.0185, 0.0890,\n",
      "         0.0228, 0.1280, 0.1566, 0.2508, 0.1958, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0068, 0.0097, 0.0116, 0.0523, 0.0425, 0.0168, 0.0399, 0.0220, 0.1240,\n",
      "         0.0236, 0.1220, 0.1312, 0.2123, 0.1853, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 1.93, Train Loss: 0.00, Val Loss: 5.54, Train BLEU: 0.00, Val BLEU: 4.34, Minutes Elapsed: 179.07\n",
      "Sampling from val predictions...\n",
      "Source: 他 骄傲 的 不仅 不仅仅 仅仅 是因为 因为 我 的 大学 学学 学历 也 是因为 因为 在 女性 中 我\n",
      "Reference: he not only <UNK> about my college degree , but also that i was the first woman , and\n",
      "Model: <SOS> she was &apos;t , , , , , i i i am me me . . . . <EOS>\n",
      "Attention Weights: tensor([[4.4092e-01, 3.3057e-01, 1.2956e-03, 1.4854e-01, 3.0369e-02, 2.2308e-02,\n",
      "         4.8946e-03, 1.6291e-02, 3.5044e-03, 2.2505e-05, 1.2990e-04, 9.4966e-05,\n",
      "         5.8884e-04, 1.7952e-04, 3.4193e-05, 2.4355e-04, 2.5016e-06, 8.5697e-06,\n",
      "         1.5277e-06, 2.5026e-06],\n",
      "        [2.0498e-02, 2.2977e-01, 1.6729e-03, 2.8452e-01, 1.1745e-01, 7.8348e-02,\n",
      "         3.2648e-02, 1.0676e-01, 1.1070e-01, 1.7220e-03, 5.5562e-03, 1.9650e-03,\n",
      "         3.2880e-03, 1.1965e-03, 5.7333e-04, 2.8952e-03, 1.2581e-04, 2.1924e-04,\n",
      "         4.0421e-05, 4.8508e-05],\n",
      "        [1.8118e-03, 2.0739e-02, 9.0718e-04, 1.1686e-01, 1.2392e-01, 9.1411e-02,\n",
      "         4.5790e-02, 1.6258e-01, 3.4771e-01, 7.3565e-03, 1.7824e-02, 1.1450e-02,\n",
      "         9.8417e-03, 7.8419e-03, 4.4592e-03, 2.5439e-02, 1.5352e-03, 1.4133e-03,\n",
      "         3.4186e-04, 7.7522e-04],\n",
      "        [1.0383e-03, 9.9425e-03, 2.7151e-04, 2.2075e-02, 3.1924e-02, 2.3936e-02,\n",
      "         4.9289e-02, 7.2288e-02, 4.5176e-01, 1.8982e-02, 1.4240e-01, 5.0148e-02,\n",
      "         4.5860e-02, 7.2643e-03, 1.0071e-02, 3.6601e-02, 7.6738e-03, 1.5573e-02,\n",
      "         1.2885e-03, 1.6137e-03],\n",
      "        [6.3110e-04, 3.6538e-03, 1.2973e-04, 5.6831e-03, 1.1228e-02, 8.8044e-03,\n",
      "         2.6647e-02, 2.8633e-02, 2.4719e-01, 1.5191e-02, 1.9022e-01, 1.0243e-01,\n",
      "         9.8668e-02, 1.8912e-02, 3.6760e-02, 8.8115e-02, 3.1194e-02, 7.3239e-02,\n",
      "         5.8318e-03, 6.8327e-03],\n",
      "        [1.9684e-03, 2.7239e-03, 8.3200e-05, 2.2819e-03, 3.7458e-03, 2.5496e-03,\n",
      "         9.7834e-03, 9.4187e-03, 8.6949e-02, 2.4997e-03, 8.3143e-02, 8.0455e-02,\n",
      "         1.0564e-01, 4.1199e-02, 9.5978e-02, 1.7896e-01, 5.3584e-02, 1.8759e-01,\n",
      "         1.6486e-02, 3.4963e-02],\n",
      "        [6.3323e-03, 3.9003e-03, 1.8825e-04, 2.1181e-03, 2.3574e-03, 2.1729e-03,\n",
      "         3.8296e-03, 4.5674e-03, 2.9638e-02, 7.4055e-04, 2.4835e-02, 2.9711e-02,\n",
      "         3.2028e-02, 2.6514e-02, 5.5290e-02, 2.1999e-01, 5.2769e-02, 2.0488e-01,\n",
      "         1.6236e-02, 2.8190e-01],\n",
      "        [3.1743e-03, 2.5115e-03, 1.6562e-04, 1.8325e-03, 2.0596e-03, 1.6340e-03,\n",
      "         2.9479e-03, 3.2530e-03, 1.7934e-02, 4.9509e-04, 2.0131e-02, 2.5914e-02,\n",
      "         3.2741e-02, 2.6555e-02, 5.2168e-02, 1.2389e-01, 4.9108e-02, 2.4508e-01,\n",
      "         3.6746e-02, 3.5166e-01],\n",
      "        [1.8843e-03, 1.8476e-03, 1.6506e-04, 1.4366e-03, 1.5005e-03, 1.3075e-03,\n",
      "         2.2896e-03, 2.3636e-03, 7.2705e-03, 5.4447e-04, 1.2556e-02, 1.4225e-02,\n",
      "         1.7593e-02, 1.2531e-02, 2.5921e-02, 6.3689e-02, 3.4772e-02, 1.6628e-01,\n",
      "         3.6294e-02, 5.9553e-01],\n",
      "        [3.3920e-03, 4.8710e-03, 3.2956e-04, 3.2204e-03, 3.0859e-03, 3.1052e-03,\n",
      "         4.9222e-03, 4.9821e-03, 1.1624e-02, 1.3169e-03, 8.7679e-03, 1.0508e-02,\n",
      "         1.0675e-02, 1.0371e-02, 1.9730e-02, 6.1268e-02, 2.1641e-02, 7.7388e-02,\n",
      "         1.4740e-02, 7.2406e-01],\n",
      "        [6.6492e-03, 7.7989e-03, 7.9552e-04, 6.6745e-03, 6.4329e-03, 6.1173e-03,\n",
      "         7.6544e-03, 8.4214e-03, 2.0453e-02, 1.8164e-03, 1.1013e-02, 1.4739e-02,\n",
      "         1.5204e-02, 1.8570e-02, 2.7778e-02, 6.7644e-02, 2.5256e-02, 9.5071e-02,\n",
      "         2.0824e-02, 6.3109e-01],\n",
      "        [1.3664e-03, 3.1829e-03, 8.7055e-04, 5.6846e-03, 7.0220e-03, 5.5311e-03,\n",
      "         7.2846e-03, 8.3247e-03, 2.7324e-02, 3.2717e-03, 8.0830e-03, 1.4660e-02,\n",
      "         1.0469e-02, 1.6191e-02, 3.2734e-02, 8.8840e-02, 4.8042e-02, 9.1931e-02,\n",
      "         2.7276e-02, 5.9191e-01],\n",
      "        [1.2600e-03, 2.9261e-03, 6.7323e-04, 5.2782e-03, 6.7830e-03, 5.6494e-03,\n",
      "         1.0532e-02, 1.0605e-02, 3.8907e-02, 5.9549e-03, 1.3129e-02, 1.8293e-02,\n",
      "         1.2243e-02, 1.1005e-02, 2.8277e-02, 6.1854e-02, 4.8025e-02, 8.5552e-02,\n",
      "         2.6158e-02, 6.0690e-01],\n",
      "        [1.7801e-03, 4.8717e-03, 4.4176e-04, 4.7521e-03, 5.5640e-03, 4.9541e-03,\n",
      "         1.2409e-02, 1.2729e-02, 5.3030e-02, 6.2594e-03, 2.3289e-02, 2.5382e-02,\n",
      "         1.8353e-02, 8.5374e-03, 2.7235e-02, 5.2599e-02, 4.6591e-02, 1.0827e-01,\n",
      "         3.0216e-02, 5.5274e-01],\n",
      "        [3.3117e-03, 8.7289e-03, 1.0901e-03, 9.7324e-03, 1.1982e-02, 1.0539e-02,\n",
      "         2.1869e-02, 2.3311e-02, 7.5601e-02, 1.2383e-02, 3.1521e-02, 3.4575e-02,\n",
      "         2.4854e-02, 1.2899e-02, 3.5981e-02, 6.6307e-02, 5.5492e-02, 1.0058e-01,\n",
      "         3.1378e-02, 4.2786e-01],\n",
      "        [5.3509e-03, 8.7125e-03, 2.7263e-03, 7.7189e-03, 8.6440e-03, 9.7406e-03,\n",
      "         1.8031e-02, 2.3003e-02, 1.3122e-01, 3.6097e-02, 8.2218e-02, 3.9383e-02,\n",
      "         2.2725e-02, 1.1922e-02, 2.6428e-02, 7.0418e-02, 1.3914e-01, 1.7320e-01,\n",
      "         3.1605e-02, 1.5171e-01],\n",
      "        [7.2484e-03, 1.5015e-02, 2.0647e-03, 6.8694e-03, 6.6390e-03, 7.4364e-03,\n",
      "         2.0349e-02, 2.1072e-02, 1.0170e-01, 3.7155e-02, 1.0688e-01, 5.3921e-02,\n",
      "         3.2263e-02, 8.8001e-03, 2.6242e-02, 6.1353e-02, 1.3220e-01, 1.8208e-01,\n",
      "         4.0533e-02, 1.3017e-01],\n",
      "        [4.0303e-02, 3.8572e-02, 3.9385e-03, 1.9845e-02, 1.7001e-02, 1.5784e-02,\n",
      "         2.9441e-02, 2.6380e-02, 5.5458e-02, 1.4776e-02, 7.4499e-02, 5.5650e-02,\n",
      "         6.8165e-02, 3.5469e-02, 5.2870e-02, 5.5346e-02, 6.5556e-02, 1.4040e-01,\n",
      "         4.9799e-02, 1.4074e-01],\n",
      "        [4.3493e-02, 4.7933e-02, 4.3727e-03, 2.7825e-02, 2.3468e-02, 2.3718e-02,\n",
      "         3.7125e-02, 3.5602e-02, 5.8816e-02, 1.4738e-02, 5.9601e-02, 5.2208e-02,\n",
      "         5.7826e-02, 4.1589e-02, 5.7063e-02, 6.8585e-02, 6.0420e-02, 1.0468e-01,\n",
      "         4.1351e-02, 1.3959e-01]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1.99, Train Loss: 0.00, Val Loss: 5.47, Train BLEU: 0.00, Val BLEU: 4.15, Minutes Elapsed: 184.20\n",
      "Sampling from val predictions...\n",
      "Source: 我 不能 披露 太多 我 离开 朝鲜 时 的 细节 但是 我 只能 说 那 是 在 饥荒 中 最\n",
      "Reference: i can &apos;t reveal many details &#91; about &#93; how i left north korea , but i only can\n",
      "Model: <SOS> i i &apos;t my my i , i i , i i a the the . . . .\n",
      "Attention Weights: tensor([[6.3450e-01, 2.3022e-01, 2.1254e-02, 1.0652e-01, 3.0188e-03, 1.7539e-04,\n",
      "         1.1694e-03, 4.8315e-04, 2.0362e-04, 6.2013e-04, 1.4570e-03, 3.3760e-04,\n",
      "         2.7218e-05, 6.4545e-06, 7.3466e-07, 1.7616e-07, 2.2553e-08, 1.3311e-07,\n",
      "         1.4360e-07, 1.1162e-07],\n",
      "        [4.7713e-02, 7.6442e-01, 1.1394e-01, 6.0669e-02, 7.4317e-03, 2.1035e-03,\n",
      "         1.6637e-03, 4.7165e-04, 2.0173e-04, 3.1039e-04, 5.4506e-04, 3.1343e-04,\n",
      "         1.3900e-04, 3.4434e-05, 1.4322e-05, 7.0077e-06, 2.3254e-06, 8.8150e-06,\n",
      "         5.0153e-06, 2.9720e-06],\n",
      "        [2.9640e-02, 5.5310e-01, 1.0471e-01, 1.7024e-01, 8.1801e-02, 3.0331e-02,\n",
      "         1.2246e-02, 3.7644e-03, 1.6327e-03, 2.4317e-03, 4.0831e-03, 3.3646e-03,\n",
      "         1.4021e-03, 3.6680e-04, 2.4407e-04, 1.7594e-04, 9.9148e-05, 1.7381e-04,\n",
      "         9.9988e-05, 8.9454e-05],\n",
      "        [1.5629e-03, 1.6090e-02, 6.1806e-02, 1.4069e-01, 3.2955e-01, 1.7534e-01,\n",
      "         1.6723e-01, 2.2236e-02, 1.3973e-02, 3.3355e-02, 1.6121e-02, 1.2055e-02,\n",
      "         4.0672e-03, 2.2011e-03, 1.1715e-03, 6.5596e-04, 4.5623e-04, 8.4322e-04,\n",
      "         3.4223e-04, 2.4967e-04],\n",
      "        [4.0136e-04, 1.7116e-03, 1.3940e-02, 3.7120e-02, 2.9064e-01, 1.7152e-01,\n",
      "         2.7605e-01, 2.8956e-02, 2.6371e-02, 7.1008e-02, 3.2532e-02, 2.8814e-02,\n",
      "         7.8653e-03, 5.1909e-03, 2.8577e-03, 1.2694e-03, 9.0540e-04, 2.0052e-03,\n",
      "         5.2065e-04, 3.1392e-04],\n",
      "        [3.7601e-04, 9.0216e-04, 7.8855e-03, 1.5604e-02, 1.9064e-01, 1.4689e-01,\n",
      "         3.3998e-01, 2.9049e-02, 2.9377e-02, 9.4489e-02, 5.5945e-02, 5.6367e-02,\n",
      "         1.3746e-02, 7.7935e-03, 4.3905e-03, 1.6595e-03, 1.0407e-03, 2.8594e-03,\n",
      "         6.7054e-04, 3.3593e-04],\n",
      "        [6.7924e-04, 8.6684e-04, 1.7190e-03, 5.2554e-03, 5.1065e-02, 4.1074e-02,\n",
      "         1.0718e-01, 2.6906e-02, 2.0225e-02, 6.7999e-02, 2.3204e-01, 2.9963e-01,\n",
      "         8.6500e-02, 3.1557e-02, 1.3225e-02, 4.5367e-03, 1.6576e-03, 5.8325e-03,\n",
      "         1.3372e-03, 7.1200e-04],\n",
      "        [2.7255e-03, 1.2159e-03, 9.5137e-04, 3.0448e-03, 2.7670e-02, 2.0113e-02,\n",
      "         4.4296e-02, 1.3593e-02, 4.6821e-03, 2.6802e-02, 2.8544e-01, 3.5320e-01,\n",
      "         1.4905e-01, 3.2220e-02, 1.3045e-02, 4.0043e-03, 2.2522e-03, 1.3663e-02,\n",
      "         1.3477e-03, 6.8168e-04],\n",
      "        [5.9533e-03, 1.0913e-03, 7.9315e-04, 1.4076e-03, 2.3255e-02, 1.5404e-02,\n",
      "         2.7972e-02, 6.0935e-03, 2.0800e-03, 9.0650e-03, 1.4370e-01, 4.6716e-01,\n",
      "         1.5480e-01, 4.6497e-02, 3.0215e-02, 1.0023e-02, 6.0807e-03, 4.3743e-02,\n",
      "         2.9367e-03, 1.7280e-03],\n",
      "        [9.4373e-03, 1.2338e-03, 7.4883e-04, 1.6294e-03, 2.3542e-02, 1.2155e-02,\n",
      "         2.3412e-02, 5.8774e-03, 2.2335e-03, 8.7326e-03, 1.2575e-01, 5.0513e-01,\n",
      "         1.2772e-01, 4.8954e-02, 3.4013e-02, 9.9911e-03, 5.3039e-03, 4.8212e-02,\n",
      "         3.6245e-03, 2.3008e-03],\n",
      "        [4.1392e-03, 2.2048e-03, 1.1560e-03, 2.6815e-03, 1.5598e-02, 1.1218e-02,\n",
      "         1.8928e-02, 6.4038e-03, 2.7059e-03, 1.3816e-02, 1.2905e-01, 3.0072e-01,\n",
      "         1.6560e-01, 6.2972e-02, 5.4466e-02, 2.7837e-02, 2.2761e-02, 1.3310e-01,\n",
      "         1.4896e-02, 9.7425e-03],\n",
      "        [2.6806e-03, 2.3300e-03, 1.0013e-03, 1.9396e-03, 1.5740e-02, 8.7010e-03,\n",
      "         1.0162e-02, 3.9974e-03, 1.7940e-03, 6.0562e-03, 6.3874e-02, 2.2982e-01,\n",
      "         1.5680e-01, 7.6977e-02, 9.5123e-02, 5.6490e-02, 4.7628e-02, 1.8044e-01,\n",
      "         2.0814e-02, 1.7628e-02],\n",
      "        [4.0255e-04, 1.4454e-03, 9.8644e-04, 2.0325e-03, 1.1299e-02, 7.0165e-03,\n",
      "         7.3232e-03, 3.3696e-03, 2.5459e-03, 4.7925e-03, 2.6859e-02, 1.0290e-01,\n",
      "         7.2823e-02, 4.7542e-02, 8.0234e-02, 7.6329e-02, 9.6978e-02, 3.3544e-01,\n",
      "         5.6172e-02, 6.3511e-02],\n",
      "        [5.7648e-05, 6.7442e-05, 1.6112e-04, 2.5707e-04, 1.1727e-03, 1.6190e-03,\n",
      "         3.4797e-03, 8.1020e-04, 1.0331e-03, 1.5110e-03, 2.9830e-03, 7.4209e-03,\n",
      "         7.1839e-03, 1.7141e-02, 6.1709e-02, 5.5760e-02, 1.2390e-01, 5.9225e-01,\n",
      "         6.0689e-02, 6.0798e-02],\n",
      "        [4.7665e-05, 7.7088e-05, 1.6740e-04, 2.3775e-04, 1.7543e-03, 1.4825e-03,\n",
      "         3.3379e-03, 7.5243e-04, 9.1950e-04, 9.7749e-04, 2.4854e-03, 9.9649e-03,\n",
      "         4.5351e-03, 7.1065e-03, 4.0318e-02, 3.6368e-02, 9.7008e-02, 6.2804e-01,\n",
      "         6.5069e-02, 9.9357e-02],\n",
      "        [3.6136e-04, 3.7807e-04, 4.7015e-04, 9.3454e-04, 7.1355e-03, 3.5873e-03,\n",
      "         6.2663e-03, 2.3301e-03, 2.3193e-03, 2.4148e-03, 9.8760e-03, 6.3975e-02,\n",
      "         9.1162e-03, 9.2999e-03, 3.2810e-02, 2.3511e-02, 5.1255e-02, 6.2450e-01,\n",
      "         4.5035e-02, 1.0443e-01],\n",
      "        [2.8151e-03, 3.0425e-03, 2.5545e-03, 5.4811e-03, 2.7339e-02, 1.4852e-02,\n",
      "         1.9258e-02, 9.7124e-03, 7.8587e-03, 8.2502e-03, 3.2368e-02, 1.6000e-01,\n",
      "         2.4370e-02, 2.1942e-02, 4.1368e-02, 2.5926e-02, 4.2165e-02, 4.4097e-01,\n",
      "         4.1234e-02, 6.8492e-02],\n",
      "        [2.4294e-03, 6.1508e-03, 4.1065e-03, 1.0262e-02, 3.2836e-02, 2.0861e-02,\n",
      "         1.7791e-02, 1.3568e-02, 1.0488e-02, 1.0355e-02, 3.7851e-02, 1.3391e-01,\n",
      "         5.8271e-02, 3.1162e-02, 4.8360e-02, 4.6475e-02, 6.7266e-02, 2.9253e-01,\n",
      "         5.6935e-02, 9.8389e-02],\n",
      "        [1.5186e-03, 3.1525e-03, 5.3341e-03, 7.8966e-03, 3.4207e-02, 3.1002e-02,\n",
      "         3.1779e-02, 1.1794e-02, 1.1720e-02, 1.5323e-02, 2.6241e-02, 9.0666e-02,\n",
      "         3.8499e-02, 2.7537e-02, 5.3575e-02, 4.5467e-02, 7.4653e-02, 3.4927e-01,\n",
      "         5.7858e-02, 8.2503e-02]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 2.00, Train Loss: 0.00, Val Loss: 5.53, Train BLEU: 0.00, Val BLEU: 4.59, Minutes Elapsed: 185.34\n",
      "Sampling from val predictions...\n",
      "Source: 我们 鼓舞 各个 社区 进行 创业 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: we activate communities . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> we have a the . <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9903, 0.0060, 0.0033, 0.0000, 0.0000, 0.0000, 0.0004, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.3081, 0.3914, 0.2950, 0.0014, 0.0008, 0.0008, 0.0025, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0651, 0.1288, 0.7445, 0.0285, 0.0174, 0.0082, 0.0073, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0035, 0.0163, 0.7553, 0.1079, 0.0824, 0.0285, 0.0063, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0042, 0.0056, 0.2343, 0.0700, 0.5173, 0.1551, 0.0137, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0313, 0.0257, 0.2239, 0.0431, 0.3243, 0.2242, 0.1276, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0821, 0.0469, 0.2598, 0.0369, 0.2589, 0.1340, 0.1814, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0689, 0.0513, 0.2163, 0.0449, 0.2154, 0.1156, 0.2876, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1816, 0.0511, 0.2872, 0.0307, 0.1602, 0.0752, 0.2141, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2027, 0.0565, 0.2823, 0.0285, 0.1425, 0.0697, 0.2178, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2108, 0.0629, 0.2835, 0.0285, 0.1353, 0.0692, 0.2098, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2196, 0.0679, 0.2823, 0.0291, 0.1306, 0.0679, 0.2027, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2256, 0.0716, 0.2824, 0.0299, 0.1279, 0.0669, 0.1958, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2303, 0.0743, 0.2830, 0.0305, 0.1262, 0.0663, 0.1895, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2341, 0.0763, 0.2837, 0.0310, 0.1250, 0.0658, 0.1843, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2371, 0.0777, 0.2842, 0.0314, 0.1241, 0.0654, 0.1801, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2395, 0.0789, 0.2847, 0.0317, 0.1233, 0.0651, 0.1767, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2414, 0.0798, 0.2851, 0.0320, 0.1227, 0.0649, 0.1741, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2430, 0.0805, 0.2854, 0.0322, 0.1222, 0.0648, 0.1719, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2.05, Train Loss: 0.00, Val Loss: 5.41, Train BLEU: 0.00, Val BLEU: 3.64, Minutes Elapsed: 190.47\n",
      "Sampling from val predictions...\n",
      "Source: 你们 应该 看看 这些 垃圾 掌声 你们 应该 看看 我们 塞 了 多少 垃圾 给 这些 满怀 信任 的 非洲\n",
      "Reference: you should see the rubbish — -- you should see the rubbish that we have <UNK> on unsuspecting african\n",
      "Model: <SOS> you you , , , of we we &apos;re the the the of the in in . <EOS> .\n",
      "Attention Weights: tensor([[8.0456e-01, 1.8576e-01, 7.2864e-03, 6.8758e-04, 3.6355e-04, 9.9578e-05,\n",
      "         1.0277e-03, 1.7211e-04, 2.9879e-05, 4.2794e-06, 1.9653e-06, 1.1723e-06,\n",
      "         4.1025e-06, 2.5386e-07, 7.3778e-08, 6.2882e-08, 2.0923e-08, 1.4084e-08,\n",
      "         4.4098e-09, 2.5148e-08],\n",
      "        [2.1034e-01, 3.2271e-01, 1.8543e-01, 1.9679e-01, 4.5871e-02, 6.8194e-03,\n",
      "         1.8496e-02, 6.6353e-03, 2.0660e-03, 2.1093e-03, 8.0778e-04, 4.8336e-04,\n",
      "         1.2062e-03, 1.1971e-04, 2.9935e-05, 4.4424e-05, 1.7393e-05, 1.1751e-05,\n",
      "         5.6496e-06, 1.5567e-05],\n",
      "        [8.6693e-02, 1.4276e-01, 1.8763e-01, 3.6204e-01, 9.5434e-02, 2.1573e-02,\n",
      "         4.4694e-02, 2.2237e-02, 9.4912e-03, 1.6267e-02, 3.0194e-03, 1.5319e-03,\n",
      "         4.5999e-03, 6.7995e-04, 2.4246e-04, 4.5813e-04, 1.9363e-04, 1.3892e-04,\n",
      "         1.2362e-04, 1.9104e-04],\n",
      "        [4.6383e-04, 7.2433e-04, 1.0659e-02, 3.3458e-01, 1.9353e-01, 7.9231e-02,\n",
      "         3.0207e-02, 3.0296e-02, 7.0844e-02, 1.2864e-01, 4.4502e-02, 6.6558e-03,\n",
      "         4.4893e-02, 1.0395e-02, 8.9748e-04, 8.3996e-03, 2.2487e-03, 8.7905e-04,\n",
      "         5.3174e-04, 1.4192e-03],\n",
      "        [6.1078e-05, 9.5368e-05, 1.2271e-03, 4.2237e-02, 3.0087e-02, 2.2432e-02,\n",
      "         4.2690e-02, 3.3300e-02, 7.9370e-02, 3.0203e-01, 1.5342e-01, 3.3454e-02,\n",
      "         1.6632e-01, 5.0454e-02, 4.3301e-03, 2.6958e-02, 5.8941e-03, 1.9338e-03,\n",
      "         9.2687e-04, 2.7761e-03],\n",
      "        [2.6623e-04, 2.8907e-04, 7.3535e-04, 1.2341e-02, 8.0403e-03, 9.1621e-03,\n",
      "         1.4448e-01, 5.5378e-02, 4.8544e-02, 2.4915e-01, 1.0765e-01, 5.7859e-02,\n",
      "         2.0389e-01, 5.2099e-02, 9.1826e-03, 2.9005e-02, 6.8270e-03, 2.0927e-03,\n",
      "         6.1248e-04, 2.3976e-03],\n",
      "        [1.5070e-03, 3.3006e-04, 3.5368e-04, 4.1708e-03, 3.7688e-03, 7.1770e-03,\n",
      "         1.7581e-01, 5.6347e-02, 2.8346e-02, 2.6727e-01, 8.3393e-02, 3.9911e-02,\n",
      "         1.9680e-01, 5.0308e-02, 2.1319e-02, 4.3542e-02, 1.1410e-02, 3.6230e-03,\n",
      "         6.1671e-04, 3.9871e-03],\n",
      "        [7.9276e-04, 5.4915e-04, 5.3873e-04, 3.4850e-03, 1.5727e-03, 1.9400e-03,\n",
      "         7.5834e-02, 2.4073e-02, 1.5784e-02, 3.9554e-01, 5.2693e-02, 2.8186e-02,\n",
      "         2.0520e-01, 4.5160e-02, 1.9735e-02, 9.1271e-02, 2.1136e-02, 5.5377e-03,\n",
      "         1.4925e-03, 9.4850e-03],\n",
      "        [5.2269e-04, 3.8291e-04, 3.8755e-04, 1.4095e-03, 6.0417e-04, 7.0716e-04,\n",
      "         2.9869e-02, 1.1236e-02, 6.5723e-03, 2.6908e-01, 2.8525e-02, 1.7529e-02,\n",
      "         1.7239e-01, 4.8472e-02, 3.8033e-02, 2.0249e-01, 9.1460e-02, 3.1010e-02,\n",
      "         7.6545e-03, 4.1673e-02],\n",
      "        [8.4442e-05, 1.9686e-04, 5.2617e-04, 1.5925e-03, 6.8721e-04, 8.2835e-04,\n",
      "         1.2683e-02, 7.5108e-03, 7.4616e-03, 2.5789e-01, 3.0551e-02, 1.7589e-02,\n",
      "         1.7393e-01, 5.3456e-02, 3.4061e-02, 1.9878e-01, 8.5554e-02, 4.5060e-02,\n",
      "         1.4179e-02, 5.7377e-02],\n",
      "        [1.7099e-05, 1.7076e-05, 5.6744e-05, 4.7540e-04, 2.4673e-04, 1.3520e-04,\n",
      "         4.4783e-04, 3.3375e-04, 8.1803e-04, 3.2202e-02, 8.8780e-03, 2.7778e-03,\n",
      "         3.5194e-02, 2.9418e-02, 1.0518e-02, 3.4422e-01, 2.0653e-01, 8.9714e-02,\n",
      "         4.6980e-02, 1.9102e-01],\n",
      "        [1.2806e-05, 1.2188e-05, 4.1840e-05, 3.5840e-04, 1.8061e-04, 8.1563e-05,\n",
      "         1.9916e-04, 1.6330e-04, 4.0035e-04, 2.1287e-02, 3.8407e-03, 1.2905e-03,\n",
      "         1.8117e-02, 1.4497e-02, 7.1733e-03, 2.8346e-01, 2.0325e-01, 9.3479e-02,\n",
      "         7.1623e-02, 2.8054e-01],\n",
      "        [6.4214e-06, 7.5059e-06, 4.5243e-05, 2.7838e-04, 1.4898e-04, 7.3802e-05,\n",
      "         2.4648e-04, 1.8619e-04, 4.2877e-04, 1.9325e-02, 2.9616e-03, 1.0506e-03,\n",
      "         1.5980e-02, 8.6980e-03, 6.3843e-03, 2.1961e-01, 1.7586e-01, 1.0311e-01,\n",
      "         8.9274e-02, 3.5633e-01],\n",
      "        [7.0304e-05, 4.2171e-05, 7.8652e-05, 3.4606e-04, 3.1633e-04, 2.8792e-04,\n",
      "         1.9326e-03, 7.3180e-04, 7.4021e-04, 2.4897e-02, 3.4960e-03, 1.2444e-03,\n",
      "         1.4443e-02, 8.3711e-03, 8.0044e-03, 1.7994e-01, 1.8531e-01, 1.0481e-01,\n",
      "         4.6519e-02, 4.1843e-01],\n",
      "        [5.6410e-05, 7.4655e-05, 2.2674e-04, 9.5064e-04, 4.0289e-04, 2.4016e-04,\n",
      "         1.9567e-03, 1.3258e-03, 1.5065e-03, 2.0141e-02, 2.2156e-03, 1.5806e-03,\n",
      "         1.0080e-02, 4.4235e-03, 3.8273e-03, 1.2362e-01, 1.3763e-01, 5.0880e-02,\n",
      "         3.2502e-02, 6.0636e-01],\n",
      "        [7.8276e-05, 7.9326e-05, 3.9822e-04, 1.9149e-03, 7.3787e-04, 2.8766e-04,\n",
      "         1.2097e-03, 1.0185e-03, 1.9800e-03, 1.7493e-02, 3.0683e-03, 2.2773e-03,\n",
      "         1.3632e-02, 5.7597e-03, 3.9196e-03, 9.5359e-02, 1.2657e-01, 6.3157e-02,\n",
      "         5.1029e-02, 6.1003e-01],\n",
      "        [3.0687e-04, 2.3024e-04, 5.9469e-04, 2.9180e-03, 1.2099e-03, 5.1102e-04,\n",
      "         1.4150e-03, 1.0976e-03, 1.9518e-03, 1.1483e-02, 3.3458e-03, 2.8219e-03,\n",
      "         9.1449e-03, 6.8955e-03, 3.8969e-03, 1.2793e-01, 1.5925e-01, 6.0821e-02,\n",
      "         5.4500e-02, 5.4967e-01],\n",
      "        [2.8346e-04, 1.9453e-04, 6.3134e-04, 4.3859e-03, 1.6992e-03, 6.2565e-04,\n",
      "         1.3953e-03, 1.0112e-03, 2.2712e-03, 1.5870e-02, 5.5151e-03, 3.3642e-03,\n",
      "         1.3255e-02, 1.0120e-02, 5.0735e-03, 1.2184e-01, 1.4814e-01, 6.7298e-02,\n",
      "         6.6797e-02, 5.3023e-01],\n",
      "        [1.4958e-03, 1.8423e-03, 5.1756e-03, 2.1002e-02, 1.0556e-02, 5.6510e-03,\n",
      "         1.3689e-02, 1.4499e-02, 1.8016e-02, 8.1770e-02, 2.6737e-02, 1.6961e-02,\n",
      "         4.1356e-02, 2.7916e-02, 2.0932e-02, 1.1015e-01, 1.1138e-01, 5.9083e-02,\n",
      "         4.2813e-02, 3.6897e-01]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 2.11, Train Loss: 0.00, Val Loss: 5.40, Train BLEU: 0.00, Val BLEU: 3.81, Minutes Elapsed: 195.62\n",
      "Sampling from val predictions...\n",
      "Source: 所以 这样 我们 不仅 知道 相机 到 门 的 距离 同时 知道 到 隐藏 物品 的 距离 但 我们 不知\n",
      "Reference: and this way , we know the distances , of course to the door , but also to the\n",
      "Model: <SOS> so , , , we we to the of , , , we , , we we don we\n",
      "Attention Weights: tensor([[3.0956e-03, 9.5796e-01, 3.7842e-02, 5.3400e-04, 4.5485e-04, 1.9493e-05,\n",
      "         2.5438e-05, 1.6197e-05, 5.2039e-06, 6.8585e-06, 1.1884e-05, 2.0995e-05,\n",
      "         8.2662e-07, 4.9777e-07, 6.1785e-07, 1.7977e-07, 3.3411e-07, 1.1873e-06,\n",
      "         2.4464e-06, 3.1222e-07],\n",
      "        [2.5985e-03, 7.5374e-01, 2.2134e-01, 1.5091e-02, 4.6307e-03, 9.2629e-04,\n",
      "         6.1714e-04, 4.6697e-04, 1.1313e-04, 1.2654e-04, 7.8900e-05, 8.2454e-05,\n",
      "         3.7284e-05, 2.7807e-05, 3.5921e-05, 1.1627e-05, 1.8719e-05, 2.4224e-05,\n",
      "         3.1022e-05, 7.8518e-06],\n",
      "        [2.8681e-03, 1.0049e-01, 5.9291e-01, 1.6815e-01, 6.8380e-02, 3.1459e-02,\n",
      "         1.5654e-02, 8.8530e-03, 2.1146e-03, 3.1329e-03, 1.2974e-03, 1.3615e-03,\n",
      "         7.3562e-04, 6.4299e-04, 7.4785e-04, 2.2592e-04, 3.5284e-04, 3.0854e-04,\n",
      "         2.3357e-04, 8.4420e-05],\n",
      "        [3.1821e-03, 7.9223e-02, 3.8023e-01, 2.8620e-01, 1.4109e-01, 4.9315e-02,\n",
      "         2.7681e-02, 1.3544e-02, 4.1750e-03, 6.1829e-03, 2.4291e-03, 2.0708e-03,\n",
      "         1.1509e-03, 8.9161e-04, 9.1547e-04, 3.6187e-04, 5.0056e-04, 4.4366e-04,\n",
      "         2.9320e-04, 1.2535e-04],\n",
      "        [9.6972e-04, 1.3079e-02, 2.7529e-01, 1.0347e-01, 1.7254e-01, 1.7116e-01,\n",
      "         1.2050e-01, 4.0847e-02, 8.5934e-03, 2.8562e-02, 1.5025e-02, 1.3667e-02,\n",
      "         9.3035e-03, 9.5091e-03, 7.7346e-03, 1.3227e-03, 3.3243e-03, 2.5663e-03,\n",
      "         1.8459e-03, 6.8933e-04],\n",
      "        [4.7281e-04, 4.5262e-03, 8.6777e-02, 4.4425e-02, 9.7463e-02, 2.1096e-01,\n",
      "         2.0121e-01, 1.0266e-01, 2.8594e-02, 7.9027e-02, 3.9154e-02, 2.8631e-02,\n",
      "         2.0542e-02, 2.3893e-02, 1.6741e-02, 2.6041e-03, 5.5824e-03, 3.7439e-03,\n",
      "         2.2284e-03, 7.5987e-04],\n",
      "        [1.0181e-03, 5.2895e-03, 1.0185e-01, 5.5935e-02, 1.3156e-01, 1.3795e-01,\n",
      "         1.3928e-01, 5.9517e-02, 3.0505e-02, 7.5218e-02, 6.2218e-02, 4.9167e-02,\n",
      "         4.9801e-02, 4.0811e-02, 2.8646e-02, 5.5242e-03, 1.2267e-02, 7.5991e-03,\n",
      "         4.1231e-03, 1.7280e-03],\n",
      "        [2.2463e-04, 8.1077e-04, 4.8283e-03, 1.1250e-02, 3.7078e-02, 2.1461e-01,\n",
      "         1.7348e-01, 1.4090e-01, 6.2521e-02, 6.8145e-02, 2.8137e-02, 1.9455e-02,\n",
      "         4.8305e-02, 9.9670e-02, 6.0411e-02, 1.2445e-02, 1.1634e-02, 3.5661e-03,\n",
      "         1.5725e-03, 9.5926e-04],\n",
      "        [7.0124e-05, 3.2039e-04, 1.6198e-03, 4.0974e-03, 1.4278e-02, 7.7569e-02,\n",
      "         8.4327e-02, 5.6615e-02, 3.5498e-02, 4.4963e-02, 4.7878e-02, 3.4130e-02,\n",
      "         9.4444e-02, 2.0455e-01, 1.7476e-01, 3.5616e-02, 5.4173e-02, 1.9460e-02,\n",
      "         1.1242e-02, 4.3898e-03],\n",
      "        [3.4002e-05, 1.5932e-04, 1.6979e-03, 3.8953e-04, 1.6286e-03, 4.9621e-03,\n",
      "         2.1790e-02, 6.2579e-03, 6.2794e-03, 2.7434e-02, 1.2197e-01, 9.7230e-02,\n",
      "         1.2333e-01, 1.2185e-01, 1.4446e-01, 3.4344e-02, 1.2387e-01, 1.1343e-01,\n",
      "         4.2854e-02, 6.0179e-03],\n",
      "        [2.5624e-05, 2.1668e-04, 1.8535e-03, 2.1728e-04, 7.8869e-04, 1.9916e-03,\n",
      "         5.5109e-03, 1.5134e-03, 1.4355e-03, 4.8029e-03, 3.2802e-02, 2.7412e-02,\n",
      "         4.7173e-02, 1.0502e-01, 1.0341e-01, 1.8941e-02, 1.0240e-01, 1.7571e-01,\n",
      "         3.3779e-01, 3.0983e-02],\n",
      "        [4.1808e-05, 2.1422e-04, 2.2105e-03, 6.4125e-04, 1.7620e-03, 2.3058e-03,\n",
      "         5.9941e-03, 1.6317e-03, 2.0509e-03, 6.7467e-03, 3.4131e-02, 3.3060e-02,\n",
      "         5.2217e-02, 7.6555e-02, 7.3340e-02, 2.2580e-02, 9.4141e-02, 2.2476e-01,\n",
      "         2.3072e-01, 1.3490e-01],\n",
      "        [9.9429e-05, 3.5718e-04, 2.6271e-03, 3.1393e-04, 8.6761e-04, 1.4511e-03,\n",
      "         6.1842e-03, 1.2785e-03, 1.4049e-03, 7.0711e-03, 5.1664e-02, 4.1634e-02,\n",
      "         4.0084e-02, 3.9318e-02, 4.0130e-02, 1.3587e-02, 7.3775e-02, 3.3571e-01,\n",
      "         2.4916e-01, 9.3284e-02],\n",
      "        [3.9016e-05, 2.3342e-04, 2.2314e-03, 2.3192e-04, 4.9557e-04, 2.8917e-04,\n",
      "         9.2620e-04, 1.9752e-04, 2.8607e-04, 8.6415e-04, 7.6563e-03, 7.7137e-03,\n",
      "         7.8209e-03, 1.1155e-02, 1.0688e-02, 3.6022e-03, 2.8644e-02, 1.8678e-01,\n",
      "         5.4853e-01, 1.8161e-01],\n",
      "        [1.8579e-05, 1.3336e-04, 6.0524e-04, 3.4831e-04, 9.3851e-04, 1.1680e-03,\n",
      "         2.0361e-03, 7.7185e-04, 9.0421e-04, 1.8421e-03, 6.0834e-03, 5.0528e-03,\n",
      "         1.0481e-02, 2.4751e-02, 3.1215e-02, 1.1347e-02, 6.5925e-02, 1.6519e-01,\n",
      "         2.3553e-01, 4.3566e-01],\n",
      "        [1.5216e-04, 4.2702e-04, 2.7496e-03, 4.2414e-04, 7.8630e-04, 8.7080e-04,\n",
      "         2.6367e-03, 6.4232e-04, 5.8551e-04, 2.2278e-03, 8.9456e-03, 7.8092e-03,\n",
      "         7.5135e-03, 1.1025e-02, 1.3772e-02, 3.0249e-03, 3.1908e-02, 2.4145e-01,\n",
      "         4.1996e-01, 2.4309e-01],\n",
      "        [2.1080e-04, 1.4188e-03, 5.3140e-03, 1.1265e-03, 1.8012e-03, 1.3245e-03,\n",
      "         3.0971e-03, 1.0479e-03, 1.0158e-03, 2.3011e-03, 7.4050e-03, 6.8403e-03,\n",
      "         5.7764e-03, 6.5537e-03, 7.0106e-03, 2.5193e-03, 1.5053e-02, 1.5374e-01,\n",
      "         5.4777e-01, 2.2868e-01],\n",
      "        [1.7378e-04, 7.4772e-04, 5.7085e-03, 1.7420e-03, 2.6585e-03, 1.2187e-03,\n",
      "         3.1910e-03, 9.9161e-04, 1.4584e-03, 2.4262e-03, 8.6378e-03, 9.7846e-03,\n",
      "         9.3985e-03, 8.3790e-03, 8.8977e-03, 5.7000e-03, 2.7548e-02, 1.5013e-01,\n",
      "         3.3321e-01, 4.1799e-01],\n",
      "        [2.4814e-04, 1.0152e-03, 7.8375e-03, 3.1414e-03, 6.2065e-03, 3.3721e-03,\n",
      "         7.1704e-03, 2.6536e-03, 3.3010e-03, 4.4740e-03, 9.5586e-03, 1.1140e-02,\n",
      "         1.3026e-02, 1.3444e-02, 1.3613e-02, 9.0158e-03, 2.7673e-02, 1.2575e-01,\n",
      "         3.6288e-01, 3.7448e-01]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2.16, Train Loss: 0.00, Val Loss: 5.47, Train BLEU: 0.00, Val BLEU: 4.30, Minutes Elapsed: 200.74\n",
      "Sampling from val predictions...\n",
      "Source: 我 确实 实有 太多 从没 机会 穿 的 8 英寸 高跟鞋 但是 免费 的 东西 却是 我 在 现实 现实生活\n",
      "Reference: i do have too many <UNK> heels which i never get to wear , except for earlier , but\n",
      "Model: <SOS> i i &apos;t have to to , , i my a my . . . . <EOS> . <EOS>\n",
      "Attention Weights: tensor([[8.2044e-01, 1.4672e-01, 1.3374e-02, 1.8543e-02, 5.7780e-04, 2.5195e-04,\n",
      "         3.2771e-05, 8.5966e-06, 2.7030e-06, 1.9053e-05, 9.6405e-06, 7.1923e-06,\n",
      "         2.7602e-06, 9.8856e-07, 3.3320e-06, 1.7936e-06, 5.6119e-07, 3.1129e-08,\n",
      "         5.7075e-08, 3.5415e-08],\n",
      "        [1.3380e-01, 4.6649e-01, 1.3086e-01, 2.2230e-01, 2.6961e-02, 1.6171e-02,\n",
      "         1.5599e-03, 4.8559e-04, 1.3567e-04, 3.7973e-04, 2.3904e-04, 2.4245e-04,\n",
      "         1.3006e-04, 5.3420e-05, 8.2865e-05, 4.1455e-05, 4.0792e-05, 6.7421e-06,\n",
      "         9.0517e-06, 5.1429e-06],\n",
      "        [6.7233e-02, 2.1612e-01, 1.1741e-01, 3.8631e-01, 9.1965e-02, 9.7276e-02,\n",
      "         7.6994e-03, 3.1450e-03, 1.1217e-03, 2.4087e-03, 1.4865e-03, 2.3744e-03,\n",
      "         1.0955e-03, 7.0376e-04, 8.2006e-04, 5.6157e-04, 1.0854e-03, 5.0458e-04,\n",
      "         3.9427e-04, 2.8465e-04],\n",
      "        [2.4544e-03, 7.6889e-03, 3.5081e-02, 1.0888e-01, 1.7152e-01, 5.1310e-01,\n",
      "         6.3723e-02, 2.5850e-02, 1.3162e-02, 2.6809e-02, 1.3511e-02, 4.1002e-03,\n",
      "         4.9721e-03, 1.1417e-03, 2.8541e-03, 1.7602e-03, 1.6428e-03, 4.1179e-04,\n",
      "         8.8995e-04, 4.4002e-04],\n",
      "        [6.5223e-04, 1.1155e-03, 7.7009e-03, 2.1370e-02, 7.0809e-02, 4.1671e-01,\n",
      "         8.8287e-02, 8.5806e-02, 4.0954e-02, 9.9329e-02, 7.2268e-02, 3.0161e-02,\n",
      "         3.0501e-02, 3.8717e-03, 1.3370e-02, 6.6156e-03, 6.3654e-03, 9.7344e-04,\n",
      "         2.2919e-03, 8.4482e-04],\n",
      "        [5.3192e-04, 4.3463e-04, 2.6374e-03, 6.2278e-03, 2.7890e-02, 2.7965e-01,\n",
      "         6.4452e-02, 9.9715e-02, 5.2135e-02, 1.3217e-01, 1.1756e-01, 6.9708e-02,\n",
      "         6.7802e-02, 7.8498e-03, 3.1614e-02, 1.6481e-02, 1.5739e-02, 1.5885e-03,\n",
      "         4.3537e-03, 1.4598e-03],\n",
      "        [4.3075e-04, 3.1608e-04, 2.3142e-03, 4.7927e-03, 1.8963e-02, 1.6703e-01,\n",
      "         4.5425e-02, 8.6283e-02, 5.6434e-02, 1.2902e-01, 1.3428e-01, 1.2472e-01,\n",
      "         1.0650e-01, 1.1986e-02, 5.6457e-02, 2.6292e-02, 1.8938e-02, 2.3850e-03,\n",
      "         5.3909e-03, 2.0340e-03],\n",
      "        [1.1851e-03, 2.6710e-04, 8.0482e-04, 1.9923e-03, 4.4835e-03, 4.6086e-02,\n",
      "         9.9003e-03, 2.0766e-02, 3.7017e-02, 1.0022e-01, 1.2192e-01, 3.0019e-01,\n",
      "         1.5620e-01, 1.9011e-02, 9.5911e-02, 4.5635e-02, 3.0312e-02, 2.1048e-03,\n",
      "         4.5142e-03, 1.4709e-03],\n",
      "        [2.3152e-03, 3.6607e-04, 4.0874e-04, 6.3151e-04, 1.1411e-03, 1.2225e-02,\n",
      "         2.2549e-03, 4.9118e-03, 9.4681e-03, 2.6792e-02, 3.6256e-02, 2.5178e-01,\n",
      "         1.2174e-01, 1.3667e-02, 1.1024e-01, 8.7986e-02, 2.6495e-01, 1.1469e-02,\n",
      "         3.3096e-02, 8.3067e-03],\n",
      "        [1.8106e-03, 8.8106e-04, 9.5995e-04, 1.2370e-03, 1.8121e-03, 9.4929e-03,\n",
      "         2.0074e-03, 4.2943e-03, 4.4003e-03, 9.8294e-03, 1.4328e-02, 1.0931e-01,\n",
      "         6.6828e-02, 8.8288e-03, 7.6678e-02, 7.4573e-02, 4.7167e-01, 2.9399e-02,\n",
      "         8.7777e-02, 2.3876e-02],\n",
      "        [6.3753e-04, 5.4851e-04, 6.0093e-04, 1.3521e-03, 1.7887e-03, 6.6861e-03,\n",
      "         1.5749e-03, 2.6227e-03, 3.6969e-03, 7.1171e-03, 1.0763e-02, 7.4628e-02,\n",
      "         5.2707e-02, 7.3212e-03, 6.5647e-02, 9.9421e-02, 4.0233e-01, 5.3231e-02,\n",
      "         1.5612e-01, 5.1204e-02],\n",
      "        [1.5235e-04, 1.0775e-04, 1.9767e-04, 2.6241e-04, 6.1780e-04, 2.7887e-03,\n",
      "         1.4056e-03, 3.8939e-03, 2.5920e-03, 3.7249e-03, 5.4598e-03, 1.6904e-02,\n",
      "         2.1229e-02, 5.5491e-03, 2.3415e-02, 4.5284e-02, 2.2034e-01, 6.5716e-02,\n",
      "         4.7598e-01, 1.0439e-01],\n",
      "        [1.0534e-04, 6.6886e-05, 1.2690e-04, 1.5315e-04, 3.4490e-04, 1.6986e-03,\n",
      "         9.8517e-04, 3.6260e-03, 1.6645e-03, 2.4704e-03, 3.4360e-03, 1.1138e-02,\n",
      "         1.3574e-02, 4.0859e-03, 1.3278e-02, 2.4350e-02, 3.0642e-01, 5.5810e-02,\n",
      "         4.3134e-01, 1.2532e-01],\n",
      "        [1.3580e-04, 1.0701e-04, 3.0196e-04, 2.5564e-04, 7.2404e-04, 2.6444e-03,\n",
      "         1.7868e-03, 5.2605e-03, 2.4431e-03, 3.2149e-03, 4.4714e-03, 1.2162e-02,\n",
      "         1.5174e-02, 4.7985e-03, 1.4608e-02, 2.2009e-02, 2.0054e-01, 6.2069e-02,\n",
      "         4.6104e-01, 1.8626e-01],\n",
      "        [2.3015e-04, 1.3093e-04, 4.3084e-04, 4.0152e-04, 1.1586e-03, 3.9574e-03,\n",
      "         2.2249e-03, 4.9932e-03, 3.4269e-03, 4.5708e-03, 5.5318e-03, 9.7973e-03,\n",
      "         1.5780e-02, 3.9378e-03, 1.1225e-02, 1.5666e-02, 1.1871e-01, 4.1558e-02,\n",
      "         4.7454e-01, 2.8172e-01],\n",
      "        [1.1826e-03, 6.0765e-04, 1.7344e-03, 1.3775e-03, 3.7313e-03, 1.1096e-02,\n",
      "         7.1696e-03, 1.4751e-02, 7.6156e-03, 1.1211e-02, 1.4922e-02, 2.6125e-02,\n",
      "         3.6304e-02, 1.3167e-02, 2.7217e-02, 2.9000e-02, 1.3450e-01, 4.8359e-02,\n",
      "         3.5764e-01, 2.5229e-01],\n",
      "        [1.8555e-03, 3.0468e-03, 4.0306e-03, 6.6933e-03, 1.0150e-02, 2.3555e-02,\n",
      "         6.8572e-03, 1.1782e-02, 4.9768e-03, 6.7761e-03, 8.6016e-03, 3.5342e-02,\n",
      "         2.7236e-02, 1.2300e-02, 2.5571e-02, 2.8117e-02, 2.0422e-01, 5.9054e-02,\n",
      "         2.9734e-01, 2.2249e-01],\n",
      "        [7.1983e-03, 7.3230e-03, 6.6738e-03, 1.1680e-02, 1.5672e-02, 3.6866e-02,\n",
      "         1.2192e-02, 1.8361e-02, 7.3815e-03, 1.1248e-02, 1.4958e-02, 6.1418e-02,\n",
      "         5.2572e-02, 2.2401e-02, 4.7383e-02, 4.7361e-02, 2.2489e-01, 6.4587e-02,\n",
      "         1.8983e-01, 1.4000e-01],\n",
      "        [1.3759e-02, 7.0842e-03, 6.8951e-03, 1.4173e-02, 2.0032e-02, 5.4814e-02,\n",
      "         1.9357e-02, 2.3229e-02, 1.8821e-02, 2.9975e-02, 3.7966e-02, 8.7035e-02,\n",
      "         9.0714e-02, 3.3412e-02, 6.1592e-02, 6.2436e-02, 1.2151e-01, 5.1951e-02,\n",
      "         1.3469e-01, 1.1055e-01]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 2.22, Train Loss: 0.00, Val Loss: 5.42, Train BLEU: 0.00, Val BLEU: 4.84, Minutes Elapsed: 205.87\n",
      "Sampling from val predictions...\n",
      "Source: 所以 我 希望 分享 这种 主动 且 有意 有意识 意识 去 创造 记忆 的 想法 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: so i want to share the idea of taking an active role in consciously creating memories . <EOS> <PAD>\n",
      "Model: <SOS> so i i to to the the of the to to to . . . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.1728, 0.8256, 0.0014, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0084, 0.9805, 0.0092, 0.0018, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0072, 0.3149, 0.5237, 0.1444, 0.0059, 0.0010, 0.0004, 0.0004, 0.0002,\n",
      "         0.0004, 0.0002, 0.0001, 0.0002, 0.0001, 0.0002, 0.0004, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0060, 0.1700, 0.5289, 0.2572, 0.0265, 0.0026, 0.0013, 0.0011, 0.0006,\n",
      "         0.0008, 0.0007, 0.0006, 0.0007, 0.0006, 0.0008, 0.0016, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0013, 0.0191, 0.1902, 0.6400, 0.0997, 0.0093, 0.0034, 0.0040, 0.0024,\n",
      "         0.0056, 0.0026, 0.0034, 0.0051, 0.0017, 0.0068, 0.0054, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0005, 0.0080, 0.0859, 0.5730, 0.2442, 0.0202, 0.0073, 0.0069, 0.0032,\n",
      "         0.0100, 0.0038, 0.0059, 0.0095, 0.0030, 0.0108, 0.0078, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0003, 0.0041, 0.0238, 0.2985, 0.4468, 0.0682, 0.0206, 0.0207, 0.0090,\n",
      "         0.0363, 0.0071, 0.0139, 0.0206, 0.0045, 0.0162, 0.0094, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0001, 0.0023, 0.0085, 0.0658, 0.5299, 0.1455, 0.0584, 0.0529, 0.0146,\n",
      "         0.0673, 0.0126, 0.0107, 0.0137, 0.0030, 0.0093, 0.0054, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0005, 0.0062, 0.0104, 0.0292, 0.1716, 0.2304, 0.1121, 0.1525, 0.0275,\n",
      "         0.1700, 0.0475, 0.0148, 0.0159, 0.0019, 0.0065, 0.0031, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0002, 0.0038, 0.0059, 0.0186, 0.1606, 0.1348, 0.0880, 0.1367, 0.0370,\n",
      "         0.2070, 0.0550, 0.0493, 0.0599, 0.0055, 0.0281, 0.0097, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0002, 0.0018, 0.0018, 0.0035, 0.0324, 0.0778, 0.0912, 0.1835, 0.0487,\n",
      "         0.2499, 0.1620, 0.0576, 0.0611, 0.0048, 0.0200, 0.0038, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0006, 0.0011, 0.0025, 0.0149, 0.0250, 0.0376, 0.0973, 0.0427,\n",
      "         0.2204, 0.1579, 0.1528, 0.1784, 0.0113, 0.0506, 0.0067, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0004, 0.0006, 0.0021, 0.0095, 0.0206, 0.0276, 0.0886, 0.0443,\n",
      "         0.2737, 0.2007, 0.1395, 0.1527, 0.0075, 0.0279, 0.0041, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0001, 0.0010, 0.0016, 0.0042, 0.0101, 0.0116, 0.0140, 0.0434, 0.0296,\n",
      "         0.1770, 0.1245, 0.1958, 0.3120, 0.0105, 0.0539, 0.0106, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0003, 0.0033, 0.0039, 0.0087, 0.0165, 0.0149, 0.0145, 0.0358, 0.0264,\n",
      "         0.1351, 0.0901, 0.1865, 0.3550, 0.0143, 0.0742, 0.0206, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0006, 0.0039, 0.0037, 0.0068, 0.0107, 0.0156, 0.0154, 0.0456, 0.0332,\n",
      "         0.1577, 0.1370, 0.1688, 0.3040, 0.0146, 0.0628, 0.0195, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0003, 0.0046, 0.0092, 0.0172, 0.0290, 0.0228, 0.0180, 0.0324, 0.0237,\n",
      "         0.0765, 0.0571, 0.1483, 0.3538, 0.0203, 0.1311, 0.0558, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0009, 0.0099, 0.0154, 0.0273, 0.0410, 0.0310, 0.0237, 0.0381, 0.0289,\n",
      "         0.0828, 0.0627, 0.1288, 0.2747, 0.0233, 0.1184, 0.0933, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0015, 0.0139, 0.0166, 0.0337, 0.0454, 0.0287, 0.0222, 0.0340, 0.0271,\n",
      "         0.0752, 0.0565, 0.1213, 0.2543, 0.0279, 0.1213, 0.1202, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2.27, Train Loss: 0.00, Val Loss: 5.38, Train BLEU: 0.00, Val BLEU: 4.28, Minutes Elapsed: 211.00\n",
      "Sampling from val predictions...\n",
      "Source: 我 发现 美国 国人 能 看出 我们 变化 中 的 脆弱 脆弱性 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: i find that americans see the fragility in changes . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> i i the the , the the of the , we &apos;re have <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9981, 0.0012, 0.0006, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.4118, 0.4435, 0.1381, 0.0055, 0.0009, 0.0001, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1429, 0.1712, 0.5516, 0.1137, 0.0132, 0.0018, 0.0020, 0.0009, 0.0006,\n",
      "         0.0004, 0.0004, 0.0003, 0.0009, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0088, 0.0264, 0.6696, 0.1945, 0.0449, 0.0216, 0.0172, 0.0081, 0.0023,\n",
      "         0.0015, 0.0023, 0.0011, 0.0018, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0122, 0.0131, 0.4943, 0.2633, 0.1432, 0.0430, 0.0163, 0.0064, 0.0027,\n",
      "         0.0014, 0.0014, 0.0006, 0.0020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0265, 0.0127, 0.3215, 0.3541, 0.2155, 0.0349, 0.0235, 0.0061, 0.0016,\n",
      "         0.0008, 0.0013, 0.0005, 0.0011, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0186, 0.0046, 0.1656, 0.2478, 0.2770, 0.0836, 0.1472, 0.0380, 0.0066,\n",
      "         0.0030, 0.0049, 0.0011, 0.0020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0083, 0.0050, 0.1117, 0.1769, 0.2202, 0.1395, 0.2106, 0.0837, 0.0160,\n",
      "         0.0078, 0.0149, 0.0031, 0.0024, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0300, 0.0046, 0.1469, 0.3087, 0.2760, 0.0457, 0.1266, 0.0432, 0.0071,\n",
      "         0.0031, 0.0061, 0.0011, 0.0011, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0208, 0.0037, 0.0736, 0.1358, 0.1631, 0.0371, 0.3749, 0.1487, 0.0176,\n",
      "         0.0063, 0.0153, 0.0017, 0.0015, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0118, 0.0033, 0.0670, 0.1064, 0.1376, 0.0558, 0.3116, 0.2131, 0.0465,\n",
      "         0.0148, 0.0271, 0.0035, 0.0015, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0100, 0.0042, 0.0415, 0.0601, 0.0627, 0.0253, 0.4350, 0.2701, 0.0403,\n",
      "         0.0126, 0.0343, 0.0028, 0.0012, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0022, 0.0009, 0.0047, 0.0096, 0.0251, 0.0152, 0.4499, 0.2969, 0.0854,\n",
      "         0.0355, 0.0681, 0.0051, 0.0014, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0013, 0.0008, 0.0038, 0.0091, 0.0199, 0.0173, 0.3340, 0.2971, 0.1050,\n",
      "         0.0571, 0.1417, 0.0110, 0.0018, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0021, 0.0014, 0.0085, 0.0094, 0.0136, 0.0084, 0.5483, 0.2425, 0.0467,\n",
      "         0.0224, 0.0850, 0.0081, 0.0036, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0053, 0.0043, 0.0199, 0.0183, 0.0252, 0.0134, 0.6096, 0.1998, 0.0341,\n",
      "         0.0151, 0.0447, 0.0051, 0.0051, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0108, 0.0090, 0.0361, 0.0304, 0.0350, 0.0188, 0.5649, 0.1956, 0.0358,\n",
      "         0.0152, 0.0375, 0.0047, 0.0062, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0168, 0.0135, 0.0507, 0.0403, 0.0439, 0.0232, 0.5265, 0.1894, 0.0368,\n",
      "         0.0150, 0.0326, 0.0044, 0.0069, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0223, 0.0173, 0.0630, 0.0483, 0.0508, 0.0261, 0.4992, 0.1806, 0.0369,\n",
      "         0.0147, 0.0291, 0.0042, 0.0074, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 2.33, Train Loss: 0.00, Val Loss: 5.50, Train BLEU: 0.00, Val BLEU: 3.72, Minutes Elapsed: 216.13\n",
      "Sampling from val predictions...\n",
      "Source: 这 就 像 在 水池 池里 扔 一块 块石 石头 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: it &apos;s like throwing a stone in a pond of water . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> this &apos;s a a a the of . . . . . <EOS> <EOS> . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.8002, 0.1723, 0.0265, 0.0006, 0.0002, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1142, 0.4826, 0.3887, 0.0115, 0.0018, 0.0007, 0.0003, 0.0001, 0.0001,\n",
      "         0.0001, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0451, 0.2814, 0.5896, 0.0591, 0.0142, 0.0049, 0.0021, 0.0008, 0.0005,\n",
      "         0.0007, 0.0017, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0185, 0.0309, 0.1924, 0.2297, 0.1869, 0.1545, 0.0493, 0.0296, 0.0278,\n",
      "         0.0554, 0.0251, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0468, 0.0414, 0.0905, 0.1678, 0.1423, 0.2447, 0.1200, 0.0373, 0.0161,\n",
      "         0.0345, 0.0586, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0305, 0.0328, 0.0817, 0.2125, 0.1358, 0.2443, 0.1382, 0.0527, 0.0148,\n",
      "         0.0286, 0.0284, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0656, 0.0375, 0.0528, 0.1150, 0.1307, 0.2740, 0.1368, 0.0924, 0.0248,\n",
      "         0.0448, 0.0257, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0305, 0.0368, 0.0488, 0.0910, 0.1225, 0.3015, 0.1639, 0.1040, 0.0264,\n",
      "         0.0509, 0.0238, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0758, 0.0565, 0.0578, 0.1180, 0.1140, 0.2157, 0.1157, 0.1050, 0.0358,\n",
      "         0.0761, 0.0295, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0601, 0.0484, 0.0470, 0.0910, 0.1130, 0.2425, 0.1172, 0.0919, 0.0385,\n",
      "         0.0758, 0.0747, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0364, 0.0406, 0.0533, 0.1044, 0.1518, 0.2539, 0.1058, 0.0908, 0.0387,\n",
      "         0.0743, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0711, 0.0614, 0.0551, 0.1042, 0.1333, 0.2162, 0.0922, 0.0782, 0.0364,\n",
      "         0.0734, 0.0785, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0484, 0.0468, 0.0483, 0.0895, 0.1430, 0.2312, 0.0998, 0.0583, 0.0316,\n",
      "         0.0673, 0.1359, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0811, 0.0799, 0.0808, 0.1119, 0.0969, 0.1373, 0.0671, 0.0863, 0.0449,\n",
      "         0.0800, 0.1337, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0527, 0.0934, 0.1087, 0.1166, 0.0453, 0.0628, 0.0732, 0.1313, 0.0680,\n",
      "         0.1390, 0.1089, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0287, 0.0541, 0.0806, 0.0960, 0.0379, 0.0587, 0.0740, 0.1535, 0.0964,\n",
      "         0.1831, 0.1371, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0988, 0.1109, 0.1079, 0.1121, 0.0342, 0.0543, 0.0515, 0.1064, 0.0445,\n",
      "         0.0768, 0.2027, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1327, 0.1245, 0.1154, 0.1105, 0.0329, 0.0476, 0.0443, 0.0982, 0.0423,\n",
      "         0.0712, 0.1802, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1454, 0.1345, 0.1203, 0.1132, 0.0336, 0.0479, 0.0424, 0.0859, 0.0369,\n",
      "         0.0643, 0.1756, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 2.38, Train Loss: 0.00, Val Loss: 5.44, Train BLEU: 0.00, Val BLEU: 4.05, Minutes Elapsed: 221.24\n",
      "Sampling from val predictions...\n",
      "Source: 今天 我 想 聊 一个 令人 令人不安 不安 的 问题 这个 问题 的 答案 同样 令人 烦扰 <EOS> <PAD> <PAD>\n",
      "Reference: i &apos;m here today to talk about a disturbing question , which has an equally disturbing answer . <EOS>\n",
      "Model: <SOS> now i to to a a a a question of this this this a . . . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9444, 0.0552, 0.0003, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.3748, 0.5398, 0.0810, 0.0036, 0.0002, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0603, 0.3351, 0.5121, 0.0774, 0.0076, 0.0018, 0.0006, 0.0009, 0.0006,\n",
      "         0.0014, 0.0005, 0.0006, 0.0002, 0.0004, 0.0002, 0.0001, 0.0000, 0.0003,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0023, 0.0125, 0.0720, 0.1984, 0.3117, 0.1633, 0.0382, 0.0430, 0.0096,\n",
      "         0.0701, 0.0202, 0.0248, 0.0034, 0.0125, 0.0066, 0.0052, 0.0022, 0.0040,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0072, 0.0270, 0.0524, 0.0542, 0.2046, 0.1995, 0.0452, 0.0652, 0.0292,\n",
      "         0.1546, 0.0520, 0.0462, 0.0110, 0.0223, 0.0122, 0.0047, 0.0011, 0.0116,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0027, 0.0100, 0.0243, 0.0550, 0.2578, 0.1990, 0.0383, 0.0628, 0.0340,\n",
      "         0.1637, 0.0576, 0.0535, 0.0096, 0.0168, 0.0076, 0.0019, 0.0004, 0.0050,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0034, 0.0088, 0.0126, 0.0167, 0.1066, 0.1312, 0.0426, 0.0994, 0.0390,\n",
      "         0.2650, 0.1228, 0.1007, 0.0102, 0.0229, 0.0113, 0.0018, 0.0004, 0.0046,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0020, 0.0052, 0.0052, 0.0061, 0.0451, 0.0967, 0.0405, 0.1038, 0.0358,\n",
      "         0.2616, 0.1918, 0.1275, 0.0165, 0.0339, 0.0168, 0.0027, 0.0005, 0.0081,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0021, 0.0046, 0.0044, 0.0060, 0.0306, 0.0426, 0.0214, 0.0671, 0.0244,\n",
      "         0.2318, 0.2984, 0.1787, 0.0150, 0.0408, 0.0244, 0.0026, 0.0004, 0.0046,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0024, 0.0048, 0.0036, 0.0025, 0.0071, 0.0180, 0.0174, 0.0619, 0.0113,\n",
      "         0.1601, 0.3737, 0.2209, 0.0160, 0.0577, 0.0336, 0.0030, 0.0006, 0.0055,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0016, 0.0041, 0.0027, 0.0016, 0.0025, 0.0110, 0.0170, 0.0569, 0.0063,\n",
      "         0.1016, 0.3978, 0.1987, 0.0184, 0.1078, 0.0550, 0.0066, 0.0015, 0.0089,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0016, 0.0039, 0.0026, 0.0016, 0.0019, 0.0038, 0.0056, 0.0160, 0.0021,\n",
      "         0.0286, 0.3211, 0.1963, 0.0132, 0.1033, 0.2679, 0.0201, 0.0034, 0.0070,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0010, 0.0027, 0.0022, 0.0028, 0.0045, 0.0042, 0.0038, 0.0083, 0.0022,\n",
      "         0.0176, 0.1779, 0.1563, 0.0128, 0.0916, 0.4513, 0.0460, 0.0071, 0.0077,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0001, 0.0003, 0.0008, 0.0006, 0.0011, 0.0015, 0.0014, 0.0033, 0.0009,\n",
      "         0.0078, 0.1202, 0.1742, 0.0155, 0.1430, 0.4211, 0.0847, 0.0194, 0.0042,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0001, 0.0002, 0.0003, 0.0002, 0.0006, 0.0011, 0.0010, 0.0022, 0.0007,\n",
      "         0.0049, 0.0338, 0.0597, 0.0089, 0.0802, 0.5243, 0.2247, 0.0489, 0.0082,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0002, 0.0003, 0.0002, 0.0003, 0.0009, 0.0015, 0.0014, 0.0035, 0.0017,\n",
      "         0.0071, 0.0559, 0.0567, 0.0140, 0.0786, 0.5782, 0.1436, 0.0296, 0.0262,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0013, 0.0018, 0.0008, 0.0012, 0.0018, 0.0030, 0.0034, 0.0094, 0.0030,\n",
      "         0.0167, 0.0731, 0.0781, 0.0175, 0.1096, 0.4317, 0.1275, 0.0377, 0.0825,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0026, 0.0058, 0.0031, 0.0038, 0.0055, 0.0075, 0.0078, 0.0217, 0.0076,\n",
      "         0.0322, 0.1025, 0.1120, 0.0246, 0.1132, 0.2828, 0.0734, 0.0327, 0.1612,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0077, 0.0187, 0.0137, 0.0146, 0.0181, 0.0148, 0.0130, 0.0280, 0.0152,\n",
      "         0.0512, 0.1243, 0.1141, 0.0280, 0.0790, 0.2115, 0.0587, 0.0234, 0.1660,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2.44, Train Loss: 0.00, Val Loss: 5.33, Train BLEU: 0.00, Val BLEU: 4.28, Minutes Elapsed: 226.37\n",
      "Sampling from val predictions...\n",
      "Source: 这些 井 有 差不多 不多 有 90 多米 深 他们 <UNK> <UNK> 出来 装满 <UNK> 的 袋子 这些 石头 被\n",
      "Reference: the shafts are up to 300 feet deep , and they carry out heavy bags of stone that later\n",
      "Model: <SOS> these are of they <UNK> they their their their they they they them them them . <EOS> . <EOS>\n",
      "Attention Weights: tensor([[7.2936e-01, 1.7139e-02, 8.2352e-02, 1.0701e-01, 5.7900e-02, 4.1197e-03,\n",
      "         9.3258e-04, 4.2123e-04, 1.6961e-04, 5.7366e-04, 1.1135e-06, 1.1350e-06,\n",
      "         2.4205e-06, 9.2868e-07, 3.8596e-07, 2.4242e-06, 1.3419e-06, 3.7807e-06,\n",
      "         3.9726e-07, 8.9233e-07],\n",
      "        [1.0111e-01, 4.2588e-02, 1.3966e-01, 3.8347e-01, 2.8029e-01, 3.3560e-02,\n",
      "         9.1147e-03, 2.9899e-03, 1.5913e-03, 5.0837e-03, 7.3389e-05, 8.7018e-05,\n",
      "         1.0766e-04, 4.7483e-05, 3.0008e-05, 5.6430e-05, 3.7861e-05, 7.7384e-05,\n",
      "         1.4485e-05, 1.7078e-05],\n",
      "        [2.4908e-02, 1.5778e-02, 8.5050e-02, 2.5294e-01, 3.4965e-01, 9.9290e-02,\n",
      "         6.6681e-02, 3.3671e-02, 2.2454e-02, 4.3329e-02, 1.3926e-03, 1.3749e-03,\n",
      "         1.0603e-03, 5.5206e-04, 3.6794e-04, 3.8287e-04, 3.1654e-04, 5.2960e-04,\n",
      "         1.3320e-04, 1.4214e-04],\n",
      "        [3.1537e-02, 4.6435e-03, 2.0681e-02, 4.7553e-02, 9.6434e-02, 7.4473e-02,\n",
      "         1.2734e-01, 1.0012e-01, 8.4544e-02, 3.9448e-01, 4.4634e-03, 4.3519e-03,\n",
      "         4.3603e-03, 1.5633e-03, 6.2751e-04, 6.5756e-04, 6.9578e-04, 1.0663e-03,\n",
      "         1.4937e-04, 2.6695e-04],\n",
      "        [5.7544e-03, 3.5071e-04, 3.3019e-03, 9.7448e-03, 2.5745e-02, 1.9344e-02,\n",
      "         4.5789e-02, 4.1373e-02, 2.6871e-02, 7.5394e-01, 1.1531e-02, 1.1881e-02,\n",
      "         2.1853e-02, 9.1132e-03, 2.2144e-03, 1.7626e-03, 2.8827e-03, 5.3277e-03,\n",
      "         4.3962e-04, 7.7582e-04],\n",
      "        [1.1905e-03, 6.8308e-05, 4.7811e-04, 3.6089e-03, 1.9685e-02, 1.3696e-02,\n",
      "         3.4137e-02, 5.6305e-02, 3.8426e-02, 5.7593e-01, 2.7710e-02, 3.7650e-02,\n",
      "         8.9888e-02, 3.5063e-02, 1.1066e-02, 1.1983e-02, 1.3257e-02, 2.6610e-02,\n",
      "         1.5573e-03, 1.6871e-03],\n",
      "        [8.3032e-04, 6.2710e-05, 3.0182e-04, 1.5271e-03, 5.4579e-03, 4.2437e-03,\n",
      "         1.3844e-02, 2.5450e-02, 1.3321e-02, 4.9031e-01, 3.8312e-02, 5.5110e-02,\n",
      "         1.5204e-01, 6.9515e-02, 2.3697e-02, 1.9504e-02, 2.5076e-02, 5.5806e-02,\n",
      "         3.3375e-03, 2.2506e-03],\n",
      "        [2.1547e-04, 2.5796e-05, 1.2188e-04, 7.4062e-04, 2.8815e-03, 1.9107e-03,\n",
      "         6.1293e-03, 1.1699e-02, 4.3542e-03, 1.9608e-01, 3.8383e-02, 6.6430e-02,\n",
      "         2.1794e-01, 1.2914e-01, 6.0534e-02, 4.1406e-02, 5.6806e-02, 1.5146e-01,\n",
      "         9.9362e-03, 3.8055e-03],\n",
      "        [2.1878e-04, 1.4853e-05, 6.0811e-05, 1.9998e-04, 4.9478e-04, 4.0504e-04,\n",
      "         9.3247e-04, 1.7535e-03, 8.2505e-04, 8.9884e-02, 6.9037e-03, 1.6020e-02,\n",
      "         1.6936e-01, 7.8694e-02, 4.1840e-02, 6.0204e-02, 6.9407e-02, 4.2218e-01,\n",
      "         2.3894e-02, 1.6707e-02],\n",
      "        [1.0816e-04, 9.8852e-06, 3.6425e-05, 1.5069e-04, 3.7274e-04, 2.6965e-04,\n",
      "         5.9193e-04, 9.2066e-04, 3.4385e-04, 2.3967e-02, 3.9851e-03, 9.3631e-03,\n",
      "         8.3870e-02, 5.9245e-02, 4.4411e-02, 5.3727e-02, 6.0359e-02, 5.6238e-01,\n",
      "         5.6560e-02, 3.9333e-02],\n",
      "        [1.5386e-04, 1.4126e-05, 5.2011e-05, 1.6810e-04, 3.2538e-04, 2.4063e-04,\n",
      "         4.7852e-04, 6.9496e-04, 3.2374e-04, 2.0818e-02, 2.4402e-03, 5.3159e-03,\n",
      "         5.4104e-02, 3.6736e-02, 2.6552e-02, 3.9437e-02, 4.4345e-02, 6.2681e-01,\n",
      "         6.6066e-02, 7.4919e-02],\n",
      "        [9.5357e-05, 2.6150e-05, 1.4109e-04, 6.6476e-04, 1.2173e-03, 5.1364e-04,\n",
      "         5.6815e-04, 6.5882e-04, 3.4043e-04, 1.4382e-02, 5.5339e-03, 1.2767e-02,\n",
      "         4.2432e-02, 7.4366e-02, 7.5246e-02, 3.8281e-02, 6.2627e-02, 4.1645e-01,\n",
      "         1.1084e-01, 1.4285e-01],\n",
      "        [1.3383e-04, 3.5877e-05, 2.2309e-04, 6.7183e-04, 1.1157e-03, 5.6549e-04,\n",
      "         4.9510e-04, 6.4314e-04, 4.9252e-04, 1.4576e-02, 4.1149e-03, 9.6189e-03,\n",
      "         3.0834e-02, 4.6121e-02, 4.7975e-02, 3.8885e-02, 5.2555e-02, 3.3993e-01,\n",
      "         1.3567e-01, 2.7534e-01],\n",
      "        [1.0813e-04, 2.8976e-05, 1.3019e-04, 3.3526e-04, 7.1404e-04, 4.5562e-04,\n",
      "         3.7426e-04, 3.9318e-04, 3.3278e-04, 3.1238e-03, 1.0541e-03, 2.0123e-03,\n",
      "         1.2636e-02, 2.6461e-02, 2.9777e-02, 3.7755e-02, 2.4004e-02, 4.9017e-01,\n",
      "         1.4262e-01, 2.2752e-01],\n",
      "        [2.2090e-04, 3.7897e-05, 1.8010e-04, 5.8266e-04, 1.2542e-03, 8.7649e-04,\n",
      "         7.1708e-04, 6.6734e-04, 4.1659e-04, 5.2059e-03, 1.2253e-03, 2.1117e-03,\n",
      "         1.2438e-02, 2.2288e-02, 2.0480e-02, 3.0714e-02, 1.5705e-02, 4.9305e-01,\n",
      "         1.1790e-01, 2.7393e-01],\n",
      "        [2.2144e-03, 3.8025e-04, 1.5699e-03, 5.2061e-03, 9.7635e-03, 6.2202e-03,\n",
      "         4.9082e-03, 4.2190e-03, 2.4072e-03, 1.8748e-02, 5.5064e-03, 8.0825e-03,\n",
      "         3.1439e-02, 4.9392e-02, 4.4732e-02, 5.1191e-02, 2.8918e-02, 4.0081e-01,\n",
      "         1.1233e-01, 2.1196e-01],\n",
      "        [9.8282e-03, 1.4385e-03, 4.3661e-03, 1.1689e-02, 1.8419e-02, 1.2820e-02,\n",
      "         1.2762e-02, 1.1357e-02, 6.1027e-03, 5.1820e-02, 1.3590e-02, 1.9048e-02,\n",
      "         6.2803e-02, 6.7006e-02, 5.7367e-02, 6.8228e-02, 4.8505e-02, 3.0571e-01,\n",
      "         9.6620e-02, 1.2052e-01],\n",
      "        [2.0665e-02, 4.4016e-03, 1.2496e-02, 3.1489e-02, 3.9438e-02, 2.3921e-02,\n",
      "         1.8813e-02, 1.4989e-02, 6.9478e-03, 6.5439e-02, 1.7318e-02, 2.3888e-02,\n",
      "         7.3574e-02, 7.2180e-02, 5.1319e-02, 6.3792e-02, 5.0022e-02, 2.4672e-01,\n",
      "         7.2378e-02, 9.0208e-02],\n",
      "        [9.9972e-03, 1.7204e-03, 4.3261e-03, 1.1791e-02, 2.3458e-02, 2.0797e-02,\n",
      "         2.3802e-02, 2.8585e-02, 1.7865e-02, 5.9945e-02, 2.8106e-02, 3.9523e-02,\n",
      "         9.3177e-02, 7.1685e-02, 7.5592e-02, 9.6626e-02, 5.3233e-02, 1.7417e-01,\n",
      "         6.3316e-02, 1.0229e-01]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 2.49, Train Loss: 0.00, Val Loss: 5.39, Train BLEU: 0.00, Val BLEU: 4.93, Minutes Elapsed: 231.51\n",
      "Sampling from val predictions...\n",
      "Source: 新大 新大陆 大陆 的 <UNK> 主要 生长 在 美洲 大陆 像是 美洲 <UNK> 和 委内瑞拉 瑞拉 <UNK> 而 在 其他\n",
      "Reference: there are the new world <UNK> that are mainly found in the americas , like the <UNK> and the\n",
      "Model: <SOS> the , a of of of the the in in in in . of . . . . .\n",
      "Attention Weights: tensor([[4.0923e-03, 1.7556e-02, 6.7040e-01, 5.1893e-02, 1.1042e-02, 2.2252e-01,\n",
      "         1.5980e-03, 1.0506e-03, 1.2425e-02, 6.4915e-03, 4.7081e-04, 2.7496e-04,\n",
      "         5.5195e-06, 9.1636e-06, 1.0030e-05, 3.0173e-06, 1.1832e-05, 2.2152e-05,\n",
      "         2.0819e-05, 1.0698e-04],\n",
      "        [3.0560e-03, 2.4017e-02, 5.9043e-01, 1.0132e-01, 4.1511e-02, 1.7642e-01,\n",
      "         8.3825e-03, 8.9113e-03, 2.5252e-02, 1.5413e-02, 3.0546e-03, 1.0407e-03,\n",
      "         6.0529e-05, 1.1752e-04, 8.3934e-05, 3.6575e-05, 1.7135e-04, 3.1681e-04,\n",
      "         1.8244e-04, 2.2953e-04],\n",
      "        [1.5938e-03, 2.2884e-02, 1.9256e-01, 9.5350e-02, 1.0493e-01, 2.4999e-01,\n",
      "         5.5919e-02, 5.5041e-02, 1.0783e-01, 5.9486e-02, 2.7577e-02, 1.3188e-02,\n",
      "         1.5049e-03, 1.7798e-03, 1.6241e-03, 7.9567e-04, 1.7892e-03, 2.3027e-03,\n",
      "         1.4571e-03, 2.4066e-03],\n",
      "        [1.2480e-04, 6.6843e-03, 6.6385e-02, 1.0705e-02, 3.9549e-02, 2.0901e-01,\n",
      "         6.0754e-02, 4.1294e-02, 2.6638e-01, 1.3886e-01, 6.1295e-02, 5.2545e-02,\n",
      "         4.2886e-03, 4.0043e-03, 6.9303e-03, 2.7394e-03, 3.7674e-03, 3.3329e-03,\n",
      "         3.3811e-03, 1.7969e-02],\n",
      "        [1.8773e-04, 6.0997e-03, 6.4568e-02, 1.3481e-02, 3.3607e-02, 1.6902e-01,\n",
      "         5.5012e-02, 7.7654e-02, 2.7997e-01, 1.3102e-01, 6.6264e-02, 5.4874e-02,\n",
      "         5.0446e-03, 6.3349e-03, 7.1229e-03, 2.9714e-03, 5.1798e-03, 5.4705e-03,\n",
      "         3.7277e-03, 1.2395e-02],\n",
      "        [5.2272e-04, 9.1408e-03, 6.0866e-02, 1.1747e-02, 3.3043e-02, 8.3245e-02,\n",
      "         6.3714e-02, 1.0339e-01, 3.8879e-01, 9.8689e-02, 5.2439e-02, 6.5974e-02,\n",
      "         5.2966e-03, 5.2514e-03, 6.8541e-03, 1.8238e-03, 2.9743e-03, 2.4675e-03,\n",
      "         1.2375e-03, 2.5317e-03],\n",
      "        [1.7652e-04, 4.3665e-03, 2.6935e-02, 5.1822e-03, 1.8203e-02, 4.6667e-02,\n",
      "         4.9042e-02, 9.7614e-02, 4.1936e-01, 1.0964e-01, 7.1323e-02, 1.0869e-01,\n",
      "         8.5763e-03, 7.7162e-03, 1.1421e-02, 2.4770e-03, 4.1824e-03, 3.3952e-03,\n",
      "         1.5876e-03, 3.4410e-03],\n",
      "        [5.2525e-05, 1.4887e-03, 9.7103e-03, 1.4986e-03, 6.4803e-03, 1.6176e-02,\n",
      "         1.7541e-02, 2.9672e-02, 3.8162e-01, 1.3428e-01, 7.3377e-02, 2.1720e-01,\n",
      "         1.8242e-02, 1.1473e-02, 3.2695e-02, 6.0472e-03, 1.2580e-02, 6.9928e-03,\n",
      "         4.1291e-03, 1.8750e-02],\n",
      "        [7.3960e-05, 9.7061e-04, 4.7902e-03, 1.1519e-03, 3.1213e-03, 6.3035e-03,\n",
      "         7.6888e-03, 1.4201e-02, 1.9579e-01, 6.2642e-02, 3.8761e-02, 2.9084e-01,\n",
      "         4.6705e-02, 2.7148e-02, 1.2140e-01, 2.2974e-02, 4.6930e-02, 2.6405e-02,\n",
      "         1.3747e-02, 6.8357e-02],\n",
      "        [1.0034e-04, 1.1609e-03, 5.4167e-03, 1.6215e-03, 3.9984e-03, 1.0987e-02,\n",
      "         1.1029e-02, 1.2409e-02, 1.1707e-01, 7.8699e-02, 6.3576e-02, 1.8670e-01,\n",
      "         4.9315e-02, 3.7737e-02, 9.3666e-02, 2.7947e-02, 5.0460e-02, 3.7849e-02,\n",
      "         2.4408e-02, 1.8585e-01],\n",
      "        [2.9326e-05, 6.1828e-04, 4.0126e-03, 9.3397e-04, 1.9660e-03, 1.0888e-02,\n",
      "         8.5391e-03, 1.0008e-02, 1.6461e-01, 8.0038e-02, 5.1950e-02, 2.3349e-01,\n",
      "         4.1752e-02, 3.2877e-02, 8.8429e-02, 2.1819e-02, 3.3787e-02, 3.1139e-02,\n",
      "         2.1751e-02, 1.6136e-01],\n",
      "        [4.3313e-05, 8.6414e-04, 5.7586e-03, 1.2879e-03, 2.5536e-03, 8.4189e-03,\n",
      "         6.7435e-03, 9.9220e-03, 1.6962e-01, 8.0098e-02, 3.0789e-02, 2.3009e-01,\n",
      "         5.1735e-02, 3.5409e-02, 1.3653e-01, 3.5867e-02, 4.8460e-02, 2.8837e-02,\n",
      "         1.7514e-02, 9.9459e-02],\n",
      "        [8.7938e-05, 1.3167e-03, 7.4092e-03, 1.9049e-03, 2.6926e-03, 7.9968e-03,\n",
      "         4.8517e-03, 7.2383e-03, 1.1342e-01, 5.6427e-02, 1.9376e-02, 1.9580e-01,\n",
      "         4.6951e-02, 2.6799e-02, 1.6849e-01, 4.8551e-02, 6.1891e-02, 3.0839e-02,\n",
      "         2.2512e-02, 1.7544e-01],\n",
      "        [1.1907e-04, 1.2656e-03, 5.9317e-03, 1.9979e-03, 3.7246e-03, 7.5827e-03,\n",
      "         9.5657e-03, 1.5143e-02, 8.1548e-02, 4.4473e-02, 2.4491e-02, 1.1360e-01,\n",
      "         6.4906e-02, 5.7651e-02, 1.6452e-01, 8.3799e-02, 1.0473e-01, 7.5330e-02,\n",
      "         3.7895e-02, 1.0173e-01],\n",
      "        [1.9096e-04, 1.6919e-03, 5.9358e-03, 2.0402e-03, 4.7451e-03, 7.3403e-03,\n",
      "         1.1424e-02, 1.8979e-02, 1.1740e-01, 3.5970e-02, 1.9736e-02, 1.5116e-01,\n",
      "         6.7550e-02, 4.4160e-02, 1.9807e-01, 7.5898e-02, 8.9214e-02, 5.5746e-02,\n",
      "         2.5624e-02, 6.7125e-02],\n",
      "        [3.5023e-04, 3.2110e-03, 1.2445e-02, 6.0869e-03, 8.2096e-03, 1.3367e-02,\n",
      "         1.1506e-02, 2.8148e-02, 1.5826e-01, 4.4899e-02, 2.2755e-02, 1.5549e-01,\n",
      "         4.3596e-02, 2.8853e-02, 1.4252e-01, 5.6713e-02, 8.5795e-02, 4.8854e-02,\n",
      "         3.2961e-02, 9.5987e-02],\n",
      "        [3.9180e-04, 2.6055e-03, 9.0521e-03, 5.4270e-03, 4.9582e-03, 1.0900e-02,\n",
      "         5.7076e-03, 1.1664e-02, 3.3903e-02, 1.9897e-02, 1.5032e-02, 6.0043e-02,\n",
      "         2.3090e-02, 1.8025e-02, 9.9762e-02, 4.9003e-02, 6.5658e-02, 7.7275e-02,\n",
      "         6.9234e-02, 4.1837e-01],\n",
      "        [3.1074e-04, 4.3934e-03, 2.3208e-02, 9.6149e-03, 8.6460e-03, 2.7891e-02,\n",
      "         9.1686e-03, 1.9674e-02, 8.0669e-02, 4.4975e-02, 2.6886e-02, 9.9941e-02,\n",
      "         2.5367e-02, 2.0039e-02, 1.0573e-01, 4.0006e-02, 5.0313e-02, 4.0632e-02,\n",
      "         4.6197e-02, 3.1634e-01],\n",
      "        [5.3674e-04, 3.8536e-03, 1.5529e-02, 6.9818e-03, 1.1910e-02, 1.9983e-02,\n",
      "         1.5765e-02, 3.8070e-02, 1.0231e-01, 4.7917e-02, 3.6167e-02, 1.2029e-01,\n",
      "         5.4422e-02, 4.2905e-02, 1.4281e-01, 7.0476e-02, 8.3023e-02, 5.0850e-02,\n",
      "         3.7464e-02, 9.8742e-02]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2.55, Train Loss: 0.00, Val Loss: 5.35, Train BLEU: 0.00, Val BLEU: 4.39, Minutes Elapsed: 236.65\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 行为 很 有 可能 会 让 他们 的 境遇 比 现在 更糟 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: i could get them in a worse situation than they were already in . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> my mean , be , , , , , they , . . . . <EOS> . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.8693, 0.0149, 0.0864, 0.0214, 0.0031, 0.0048, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0330, 0.0204, 0.8012, 0.1032, 0.0222, 0.0194, 0.0005, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0310, 0.0084, 0.1955, 0.3389, 0.1307, 0.2679, 0.0234, 0.0013, 0.0016,\n",
      "         0.0001, 0.0004, 0.0001, 0.0001, 0.0002, 0.0002, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0196, 0.0036, 0.0988, 0.2284, 0.1123, 0.3226, 0.1131, 0.0276, 0.0504,\n",
      "         0.0026, 0.0105, 0.0011, 0.0020, 0.0037, 0.0036, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0138, 0.0012, 0.0130, 0.0502, 0.0292, 0.1839, 0.1367, 0.0994, 0.3516,\n",
      "         0.0221, 0.0615, 0.0056, 0.0090, 0.0145, 0.0085, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0069, 0.0006, 0.0044, 0.0184, 0.0099, 0.0884, 0.0821, 0.0837, 0.4670,\n",
      "         0.0445, 0.1164, 0.0157, 0.0242, 0.0237, 0.0141, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0062, 0.0005, 0.0019, 0.0057, 0.0029, 0.0423, 0.0660, 0.0695, 0.4121,\n",
      "         0.0515, 0.1994, 0.0321, 0.0517, 0.0433, 0.0150, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0098, 0.0004, 0.0018, 0.0034, 0.0016, 0.0381, 0.0964, 0.0974, 0.3783,\n",
      "         0.0235, 0.1468, 0.0606, 0.1018, 0.0323, 0.0079, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0086, 0.0007, 0.0044, 0.0052, 0.0028, 0.0510, 0.0974, 0.0900, 0.3951,\n",
      "         0.0198, 0.1398, 0.0531, 0.0904, 0.0363, 0.0054, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0093, 0.0002, 0.0011, 0.0014, 0.0007, 0.0156, 0.0452, 0.0491, 0.5724,\n",
      "         0.0092, 0.1269, 0.0281, 0.0987, 0.0367, 0.0054, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0056, 0.0003, 0.0009, 0.0012, 0.0006, 0.0053, 0.0090, 0.0120, 0.4274,\n",
      "         0.0065, 0.1070, 0.0255, 0.2755, 0.1133, 0.0100, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0028, 0.0002, 0.0005, 0.0006, 0.0004, 0.0028, 0.0045, 0.0063, 0.1668,\n",
      "         0.0056, 0.1031, 0.0451, 0.4522, 0.1895, 0.0195, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0027, 0.0004, 0.0006, 0.0007, 0.0005, 0.0015, 0.0014, 0.0041, 0.2915,\n",
      "         0.0076, 0.0855, 0.0122, 0.2474, 0.3173, 0.0268, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0068, 0.0006, 0.0011, 0.0012, 0.0008, 0.0024, 0.0025, 0.0050, 0.2940,\n",
      "         0.0074, 0.0838, 0.0133, 0.2430, 0.2782, 0.0599, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0110, 0.0019, 0.0030, 0.0029, 0.0023, 0.0052, 0.0039, 0.0065, 0.2731,\n",
      "         0.0138, 0.0824, 0.0138, 0.1535, 0.3441, 0.0823, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0312, 0.0035, 0.0061, 0.0068, 0.0046, 0.0167, 0.0172, 0.0163, 0.2283,\n",
      "         0.0118, 0.1197, 0.0254, 0.1687, 0.1447, 0.1989, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0128, 0.0087, 0.0291, 0.0132, 0.0108, 0.0338, 0.0268, 0.0253, 0.1930,\n",
      "         0.0166, 0.0803, 0.0211, 0.1485, 0.2830, 0.0971, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0081, 0.0071, 0.0239, 0.0138, 0.0126, 0.0356, 0.0278, 0.0311, 0.1708,\n",
      "         0.0227, 0.0781, 0.0237, 0.1691, 0.2568, 0.1188, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0214, 0.0068, 0.0164, 0.0182, 0.0109, 0.0315, 0.0252, 0.0249, 0.2183,\n",
      "         0.0178, 0.0544, 0.0216, 0.2454, 0.1890, 0.0981, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 2.60, Train Loss: 0.00, Val Loss: 5.32, Train BLEU: 0.00, Val BLEU: 4.76, Minutes Elapsed: 241.78\n",
      "Sampling from val predictions...\n",
      "Source: 有趣 的 是 得来 <UNK> 飞车 杀死 的 人 更多 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: funny thing is , the <UNK> are killing more people than the <UNK> . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> the , the is is &apos;s is . . <EOS> . <EOS> . . <EOS> <EOS> . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9917, 0.0079, 0.0003, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.9394, 0.0525, 0.0063, 0.0001, 0.0000, 0.0001, 0.0001, 0.0001, 0.0005,\n",
      "         0.0005, 0.0003, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.6574, 0.1604, 0.0928, 0.0047, 0.0020, 0.0045, 0.0063, 0.0065, 0.0177,\n",
      "         0.0262, 0.0215, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1824, 0.0627, 0.2365, 0.0542, 0.0294, 0.0388, 0.0582, 0.0202, 0.1075,\n",
      "         0.1683, 0.0417, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0133, 0.0060, 0.0569, 0.0517, 0.0791, 0.0943, 0.1953, 0.0415, 0.1908,\n",
      "         0.2443, 0.0268, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0089, 0.0033, 0.0207, 0.0320, 0.0679, 0.1029, 0.2304, 0.0590, 0.1736,\n",
      "         0.2799, 0.0214, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0238, 0.0134, 0.0855, 0.0670, 0.0759, 0.0974, 0.1672, 0.0578, 0.1471,\n",
      "         0.2407, 0.0243, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0012, 0.0008, 0.0198, 0.0143, 0.0678, 0.1414, 0.3725, 0.0571, 0.1449,\n",
      "         0.1650, 0.0152, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0011, 0.0005, 0.0046, 0.0017, 0.0120, 0.0632, 0.3485, 0.0670, 0.1763,\n",
      "         0.2914, 0.0336, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0036, 0.0008, 0.0023, 0.0051, 0.0258, 0.1065, 0.2473, 0.1036, 0.1400,\n",
      "         0.3215, 0.0435, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0163, 0.0054, 0.0122, 0.0158, 0.0459, 0.1167, 0.2782, 0.0649, 0.1326,\n",
      "         0.1968, 0.1152, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0151, 0.0054, 0.0102, 0.0226, 0.0648, 0.1269, 0.2708, 0.0560, 0.1310,\n",
      "         0.1780, 0.1191, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0316, 0.0074, 0.0156, 0.0144, 0.0317, 0.0860, 0.2095, 0.0559, 0.1445,\n",
      "         0.2281, 0.1753, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0163, 0.0054, 0.0113, 0.0210, 0.0544, 0.1147, 0.2618, 0.0540, 0.1332,\n",
      "         0.1949, 0.1329, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0056, 0.0029, 0.0101, 0.0218, 0.0818, 0.1544, 0.3635, 0.0360, 0.1185,\n",
      "         0.1156, 0.0898, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0233, 0.0095, 0.0235, 0.0166, 0.0452, 0.0989, 0.2678, 0.0462, 0.1343,\n",
      "         0.1578, 0.1769, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0096, 0.0058, 0.0155, 0.0105, 0.0234, 0.0637, 0.2051, 0.0858, 0.1867,\n",
      "         0.2876, 0.1065, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0095, 0.0047, 0.0122, 0.0109, 0.0263, 0.0777, 0.2105, 0.0913, 0.1752,\n",
      "         0.2619, 0.1198, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0251, 0.0088, 0.0215, 0.0066, 0.0159, 0.0594, 0.2013, 0.0677, 0.1438,\n",
      "         0.2203, 0.2297, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 2.66, Train Loss: 0.00, Val Loss: 5.35, Train BLEU: 0.00, Val BLEU: 4.69, Minutes Elapsed: 246.94\n",
      "Sampling from val predictions...\n",
      "Source: 我 想 介绍 给 你们 认识 我 的 两个 兄弟 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: now i &apos;d like to introduce you to my brothers . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> i want i to to show you two two my . <EOS> <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9636, 0.0361, 0.0002, 0.0001, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0490, 0.9464, 0.0038, 0.0005, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0373, 0.8549, 0.0631, 0.0218, 0.0190, 0.0010, 0.0009, 0.0004, 0.0002,\n",
      "         0.0005, 0.0009, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0508, 0.6899, 0.1136, 0.0585, 0.0759, 0.0045, 0.0026, 0.0009, 0.0005,\n",
      "         0.0012, 0.0016, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0043, 0.0535, 0.2071, 0.2726, 0.3876, 0.0479, 0.0110, 0.0029, 0.0034,\n",
      "         0.0068, 0.0029, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0037, 0.0241, 0.1404, 0.2134, 0.4638, 0.0983, 0.0268, 0.0046, 0.0060,\n",
      "         0.0141, 0.0048, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0011, 0.0050, 0.0288, 0.0751, 0.5541, 0.1330, 0.1341, 0.0159, 0.0140,\n",
      "         0.0320, 0.0070, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0009, 0.0021, 0.0113, 0.0153, 0.1816, 0.1668, 0.4054, 0.0601, 0.0573,\n",
      "         0.0895, 0.0098, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0007, 0.0012, 0.0021, 0.0035, 0.0320, 0.0388, 0.3600, 0.0961, 0.1379,\n",
      "         0.3063, 0.0216, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0002, 0.0004, 0.0018, 0.0018, 0.0152, 0.0211, 0.4428, 0.0966, 0.1434,\n",
      "         0.2666, 0.0103, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0007, 0.0009, 0.0023, 0.0029, 0.0212, 0.0262, 0.3295, 0.0794, 0.1472,\n",
      "         0.3616, 0.0281, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0059, 0.0037, 0.0045, 0.0088, 0.0280, 0.0241, 0.2643, 0.0511, 0.0948,\n",
      "         0.4331, 0.0818, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0111, 0.0116, 0.0093, 0.0118, 0.0628, 0.0249, 0.2213, 0.0307, 0.0474,\n",
      "         0.4240, 0.1451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0036, 0.0112, 0.0059, 0.0091, 0.0604, 0.0309, 0.3134, 0.0597, 0.0668,\n",
      "         0.3115, 0.1275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0056, 0.0130, 0.0069, 0.0111, 0.0525, 0.0310, 0.2191, 0.0467, 0.0672,\n",
      "         0.3646, 0.1823, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0203, 0.0272, 0.0086, 0.0228, 0.1361, 0.0265, 0.1844, 0.0251, 0.0341,\n",
      "         0.2887, 0.2263, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0211, 0.0341, 0.0118, 0.0217, 0.1750, 0.0233, 0.2353, 0.0245, 0.0229,\n",
      "         0.2110, 0.2193, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0273, 0.0409, 0.0133, 0.0242, 0.2017, 0.0237, 0.2426, 0.0220, 0.0197,\n",
      "         0.1821, 0.2025, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0321, 0.0459, 0.0142, 0.0265, 0.2123, 0.0247, 0.2354, 0.0205, 0.0184,\n",
      "         0.1680, 0.2020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2.71, Train Loss: 0.00, Val Loss: 5.32, Train BLEU: 0.00, Val BLEU: 4.54, Minutes Elapsed: 252.09\n",
      "Sampling from val predictions...\n",
      "Source: 我 11 岁 那年 记得 得有 一天 早晨 醒来 听见 家里 有 愉悦 的 声音 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: when i was 11 , i remember waking up one morning to the sound of joy in my house\n",
      "Model: <SOS> i i was in , , i a a a a a <EOS> . . <EOS> . <EOS> .\n",
      "Attention Weights: tensor([[0.9430, 0.0273, 0.0252, 0.0013, 0.0030, 0.0001, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0888, 0.2131, 0.6465, 0.0297, 0.0170, 0.0012, 0.0021, 0.0007, 0.0003,\n",
      "         0.0001, 0.0001, 0.0001, 0.0001, 0.0000, 0.0001, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0753, 0.1122, 0.6764, 0.0544, 0.0511, 0.0052, 0.0123, 0.0043, 0.0022,\n",
      "         0.0014, 0.0009, 0.0008, 0.0007, 0.0004, 0.0008, 0.0017, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0543, 0.0586, 0.6305, 0.1031, 0.0793, 0.0118, 0.0306, 0.0107, 0.0051,\n",
      "         0.0036, 0.0020, 0.0015, 0.0021, 0.0009, 0.0025, 0.0035, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0056, 0.0341, 0.2619, 0.1279, 0.1778, 0.0563, 0.1443, 0.0874, 0.0227,\n",
      "         0.0208, 0.0126, 0.0052, 0.0143, 0.0031, 0.0173, 0.0086, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0393, 0.0800, 0.3037, 0.0772, 0.1264, 0.0410, 0.1414, 0.1093, 0.0298,\n",
      "         0.0154, 0.0077, 0.0036, 0.0064, 0.0021, 0.0055, 0.0111, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0154, 0.0306, 0.1129, 0.0313, 0.1104, 0.0475, 0.2599, 0.2223, 0.0876,\n",
      "         0.0398, 0.0179, 0.0040, 0.0071, 0.0011, 0.0050, 0.0072, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0069, 0.0068, 0.0334, 0.0176, 0.0785, 0.0410, 0.2428, 0.2533, 0.1855,\n",
      "         0.0863, 0.0253, 0.0055, 0.0070, 0.0012, 0.0072, 0.0020, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0004, 0.0007, 0.0075, 0.0083, 0.0230, 0.0321, 0.1826, 0.2420, 0.1425,\n",
      "         0.1756, 0.0817, 0.0123, 0.0500, 0.0049, 0.0320, 0.0042, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0005, 0.0012, 0.0085, 0.0064, 0.0190, 0.0230, 0.1255, 0.1804, 0.1980,\n",
      "         0.1762, 0.1352, 0.0327, 0.0529, 0.0074, 0.0232, 0.0099, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0007, 0.0012, 0.0034, 0.0021, 0.0079, 0.0063, 0.0392, 0.0682, 0.1367,\n",
      "         0.1790, 0.2677, 0.0984, 0.1205, 0.0156, 0.0390, 0.0140, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0009, 0.0012, 0.0035, 0.0024, 0.0069, 0.0056, 0.0272, 0.0408, 0.0768,\n",
      "         0.1238, 0.3217, 0.1363, 0.1685, 0.0232, 0.0463, 0.0151, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0022, 0.0026, 0.0051, 0.0026, 0.0094, 0.0056, 0.0247, 0.0319, 0.0587,\n",
      "         0.1051, 0.3506, 0.1470, 0.1761, 0.0206, 0.0431, 0.0147, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0037, 0.0045, 0.0083, 0.0044, 0.0161, 0.0074, 0.0229, 0.0231, 0.0406,\n",
      "         0.0904, 0.3706, 0.1372, 0.1878, 0.0217, 0.0447, 0.0166, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0011, 0.0011, 0.0034, 0.0023, 0.0040, 0.0050, 0.0125, 0.0140, 0.0140,\n",
      "         0.0413, 0.2562, 0.1691, 0.3281, 0.0499, 0.0773, 0.0208, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0157, 0.0165, 0.0215, 0.0092, 0.0216, 0.0153, 0.0523, 0.0573, 0.0780,\n",
      "         0.0854, 0.2471, 0.0896, 0.1962, 0.0241, 0.0331, 0.0371, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0210, 0.0236, 0.0397, 0.0160, 0.0528, 0.0268, 0.0673, 0.0507, 0.0676,\n",
      "         0.0842, 0.2437, 0.0608, 0.1368, 0.0179, 0.0346, 0.0564, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0459, 0.0473, 0.0616, 0.0231, 0.0529, 0.0308, 0.0693, 0.0611, 0.0644,\n",
      "         0.0552, 0.1268, 0.0458, 0.1341, 0.0204, 0.0379, 0.1234, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0217, 0.0257, 0.0484, 0.0225, 0.0639, 0.0377, 0.0778, 0.0562, 0.0746,\n",
      "         0.0794, 0.1569, 0.0486, 0.0966, 0.0194, 0.0406, 0.1299, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 2.77, Train Loss: 0.00, Val Loss: 5.42, Train BLEU: 0.00, Val BLEU: 4.84, Minutes Elapsed: 257.25\n",
      "Sampling from val predictions...\n",
      "Source: 有趣 的 是 得来 <UNK> 飞车 杀死 的 人 更多 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: funny thing is , the <UNK> are killing more people than the <UNK> . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> the &apos;s the the . &apos;s of . . <EOS> . <EOS> . . <EOS> <EOS> . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9847, 0.0141, 0.0010, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.9008, 0.0711, 0.0230, 0.0002, 0.0001, 0.0002, 0.0003, 0.0003, 0.0015,\n",
      "         0.0020, 0.0006, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.3971, 0.1076, 0.1248, 0.0225, 0.0134, 0.0233, 0.0287, 0.0282, 0.0746,\n",
      "         0.1273, 0.0524, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0481, 0.0239, 0.1058, 0.0471, 0.0511, 0.0795, 0.1249, 0.0450, 0.1667,\n",
      "         0.2729, 0.0352, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0079, 0.0028, 0.0233, 0.0127, 0.0280, 0.0910, 0.1937, 0.0467, 0.1837,\n",
      "         0.3774, 0.0327, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0082, 0.0020, 0.0102, 0.0181, 0.0537, 0.1527, 0.2433, 0.0468, 0.1413,\n",
      "         0.2998, 0.0239, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0049, 0.0026, 0.0221, 0.0180, 0.0436, 0.1122, 0.2437, 0.0685, 0.1495,\n",
      "         0.3065, 0.0284, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0011, 0.0008, 0.0144, 0.0070, 0.0360, 0.1637, 0.4649, 0.0487, 0.1251,\n",
      "         0.1297, 0.0086, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0019, 0.0008, 0.0036, 0.0014, 0.0057, 0.0531, 0.3067, 0.0898, 0.1920,\n",
      "         0.3243, 0.0207, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0070, 0.0013, 0.0024, 0.0033, 0.0094, 0.0703, 0.1918, 0.0746, 0.1949,\n",
      "         0.4263, 0.0186, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0224, 0.0050, 0.0086, 0.0072, 0.0138, 0.0705, 0.2349, 0.0671, 0.1896,\n",
      "         0.3309, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0230, 0.0056, 0.0082, 0.0106, 0.0226, 0.0794, 0.2277, 0.0606, 0.1912,\n",
      "         0.3114, 0.0597, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0432, 0.0086, 0.0136, 0.0076, 0.0114, 0.0525, 0.1511, 0.0642, 0.1755,\n",
      "         0.3753, 0.0970, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0185, 0.0049, 0.0075, 0.0120, 0.0266, 0.0874, 0.2343, 0.0588, 0.1768,\n",
      "         0.2856, 0.0876, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0068, 0.0037, 0.0096, 0.0130, 0.0449, 0.1320, 0.3745, 0.0446, 0.1619,\n",
      "         0.1572, 0.0517, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0308, 0.0093, 0.0215, 0.0101, 0.0192, 0.0747, 0.2212, 0.0615, 0.1796,\n",
      "         0.2681, 0.1039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0067, 0.0023, 0.0068, 0.0035, 0.0069, 0.0361, 0.1378, 0.0837, 0.1910,\n",
      "         0.4531, 0.0720, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0060, 0.0021, 0.0058, 0.0028, 0.0068, 0.0421, 0.1436, 0.0810, 0.1990,\n",
      "         0.4238, 0.0869, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0212, 0.0050, 0.0109, 0.0028, 0.0052, 0.0372, 0.1420, 0.0665, 0.1759,\n",
      "         0.3710, 0.1623, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 2.82, Train Loss: 0.00, Val Loss: 5.32, Train BLEU: 0.00, Val BLEU: 4.47, Minutes Elapsed: 262.40\n",
      "Sampling from val predictions...\n",
      "Source: 当时 我 在 一家 意大利 大利 非政府 政府 组织 织工 工作 我们 在 非洲 建立 的 每 一个 项目 都\n",
      "Reference: i worked for an italian ngo , and every single project that we set up in africa failed .\n",
      "Model: <SOS> i i a to to in , and we have of of the . . <EOS> <EOS> . <EOS>\n",
      "Attention Weights: tensor([[6.4788e-01, 3.4953e-01, 2.2610e-04, 4.6183e-04, 5.1767e-05, 4.7013e-05,\n",
      "         3.9644e-05, 9.9603e-04, 1.5141e-04, 1.9766e-05, 4.2351e-04, 9.9376e-05,\n",
      "         1.7326e-06, 1.8788e-05, 2.6801e-06, 3.3375e-06, 3.5125e-05, 3.7912e-06,\n",
      "         6.5597e-06, 4.2731e-06],\n",
      "        [1.9518e-01, 7.6314e-01, 1.3381e-02, 1.6512e-02, 1.5045e-03, 7.0097e-04,\n",
      "         5.9242e-04, 6.3748e-03, 1.1325e-03, 9.9245e-05, 9.8510e-04, 2.6560e-04,\n",
      "         1.0978e-05, 4.5324e-05, 1.0552e-05, 8.7196e-06, 3.4210e-05, 7.0046e-06,\n",
      "         1.0632e-05, 3.1041e-06],\n",
      "        [6.0968e-02, 5.8014e-01, 6.5202e-02, 1.2279e-01, 3.3287e-02, 1.3133e-02,\n",
      "         1.0216e-02, 6.5480e-02, 2.4835e-02, 2.2273e-03, 1.2024e-02, 6.3362e-03,\n",
      "         4.2544e-04, 9.5648e-04, 2.5741e-04, 3.4512e-04, 7.0934e-04, 2.7535e-04,\n",
      "         2.7147e-04, 1.1298e-04],\n",
      "        [7.2407e-03, 2.5657e-02, 1.3414e-02, 2.9276e-01, 1.4925e-01, 4.5102e-02,\n",
      "         3.2350e-02, 1.2271e-01, 6.5109e-02, 2.2787e-02, 9.7364e-02, 2.2584e-02,\n",
      "         5.8067e-03, 3.7949e-02, 5.0646e-03, 5.8442e-03, 2.3918e-02, 1.6685e-02,\n",
      "         7.6264e-03, 7.8351e-04],\n",
      "        [3.5351e-03, 9.4771e-03, 2.8701e-03, 4.4284e-02, 4.7523e-02, 1.8555e-02,\n",
      "         2.2397e-02, 1.5180e-01, 1.0124e-01, 2.3538e-02, 2.4384e-01, 1.6394e-01,\n",
      "         1.0479e-02, 4.9938e-02, 8.5254e-03, 1.6158e-02, 4.8898e-02, 2.1230e-02,\n",
      "         9.7468e-03, 2.0288e-03],\n",
      "        [3.7607e-03, 8.2194e-03, 1.5095e-03, 8.0492e-03, 2.7589e-02, 1.9318e-02,\n",
      "         2.6999e-02, 1.2626e-01, 1.1491e-01, 2.0270e-02, 1.7123e-01, 3.5211e-01,\n",
      "         1.3276e-02, 5.0341e-02, 7.6550e-03, 1.0600e-02, 2.6828e-02, 5.7169e-03,\n",
      "         3.9334e-03, 1.4232e-03],\n",
      "        [4.9681e-03, 1.4539e-02, 1.6572e-03, 7.2095e-03, 2.6576e-02, 1.7764e-02,\n",
      "         2.3520e-02, 1.4442e-01, 1.2520e-01, 1.5989e-02, 1.5654e-01, 3.6939e-01,\n",
      "         1.1211e-02, 4.5166e-02, 6.1846e-03, 6.6004e-03, 1.5640e-02, 3.1597e-03,\n",
      "         3.2612e-03, 1.0067e-03],\n",
      "        [1.2172e-03, 6.7084e-03, 1.2261e-03, 4.5896e-03, 1.2016e-02, 4.3388e-03,\n",
      "         7.1732e-03, 2.9447e-02, 4.0811e-02, 6.5273e-03, 3.3420e-02, 5.9136e-01,\n",
      "         1.8082e-02, 1.9738e-01, 1.2865e-02, 4.6780e-03, 1.6320e-02, 4.9805e-03,\n",
      "         5.0860e-03, 1.7744e-03],\n",
      "        [5.1135e-04, 3.1624e-03, 9.9760e-04, 2.1009e-03, 2.5233e-03, 6.5750e-04,\n",
      "         1.2290e-03, 4.8512e-03, 8.0922e-03, 2.0163e-03, 7.6282e-03, 2.8582e-01,\n",
      "         2.7260e-02, 5.1766e-01, 3.1350e-02, 8.6275e-03, 4.0774e-02, 2.5701e-02,\n",
      "         2.4365e-02, 4.6755e-03],\n",
      "        [4.3087e-04, 2.0700e-03, 6.3546e-04, 1.0136e-03, 1.2248e-03, 3.6660e-04,\n",
      "         6.9315e-04, 3.9423e-03, 7.5556e-03, 2.6486e-03, 9.5016e-03, 1.6709e-01,\n",
      "         2.4564e-02, 4.2907e-01, 5.2070e-02, 1.9933e-02, 1.0488e-01, 9.3420e-02,\n",
      "         7.0334e-02, 8.5629e-03],\n",
      "        [4.4179e-04, 1.8803e-03, 4.8050e-04, 6.5265e-04, 6.9615e-04, 2.7441e-04,\n",
      "         5.1616e-04, 2.8686e-03, 5.1442e-03, 2.4766e-03, 9.5493e-03, 1.2072e-01,\n",
      "         2.5071e-02, 2.4705e-01, 6.7568e-02, 4.1898e-02, 1.6346e-01, 1.6833e-01,\n",
      "         1.2273e-01, 1.8194e-02],\n",
      "        [9.5982e-05, 9.1567e-04, 1.6469e-04, 4.0748e-04, 5.7207e-04, 2.0761e-04,\n",
      "         3.6896e-04, 2.0585e-03, 2.6529e-03, 1.2818e-03, 4.7925e-03, 7.0993e-02,\n",
      "         9.2251e-03, 3.5285e-01, 5.6951e-02, 1.8254e-02, 8.4566e-02, 1.0934e-01,\n",
      "         1.5498e-01, 1.2932e-01],\n",
      "        [1.4806e-04, 1.2684e-03, 3.2120e-04, 7.6405e-04, 7.7811e-04, 2.7929e-04,\n",
      "         4.7340e-04, 2.1867e-03, 2.1904e-03, 1.2987e-03, 4.5752e-03, 3.8892e-02,\n",
      "         7.1317e-03, 3.5110e-01, 3.6619e-02, 1.0387e-02, 5.3467e-02, 8.9528e-02,\n",
      "         1.1958e-01, 2.7901e-01],\n",
      "        [4.3614e-04, 5.1477e-03, 1.0681e-03, 2.9516e-03, 1.6694e-03, 4.1253e-04,\n",
      "         6.3692e-04, 2.7612e-03, 2.4940e-03, 1.5597e-03, 7.0529e-03, 1.1810e-01,\n",
      "         1.7554e-02, 3.8094e-01, 3.3887e-02, 1.6507e-02, 4.9481e-02, 7.0401e-02,\n",
      "         4.9895e-02, 2.3705e-01],\n",
      "        [1.3356e-03, 9.9702e-03, 3.0254e-03, 6.6379e-03, 3.8837e-03, 9.9355e-04,\n",
      "         1.2580e-03, 5.4481e-03, 4.6656e-03, 3.6897e-03, 1.4811e-02, 9.5828e-02,\n",
      "         3.0076e-02, 3.4031e-01, 4.5903e-02, 3.1845e-02, 8.6094e-02, 1.3311e-01,\n",
      "         8.5313e-02, 9.5802e-02],\n",
      "        [3.3567e-03, 9.5917e-03, 3.6917e-03, 8.9877e-03, 3.2894e-03, 1.2759e-03,\n",
      "         1.5336e-03, 4.9464e-03, 3.9738e-03, 4.4220e-03, 1.3450e-02, 2.8178e-02,\n",
      "         2.1045e-02, 3.3075e-01, 3.5889e-02, 4.2801e-02, 1.1733e-01, 2.3496e-01,\n",
      "         7.8689e-02, 5.1829e-02],\n",
      "        [1.0135e-02, 1.7382e-02, 5.1850e-03, 1.7132e-02, 8.4195e-03, 2.6742e-03,\n",
      "         4.2298e-03, 1.8110e-02, 9.2949e-03, 8.2391e-03, 3.2871e-02, 4.8345e-02,\n",
      "         2.0314e-02, 5.1576e-01, 5.3942e-02, 2.4002e-02, 6.3417e-02, 5.7673e-02,\n",
      "         5.0125e-02, 3.2753e-02],\n",
      "        [1.5999e-02, 2.6644e-02, 1.0846e-02, 3.4118e-02, 1.3567e-02, 3.4212e-03,\n",
      "         5.3794e-03, 2.0660e-02, 1.2240e-02, 9.9528e-03, 3.5728e-02, 5.6796e-02,\n",
      "         2.8302e-02, 4.4930e-01, 5.8742e-02, 2.3776e-02, 6.1096e-02, 5.9893e-02,\n",
      "         5.0407e-02, 2.3140e-02],\n",
      "        [2.4368e-02, 3.7781e-02, 1.0416e-02, 2.3003e-02, 2.9362e-02, 1.7193e-02,\n",
      "         2.8139e-02, 8.8576e-02, 5.3135e-02, 3.0088e-02, 9.0819e-02, 6.7586e-02,\n",
      "         3.2806e-02, 2.5685e-01, 6.0455e-02, 2.0786e-02, 4.4250e-02, 1.6700e-02,\n",
      "         3.5541e-02, 3.2144e-02]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2.88, Train Loss: 0.00, Val Loss: 5.34, Train BLEU: 0.00, Val BLEU: 4.27, Minutes Elapsed: 267.54\n",
      "Sampling from val predictions...\n",
      "Source: 没有 有人 会 拒绝 幸运 的 是 也 没有 有人 拿 着 我们 的 相机 <UNK> <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: no one &apos;s ever refused , and luckily no one &apos;s ever run off with our camera . <EOS>\n",
      "Model: <SOS> no you , , to to , the &apos;s they the the . . <EOS> <EOS> . . <EOS>\n",
      "Attention Weights: tensor([[0.8476, 0.1496, 0.0027, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0878, 0.7132, 0.1493, 0.0202, 0.0254, 0.0005, 0.0006, 0.0005, 0.0009,\n",
      "         0.0008, 0.0001, 0.0001, 0.0003, 0.0000, 0.0001, 0.0001, 0.0002, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0699, 0.3023, 0.1754, 0.1595, 0.1443, 0.0104, 0.0140, 0.0161, 0.0367,\n",
      "         0.0281, 0.0031, 0.0024, 0.0085, 0.0013, 0.0024, 0.0061, 0.0195, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0326, 0.2353, 0.2202, 0.1614, 0.2525, 0.0053, 0.0114, 0.0140, 0.0227,\n",
      "         0.0188, 0.0024, 0.0017, 0.0061, 0.0006, 0.0015, 0.0031, 0.0103, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0131, 0.0698, 0.0988, 0.1905, 0.4609, 0.0094, 0.0209, 0.0284, 0.0421,\n",
      "         0.0292, 0.0036, 0.0027, 0.0094, 0.0013, 0.0028, 0.0047, 0.0123, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0045, 0.0344, 0.0442, 0.1459, 0.5194, 0.0094, 0.0219, 0.0602, 0.0554,\n",
      "         0.0444, 0.0079, 0.0049, 0.0152, 0.0022, 0.0048, 0.0077, 0.0175, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0016, 0.0155, 0.0198, 0.1070, 0.6106, 0.0126, 0.0247, 0.0515, 0.0658,\n",
      "         0.0428, 0.0058, 0.0034, 0.0110, 0.0018, 0.0038, 0.0062, 0.0160, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0011, 0.0079, 0.0071, 0.0407, 0.4989, 0.0046, 0.0115, 0.0702, 0.1642,\n",
      "         0.1119, 0.0141, 0.0069, 0.0303, 0.0028, 0.0051, 0.0063, 0.0162, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0014, 0.0064, 0.0059, 0.0360, 0.2254, 0.0024, 0.0071, 0.0507, 0.3456,\n",
      "         0.2553, 0.0090, 0.0054, 0.0339, 0.0023, 0.0056, 0.0043, 0.0033, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0011, 0.0038, 0.0038, 0.0165, 0.0669, 0.0027, 0.0091, 0.0594, 0.4122,\n",
      "         0.2847, 0.0258, 0.0189, 0.0637, 0.0065, 0.0138, 0.0076, 0.0037, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0004, 0.0024, 0.0018, 0.0029, 0.0304, 0.0008, 0.0027, 0.0159, 0.1021,\n",
      "         0.2269, 0.0509, 0.0498, 0.4118, 0.0171, 0.0524, 0.0226, 0.0092, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0002, 0.0011, 0.0008, 0.0019, 0.0158, 0.0004, 0.0008, 0.0055, 0.0273,\n",
      "         0.0895, 0.0334, 0.0445, 0.5762, 0.0181, 0.0972, 0.0697, 0.0176, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0002, 0.0008, 0.0005, 0.0020, 0.0160, 0.0006, 0.0007, 0.0041, 0.0127,\n",
      "         0.0447, 0.0248, 0.0377, 0.5335, 0.0202, 0.1134, 0.1359, 0.0523, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0006, 0.0025, 0.0016, 0.0040, 0.0225, 0.0010, 0.0010, 0.0072, 0.0160,\n",
      "         0.0502, 0.0318, 0.0471, 0.4407, 0.0198, 0.1061, 0.1693, 0.0788, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0006, 0.0033, 0.0026, 0.0096, 0.0522, 0.0023, 0.0015, 0.0053, 0.0150,\n",
      "         0.0460, 0.0309, 0.0402, 0.4223, 0.0231, 0.0806, 0.1473, 0.1171, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0037, 0.0093, 0.0063, 0.0174, 0.0977, 0.0085, 0.0053, 0.0141, 0.0333,\n",
      "         0.0524, 0.0318, 0.0381, 0.2332, 0.0219, 0.0465, 0.1016, 0.2791, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0112, 0.0199, 0.0137, 0.0304, 0.1429, 0.0133, 0.0116, 0.0263, 0.0609,\n",
      "         0.0728, 0.0317, 0.0395, 0.1718, 0.0187, 0.0292, 0.0552, 0.2510, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0116, 0.0268, 0.0200, 0.0369, 0.1175, 0.0238, 0.0221, 0.0500, 0.0670,\n",
      "         0.0764, 0.0481, 0.0468, 0.1333, 0.0237, 0.0455, 0.0713, 0.1792, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0070, 0.0160, 0.0156, 0.0374, 0.0982, 0.0171, 0.0156, 0.0284, 0.0523,\n",
      "         0.0762, 0.0485, 0.0547, 0.1575, 0.0322, 0.0603, 0.0937, 0.1894, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 2.93, Train Loss: 0.00, Val Loss: 5.42, Train BLEU: 0.00, Val BLEU: 4.54, Minutes Elapsed: 272.66\n",
      "Sampling from val predictions...\n",
      "Source: 当 我 今天 站 在 这里 跟 你们 演讲 的 时候 这些 矿工 们 还 在 这样 的 矿井 里\n",
      "Reference: as i stand talking to you today , these men are still deep in that hole , risking their\n",
      "Model: <SOS> when i , you , this these these these these these these . . . . . <EOS> .\n",
      "Attention Weights: tensor([[1.0260e-02, 9.6750e-01, 1.7461e-02, 9.8214e-05, 6.8928e-05, 3.6749e-03,\n",
      "         3.9987e-04, 5.1372e-04, 2.7373e-06, 1.1629e-06, 1.0178e-05, 6.2070e-06,\n",
      "         1.3841e-06, 3.0092e-06, 4.8165e-07, 6.5374e-08, 8.2745e-07, 6.7237e-08,\n",
      "         2.6220e-07, 3.3995e-07],\n",
      "        [4.9487e-03, 4.4286e-01, 5.3439e-01, 7.3015e-03, 1.6419e-03, 5.7649e-03,\n",
      "         1.1877e-03, 1.5855e-03, 7.3335e-05, 2.5792e-05, 8.3430e-05, 6.1097e-05,\n",
      "         2.2214e-05, 2.9118e-05, 9.2469e-06, 2.5114e-06, 7.6871e-06, 1.4090e-06,\n",
      "         3.9967e-06, 1.6358e-06],\n",
      "        [5.8891e-03, 1.5468e-01, 4.7756e-01, 5.3684e-02, 2.4512e-02, 1.4710e-01,\n",
      "         4.2746e-02, 7.3750e-02, 1.0815e-02, 1.2749e-03, 4.0996e-03, 2.1284e-03,\n",
      "         5.6505e-04, 4.8489e-04, 2.6681e-04, 1.1222e-04, 1.7114e-04, 5.2921e-05,\n",
      "         6.4083e-05, 4.1581e-05],\n",
      "        [2.1495e-03, 3.9007e-02, 1.0844e-01, 2.0330e-02, 1.3936e-02, 2.6892e-01,\n",
      "         9.8053e-02, 2.9281e-01, 7.6831e-02, 4.9814e-03, 3.9698e-02, 2.7005e-02,\n",
      "         3.6867e-03, 2.5272e-03, 7.1183e-04, 1.7068e-04, 4.6618e-04, 7.7520e-05,\n",
      "         1.3220e-04, 6.6881e-05],\n",
      "        [1.0912e-04, 1.0599e-03, 1.3456e-02, 2.9340e-03, 1.6571e-03, 8.1402e-02,\n",
      "         1.3012e-02, 2.4758e-01, 3.0786e-01, 6.3227e-03, 8.0024e-02, 1.8246e-01,\n",
      "         4.6720e-02, 1.0222e-02, 1.1891e-03, 4.9052e-04, 2.5651e-03, 3.0155e-04,\n",
      "         5.6002e-04, 7.7576e-05],\n",
      "        [1.6018e-04, 1.0397e-03, 3.5197e-03, 1.1306e-03, 1.0825e-03, 4.2160e-02,\n",
      "         7.2208e-03, 8.4208e-02, 1.3284e-01, 1.1811e-02, 1.7295e-01, 3.1143e-01,\n",
      "         1.2682e-01, 7.9398e-02, 1.2876e-02, 2.1143e-03, 7.4103e-03, 4.1103e-04,\n",
      "         1.2245e-03, 1.9424e-04],\n",
      "        [1.3477e-04, 1.5136e-03, 3.8749e-03, 5.4601e-04, 6.5657e-04, 1.8034e-02,\n",
      "         2.6301e-03, 5.2277e-02, 6.2031e-02, 3.7375e-03, 8.5807e-02, 3.8938e-01,\n",
      "         1.4161e-01, 1.2512e-01, 5.7594e-02, 6.3163e-03, 4.3925e-02, 9.1156e-04,\n",
      "         3.5794e-03, 3.1357e-04],\n",
      "        [3.5314e-05, 2.9570e-04, 1.4691e-03, 2.2473e-04, 3.5386e-04, 6.6629e-03,\n",
      "         1.0585e-03, 1.4030e-02, 2.6795e-02, 2.6735e-03, 6.5464e-02, 3.0099e-01,\n",
      "         1.5294e-01, 1.1004e-01, 1.1628e-01, 2.3409e-02, 1.5122e-01, 5.2704e-03,\n",
      "         1.9248e-02, 1.5367e-03],\n",
      "        [1.3935e-05, 1.5959e-04, 1.1032e-03, 1.9122e-04, 2.7082e-04, 3.5439e-03,\n",
      "         5.7859e-04, 7.9297e-03, 3.4474e-02, 1.8319e-03, 3.3357e-02, 2.2001e-01,\n",
      "         1.1826e-01, 7.2650e-02, 1.1645e-01, 4.1336e-02, 2.8471e-01, 1.3730e-02,\n",
      "         4.6573e-02, 2.8220e-03],\n",
      "        [4.9881e-05, 4.7174e-04, 1.4365e-03, 1.7213e-04, 3.1510e-04, 4.3547e-03,\n",
      "         7.3558e-04, 6.0936e-03, 7.6374e-03, 9.7404e-04, 1.3745e-02, 9.3833e-02,\n",
      "         4.0530e-02, 6.7117e-02, 1.5822e-01, 3.2936e-02, 4.8426e-01, 1.4463e-02,\n",
      "         6.6530e-02, 6.1252e-03],\n",
      "        [1.2767e-05, 3.1775e-04, 1.0489e-03, 1.0737e-04, 1.7579e-04, 1.6290e-03,\n",
      "         5.1282e-04, 1.1524e-02, 6.7231e-03, 9.1849e-04, 1.6845e-02, 5.6833e-02,\n",
      "         2.9991e-02, 3.9852e-02, 1.0636e-01, 3.7311e-02, 5.1299e-01, 3.2678e-02,\n",
      "         1.3420e-01, 9.9664e-03],\n",
      "        [2.1242e-06, 6.5480e-05, 2.7855e-04, 1.7080e-05, 3.0993e-05, 5.0426e-04,\n",
      "         1.5076e-04, 2.7556e-03, 1.9216e-03, 1.5598e-04, 2.9047e-03, 1.1572e-02,\n",
      "         6.7718e-03, 5.3734e-03, 1.8957e-02, 1.0323e-02, 6.0834e-01, 4.5878e-02,\n",
      "         2.5870e-01, 2.5294e-02],\n",
      "        [8.8803e-06, 1.0206e-04, 3.6740e-04, 3.8324e-05, 8.3868e-05, 1.1982e-03,\n",
      "         2.5265e-04, 2.0311e-03, 2.0142e-03, 3.4710e-04, 3.9953e-03, 1.7778e-02,\n",
      "         7.7780e-03, 4.5831e-03, 1.6231e-02, 1.0510e-02, 5.5115e-01, 5.0367e-02,\n",
      "         2.8686e-01, 4.4306e-02],\n",
      "        [6.8201e-05, 5.0689e-04, 1.7707e-03, 2.4415e-04, 4.0852e-04, 2.5206e-03,\n",
      "         6.6821e-04, 3.6645e-03, 6.6121e-03, 8.0993e-04, 7.3877e-03, 3.8946e-02,\n",
      "         2.1411e-02, 5.8579e-03, 1.2754e-02, 1.2877e-02, 4.3420e-01, 5.9958e-02,\n",
      "         3.5413e-01, 3.5204e-02],\n",
      "        [3.9593e-04, 3.3487e-03, 1.0768e-02, 1.8133e-03, 2.2781e-03, 1.0909e-02,\n",
      "         2.8933e-03, 1.5015e-02, 3.3659e-02, 3.7557e-03, 2.3961e-02, 8.9519e-02,\n",
      "         6.1776e-02, 1.5826e-02, 2.6182e-02, 2.7372e-02, 3.0290e-01, 5.5975e-02,\n",
      "         2.8053e-01, 3.1130e-02],\n",
      "        [3.2829e-03, 1.5337e-02, 4.2257e-02, 5.8268e-03, 8.4159e-03, 3.7113e-02,\n",
      "         8.2373e-03, 2.8827e-02, 4.9979e-02, 7.2010e-03, 4.8050e-02, 1.0807e-01,\n",
      "         7.5749e-02, 3.5630e-02, 4.5341e-02, 2.6478e-02, 2.5261e-01, 3.1470e-02,\n",
      "         1.3992e-01, 3.0210e-02],\n",
      "        [9.1830e-03, 3.6515e-02, 5.7701e-02, 1.1274e-02, 1.2004e-02, 8.7198e-02,\n",
      "         1.5284e-02, 2.6546e-02, 2.7613e-02, 7.1624e-03, 6.6064e-02, 1.0191e-01,\n",
      "         9.6962e-02, 5.3674e-02, 4.7441e-02, 2.0070e-02, 1.4574e-01, 2.3705e-02,\n",
      "         1.2202e-01, 3.1932e-02],\n",
      "        [2.3533e-03, 1.8515e-02, 5.0786e-02, 6.4814e-03, 5.1674e-03, 3.4155e-02,\n",
      "         1.0053e-02, 4.3036e-02, 8.7704e-02, 8.4554e-03, 6.2209e-02, 8.6825e-02,\n",
      "         9.5937e-02, 5.0279e-02, 5.6101e-02, 3.6776e-02, 1.2577e-01, 3.0200e-02,\n",
      "         1.6162e-01, 2.7581e-02],\n",
      "        [2.3631e-03, 2.1858e-02, 5.6867e-02, 5.0833e-03, 5.9886e-03, 5.0019e-02,\n",
      "         1.1083e-02, 5.3726e-02, 8.8116e-02, 8.9471e-03, 6.3979e-02, 1.0396e-01,\n",
      "         7.9629e-02, 5.2269e-02, 6.2948e-02, 4.0817e-02, 1.4318e-01, 2.7619e-02,\n",
      "         9.3685e-02, 2.7860e-02]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2.99, Train Loss: 0.00, Val Loss: 5.31, Train BLEU: 0.00, Val BLEU: 4.49, Minutes Elapsed: 277.80\n",
      "Sampling from val predictions...\n",
      "Source: 但是 言语 语词 词汇 对于 政治 中心 之 作用 是非 非常 重要 的 并且 所有 的 政客 都 明白 他们\n",
      "Reference: but it &apos;s very important that words are at the center of politics , and all politicians know they\n",
      "Model: <SOS> but the , &apos;t a , , do the , , of , , they they are them <EOS>\n",
      "Attention Weights: tensor([[0.0654, 0.0282, 0.0016, 0.0446, 0.6808, 0.0158, 0.0752, 0.0246, 0.0424,\n",
      "         0.0061, 0.0018, 0.0043, 0.0002, 0.0004, 0.0017, 0.0000, 0.0033, 0.0001,\n",
      "         0.0035, 0.0000],\n",
      "        [0.0224, 0.1594, 0.0105, 0.1341, 0.3217, 0.1137, 0.1698, 0.0187, 0.0273,\n",
      "         0.0034, 0.0020, 0.0061, 0.0002, 0.0009, 0.0030, 0.0001, 0.0059, 0.0001,\n",
      "         0.0006, 0.0001],\n",
      "        [0.0067, 0.0150, 0.0057, 0.0579, 0.2705, 0.1665, 0.2183, 0.0488, 0.0647,\n",
      "         0.0263, 0.0298, 0.0419, 0.0025, 0.0094, 0.0160, 0.0013, 0.0165, 0.0004,\n",
      "         0.0016, 0.0003],\n",
      "        [0.0027, 0.0084, 0.0050, 0.0322, 0.1862, 0.1259, 0.1508, 0.0627, 0.0978,\n",
      "         0.0612, 0.0986, 0.0808, 0.0059, 0.0237, 0.0305, 0.0028, 0.0205, 0.0008,\n",
      "         0.0029, 0.0006],\n",
      "        [0.0008, 0.0037, 0.0030, 0.0078, 0.0533, 0.0895, 0.0624, 0.0205, 0.0331,\n",
      "         0.0406, 0.2663, 0.1918, 0.0087, 0.0487, 0.1121, 0.0070, 0.0454, 0.0010,\n",
      "         0.0036, 0.0008],\n",
      "        [0.0009, 0.0031, 0.0028, 0.0077, 0.0346, 0.1144, 0.1080, 0.0177, 0.0238,\n",
      "         0.0239, 0.1382, 0.1446, 0.0119, 0.0736, 0.1580, 0.0072, 0.1216, 0.0016,\n",
      "         0.0057, 0.0008],\n",
      "        [0.0006, 0.0021, 0.0020, 0.0039, 0.0146, 0.1211, 0.1079, 0.0072, 0.0100,\n",
      "         0.0118, 0.0735, 0.1101, 0.0099, 0.0957, 0.2234, 0.0088, 0.1818, 0.0026,\n",
      "         0.0104, 0.0027],\n",
      "        [0.0006, 0.0009, 0.0010, 0.0019, 0.0116, 0.1785, 0.1350, 0.0052, 0.0071,\n",
      "         0.0110, 0.0303, 0.0528, 0.0033, 0.0917, 0.2373, 0.0054, 0.1883, 0.0060,\n",
      "         0.0238, 0.0084],\n",
      "        [0.0007, 0.0022, 0.0019, 0.0029, 0.0138, 0.1112, 0.0644, 0.0048, 0.0118,\n",
      "         0.0247, 0.0780, 0.0768, 0.0039, 0.0889, 0.2144, 0.0090, 0.1904, 0.0083,\n",
      "         0.0591, 0.0328],\n",
      "        [0.0004, 0.0004, 0.0005, 0.0009, 0.0047, 0.0663, 0.0368, 0.0022, 0.0047,\n",
      "         0.0118, 0.0335, 0.0360, 0.0030, 0.0790, 0.2835, 0.0075, 0.2137, 0.0164,\n",
      "         0.1304, 0.0683],\n",
      "        [0.0002, 0.0002, 0.0003, 0.0003, 0.0016, 0.0342, 0.0116, 0.0008, 0.0015,\n",
      "         0.0041, 0.0317, 0.0419, 0.0028, 0.0632, 0.3029, 0.0109, 0.2464, 0.0190,\n",
      "         0.1099, 0.1168],\n",
      "        [0.0003, 0.0005, 0.0006, 0.0007, 0.0022, 0.0437, 0.0254, 0.0014, 0.0023,\n",
      "         0.0043, 0.0127, 0.0262, 0.0034, 0.0421, 0.1607, 0.0078, 0.2932, 0.0307,\n",
      "         0.1272, 0.2145],\n",
      "        [0.0005, 0.0011, 0.0010, 0.0010, 0.0045, 0.0470, 0.0366, 0.0038, 0.0046,\n",
      "         0.0079, 0.0091, 0.0127, 0.0027, 0.0548, 0.0940, 0.0040, 0.2165, 0.0456,\n",
      "         0.2018, 0.2509],\n",
      "        [0.0002, 0.0003, 0.0004, 0.0005, 0.0019, 0.0173, 0.0109, 0.0008, 0.0011,\n",
      "         0.0019, 0.0029, 0.0041, 0.0009, 0.0141, 0.0412, 0.0013, 0.0438, 0.0132,\n",
      "         0.0808, 0.7623],\n",
      "        [0.0004, 0.0004, 0.0004, 0.0006, 0.0034, 0.0111, 0.0086, 0.0017, 0.0022,\n",
      "         0.0040, 0.0065, 0.0082, 0.0022, 0.0244, 0.0348, 0.0030, 0.0490, 0.0302,\n",
      "         0.1385, 0.6703],\n",
      "        [0.0004, 0.0004, 0.0004, 0.0006, 0.0035, 0.0079, 0.0044, 0.0013, 0.0019,\n",
      "         0.0039, 0.0068, 0.0066, 0.0014, 0.0127, 0.0282, 0.0023, 0.0125, 0.0137,\n",
      "         0.0749, 0.8160],\n",
      "        [0.0003, 0.0005, 0.0004, 0.0008, 0.0038, 0.0058, 0.0038, 0.0012, 0.0023,\n",
      "         0.0051, 0.0125, 0.0123, 0.0027, 0.0205, 0.0481, 0.0054, 0.0240, 0.0168,\n",
      "         0.1030, 0.7306],\n",
      "        [0.0005, 0.0006, 0.0006, 0.0012, 0.0064, 0.0085, 0.0059, 0.0022, 0.0035,\n",
      "         0.0076, 0.0216, 0.0196, 0.0051, 0.0223, 0.0392, 0.0085, 0.0222, 0.0246,\n",
      "         0.1288, 0.6710],\n",
      "        [0.0006, 0.0006, 0.0006, 0.0013, 0.0074, 0.0267, 0.0115, 0.0024, 0.0043,\n",
      "         0.0080, 0.0490, 0.0495, 0.0067, 0.0386, 0.1176, 0.0161, 0.0396, 0.0139,\n",
      "         0.0571, 0.5484]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 3.00, Train Loss: 0.00, Val Loss: 5.39, Train BLEU: 0.00, Val BLEU: 4.68, Minutes Elapsed: 278.95\n",
      "Sampling from val predictions...\n",
      "Source: 人们 把 收集 到 的 照片 送到 那个 <UNK> <UNK> 当时 我 十分 有幸 <UNK> 得到 了 他们 的 信任\n",
      "Reference: this is where people were handing them in , and i was honored that day that they actually trusted\n",
      "Model: <SOS> people &apos;re a a , , , i i , i have them to . <EOS> <EOS> <EOS> .\n",
      "Attention Weights: tensor([[9.9242e-01, 6.9350e-03, 2.3947e-04, 4.0071e-05, 2.2998e-05, 2.8457e-04,\n",
      "         2.0742e-05, 1.5335e-05, 5.5017e-07, 1.8653e-06, 1.1921e-05, 9.8209e-06,\n",
      "         1.6544e-07, 2.7720e-07, 2.2210e-08, 2.5102e-08, 1.5011e-08, 3.8404e-08,\n",
      "         1.3031e-08, 3.4908e-08],\n",
      "        [2.5765e-01, 4.8683e-01, 1.6464e-01, 2.3168e-02, 8.7540e-03, 4.7239e-02,\n",
      "         4.9294e-03, 3.2679e-03, 3.6873e-04, 5.6834e-04, 8.6912e-04, 1.0227e-03,\n",
      "         3.0029e-04, 2.4680e-04, 3.5252e-05, 2.4341e-05, 2.1900e-05, 2.8696e-05,\n",
      "         1.1113e-05, 2.0591e-05],\n",
      "        [4.5019e-02, 1.6210e-01, 3.1547e-01, 1.2131e-01, 6.4636e-02, 1.9659e-01,\n",
      "         4.1197e-02, 2.2550e-02, 3.9934e-03, 4.3769e-03, 4.6950e-03, 7.2347e-03,\n",
      "         4.4752e-03, 3.4270e-03, 6.8620e-04, 4.6264e-04, 4.6408e-04, 5.5013e-04,\n",
      "         3.7073e-04, 3.8667e-04],\n",
      "        [7.3582e-02, 1.6452e-02, 1.5303e-01, 5.7743e-02, 3.4433e-02, 3.2333e-01,\n",
      "         5.7961e-02, 5.9555e-02, 3.3771e-02, 3.4132e-02, 4.2333e-02, 4.2967e-02,\n",
      "         2.7768e-02, 2.7481e-02, 2.7434e-03, 1.2534e-03, 8.2701e-04, 4.5529e-03,\n",
      "         1.2871e-03, 4.8029e-03],\n",
      "        [1.0017e-01, 9.3291e-03, 5.2896e-02, 5.7949e-02, 2.7289e-02, 1.3775e-01,\n",
      "         1.4992e-01, 7.8408e-02, 6.0964e-02, 9.3737e-02, 1.2165e-01, 6.3958e-02,\n",
      "         2.2866e-02, 1.7540e-02, 1.6019e-03, 6.2881e-04, 3.7980e-04, 1.8958e-03,\n",
      "         2.9102e-04, 7.6758e-04],\n",
      "        [3.7537e-02, 1.1912e-02, 5.0656e-02, 4.3582e-02, 2.1020e-02, 8.1644e-02,\n",
      "         9.6526e-02, 9.8635e-02, 8.4764e-02, 9.9391e-02, 1.2445e-01, 1.0057e-01,\n",
      "         7.8440e-02, 5.8802e-02, 4.8732e-03, 1.2087e-03, 7.2342e-04, 3.6919e-03,\n",
      "         4.4816e-04, 1.1280e-03],\n",
      "        [4.4996e-03, 1.4480e-03, 8.9735e-03, 6.8808e-03, 4.9249e-03, 1.2880e-02,\n",
      "         1.4129e-02, 9.8853e-02, 6.8839e-02, 6.9323e-02, 1.9039e-01, 2.6638e-01,\n",
      "         1.3277e-01, 9.4572e-02, 1.0416e-02, 2.1443e-03, 1.1832e-03, 8.4088e-03,\n",
      "         7.2797e-04, 2.2561e-03],\n",
      "        [3.1043e-03, 6.3255e-04, 4.7739e-03, 4.2731e-03, 3.5565e-03, 9.6101e-03,\n",
      "         9.0939e-03, 5.0945e-02, 5.4934e-02, 7.3537e-02, 2.6007e-01, 2.0885e-01,\n",
      "         1.5235e-01, 1.2581e-01, 1.8174e-02, 3.7990e-03, 2.0262e-03, 9.7674e-03,\n",
      "         1.0851e-03, 3.6204e-03],\n",
      "        [1.0154e-02, 1.5033e-03, 2.7076e-03, 2.5945e-03, 1.2475e-03, 2.6209e-03,\n",
      "         4.2509e-03, 1.4704e-02, 1.0487e-02, 1.5529e-02, 7.9525e-02, 4.0405e-01,\n",
      "         1.4679e-01, 1.9510e-01, 2.9669e-02, 1.3387e-02, 6.3048e-03, 5.0745e-02,\n",
      "         2.0443e-03, 6.5900e-03],\n",
      "        [1.3129e-03, 8.7201e-04, 1.7846e-03, 1.3924e-03, 8.4362e-04, 9.6431e-04,\n",
      "         1.4836e-03, 4.1843e-03, 2.6913e-03, 2.7591e-03, 8.2308e-03, 6.4327e-02,\n",
      "         9.7052e-02, 3.1434e-01, 7.4340e-02, 3.4605e-02, 1.8341e-02, 3.0052e-01,\n",
      "         9.1263e-03, 6.0825e-02],\n",
      "        [5.6147e-03, 1.4091e-03, 9.5524e-04, 2.0152e-03, 8.7325e-04, 1.3524e-03,\n",
      "         4.2723e-03, 7.6738e-03, 6.5911e-03, 9.8966e-03, 4.2869e-02, 1.5747e-01,\n",
      "         7.7792e-02, 2.0425e-01, 7.2572e-02, 8.4919e-02, 3.2417e-02, 2.0251e-01,\n",
      "         1.1649e-02, 7.2895e-02],\n",
      "        [5.5501e-04, 7.7288e-04, 9.4580e-04, 8.2544e-04, 6.4716e-04, 5.6564e-04,\n",
      "         9.1981e-04, 2.9104e-03, 1.1835e-03, 1.4844e-03, 7.1387e-03, 3.0992e-02,\n",
      "         4.6727e-02, 1.9009e-01, 3.9037e-02, 3.3353e-02, 2.7507e-02, 4.6387e-01,\n",
      "         2.7316e-02, 1.2317e-01],\n",
      "        [2.3275e-04, 7.3125e-04, 7.8317e-04, 9.8366e-04, 8.8814e-04, 6.2355e-04,\n",
      "         1.0069e-03, 3.4563e-03, 1.0525e-03, 1.3432e-03, 5.9306e-03, 3.2329e-02,\n",
      "         4.9651e-02, 1.3124e-01, 2.5038e-02, 4.2106e-02, 4.4546e-02, 3.6821e-01,\n",
      "         6.9641e-02, 2.2021e-01],\n",
      "        [5.8008e-05, 1.6250e-04, 6.8846e-04, 9.1561e-04, 1.0873e-03, 9.3062e-04,\n",
      "         6.9392e-04, 3.7639e-03, 1.2612e-03, 1.0157e-03, 2.7482e-03, 5.5927e-03,\n",
      "         1.2598e-02, 3.4722e-02, 1.5207e-02, 2.1633e-02, 2.8828e-02, 4.7413e-01,\n",
      "         8.2728e-02, 3.1123e-01],\n",
      "        [1.6048e-04, 2.9106e-04, 1.7719e-03, 2.0727e-03, 2.3436e-03, 2.1753e-03,\n",
      "         1.5979e-03, 1.0748e-02, 3.2659e-03, 2.5745e-03, 5.3429e-03, 4.9694e-03,\n",
      "         6.4147e-03, 1.8053e-02, 8.6838e-03, 1.2120e-02, 1.9516e-02, 5.8607e-01,\n",
      "         5.9385e-02, 2.5244e-01],\n",
      "        [1.7374e-03, 2.3018e-03, 1.0994e-02, 1.3136e-02, 1.5023e-02, 1.2855e-02,\n",
      "         7.2518e-03, 4.3175e-02, 1.5502e-02, 1.3437e-02, 2.5754e-02, 2.6505e-02,\n",
      "         3.8636e-02, 7.3716e-02, 3.5053e-02, 3.5821e-02, 5.6223e-02, 3.2108e-01,\n",
      "         9.8218e-02, 1.5358e-01],\n",
      "        [2.1427e-03, 4.0427e-03, 1.6795e-02, 1.4833e-02, 1.1256e-02, 1.4073e-02,\n",
      "         9.9343e-03, 2.4574e-02, 1.5954e-02, 1.2951e-02, 1.9297e-02, 3.1197e-02,\n",
      "         5.9062e-02, 1.4215e-01, 5.7034e-02, 4.0118e-02, 4.1094e-02, 2.9594e-01,\n",
      "         5.4036e-02, 1.3352e-01],\n",
      "        [6.8350e-03, 6.8542e-03, 2.7015e-02, 1.9319e-02, 1.3587e-02, 2.0282e-02,\n",
      "         1.2528e-02, 3.6915e-02, 2.1595e-02, 1.8959e-02, 3.5251e-02, 5.6912e-02,\n",
      "         6.4277e-02, 1.2251e-01, 5.2086e-02, 4.2361e-02, 4.3755e-02, 2.7365e-01,\n",
      "         4.7712e-02, 7.7596e-02],\n",
      "        [4.2232e-03, 5.9662e-03, 2.4894e-02, 1.8813e-02, 1.5719e-02, 2.1575e-02,\n",
      "         1.4190e-02, 2.9566e-02, 2.3619e-02, 1.9159e-02, 2.3577e-02, 3.3299e-02,\n",
      "         6.4199e-02, 1.4930e-01, 5.9968e-02, 4.1071e-02, 3.9482e-02, 2.6034e-01,\n",
      "         4.5499e-02, 1.0555e-01]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3.05, Train Loss: 0.00, Val Loss: 5.29, Train BLEU: 0.00, Val BLEU: 3.79, Minutes Elapsed: 284.09\n",
      "Sampling from val predictions...\n",
      "Source: 但 它们 会 损坏 你 的 挡风 挡风玻璃 玻璃 你 肯定 不 高兴 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: but they can damage your windshield , so you &apos;re not happy with that . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> but they &apos;re to your your , you you don &apos;t . . <EOS> . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0136, 0.9672, 0.0184, 0.0002, 0.0001, 0.0000, 0.0000, 0.0001, 0.0002,\n",
      "         0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0026, 0.9027, 0.0891, 0.0026, 0.0018, 0.0000, 0.0001, 0.0004, 0.0006,\n",
      "         0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0061, 0.1743, 0.5455, 0.1291, 0.1008, 0.0066, 0.0064, 0.0095, 0.0092,\n",
      "         0.0040, 0.0025, 0.0021, 0.0008, 0.0032, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0021, 0.0228, 0.1841, 0.2181, 0.3753, 0.0400, 0.0271, 0.0316, 0.0256,\n",
      "         0.0180, 0.0155, 0.0146, 0.0101, 0.0151, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0005, 0.0008, 0.0040, 0.0822, 0.5483, 0.0460, 0.0698, 0.0904, 0.1083,\n",
      "         0.0043, 0.0071, 0.0049, 0.0200, 0.0135, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0006, 0.0008, 0.0025, 0.0528, 0.4674, 0.0476, 0.0892, 0.1232, 0.1733,\n",
      "         0.0062, 0.0062, 0.0048, 0.0112, 0.0142, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0014, 0.0040, 0.0025, 0.0163, 0.1884, 0.0156, 0.0592, 0.1766, 0.3427,\n",
      "         0.1299, 0.0276, 0.0167, 0.0074, 0.0117, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0031, 0.0063, 0.0060, 0.0294, 0.0840, 0.0315, 0.0815, 0.1713, 0.2368,\n",
      "         0.1822, 0.0706, 0.0628, 0.0219, 0.0125, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0021, 0.0060, 0.0048, 0.0029, 0.0333, 0.0044, 0.0040, 0.0077, 0.0259,\n",
      "         0.5898, 0.1515, 0.1282, 0.0263, 0.0131, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0001, 0.0005, 0.0009, 0.0005, 0.0050, 0.0011, 0.0010, 0.0017, 0.0058,\n",
      "         0.2455, 0.3188, 0.3227, 0.0901, 0.0063, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0002, 0.0004, 0.0001, 0.0016, 0.0003, 0.0003, 0.0004, 0.0016,\n",
      "         0.1526, 0.2959, 0.4165, 0.1268, 0.0033, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0004, 0.0021, 0.0005, 0.0008, 0.0008, 0.0020,\n",
      "         0.0088, 0.0514, 0.1602, 0.7609, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0001, 0.0001, 0.0001, 0.0008, 0.0036, 0.0009, 0.0011, 0.0012, 0.0021,\n",
      "         0.0061, 0.0198, 0.1509, 0.7634, 0.0500, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0010, 0.0014, 0.0017, 0.0096, 0.0506, 0.0108, 0.0159, 0.0165, 0.0292,\n",
      "         0.0126, 0.0224, 0.0952, 0.5355, 0.1977, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0022, 0.0083, 0.0054, 0.0140, 0.0645, 0.0116, 0.0164, 0.0226, 0.0349,\n",
      "         0.0314, 0.0405, 0.1212, 0.1274, 0.4995, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0037, 0.0144, 0.0094, 0.0297, 0.0449, 0.0200, 0.0315, 0.0392, 0.0544,\n",
      "         0.0325, 0.0487, 0.1295, 0.1073, 0.4348, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0012, 0.0084, 0.0066, 0.0212, 0.0453, 0.0108, 0.0187, 0.0245, 0.0331,\n",
      "         0.0314, 0.0507, 0.1562, 0.2491, 0.3430, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0007, 0.0074, 0.0076, 0.0095, 0.0313, 0.0074, 0.0075, 0.0085, 0.0103,\n",
      "         0.0374, 0.0761, 0.3236, 0.3182, 0.1545, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0005, 0.0023, 0.0036, 0.0049, 0.0161, 0.0050, 0.0046, 0.0047, 0.0053,\n",
      "         0.0299, 0.0684, 0.3355, 0.3378, 0.1816, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 3.11, Train Loss: 0.00, Val Loss: 5.26, Train BLEU: 0.00, Val BLEU: 4.18, Minutes Elapsed: 289.24\n",
      "Sampling from val predictions...\n",
      "Source: 花园 非常 的 美丽 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: and the garden , it was beautiful . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> the &apos;s &apos;s is very . a . <EOS> <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.8868, 0.0905, 0.0070, 0.0115, 0.0042, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.5693, 0.3759, 0.0202, 0.0326, 0.0020, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1517, 0.7061, 0.0330, 0.1048, 0.0043, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1371, 0.7244, 0.0296, 0.1047, 0.0043, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0931, 0.6782, 0.0439, 0.1776, 0.0073, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0126, 0.4758, 0.0441, 0.4605, 0.0070, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0206, 0.3942, 0.0861, 0.4803, 0.0187, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0197, 0.3037, 0.0342, 0.6391, 0.0033, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1483, 0.1929, 0.0390, 0.6076, 0.0121, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2420, 0.1809, 0.0452, 0.4596, 0.0723, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0451, 0.2241, 0.0689, 0.5639, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0341, 0.1847, 0.0631, 0.5885, 0.1295, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0464, 0.3218, 0.0559, 0.3724, 0.2035, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0736, 0.3652, 0.0655, 0.3615, 0.1341, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0969, 0.3604, 0.0721, 0.3353, 0.1352, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1159, 0.3480, 0.0762, 0.3145, 0.1454, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1288, 0.3406, 0.0785, 0.2989, 0.1532, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1376, 0.3372, 0.0801, 0.2863, 0.1588, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1439, 0.3353, 0.0814, 0.2762, 0.1632, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 3.16, Train Loss: 0.00, Val Loss: 5.36, Train BLEU: 0.00, Val BLEU: 4.36, Minutes Elapsed: 294.38\n",
      "Sampling from val predictions...\n",
      "Source: 这 也 能 为 病人 节省 节省下 那段 去 诊所 的 路程 如果 病人 能 独立 完成 这个 测试 呢\n",
      "Reference: now , that would actually save on a difficult trip to the clinic , and what if patients could\n",
      "Model: <SOS> it can can can be be to to to or or a a ? <EOS> ? ? <EOS> ?\n",
      "Attention Weights: tensor([[8.6753e-01, 6.1292e-02, 6.0350e-02, 1.8769e-04, 1.0255e-03, 1.7915e-04,\n",
      "         1.0946e-04, 1.4452e-05, 6.8697e-05, 2.8453e-05, 1.4767e-04, 1.6835e-03,\n",
      "         6.8740e-03, 7.7817e-05, 1.0727e-04, 3.7374e-06, 1.8991e-05, 3.4135e-05,\n",
      "         1.4796e-05, 2.5499e-04],\n",
      "        [9.9860e-02, 2.5077e-01, 5.3878e-01, 2.8663e-02, 5.6520e-02, 6.1906e-03,\n",
      "         1.4416e-03, 3.9468e-04, 1.9916e-03, 1.7933e-03, 7.3389e-04, 7.1016e-03,\n",
      "         4.3238e-03, 1.0052e-03, 2.7095e-04, 4.7167e-05, 3.1648e-05, 2.3199e-05,\n",
      "         3.1424e-05, 2.6129e-05],\n",
      "        [3.3661e-02, 9.9681e-02, 4.9778e-01, 7.3248e-02, 1.4603e-01, 3.3055e-02,\n",
      "         5.6021e-03, 2.6866e-03, 1.8842e-02, 1.8921e-02, 5.7546e-03, 3.2447e-02,\n",
      "         2.0704e-02, 5.2462e-03, 2.6010e-03, 1.2463e-03, 5.7980e-04, 7.7306e-04,\n",
      "         5.6845e-04, 5.7251e-04],\n",
      "        [2.1664e-02, 3.5829e-02, 2.1329e-01, 8.9176e-02, 2.9561e-01, 7.0233e-02,\n",
      "         1.2290e-02, 5.7106e-03, 3.8937e-02, 6.2036e-02, 1.2175e-02, 6.7117e-02,\n",
      "         4.4553e-02, 1.5362e-02, 5.6536e-03, 3.6822e-03, 1.4587e-03, 2.1883e-03,\n",
      "         1.5395e-03, 1.4872e-03],\n",
      "        [1.9741e-02, 5.0979e-02, 2.5094e-01, 7.2322e-02, 1.8847e-01, 7.4970e-02,\n",
      "         1.4350e-02, 7.2820e-03, 4.6586e-02, 5.7227e-02, 1.8393e-02, 9.4121e-02,\n",
      "         6.3313e-02, 1.6905e-02, 9.3623e-03, 5.1141e-03, 2.1299e-03, 3.3460e-03,\n",
      "         2.1882e-03, 2.2525e-03],\n",
      "        [9.8457e-04, 1.6716e-03, 1.1009e-02, 8.7504e-03, 2.4901e-01, 3.1378e-02,\n",
      "         7.4703e-03, 5.4964e-03, 5.8339e-02, 1.1269e-01, 1.6679e-02, 1.9873e-01,\n",
      "         1.6109e-01, 4.5588e-02, 1.2834e-02, 2.9544e-02, 1.0685e-02, 1.6983e-02,\n",
      "         1.4298e-02, 6.7696e-03],\n",
      "        [5.0403e-04, 6.6102e-04, 1.8568e-03, 6.5899e-03, 9.0627e-02, 2.0651e-02,\n",
      "         6.9077e-03, 8.1234e-03, 9.6638e-02, 2.1483e-01, 2.5243e-02, 1.3994e-01,\n",
      "         1.5040e-01, 5.7630e-02, 1.7965e-02, 5.7348e-02, 2.2767e-02, 4.7496e-02,\n",
      "         2.4207e-02, 9.6129e-03],\n",
      "        [2.2549e-04, 2.3402e-04, 5.9896e-04, 1.9895e-03, 3.7878e-02, 9.6936e-03,\n",
      "         3.8914e-03, 5.3448e-03, 6.3745e-02, 2.8014e-01, 1.5356e-02, 8.7782e-02,\n",
      "         2.1252e-01, 7.5155e-02, 2.0378e-02, 6.8624e-02, 1.9809e-02, 5.5290e-02,\n",
      "         3.2771e-02, 8.5771e-03],\n",
      "        [2.2236e-04, 1.3747e-04, 2.3528e-04, 8.1497e-04, 1.9184e-02, 4.4413e-03,\n",
      "         2.4327e-03, 3.3356e-03, 3.4702e-02, 2.6525e-01, 1.3767e-02, 6.0859e-02,\n",
      "         2.1004e-01, 6.9971e-02, 2.9106e-02, 9.2604e-02, 2.0385e-02, 1.0847e-01,\n",
      "         4.7659e-02, 1.6380e-02],\n",
      "        [3.7543e-04, 2.2523e-04, 3.0391e-04, 3.5676e-04, 1.1520e-02, 4.3083e-03,\n",
      "         2.5156e-03, 3.3831e-03, 2.5125e-02, 9.8643e-02, 1.1695e-02, 8.1176e-02,\n",
      "         2.8893e-01, 7.4909e-02, 6.6180e-02, 6.4024e-02, 2.9291e-02, 1.2078e-01,\n",
      "         6.5397e-02, 5.0858e-02],\n",
      "        [3.1135e-04, 2.7149e-04, 5.2241e-04, 6.1346e-04, 8.9992e-03, 5.7800e-03,\n",
      "         2.5812e-03, 3.5711e-03, 4.1036e-02, 9.2752e-02, 8.6631e-03, 6.9826e-02,\n",
      "         3.5779e-01, 7.3100e-02, 8.4464e-02, 3.8123e-02, 1.7670e-02, 9.4528e-02,\n",
      "         4.2295e-02, 5.7104e-02],\n",
      "        [5.4165e-04, 5.1294e-04, 1.3212e-03, 1.6027e-03, 2.4618e-02, 1.0145e-02,\n",
      "         3.9737e-03, 5.9554e-03, 3.6920e-02, 1.5091e-01, 6.9471e-03, 5.7344e-02,\n",
      "         1.3390e-01, 1.0268e-01, 4.9999e-02, 5.2870e-02, 1.8166e-02, 1.3465e-01,\n",
      "         6.6181e-02, 1.4077e-01],\n",
      "        [1.2152e-03, 8.4524e-04, 1.2665e-03, 2.1206e-03, 2.4086e-02, 7.0435e-03,\n",
      "         3.0690e-03, 3.4769e-03, 2.3924e-02, 1.0461e-01, 6.3382e-03, 4.5221e-02,\n",
      "         8.0071e-02, 6.9691e-02, 2.2205e-02, 5.9786e-02, 1.5230e-02, 2.1651e-01,\n",
      "         8.6257e-02, 2.2704e-01],\n",
      "        [9.4703e-05, 7.8573e-05, 1.1925e-04, 3.0750e-04, 9.7044e-03, 6.8979e-04,\n",
      "         5.7461e-04, 1.0470e-03, 5.0319e-03, 7.5660e-02, 3.9939e-03, 1.2340e-02,\n",
      "         7.8215e-03, 3.1671e-02, 4.6251e-03, 1.2038e-01, 3.2888e-02, 2.8470e-01,\n",
      "         2.8881e-01, 1.1947e-01],\n",
      "        [6.0248e-04, 8.6478e-04, 1.3097e-03, 1.8814e-03, 2.0746e-02, 1.0546e-02,\n",
      "         5.7105e-03, 9.3414e-03, 4.9316e-02, 1.5864e-01, 1.1800e-02, 8.6463e-02,\n",
      "         8.7761e-02, 1.0414e-01, 3.9716e-02, 5.4121e-02, 3.2448e-02, 8.4802e-02,\n",
      "         6.6156e-02, 1.7364e-01],\n",
      "        [2.3118e-03, 2.3803e-03, 3.3467e-03, 6.6710e-03, 5.1618e-02, 1.9191e-02,\n",
      "         8.5266e-03, 1.0983e-02, 5.6716e-02, 1.8554e-01, 1.6936e-02, 7.5730e-02,\n",
      "         7.8195e-02, 1.2979e-01, 2.5384e-02, 6.4240e-02, 2.2103e-02, 9.8771e-02,\n",
      "         5.4032e-02, 8.7540e-02],\n",
      "        [1.8183e-03, 2.7755e-03, 7.5603e-03, 1.3448e-02, 3.6726e-02, 2.1494e-02,\n",
      "         1.0514e-02, 1.1231e-02, 5.4855e-02, 7.6447e-02, 1.7747e-02, 5.2450e-02,\n",
      "         6.5878e-02, 6.3927e-02, 4.5583e-02, 8.5117e-02, 3.2298e-02, 1.1255e-01,\n",
      "         9.7949e-02, 1.8963e-01],\n",
      "        [2.9893e-03, 4.0520e-03, 1.1212e-02, 1.4881e-02, 3.8181e-02, 2.6906e-02,\n",
      "         1.2667e-02, 1.3293e-02, 5.6092e-02, 7.3490e-02, 1.9584e-02, 5.5980e-02,\n",
      "         7.6926e-02, 6.7330e-02, 5.2684e-02, 7.6265e-02, 3.2364e-02, 1.1529e-01,\n",
      "         8.0687e-02, 1.6913e-01],\n",
      "        [7.6829e-04, 1.1155e-03, 2.9246e-03, 8.9478e-03, 6.0242e-02, 1.3383e-02,\n",
      "         7.1392e-03, 9.9799e-03, 6.8911e-02, 1.5085e-01, 1.3819e-02, 5.6013e-02,\n",
      "         4.8137e-02, 6.7582e-02, 2.6584e-02, 1.3292e-01, 3.9463e-02, 1.1705e-01,\n",
      "         8.9771e-02, 8.4393e-02]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3.22, Train Loss: 0.00, Val Loss: 5.24, Train BLEU: 0.00, Val BLEU: 5.14, Minutes Elapsed: 299.50\n",
      "Sampling from val predictions...\n",
      "Source: 谢谢 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: thank you . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> thank you . <EOS> you <EOS> <EOS> <EOS> <EOS> you you you you you you you you you you\n",
      "Attention Weights: tensor([[0.9956, 0.0044, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.9921, 0.0079, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.9574, 0.0426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.5445, 0.4555, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.5174, 0.4826, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.7447, 0.2553, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.6131, 0.3869, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.8283, 0.1717, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.8375, 0.1625, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.8928, 0.1072, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.9309, 0.0691, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.9512, 0.0488, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.9616, 0.0384, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.9675, 0.0325, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.9713, 0.0287, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.9740, 0.0260, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.9759, 0.0241, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.9774, 0.0226, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.9785, 0.0215, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 3.27, Train Loss: 0.00, Val Loss: 5.26, Train BLEU: 0.00, Val BLEU: 4.86, Minutes Elapsed: 304.65\n",
      "Sampling from val predictions...\n",
      "Source: 这 就是 我们 的 模型 重建 音乐 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: so this is our reconstruction . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> and is is our we of . <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.8794, 0.1149, 0.0050, 0.0001, 0.0003, 0.0000, 0.0001, 0.0002, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.4046, 0.5631, 0.0302, 0.0006, 0.0009, 0.0001, 0.0003, 0.0002, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1401, 0.4395, 0.3686, 0.0122, 0.0229, 0.0035, 0.0076, 0.0056, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1521, 0.3478, 0.3887, 0.0242, 0.0494, 0.0090, 0.0188, 0.0101, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0219, 0.0480, 0.3773, 0.0197, 0.3047, 0.0536, 0.1617, 0.0130, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0322, 0.0592, 0.3857, 0.0230, 0.1580, 0.1066, 0.2200, 0.0154, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0149, 0.0215, 0.2583, 0.0193, 0.2064, 0.1741, 0.2975, 0.0080, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0388, 0.0234, 0.4863, 0.0141, 0.0831, 0.0825, 0.2599, 0.0120, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0391, 0.0539, 0.4699, 0.0372, 0.0598, 0.0743, 0.2336, 0.0323, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0338, 0.0451, 0.4287, 0.0300, 0.0519, 0.0707, 0.3074, 0.0325, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1246, 0.0941, 0.5103, 0.0239, 0.0341, 0.0337, 0.1252, 0.0541, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1395, 0.1063, 0.4962, 0.0194, 0.0344, 0.0256, 0.1087, 0.0700, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1587, 0.1163, 0.4660, 0.0201, 0.0374, 0.0254, 0.0999, 0.0763, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1687, 0.1200, 0.4469, 0.0213, 0.0398, 0.0267, 0.0937, 0.0829, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1739, 0.1228, 0.4341, 0.0221, 0.0419, 0.0278, 0.0894, 0.0880, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1776, 0.1252, 0.4243, 0.0227, 0.0434, 0.0287, 0.0866, 0.0915, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1795, 0.1268, 0.4175, 0.0232, 0.0447, 0.0295, 0.0850, 0.0938, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1803, 0.1278, 0.4128, 0.0235, 0.0458, 0.0302, 0.0842, 0.0954, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1805, 0.1283, 0.4094, 0.0238, 0.0467, 0.0308, 0.0838, 0.0967, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 3.33, Train Loss: 0.00, Val Loss: 5.44, Train BLEU: 0.00, Val BLEU: 4.07, Minutes Elapsed: 309.78\n",
      "Sampling from val predictions...\n",
      "Source: 他们 第一 第一天 一天 来时 看到 了 稻草 <UNK> <UNK> 然后 就 回去 了 但是 第二 第二天 二天 他们 会\n",
      "Reference: they will come the first day and they see the <UNK> , and they go back , but the\n",
      "Model: <SOS> they they the the the and , they they the the . . . . . <EOS> <EOS> .\n",
      "Attention Weights: tensor([[2.4493e-01, 1.7992e-01, 2.0516e-02, 5.0780e-01, 1.3753e-02, 3.1679e-02,\n",
      "         6.5470e-04, 5.2748e-04, 5.0107e-06, 2.7579e-05, 3.0873e-05, 1.2100e-04,\n",
      "         9.0892e-06, 1.0099e-06, 4.1711e-06, 8.1918e-06, 1.2162e-06, 6.0429e-06,\n",
      "         3.3377e-06, 2.2681e-07],\n",
      "        [1.1433e-01, 3.7511e-01, 9.8087e-02, 3.0385e-01, 4.1522e-02, 4.5549e-02,\n",
      "         6.4611e-03, 1.1410e-02, 6.1425e-04, 1.3031e-03, 1.9096e-04, 5.0399e-04,\n",
      "         6.4056e-04, 5.5619e-05, 1.8477e-04, 1.1475e-04, 1.8620e-05, 3.5040e-05,\n",
      "         1.8156e-05, 3.2068e-06],\n",
      "        [8.2837e-02, 1.0973e-01, 5.1436e-02, 1.9192e-01, 6.0584e-02, 1.2105e-01,\n",
      "         6.5835e-02, 1.5566e-01, 3.4528e-02, 5.8974e-02, 1.2484e-02, 1.2759e-02,\n",
      "         3.0380e-02, 2.7088e-03, 4.9434e-03, 2.1037e-03, 5.0370e-04, 8.6055e-04,\n",
      "         5.0780e-04, 1.8892e-04],\n",
      "        [2.7332e-03, 2.5374e-02, 2.3850e-02, 3.5716e-02, 1.5940e-02, 1.4550e-02,\n",
      "         3.2370e-02, 2.3154e-01, 5.9369e-02, 1.0533e-01, 2.1743e-02, 1.5723e-02,\n",
      "         8.1637e-02, 1.6558e-02, 1.5768e-01, 1.3711e-01, 1.0048e-02, 1.1116e-02,\n",
      "         1.1501e-03, 4.6710e-04],\n",
      "        [5.6218e-03, 4.8778e-02, 2.7434e-02, 6.9400e-02, 1.7023e-02, 1.1408e-02,\n",
      "         2.9029e-02, 1.5984e-01, 4.0302e-02, 7.4976e-02, 2.7097e-02, 2.2242e-02,\n",
      "         8.4775e-02, 1.9277e-02, 1.7479e-01, 1.4819e-01, 1.7415e-02, 2.0190e-02,\n",
      "         1.8662e-03, 3.4682e-04],\n",
      "        [7.9412e-03, 5.4622e-02, 2.4020e-02, 5.2975e-02, 1.7563e-02, 8.1122e-03,\n",
      "         1.6654e-02, 8.2140e-02, 3.0354e-02, 5.0131e-02, 3.6213e-02, 4.0324e-02,\n",
      "         7.9423e-02, 2.3213e-02, 2.5561e-01, 1.4652e-01, 2.3306e-02, 4.1748e-02,\n",
      "         8.1859e-03, 9.5073e-04],\n",
      "        [3.1052e-02, 2.0644e-02, 7.7102e-03, 5.4759e-02, 9.9385e-03, 9.4950e-03,\n",
      "         9.9341e-03, 2.9673e-02, 2.1825e-02, 4.0709e-02, 1.3363e-01, 1.4590e-01,\n",
      "         9.7355e-02, 1.3429e-02, 2.0848e-01, 3.6997e-02, 1.6009e-02, 5.8697e-02,\n",
      "         5.1480e-02, 2.2816e-03],\n",
      "        [5.8943e-02, 1.6267e-02, 4.2118e-03, 3.6128e-02, 6.5438e-03, 8.1845e-03,\n",
      "         8.0703e-03, 3.1778e-02, 1.9402e-02, 3.1400e-02, 7.9557e-02, 1.1746e-01,\n",
      "         1.0119e-01, 1.1367e-02, 2.2515e-01, 3.6380e-02, 1.5113e-02, 5.3715e-02,\n",
      "         1.3191e-01, 7.2334e-03],\n",
      "        [2.8442e-02, 3.3671e-02, 1.0700e-02, 2.2512e-02, 7.2723e-03, 5.2494e-03,\n",
      "         4.0823e-03, 1.4387e-02, 6.4780e-03, 1.0126e-02, 1.7256e-02, 2.7324e-02,\n",
      "         4.5181e-02, 1.6860e-02, 2.4005e-01, 1.1477e-01, 3.9797e-02, 6.9797e-02,\n",
      "         2.3939e-01, 4.6658e-02],\n",
      "        [3.4663e-03, 9.6483e-03, 4.6090e-03, 6.7583e-03, 2.3756e-03, 2.5097e-03,\n",
      "         2.3053e-03, 7.3879e-03, 3.4813e-03, 4.9570e-03, 6.5998e-03, 1.0269e-02,\n",
      "         3.5358e-02, 1.3497e-02, 2.4533e-01, 1.1915e-01, 4.6280e-02, 5.3442e-02,\n",
      "         2.2079e-01, 2.0178e-01],\n",
      "        [3.5607e-04, 2.5690e-03, 2.0627e-03, 2.1545e-03, 6.0833e-04, 4.4876e-04,\n",
      "         1.2087e-03, 3.9031e-03, 1.2053e-03, 1.6223e-03, 1.0445e-03, 1.0319e-03,\n",
      "         5.3699e-03, 4.9100e-03, 3.3340e-01, 4.6469e-01, 8.0388e-02, 3.1975e-02,\n",
      "         2.8284e-02, 3.2761e-02],\n",
      "        [4.6412e-03, 3.1296e-02, 2.2224e-02, 2.0355e-02, 8.3629e-03, 3.4290e-03,\n",
      "         6.0886e-03, 1.6566e-02, 5.2083e-03, 5.5852e-03, 2.6708e-03, 2.5190e-03,\n",
      "         5.5222e-03, 7.0200e-03, 1.5394e-01, 3.8217e-01, 1.5382e-01, 1.0044e-01,\n",
      "         4.0006e-02, 2.8135e-02],\n",
      "        [1.7577e-02, 1.8077e-02, 1.0147e-02, 3.6352e-02, 9.8132e-03, 6.2700e-03,\n",
      "         8.6112e-03, 2.7945e-02, 1.4575e-02, 1.7382e-02, 1.2953e-02, 9.5411e-03,\n",
      "         1.3979e-02, 5.3957e-03, 1.4354e-01, 1.4633e-01, 1.5126e-01, 1.9628e-01,\n",
      "         1.1100e-01, 4.2980e-02],\n",
      "        [5.7985e-02, 7.3371e-02, 2.4652e-02, 9.0133e-02, 2.5021e-02, 2.1305e-02,\n",
      "         2.3468e-02, 6.0344e-02, 1.9380e-02, 2.9588e-02, 2.2309e-02, 2.4745e-02,\n",
      "         2.5453e-02, 1.4825e-02, 1.0052e-01, 1.2733e-01, 7.9585e-02, 9.3151e-02,\n",
      "         5.6175e-02, 3.0667e-02],\n",
      "        [2.5404e-02, 7.3705e-02, 4.2920e-02, 5.1000e-02, 1.8270e-02, 1.3643e-02,\n",
      "         1.8818e-02, 3.3181e-02, 1.2169e-02, 1.6163e-02, 1.4236e-02, 1.6334e-02,\n",
      "         6.2387e-02, 2.5939e-02, 1.3691e-01, 9.6864e-02, 4.4771e-02, 3.8552e-02,\n",
      "         9.3849e-02, 1.6489e-01],\n",
      "        [1.7198e-02, 7.6400e-02, 4.1853e-02, 5.0609e-02, 1.9624e-02, 1.7812e-02,\n",
      "         2.3449e-02, 3.7220e-02, 1.5840e-02, 2.1617e-02, 1.7250e-02, 2.4361e-02,\n",
      "         8.2056e-02, 3.6802e-02, 1.1993e-01, 7.3568e-02, 3.5103e-02, 2.9922e-02,\n",
      "         7.2254e-02, 1.8713e-01],\n",
      "        [6.8552e-03, 3.1869e-02, 2.6167e-02, 2.5545e-02, 8.8858e-03, 9.2286e-03,\n",
      "         1.7092e-02, 3.0160e-02, 1.0612e-02, 1.5299e-02, 1.6966e-02, 1.7746e-02,\n",
      "         3.4338e-02, 3.3142e-02, 2.5389e-01, 2.9295e-01, 7.7915e-02, 4.6826e-02,\n",
      "         1.7461e-02, 2.7054e-02],\n",
      "        [2.1817e-02, 5.9531e-02, 4.7037e-02, 5.8876e-02, 2.4278e-02, 1.2986e-02,\n",
      "         1.7299e-02, 4.9039e-02, 1.2554e-02, 1.4632e-02, 7.9592e-03, 7.3335e-03,\n",
      "         1.8537e-02, 1.9518e-02, 1.3838e-01, 2.9238e-01, 1.1518e-01, 6.0213e-02,\n",
      "         1.7283e-02, 5.1663e-03],\n",
      "        [2.5381e-02, 6.3149e-02, 4.7266e-02, 6.3687e-02, 2.8946e-02, 1.4044e-02,\n",
      "         1.7922e-02, 4.9306e-02, 1.2900e-02, 1.5865e-02, 9.1183e-03, 7.1050e-03,\n",
      "         1.2790e-02, 1.7231e-02, 1.1284e-01, 2.9721e-01, 1.1903e-01, 7.2332e-02,\n",
      "         1.0174e-02, 3.7041e-03]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3.38, Train Loss: 0.00, Val Loss: 5.31, Train BLEU: 0.00, Val BLEU: 4.37, Minutes Elapsed: 314.90\n",
      "Sampling from val predictions...\n",
      "Source: 他 无所 无所谓 所谓 宗教 宗教信仰 信仰 的 差异 还有 他 从来 从来没 说 过 谎 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: he doesn &apos;t care about religious differences , and get this : he has never told a lie .\n",
      "Model: <SOS> he didn &apos;t know any the , and but he didn &apos;t . &apos;t &apos;t . <EOS> <EOS> .\n",
      "Attention Weights: tensor([[0.9842, 0.0011, 0.0125, 0.0001, 0.0000, 0.0000, 0.0000, 0.0002, 0.0015,\n",
      "         0.0004, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.3546, 0.1514, 0.4484, 0.0090, 0.0035, 0.0010, 0.0051, 0.0040, 0.0168,\n",
      "         0.0033, 0.0020, 0.0005, 0.0002, 0.0001, 0.0000, 0.0000, 0.0001, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1514, 0.0886, 0.5483, 0.0718, 0.0222, 0.0058, 0.0257, 0.0164, 0.0393,\n",
      "         0.0095, 0.0073, 0.0029, 0.0024, 0.0024, 0.0011, 0.0010, 0.0040, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0088, 0.0166, 0.3958, 0.2278, 0.1346, 0.0179, 0.0481, 0.0191, 0.0996,\n",
      "         0.0160, 0.0058, 0.0013, 0.0021, 0.0017, 0.0008, 0.0010, 0.0030, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0014, 0.0038, 0.0572, 0.1584, 0.2684, 0.0373, 0.1798, 0.0334, 0.1536,\n",
      "         0.0432, 0.0316, 0.0042, 0.0064, 0.0046, 0.0026, 0.0024, 0.0117, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0020, 0.0011, 0.0167, 0.0659, 0.3509, 0.0610, 0.2289, 0.0206, 0.1524,\n",
      "         0.0512, 0.0391, 0.0016, 0.0019, 0.0013, 0.0007, 0.0007, 0.0042, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0027, 0.0007, 0.0114, 0.0505, 0.3159, 0.0497, 0.2553, 0.0294, 0.1457,\n",
      "         0.0776, 0.0540, 0.0019, 0.0014, 0.0009, 0.0003, 0.0003, 0.0023, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0129, 0.0009, 0.0142, 0.0305, 0.1561, 0.0436, 0.2852, 0.0236, 0.1769,\n",
      "         0.1432, 0.1036, 0.0029, 0.0021, 0.0013, 0.0004, 0.0003, 0.0024, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0067, 0.0002, 0.0045, 0.0114, 0.1057, 0.0257, 0.1506, 0.0041, 0.0437,\n",
      "         0.1191, 0.4805, 0.0156, 0.0113, 0.0101, 0.0025, 0.0021, 0.0062, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0057, 0.0003, 0.0044, 0.0061, 0.0402, 0.0129, 0.0633, 0.0026, 0.0300,\n",
      "         0.0891, 0.6211, 0.0450, 0.0323, 0.0311, 0.0061, 0.0049, 0.0049, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0010, 0.0010, 0.0039, 0.0072, 0.0440, 0.0211, 0.0819, 0.0058, 0.0941,\n",
      "         0.0770, 0.2345, 0.1781, 0.1336, 0.0726, 0.0193, 0.0210, 0.0040, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0002, 0.0002, 0.0006, 0.0008, 0.0030, 0.0018, 0.0063, 0.0011, 0.0113,\n",
      "         0.0191, 0.0883, 0.2818, 0.2573, 0.2055, 0.0605, 0.0593, 0.0032, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0001, 0.0003, 0.0008, 0.0003, 0.0005, 0.0001, 0.0016,\n",
      "         0.0015, 0.0070, 0.0367, 0.1430, 0.2249, 0.2264, 0.3509, 0.0060, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0002, 0.0003, 0.0011, 0.0005, 0.0010, 0.0001, 0.0008,\n",
      "         0.0012, 0.0111, 0.0290, 0.1180, 0.2254, 0.2819, 0.3183, 0.0111, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0002, 0.0002, 0.0005, 0.0003, 0.0006, 0.0001, 0.0004,\n",
      "         0.0007, 0.0097, 0.0231, 0.0851, 0.1732, 0.3163, 0.3691, 0.0205, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0001, 0.0002, 0.0006, 0.0002, 0.0003, 0.0001, 0.0004,\n",
      "         0.0003, 0.0010, 0.0044, 0.0222, 0.0708, 0.3131, 0.5609, 0.0254, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0001, 0.0000, 0.0007, 0.0010, 0.0075, 0.0020, 0.0041, 0.0006, 0.0029,\n",
      "         0.0017, 0.0049, 0.0030, 0.0207, 0.0763, 0.3246, 0.4280, 0.1218, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0007, 0.0002, 0.0032, 0.0058, 0.0263, 0.0069, 0.0141, 0.0020, 0.0081,\n",
      "         0.0046, 0.0101, 0.0041, 0.0189, 0.0635, 0.1768, 0.4590, 0.1956, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0009, 0.0004, 0.0051, 0.0121, 0.0471, 0.0165, 0.0303, 0.0028, 0.0108,\n",
      "         0.0060, 0.0159, 0.0052, 0.0198, 0.0512, 0.1356, 0.3902, 0.2501, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 3.44, Train Loss: 0.00, Val Loss: 5.23, Train BLEU: 0.00, Val BLEU: 4.76, Minutes Elapsed: 320.03\n",
      "Sampling from val predictions...\n",
      "Source: 我 把 样品 放进 放进去 进去 了 现在 把 它 拿出 出来 看看 发生 了 什么 事 <EOS> <PAD> <PAD>\n",
      "Reference: so i put the specimen in , which i &apos;m now going to take out to see what happened\n",
      "Model: <SOS> i i &apos;ll going the , , , i what it to this do this this this . <EOS>\n",
      "Attention Weights: tensor([[0.9648, 0.0298, 0.0035, 0.0005, 0.0002, 0.0000, 0.0000, 0.0001, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0010, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1522, 0.6803, 0.1524, 0.0087, 0.0026, 0.0006, 0.0002, 0.0006, 0.0002,\n",
      "         0.0003, 0.0002, 0.0001, 0.0002, 0.0001, 0.0001, 0.0010, 0.0001, 0.0001,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1144, 0.2901, 0.4034, 0.1064, 0.0381, 0.0099, 0.0025, 0.0077, 0.0022,\n",
      "         0.0049, 0.0014, 0.0012, 0.0021, 0.0021, 0.0013, 0.0057, 0.0023, 0.0044,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1067, 0.1986, 0.4468, 0.1468, 0.0497, 0.0137, 0.0028, 0.0094, 0.0020,\n",
      "         0.0051, 0.0015, 0.0013, 0.0020, 0.0019, 0.0011, 0.0045, 0.0019, 0.0041,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0089, 0.0197, 0.3878, 0.1955, 0.1927, 0.0624, 0.0039, 0.0255, 0.0027,\n",
      "         0.0132, 0.0063, 0.0101, 0.0218, 0.0072, 0.0028, 0.0191, 0.0074, 0.0130,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0126, 0.0066, 0.1623, 0.1542, 0.3066, 0.1316, 0.0097, 0.0945, 0.0049,\n",
      "         0.0192, 0.0040, 0.0063, 0.0187, 0.0075, 0.0037, 0.0370, 0.0051, 0.0154,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0197, 0.0103, 0.0463, 0.0480, 0.1293, 0.1333, 0.0524, 0.3876, 0.0489,\n",
      "         0.0429, 0.0092, 0.0062, 0.0182, 0.0055, 0.0034, 0.0235, 0.0043, 0.0110,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0105, 0.0089, 0.0351, 0.0331, 0.1057, 0.1143, 0.0192, 0.4343, 0.0419,\n",
      "         0.0738, 0.0149, 0.0087, 0.0212, 0.0073, 0.0041, 0.0479, 0.0067, 0.0123,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0134, 0.0043, 0.0097, 0.0120, 0.0432, 0.0554, 0.0391, 0.6435, 0.0608,\n",
      "         0.0588, 0.0095, 0.0046, 0.0141, 0.0042, 0.0022, 0.0196, 0.0020, 0.0034,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0056, 0.0073, 0.0375, 0.0469, 0.1058, 0.0994, 0.0154, 0.2913, 0.0533,\n",
      "         0.1446, 0.0810, 0.0181, 0.0357, 0.0139, 0.0036, 0.0257, 0.0084, 0.0063,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0015, 0.0009, 0.0045, 0.0042, 0.0102, 0.0137, 0.0035, 0.1746, 0.0163,\n",
      "         0.2107, 0.1578, 0.0843, 0.1667, 0.0617, 0.0106, 0.0427, 0.0251, 0.0110,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0002, 0.0002, 0.0014, 0.0013, 0.0053, 0.0077, 0.0022, 0.0549, 0.0087,\n",
      "         0.1955, 0.1294, 0.1931, 0.2188, 0.0950, 0.0141, 0.0443, 0.0190, 0.0090,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0002, 0.0002, 0.0024, 0.0018, 0.0080, 0.0096, 0.0020, 0.0933, 0.0106,\n",
      "         0.2174, 0.1247, 0.1510, 0.2068, 0.0873, 0.0128, 0.0368, 0.0238, 0.0111,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0002, 0.0002, 0.0024, 0.0013, 0.0042, 0.0046, 0.0009, 0.0566, 0.0045,\n",
      "         0.1587, 0.0640, 0.1140, 0.2270, 0.2166, 0.0270, 0.0706, 0.0336, 0.0136,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0002, 0.0001, 0.0009, 0.0006, 0.0025, 0.0025, 0.0009, 0.0190, 0.0025,\n",
      "         0.1096, 0.0398, 0.1706, 0.2762, 0.2173, 0.0230, 0.0975, 0.0252, 0.0117,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0002, 0.0001, 0.0011, 0.0005, 0.0021, 0.0023, 0.0007, 0.0231, 0.0019,\n",
      "         0.0972, 0.0234, 0.1097, 0.2178, 0.2813, 0.0348, 0.1399, 0.0489, 0.0151,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0006, 0.0003, 0.0019, 0.0008, 0.0026, 0.0027, 0.0006, 0.0275, 0.0016,\n",
      "         0.0635, 0.0190, 0.0693, 0.2072, 0.2886, 0.0408, 0.2145, 0.0406, 0.0180,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0011, 0.0006, 0.0048, 0.0018, 0.0038, 0.0038, 0.0009, 0.0207, 0.0016,\n",
      "         0.0353, 0.0132, 0.0395, 0.1188, 0.3274, 0.0448, 0.2732, 0.0665, 0.0422,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0007, 0.0004, 0.0029, 0.0012, 0.0026, 0.0026, 0.0010, 0.0130, 0.0019,\n",
      "         0.0295, 0.0133, 0.0392, 0.1112, 0.3535, 0.0441, 0.2042, 0.1297, 0.0491,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 3.49, Train Loss: 0.00, Val Loss: 5.27, Train BLEU: 0.00, Val BLEU: 5.39, Minutes Elapsed: 325.18\n",
      "Sampling from val predictions...\n",
      "Source: 在 韩国 <UNK> 定居 比 我 想象 的 更加 困难 并且 充满 了 挑战 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: settling down in south korea was a lot more challenging than i had expected . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> in in in the , , i very of to . <EOS> . . . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0852, 0.3258, 0.0343, 0.3941, 0.1229, 0.0337, 0.0013, 0.0004, 0.0010,\n",
      "         0.0006, 0.0001, 0.0000, 0.0001, 0.0001, 0.0004, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0178, 0.6811, 0.0405, 0.1845, 0.0422, 0.0099, 0.0132, 0.0013, 0.0065,\n",
      "         0.0020, 0.0002, 0.0001, 0.0001, 0.0002, 0.0005, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0151, 0.3236, 0.0689, 0.2652, 0.1569, 0.0361, 0.0404, 0.0098, 0.0409,\n",
      "         0.0218, 0.0030, 0.0033, 0.0014, 0.0054, 0.0081, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0018, 0.2849, 0.0318, 0.1767, 0.0742, 0.1677, 0.1168, 0.0049, 0.0653,\n",
      "         0.0422, 0.0102, 0.0044, 0.0026, 0.0073, 0.0092, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0021, 0.3379, 0.0334, 0.1352, 0.0650, 0.1381, 0.0969, 0.0060, 0.0767,\n",
      "         0.0619, 0.0157, 0.0069, 0.0038, 0.0113, 0.0090, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0092, 0.2955, 0.0859, 0.1884, 0.1014, 0.1531, 0.0304, 0.0049, 0.0565,\n",
      "         0.0498, 0.0133, 0.0028, 0.0017, 0.0032, 0.0038, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0050, 0.1517, 0.0250, 0.0883, 0.0288, 0.2084, 0.2017, 0.0042, 0.0689,\n",
      "         0.0920, 0.0793, 0.0176, 0.0069, 0.0140, 0.0083, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0019, 0.0281, 0.0046, 0.0161, 0.0081, 0.1865, 0.1892, 0.0039, 0.0664,\n",
      "         0.1421, 0.2182, 0.0554, 0.0162, 0.0506, 0.0127, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0006, 0.0120, 0.0024, 0.0045, 0.0018, 0.0800, 0.0594, 0.0016, 0.0630,\n",
      "         0.2349, 0.2681, 0.0703, 0.0235, 0.1696, 0.0083, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0018, 0.0408, 0.0119, 0.0285, 0.0052, 0.0891, 0.0429, 0.0017, 0.0453,\n",
      "         0.1781, 0.2916, 0.0634, 0.0225, 0.1611, 0.0161, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0048, 0.1378, 0.0223, 0.0362, 0.0053, 0.1559, 0.1204, 0.0014, 0.0196,\n",
      "         0.0816, 0.2238, 0.0337, 0.0160, 0.1138, 0.0275, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0066, 0.1805, 0.0302, 0.0362, 0.0065, 0.1099, 0.1128, 0.0017, 0.0155,\n",
      "         0.0593, 0.1415, 0.0363, 0.0212, 0.1834, 0.0584, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0159, 0.3340, 0.0477, 0.0617, 0.0097, 0.1350, 0.1122, 0.0024, 0.0094,\n",
      "         0.0253, 0.0684, 0.0185, 0.0126, 0.0743, 0.0727, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0102, 0.1814, 0.0367, 0.0402, 0.0093, 0.0804, 0.0981, 0.0032, 0.0182,\n",
      "         0.0472, 0.0875, 0.0365, 0.0245, 0.1966, 0.1302, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0023, 0.0219, 0.0046, 0.0073, 0.0025, 0.0253, 0.0905, 0.0040, 0.0236,\n",
      "         0.0545, 0.1163, 0.1180, 0.0394, 0.3883, 0.1013, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0036, 0.0352, 0.0066, 0.0114, 0.0045, 0.0494, 0.0731, 0.0041, 0.0155,\n",
      "         0.0334, 0.0688, 0.0578, 0.0476, 0.3182, 0.2708, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0093, 0.1257, 0.0173, 0.0258, 0.0083, 0.0706, 0.0942, 0.0043, 0.0147,\n",
      "         0.0281, 0.0417, 0.0364, 0.0295, 0.1945, 0.2995, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0097, 0.0892, 0.0217, 0.0242, 0.0091, 0.0355, 0.1841, 0.0178, 0.0428,\n",
      "         0.0647, 0.1191, 0.0938, 0.0456, 0.1106, 0.1320, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0049, 0.0637, 0.0119, 0.0146, 0.0056, 0.0256, 0.1399, 0.0173, 0.0414,\n",
      "         0.0658, 0.1463, 0.1271, 0.0526, 0.1248, 0.1585, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3.55, Train Loss: 0.00, Val Loss: 5.25, Train BLEU: 0.00, Val BLEU: 4.80, Minutes Elapsed: 330.32\n",
      "Sampling from val predictions...\n",
      "Source: 但是 言语 语词 词汇 对于 政治 中心 之 作用 是非 非常 重要 的 并且 所有 的 政客 都 明白 他们\n",
      "Reference: but it &apos;s very important that words are at the center of politics , and all politicians know they\n",
      "Model: <SOS> but the &apos;s important important , the &apos;s the , , , , , , they are them <EOS>\n",
      "Attention Weights: tensor([[0.2486, 0.0689, 0.0012, 0.0752, 0.4425, 0.0282, 0.0659, 0.0135, 0.0258,\n",
      "         0.0072, 0.0065, 0.0054, 0.0002, 0.0004, 0.0012, 0.0001, 0.0077, 0.0001,\n",
      "         0.0015, 0.0000],\n",
      "        [0.0692, 0.2762, 0.0115, 0.2610, 0.1427, 0.0884, 0.1092, 0.0091, 0.0135,\n",
      "         0.0025, 0.0040, 0.0038, 0.0002, 0.0006, 0.0014, 0.0001, 0.0061, 0.0001,\n",
      "         0.0005, 0.0000],\n",
      "        [0.0078, 0.0088, 0.0039, 0.0726, 0.1710, 0.2650, 0.3024, 0.0478, 0.0409,\n",
      "         0.0139, 0.0242, 0.0206, 0.0014, 0.0030, 0.0050, 0.0005, 0.0104, 0.0002,\n",
      "         0.0006, 0.0001],\n",
      "        [0.0020, 0.0054, 0.0033, 0.0409, 0.1794, 0.1635, 0.1750, 0.0730, 0.0915,\n",
      "         0.0456, 0.1006, 0.0707, 0.0036, 0.0095, 0.0118, 0.0016, 0.0207, 0.0006,\n",
      "         0.0010, 0.0001],\n",
      "        [0.0010, 0.0019, 0.0017, 0.0081, 0.0454, 0.1162, 0.0802, 0.0188, 0.0237,\n",
      "         0.0228, 0.3423, 0.2174, 0.0074, 0.0257, 0.0315, 0.0041, 0.0482, 0.0006,\n",
      "         0.0026, 0.0003],\n",
      "        [0.0015, 0.0023, 0.0022, 0.0076, 0.0444, 0.1762, 0.1603, 0.0227, 0.0286,\n",
      "         0.0208, 0.1723, 0.1454, 0.0119, 0.0492, 0.0564, 0.0045, 0.0867, 0.0013,\n",
      "         0.0052, 0.0005],\n",
      "        [0.0009, 0.0016, 0.0018, 0.0057, 0.0306, 0.2494, 0.2311, 0.0149, 0.0152,\n",
      "         0.0179, 0.0793, 0.0771, 0.0100, 0.0614, 0.0736, 0.0049, 0.1187, 0.0013,\n",
      "         0.0039, 0.0007],\n",
      "        [0.0006, 0.0006, 0.0006, 0.0020, 0.0124, 0.3107, 0.2996, 0.0095, 0.0077,\n",
      "         0.0117, 0.0357, 0.0358, 0.0026, 0.0599, 0.0799, 0.0028, 0.1224, 0.0014,\n",
      "         0.0033, 0.0010],\n",
      "        [0.0004, 0.0009, 0.0009, 0.0032, 0.0161, 0.1233, 0.0959, 0.0128, 0.0207,\n",
      "         0.0440, 0.1078, 0.1050, 0.0053, 0.0875, 0.1402, 0.0097, 0.1992, 0.0037,\n",
      "         0.0195, 0.0036],\n",
      "        [0.0002, 0.0001, 0.0001, 0.0004, 0.0032, 0.1328, 0.0864, 0.0033, 0.0042,\n",
      "         0.0139, 0.0612, 0.0627, 0.0025, 0.0884, 0.2496, 0.0080, 0.2469, 0.0067,\n",
      "         0.0231, 0.0062],\n",
      "        [0.0001, 0.0001, 0.0001, 0.0002, 0.0019, 0.0736, 0.0390, 0.0012, 0.0014,\n",
      "         0.0061, 0.0406, 0.0415, 0.0053, 0.1036, 0.2750, 0.0158, 0.3422, 0.0088,\n",
      "         0.0302, 0.0132],\n",
      "        [0.0004, 0.0003, 0.0003, 0.0007, 0.0029, 0.0861, 0.0838, 0.0036, 0.0030,\n",
      "         0.0099, 0.0260, 0.0389, 0.0075, 0.0909, 0.1949, 0.0144, 0.3542, 0.0270,\n",
      "         0.0419, 0.0133],\n",
      "        [0.0005, 0.0007, 0.0006, 0.0010, 0.0036, 0.0752, 0.0631, 0.0035, 0.0030,\n",
      "         0.0094, 0.0141, 0.0152, 0.0035, 0.0859, 0.1479, 0.0070, 0.3184, 0.0554,\n",
      "         0.1559, 0.0361],\n",
      "        [0.0003, 0.0001, 0.0001, 0.0002, 0.0016, 0.0592, 0.0361, 0.0009, 0.0008,\n",
      "         0.0028, 0.0049, 0.0061, 0.0010, 0.0404, 0.1494, 0.0024, 0.1684, 0.0318,\n",
      "         0.1979, 0.2956],\n",
      "        [0.0007, 0.0002, 0.0002, 0.0005, 0.0028, 0.0291, 0.0282, 0.0025, 0.0021,\n",
      "         0.0075, 0.0125, 0.0147, 0.0038, 0.0513, 0.0983, 0.0066, 0.1459, 0.0931,\n",
      "         0.2923, 0.2079],\n",
      "        [0.0001, 0.0001, 0.0001, 0.0002, 0.0012, 0.0048, 0.0029, 0.0005, 0.0006,\n",
      "         0.0019, 0.0035, 0.0038, 0.0005, 0.0079, 0.0309, 0.0012, 0.0220, 0.0152,\n",
      "         0.1280, 0.7747],\n",
      "        [0.0001, 0.0001, 0.0001, 0.0003, 0.0014, 0.0037, 0.0022, 0.0004, 0.0008,\n",
      "         0.0029, 0.0062, 0.0066, 0.0010, 0.0108, 0.0408, 0.0028, 0.0445, 0.0088,\n",
      "         0.1106, 0.7559],\n",
      "        [0.0002, 0.0002, 0.0002, 0.0007, 0.0035, 0.0057, 0.0041, 0.0013, 0.0018,\n",
      "         0.0057, 0.0114, 0.0102, 0.0021, 0.0111, 0.0252, 0.0049, 0.0212, 0.0177,\n",
      "         0.1274, 0.7454],\n",
      "        [0.0002, 0.0003, 0.0003, 0.0008, 0.0061, 0.0245, 0.0128, 0.0016, 0.0020,\n",
      "         0.0067, 0.0324, 0.0313, 0.0034, 0.0255, 0.0647, 0.0078, 0.0437, 0.0144,\n",
      "         0.0936, 0.6280]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 3.60, Train Loss: 0.00, Val Loss: 5.23, Train BLEU: 0.00, Val BLEU: 5.01, Minutes Elapsed: 335.46\n",
      "Sampling from val predictions...\n",
      "Source: 而且 速度 也 快 最多 多只 只要 30 秒 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: they &apos;re high-speed , take about 30 seconds at most . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> and it be to of &apos;s every . . <EOS> . . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.8435, 0.1427, 0.0039, 0.0038, 0.0034, 0.0002, 0.0024, 0.0000, 0.0000,\n",
      "         0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1731, 0.6974, 0.0230, 0.0519, 0.0388, 0.0037, 0.0068, 0.0019, 0.0010,\n",
      "         0.0024, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2255, 0.3078, 0.1518, 0.1313, 0.0903, 0.0202, 0.0206, 0.0079, 0.0097,\n",
      "         0.0351, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0355, 0.1368, 0.0932, 0.2555, 0.2585, 0.0431, 0.0756, 0.0431, 0.0431,\n",
      "         0.0156, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0210, 0.0798, 0.1444, 0.2504, 0.2066, 0.0472, 0.1413, 0.0477, 0.0453,\n",
      "         0.0163, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0134, 0.0812, 0.1373, 0.1807, 0.1298, 0.0366, 0.1988, 0.0805, 0.1062,\n",
      "         0.0354, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0226, 0.0503, 0.1421, 0.1731, 0.2420, 0.0760, 0.1495, 0.0574, 0.0649,\n",
      "         0.0220, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0023, 0.0074, 0.0165, 0.0320, 0.0717, 0.0526, 0.2942, 0.2113, 0.2770,\n",
      "         0.0349, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0042, 0.0106, 0.0175, 0.0216, 0.0294, 0.0272, 0.2027, 0.1860, 0.4141,\n",
      "         0.0867, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0155, 0.0254, 0.0507, 0.0431, 0.0434, 0.0217, 0.1826, 0.1357, 0.3009,\n",
      "         0.1809, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0223, 0.0440, 0.0510, 0.0583, 0.0569, 0.0225, 0.1186, 0.1347, 0.3003,\n",
      "         0.1915, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0092, 0.0186, 0.0183, 0.0326, 0.0487, 0.0301, 0.0849, 0.1362, 0.3587,\n",
      "         0.2629, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0087, 0.0203, 0.0241, 0.0308, 0.0266, 0.0170, 0.1003, 0.0995, 0.2266,\n",
      "         0.4460, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0172, 0.0298, 0.0475, 0.0570, 0.0787, 0.0332, 0.1422, 0.1430, 0.2682,\n",
      "         0.1833, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0078, 0.0150, 0.0266, 0.0362, 0.0601, 0.0323, 0.1313, 0.1351, 0.2841,\n",
      "         0.2715, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0216, 0.0260, 0.0674, 0.0546, 0.0479, 0.0181, 0.1345, 0.0640, 0.1161,\n",
      "         0.4499, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0240, 0.0330, 0.0640, 0.0598, 0.0537, 0.0175, 0.1285, 0.0530, 0.0981,\n",
      "         0.4682, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0244, 0.0335, 0.0608, 0.0591, 0.0556, 0.0169, 0.1272, 0.0501, 0.0948,\n",
      "         0.4775, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0247, 0.0333, 0.0583, 0.0578, 0.0570, 0.0167, 0.1270, 0.0483, 0.0924,\n",
      "         0.4845, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 3.66, Train Loss: 0.00, Val Loss: 5.23, Train BLEU: 0.00, Val BLEU: 5.08, Minutes Elapsed: 340.60\n",
      "Sampling from val predictions...\n",
      "Source: 讲话 会 变得 <UNK> 而且 之后 伴随 更多 气息 音 这些 都 是 症状 的 例子 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: the speech actually becomes quieter and more <UNK> after a while , and that &apos;s one of the example\n",
      "Model: <SOS> the , is to , , they , , <EOS> . of . . . . . <EOS> .\n",
      "Attention Weights: tensor([[0.6759, 0.3202, 0.0038, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.4333, 0.4260, 0.1354, 0.0024, 0.0015, 0.0008, 0.0002, 0.0002, 0.0000,\n",
      "         0.0000, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0967, 0.4293, 0.3293, 0.0448, 0.0506, 0.0235, 0.0093, 0.0060, 0.0013,\n",
      "         0.0004, 0.0016, 0.0008, 0.0005, 0.0001, 0.0003, 0.0026, 0.0029, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0456, 0.3271, 0.2636, 0.0990, 0.1202, 0.0698, 0.0263, 0.0289, 0.0057,\n",
      "         0.0016, 0.0020, 0.0011, 0.0010, 0.0002, 0.0003, 0.0030, 0.0046, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0036, 0.0117, 0.0918, 0.1115, 0.2797, 0.1610, 0.0818, 0.2110, 0.0241,\n",
      "         0.0029, 0.0045, 0.0011, 0.0006, 0.0005, 0.0007, 0.0096, 0.0040, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0012, 0.0013, 0.0217, 0.0467, 0.3223, 0.1545, 0.0897, 0.2684, 0.0479,\n",
      "         0.0118, 0.0064, 0.0011, 0.0006, 0.0007, 0.0012, 0.0205, 0.0041, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0007, 0.0011, 0.0031, 0.0070, 0.1408, 0.1095, 0.1228, 0.3266, 0.1117,\n",
      "         0.0726, 0.0583, 0.0072, 0.0030, 0.0021, 0.0017, 0.0243, 0.0074, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0006, 0.0011, 0.0011, 0.0007, 0.0133, 0.0121, 0.0226, 0.1174, 0.0302,\n",
      "         0.0282, 0.6244, 0.0591, 0.0211, 0.0146, 0.0040, 0.0401, 0.0092, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0003, 0.0004, 0.0005, 0.0007, 0.0067, 0.0056, 0.0142, 0.0766, 0.0520,\n",
      "         0.0537, 0.3904, 0.1557, 0.0889, 0.0575, 0.0151, 0.0748, 0.0069, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0001, 0.0001, 0.0003, 0.0005, 0.0036, 0.0027, 0.0048, 0.0230, 0.0228,\n",
      "         0.0313, 0.5008, 0.1693, 0.0560, 0.0851, 0.0154, 0.0712, 0.0129, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0004, 0.0007, 0.0014, 0.0005, 0.0058, 0.0050, 0.0061, 0.0119, 0.0043,\n",
      "         0.0040, 0.5857, 0.1301, 0.0666, 0.0995, 0.0102, 0.0523, 0.0156, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0029, 0.0059, 0.0041, 0.0020, 0.0169, 0.0165, 0.0135, 0.0205, 0.0092,\n",
      "         0.0101, 0.4104, 0.1293, 0.0943, 0.1677, 0.0113, 0.0506, 0.0349, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0005, 0.0004, 0.0014, 0.0018, 0.0081, 0.0075, 0.0077, 0.0223, 0.0166,\n",
      "         0.0125, 0.3467, 0.1162, 0.0763, 0.2428, 0.0220, 0.0720, 0.0450, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0006, 0.0008, 0.0015, 0.0020, 0.0066, 0.0082, 0.0075, 0.0174, 0.0131,\n",
      "         0.0111, 0.0778, 0.0394, 0.0576, 0.5168, 0.0235, 0.0910, 0.1252, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0002, 0.0004, 0.0014, 0.0007, 0.0027, 0.0031, 0.0043, 0.0083, 0.0036,\n",
      "         0.0017, 0.0801, 0.0597, 0.1223, 0.4199, 0.0502, 0.1950, 0.0463, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0004, 0.0012, 0.0029, 0.0014, 0.0085, 0.0086, 0.0092, 0.0082, 0.0040,\n",
      "         0.0028, 0.0895, 0.0810, 0.1471, 0.3288, 0.0630, 0.1668, 0.0766, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0001, 0.0001, 0.0007, 0.0005, 0.0020, 0.0022, 0.0027, 0.0094, 0.0029,\n",
      "         0.0012, 0.0401, 0.0141, 0.0228, 0.4977, 0.0420, 0.3032, 0.0584, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0009, 0.0003, 0.0014, 0.0010, 0.0032, 0.0038, 0.0038, 0.0267, 0.0118,\n",
      "         0.0062, 0.0739, 0.0155, 0.0162, 0.4668, 0.0340, 0.1927, 0.1419, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0048, 0.0041, 0.0077, 0.0070, 0.0129, 0.0244, 0.0161, 0.0561, 0.0347,\n",
      "         0.0286, 0.1026, 0.0285, 0.0271, 0.2839, 0.0215, 0.0775, 0.2625, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3.71, Train Loss: 0.00, Val Loss: 5.20, Train BLEU: 0.00, Val BLEU: 5.08, Minutes Elapsed: 345.76\n",
      "Sampling from val predictions...\n",
      "Source: 我们 看 这个 样品 现在 还有 有点 烫 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: so we still have the specimen here . it &apos;s quite warm . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> we we we this this , , this this &apos;s a a . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.8711, 0.1264, 0.0023, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0882, 0.8478, 0.0596, 0.0022, 0.0006, 0.0009, 0.0003, 0.0000, 0.0002,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1507, 0.4926, 0.2912, 0.0243, 0.0108, 0.0131, 0.0097, 0.0008, 0.0068,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1924, 0.3761, 0.2933, 0.0628, 0.0196, 0.0246, 0.0206, 0.0013, 0.0093,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0066, 0.0619, 0.5436, 0.1629, 0.0502, 0.0367, 0.1063, 0.0174, 0.0145,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0086, 0.0194, 0.2817, 0.1768, 0.3283, 0.0776, 0.0768, 0.0087, 0.0220,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0078, 0.0168, 0.1468, 0.0939, 0.4209, 0.1235, 0.1294, 0.0302, 0.0306,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0252, 0.0160, 0.0630, 0.0397, 0.5727, 0.1133, 0.1303, 0.0201, 0.0196,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0413, 0.0413, 0.0543, 0.0360, 0.2860, 0.2270, 0.2445, 0.0455, 0.0241,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0266, 0.0498, 0.0713, 0.0744, 0.1052, 0.1477, 0.3157, 0.1318, 0.0775,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0021, 0.0035, 0.0074, 0.0043, 0.0483, 0.3227, 0.5419, 0.0603, 0.0094,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0008, 0.0006, 0.0038, 0.0019, 0.0194, 0.0611, 0.6368, 0.2672, 0.0084,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0022, 0.0018, 0.0066, 0.0047, 0.0298, 0.0278, 0.3613, 0.5296, 0.0363,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0154, 0.0065, 0.0251, 0.0160, 0.0406, 0.0191, 0.1502, 0.5129, 0.2143,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0572, 0.0525, 0.1094, 0.1047, 0.0628, 0.0279, 0.0787, 0.1385, 0.3682,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0063, 0.0153, 0.0331, 0.0315, 0.0654, 0.1481, 0.3224, 0.1854, 0.1925,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0039, 0.0119, 0.0269, 0.0178, 0.0652, 0.1129, 0.2597, 0.1992, 0.3025,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0161, 0.0211, 0.0569, 0.0157, 0.1447, 0.0692, 0.1851, 0.1427, 0.3483,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0262, 0.0429, 0.0798, 0.0188, 0.1819, 0.0968, 0.2030, 0.0816, 0.2690,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 3.77, Train Loss: 0.00, Val Loss: 5.33, Train BLEU: 0.00, Val BLEU: 5.32, Minutes Elapsed: 350.91\n",
      "Sampling from val predictions...\n",
      "Source: 举例 举例来说 来说 一直 直到 <UNK> 年 英国 <UNK> <UNK> 议会 才 允许 新闻 闻报 报纸 报道 在 辩论 <UNK>\n",
      "Reference: it wasn &apos;t until , for example , <UNK> that the british parliament allowed newspapers to report the exact\n",
      "Model: <SOS> question problem not , to the , , , the , the of . <EOS> . <EOS> . <EOS>\n",
      "Attention Weights: tensor([[8.9166e-01, 9.2324e-02, 1.5863e-02, 6.4984e-05, 4.2876e-06, 9.5611e-07,\n",
      "         1.0777e-05, 1.6480e-05, 4.4489e-07, 3.7060e-06, 4.5366e-05, 5.0558e-06,\n",
      "         3.6055e-06, 1.2805e-07, 2.2019e-08, 1.7045e-07, 1.8503e-07, 5.3466e-08,\n",
      "         4.6081e-08, 4.7797e-09],\n",
      "        [2.3570e-01, 4.9208e-01, 2.4457e-01, 1.3507e-02, 9.2863e-04, 2.7773e-04,\n",
      "         1.3305e-03, 1.5970e-03, 1.2914e-04, 7.2785e-04, 6.8268e-03, 1.4761e-03,\n",
      "         6.1738e-04, 3.6156e-05, 8.0427e-06, 7.1918e-05, 5.6150e-05, 4.1334e-05,\n",
      "         1.5697e-05, 1.8435e-06],\n",
      "        [2.0285e-02, 1.7381e-01, 2.2823e-01, 2.2442e-01, 4.4329e-02, 1.9200e-02,\n",
      "         3.3246e-02, 6.7500e-02, 7.1552e-03, 2.5271e-02, 1.2279e-01, 1.5440e-02,\n",
      "         1.3505e-02, 1.5573e-03, 3.2989e-04, 9.9738e-04, 1.0120e-03, 4.2329e-04,\n",
      "         4.3963e-04, 6.2298e-05],\n",
      "        [6.4847e-03, 3.3974e-02, 9.5751e-02, 2.7845e-01, 1.0333e-01, 4.9135e-02,\n",
      "         5.8807e-02, 1.1835e-01, 1.1706e-02, 3.1891e-02, 1.3318e-01, 1.1814e-02,\n",
      "         3.2216e-02, 1.6605e-02, 2.0989e-03, 5.1015e-03, 4.9520e-03, 1.5453e-03,\n",
      "         4.1440e-03, 4.6366e-04],\n",
      "        [2.6510e-03, 1.0746e-02, 2.1107e-02, 1.0904e-01, 7.9218e-02, 4.9212e-02,\n",
      "         7.2781e-02, 2.4468e-01, 1.2382e-02, 3.2742e-02, 2.0603e-01, 2.4419e-02,\n",
      "         5.4835e-02, 4.3520e-02, 3.5273e-03, 1.4168e-02, 8.3930e-03, 2.6399e-03,\n",
      "         7.3612e-03, 5.4239e-04],\n",
      "        [1.3323e-03, 4.3354e-03, 5.7633e-03, 5.8123e-02, 7.1029e-02, 4.2752e-02,\n",
      "         1.0711e-01, 2.7315e-01, 1.5320e-02, 2.9695e-02, 1.5782e-01, 2.5957e-02,\n",
      "         4.7733e-02, 7.0210e-02, 6.5786e-03, 4.3775e-02, 1.5644e-02, 8.4781e-03,\n",
      "         1.4449e-02, 7.3451e-04],\n",
      "        [2.9589e-03, 5.8922e-03, 5.0749e-03, 3.1200e-02, 4.4565e-02, 2.6937e-02,\n",
      "         1.2190e-01, 3.2267e-01, 1.1739e-02, 2.6522e-02, 1.6899e-01, 3.2345e-02,\n",
      "         4.6066e-02, 5.0966e-02, 3.9133e-03, 6.2602e-02, 1.4745e-02, 9.4536e-03,\n",
      "         1.1113e-02, 3.4498e-04],\n",
      "        [8.2975e-04, 3.3126e-03, 4.4088e-03, 2.8619e-02, 3.3865e-02, 2.6089e-02,\n",
      "         4.2605e-02, 1.3371e-01, 1.0552e-02, 2.8424e-02, 2.1326e-01, 7.9347e-02,\n",
      "         2.1832e-01, 7.6792e-02, 8.5275e-03, 4.7221e-02, 2.5340e-02, 6.5484e-03,\n",
      "         1.1550e-02, 6.7024e-04],\n",
      "        [2.4096e-04, 3.7386e-04, 1.1740e-03, 1.1671e-02, 1.9571e-02, 1.3458e-02,\n",
      "         4.9995e-02, 1.3744e-01, 1.4014e-02, 2.5715e-02, 1.1368e-01, 1.5846e-01,\n",
      "         1.8050e-01, 4.0607e-02, 1.3215e-02, 1.1966e-01, 4.0411e-02, 3.3480e-02,\n",
      "         2.4859e-02, 1.4777e-03],\n",
      "        [2.8440e-04, 5.3486e-04, 1.0661e-03, 7.5475e-03, 9.0112e-03, 9.0096e-03,\n",
      "         2.0801e-02, 7.3558e-02, 5.3592e-03, 9.2050e-03, 5.4701e-02, 7.5730e-02,\n",
      "         1.5242e-01, 1.0668e-01, 1.2913e-02, 2.2047e-01, 5.6377e-02, 5.7744e-02,\n",
      "         1.1965e-01, 6.9315e-03],\n",
      "        [1.0767e-04, 4.1252e-04, 9.0786e-04, 3.7029e-03, 4.1750e-03, 3.4849e-03,\n",
      "         3.5442e-03, 1.9891e-02, 1.9314e-03, 3.2961e-03, 2.7132e-02, 2.4459e-02,\n",
      "         1.7818e-01, 1.4625e-01, 2.2828e-02, 2.0597e-01, 1.1623e-01, 6.0509e-02,\n",
      "         1.5890e-01, 1.8089e-02],\n",
      "        [1.7281e-04, 3.4137e-04, 1.1968e-03, 4.3912e-03, 3.2952e-03, 1.8752e-03,\n",
      "         3.1961e-03, 6.5916e-03, 7.0492e-04, 1.3317e-03, 8.4833e-03, 2.1212e-02,\n",
      "         4.3407e-02, 8.0062e-02, 8.3501e-03, 1.4162e-01, 7.1580e-02, 1.3986e-01,\n",
      "         4.2400e-01, 3.8331e-02],\n",
      "        [4.0907e-05, 1.5016e-04, 4.3847e-04, 2.5341e-03, 2.8636e-03, 1.7559e-03,\n",
      "         1.9843e-03, 4.4287e-03, 3.6123e-04, 5.9437e-04, 2.6031e-03, 1.3239e-03,\n",
      "         6.9994e-03, 8.9325e-02, 8.5755e-03, 8.2599e-02, 4.4518e-02, 5.2265e-02,\n",
      "         5.5512e-01, 1.4152e-01],\n",
      "        [1.9264e-04, 3.8952e-04, 7.6398e-04, 8.2989e-03, 1.2418e-02, 1.1550e-02,\n",
      "         1.5483e-02, 3.8489e-02, 4.5921e-03, 6.6656e-03, 2.0487e-02, 4.9591e-03,\n",
      "         2.3940e-02, 6.0929e-02, 1.3119e-02, 1.0309e-01, 5.8932e-02, 7.9215e-02,\n",
      "         4.0191e-01, 1.3457e-01],\n",
      "        [6.5192e-04, 1.6153e-03, 2.4891e-03, 2.5205e-02, 3.1082e-02, 2.1229e-02,\n",
      "         3.3409e-02, 6.0238e-02, 7.0709e-03, 1.0714e-02, 3.9586e-02, 2.1238e-02,\n",
      "         3.9673e-02, 9.6497e-02, 1.4652e-02, 1.0163e-01, 5.1294e-02, 8.6465e-02,\n",
      "         2.7310e-01, 8.2167e-02],\n",
      "        [1.7414e-03, 4.3582e-03, 9.9254e-03, 4.4471e-02, 4.2206e-02, 2.1837e-02,\n",
      "         4.7650e-02, 9.1719e-02, 7.1535e-03, 1.1525e-02, 6.1190e-02, 3.5640e-02,\n",
      "         5.4696e-02, 1.1260e-01, 1.3644e-02, 1.0921e-01, 6.1451e-02, 7.9825e-02,\n",
      "         1.6009e-01, 2.9061e-02],\n",
      "        [2.1366e-03, 4.1223e-03, 6.4662e-03, 4.0877e-02, 5.6429e-02, 2.8545e-02,\n",
      "         5.4147e-02, 1.2235e-01, 5.2637e-03, 8.6353e-03, 4.3588e-02, 1.0582e-02,\n",
      "         1.5198e-02, 1.4155e-01, 1.4389e-02, 1.5561e-01, 5.4540e-02, 5.6524e-02,\n",
      "         1.5814e-01, 2.0901e-02],\n",
      "        [5.3355e-03, 7.3301e-03, 1.5416e-02, 5.6515e-02, 5.2262e-02, 2.6836e-02,\n",
      "         5.4332e-02, 1.3872e-01, 7.1572e-03, 1.2798e-02, 7.1156e-02, 2.2796e-02,\n",
      "         2.9695e-02, 1.2900e-01, 1.1918e-02, 1.3237e-01, 5.0536e-02, 5.7847e-02,\n",
      "         1.0789e-01, 1.0086e-02],\n",
      "        [3.6928e-03, 5.4217e-03, 8.8512e-03, 3.6534e-02, 5.9690e-02, 3.3901e-02,\n",
      "         7.3537e-02, 1.0778e-01, 7.6627e-03, 1.2667e-02, 4.5338e-02, 7.5838e-03,\n",
      "         1.2781e-02, 1.6578e-01, 2.7863e-02, 1.4302e-01, 8.5671e-02, 5.0748e-02,\n",
      "         9.4327e-02, 1.7155e-02]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3.82, Train Loss: 0.00, Val Loss: 5.23, Train BLEU: 0.00, Val BLEU: 4.84, Minutes Elapsed: 356.06\n",
      "Sampling from val predictions...\n",
      "Source: 然而 与 创业 创业者 业者 打交道 交道 有 个 秘诀 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: however , there is a secret to work with entrepreneurs . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> but , a , a of of of a the . <EOS> <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.6436, 0.1390, 0.1464, 0.0128, 0.0205, 0.0074, 0.0015, 0.0061, 0.0037,\n",
      "         0.0057, 0.0133, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1458, 0.1639, 0.4889, 0.0273, 0.0538, 0.0335, 0.0090, 0.0118, 0.0108,\n",
      "         0.0264, 0.0289, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0693, 0.0495, 0.2140, 0.0390, 0.0716, 0.0840, 0.0513, 0.0899, 0.0967,\n",
      "         0.1151, 0.1197, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0230, 0.0229, 0.2105, 0.0249, 0.0589, 0.0903, 0.0790, 0.1161, 0.1376,\n",
      "         0.1623, 0.0745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0339, 0.0263, 0.2110, 0.0461, 0.1311, 0.1317, 0.0832, 0.1088, 0.0842,\n",
      "         0.0962, 0.0476, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0265, 0.0255, 0.2403, 0.0233, 0.0646, 0.1287, 0.1116, 0.1475, 0.1089,\n",
      "         0.1018, 0.0211, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0449, 0.0418, 0.2838, 0.0451, 0.1216, 0.1163, 0.0672, 0.0844, 0.0428,\n",
      "         0.0843, 0.0679, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0385, 0.0255, 0.2753, 0.0419, 0.1447, 0.1570, 0.0814, 0.0839, 0.0271,\n",
      "         0.0635, 0.0613, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0351, 0.0458, 0.3909, 0.0598, 0.1682, 0.1499, 0.0576, 0.0307, 0.0102,\n",
      "         0.0144, 0.0374, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0171, 0.0181, 0.3030, 0.0411, 0.1288, 0.1954, 0.1202, 0.0540, 0.0312,\n",
      "         0.0457, 0.0453, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0213, 0.0221, 0.3354, 0.0428, 0.1348, 0.1866, 0.1220, 0.0324, 0.0230,\n",
      "         0.0268, 0.0529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0193, 0.0260, 0.2977, 0.0609, 0.1511, 0.1693, 0.1094, 0.0207, 0.0104,\n",
      "         0.0195, 0.1157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0429, 0.0388, 0.2813, 0.0330, 0.0836, 0.1351, 0.1041, 0.0265, 0.0188,\n",
      "         0.0240, 0.2119, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0138, 0.0165, 0.0962, 0.0240, 0.0489, 0.1486, 0.1798, 0.1222, 0.0829,\n",
      "         0.0600, 0.2071, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0104, 0.0104, 0.0576, 0.0155, 0.0330, 0.1260, 0.1692, 0.1110, 0.0892,\n",
      "         0.0712, 0.3066, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0217, 0.0127, 0.0591, 0.0151, 0.0304, 0.1331, 0.1588, 0.0867, 0.0691,\n",
      "         0.0410, 0.3722, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0237, 0.0131, 0.0695, 0.0167, 0.0321, 0.1111, 0.1377, 0.0953, 0.0869,\n",
      "         0.0423, 0.3716, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0241, 0.0131, 0.0691, 0.0174, 0.0332, 0.1127, 0.1367, 0.0933, 0.0878,\n",
      "         0.0406, 0.3720, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0245, 0.0130, 0.0673, 0.0173, 0.0328, 0.1131, 0.1366, 0.0916, 0.0875,\n",
      "         0.0411, 0.3752, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 3.88, Train Loss: 0.00, Val Loss: 5.25, Train BLEU: 0.00, Val BLEU: 4.91, Minutes Elapsed: 361.20\n",
      "Sampling from val predictions...\n",
      "Source: 当 西红柿 成熟 了 <UNK> 的 好看 极了 一夜 一夜之间 之间 从 <UNK> <UNK> <UNK> 跑 来 两百 两百多 百多\n",
      "Reference: when the tomatoes were nice and ripe and red , overnight , some 200 <UNK> came out from the\n",
      "Model: <SOS> when the the of the , , , , , , , years years years . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[3.8519e-01, 3.7724e-01, 7.4080e-02, 1.4888e-02, 7.3501e-03, 3.4210e-02,\n",
      "         1.0405e-01, 2.2357e-03, 1.1860e-04, 4.3110e-04, 6.9682e-05, 2.4176e-05,\n",
      "         1.9113e-06, 2.2969e-06, 6.6522e-06, 5.6412e-05, 2.1088e-05, 1.6706e-05,\n",
      "         7.2587e-06, 4.6658e-06],\n",
      "        [2.4455e-02, 6.1830e-01, 1.8352e-01, 2.1039e-02, 6.4796e-02, 1.3128e-02,\n",
      "         6.5988e-02, 4.2602e-03, 1.8850e-03, 1.5504e-03, 3.1722e-04, 1.4767e-04,\n",
      "         3.5316e-05, 3.7284e-05, 7.9968e-05, 1.6047e-04, 5.5591e-05, 1.6339e-04,\n",
      "         5.8969e-05, 2.2683e-05],\n",
      "        [1.3877e-02, 3.1216e-01, 1.8167e-01, 6.3555e-02, 2.1658e-01, 3.4592e-02,\n",
      "         1.2617e-01, 2.5133e-02, 1.3426e-02, 8.1292e-03, 1.4739e-03, 5.8153e-04,\n",
      "         1.9623e-04, 1.8462e-04, 3.6554e-04, 5.0986e-04, 1.8837e-04, 6.0496e-04,\n",
      "         3.7484e-04, 2.2015e-04],\n",
      "        [5.5671e-03, 1.1656e-01, 1.7584e-01, 7.6963e-02, 2.3428e-01, 5.2752e-02,\n",
      "         2.1718e-01, 5.7706e-02, 3.0927e-02, 2.0465e-02, 4.9108e-03, 1.8380e-03,\n",
      "         3.3944e-04, 3.3375e-04, 7.3152e-04, 1.0064e-03, 4.2236e-04, 1.1053e-03,\n",
      "         6.4943e-04, 4.2221e-04],\n",
      "        [6.0606e-03, 4.3514e-02, 4.6280e-02, 8.6485e-02, 2.2423e-01, 7.8423e-02,\n",
      "         2.1610e-01, 2.0748e-01, 3.9386e-02, 2.9966e-02, 1.0494e-02, 5.9411e-03,\n",
      "         5.3713e-04, 5.0650e-04, 1.2270e-03, 2.1416e-03, 6.7756e-04, 2.7240e-04,\n",
      "         1.6950e-04, 1.0013e-04],\n",
      "        [4.7740e-04, 6.7098e-03, 3.8625e-03, 6.1220e-03, 2.7035e-02, 7.4398e-03,\n",
      "         5.7183e-02, 2.0815e-01, 3.1025e-01, 2.0145e-01, 7.9683e-02, 3.7469e-02,\n",
      "         7.0345e-03, 5.1575e-03, 8.9977e-03, 1.3078e-02, 3.5284e-03, 8.6405e-03,\n",
      "         4.8483e-03, 2.8918e-03],\n",
      "        [1.1900e-04, 2.7344e-03, 2.3227e-03, 3.4820e-03, 1.3882e-02, 6.7991e-03,\n",
      "         4.5332e-02, 1.7657e-01, 1.9960e-01, 2.0967e-01, 1.2994e-01, 8.1922e-02,\n",
      "         1.8847e-02, 1.4386e-02, 2.5037e-02, 3.4439e-02, 7.3869e-03, 1.7022e-02,\n",
      "         6.8210e-03, 3.6994e-03],\n",
      "        [2.0704e-04, 4.1353e-03, 1.9755e-03, 1.6195e-03, 6.9216e-03, 2.7554e-03,\n",
      "         1.0905e-02, 5.5104e-02, 1.4795e-01, 1.6179e-01, 1.0702e-01, 1.3298e-01,\n",
      "         5.0662e-02, 3.9458e-02, 6.5471e-02, 8.9938e-02, 2.0383e-02, 6.0596e-02,\n",
      "         2.7491e-02, 1.2635e-02],\n",
      "        [1.2808e-04, 1.1905e-03, 6.5251e-04, 5.4496e-04, 1.6312e-03, 6.2720e-04,\n",
      "         1.7934e-03, 6.9746e-03, 3.9438e-02, 3.4344e-02, 4.0942e-02, 7.5445e-02,\n",
      "         5.4542e-02, 5.3678e-02, 9.0341e-02, 1.0368e-01, 6.1232e-02, 2.2923e-01,\n",
      "         1.3278e-01, 7.0806e-02],\n",
      "        [3.1448e-05, 4.8651e-04, 3.0471e-04, 2.6209e-04, 6.5874e-04, 4.1450e-04,\n",
      "         8.8940e-04, 2.5194e-03, 8.4670e-03, 9.9321e-03, 7.5798e-03, 1.6988e-02,\n",
      "         1.5908e-02, 1.6319e-02, 2.5595e-02, 3.6612e-02, 2.7276e-02, 4.1933e-01,\n",
      "         2.8027e-01, 1.3015e-01],\n",
      "        [2.5956e-05, 3.4606e-04, 2.8601e-04, 2.0410e-04, 3.8998e-04, 1.7482e-04,\n",
      "         3.7503e-04, 6.9301e-04, 3.9796e-03, 2.8054e-03, 2.9652e-03, 7.2471e-03,\n",
      "         9.3946e-03, 9.8866e-03, 1.4169e-02, 1.1281e-02, 1.2818e-02, 3.0181e-01,\n",
      "         3.7231e-01, 2.4884e-01],\n",
      "        [2.3233e-05, 4.4406e-04, 3.8893e-04, 2.0639e-04, 5.8741e-04, 3.1312e-04,\n",
      "         7.6016e-04, 1.1538e-03, 3.9335e-03, 2.8513e-03, 1.5860e-03, 2.4969e-03,\n",
      "         4.5329e-03, 4.7808e-03, 5.9269e-03, 4.8839e-03, 3.9632e-03, 2.5219e-01,\n",
      "         4.0995e-01, 2.9903e-01],\n",
      "        [3.8345e-05, 4.5292e-04, 4.5487e-04, 2.8422e-04, 4.7778e-04, 1.9672e-04,\n",
      "         5.1157e-04, 6.4444e-04, 3.3646e-03, 2.4317e-03, 2.4324e-03, 4.0435e-03,\n",
      "         4.7290e-03, 4.9023e-03, 6.6875e-03, 4.3135e-03, 4.8531e-03, 2.9304e-01,\n",
      "         3.9963e-01, 2.6651e-01],\n",
      "        [1.0796e-04, 1.2740e-03, 1.1410e-03, 7.2012e-04, 1.4884e-03, 1.0769e-03,\n",
      "         2.1274e-03, 2.7876e-03, 8.1644e-03, 5.2335e-03, 3.2822e-03, 4.2721e-03,\n",
      "         5.8253e-03, 5.9521e-03, 7.0311e-03, 6.8768e-03, 4.6391e-03, 2.8080e-01,\n",
      "         3.7697e-01, 2.8023e-01],\n",
      "        [7.8840e-05, 8.7479e-04, 7.4134e-04, 5.7188e-04, 7.8174e-04, 4.2148e-04,\n",
      "         9.1703e-04, 1.2275e-03, 5.0527e-03, 3.5497e-03, 2.5506e-03, 2.8042e-03,\n",
      "         3.1377e-03, 3.2226e-03, 3.9537e-03, 2.7790e-03, 2.5750e-03, 2.8867e-01,\n",
      "         4.0589e-01, 2.7020e-01],\n",
      "        [1.9369e-04, 1.5854e-03, 2.3961e-03, 1.0895e-03, 2.3456e-03, 1.0444e-03,\n",
      "         2.9074e-03, 2.5725e-03, 1.5246e-02, 9.4806e-03, 3.8781e-03, 4.3577e-03,\n",
      "         7.1118e-03, 7.4204e-03, 8.6277e-03, 7.1728e-03, 3.0032e-03, 2.7254e-01,\n",
      "         4.0209e-01, 2.4494e-01],\n",
      "        [1.1068e-03, 8.3480e-03, 6.5210e-03, 5.7277e-03, 7.6403e-03, 4.8678e-03,\n",
      "         1.0498e-02, 1.7660e-02, 3.4055e-02, 2.2591e-02, 1.5033e-02, 1.8160e-02,\n",
      "         1.4159e-02, 1.4083e-02, 1.8059e-02, 2.2867e-02, 1.2851e-02, 3.5516e-01,\n",
      "         2.7157e-01, 1.3905e-01],\n",
      "        [2.4813e-03, 1.7860e-02, 8.7573e-03, 8.5147e-03, 1.0477e-02, 8.4497e-03,\n",
      "         1.5376e-02, 3.1116e-02, 5.3932e-02, 3.3979e-02, 2.0022e-02, 2.4029e-02,\n",
      "         1.3774e-02, 1.3651e-02, 1.8816e-02, 2.6442e-02, 1.8583e-02, 3.5007e-01,\n",
      "         2.2367e-01, 9.9999e-02],\n",
      "        [2.3604e-03, 2.1695e-02, 2.2775e-02, 1.3718e-02, 1.8592e-02, 1.3072e-02,\n",
      "         2.9364e-02, 2.6463e-02, 8.1397e-02, 4.4794e-02, 2.4862e-02, 2.2378e-02,\n",
      "         2.0073e-02, 1.8929e-02, 2.1965e-02, 2.8500e-02, 1.1677e-02, 3.0684e-01,\n",
      "         1.8770e-01, 8.2853e-02]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3.93, Train Loss: 0.00, Val Loss: 5.34, Train BLEU: 0.00, Val BLEU: 4.65, Minutes Elapsed: 366.35\n",
      "Sampling from val predictions...\n",
      "Source: 康 纳 第一 第一次 一次 打 我 是 在 我们 婚礼 的 五天 前 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: <UNK> first physically attacked me five days before our wedding . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> the : : , i i the ago <EOS> . . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0074, 0.0377, 0.6804, 0.1295, 0.1122, 0.0098, 0.0191, 0.0006, 0.0002,\n",
      "         0.0006, 0.0000, 0.0001, 0.0012, 0.0006, 0.0006, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0088, 0.0513, 0.8472, 0.0734, 0.0156, 0.0011, 0.0022, 0.0001, 0.0000,\n",
      "         0.0001, 0.0000, 0.0000, 0.0001, 0.0000, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0068, 0.0428, 0.5855, 0.1789, 0.1301, 0.0354, 0.0120, 0.0014, 0.0003,\n",
      "         0.0005, 0.0001, 0.0003, 0.0016, 0.0006, 0.0037, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0006, 0.0048, 0.1459, 0.1342, 0.2621, 0.1208, 0.2277, 0.0394, 0.0089,\n",
      "         0.0214, 0.0038, 0.0020, 0.0188, 0.0026, 0.0070, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0009, 0.0044, 0.0309, 0.0247, 0.0851, 0.1216, 0.5520, 0.0742, 0.0194,\n",
      "         0.0405, 0.0083, 0.0023, 0.0239, 0.0029, 0.0089, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0006, 0.0025, 0.0184, 0.0106, 0.0218, 0.0314, 0.3224, 0.1373, 0.0537,\n",
      "         0.2361, 0.0424, 0.0078, 0.0817, 0.0107, 0.0224, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0005, 0.0016, 0.0131, 0.0080, 0.0117, 0.0125, 0.1717, 0.0976, 0.0500,\n",
      "         0.2956, 0.1200, 0.0107, 0.1683, 0.0186, 0.0203, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0002, 0.0007, 0.0086, 0.0064, 0.0050, 0.0015, 0.0151, 0.0069, 0.0183,\n",
      "         0.2723, 0.3085, 0.0118, 0.3118, 0.0218, 0.0111, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0019, 0.0034, 0.0179, 0.0133, 0.0142, 0.0032, 0.0212, 0.0042, 0.0093,\n",
      "         0.1755, 0.3495, 0.0065, 0.3275, 0.0308, 0.0216, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0011, 0.0051, 0.0374, 0.0169, 0.0112, 0.0026, 0.0183, 0.0036, 0.0075,\n",
      "         0.2553, 0.3609, 0.0039, 0.2163, 0.0259, 0.0340, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0015, 0.0049, 0.0290, 0.0188, 0.0149, 0.0031, 0.0088, 0.0069, 0.0119,\n",
      "         0.1604, 0.3834, 0.0064, 0.2869, 0.0400, 0.0230, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0018, 0.0033, 0.0138, 0.0110, 0.0099, 0.0020, 0.0032, 0.0037, 0.0125,\n",
      "         0.1015, 0.3606, 0.0084, 0.3897, 0.0493, 0.0293, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0011, 0.0040, 0.0282, 0.0170, 0.0123, 0.0025, 0.0133, 0.0039, 0.0126,\n",
      "         0.1723, 0.3412, 0.0065, 0.2186, 0.0632, 0.1033, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0001, 0.0005, 0.0065, 0.0049, 0.0043, 0.0009, 0.0048, 0.0096, 0.0213,\n",
      "         0.2739, 0.1976, 0.0225, 0.3302, 0.0879, 0.0349, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0003, 0.0032, 0.0026, 0.0021, 0.0005, 0.0049, 0.0067, 0.0197,\n",
      "         0.2228, 0.1953, 0.0215, 0.3391, 0.1256, 0.0556, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0002, 0.0008, 0.0086, 0.0060, 0.0039, 0.0011, 0.0188, 0.0078, 0.0202,\n",
      "         0.2316, 0.2157, 0.0135, 0.2385, 0.0966, 0.1368, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0005, 0.0017, 0.0162, 0.0100, 0.0055, 0.0014, 0.0237, 0.0083, 0.0161,\n",
      "         0.2473, 0.1914, 0.0100, 0.2013, 0.0841, 0.1826, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0007, 0.0026, 0.0240, 0.0141, 0.0075, 0.0017, 0.0287, 0.0089, 0.0158,\n",
      "         0.2427, 0.1869, 0.0090, 0.1829, 0.0751, 0.1995, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0011, 0.0036, 0.0308, 0.0179, 0.0094, 0.0020, 0.0331, 0.0094, 0.0163,\n",
      "         0.2267, 0.1805, 0.0088, 0.1708, 0.0708, 0.2191, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 3.99, Train Loss: 0.00, Val Loss: 5.20, Train BLEU: 0.00, Val BLEU: 4.87, Minutes Elapsed: 371.49\n",
      "Sampling from val predictions...\n",
      "Source: 而且 仅仅 几年 年后 我们 有 了 第一 第一次 一次 记录 使用 短语 <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>\n",
      "Reference: and it was only a few years later that we have the first recorded use of the phrase &quot;\n",
      "Model: <SOS> and , , been a first of of , <UNK> <UNK> to <UNK> <UNK> <UNK> . . . .\n",
      "Attention Weights: tensor([[3.2574e-02, 9.1851e-01, 3.7070e-02, 3.4314e-03, 3.4086e-03, 3.2121e-04,\n",
      "         1.8480e-04, 3.3342e-03, 6.0144e-04, 3.1356e-04, 1.4802e-04, 7.2368e-05,\n",
      "         4.2235e-06, 2.9445e-06, 3.3529e-06, 3.6693e-06, 3.6570e-06, 3.5133e-06,\n",
      "         3.6945e-06, 6.9714e-06],\n",
      "        [6.0758e-03, 8.2513e-01, 1.3425e-01, 1.5029e-02, 6.7608e-03, 1.3078e-03,\n",
      "         4.9524e-04, 9.0488e-03, 1.0824e-03, 3.3577e-04, 2.2868e-04, 1.5592e-04,\n",
      "         1.1511e-05, 1.1162e-05, 1.1655e-05, 1.2274e-05, 1.2090e-05, 1.1511e-05,\n",
      "         1.1476e-05, 1.6455e-05],\n",
      "        [4.4426e-03, 2.3990e-01, 4.3802e-01, 8.0044e-02, 4.5234e-02, 3.0677e-02,\n",
      "         2.9214e-02, 1.0694e-01, 1.4082e-02, 4.1983e-03, 1.8641e-03, 2.0943e-03,\n",
      "         5.2440e-04, 4.7396e-04, 4.2973e-04, 4.1356e-04, 3.8734e-04, 3.5640e-04,\n",
      "         3.3585e-04, 3.7151e-04],\n",
      "        [3.7984e-03, 1.4981e-01, 3.2307e-01, 7.9686e-02, 9.8637e-02, 7.5226e-02,\n",
      "         6.4804e-02, 1.6196e-01, 2.4953e-02, 8.4606e-03, 3.6026e-03, 3.0115e-03,\n",
      "         6.0686e-04, 4.3023e-04, 3.7468e-04, 3.5439e-04, 3.2896e-04, 2.9976e-04,\n",
      "         2.7836e-04, 3.0649e-04],\n",
      "        [8.1576e-04, 2.9392e-03, 6.2275e-02, 3.0947e-02, 5.5045e-02, 8.6477e-03,\n",
      "         2.0952e-02, 6.2121e-01, 1.1562e-01, 4.3738e-02, 1.4317e-02, 9.9533e-03,\n",
      "         2.8850e-03, 2.1249e-03, 1.6847e-03, 1.5421e-03, 1.4241e-03, 1.3112e-03,\n",
      "         1.2286e-03, 1.3331e-03],\n",
      "        [5.4323e-04, 2.8341e-03, 4.7946e-02, 3.4044e-02, 6.6191e-02, 4.9009e-03,\n",
      "         1.6275e-02, 4.6987e-01, 1.4209e-01, 7.9396e-02, 3.4639e-02, 4.2897e-02,\n",
      "         1.1114e-02, 9.4415e-03, 7.6694e-03, 7.0286e-03, 6.4358e-03, 5.8145e-03,\n",
      "         5.2798e-03, 5.5939e-03],\n",
      "        [6.8588e-04, 4.5763e-03, 7.1869e-02, 4.3790e-02, 9.0187e-02, 3.1043e-03,\n",
      "         7.4028e-03, 2.2181e-01, 8.8389e-02, 7.8207e-02, 4.6183e-02, 1.5906e-01,\n",
      "         3.3469e-02, 3.5084e-02, 2.7132e-02, 2.3607e-02, 2.0302e-02, 1.7082e-02,\n",
      "         1.4349e-02, 1.3715e-02],\n",
      "        [8.4482e-04, 1.4464e-02, 9.4959e-02, 3.8397e-02, 8.5103e-02, 3.0433e-03,\n",
      "         3.6156e-03, 2.9400e-02, 3.0401e-02, 5.5744e-02, 3.0429e-02, 3.3435e-01,\n",
      "         4.3424e-02, 5.7426e-02, 4.5714e-02, 3.9215e-02, 3.2015e-02, 2.4852e-02,\n",
      "         1.9140e-02, 1.7466e-02],\n",
      "        [4.4656e-04, 5.7916e-03, 6.9629e-02, 3.1489e-02, 6.6517e-02, 1.2605e-03,\n",
      "         2.1226e-03, 2.6821e-02, 2.2195e-02, 3.4489e-02, 2.5405e-02, 3.7332e-01,\n",
      "         4.8945e-02, 7.3545e-02, 5.8830e-02, 4.9587e-02, 3.9123e-02, 2.9029e-02,\n",
      "         2.1416e-02, 2.0041e-02],\n",
      "        [5.2260e-04, 6.4416e-03, 8.6918e-02, 3.0693e-02, 9.0192e-02, 2.1953e-03,\n",
      "         4.6669e-03, 4.0080e-02, 1.3531e-02, 1.4827e-02, 2.2417e-02, 3.8883e-01,\n",
      "         3.6131e-02, 6.3674e-02, 5.1100e-02, 4.3086e-02, 3.4679e-02, 2.6591e-02,\n",
      "         2.0716e-02, 2.2705e-02],\n",
      "        [3.3896e-04, 4.8637e-03, 7.3177e-02, 3.0819e-02, 7.8919e-02, 2.0038e-03,\n",
      "         6.3839e-03, 4.7756e-02, 1.4484e-02, 1.5466e-02, 2.2562e-02, 2.2615e-01,\n",
      "         3.9256e-02, 8.6677e-02, 7.8967e-02, 7.1902e-02, 6.1346e-02, 4.9465e-02,\n",
      "         4.0687e-02, 4.8771e-02],\n",
      "        [1.0186e-04, 1.7510e-03, 4.1293e-02, 2.0943e-02, 2.8771e-02, 2.0763e-03,\n",
      "         9.5652e-03, 5.8802e-02, 2.1193e-02, 2.5921e-02, 2.4700e-02, 1.8519e-01,\n",
      "         4.9152e-02, 1.0434e-01, 9.5967e-02, 8.5346e-02, 7.2212e-02, 5.9074e-02,\n",
      "         5.0553e-02, 6.3047e-02],\n",
      "        [2.3832e-04, 7.5944e-04, 9.0929e-03, 5.2753e-03, 2.6121e-03, 1.5507e-03,\n",
      "         6.0908e-03, 9.3673e-02, 3.4627e-02, 3.1255e-02, 2.2872e-02, 1.0926e-01,\n",
      "         5.9498e-02, 1.3284e-01, 1.1980e-01, 1.0471e-01, 8.7268e-02, 6.9544e-02,\n",
      "         5.5236e-02, 5.3784e-02],\n",
      "        [3.6291e-04, 9.8014e-04, 9.9329e-03, 5.8520e-03, 3.7701e-03, 1.0414e-03,\n",
      "         5.5033e-03, 1.1307e-01, 5.5182e-02, 5.3525e-02, 1.9494e-02, 5.2966e-02,\n",
      "         3.7029e-02, 8.3579e-02, 9.9077e-02, 1.0544e-01, 1.0055e-01, 8.7732e-02,\n",
      "         7.5658e-02, 8.9258e-02],\n",
      "        [2.0786e-04, 1.1735e-03, 6.5928e-03, 4.4012e-03, 5.8462e-03, 2.8176e-04,\n",
      "         8.8230e-04, 1.1119e-02, 9.5322e-03, 1.5689e-02, 6.0094e-03, 3.7452e-02,\n",
      "         1.7344e-02, 4.9713e-02, 7.8233e-02, 1.0506e-01, 1.2331e-01, 1.3128e-01,\n",
      "         1.4248e-01, 2.5339e-01],\n",
      "        [1.0371e-03, 4.1642e-03, 1.8640e-02, 1.0290e-02, 1.7745e-02, 5.8139e-04,\n",
      "         1.6869e-03, 1.2449e-02, 1.3885e-02, 2.1198e-02, 8.1393e-03, 4.1525e-02,\n",
      "         1.7965e-02, 5.4262e-02, 8.3265e-02, 1.0821e-01, 1.2248e-01, 1.2517e-01,\n",
      "         1.2828e-01, 2.0903e-01],\n",
      "        [4.1960e-03, 1.5809e-02, 1.0865e-01, 5.0379e-02, 5.9956e-02, 1.5806e-03,\n",
      "         7.4221e-03, 4.6354e-02, 3.6897e-02, 4.8838e-02, 2.5946e-02, 5.3956e-02,\n",
      "         2.2962e-02, 4.3402e-02, 5.7191e-02, 6.8192e-02, 7.3074e-02, 7.2548e-02,\n",
      "         7.4346e-02, 1.2830e-01],\n",
      "        [4.5888e-03, 1.5437e-02, 1.2617e-01, 6.1769e-02, 3.8760e-02, 2.6242e-03,\n",
      "         1.1963e-02, 1.3542e-01, 8.1757e-02, 8.3391e-02, 2.6537e-02, 4.0409e-02,\n",
      "         2.4155e-02, 3.3826e-02, 4.0333e-02, 4.4986e-02, 4.7478e-02, 4.8369e-02,\n",
      "         5.1292e-02, 8.0739e-02],\n",
      "        [3.8661e-03, 1.3997e-02, 6.5419e-02, 3.7441e-02, 3.6689e-02, 2.1584e-03,\n",
      "         3.9810e-03, 2.8995e-02, 4.7807e-02, 7.5325e-02, 2.0760e-02, 5.4508e-02,\n",
      "         2.4898e-02, 5.3762e-02, 7.2228e-02, 8.4658e-02, 8.9907e-02, 8.8772e-02,\n",
      "         8.6263e-02, 1.0856e-01]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4.00, Train Loss: 0.00, Val Loss: 5.28, Train BLEU: 0.00, Val BLEU: 4.91, Minutes Elapsed: 372.66\n",
      "Sampling from val predictions...\n",
      "Source: 这个 个人 还 得 去 <UNK> 条约 和 接见 <UNK> <UNK> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: this guy has to go and sign treaties and meet foreign <UNK> . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> this &apos;s is a <UNK> with and and the <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.5153, 0.4825, 0.0020, 0.0002, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0323, 0.9382, 0.0148, 0.0088, 0.0041, 0.0005, 0.0006, 0.0001, 0.0002,\n",
      "         0.0001, 0.0001, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0972, 0.5074, 0.1599, 0.0929, 0.0537, 0.0117, 0.0150, 0.0059, 0.0108,\n",
      "         0.0094, 0.0130, 0.0230, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0608, 0.2575, 0.1665, 0.1546, 0.1283, 0.0416, 0.0502, 0.0159, 0.0298,\n",
      "         0.0196, 0.0254, 0.0498, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0188, 0.1290, 0.0722, 0.0935, 0.1957, 0.1532, 0.1959, 0.0221, 0.0387,\n",
      "         0.0208, 0.0254, 0.0347, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0132, 0.0327, 0.0217, 0.0340, 0.1632, 0.1134, 0.3683, 0.0803, 0.0720,\n",
      "         0.0317, 0.0407, 0.0288, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0094, 0.0193, 0.0066, 0.0061, 0.0515, 0.0564, 0.6844, 0.0725, 0.0433,\n",
      "         0.0153, 0.0214, 0.0139, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0286, 0.0306, 0.0112, 0.0056, 0.0366, 0.0395, 0.6771, 0.0979, 0.0429,\n",
      "         0.0089, 0.0105, 0.0106, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0125, 0.0121, 0.0066, 0.0033, 0.0184, 0.0298, 0.7399, 0.1023, 0.0467,\n",
      "         0.0080, 0.0094, 0.0109, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0445, 0.0166, 0.0060, 0.0021, 0.0166, 0.0256, 0.6723, 0.1248, 0.0608,\n",
      "         0.0091, 0.0093, 0.0122, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2246, 0.1083, 0.0260, 0.0074, 0.0263, 0.0251, 0.4139, 0.0583, 0.0380,\n",
      "         0.0144, 0.0205, 0.0371, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0434, 0.0616, 0.0171, 0.0093, 0.0284, 0.0388, 0.5070, 0.0707, 0.0663,\n",
      "         0.0361, 0.0521, 0.0693, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0444, 0.0518, 0.0072, 0.0058, 0.0174, 0.0423, 0.5893, 0.0363, 0.0484,\n",
      "         0.0295, 0.0474, 0.0802, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1750, 0.1229, 0.0259, 0.0141, 0.0388, 0.0347, 0.2572, 0.0630, 0.0495,\n",
      "         0.0219, 0.0352, 0.1618, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2635, 0.1835, 0.0453, 0.0185, 0.0348, 0.0271, 0.1457, 0.0484, 0.0382,\n",
      "         0.0177, 0.0259, 0.1512, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0399, 0.2163, 0.0680, 0.0511, 0.0901, 0.0479, 0.1527, 0.0633, 0.0764,\n",
      "         0.0468, 0.0538, 0.0937, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0195, 0.0805, 0.0583, 0.0425, 0.0723, 0.0416, 0.1531, 0.0723, 0.1005,\n",
      "         0.0768, 0.1144, 0.1682, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0958, 0.0940, 0.0690, 0.0344, 0.0637, 0.0237, 0.1340, 0.0866, 0.0735,\n",
      "         0.0431, 0.0569, 0.2252, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1413, 0.1472, 0.0526, 0.0242, 0.0478, 0.0243, 0.1620, 0.0561, 0.0504,\n",
      "         0.0288, 0.0427, 0.2226, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 4.05, Train Loss: 0.00, Val Loss: 5.19, Train BLEU: 0.00, Val BLEU: 4.18, Minutes Elapsed: 377.81\n",
      "Sampling from val predictions...\n",
      "Source: 我们 怎样 能够 更好 地 分享 各自 的 关于 被 <UNK> 的 建筑 的 回忆 并 更好 地理 理解 我们\n",
      "Reference: how can we share more of our memories of our abandoned buildings , and gain a better understanding of\n",
      "Model: <SOS> how we we do to to of and and and and and ? <EOS> we can . . <EOS>\n",
      "Attention Weights: tensor([[4.6597e-02, 8.8309e-01, 3.2780e-02, 1.6701e-02, 3.1834e-04, 3.9667e-03,\n",
      "         4.0378e-03, 6.0341e-04, 8.0434e-03, 2.7304e-04, 3.4781e-05, 8.0722e-05,\n",
      "         4.7286e-04, 3.4849e-04, 2.4382e-03, 9.1300e-05, 8.3204e-05, 8.6323e-06,\n",
      "         2.9376e-05, 8.3406e-07],\n",
      "        [3.9364e-02, 1.6397e-01, 4.7637e-01, 2.6010e-01, 3.8799e-03, 1.5577e-02,\n",
      "         1.1264e-02, 2.3921e-03, 1.3306e-02, 2.2622e-03, 5.5316e-04, 4.5807e-04,\n",
      "         1.5190e-03, 8.7387e-04, 7.4716e-03, 2.4964e-04, 2.3175e-04, 6.6672e-05,\n",
      "         6.4262e-05, 1.4278e-05],\n",
      "        [2.8661e-02, 6.1140e-02, 3.7787e-01, 3.6188e-01, 1.9091e-02, 4.8294e-02,\n",
      "         2.5460e-02, 7.8771e-03, 2.4793e-02, 1.0386e-02, 3.2838e-03, 2.7353e-03,\n",
      "         4.5551e-03, 3.4621e-03, 1.3914e-02, 1.7254e-03, 2.8999e-03, 1.0390e-03,\n",
      "         6.5847e-04, 2.7231e-04],\n",
      "        [1.0690e-02, 2.3569e-02, 2.0006e-01, 5.1886e-01, 2.3648e-02, 9.2713e-02,\n",
      "         3.0428e-02, 5.7533e-03, 3.5277e-02, 1.2141e-02, 4.8835e-03, 2.9797e-03,\n",
      "         8.1529e-03, 2.4592e-03, 1.6074e-02, 1.4571e-03, 6.2029e-03, 2.7930e-03,\n",
      "         1.4476e-03, 4.0611e-04],\n",
      "        [5.3770e-04, 1.1325e-03, 6.4461e-03, 1.5562e-01, 4.3058e-02, 4.1695e-01,\n",
      "         1.2397e-01, 1.1067e-02, 7.6456e-02, 3.8511e-02, 1.7200e-02, 1.1482e-02,\n",
      "         3.0831e-02, 6.0559e-03, 2.7161e-02, 2.2979e-03, 1.5147e-02, 1.1827e-02,\n",
      "         3.0661e-03, 1.1866e-03],\n",
      "        [3.4635e-04, 3.7935e-04, 2.4960e-03, 7.8747e-02, 3.4356e-02, 2.9196e-01,\n",
      "         1.7352e-01, 1.9851e-02, 1.0623e-01, 6.3172e-02, 3.3878e-02, 2.4941e-02,\n",
      "         7.6305e-02, 1.6430e-02, 4.4695e-02, 1.7347e-03, 1.6322e-02, 1.2634e-02,\n",
      "         1.5910e-03, 4.1304e-04],\n",
      "        [2.2247e-04, 2.5519e-04, 1.1472e-03, 1.3637e-02, 6.4226e-03, 7.1218e-02,\n",
      "         6.5247e-02, 8.6554e-03, 8.1319e-02, 1.7379e-01, 9.3016e-02, 6.3950e-02,\n",
      "         1.9161e-01, 3.2045e-02, 9.8710e-02, 1.4241e-02, 5.3514e-02, 2.5282e-02,\n",
      "         5.1030e-03, 6.1482e-04],\n",
      "        [1.2608e-04, 6.9229e-05, 2.6648e-04, 3.4050e-03, 3.2537e-03, 4.5544e-02,\n",
      "         2.8895e-02, 2.2700e-03, 2.9005e-02, 2.1744e-01, 1.3180e-01, 5.8916e-02,\n",
      "         2.2997e-01, 2.0827e-02, 6.6054e-02, 3.8095e-02, 6.8290e-02, 4.6657e-02,\n",
      "         8.1721e-03, 9.4428e-04],\n",
      "        [1.8854e-04, 8.9768e-05, 2.9126e-04, 2.0706e-03, 1.5797e-03, 2.0819e-02,\n",
      "         1.1323e-02, 4.3747e-04, 8.4112e-03, 2.4504e-01, 1.4222e-01, 2.7756e-02,\n",
      "         1.8596e-01, 1.0493e-02, 6.6227e-02, 1.4214e-01, 7.9432e-02, 3.9018e-02,\n",
      "         1.5001e-02, 1.5087e-03],\n",
      "        [8.8366e-05, 4.2373e-05, 1.3384e-04, 9.9149e-04, 1.4952e-03, 1.2824e-02,\n",
      "         7.4567e-03, 5.8811e-04, 7.2668e-03, 1.5048e-01, 1.1827e-01, 3.5557e-02,\n",
      "         1.3701e-01, 1.2846e-02, 5.2961e-02, 1.8975e-01, 1.3859e-01, 9.0909e-02,\n",
      "         3.8537e-02, 4.2002e-03],\n",
      "        [1.2086e-04, 6.0484e-05, 8.2477e-05, 4.9265e-04, 5.6903e-04, 8.4058e-03,\n",
      "         3.8750e-03, 3.6243e-04, 1.7610e-03, 5.5372e-02, 6.4622e-02, 1.4246e-02,\n",
      "         6.5882e-02, 3.5116e-03, 1.6629e-02, 1.3731e-01, 3.1443e-01, 2.2329e-01,\n",
      "         6.2728e-02, 2.6250e-02],\n",
      "        [4.4794e-04, 1.9909e-04, 1.4028e-04, 6.2680e-04, 7.3806e-04, 7.5676e-03,\n",
      "         3.6379e-03, 2.9042e-04, 2.1698e-03, 8.7346e-02, 4.6628e-02, 1.0902e-02,\n",
      "         6.1655e-02, 5.3564e-03, 2.5167e-02, 2.7391e-01, 1.5535e-01, 1.1436e-01,\n",
      "         1.1987e-01, 8.3638e-02],\n",
      "        [2.2250e-04, 8.6517e-05, 1.3908e-04, 5.9943e-04, 9.0562e-04, 6.4542e-03,\n",
      "         3.3556e-03, 4.1820e-04, 1.9419e-03, 3.7142e-02, 4.2539e-02, 1.0355e-02,\n",
      "         5.6130e-02, 4.6495e-03, 1.9143e-02, 7.9376e-02, 8.8314e-02, 2.0410e-01,\n",
      "         2.0542e-01, 2.3871e-01],\n",
      "        [2.6891e-04, 1.0863e-04, 1.6819e-04, 6.8070e-04, 1.1062e-03, 8.7533e-03,\n",
      "         3.2453e-03, 3.5104e-04, 1.1496e-03, 1.6689e-02, 2.0479e-02, 4.8599e-03,\n",
      "         3.1791e-02, 1.3732e-03, 4.4110e-03, 1.3138e-02, 3.3820e-02, 2.1351e-01,\n",
      "         8.1468e-02, 5.6263e-01],\n",
      "        [1.4035e-03, 7.9685e-04, 6.3338e-04, 1.7891e-03, 1.7826e-03, 8.3889e-03,\n",
      "         4.9756e-03, 7.3265e-04, 2.6654e-03, 2.1388e-02, 1.7211e-02, 3.7100e-03,\n",
      "         1.5940e-02, 1.7756e-03, 8.0426e-03, 3.3619e-02, 6.9795e-02, 1.4157e-01,\n",
      "         1.0898e-01, 5.5480e-01],\n",
      "        [4.7262e-04, 4.6820e-04, 2.6890e-03, 5.4123e-03, 1.9392e-03, 4.2717e-03,\n",
      "         3.6974e-03, 1.3565e-03, 1.9594e-03, 1.5185e-02, 8.2080e-03, 5.2335e-03,\n",
      "         6.6538e-03, 2.2798e-03, 4.9403e-03, 2.7234e-02, 9.0729e-02, 9.9206e-02,\n",
      "         9.3682e-02, 6.2438e-01],\n",
      "        [9.1848e-04, 1.2432e-03, 3.2142e-03, 5.6153e-03, 2.4660e-03, 5.2319e-03,\n",
      "         4.1252e-03, 2.1157e-03, 3.1915e-03, 1.7901e-02, 8.2773e-03, 6.5229e-03,\n",
      "         7.0914e-03, 3.5011e-03, 7.3699e-03, 3.8797e-02, 9.2376e-02, 7.3328e-02,\n",
      "         8.9849e-02, 6.2686e-01],\n",
      "        [9.3020e-04, 6.5610e-04, 7.7454e-04, 2.2921e-03, 1.6881e-03, 6.5638e-03,\n",
      "         3.8053e-03, 7.4409e-04, 2.4581e-03, 1.5077e-02, 1.0768e-02, 4.5125e-03,\n",
      "         1.1414e-02, 1.9463e-03, 6.0848e-03, 1.6716e-02, 3.9630e-02, 8.3982e-02,\n",
      "         8.0148e-02, 7.0981e-01],\n",
      "        [3.5484e-03, 2.0999e-03, 5.0254e-03, 8.3899e-03, 5.1815e-03, 2.0333e-02,\n",
      "         1.2851e-02, 1.9033e-03, 6.4996e-03, 4.7434e-02, 3.8673e-02, 1.2051e-02,\n",
      "         4.1606e-02, 6.8215e-03, 2.4750e-02, 5.6773e-02, 4.2325e-02, 8.8959e-02,\n",
      "         8.1139e-02, 4.9364e-01]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4.11, Train Loss: 0.00, Val Loss: 5.19, Train BLEU: 0.00, Val BLEU: 4.51, Minutes Elapsed: 382.98\n",
      "Sampling from val predictions...\n",
      "Source: 照片 片中 中美 美丽 的 和服 必须 通过 过手 手绘 处理 或者 一点 一点一点 一点 拼接 而 成 <UNK> 配上\n",
      "Reference: the <UNK> in this shot pretty much had to be <UNK> , or <UNK> together , picking out the\n",
      "Model: <SOS> the , of the , , , , , be and and <EOS> . . <EOS> <EOS> . <EOS>\n",
      "Attention Weights: tensor([[2.8535e-01, 3.5222e-01, 1.7358e-01, 1.5906e-01, 5.2992e-03, 1.0520e-02,\n",
      "         8.2944e-03, 1.1040e-04, 3.7901e-05, 1.0536e-04, 5.5387e-04, 4.4237e-03,\n",
      "         2.7083e-04, 1.2035e-05, 1.0287e-04, 1.4491e-05, 8.1513e-06, 9.1695e-06,\n",
      "         3.6205e-06, 2.3322e-05],\n",
      "        [7.5046e-02, 2.8411e-01, 2.4544e-01, 3.5021e-01, 1.6677e-02, 1.8973e-02,\n",
      "         8.0205e-03, 3.7115e-04, 3.9781e-05, 7.6286e-05, 1.0786e-04, 7.6161e-04,\n",
      "         8.7394e-05, 1.3492e-05, 3.7174e-05, 1.3080e-05, 8.4862e-06, 2.3563e-06,\n",
      "         1.0198e-06, 1.8721e-06],\n",
      "        [4.5666e-02, 1.7331e-01, 2.2004e-01, 4.2604e-01, 3.5885e-02, 4.1846e-02,\n",
      "         4.7813e-02, 2.8594e-03, 5.9319e-04, 9.5199e-04, 1.0242e-03, 2.7084e-03,\n",
      "         5.9109e-04, 1.0533e-04, 3.1352e-04, 1.1982e-04, 7.6321e-05, 2.0103e-05,\n",
      "         9.7560e-06, 2.4096e-05],\n",
      "        [1.3520e-02, 4.9773e-02, 3.2941e-01, 4.6038e-01, 1.5135e-02, 2.4707e-02,\n",
      "         1.0231e-01, 2.1462e-03, 2.4953e-04, 4.1307e-04, 4.8371e-04, 1.2263e-03,\n",
      "         1.2789e-04, 1.6703e-05, 5.5644e-05, 1.7599e-05, 1.4801e-05, 3.8079e-06,\n",
      "         2.1049e-06, 3.3034e-06],\n",
      "        [3.2870e-03, 1.5962e-02, 1.4281e-01, 2.8628e-01, 8.2678e-03, 2.8547e-02,\n",
      "         3.7580e-01, 5.5075e-02, 1.1020e-02, 1.9882e-02, 9.8263e-03, 3.0402e-02,\n",
      "         7.5423e-03, 9.3218e-04, 2.8905e-03, 7.2016e-04, 4.9253e-04, 1.1078e-04,\n",
      "         7.0365e-05, 7.5052e-05],\n",
      "        [1.5248e-03, 5.9613e-03, 5.9589e-02, 7.9364e-02, 9.2307e-03, 1.9543e-02,\n",
      "         6.3256e-01, 5.9047e-02, 1.5243e-02, 2.1519e-02, 1.5771e-02, 7.0853e-02,\n",
      "         6.8192e-03, 5.3111e-04, 1.9158e-03, 2.9190e-04, 1.8042e-04, 2.4453e-05,\n",
      "         1.3134e-05, 1.4181e-05],\n",
      "        [1.0590e-03, 3.4649e-03, 3.4109e-02, 5.0772e-02, 2.4790e-03, 1.2365e-02,\n",
      "         4.7723e-01, 1.3456e-01, 4.8265e-02, 6.3811e-02, 2.5809e-02, 1.0337e-01,\n",
      "         2.5367e-02, 3.0267e-03, 1.0187e-02, 2.2409e-03, 1.3260e-03, 2.3745e-04,\n",
      "         1.9250e-04, 1.3217e-04],\n",
      "        [4.0797e-04, 1.7785e-03, 1.1033e-02, 1.3599e-02, 8.3479e-04, 1.9818e-03,\n",
      "         5.6132e-02, 8.9969e-02, 8.7902e-02, 1.7024e-01, 6.5976e-02, 2.8582e-01,\n",
      "         1.1765e-01, 2.1931e-02, 4.7851e-02, 1.4030e-02, 9.1375e-03, 1.6879e-03,\n",
      "         1.1459e-03, 8.8552e-04],\n",
      "        [2.1847e-04, 1.0024e-03, 2.9506e-03, 3.0731e-03, 3.5720e-04, 4.1802e-04,\n",
      "         6.5865e-03, 1.3361e-02, 3.4596e-02, 7.2817e-02, 3.3358e-02, 3.3573e-01,\n",
      "         2.1864e-01, 4.9509e-02, 1.2525e-01, 4.7806e-02, 4.1420e-02, 6.4554e-03,\n",
      "         4.2307e-03, 2.2266e-03],\n",
      "        [2.8785e-04, 1.3453e-03, 1.8613e-03, 1.6394e-03, 3.9279e-04, 3.0133e-04,\n",
      "         8.8495e-04, 2.4007e-03, 1.1320e-02, 2.1506e-02, 1.2225e-02, 9.0039e-02,\n",
      "         1.0055e-01, 4.9581e-02, 9.9719e-02, 9.8589e-02, 3.3431e-01, 8.4953e-02,\n",
      "         6.4903e-02, 2.3195e-02],\n",
      "        [1.5779e-04, 9.5653e-04, 1.1786e-03, 8.4658e-04, 4.4430e-04, 2.7052e-04,\n",
      "         3.6961e-04, 1.3243e-03, 8.5804e-03, 1.7618e-02, 1.0744e-02, 3.3712e-02,\n",
      "         4.2566e-02, 3.4202e-02, 4.7381e-02, 6.8273e-02, 3.6712e-01, 1.5890e-01,\n",
      "         1.5133e-01, 5.4026e-02],\n",
      "        [4.8436e-04, 2.8884e-03, 3.8173e-03, 2.9283e-03, 1.1629e-03, 7.2395e-04,\n",
      "         7.6249e-04, 1.0864e-03, 6.9002e-03, 1.4884e-02, 8.5377e-03, 3.7226e-02,\n",
      "         4.5079e-02, 3.7394e-02, 3.8367e-02, 5.3910e-02, 3.5622e-01, 1.1343e-01,\n",
      "         2.1979e-01, 5.4398e-02],\n",
      "        [1.4008e-03, 7.1839e-03, 1.1898e-02, 7.4923e-03, 2.3237e-03, 1.3977e-03,\n",
      "         1.9808e-03, 2.4260e-03, 1.5010e-02, 3.0358e-02, 1.7354e-02, 5.9328e-02,\n",
      "         5.2504e-02, 3.2888e-02, 3.1235e-02, 3.4956e-02, 2.1652e-01, 1.1075e-01,\n",
      "         2.7959e-01, 8.3404e-02],\n",
      "        [1.1081e-02, 5.3961e-02, 8.4499e-02, 5.4781e-02, 1.5312e-02, 8.6788e-03,\n",
      "         2.0733e-02, 1.3653e-02, 2.8538e-02, 4.3340e-02, 2.9842e-02, 1.3841e-01,\n",
      "         6.7938e-02, 4.1929e-02, 3.3995e-02, 3.3662e-02, 8.2782e-02, 4.3688e-02,\n",
      "         1.1216e-01, 8.1010e-02],\n",
      "        [4.2386e-03, 1.6529e-02, 1.9598e-02, 1.4063e-02, 3.1212e-03, 3.3732e-03,\n",
      "         6.5416e-03, 1.1086e-02, 2.0579e-02, 2.7749e-02, 1.3799e-02, 4.4535e-02,\n",
      "         4.7390e-02, 3.1446e-02, 4.3262e-02, 6.2586e-02, 1.4692e-01, 8.1734e-02,\n",
      "         2.3298e-01, 1.6847e-01],\n",
      "        [2.2557e-03, 1.1489e-02, 1.5351e-02, 1.1847e-02, 3.8967e-03, 2.7312e-03,\n",
      "         6.6697e-03, 1.1608e-02, 2.2767e-02, 3.3636e-02, 2.2316e-02, 4.7613e-02,\n",
      "         4.8208e-02, 3.7433e-02, 3.8147e-02, 5.8099e-02, 1.3412e-01, 8.5236e-02,\n",
      "         2.4247e-01, 1.6410e-01],\n",
      "        [4.7033e-03, 2.2812e-02, 4.1260e-02, 2.7100e-02, 5.8248e-03, 4.5279e-03,\n",
      "         3.2199e-02, 2.8034e-02, 3.5750e-02, 4.7718e-02, 3.8408e-02, 1.2892e-01,\n",
      "         1.0884e-01, 4.7934e-02, 8.7813e-02, 5.8968e-02, 9.3383e-02, 4.3303e-02,\n",
      "         5.7837e-02, 8.4665e-02],\n",
      "        [1.5329e-02, 5.7219e-02, 6.5936e-02, 4.8868e-02, 1.3445e-02, 9.3810e-03,\n",
      "         2.4969e-02, 3.1523e-02, 4.1621e-02, 6.4326e-02, 5.2173e-02, 1.0203e-01,\n",
      "         1.1173e-01, 5.3223e-02, 6.5697e-02, 4.9083e-02, 6.2458e-02, 3.9104e-02,\n",
      "         4.6424e-02, 4.5457e-02],\n",
      "        [9.2212e-03, 3.1952e-02, 4.1397e-02, 2.7022e-02, 6.4784e-03, 6.6174e-03,\n",
      "         1.2367e-02, 2.7431e-02, 4.6950e-02, 5.6329e-02, 3.4083e-02, 6.2627e-02,\n",
      "         8.6768e-02, 5.6480e-02, 6.5388e-02, 8.0787e-02, 9.5935e-02, 5.6829e-02,\n",
      "         1.1272e-01, 8.2615e-02]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 4.16, Train Loss: 0.00, Val Loss: 5.27, Train BLEU: 0.00, Val BLEU: 4.59, Minutes Elapsed: 388.15\n",
      "Sampling from val predictions...\n",
      "Source: 没过 <UNK> 几天 过完 <UNK> 开车 回家 的 路上 堵车 让 他 很烦 烦躁 他 把 一个 冰冷 的 巨无霸\n",
      "Reference: and then a few days later , driving home from our <UNK> , he got frustrated by traffic ,\n",
      "Model: <SOS> after then , the later , she her she her his a . . <UNK> a . . .\n",
      "Attention Weights: tensor([[3.2241e-01, 3.5672e-02, 1.5305e-01, 4.6562e-03, 3.0110e-03, 2.1322e-02,\n",
      "         7.7895e-02, 2.3534e-02, 2.2922e-01, 4.9825e-02, 5.7867e-02, 2.0126e-02,\n",
      "         2.0334e-04, 2.2464e-04, 8.1996e-04, 2.5462e-05, 4.0915e-06, 5.6652e-06,\n",
      "         2.4359e-05, 1.0078e-04],\n",
      "        [2.3819e-01, 2.5884e-01, 2.7139e-01, 2.0305e-02, 1.4703e-02, 2.0471e-02,\n",
      "         8.8058e-02, 6.5924e-03, 6.4938e-02, 6.4903e-03, 4.3705e-03, 4.9982e-03,\n",
      "         1.3792e-04, 1.6380e-04, 2.3094e-04, 1.6124e-05, 7.4885e-06, 1.4417e-05,\n",
      "         1.0929e-05, 7.4959e-05],\n",
      "        [4.8157e-02, 9.3036e-02, 1.9182e-01, 2.9168e-02, 3.8510e-02, 9.6230e-02,\n",
      "         3.2763e-01, 1.7328e-02, 1.0418e-01, 1.9304e-02, 1.2517e-02, 1.6364e-02,\n",
      "         1.7601e-03, 1.7220e-03, 1.4822e-03, 1.7403e-04, 9.9269e-05, 1.0588e-04,\n",
      "         1.3866e-04, 2.6962e-04],\n",
      "        [2.9251e-02, 3.6120e-02, 1.3014e-01, 1.8919e-02, 3.7902e-02, 1.3539e-01,\n",
      "         4.0664e-01, 2.3930e-02, 1.0037e-01, 2.9292e-02, 2.7330e-02, 1.9285e-02,\n",
      "         1.7168e-03, 1.5526e-03, 1.4648e-03, 1.9309e-04, 6.2911e-05, 7.4838e-05,\n",
      "         1.3603e-04, 2.3224e-04],\n",
      "        [6.7789e-03, 1.1582e-02, 5.0825e-02, 8.4857e-03, 2.9944e-02, 1.4377e-01,\n",
      "         5.2579e-01, 2.2122e-02, 9.3730e-02, 3.7581e-02, 2.0912e-02, 3.4689e-02,\n",
      "         4.5203e-03, 4.2772e-03, 2.7561e-03, 5.2636e-04, 3.5750e-04, 2.8804e-04,\n",
      "         2.8274e-04, 7.7762e-04],\n",
      "        [1.0586e-02, 6.9730e-03, 3.6581e-02, 5.2827e-03, 1.9696e-02, 1.1193e-01,\n",
      "         3.3989e-01, 8.8669e-03, 3.5043e-02, 2.1267e-02, 1.9902e-01, 1.8395e-01,\n",
      "         5.6235e-03, 3.9610e-03, 1.0472e-02, 4.8775e-04, 6.6276e-05, 1.0105e-04,\n",
      "         6.2359e-05, 1.4455e-04],\n",
      "        [5.2975e-03, 3.7529e-03, 2.0670e-02, 3.7116e-03, 1.3747e-02, 9.4573e-02,\n",
      "         3.1352e-01, 6.3664e-03, 2.1222e-02, 1.9693e-02, 2.2233e-01, 2.4309e-01,\n",
      "         8.4838e-03, 7.1112e-03, 1.4688e-02, 1.0730e-03, 1.2664e-04, 1.8241e-04,\n",
      "         9.1314e-05, 2.6362e-04],\n",
      "        [1.2176e-03, 2.4169e-03, 1.3548e-02, 3.5004e-03, 1.2690e-02, 7.1216e-02,\n",
      "         2.3877e-01, 2.3978e-03, 1.8586e-02, 1.2966e-02, 6.5474e-02, 4.0587e-01,\n",
      "         4.6956e-02, 4.2169e-02, 5.1470e-02, 6.5320e-03, 1.3128e-03, 1.2976e-03,\n",
      "         3.5488e-04, 1.2570e-03],\n",
      "        [4.9583e-04, 8.4420e-04, 5.4447e-03, 1.4258e-03, 3.6181e-03, 1.9991e-02,\n",
      "         6.9965e-02, 1.4665e-03, 9.8079e-03, 8.7431e-03, 2.6596e-02, 3.5605e-01,\n",
      "         1.2683e-01, 1.4536e-01, 1.4893e-01, 3.5804e-02, 1.5822e-02, 1.1520e-02,\n",
      "         1.5568e-03, 9.7348e-03],\n",
      "        [7.0733e-04, 5.4057e-04, 3.2957e-03, 9.1281e-04, 2.1726e-03, 1.2852e-02,\n",
      "         4.7052e-02, 6.1577e-03, 1.4700e-02, 1.3291e-02, 2.5395e-02, 2.1064e-01,\n",
      "         1.2789e-01, 1.7527e-01, 1.8771e-01, 8.6264e-02, 4.5585e-02, 1.5378e-02,\n",
      "         4.3653e-03, 1.9823e-02],\n",
      "        [5.1332e-05, 5.1270e-05, 7.4176e-04, 2.0156e-04, 5.0108e-04, 1.8125e-03,\n",
      "         7.2721e-03, 6.8000e-04, 2.6768e-03, 1.8458e-03, 7.8236e-03, 8.7376e-02,\n",
      "         3.6405e-02, 8.2891e-02, 3.4659e-01, 8.7125e-02, 7.5537e-02, 1.4686e-01,\n",
      "         1.1061e-02, 1.0249e-01],\n",
      "        [3.9113e-05, 2.5407e-05, 4.9512e-04, 9.6953e-05, 1.6382e-04, 5.0992e-04,\n",
      "         1.9132e-03, 2.5088e-04, 8.4159e-04, 3.5542e-04, 1.4107e-03, 2.0315e-02,\n",
      "         7.7511e-03, 2.5542e-02, 1.6797e-01, 5.6854e-02, 1.9207e-01, 3.1605e-01,\n",
      "         1.2492e-02, 1.9485e-01],\n",
      "        [7.2351e-05, 5.9602e-05, 1.1515e-03, 2.9159e-04, 4.5657e-04, 1.4101e-03,\n",
      "         4.0269e-03, 1.2943e-03, 3.4330e-03, 1.7549e-03, 3.1002e-03, 1.2559e-02,\n",
      "         3.0574e-03, 1.3068e-02, 1.2095e-01, 3.1220e-02, 3.1786e-02, 2.9078e-01,\n",
      "         9.2177e-02, 3.8736e-01],\n",
      "        [2.5627e-04, 2.4387e-04, 3.0388e-03, 9.4908e-04, 2.0285e-03, 6.8301e-03,\n",
      "         1.2598e-02, 2.3689e-03, 6.7131e-03, 3.8053e-03, 7.3901e-03, 1.9017e-02,\n",
      "         8.1898e-03, 2.4114e-02, 1.4929e-01, 7.0580e-02, 2.4120e-02, 3.8177e-01,\n",
      "         9.8694e-02, 1.7801e-01],\n",
      "        [1.4231e-03, 1.6989e-03, 2.3711e-02, 4.8913e-03, 6.7977e-03, 1.7872e-02,\n",
      "         3.7550e-02, 7.2501e-03, 1.6127e-02, 5.2357e-03, 3.2813e-02, 9.1705e-02,\n",
      "         2.3141e-02, 2.6084e-02, 1.9600e-01, 7.1837e-02, 2.7818e-02, 3.2291e-01,\n",
      "         2.7039e-02, 5.8096e-02],\n",
      "        [1.2514e-03, 9.9799e-04, 1.0328e-02, 3.0608e-03, 4.5730e-03, 1.0881e-02,\n",
      "         2.5831e-02, 7.2775e-03, 1.1230e-02, 4.9167e-03, 1.1099e-02, 3.1476e-02,\n",
      "         1.1616e-02, 1.9219e-02, 1.0748e-01, 9.4109e-02, 1.3620e-01, 2.5820e-01,\n",
      "         7.9186e-02, 1.7108e-01],\n",
      "        [2.4289e-04, 2.6468e-04, 5.2835e-03, 1.3937e-03, 1.7375e-03, 2.9685e-03,\n",
      "         9.1437e-03, 3.0820e-03, 5.1543e-03, 2.3743e-03, 4.4962e-03, 8.1450e-03,\n",
      "         2.0828e-03, 2.9136e-03, 2.5883e-02, 2.3937e-02, 1.4981e-01, 5.9788e-01,\n",
      "         3.5805e-02, 1.1740e-01],\n",
      "        [2.4676e-04, 1.6238e-04, 5.1253e-03, 1.3684e-03, 1.1394e-03, 2.3634e-03,\n",
      "         7.5602e-03, 3.9130e-03, 4.9350e-03, 1.7825e-03, 3.2058e-03, 7.7378e-03,\n",
      "         1.4566e-03, 2.7913e-03, 2.0926e-02, 1.0463e-02, 1.5357e-01, 6.3005e-01,\n",
      "         3.4238e-02, 1.0697e-01],\n",
      "        [5.5085e-04, 5.1704e-04, 1.5510e-02, 3.5135e-03, 3.2957e-03, 8.0607e-03,\n",
      "         1.8798e-02, 9.5813e-03, 1.5832e-02, 4.8813e-03, 9.4613e-03, 1.9849e-02,\n",
      "         4.6324e-03, 8.1884e-03, 4.1534e-02, 1.6086e-02, 5.4296e-02, 5.6350e-01,\n",
      "         5.3456e-02, 1.4846e-01]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4.22, Train Loss: 0.00, Val Loss: 5.11, Train BLEU: 0.00, Val BLEU: 5.47, Minutes Elapsed: 393.32\n",
      "Sampling from val predictions...\n",
      "Source: 我们 在 巴士 上 的 旅途 有 一周 之久 好几 几次 都 差点 被 抓住 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: the journey by bus took one week , and we were almost caught several times . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> we spent of we we we the , the , was been to the . . <EOS> <EOS> .\n",
      "Attention Weights: tensor([[0.7352, 0.0079, 0.0003, 0.0076, 0.0177, 0.1327, 0.0188, 0.0282, 0.0159,\n",
      "         0.0246, 0.0055, 0.0044, 0.0006, 0.0001, 0.0000, 0.0007, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2202, 0.0707, 0.0071, 0.0220, 0.0234, 0.4913, 0.0286, 0.0600, 0.0221,\n",
      "         0.0144, 0.0237, 0.0047, 0.0098, 0.0004, 0.0003, 0.0014, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2769, 0.0405, 0.0178, 0.0458, 0.0465, 0.3135, 0.0470, 0.0832, 0.0324,\n",
      "         0.0330, 0.0268, 0.0091, 0.0123, 0.0019, 0.0014, 0.0120, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.6584, 0.0323, 0.0293, 0.0380, 0.0166, 0.1111, 0.0198, 0.0352, 0.0147,\n",
      "         0.0123, 0.0090, 0.0065, 0.0070, 0.0016, 0.0014, 0.0067, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.3071, 0.0456, 0.0471, 0.0332, 0.0224, 0.2556, 0.0370, 0.0979, 0.0300,\n",
      "         0.0308, 0.0368, 0.0093, 0.0221, 0.0039, 0.0066, 0.0146, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.3345, 0.0117, 0.0365, 0.0253, 0.0099, 0.1888, 0.0358, 0.1391, 0.0878,\n",
      "         0.0532, 0.0428, 0.0150, 0.0127, 0.0012, 0.0010, 0.0046, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0754, 0.0110, 0.0694, 0.0154, 0.0075, 0.1787, 0.0230, 0.2848, 0.1218,\n",
      "         0.0881, 0.0883, 0.0088, 0.0201, 0.0013, 0.0011, 0.0053, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0142, 0.0022, 0.0657, 0.0074, 0.0049, 0.0911, 0.0121, 0.3160, 0.1645,\n",
      "         0.1378, 0.1279, 0.0155, 0.0278, 0.0032, 0.0031, 0.0065, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0172, 0.0038, 0.0757, 0.0092, 0.0048, 0.0652, 0.0113, 0.2694, 0.1955,\n",
      "         0.1313, 0.1175, 0.0287, 0.0500, 0.0063, 0.0048, 0.0095, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0126, 0.0028, 0.0348, 0.0053, 0.0029, 0.0408, 0.0069, 0.2070, 0.1926,\n",
      "         0.1621, 0.1647, 0.0426, 0.0914, 0.0134, 0.0085, 0.0116, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0030, 0.0012, 0.0122, 0.0025, 0.0020, 0.0171, 0.0123, 0.1469, 0.1505,\n",
      "         0.1396, 0.2906, 0.0371, 0.1564, 0.0137, 0.0118, 0.0031, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0025, 0.0009, 0.0085, 0.0020, 0.0017, 0.0109, 0.0116, 0.1129, 0.1319,\n",
      "         0.1472, 0.3123, 0.0405, 0.1930, 0.0126, 0.0102, 0.0015, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0002, 0.0003, 0.0076, 0.0007, 0.0007, 0.0073, 0.0025, 0.1531, 0.1085,\n",
      "         0.1566, 0.2936, 0.0259, 0.1407, 0.0293, 0.0647, 0.0083, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0005, 0.0004, 0.0133, 0.0013, 0.0013, 0.0189, 0.0021, 0.2003, 0.1442,\n",
      "         0.1840, 0.1723, 0.0283, 0.1463, 0.0326, 0.0421, 0.0122, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0012, 0.0008, 0.0212, 0.0018, 0.0018, 0.0367, 0.0016, 0.2427, 0.1382,\n",
      "         0.1477, 0.1571, 0.0257, 0.1602, 0.0265, 0.0244, 0.0124, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0053, 0.0043, 0.0479, 0.0092, 0.0067, 0.0843, 0.0051, 0.2080, 0.1276,\n",
      "         0.0882, 0.0968, 0.0268, 0.1617, 0.0579, 0.0299, 0.0402, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0121, 0.0054, 0.0515, 0.0136, 0.0087, 0.1141, 0.0046, 0.2343, 0.1313,\n",
      "         0.1122, 0.0651, 0.0197, 0.0694, 0.0503, 0.0259, 0.0817, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0165, 0.0119, 0.0472, 0.0174, 0.0111, 0.1356, 0.0079, 0.2060, 0.1131,\n",
      "         0.1055, 0.0719, 0.0189, 0.0632, 0.0514, 0.0249, 0.0975, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0149, 0.0191, 0.0155, 0.0147, 0.0110, 0.0400, 0.0172, 0.0718, 0.0660,\n",
      "         0.0615, 0.1008, 0.0383, 0.2370, 0.1392, 0.1076, 0.0453, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 4.27, Train Loss: 0.00, Val Loss: 5.16, Train BLEU: 0.00, Val BLEU: 4.92, Minutes Elapsed: 398.47\n",
      "Sampling from val predictions...\n",
      "Source: 最近 一次 旅程 我们 在 路上 走 着 她 突然 停 了 下来 她 指着 一间 玩偶 店 的 红色\n",
      "Reference: recently , on one trip , we were walking , and she stops dead in her tracks , and\n",
      "Model: <SOS> last , , , , , we &apos;ve her to his his his a a of . . <EOS>\n",
      "Attention Weights: tensor([[8.4033e-01, 1.2879e-01, 1.8979e-02, 1.0712e-02, 7.3146e-05, 2.6816e-04,\n",
      "         3.1602e-05, 1.0491e-04, 6.9999e-04, 1.7809e-06, 5.3347e-07, 1.1058e-06,\n",
      "         3.8766e-06, 1.1174e-06, 1.9267e-08, 5.8436e-08, 5.5293e-08, 1.0615e-07,\n",
      "         1.9670e-07, 2.2555e-07],\n",
      "        [4.0182e-01, 2.6707e-01, 2.8899e-01, 3.4467e-02, 1.3260e-03, 2.9882e-03,\n",
      "         4.1426e-04, 4.4662e-04, 2.3060e-03, 6.3704e-05, 1.2824e-05, 1.2768e-05,\n",
      "         4.3619e-05, 1.9607e-05, 5.4346e-07, 9.0211e-07, 9.0137e-07, 1.5755e-06,\n",
      "         2.6791e-06, 6.9847e-06],\n",
      "        [1.7024e-01, 1.3979e-01, 2.3961e-01, 3.6338e-01, 1.4303e-02, 2.9548e-02,\n",
      "         8.7918e-03, 8.6243e-03, 2.0807e-02, 1.8877e-03, 5.1529e-04, 3.5896e-04,\n",
      "         1.0443e-03, 4.2508e-04, 4.6643e-05, 5.8825e-05, 5.9566e-05, 9.2537e-05,\n",
      "         1.1669e-04, 3.0685e-04],\n",
      "        [7.1500e-02, 4.8203e-02, 1.2504e-01, 5.4695e-01, 1.6963e-02, 7.1425e-02,\n",
      "         1.6874e-02, 1.5536e-02, 7.1712e-02, 5.6148e-03, 1.3766e-03, 8.6040e-04,\n",
      "         3.6259e-03, 2.2424e-03, 2.1085e-04, 2.2234e-04, 2.9306e-04, 2.6026e-04,\n",
      "         2.3258e-04, 8.6027e-04],\n",
      "        [2.5776e-02, 2.7951e-02, 3.0596e-02, 2.3223e-01, 6.7017e-02, 2.0738e-01,\n",
      "         4.9028e-02, 4.3769e-02, 2.1250e-01, 4.9938e-02, 1.0206e-02, 6.7718e-03,\n",
      "         2.3149e-02, 7.2739e-03, 4.7362e-04, 5.6213e-04, 6.0025e-04, 5.8099e-04,\n",
      "         1.0899e-03, 3.1076e-03],\n",
      "        [7.1000e-02, 3.6533e-02, 4.2994e-02, 3.5266e-01, 1.0957e-02, 4.1995e-02,\n",
      "         3.2171e-02, 3.8813e-02, 2.9702e-01, 2.3950e-02, 8.3979e-03, 4.5573e-03,\n",
      "         2.6191e-02, 1.0384e-02, 2.7261e-04, 3.6234e-04, 4.1446e-04, 3.5236e-04,\n",
      "         2.4874e-04, 7.2637e-04],\n",
      "        [2.1414e-02, 1.1540e-02, 2.0438e-02, 3.4858e-01, 1.1572e-02, 5.4793e-02,\n",
      "         2.7713e-02, 2.0097e-02, 3.7383e-01, 4.0681e-02, 1.0694e-02, 3.0599e-03,\n",
      "         3.1783e-02, 1.9683e-02, 6.7863e-04, 7.1109e-04, 9.3174e-04, 4.4691e-04,\n",
      "         2.4019e-04, 1.1050e-03],\n",
      "        [9.6715e-03, 5.0900e-03, 5.7800e-03, 2.4553e-01, 1.5324e-02, 5.3007e-02,\n",
      "         8.7902e-03, 1.0632e-02, 4.0075e-01, 6.2992e-02, 1.1193e-02, 4.5476e-03,\n",
      "         7.6270e-02, 8.0720e-02, 1.5010e-03, 1.9672e-03, 2.4941e-03, 6.6368e-04,\n",
      "         4.3850e-04, 2.6424e-03],\n",
      "        [6.0289e-03, 4.8171e-03, 3.0490e-03, 5.0702e-02, 2.5352e-02, 1.0965e-01,\n",
      "         9.5016e-03, 1.3898e-02, 2.6320e-01, 1.1349e-01, 2.4426e-02, 1.2131e-02,\n",
      "         1.4606e-01, 1.5896e-01, 6.5857e-03, 7.4774e-03, 8.0068e-03, 2.9960e-03,\n",
      "         2.9259e-03, 3.0746e-02],\n",
      "        [2.0668e-03, 1.4027e-03, 6.3831e-04, 1.3527e-03, 1.7832e-03, 1.2375e-01,\n",
      "         6.8241e-03, 4.4165e-03, 2.1524e-01, 4.4843e-02, 2.9075e-02, 5.1982e-03,\n",
      "         1.0584e-01, 2.7815e-01, 2.3667e-02, 3.3930e-02, 5.0072e-02, 9.5815e-03,\n",
      "         5.6808e-03, 5.6478e-02],\n",
      "        [2.3801e-03, 1.3763e-03, 5.5334e-04, 1.1296e-03, 6.6440e-04, 5.8427e-02,\n",
      "         3.3179e-03, 2.8804e-03, 1.1616e-01, 2.9184e-02, 2.4217e-02, 7.0620e-03,\n",
      "         1.0529e-01, 2.9756e-01, 2.6325e-02, 5.4867e-02, 1.1417e-01, 2.9332e-02,\n",
      "         1.1541e-02, 1.1356e-01],\n",
      "        [4.8957e-03, 2.7344e-03, 8.1299e-04, 1.8003e-03, 8.3596e-04, 3.8403e-02,\n",
      "         1.5257e-03, 1.7274e-03, 3.2578e-02, 1.4453e-02, 1.1062e-02, 3.2569e-03,\n",
      "         2.8959e-02, 1.5216e-01, 2.6230e-02, 7.6539e-02, 2.4539e-01, 7.5381e-02,\n",
      "         1.4613e-02, 2.6664e-01],\n",
      "        [1.4695e-03, 8.6874e-04, 2.5803e-04, 1.5577e-03, 1.6853e-03, 2.1107e-02,\n",
      "         1.3741e-03, 1.9455e-03, 2.9792e-02, 2.3290e-02, 1.3028e-02, 6.1545e-03,\n",
      "         5.0655e-02, 1.5953e-01, 3.5323e-02, 6.6838e-02, 1.4499e-01, 7.1226e-02,\n",
      "         4.9443e-02, 3.1946e-01],\n",
      "        [2.1695e-03, 1.2600e-03, 4.4590e-04, 3.4902e-03, 2.7472e-03, 1.5588e-02,\n",
      "         2.2495e-03, 3.1611e-03, 3.6025e-02, 2.1779e-02, 1.5669e-02, 8.9060e-03,\n",
      "         5.1887e-02, 1.9685e-01, 3.2390e-02, 6.1637e-02, 1.3159e-01, 6.9794e-02,\n",
      "         4.3296e-02, 2.9907e-01],\n",
      "        [1.0703e-03, 5.6190e-04, 1.9632e-04, 1.1565e-03, 7.5137e-04, 1.3951e-02,\n",
      "         9.9841e-04, 1.3471e-03, 1.7277e-02, 7.2479e-03, 5.3066e-03, 2.6950e-03,\n",
      "         1.8869e-02, 1.7160e-01, 4.2139e-02, 9.6246e-02, 2.0328e-01, 6.5645e-02,\n",
      "         3.2639e-02, 3.1702e-01],\n",
      "        [5.3371e-03, 2.5371e-03, 4.4300e-04, 2.9203e-03, 1.0264e-03, 1.7210e-02,\n",
      "         1.3158e-03, 2.4183e-03, 2.2543e-02, 7.5422e-03, 6.5409e-03, 4.1956e-03,\n",
      "         1.5890e-02, 8.1761e-02, 1.7909e-02, 6.4696e-02, 2.3260e-01, 1.1915e-01,\n",
      "         3.7016e-02, 3.5695e-01],\n",
      "        [2.4286e-02, 1.0719e-02, 2.7740e-03, 2.2456e-02, 3.2607e-03, 5.4469e-02,\n",
      "         4.7546e-03, 8.6169e-03, 8.6213e-02, 1.7035e-02, 1.2387e-02, 7.4635e-03,\n",
      "         3.9730e-02, 1.4963e-01, 2.6996e-02, 7.2013e-02, 1.9351e-01, 1.1319e-01,\n",
      "         1.7667e-02, 1.3283e-01],\n",
      "        [9.7890e-02, 3.4982e-02, 6.5623e-03, 5.4818e-02, 6.3882e-03, 5.7980e-02,\n",
      "         1.1649e-02, 2.2258e-02, 1.1488e-01, 4.7276e-02, 4.1915e-02, 1.8471e-02,\n",
      "         8.9196e-02, 9.3162e-02, 1.0800e-02, 2.9439e-02, 6.6533e-02, 8.2463e-02,\n",
      "         2.7352e-02, 8.5982e-02],\n",
      "        [1.3742e-01, 5.2387e-02, 1.7770e-02, 5.0027e-02, 1.1662e-02, 1.0953e-01,\n",
      "         2.2290e-02, 2.0622e-02, 7.9530e-02, 4.5593e-02, 4.9232e-02, 1.3232e-02,\n",
      "         6.0723e-02, 6.6705e-02, 1.7671e-02, 3.5561e-02, 7.5129e-02, 6.3060e-02,\n",
      "         1.0683e-02, 6.1166e-02]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4.33, Train Loss: 0.00, Val Loss: 5.39, Train BLEU: 0.00, Val BLEU: 4.87, Minutes Elapsed: 403.61\n",
      "Sampling from val predictions...\n",
      "Source: 我 把 花园 和 土地 视为 画布 而 植物 和 树木 就是 我 在 画布 上 的 装饰 <EOS> <PAD>\n",
      "Reference: i use the garden , the soil , like it &apos;s a piece of cloth , and the plants\n",
      "Model: <SOS> i i a in and and the , , , , the i . i . <EOS> i .\n",
      "Attention Weights: tensor([[0.9466, 0.0444, 0.0043, 0.0037, 0.0010, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1077, 0.7792, 0.0915, 0.0134, 0.0062, 0.0010, 0.0001, 0.0001, 0.0002,\n",
      "         0.0001, 0.0003, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0589, 0.2354, 0.3960, 0.0766, 0.1447, 0.0279, 0.0099, 0.0042, 0.0096,\n",
      "         0.0029, 0.0120, 0.0041, 0.0021, 0.0010, 0.0005, 0.0020, 0.0036, 0.0040,\n",
      "         0.0047, 0.0000],\n",
      "        [0.0045, 0.0079, 0.2850, 0.0768, 0.2120, 0.0504, 0.1819, 0.0203, 0.0891,\n",
      "         0.0051, 0.0297, 0.0012, 0.0028, 0.0002, 0.0007, 0.0011, 0.0035, 0.0216,\n",
      "         0.0062, 0.0000],\n",
      "        [0.0076, 0.0038, 0.0313, 0.1088, 0.4910, 0.0811, 0.0655, 0.1186, 0.0676,\n",
      "         0.0099, 0.0103, 0.0019, 0.0013, 0.0000, 0.0000, 0.0001, 0.0002, 0.0004,\n",
      "         0.0006, 0.0000],\n",
      "        [0.0109, 0.0078, 0.0237, 0.0947, 0.2340, 0.2502, 0.0644, 0.2098, 0.0764,\n",
      "         0.0148, 0.0079, 0.0030, 0.0014, 0.0000, 0.0000, 0.0001, 0.0001, 0.0002,\n",
      "         0.0005, 0.0000],\n",
      "        [0.0059, 0.0065, 0.0281, 0.0184, 0.1655, 0.1929, 0.1525, 0.2069, 0.1503,\n",
      "         0.0254, 0.0340, 0.0085, 0.0028, 0.0002, 0.0001, 0.0002, 0.0002, 0.0006,\n",
      "         0.0009, 0.0000],\n",
      "        [0.0005, 0.0007, 0.0043, 0.0038, 0.0296, 0.0579, 0.1123, 0.1369, 0.2581,\n",
      "         0.0885, 0.2592, 0.0218, 0.0144, 0.0006, 0.0002, 0.0010, 0.0023, 0.0065,\n",
      "         0.0016, 0.0000],\n",
      "        [0.0007, 0.0002, 0.0007, 0.0030, 0.0198, 0.0535, 0.0240, 0.3050, 0.1351,\n",
      "         0.2325, 0.1483, 0.0550, 0.0202, 0.0003, 0.0001, 0.0002, 0.0002, 0.0006,\n",
      "         0.0003, 0.0000],\n",
      "        [0.0005, 0.0002, 0.0007, 0.0013, 0.0147, 0.0193, 0.0259, 0.2010, 0.1367,\n",
      "         0.1787, 0.2401, 0.1300, 0.0467, 0.0007, 0.0003, 0.0005, 0.0007, 0.0012,\n",
      "         0.0005, 0.0000],\n",
      "        [0.0001, 0.0001, 0.0004, 0.0006, 0.0035, 0.0058, 0.0173, 0.0469, 0.0717,\n",
      "         0.0911, 0.3545, 0.1747, 0.2010, 0.0068, 0.0024, 0.0057, 0.0067, 0.0093,\n",
      "         0.0015, 0.0000],\n",
      "        [0.0001, 0.0000, 0.0002, 0.0004, 0.0023, 0.0022, 0.0049, 0.0283, 0.0290,\n",
      "         0.0703, 0.1762, 0.3354, 0.3129, 0.0159, 0.0040, 0.0071, 0.0040, 0.0062,\n",
      "         0.0009, 0.0000],\n",
      "        [0.0001, 0.0000, 0.0003, 0.0001, 0.0008, 0.0003, 0.0024, 0.0033, 0.0085,\n",
      "         0.0068, 0.0783, 0.0620, 0.6042, 0.0410, 0.0442, 0.0319, 0.0262, 0.0854,\n",
      "         0.0041, 0.0000],\n",
      "        [0.0002, 0.0002, 0.0003, 0.0002, 0.0009, 0.0004, 0.0009, 0.0021, 0.0024,\n",
      "         0.0035, 0.0225, 0.0410, 0.5983, 0.1247, 0.0712, 0.0447, 0.0190, 0.0624,\n",
      "         0.0052, 0.0000],\n",
      "        [0.0003, 0.0002, 0.0004, 0.0003, 0.0021, 0.0011, 0.0013, 0.0032, 0.0048,\n",
      "         0.0048, 0.0244, 0.0607, 0.6750, 0.0961, 0.0714, 0.0212, 0.0057, 0.0228,\n",
      "         0.0042, 0.0000],\n",
      "        [0.0037, 0.0049, 0.0040, 0.0013, 0.0095, 0.0039, 0.0047, 0.0033, 0.0065,\n",
      "         0.0045, 0.0345, 0.0413, 0.5481, 0.1482, 0.1652, 0.0068, 0.0010, 0.0040,\n",
      "         0.0044, 0.0000],\n",
      "        [0.0041, 0.0040, 0.0019, 0.0029, 0.0083, 0.0087, 0.0041, 0.0094, 0.0072,\n",
      "         0.0129, 0.0299, 0.1042, 0.4779, 0.1352, 0.1407, 0.0227, 0.0040, 0.0107,\n",
      "         0.0112, 0.0000],\n",
      "        [0.0043, 0.0059, 0.0058, 0.0017, 0.0078, 0.0041, 0.0046, 0.0029, 0.0062,\n",
      "         0.0038, 0.0268, 0.0565, 0.3663, 0.1795, 0.2860, 0.0151, 0.0018, 0.0050,\n",
      "         0.0159, 0.0000],\n",
      "        [0.0007, 0.0015, 0.0023, 0.0014, 0.0022, 0.0024, 0.0021, 0.0024, 0.0037,\n",
      "         0.0033, 0.0141, 0.0442, 0.2642, 0.2676, 0.2330, 0.0636, 0.0281, 0.0409,\n",
      "         0.0222, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 4.38, Train Loss: 0.00, Val Loss: 5.25, Train BLEU: 0.00, Val BLEU: 4.57, Minutes Elapsed: 408.76\n",
      "Sampling from val predictions...\n",
      "Source: 2009 年 我 失去 了 一个 我 挚爱 的 人 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: in 2009 , i lost someone i loved very much . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> and : , i was a my my . <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0558, 0.8641, 0.0730, 0.0049, 0.0008, 0.0002, 0.0004, 0.0000, 0.0001,\n",
      "         0.0005, 0.0003, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0684, 0.8535, 0.0672, 0.0088, 0.0012, 0.0002, 0.0001, 0.0000, 0.0001,\n",
      "         0.0004, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0312, 0.2408, 0.5962, 0.1135, 0.0104, 0.0019, 0.0009, 0.0004, 0.0003,\n",
      "         0.0021, 0.0024, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0317, 0.0695, 0.8229, 0.0597, 0.0053, 0.0012, 0.0065, 0.0003, 0.0002,\n",
      "         0.0018, 0.0010, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0014, 0.0073, 0.1641, 0.7458, 0.0304, 0.0168, 0.0149, 0.0038, 0.0015,\n",
      "         0.0105, 0.0033, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0005, 0.0018, 0.0460, 0.5114, 0.1457, 0.1361, 0.0983, 0.0129, 0.0078,\n",
      "         0.0345, 0.0049, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0003, 0.0003, 0.0013, 0.0044, 0.0059, 0.2104, 0.3926, 0.1044, 0.0379,\n",
      "         0.2329, 0.0096, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0029, 0.0019, 0.0053, 0.0038, 0.0034, 0.0287, 0.3774, 0.1971, 0.0412,\n",
      "         0.2957, 0.0428, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0063, 0.0043, 0.0151, 0.0160, 0.0073, 0.0397, 0.3462, 0.3276, 0.0203,\n",
      "         0.1604, 0.0569, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0025, 0.0019, 0.0042, 0.0047, 0.0057, 0.0436, 0.3788, 0.3583, 0.0199,\n",
      "         0.1379, 0.0426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0142, 0.0133, 0.0126, 0.0115, 0.0065, 0.0300, 0.1533, 0.3803, 0.0347,\n",
      "         0.1521, 0.1915, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0249, 0.0173, 0.0274, 0.0140, 0.0053, 0.0135, 0.1579, 0.1816, 0.0196,\n",
      "         0.1659, 0.3726, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0215, 0.0092, 0.0333, 0.0398, 0.0130, 0.0285, 0.2380, 0.2195, 0.0163,\n",
      "         0.1105, 0.2704, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0063, 0.0051, 0.0138, 0.0816, 0.0304, 0.0211, 0.2687, 0.2315, 0.0352,\n",
      "         0.1486, 0.1577, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0027, 0.0029, 0.0148, 0.0451, 0.0246, 0.0218, 0.3537, 0.2403, 0.0290,\n",
      "         0.1473, 0.1178, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0041, 0.0058, 0.0272, 0.0463, 0.0114, 0.0126, 0.4041, 0.1615, 0.0149,\n",
      "         0.1278, 0.1844, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0049, 0.0065, 0.0341, 0.0409, 0.0107, 0.0149, 0.4468, 0.1294, 0.0101,\n",
      "         0.0979, 0.2037, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0072, 0.0104, 0.0471, 0.0473, 0.0108, 0.0140, 0.4131, 0.1117, 0.0087,\n",
      "         0.0991, 0.2307, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0099, 0.0156, 0.0598, 0.0549, 0.0110, 0.0130, 0.3686, 0.1054, 0.0084,\n",
      "         0.1066, 0.2468, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 4.44, Train Loss: 0.00, Val Loss: 5.16, Train BLEU: 0.00, Val BLEU: 5.11, Minutes Elapsed: 413.91\n",
      "Sampling from val predictions...\n",
      "Source: 我 只是 在 6 秒 内 就 彻底 彻底改变 改变 了 自己 在 你们 心中 的 形象 <EOS> <PAD> <PAD>\n",
      "Reference: i just totally transformed what you thought of me in six seconds . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> i i just in the and was in in in <EOS> life . <EOS> <EOS> own <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9124, 0.0853, 0.0007, 0.0003, 0.0002, 0.0006, 0.0005, 0.0001, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0337, 0.9531, 0.0092, 0.0015, 0.0006, 0.0007, 0.0004, 0.0005, 0.0000,\n",
      "         0.0001, 0.0000, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0653, 0.7665, 0.0876, 0.0277, 0.0170, 0.0081, 0.0031, 0.0074, 0.0015,\n",
      "         0.0024, 0.0009, 0.0028, 0.0006, 0.0012, 0.0006, 0.0005, 0.0016, 0.0051,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0051, 0.0257, 0.0581, 0.3959, 0.3355, 0.0359, 0.0036, 0.0188, 0.0136,\n",
      "         0.0178, 0.0025, 0.0199, 0.0011, 0.0132, 0.0051, 0.0022, 0.0282, 0.0176,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0025, 0.0029, 0.0190, 0.2832, 0.4815, 0.0458, 0.0073, 0.0124, 0.0099,\n",
      "         0.0337, 0.0023, 0.0380, 0.0007, 0.0132, 0.0059, 0.0015, 0.0246, 0.0157,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0070, 0.0024, 0.0097, 0.1428, 0.3534, 0.0707, 0.0237, 0.0390, 0.0211,\n",
      "         0.1150, 0.0060, 0.0908, 0.0019, 0.0496, 0.0104, 0.0020, 0.0224, 0.0320,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0172, 0.0023, 0.0020, 0.0089, 0.0272, 0.0137, 0.0415, 0.0992, 0.0254,\n",
      "         0.3142, 0.0173, 0.2953, 0.0071, 0.0951, 0.0109, 0.0012, 0.0069, 0.0146,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0018, 0.0022, 0.0058, 0.0084, 0.0110, 0.0055, 0.0081, 0.0452, 0.0505,\n",
      "         0.1807, 0.0204, 0.3109, 0.0197, 0.1882, 0.0722, 0.0081, 0.0451, 0.0160,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0003, 0.0001, 0.0008, 0.0078, 0.0084, 0.0014, 0.0012, 0.0046, 0.0216,\n",
      "         0.0957, 0.0163, 0.3615, 0.0149, 0.2374, 0.1394, 0.0140, 0.0606, 0.0142,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0014, 0.0004, 0.0022, 0.0103, 0.0095, 0.0030, 0.0017, 0.0052, 0.0268,\n",
      "         0.0629, 0.0078, 0.1893, 0.0286, 0.2602, 0.2454, 0.0188, 0.0956, 0.0309,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0036, 0.0010, 0.0042, 0.0224, 0.0332, 0.0143, 0.0113, 0.0184, 0.0180,\n",
      "         0.0763, 0.0155, 0.2757, 0.0357, 0.2358, 0.1416, 0.0101, 0.0439, 0.0390,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0024, 0.0007, 0.0025, 0.0123, 0.0096, 0.0030, 0.0020, 0.0048, 0.0140,\n",
      "         0.0267, 0.0034, 0.1271, 0.0139, 0.2432, 0.4016, 0.0077, 0.0809, 0.0442,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0102, 0.0009, 0.0045, 0.0406, 0.0654, 0.0224, 0.0124, 0.0179, 0.0154,\n",
      "         0.0720, 0.0163, 0.1652, 0.0278, 0.2036, 0.1685, 0.0063, 0.0423, 0.1082,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0134, 0.0016, 0.0033, 0.0235, 0.0409, 0.0118, 0.0105, 0.0148, 0.0085,\n",
      "         0.0527, 0.0072, 0.2047, 0.0172, 0.3227, 0.1808, 0.0026, 0.0180, 0.0659,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0113, 0.0054, 0.0108, 0.0133, 0.0153, 0.0058, 0.0079, 0.0225, 0.0125,\n",
      "         0.0342, 0.0048, 0.1514, 0.0133, 0.3650, 0.2452, 0.0018, 0.0144, 0.0650,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0004, 0.0017, 0.0024, 0.0020, 0.0017, 0.0008, 0.0007, 0.0092, 0.0070,\n",
      "         0.0160, 0.0031, 0.0635, 0.0126, 0.4259, 0.4084, 0.0060, 0.0161, 0.0224,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0003, 0.0009, 0.0016, 0.0012, 0.0010, 0.0005, 0.0006, 0.0057, 0.0037,\n",
      "         0.0145, 0.0034, 0.0676, 0.0208, 0.3896, 0.4121, 0.0132, 0.0354, 0.0279,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0018, 0.0013, 0.0016, 0.0011, 0.0012, 0.0007, 0.0020, 0.0129, 0.0062,\n",
      "         0.0224, 0.0037, 0.1033, 0.0163, 0.4092, 0.3482, 0.0029, 0.0167, 0.0485,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0031, 0.0013, 0.0015, 0.0014, 0.0014, 0.0009, 0.0021, 0.0123, 0.0053,\n",
      "         0.0234, 0.0038, 0.1292, 0.0146, 0.4508, 0.2823, 0.0020, 0.0124, 0.0525,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4.49, Train Loss: 0.00, Val Loss: 5.18, Train BLEU: 0.00, Val BLEU: 5.62, Minutes Elapsed: 419.07\n",
      "Sampling from val predictions...\n",
      "Source: 这 很 怪 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: that was awkward . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.8713, 0.1174, 0.0059, 0.0054, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2408, 0.4360, 0.2972, 0.0261, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1232, 0.5159, 0.3294, 0.0315, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0478, 0.2748, 0.6463, 0.0310, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0907, 0.1223, 0.4924, 0.2946, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2351, 0.0764, 0.1601, 0.5284, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1148, 0.3185, 0.3346, 0.2321, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0875, 0.2382, 0.3522, 0.3221, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2636, 0.2230, 0.1056, 0.4078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2812, 0.2804, 0.0949, 0.3435, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.3040, 0.2802, 0.0834, 0.3325, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.3089, 0.2766, 0.0784, 0.3361, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.3077, 0.2747, 0.0770, 0.3406, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.3059, 0.2745, 0.0767, 0.3429, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.3042, 0.2749, 0.0767, 0.3442, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.3026, 0.2756, 0.0767, 0.3452, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.3011, 0.2763, 0.0766, 0.3461, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2997, 0.2768, 0.0764, 0.3471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2984, 0.2773, 0.0761, 0.3482, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 4.55, Train Loss: 0.00, Val Loss: 5.15, Train BLEU: 0.00, Val BLEU: 5.12, Minutes Elapsed: 424.21\n",
      "Sampling from val predictions...\n",
      "Source: 谢谢 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: thank you . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> thank you . <EOS> you <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> you you\n",
      "Attention Weights: tensor([[0.9988, 0.0012, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.9931, 0.0069, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.9425, 0.0574, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2585, 0.7415, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2408, 0.7592, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.5014, 0.4986, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.4532, 0.5468, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.7479, 0.2521, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.8116, 0.1884, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.8563, 0.1437, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.8778, 0.1222, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.8921, 0.1079, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.9000, 0.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.9049, 0.0951, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.9082, 0.0918, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.9107, 0.0893, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.9126, 0.0874, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.9140, 0.0860, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.9150, 0.0850, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4.60, Train Loss: 0.00, Val Loss: 5.16, Train BLEU: 0.00, Val BLEU: 5.24, Minutes Elapsed: 429.36\n",
      "Sampling from val predictions...\n",
      "Source: 这些 光会 反射 射进 进入 房间 一些 会 返回 回到 门上 然后 后进 进入 照相 照相机 相机 这样 我们 就\n",
      "Reference: it &apos;s going to bounce , go inside the room , some of that is going to reflect back\n",
      "Model: <SOS> these , to to be back and , and , , and we we , . . . .\n",
      "Attention Weights: tensor([[4.6027e-01, 3.8181e-02, 7.5439e-02, 5.0506e-03, 9.5843e-03, 5.2556e-02,\n",
      "         2.7625e-01, 7.8316e-02, 2.5167e-03, 1.1873e-03, 5.8926e-05, 2.2530e-05,\n",
      "         1.4503e-05, 9.4098e-06, 5.2670e-06, 1.3241e-06, 2.0082e-06, 5.2104e-04,\n",
      "         1.1150e-05, 7.6358e-08],\n",
      "        [7.5332e-02, 4.7504e-02, 2.7120e-01, 7.2605e-02, 6.9432e-02, 1.6438e-01,\n",
      "         5.7650e-02, 1.2797e-01, 6.6265e-02, 4.1663e-02, 3.2173e-03, 6.7726e-04,\n",
      "         5.6558e-04, 5.2290e-04, 1.9458e-04, 7.5504e-05, 1.1976e-04, 4.0424e-04,\n",
      "         2.1333e-04, 1.0713e-05],\n",
      "        [9.7575e-03, 9.2908e-03, 6.4512e-02, 4.9320e-02, 1.2670e-01, 1.3295e-01,\n",
      "         7.0471e-02, 1.8000e-01, 1.7115e-01, 1.4338e-01, 2.3099e-02, 6.0880e-03,\n",
      "         4.1857e-03, 5.0578e-03, 1.1810e-03, 4.8063e-04, 5.7320e-04, 1.1450e-03,\n",
      "         5.2276e-04, 1.3835e-04],\n",
      "        [1.1294e-02, 2.5952e-02, 4.8828e-02, 2.8684e-02, 2.2169e-02, 1.5884e-01,\n",
      "         1.9799e-01, 4.8036e-02, 9.3592e-02, 2.1875e-01, 7.4322e-02, 1.7761e-02,\n",
      "         1.4494e-02, 1.5198e-02, 1.3459e-02, 4.5379e-03, 2.4253e-03, 1.9971e-03,\n",
      "         1.4610e-03, 2.0521e-04],\n",
      "        [1.3591e-02, 2.0659e-02, 4.3310e-02, 2.2803e-02, 1.5564e-02, 9.1352e-02,\n",
      "         1.5622e-01, 6.3319e-02, 9.3849e-02, 2.2540e-01, 1.0672e-01, 3.9855e-02,\n",
      "         2.6081e-02, 3.1114e-02, 2.9270e-02, 9.0720e-03, 5.9394e-03, 3.3017e-03,\n",
      "         2.3105e-03, 2.7151e-04],\n",
      "        [3.9095e-03, 7.7576e-03, 1.8934e-02, 2.0156e-02, 1.0985e-02, 1.1639e-01,\n",
      "         4.7782e-02, 1.1071e-02, 5.0580e-02, 2.2101e-01, 1.8321e-01, 7.1476e-02,\n",
      "         5.5949e-02, 4.7723e-02, 8.6306e-02, 1.8608e-02, 1.1639e-02, 1.3319e-02,\n",
      "         2.8543e-03, 3.4015e-04],\n",
      "        [7.1210e-03, 1.1572e-02, 2.2281e-02, 1.1877e-02, 3.7295e-03, 8.5268e-02,\n",
      "         3.4377e-02, 3.4611e-03, 1.5050e-02, 8.6711e-02, 2.1416e-01, 8.9748e-02,\n",
      "         8.1057e-02, 6.3218e-02, 1.7118e-01, 4.4117e-02, 3.2490e-02, 1.9493e-02,\n",
      "         2.7361e-03, 3.4758e-04],\n",
      "        [2.7858e-02, 1.7688e-02, 3.6146e-02, 1.3332e-02, 5.4782e-03, 1.3708e-01,\n",
      "         3.7644e-02, 3.7664e-03, 1.1654e-02, 4.2828e-02, 1.1947e-01, 1.1633e-01,\n",
      "         7.5744e-02, 6.0798e-02, 1.2075e-01, 3.4584e-02, 4.2185e-02, 8.0761e-02,\n",
      "         1.5110e-02, 7.8680e-04],\n",
      "        [3.1394e-03, 3.0366e-03, 4.5523e-03, 3.2318e-03, 2.9402e-03, 2.7434e-02,\n",
      "         1.9893e-02, 6.2324e-03, 4.1133e-02, 1.0620e-01, 1.6273e-01, 7.6077e-02,\n",
      "         7.6265e-02, 1.1865e-01, 1.3966e-01, 4.9696e-02, 6.0153e-02, 5.2422e-02,\n",
      "         3.8470e-02, 8.0866e-03],\n",
      "        [1.1079e-03, 1.1589e-03, 1.8208e-03, 1.2926e-03, 6.0423e-04, 1.3921e-02,\n",
      "         5.7851e-03, 8.1548e-04, 4.5702e-03, 2.7507e-02, 1.2560e-01, 5.9465e-02,\n",
      "         5.7816e-02, 6.6197e-02, 2.3451e-01, 9.6369e-02, 1.2245e-01, 1.2327e-01,\n",
      "         4.5535e-02, 1.0199e-02],\n",
      "        [2.1495e-03, 1.2760e-03, 1.9374e-03, 9.4726e-04, 3.5009e-04, 9.4785e-03,\n",
      "         3.8876e-03, 4.4076e-04, 8.2446e-04, 3.5049e-03, 1.7788e-02, 1.7367e-02,\n",
      "         1.2718e-02, 1.4071e-02, 4.3715e-02, 2.6366e-02, 3.8038e-02, 3.8347e-01,\n",
      "         3.8240e-01, 3.9266e-02],\n",
      "        [5.6914e-03, 1.4569e-03, 3.6482e-03, 2.1111e-03, 2.6583e-03, 5.6252e-03,\n",
      "         5.4615e-03, 2.8020e-03, 4.6865e-03, 9.2466e-03, 1.5587e-02, 2.4250e-02,\n",
      "         1.0637e-02, 1.4519e-02, 8.9263e-03, 8.0085e-03, 1.5419e-02, 3.4939e-01,\n",
      "         4.2884e-01, 8.1037e-02],\n",
      "        [3.4479e-03, 1.1655e-03, 1.1620e-03, 7.3950e-04, 1.5123e-03, 5.9368e-03,\n",
      "         6.2253e-03, 2.7925e-03, 5.9733e-03, 1.2161e-02, 1.3927e-02, 7.3287e-03,\n",
      "         4.9296e-03, 6.5668e-03, 2.8333e-03, 1.6301e-03, 3.2531e-03, 1.3148e-01,\n",
      "         5.1755e-01, 2.6938e-01],\n",
      "        [8.1328e-04, 4.8287e-04, 5.6250e-04, 4.5999e-04, 8.6401e-04, 1.8036e-03,\n",
      "         1.5195e-03, 2.4229e-03, 7.0117e-03, 1.1915e-02, 8.6653e-03, 5.2342e-03,\n",
      "         3.1618e-03, 7.9419e-03, 2.8103e-03, 1.8090e-03, 3.2866e-03, 4.4701e-02,\n",
      "         4.9125e-01, 4.0329e-01],\n",
      "        [1.9094e-03, 1.3169e-03, 1.4417e-03, 1.3284e-03, 2.8421e-03, 3.5361e-03,\n",
      "         3.5764e-03, 8.0230e-03, 2.0790e-02, 2.8425e-02, 1.5951e-02, 1.1046e-02,\n",
      "         7.4629e-03, 1.2545e-02, 5.6426e-03, 3.2665e-03, 4.1880e-03, 5.0416e-02,\n",
      "         4.1614e-01, 4.0015e-01],\n",
      "        [7.1249e-03, 2.6579e-03, 4.5997e-03, 4.8578e-03, 1.5948e-02, 9.7992e-03,\n",
      "         7.7020e-03, 2.7587e-02, 5.2862e-02, 4.9349e-02, 2.8412e-02, 2.3040e-02,\n",
      "         1.7304e-02, 2.7970e-02, 1.1523e-02, 7.3260e-03, 1.0932e-02, 7.2878e-02,\n",
      "         3.5787e-01, 2.6026e-01],\n",
      "        [6.2689e-03, 3.7827e-03, 6.3869e-03, 6.1706e-03, 6.5875e-03, 1.0361e-02,\n",
      "         4.1552e-03, 8.6888e-03, 4.4425e-02, 6.7949e-02, 3.8231e-02, 2.1137e-02,\n",
      "         1.4547e-02, 2.3971e-02, 1.4121e-02, 7.9568e-03, 1.2286e-02, 5.9987e-02,\n",
      "         4.3851e-01, 2.0447e-01],\n",
      "        [8.3071e-03, 5.1448e-03, 1.0453e-02, 7.6401e-03, 4.1923e-03, 1.8186e-02,\n",
      "         4.5777e-03, 3.0335e-03, 2.5097e-02, 6.8788e-02, 5.4736e-02, 3.0022e-02,\n",
      "         2.3322e-02, 3.3447e-02, 2.6161e-02, 1.3499e-02, 2.1658e-02, 6.3078e-02,\n",
      "         4.6346e-01, 1.1520e-01],\n",
      "        [4.6044e-03, 3.9438e-03, 5.4697e-03, 6.4243e-03, 4.5111e-03, 3.4477e-02,\n",
      "         5.3876e-03, 2.0805e-03, 1.7560e-02, 7.0975e-02, 1.3979e-01, 5.5324e-02,\n",
      "         6.4486e-02, 4.8426e-02, 1.7698e-01, 7.0098e-02, 4.8046e-02, 8.2933e-02,\n",
      "         1.2382e-01, 3.4657e-02]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 4.66, Train Loss: 0.00, Val Loss: 5.18, Train BLEU: 0.00, Val BLEU: 5.38, Minutes Elapsed: 434.52\n",
      "Sampling from val predictions...\n",
      "Source: 赞比亚 比亚 人 说 没错 这 就是 我们 不在 这里 耕种 的 原因 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: and the <UNK> said , &quot; yes , that &apos;s why we have no agriculture here . &quot; <EOS>\n",
      "Model: <SOS> the , said said , &quot; that , that &apos;s why we &apos;re &apos;t . . &quot; <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0232, 0.3653, 0.6004, 0.0104, 0.0005, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0076, 0.1610, 0.7074, 0.1107, 0.0073, 0.0056, 0.0002, 0.0001, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0020, 0.0315, 0.2314, 0.6291, 0.0992, 0.0050, 0.0006, 0.0001, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0002, 0.0008, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0013, 0.0265, 0.2113, 0.6552, 0.1002, 0.0044, 0.0006, 0.0001, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0001, 0.0004, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0009, 0.0365, 0.1302, 0.7504, 0.0769, 0.0039, 0.0006, 0.0002, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0004, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0002, 0.0032, 0.0235, 0.3160, 0.5379, 0.0968, 0.0082, 0.0091, 0.0008,\n",
      "         0.0002, 0.0002, 0.0001, 0.0020, 0.0016, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0002, 0.0025, 0.0131, 0.0927, 0.5919, 0.2594, 0.0210, 0.0135, 0.0013,\n",
      "         0.0002, 0.0001, 0.0001, 0.0029, 0.0011, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0009, 0.0042, 0.0561, 0.5104, 0.2659, 0.0799, 0.0608, 0.0107,\n",
      "         0.0004, 0.0002, 0.0003, 0.0085, 0.0017, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0004, 0.0012, 0.0166, 0.2256, 0.3565, 0.1422, 0.2025, 0.0276,\n",
      "         0.0016, 0.0010, 0.0009, 0.0209, 0.0029, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0002, 0.0008, 0.0040, 0.0575, 0.4629, 0.1272, 0.2446, 0.0544,\n",
      "         0.0021, 0.0011, 0.0008, 0.0368, 0.0077, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0001, 0.0012, 0.0255, 0.0371, 0.0715, 0.3387, 0.4720,\n",
      "         0.0145, 0.0056, 0.0016, 0.0310, 0.0011, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0002, 0.0013, 0.0081, 0.0071, 0.3955, 0.3742,\n",
      "         0.0567, 0.0363, 0.0034, 0.1141, 0.0032, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0002, 0.0005, 0.0004, 0.0015, 0.0045, 0.0049, 0.3398, 0.2891,\n",
      "         0.1093, 0.1522, 0.0074, 0.0817, 0.0084, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0001, 0.0007, 0.0036, 0.0056, 0.0042, 0.0909, 0.5533,\n",
      "         0.1333, 0.1605, 0.0050, 0.0386, 0.0040, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0001, 0.0002, 0.0016, 0.0003, 0.0108, 0.0430,\n",
      "         0.4979, 0.3122, 0.0130, 0.1028, 0.0181, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0001, 0.0002, 0.0003, 0.0001, 0.0002, 0.0034, 0.0005, 0.0133, 0.0141,\n",
      "         0.4227, 0.2725, 0.0155, 0.1196, 0.1375, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0003, 0.0009, 0.0020, 0.0004, 0.0005, 0.0026, 0.0006, 0.0175, 0.0140,\n",
      "         0.2491, 0.4026, 0.0056, 0.1056, 0.1984, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0010, 0.0056, 0.0085, 0.0041, 0.0140, 0.0528, 0.0107, 0.0535, 0.0519,\n",
      "         0.2140, 0.1750, 0.0063, 0.0758, 0.3268, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0022, 0.0102, 0.0113, 0.0041, 0.0155, 0.0438, 0.0078, 0.0479, 0.0516,\n",
      "         0.1924, 0.1855, 0.0059, 0.0987, 0.3231, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4.71, Train Loss: 0.00, Val Loss: 5.17, Train BLEU: 0.00, Val BLEU: 5.29, Minutes Elapsed: 439.69\n",
      "Sampling from val predictions...\n",
      "Source: 看看 以 一位 位非 非洲 女性 的 眼光 我们 所 带来 的 损害 有 多 大 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: read it from an african woman , the damage that we have done . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> look , the a , of , in , of our are to . . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9968, 0.0016, 0.0009, 0.0001, 0.0003, 0.0001, 0.0000, 0.0001, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.6979, 0.0393, 0.1318, 0.0095, 0.0331, 0.0333, 0.0023, 0.0314, 0.0110,\n",
      "         0.0014, 0.0018, 0.0005, 0.0038, 0.0004, 0.0006, 0.0009, 0.0010, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1535, 0.0682, 0.1372, 0.0373, 0.1395, 0.0920, 0.0141, 0.0749, 0.0585,\n",
      "         0.0231, 0.0393, 0.0094, 0.0500, 0.0087, 0.0187, 0.0324, 0.0431, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0188, 0.0298, 0.4044, 0.0290, 0.2342, 0.1482, 0.0160, 0.0747, 0.0167,\n",
      "         0.0030, 0.0038, 0.0017, 0.0062, 0.0008, 0.0019, 0.0059, 0.0050, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0258, 0.0208, 0.1574, 0.0441, 0.2697, 0.1627, 0.0089, 0.1361, 0.0234,\n",
      "         0.0032, 0.0215, 0.0072, 0.0304, 0.0042, 0.0194, 0.0479, 0.0173, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0138, 0.0170, 0.0841, 0.0579, 0.4031, 0.2386, 0.0129, 0.1172, 0.0396,\n",
      "         0.0010, 0.0025, 0.0006, 0.0032, 0.0004, 0.0012, 0.0035, 0.0033, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0126, 0.0149, 0.0483, 0.0567, 0.6120, 0.1689, 0.0053, 0.0450, 0.0227,\n",
      "         0.0016, 0.0035, 0.0005, 0.0035, 0.0004, 0.0010, 0.0013, 0.0017, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0143, 0.0247, 0.0657, 0.0272, 0.3626, 0.1030, 0.0064, 0.0379, 0.2152,\n",
      "         0.0202, 0.0543, 0.0048, 0.0257, 0.0096, 0.0130, 0.0071, 0.0082, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0091, 0.0126, 0.0480, 0.0094, 0.1325, 0.0449, 0.0031, 0.0216, 0.3185,\n",
      "         0.0712, 0.1635, 0.0108, 0.0614, 0.0272, 0.0364, 0.0164, 0.0133, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0005, 0.0009, 0.0023, 0.0010, 0.0125, 0.0135, 0.0022, 0.0156, 0.2765,\n",
      "         0.1413, 0.2676, 0.0245, 0.1324, 0.0331, 0.0435, 0.0264, 0.0062, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0019, 0.0012, 0.0034, 0.0018, 0.0486, 0.0320, 0.0028, 0.0446, 0.5859,\n",
      "         0.0549, 0.1200, 0.0072, 0.0620, 0.0102, 0.0139, 0.0075, 0.0023, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0005, 0.0003, 0.0009, 0.0002, 0.0066, 0.0051, 0.0007, 0.0057, 0.4066,\n",
      "         0.1077, 0.3090, 0.0085, 0.0910, 0.0190, 0.0259, 0.0095, 0.0029, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0003, 0.0002, 0.0006, 0.0001, 0.0016, 0.0017, 0.0005, 0.0027, 0.0634,\n",
      "         0.0940, 0.4078, 0.0207, 0.2517, 0.0677, 0.0646, 0.0197, 0.0028, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0002, 0.0002, 0.0029, 0.0004, 0.0022, 0.0045, 0.0005, 0.0026, 0.0090,\n",
      "         0.0122, 0.2421, 0.0453, 0.2178, 0.1357, 0.2168, 0.0967, 0.0109, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0003, 0.0004, 0.0033, 0.0006, 0.0039, 0.0058, 0.0005, 0.0024, 0.0092,\n",
      "         0.0049, 0.0746, 0.0336, 0.0801, 0.1367, 0.2889, 0.3281, 0.0267, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0008, 0.0015, 0.0075, 0.0014, 0.0105, 0.0149, 0.0018, 0.0061, 0.0111,\n",
      "         0.0119, 0.0923, 0.0306, 0.0952, 0.0977, 0.2018, 0.3883, 0.0267, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0001, 0.0002, 0.0012, 0.0003, 0.0028, 0.0039, 0.0004, 0.0023, 0.0127,\n",
      "         0.0300, 0.1853, 0.0212, 0.1698, 0.1974, 0.2261, 0.1304, 0.0158, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0003, 0.0004, 0.0029, 0.0003, 0.0047, 0.0066, 0.0008, 0.0031, 0.0227,\n",
      "         0.0366, 0.1508, 0.0225, 0.0960, 0.1602, 0.2202, 0.1755, 0.0964, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0012, 0.0012, 0.0073, 0.0008, 0.0123, 0.0135, 0.0018, 0.0120, 0.1137,\n",
      "         0.0424, 0.1372, 0.0142, 0.0420, 0.0772, 0.1223, 0.1741, 0.2267, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 4.82, Train Loss: 0.00, Val Loss: 5.16, Train BLEU: 0.00, Val BLEU: 5.08, Minutes Elapsed: 450.02\n",
      "Sampling from val predictions...\n",
      "Source: 到 时人 人们 将 会 被 <UNK> 淹没 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: they were already drowning in manure . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> and the them to the the . <EOS> <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.6540, 0.1043, 0.2374, 0.0017, 0.0018, 0.0001, 0.0000, 0.0000, 0.0006,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0167, 0.0953, 0.7279, 0.0274, 0.0852, 0.0116, 0.0019, 0.0055, 0.0284,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0488, 0.0578, 0.3562, 0.0795, 0.2386, 0.0556, 0.0191, 0.0526, 0.0918,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0103, 0.0140, 0.1063, 0.0417, 0.2488, 0.2832, 0.0803, 0.1155, 0.0999,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0333, 0.0355, 0.1709, 0.0257, 0.2242, 0.2883, 0.0732, 0.0755, 0.0735,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0220, 0.0191, 0.0707, 0.0239, 0.1831, 0.3271, 0.0863, 0.1178, 0.1502,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0444, 0.0598, 0.1363, 0.0220, 0.1668, 0.2578, 0.0736, 0.1139, 0.1255,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1569, 0.1413, 0.1473, 0.0317, 0.0982, 0.1211, 0.0364, 0.0544, 0.2126,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0672, 0.0820, 0.1471, 0.0201, 0.0897, 0.1516, 0.0716, 0.1212, 0.2493,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0043, 0.0039, 0.0356, 0.0446, 0.2500, 0.1740, 0.0957, 0.2808, 0.1111,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0014, 0.0009, 0.0097, 0.0212, 0.1964, 0.2565, 0.1068, 0.3074, 0.0997,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0057, 0.0018, 0.0447, 0.0206, 0.2040, 0.2426, 0.0368, 0.1310, 0.3128,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0076, 0.0036, 0.0485, 0.0198, 0.1668, 0.2229, 0.0320, 0.1319, 0.3668,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0132, 0.0076, 0.0595, 0.0231, 0.1502, 0.2046, 0.0286, 0.1124, 0.4010,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0177, 0.0103, 0.0665, 0.0251, 0.1387, 0.1909, 0.0270, 0.0996, 0.4243,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0206, 0.0124, 0.0719, 0.0265, 0.1317, 0.1826, 0.0264, 0.0928, 0.4351,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0230, 0.0142, 0.0772, 0.0277, 0.1268, 0.1764, 0.0260, 0.0881, 0.4407,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0251, 0.0158, 0.0822, 0.0289, 0.1233, 0.1719, 0.0256, 0.0847, 0.4426,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0269, 0.0173, 0.0870, 0.0300, 0.1208, 0.1686, 0.0254, 0.0820, 0.4419,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 4.88, Train Loss: 0.00, Val Loss: 5.16, Train BLEU: 0.00, Val BLEU: 5.39, Minutes Elapsed: 455.20\n",
      "Sampling from val predictions...\n",
      "Source: 几千 几千人 成为 <UNK> 餐馆 <UNK> 家庭 <UNK> 还 不止 这些 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: tens of hundreds of people are enslaved in agriculture , in restaurants , in domestic <UNK> , and the\n",
      "Model: <SOS> and &apos;s these , been , the , and . <EOS> they . <EOS> &apos;t . <EOS> <EOS> .\n",
      "Attention Weights: tensor([[0.9733, 0.0127, 0.0060, 0.0001, 0.0003, 0.0001, 0.0016, 0.0007, 0.0039,\n",
      "         0.0008, 0.0003, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.4837, 0.2693, 0.1479, 0.0070, 0.0062, 0.0042, 0.0219, 0.0163, 0.0059,\n",
      "         0.0259, 0.0076, 0.0043, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2041, 0.2139, 0.1983, 0.0306, 0.0221, 0.0145, 0.0296, 0.0342, 0.0274,\n",
      "         0.1425, 0.0468, 0.0360, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0640, 0.0751, 0.2563, 0.1582, 0.1505, 0.0387, 0.0724, 0.0249, 0.0109,\n",
      "         0.0517, 0.0508, 0.0465, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1451, 0.0841, 0.3356, 0.0582, 0.1339, 0.0484, 0.1096, 0.0364, 0.0214,\n",
      "         0.0106, 0.0042, 0.0127, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0104, 0.0099, 0.0810, 0.1163, 0.2699, 0.0732, 0.1444, 0.0526, 0.0325,\n",
      "         0.0843, 0.0573, 0.0680, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0137, 0.0080, 0.0737, 0.0733, 0.2740, 0.1356, 0.2310, 0.0857, 0.0674,\n",
      "         0.0195, 0.0049, 0.0133, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0030, 0.0020, 0.0113, 0.0581, 0.2233, 0.0829, 0.1989, 0.0625, 0.0328,\n",
      "         0.0867, 0.1266, 0.1117, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0024, 0.0017, 0.0095, 0.0697, 0.2043, 0.1090, 0.2520, 0.0508, 0.0265,\n",
      "         0.0668, 0.1492, 0.0581, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0071, 0.0026, 0.0081, 0.0224, 0.0739, 0.0376, 0.1826, 0.0660, 0.1069,\n",
      "         0.1867, 0.2128, 0.0932, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0248, 0.0065, 0.0153, 0.0157, 0.0559, 0.0444, 0.1596, 0.0589, 0.3858,\n",
      "         0.1667, 0.0323, 0.0341, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0033, 0.0018, 0.0037, 0.0024, 0.0039, 0.0022, 0.0096, 0.0062, 0.0981,\n",
      "         0.4801, 0.3319, 0.0569, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0003, 0.0002, 0.0007, 0.0007, 0.0013, 0.0009, 0.0030, 0.0031, 0.0425,\n",
      "         0.6988, 0.2340, 0.0145, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0075, 0.0040, 0.0060, 0.0084, 0.0167, 0.0142, 0.0438, 0.0364, 0.3805,\n",
      "         0.2698, 0.1485, 0.0643, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0027, 0.0017, 0.0034, 0.0042, 0.0094, 0.0052, 0.0202, 0.0115, 0.0563,\n",
      "         0.3851, 0.4242, 0.0761, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0003, 0.0003, 0.0008, 0.0008, 0.0013, 0.0008, 0.0026, 0.0016, 0.0200,\n",
      "         0.6323, 0.3200, 0.0194, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0102, 0.0062, 0.0125, 0.0115, 0.0235, 0.0167, 0.0535, 0.0379, 0.2061,\n",
      "         0.2313, 0.2310, 0.1594, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0070, 0.0045, 0.0070, 0.0085, 0.0197, 0.0108, 0.0359, 0.0241, 0.0698,\n",
      "         0.3028, 0.3403, 0.1697, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0057, 0.0037, 0.0072, 0.0105, 0.0201, 0.0113, 0.0436, 0.0201, 0.0558,\n",
      "         0.3453, 0.3191, 0.1578, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4.93, Train Loss: 0.00, Val Loss: 5.28, Train BLEU: 0.00, Val BLEU: 5.03, Minutes Elapsed: 460.37\n",
      "Sampling from val predictions...\n",
      "Source: 尽管 她们 被 抓住 了 但是 <UNK> 巨大 的 国际 <UNK> 舆论 <UNK> 压力 她们 最终 被 释放 了 <EOS>\n",
      "Reference: even though they were caught , they were eventually released after heavy international pressure . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> and they they they , , , they the , the the . . <EOS> <EOS> <EOS> . <EOS>\n",
      "Attention Weights: tensor([[1.0899e-01, 8.8196e-01, 8.6218e-03, 2.7010e-04, 1.8200e-05, 2.0886e-05,\n",
      "         3.5542e-06, 2.0424e-05, 3.4665e-06, 4.5659e-05, 2.8812e-06, 9.4374e-06,\n",
      "         3.4989e-06, 1.3047e-05, 1.1550e-05, 1.0745e-06, 7.4694e-07, 2.2303e-07,\n",
      "         3.5908e-07, 2.4323e-06],\n",
      "        [1.6442e-02, 8.7785e-01, 8.4943e-02, 1.2796e-02, 2.7427e-04, 5.7257e-04,\n",
      "         1.7563e-04, 1.0617e-03, 1.9223e-04, 4.1019e-03, 2.9134e-04, 5.1144e-04,\n",
      "         1.7592e-04, 2.9530e-04, 1.4770e-04, 2.7333e-05, 1.3596e-05, 9.2995e-06,\n",
      "         8.7489e-06, 1.1223e-04],\n",
      "        [1.4978e-02, 2.1902e-01, 4.0234e-01, 2.9537e-01, 1.4721e-02, 1.4261e-02,\n",
      "         2.9988e-03, 1.0905e-02, 9.8043e-04, 1.7325e-02, 1.6440e-03, 2.5780e-03,\n",
      "         7.5880e-04, 8.1196e-04, 1.8996e-04, 1.8477e-04, 6.2532e-05, 5.9791e-05,\n",
      "         2.4564e-05, 7.8894e-04],\n",
      "        [1.5636e-03, 3.8861e-02, 2.4716e-01, 5.0143e-01, 5.4376e-02, 4.3404e-02,\n",
      "         8.6766e-03, 4.1913e-02, 3.0763e-03, 4.4340e-02, 3.2532e-03, 5.3875e-03,\n",
      "         1.3175e-03, 1.4250e-03, 3.9581e-04, 4.7201e-04, 2.6966e-04, 2.6283e-04,\n",
      "         2.2345e-04, 2.1932e-03],\n",
      "        [2.4923e-04, 2.3085e-03, 1.4068e-02, 7.1114e-02, 5.2654e-02, 3.5938e-01,\n",
      "         5.6964e-02, 1.9694e-01, 9.2560e-03, 2.0490e-01, 7.1627e-03, 1.0805e-02,\n",
      "         2.5627e-03, 3.2569e-03, 1.0469e-03, 1.4744e-03, 6.7657e-04, 5.4984e-04,\n",
      "         5.3757e-04, 4.0982e-03],\n",
      "        [1.9103e-04, 2.5258e-04, 1.9724e-03, 1.1923e-02, 2.3413e-02, 4.9418e-01,\n",
      "         6.2837e-02, 2.2009e-01, 1.2150e-02, 1.4503e-01, 7.2340e-03, 1.0030e-02,\n",
      "         2.8377e-03, 3.0101e-03, 9.4459e-04, 6.6896e-04, 3.0294e-04, 2.5839e-04,\n",
      "         4.0771e-04, 2.2680e-03],\n",
      "        [1.2524e-04, 1.1551e-04, 4.5596e-04, 9.8802e-04, 2.2246e-03, 4.3280e-01,\n",
      "         6.2676e-02, 1.5797e-01, 1.2416e-02, 2.8721e-01, 1.6582e-02, 1.6027e-02,\n",
      "         4.1400e-03, 3.6669e-03, 9.7280e-04, 4.2517e-04, 8.4317e-05, 5.6974e-05,\n",
      "         5.5540e-05, 1.0059e-03],\n",
      "        [8.0896e-04, 8.3697e-04, 1.3592e-03, 1.2480e-03, 1.4337e-03, 1.8878e-01,\n",
      "         4.2868e-02, 1.2871e-01, 1.3612e-02, 4.9866e-01, 3.9195e-02, 3.4617e-02,\n",
      "         1.2723e-02, 1.8077e-02, 9.1258e-03, 2.4268e-03, 8.1112e-04, 3.0987e-04,\n",
      "         2.7376e-04, 4.1329e-03],\n",
      "        [1.9989e-04, 7.3871e-04, 9.8096e-04, 1.4031e-03, 2.0175e-03, 7.6468e-02,\n",
      "         6.0761e-02, 1.4561e-01, 1.1213e-02, 4.4112e-01, 6.2745e-02, 6.6307e-02,\n",
      "         3.6316e-02, 6.4218e-02, 1.2697e-02, 1.0651e-02, 1.9397e-03, 2.0567e-03,\n",
      "         4.3783e-04, 2.1227e-03],\n",
      "        [3.8530e-05, 3.8714e-05, 1.7964e-04, 4.3701e-04, 1.4614e-03, 1.3779e-01,\n",
      "         7.1248e-02, 2.8663e-01, 1.9962e-02, 1.8571e-01, 3.0365e-02, 4.4781e-02,\n",
      "         2.8032e-02, 4.6247e-02, 2.6843e-02, 2.8286e-02, 1.7009e-02, 2.2304e-02,\n",
      "         2.3918e-02, 2.8717e-02],\n",
      "        [6.3941e-05, 4.4967e-05, 1.0400e-04, 1.8733e-04, 2.1236e-04, 7.7336e-02,\n",
      "         5.3388e-02, 1.2582e-01, 1.8245e-02, 3.1306e-01, 7.2950e-02, 8.0857e-02,\n",
      "         4.9411e-02, 7.2099e-02, 5.6804e-02, 3.3318e-02, 1.1557e-02, 7.7398e-03,\n",
      "         4.0784e-03, 2.2726e-02],\n",
      "        [1.0667e-04, 1.1613e-04, 1.8514e-04, 2.7491e-04, 2.6687e-04, 3.1258e-02,\n",
      "         2.2404e-02, 6.4641e-02, 1.1114e-02, 4.1256e-01, 6.1850e-02, 5.6806e-02,\n",
      "         4.2632e-02, 7.5809e-02, 1.1048e-01, 6.2964e-02, 1.8700e-02, 8.8090e-03,\n",
      "         2.5354e-03, 1.6487e-02],\n",
      "        [5.8919e-04, 5.3294e-04, 8.1028e-04, 8.3744e-04, 4.3129e-04, 2.0300e-02,\n",
      "         1.7041e-02, 5.6597e-02, 6.3932e-03, 3.2072e-01, 2.9317e-02, 2.2031e-02,\n",
      "         1.8621e-02, 4.8133e-02, 2.7818e-01, 9.7604e-02, 4.1364e-02, 1.4159e-02,\n",
      "         3.1562e-03, 2.3185e-02],\n",
      "        [9.3535e-04, 1.2934e-03, 2.2952e-03, 1.5596e-03, 4.0155e-04, 1.6706e-02,\n",
      "         1.5434e-02, 1.7653e-02, 4.1759e-03, 2.0437e-01, 4.7919e-02, 4.0464e-02,\n",
      "         3.7369e-02, 6.0350e-02, 2.4415e-01, 1.8588e-01, 7.4982e-02, 2.1523e-02,\n",
      "         2.3379e-03, 2.0196e-02],\n",
      "        [7.9189e-04, 1.2481e-03, 1.8412e-03, 1.4931e-03, 6.4400e-04, 1.5648e-02,\n",
      "         9.5726e-03, 1.2032e-02, 2.2802e-03, 7.0917e-02, 1.0908e-02, 1.0088e-02,\n",
      "         8.8842e-03, 1.8314e-02, 1.9217e-01, 2.9392e-01, 2.2353e-01, 6.2021e-02,\n",
      "         1.2234e-02, 5.1464e-02],\n",
      "        [6.5746e-04, 1.1014e-03, 2.6507e-03, 1.9156e-03, 9.7743e-04, 1.2148e-02,\n",
      "         4.7997e-03, 7.9722e-03, 1.3407e-03, 2.2885e-02, 3.2499e-03, 3.2818e-03,\n",
      "         2.8900e-03, 7.3303e-03, 1.0084e-01, 2.9869e-01, 3.4662e-01, 9.4444e-02,\n",
      "         2.2521e-02, 6.3679e-02],\n",
      "        [1.1916e-03, 1.5607e-03, 4.0676e-03, 3.9975e-03, 2.2646e-03, 2.3677e-02,\n",
      "         8.5538e-03, 1.9467e-02, 2.8655e-03, 6.3068e-02, 6.4240e-03, 6.7548e-03,\n",
      "         4.8556e-03, 1.0649e-02, 8.8821e-02, 2.1470e-01, 2.4068e-01, 1.0923e-01,\n",
      "         2.1915e-02, 1.6526e-01],\n",
      "        [7.2325e-05, 4.3265e-04, 1.7436e-03, 1.8835e-03, 4.8655e-04, 1.7636e-03,\n",
      "         1.3697e-03, 2.2110e-03, 5.3876e-04, 4.2240e-03, 1.4344e-03, 1.8107e-03,\n",
      "         1.7920e-03, 4.6281e-03, 3.0076e-02, 1.8186e-01, 2.4240e-01, 4.4439e-01,\n",
      "         4.8248e-02, 2.8640e-02],\n",
      "        [1.6246e-05, 7.1686e-05, 7.8163e-04, 7.6690e-04, 4.6266e-04, 1.1547e-03,\n",
      "         7.0453e-04, 1.0905e-03, 3.2040e-04, 2.1705e-03, 8.0163e-04, 9.2072e-04,\n",
      "         8.9621e-04, 2.0708e-03, 1.4852e-02, 1.5012e-01, 2.7585e-01, 3.9996e-01,\n",
      "         1.0157e-01, 4.5419e-02]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 4.99, Train Loss: 0.00, Val Loss: 5.21, Train BLEU: 0.00, Val BLEU: 4.94, Minutes Elapsed: 465.54\n",
      "Sampling from val predictions...\n",
      "Source: 超过 70 的 家庭 家庭暴力 暴力 谋杀 发生 生在 受害 受害者 结束 这段 关系 后 在 她 离开 之后 因为\n",
      "Reference: over 70 percent of domestic violence murders happen after the victim has ended the relationship , after she &apos;s\n",
      "Model: <SOS> and women of of the , , , , when when of <EOS> . . . <EOS> . .\n",
      "Attention Weights: tensor([[3.3048e-01, 5.7517e-02, 5.0660e-03, 4.0309e-01, 1.7608e-02, 1.2338e-01,\n",
      "         1.7766e-02, 1.1567e-02, 1.8283e-03, 2.3158e-02, 5.2355e-03, 2.1110e-03,\n",
      "         3.7295e-04, 2.8139e-04, 1.8909e-04, 3.5887e-05, 2.9122e-04, 6.2947e-06,\n",
      "         2.8838e-06, 2.4769e-06],\n",
      "        [1.1964e-01, 6.7208e-02, 1.9886e-02, 4.2591e-01, 5.1481e-02, 1.7852e-01,\n",
      "         5.4257e-02, 1.8942e-02, 3.7095e-03, 2.0291e-02, 1.9305e-02, 6.9747e-03,\n",
      "         5.5390e-03, 3.8794e-03, 1.1657e-03, 4.0241e-04, 2.7652e-03, 8.6683e-05,\n",
      "         2.4328e-05, 1.7614e-05],\n",
      "        [5.1904e-02, 4.2461e-02, 4.7472e-02, 2.7130e-01, 8.1972e-02, 2.4508e-01,\n",
      "         7.6070e-02, 6.6268e-02, 8.8060e-03, 2.6227e-02, 2.5809e-02, 2.2628e-02,\n",
      "         1.3961e-02, 1.0143e-02, 3.4443e-03, 1.4918e-03, 4.4530e-03, 2.9010e-04,\n",
      "         1.2453e-04, 9.5027e-05],\n",
      "        [2.4246e-02, 2.1664e-02, 1.9262e-02, 2.5108e-01, 9.3478e-02, 2.8486e-01,\n",
      "         9.6499e-02, 5.4395e-02, 5.4790e-03, 3.7669e-02, 4.3182e-02, 2.9343e-02,\n",
      "         1.8331e-02, 8.7787e-03, 3.4984e-03, 1.0740e-03, 6.7870e-03, 2.5234e-04,\n",
      "         6.4559e-05, 5.0855e-05],\n",
      "        [1.5026e-02, 1.1287e-02, 3.5479e-03, 1.6796e-01, 3.6133e-02, 1.3940e-01,\n",
      "         8.3861e-02, 4.9214e-02, 7.4764e-03, 1.4132e-01, 1.4029e-01, 4.5213e-02,\n",
      "         5.6986e-02, 4.8392e-02, 1.4000e-02, 4.1385e-03, 3.3761e-02, 1.5696e-03,\n",
      "         2.5840e-04, 1.6356e-04],\n",
      "        [5.5206e-03, 3.9197e-03, 9.6523e-04, 3.8093e-02, 5.2364e-03, 2.1337e-02,\n",
      "         1.5653e-02, 1.6256e-02, 1.0100e-02, 1.3278e-01, 1.3223e-01, 4.0160e-02,\n",
      "         9.8366e-02, 1.1494e-01, 4.4095e-02, 1.5936e-02, 2.7549e-01, 2.0838e-02,\n",
      "         5.0353e-03, 3.0548e-03],\n",
      "        [3.8883e-03, 1.8565e-03, 7.7771e-04, 7.3695e-03, 4.2913e-03, 1.0214e-02,\n",
      "         1.0202e-02, 2.3777e-02, 1.0283e-02, 9.5419e-02, 1.0205e-01, 8.2559e-02,\n",
      "         1.0649e-01, 1.5541e-01, 1.0597e-01, 3.1552e-02, 2.0811e-01, 3.2436e-02,\n",
      "         4.5808e-03, 2.7744e-03],\n",
      "        [3.4976e-04, 1.8795e-04, 7.0237e-05, 8.5700e-04, 2.3985e-04, 5.3786e-04,\n",
      "         4.9881e-04, 1.4058e-03, 1.9763e-03, 8.9429e-03, 9.9592e-03, 7.7788e-03,\n",
      "         3.1874e-02, 6.0710e-02, 4.9762e-02, 1.9245e-02, 6.3695e-01, 1.1906e-01,\n",
      "         2.6438e-02, 2.3162e-02],\n",
      "        [3.0137e-04, 1.6561e-04, 4.3204e-05, 6.5230e-04, 1.3189e-04, 3.3297e-04,\n",
      "         2.9949e-04, 5.9324e-04, 1.0459e-03, 3.7488e-03, 3.5683e-03, 2.4190e-03,\n",
      "         1.5625e-02, 3.1101e-02, 1.6710e-02, 9.3685e-03, 6.0569e-01, 1.2019e-01,\n",
      "         8.8176e-02, 9.9837e-02],\n",
      "        [5.5974e-04, 2.6902e-04, 5.8027e-05, 6.6617e-04, 1.9335e-04, 3.9200e-04,\n",
      "         4.4866e-04, 7.8023e-04, 1.0244e-03, 3.1645e-03, 2.4798e-03, 1.8241e-03,\n",
      "         7.8702e-03, 1.7921e-02, 1.1350e-02, 6.5063e-03, 3.2059e-01, 1.2925e-01,\n",
      "         1.5997e-01, 3.3468e-01],\n",
      "        [6.9931e-04, 4.3074e-04, 1.9733e-04, 1.4877e-03, 3.3573e-04, 5.4189e-04,\n",
      "         4.3975e-04, 6.4079e-04, 1.7274e-03, 4.0091e-03, 4.2497e-03, 1.8992e-03,\n",
      "         7.8021e-03, 1.2564e-02, 7.9496e-03, 4.6036e-03, 2.2381e-01, 5.7114e-02,\n",
      "         1.5053e-01, 5.1897e-01],\n",
      "        [1.2752e-03, 4.9143e-04, 1.7304e-04, 1.2252e-03, 5.5222e-04, 7.7874e-04,\n",
      "         8.6440e-04, 2.3629e-03, 2.3840e-03, 4.8652e-03, 3.6568e-03, 5.3080e-03,\n",
      "         4.5935e-03, 1.0016e-02, 1.0395e-02, 5.0221e-03, 7.5261e-02, 5.0618e-02,\n",
      "         1.2637e-01, 6.9378e-01],\n",
      "        [4.2056e-03, 1.6372e-03, 5.1987e-04, 2.8851e-03, 1.6235e-03, 2.1317e-03,\n",
      "         2.4715e-03, 8.1822e-03, 6.7074e-03, 1.7374e-02, 1.2750e-02, 1.8286e-02,\n",
      "         7.1338e-03, 2.4740e-02, 2.9099e-02, 9.9278e-03, 8.9543e-02, 9.7198e-02,\n",
      "         1.4041e-01, 5.2318e-01],\n",
      "        [2.5281e-03, 1.6155e-03, 3.7422e-04, 4.6251e-03, 1.3295e-03, 2.3547e-03,\n",
      "         1.7334e-03, 1.9456e-03, 5.7581e-03, 1.3710e-02, 1.1417e-02, 4.9487e-03,\n",
      "         1.1729e-02, 1.6091e-02, 2.0482e-02, 1.3660e-02, 2.5259e-01, 8.4815e-02,\n",
      "         1.5284e-01, 3.9546e-01],\n",
      "        [3.3828e-03, 2.3310e-03, 1.0563e-03, 6.2754e-03, 1.7435e-03, 2.7915e-03,\n",
      "         1.0162e-03, 1.3628e-03, 5.4505e-03, 1.1472e-02, 1.1550e-02, 5.1983e-03,\n",
      "         1.2789e-02, 1.0056e-02, 2.0207e-02, 1.0239e-02, 1.0803e-01, 3.4216e-02,\n",
      "         1.6186e-01, 5.8897e-01],\n",
      "        [1.1923e-02, 7.8690e-03, 2.2091e-03, 2.2232e-02, 5.2680e-03, 8.9861e-03,\n",
      "         3.9663e-03, 7.0733e-03, 2.0866e-02, 5.3577e-02, 5.2610e-02, 1.9845e-02,\n",
      "         3.5441e-02, 3.3707e-02, 3.5219e-02, 2.0732e-02, 2.7446e-01, 5.5992e-02,\n",
      "         1.4445e-01, 1.8358e-01],\n",
      "        [1.9212e-02, 9.4718e-03, 1.7677e-03, 1.5344e-02, 9.0995e-03, 1.3947e-02,\n",
      "         1.0925e-02, 1.9423e-02, 1.4420e-02, 7.2924e-02, 7.7503e-02, 6.4971e-02,\n",
      "         4.1460e-02, 8.0414e-02, 9.9768e-02, 3.4742e-02, 1.1539e-01, 1.2303e-01,\n",
      "         1.1133e-01, 6.4857e-02],\n",
      "        [1.0517e-02, 6.5716e-03, 1.1643e-03, 2.6343e-02, 7.2501e-03, 1.3973e-02,\n",
      "         1.3958e-02, 1.1532e-02, 1.5999e-02, 5.5277e-02, 7.6120e-02, 2.4112e-02,\n",
      "         4.6925e-02, 6.2675e-02, 3.8043e-02, 1.7099e-02, 2.8398e-01, 1.0788e-01,\n",
      "         1.0829e-01, 7.2288e-02],\n",
      "        [2.3053e-02, 1.1372e-02, 5.1633e-03, 2.1510e-02, 7.9436e-03, 9.6608e-03,\n",
      "         8.6223e-03, 1.7142e-02, 4.2219e-02, 7.2194e-02, 6.4900e-02, 2.7098e-02,\n",
      "         3.7478e-02, 6.3448e-02, 3.4556e-02, 1.9890e-02, 1.3180e-01, 1.3152e-01,\n",
      "         9.8242e-02, 1.7219e-01]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5.00, Train Loss: 0.00, Val Loss: 5.23, Train BLEU: 0.00, Val BLEU: 5.02, Minutes Elapsed: 466.68\n",
      "Sampling from val predictions...\n",
      "Source: 嗯 跳舞 是 人类 众多 的 活动 之一 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: so , dancing is one of the most human of activities . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> well , is is is a the of of of . . <EOS> <EOS> . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9998, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.9576, 0.0419, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0001, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2375, 0.7242, 0.0202, 0.0055, 0.0028, 0.0003, 0.0019, 0.0061, 0.0014,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.3756, 0.4921, 0.0754, 0.0090, 0.0106, 0.0014, 0.0062, 0.0246, 0.0050,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2750, 0.4831, 0.1356, 0.0257, 0.0201, 0.0022, 0.0132, 0.0401, 0.0050,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0113, 0.0275, 0.1007, 0.1911, 0.3483, 0.0096, 0.0726, 0.2351, 0.0037,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0136, 0.0464, 0.0138, 0.1074, 0.2809, 0.0184, 0.1983, 0.3182, 0.0031,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0064, 0.0391, 0.0080, 0.3363, 0.3852, 0.0133, 0.1059, 0.1030, 0.0027,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0038, 0.0044, 0.0066, 0.2796, 0.3342, 0.0295, 0.2694, 0.0603, 0.0122,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0019, 0.0042, 0.0037, 0.7412, 0.1175, 0.0055, 0.1101, 0.0118, 0.0040,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0039, 0.0043, 0.0015, 0.8365, 0.0756, 0.0032, 0.0606, 0.0089, 0.0054,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0092, 0.0190, 0.0049, 0.8715, 0.0447, 0.0021, 0.0133, 0.0066, 0.0287,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0146, 0.0215, 0.0082, 0.6336, 0.1307, 0.0070, 0.0740, 0.0134, 0.0969,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0100, 0.0319, 0.0048, 0.7281, 0.0607, 0.0034, 0.0145, 0.0186, 0.1282,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0061, 0.0220, 0.0343, 0.5117, 0.1349, 0.0175, 0.0714, 0.0561, 0.1459,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0069, 0.0125, 0.0477, 0.3507, 0.1234, 0.0225, 0.0677, 0.0862, 0.2825,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0129, 0.0082, 0.0140, 0.3019, 0.0862, 0.0182, 0.0197, 0.1340, 0.4050,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0248, 0.0132, 0.0109, 0.3265, 0.1047, 0.0105, 0.0109, 0.2211, 0.2773,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0318, 0.0148, 0.0095, 0.3469, 0.1102, 0.0086, 0.0105, 0.2312, 0.2363,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 5.05, Train Loss: 0.00, Val Loss: 5.14, Train BLEU: 0.00, Val BLEU: 4.42, Minutes Elapsed: 471.85\n",
      "Sampling from val predictions...\n",
      "Source: 我 把 样品 放进 放进去 进去 了 现在 把 它 拿出 出来 看看 发生 了 什么 事 <EOS> <PAD> <PAD>\n",
      "Reference: so i put the specimen in , which i &apos;m now going to take out to see what happened\n",
      "Model: <SOS> i i i them the and and and now what it to to do it . . . <EOS>\n",
      "Attention Weights: tensor([[0.9318, 0.0623, 0.0037, 0.0008, 0.0005, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0007, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2782, 0.6268, 0.0796, 0.0073, 0.0038, 0.0008, 0.0003, 0.0006, 0.0002,\n",
      "         0.0004, 0.0002, 0.0001, 0.0001, 0.0001, 0.0001, 0.0010, 0.0003, 0.0003,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2025, 0.3106, 0.3212, 0.0594, 0.0394, 0.0112, 0.0038, 0.0093, 0.0024,\n",
      "         0.0087, 0.0027, 0.0021, 0.0037, 0.0032, 0.0018, 0.0075, 0.0044, 0.0061,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1275, 0.2606, 0.4645, 0.0558, 0.0375, 0.0102, 0.0026, 0.0102, 0.0015,\n",
      "         0.0066, 0.0018, 0.0012, 0.0027, 0.0026, 0.0011, 0.0054, 0.0036, 0.0048,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0080, 0.0294, 0.5818, 0.1249, 0.1328, 0.0711, 0.0053, 0.0151, 0.0015,\n",
      "         0.0053, 0.0016, 0.0026, 0.0055, 0.0017, 0.0007, 0.0055, 0.0037, 0.0034,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0104, 0.0172, 0.3727, 0.1499, 0.1936, 0.1382, 0.0205, 0.0584, 0.0034,\n",
      "         0.0085, 0.0009, 0.0012, 0.0055, 0.0016, 0.0008, 0.0091, 0.0042, 0.0038,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0500, 0.0300, 0.1070, 0.1258, 0.1889, 0.2067, 0.0412, 0.1743, 0.0202,\n",
      "         0.0233, 0.0037, 0.0019, 0.0078, 0.0035, 0.0008, 0.0056, 0.0040, 0.0051,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0316, 0.0148, 0.0869, 0.0583, 0.1235, 0.1606, 0.0181, 0.2844, 0.0350,\n",
      "         0.0977, 0.0119, 0.0055, 0.0190, 0.0093, 0.0022, 0.0216, 0.0093, 0.0102,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0206, 0.0037, 0.0098, 0.0111, 0.0354, 0.0804, 0.0437, 0.6204, 0.0613,\n",
      "         0.0774, 0.0067, 0.0015, 0.0091, 0.0052, 0.0007, 0.0065, 0.0042, 0.0024,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0133, 0.0172, 0.0436, 0.0427, 0.0912, 0.1057, 0.0169, 0.2941, 0.0635,\n",
      "         0.1935, 0.0381, 0.0058, 0.0241, 0.0137, 0.0018, 0.0161, 0.0130, 0.0058,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0026, 0.0014, 0.0084, 0.0079, 0.0226, 0.0459, 0.0057, 0.2577, 0.0183,\n",
      "         0.2619, 0.0830, 0.0434, 0.1253, 0.0342, 0.0047, 0.0213, 0.0412, 0.0146,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0002, 0.0002, 0.0028, 0.0024, 0.0120, 0.0304, 0.0045, 0.1578, 0.0182,\n",
      "         0.3405, 0.1038, 0.0989, 0.1101, 0.0509, 0.0069, 0.0190, 0.0317, 0.0097,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0001, 0.0002, 0.0033, 0.0022, 0.0071, 0.0168, 0.0026, 0.1002, 0.0196,\n",
      "         0.2795, 0.1650, 0.1103, 0.1407, 0.0755, 0.0090, 0.0182, 0.0409, 0.0089,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0001, 0.0001, 0.0031, 0.0009, 0.0030, 0.0058, 0.0012, 0.0566, 0.0058,\n",
      "         0.2406, 0.0776, 0.0738, 0.1806, 0.2047, 0.0249, 0.0357, 0.0734, 0.0120,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0001, 0.0001, 0.0008, 0.0008, 0.0030, 0.0052, 0.0011, 0.0230, 0.0026,\n",
      "         0.1468, 0.0601, 0.1873, 0.2697, 0.1549, 0.0255, 0.0525, 0.0576, 0.0091,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0003, 0.0002, 0.0011, 0.0006, 0.0025, 0.0048, 0.0012, 0.0235, 0.0017,\n",
      "         0.0885, 0.0216, 0.0821, 0.2329, 0.2284, 0.0338, 0.0790, 0.1782, 0.0198,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0005, 0.0002, 0.0022, 0.0006, 0.0020, 0.0034, 0.0011, 0.0247, 0.0011,\n",
      "         0.0340, 0.0207, 0.0431, 0.2362, 0.2976, 0.0361, 0.0940, 0.1811, 0.0212,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0007, 0.0004, 0.0045, 0.0014, 0.0039, 0.0058, 0.0018, 0.0250, 0.0011,\n",
      "         0.0224, 0.0126, 0.0275, 0.1599, 0.3016, 0.0263, 0.1237, 0.2366, 0.0447,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0005, 0.0003, 0.0026, 0.0009, 0.0027, 0.0041, 0.0011, 0.0152, 0.0009,\n",
      "         0.0170, 0.0117, 0.0289, 0.1344, 0.2867, 0.0259, 0.0852, 0.3088, 0.0731,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 5.11, Train Loss: 0.00, Val Loss: 5.14, Train BLEU: 0.00, Val BLEU: 4.84, Minutes Elapsed: 477.01\n",
      "Sampling from val predictions...\n",
      "Source: 而 你 唯一 能够 守护 <UNK> 的 东西 就是 这里 如果 我们 不得 不得不 不靠 卖 血 来 支付 你\n",
      "Reference: but the one thing that will always remain with you is what is here , and if we have\n",
      "Model: <SOS> and you you thing you can can , , , , , to call to you you you have\n",
      "Attention Weights: tensor([[3.0119e-03, 9.3845e-01, 7.9297e-03, 1.1141e-02, 1.8919e-04, 6.0000e-05,\n",
      "         2.1869e-04, 1.9860e-02, 1.4792e-03, 2.1382e-04, 1.7352e-02, 8.4613e-05,\n",
      "         6.8535e-07, 3.9488e-07, 1.6709e-07, 8.7343e-07, 3.8477e-07, 3.8213e-06,\n",
      "         1.2197e-06, 6.1891e-06],\n",
      "        [3.6991e-03, 8.0834e-01, 1.2637e-01, 4.6411e-02, 2.9620e-03, 1.1650e-03,\n",
      "         4.4141e-04, 9.2190e-03, 7.0179e-04, 1.5119e-04, 4.5645e-04, 6.2515e-05,\n",
      "         2.4055e-06, 1.0284e-06, 6.6992e-07, 2.7416e-06, 1.6739e-06, 2.9431e-06,\n",
      "         2.1727e-06, 4.2896e-06],\n",
      "        [3.8613e-03, 2.0136e-01, 1.9280e-01, 3.7561e-01, 5.9991e-02, 4.7389e-02,\n",
      "         7.5225e-03, 9.9143e-02, 6.3919e-03, 1.5090e-03, 2.8132e-03, 9.7936e-04,\n",
      "         2.2363e-04, 1.4350e-04, 4.5747e-05, 3.9832e-05, 4.3795e-05, 5.7159e-05,\n",
      "         3.6432e-05, 3.4087e-05],\n",
      "        [1.9593e-03, 8.3395e-02, 1.3569e-01, 3.3998e-01, 1.5904e-01, 1.3418e-01,\n",
      "         1.2290e-02, 9.8687e-02, 1.3191e-02, 4.9023e-03, 7.2768e-03, 5.3566e-03,\n",
      "         1.1409e-03, 1.1848e-03, 4.2520e-04, 3.4380e-04, 2.9104e-04, 2.2770e-04,\n",
      "         2.9149e-04, 1.3936e-04],\n",
      "        [1.4628e-03, 2.2933e-01, 2.0282e-02, 3.6177e-01, 1.3678e-01, 1.0218e-01,\n",
      "         4.9129e-03, 4.2288e-02, 2.8872e-02, 1.0834e-02, 3.2244e-02, 2.2794e-02,\n",
      "         1.6846e-03, 1.7475e-03, 4.1356e-04, 4.7500e-04, 3.4200e-04, 5.6081e-04,\n",
      "         6.3247e-04, 3.9481e-04],\n",
      "        [4.3054e-04, 8.3095e-02, 2.1214e-02, 3.1690e-01, 1.6771e-01, 1.1812e-01,\n",
      "         2.5616e-03, 4.5287e-02, 1.8658e-02, 2.8342e-02, 1.2784e-01, 5.1660e-02,\n",
      "         6.1283e-03, 5.8557e-03, 1.5274e-03, 1.3356e-03, 8.3906e-04, 8.7479e-04,\n",
      "         1.0237e-03, 5.9021e-04],\n",
      "        [2.8591e-04, 3.3192e-02, 1.4716e-02, 1.9669e-01, 7.9353e-02, 7.2744e-02,\n",
      "         2.5201e-03, 3.7936e-02, 2.6302e-02, 6.1721e-02, 2.6391e-01, 1.6251e-01,\n",
      "         2.1236e-02, 1.7847e-02, 3.1401e-03, 2.0812e-03, 8.4057e-04, 8.4649e-04,\n",
      "         1.2589e-03, 8.7611e-04],\n",
      "        [2.5744e-04, 1.3520e-02, 9.0743e-03, 7.7260e-02, 2.9510e-02, 3.1792e-02,\n",
      "         2.2238e-03, 2.5653e-02, 2.4351e-02, 7.0365e-02, 3.5126e-01, 2.7077e-01,\n",
      "         4.4700e-02, 3.8193e-02, 4.5028e-03, 2.8137e-03, 1.1039e-03, 9.4961e-04,\n",
      "         1.0948e-03, 5.9732e-04],\n",
      "        [3.0570e-05, 1.5308e-03, 5.5702e-04, 4.2580e-03, 7.6817e-03, 7.4005e-03,\n",
      "         6.2817e-04, 4.0433e-03, 3.6880e-03, 1.0440e-01, 3.7037e-01, 3.2897e-01,\n",
      "         3.7448e-02, 8.8708e-02, 1.5250e-02, 1.1033e-02, 5.5762e-03, 2.0577e-03,\n",
      "         3.9301e-03, 2.4400e-03],\n",
      "        [1.3114e-05, 6.0681e-04, 2.1654e-04, 9.5948e-04, 7.7025e-04, 5.8006e-04,\n",
      "         8.5578e-05, 6.5525e-04, 1.2553e-03, 4.2918e-02, 3.7919e-01, 3.1384e-01,\n",
      "         8.7650e-02, 1.0885e-01, 2.2384e-02, 1.4401e-02, 9.1993e-03, 6.4801e-03,\n",
      "         7.5811e-03, 2.3652e-03],\n",
      "        [1.3721e-05, 5.6189e-04, 1.8121e-04, 8.9613e-04, 3.4877e-04, 2.4204e-04,\n",
      "         3.0235e-05, 2.6181e-04, 1.0399e-03, 2.6350e-02, 2.8730e-01, 3.1249e-01,\n",
      "         1.5734e-01, 1.4353e-01, 2.4136e-02, 1.4012e-02, 7.5020e-03, 9.7185e-03,\n",
      "         1.0773e-02, 3.2730e-03],\n",
      "        [3.5869e-05, 7.2887e-04, 1.3933e-04, 7.1038e-04, 4.8017e-04, 3.9700e-04,\n",
      "         4.6080e-05, 2.3966e-04, 1.2877e-03, 2.7354e-02, 2.2868e-01, 2.8065e-01,\n",
      "         1.4250e-01, 1.4704e-01, 3.5315e-02, 3.1810e-02, 2.3034e-02, 3.2907e-02,\n",
      "         3.2317e-02, 1.4322e-02],\n",
      "        [2.4000e-06, 4.0604e-05, 3.6625e-05, 1.8755e-04, 3.6262e-04, 2.9200e-04,\n",
      "         4.9736e-05, 1.1987e-04, 1.0204e-04, 3.3366e-03, 1.0146e-02, 1.9585e-02,\n",
      "         2.4671e-02, 1.8779e-01, 1.7904e-01, 1.3524e-01, 1.1364e-01, 3.3421e-02,\n",
      "         1.9263e-01, 9.9310e-02],\n",
      "        [2.1752e-06, 8.3731e-05, 1.5748e-05, 6.9182e-05, 1.8753e-04, 1.3731e-04,\n",
      "         2.5346e-05, 4.2961e-05, 3.4362e-05, 1.2753e-03, 4.9588e-03, 1.0045e-02,\n",
      "         2.1414e-03, 2.5527e-02, 3.0970e-02, 4.1888e-02, 5.4433e-02, 3.2548e-02,\n",
      "         1.7664e-01, 6.1897e-01],\n",
      "        [3.5464e-06, 2.0022e-04, 1.0810e-04, 2.6692e-04, 3.2936e-04, 4.5177e-04,\n",
      "         1.9597e-04, 2.4299e-04, 5.5129e-04, 5.7414e-03, 1.3072e-02, 3.4205e-02,\n",
      "         2.8318e-02, 9.5182e-02, 7.4308e-02, 6.4729e-02, 3.7109e-02, 2.8356e-02,\n",
      "         1.3469e-01, 4.8194e-01],\n",
      "        [5.7839e-06, 1.2928e-04, 3.0499e-05, 1.4184e-04, 2.9091e-04, 2.3289e-04,\n",
      "         3.2287e-05, 6.1832e-05, 5.2671e-05, 1.2521e-03, 3.2278e-03, 4.5465e-03,\n",
      "         1.9250e-03, 1.9930e-02, 3.0620e-02, 3.7381e-02, 5.5484e-02, 2.8749e-02,\n",
      "         1.9230e-01, 6.2361e-01],\n",
      "        [1.2648e-05, 2.4041e-04, 1.1219e-04, 2.7240e-04, 5.3157e-04, 5.5161e-04,\n",
      "         8.9332e-05, 2.0788e-04, 1.5418e-04, 3.2789e-03, 3.5511e-03, 3.4819e-03,\n",
      "         1.1194e-03, 9.8449e-03, 1.7579e-02, 2.4319e-02, 3.8317e-02, 1.5153e-02,\n",
      "         9.5950e-02, 7.8523e-01],\n",
      "        [1.1740e-05, 3.5267e-04, 3.0209e-04, 1.1424e-03, 8.7704e-04, 8.4479e-04,\n",
      "         1.6901e-04, 3.6148e-04, 3.5790e-04, 3.9451e-03, 5.7401e-03, 1.8304e-02,\n",
      "         1.0848e-02, 3.2148e-02, 3.3608e-02, 2.6764e-02, 2.0898e-02, 1.6725e-02,\n",
      "         7.9045e-02, 7.4756e-01],\n",
      "        [1.9725e-05, 9.2014e-04, 5.8303e-04, 1.7381e-03, 8.5296e-04, 8.6604e-04,\n",
      "         2.8129e-04, 5.4996e-04, 9.0182e-04, 9.3498e-03, 1.6381e-02, 3.8247e-02,\n",
      "         2.1601e-02, 3.4066e-02, 2.0800e-02, 1.7272e-02, 1.2162e-02, 1.5488e-02,\n",
      "         6.2134e-02, 7.4579e-01]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5.16, Train Loss: 0.00, Val Loss: 5.22, Train BLEU: 0.00, Val BLEU: 5.01, Minutes Elapsed: 482.17\n",
      "Sampling from val predictions...\n",
      "Source: 我 养 了 一只 黑色 <UNK> 拉布 <UNK> 布拉 拉多 猎犬 <UNK> <UNK> 奥 <UNK> 面包 面包车 包车 <EOS> <PAD>\n",
      "Reference: my dog is a black lab , and i drive a <UNK> odyssey <UNK> . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> i i <UNK> a <UNK> , , , , , a <UNK> , . <EOS> <EOS> <EOS> . <EOS>\n",
      "Attention Weights: tensor([[0.9657, 0.0114, 0.0033, 0.0184, 0.0008, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0002, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0619, 0.5555, 0.0652, 0.2927, 0.0156, 0.0022, 0.0013, 0.0010, 0.0005,\n",
      "         0.0012, 0.0012, 0.0002, 0.0002, 0.0001, 0.0002, 0.0003, 0.0001, 0.0002,\n",
      "         0.0003, 0.0000],\n",
      "        [0.0232, 0.0636, 0.1199, 0.6027, 0.0870, 0.0169, 0.0079, 0.0059, 0.0031,\n",
      "         0.0090, 0.0093, 0.0018, 0.0018, 0.0013, 0.0028, 0.0087, 0.0055, 0.0127,\n",
      "         0.0165, 0.0000],\n",
      "        [0.0672, 0.0419, 0.0828, 0.2793, 0.1354, 0.0911, 0.0547, 0.0550, 0.0245,\n",
      "         0.0639, 0.0611, 0.0103, 0.0078, 0.0033, 0.0040, 0.0057, 0.0027, 0.0038,\n",
      "         0.0054, 0.0000],\n",
      "        [0.0197, 0.0083, 0.0189, 0.1809, 0.2151, 0.0641, 0.0476, 0.0461, 0.0356,\n",
      "         0.1165, 0.1427, 0.0244, 0.0205, 0.0092, 0.0128, 0.0158, 0.0049, 0.0071,\n",
      "         0.0101, 0.0000],\n",
      "        [0.0326, 0.0032, 0.0083, 0.0560, 0.1318, 0.0656, 0.0475, 0.0616, 0.0494,\n",
      "         0.1889, 0.2401, 0.0255, 0.0212, 0.0067, 0.0102, 0.0221, 0.0071, 0.0112,\n",
      "         0.0109, 0.0000],\n",
      "        [0.0082, 0.0010, 0.0014, 0.0127, 0.0126, 0.0186, 0.0165, 0.0432, 0.0394,\n",
      "         0.2398, 0.4814, 0.0532, 0.0437, 0.0081, 0.0061, 0.0085, 0.0016, 0.0018,\n",
      "         0.0022, 0.0000],\n",
      "        [0.0135, 0.0018, 0.0014, 0.0164, 0.0129, 0.0066, 0.0057, 0.0122, 0.0152,\n",
      "         0.2307, 0.5176, 0.0421, 0.0483, 0.0189, 0.0155, 0.0278, 0.0037, 0.0048,\n",
      "         0.0048, 0.0000],\n",
      "        [0.0364, 0.0059, 0.0084, 0.0444, 0.0184, 0.0051, 0.0048, 0.0063, 0.0070,\n",
      "         0.0664, 0.2491, 0.0299, 0.0439, 0.0379, 0.0657, 0.2715, 0.0301, 0.0383,\n",
      "         0.0303, 0.0000],\n",
      "        [0.0052, 0.0019, 0.0059, 0.0204, 0.0124, 0.0043, 0.0048, 0.0080, 0.0128,\n",
      "         0.0558, 0.2184, 0.0533, 0.0785, 0.0491, 0.1184, 0.2595, 0.0331, 0.0435,\n",
      "         0.0147, 0.0000],\n",
      "        [0.0048, 0.0015, 0.0114, 0.0293, 0.0121, 0.0046, 0.0058, 0.0082, 0.0130,\n",
      "         0.0477, 0.1515, 0.0377, 0.0560, 0.0383, 0.1251, 0.3607, 0.0321, 0.0421,\n",
      "         0.0180, 0.0000],\n",
      "        [0.0008, 0.0001, 0.0014, 0.0168, 0.0174, 0.0033, 0.0033, 0.0036, 0.0082,\n",
      "         0.0855, 0.0782, 0.0203, 0.0349, 0.0464, 0.0968, 0.3955, 0.0575, 0.1095,\n",
      "         0.0205, 0.0000],\n",
      "        [0.0015, 0.0000, 0.0003, 0.0053, 0.0095, 0.0021, 0.0021, 0.0024, 0.0048,\n",
      "         0.0484, 0.0602, 0.0116, 0.0284, 0.0671, 0.0964, 0.5291, 0.0535, 0.0623,\n",
      "         0.0150, 0.0000],\n",
      "        [0.0024, 0.0002, 0.0005, 0.0056, 0.0066, 0.0038, 0.0038, 0.0066, 0.0117,\n",
      "         0.0835, 0.1071, 0.0318, 0.0620, 0.1066, 0.1089, 0.3487, 0.0491, 0.0503,\n",
      "         0.0108, 0.0000],\n",
      "        [0.0298, 0.0041, 0.0061, 0.0388, 0.0142, 0.0052, 0.0058, 0.0065, 0.0092,\n",
      "         0.0481, 0.0557, 0.0170, 0.0292, 0.0636, 0.0902, 0.3385, 0.0811, 0.0964,\n",
      "         0.0605, 0.0000],\n",
      "        [0.0825, 0.0193, 0.0200, 0.0869, 0.0180, 0.0043, 0.0041, 0.0041, 0.0050,\n",
      "         0.0281, 0.0345, 0.0094, 0.0151, 0.0223, 0.0415, 0.2264, 0.0617, 0.1051,\n",
      "         0.2117, 0.0000],\n",
      "        [0.0893, 0.0369, 0.0279, 0.0888, 0.0185, 0.0047, 0.0045, 0.0048, 0.0059,\n",
      "         0.0313, 0.0410, 0.0108, 0.0161, 0.0220, 0.0403, 0.1833, 0.0502, 0.0865,\n",
      "         0.2372, 0.0000],\n",
      "        [0.0213, 0.0364, 0.0387, 0.0602, 0.0114, 0.0039, 0.0036, 0.0035, 0.0038,\n",
      "         0.0088, 0.0152, 0.0067, 0.0088, 0.0118, 0.0310, 0.2156, 0.0898, 0.1918,\n",
      "         0.2378, 0.0000],\n",
      "        [0.0113, 0.0076, 0.0333, 0.0312, 0.0056, 0.0016, 0.0015, 0.0014, 0.0017,\n",
      "         0.0053, 0.0086, 0.0031, 0.0049, 0.0091, 0.0237, 0.2920, 0.0971, 0.2034,\n",
      "         0.2579, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 5.22, Train Loss: 0.00, Val Loss: 5.08, Train BLEU: 0.00, Val BLEU: 5.52, Minutes Elapsed: 487.34\n",
      "Sampling from val predictions...\n",
      "Source: 我 所 做 的 一切 不论 不论是 生活 上 还是 工作 上 我 的 整个 个人 人生 深深 深受 受到\n",
      "Reference: everything i do , and everything i do professionally -- my life -- has been shaped by seven years\n",
      "Model: <SOS> i i i all in my life my my my my was , , , . . <EOS> .\n",
      "Attention Weights: tensor([[7.4973e-01, 2.3942e-03, 1.7707e-03, 3.4895e-04, 2.2718e-01, 1.2250e-02,\n",
      "         2.8272e-03, 2.0933e-04, 8.1609e-05, 3.0429e-03, 6.1338e-05, 1.0045e-05,\n",
      "         1.8998e-05, 4.1235e-06, 2.1439e-05, 2.4538e-05, 1.5004e-05, 2.3460e-06,\n",
      "         2.2510e-07, 2.6972e-07],\n",
      "        [7.6736e-02, 7.8986e-02, 6.9536e-02, 7.4994e-03, 6.3229e-01, 9.0851e-02,\n",
      "         3.4976e-02, 3.5893e-03, 3.1890e-04, 2.9395e-03, 5.6767e-04, 1.1206e-04,\n",
      "         2.2643e-04, 1.1644e-04, 4.6518e-04, 3.4631e-04, 1.6818e-04, 1.7801e-04,\n",
      "         7.1203e-05, 2.3362e-05],\n",
      "        [1.1539e-01, 6.1279e-02, 1.1429e-01, 2.6187e-02, 3.7846e-01, 1.6369e-01,\n",
      "         8.9483e-02, 2.7027e-02, 1.5260e-03, 1.3665e-02, 3.1788e-03, 5.3558e-04,\n",
      "         1.6947e-03, 2.7970e-04, 1.9260e-03, 3.9888e-04, 2.9638e-04, 3.5231e-04,\n",
      "         1.8816e-04, 1.4436e-04],\n",
      "        [1.9353e-01, 2.8042e-02, 5.3750e-02, 5.0081e-03, 2.0220e-01, 1.0881e-01,\n",
      "         1.9260e-01, 9.3902e-02, 1.7316e-03, 5.9687e-02, 2.3169e-02, 1.7954e-03,\n",
      "         8.9456e-03, 1.0104e-03, 1.6412e-02, 3.5283e-03, 2.0646e-03, 2.2597e-03,\n",
      "         9.3277e-04, 6.1405e-04],\n",
      "        [3.9153e-03, 4.0676e-04, 2.3658e-03, 1.8409e-03, 2.7170e-02, 2.3829e-02,\n",
      "         3.1618e-01, 3.6417e-01, 7.2009e-03, 1.0148e-01, 6.7382e-02, 5.1494e-03,\n",
      "         2.0098e-02, 1.7577e-03, 3.3283e-02, 1.0930e-02, 5.5851e-03, 5.1163e-03,\n",
      "         1.4376e-03, 6.9904e-04],\n",
      "        [8.8743e-04, 1.2572e-04, 2.8074e-04, 7.3159e-04, 4.3762e-03, 2.0227e-03,\n",
      "         7.4302e-02, 2.2654e-01, 7.9575e-03, 2.0050e-01, 8.7340e-02, 1.2544e-02,\n",
      "         1.6027e-01, 7.8857e-03, 1.0958e-01, 4.6817e-02, 2.7299e-02, 2.5419e-02,\n",
      "         3.0610e-03, 2.0618e-03],\n",
      "        [5.3453e-03, 3.1561e-03, 4.3495e-03, 2.8201e-03, 1.7303e-02, 3.2818e-02,\n",
      "         1.6003e-01, 2.0354e-01, 5.3441e-03, 1.3620e-01, 1.0101e-01, 6.7567e-03,\n",
      "         1.1585e-01, 6.5913e-03, 1.2703e-01, 3.0677e-02, 1.6956e-02, 1.7854e-02,\n",
      "         4.6779e-03, 1.6765e-03],\n",
      "        [4.7697e-03, 1.9887e-03, 2.9778e-03, 1.9015e-03, 8.1766e-03, 1.3991e-02,\n",
      "         4.5995e-02, 8.9630e-02, 3.8207e-03, 6.5417e-02, 9.1516e-02, 9.7321e-03,\n",
      "         2.2073e-01, 2.1783e-02, 2.1512e-01, 8.0563e-02, 4.1212e-02, 5.8645e-02,\n",
      "         1.7675e-02, 4.3589e-03],\n",
      "        [2.3246e-03, 1.2974e-04, 2.6615e-04, 2.5545e-04, 2.1439e-03, 1.5066e-03,\n",
      "         1.3455e-02, 5.7563e-02, 1.3750e-03, 3.7434e-02, 5.4160e-02, 5.4087e-03,\n",
      "         3.5361e-01, 7.9940e-03, 1.8701e-01, 1.2013e-01, 6.5581e-02, 6.5068e-02,\n",
      "         1.5969e-02, 8.6128e-03],\n",
      "        [6.5665e-05, 6.9025e-06, 1.9947e-05, 4.9261e-05, 2.7433e-04, 9.4527e-05,\n",
      "         5.3032e-03, 4.2806e-02, 4.2988e-04, 1.4611e-02, 2.7936e-02, 3.3245e-03,\n",
      "         2.4296e-01, 6.4054e-03, 2.7182e-01, 2.2592e-01, 8.3242e-02, 5.8142e-02,\n",
      "         8.2394e-03, 8.3480e-03],\n",
      "        [1.4648e-04, 2.3109e-05, 3.4220e-05, 9.1383e-05, 5.8791e-04, 1.2046e-04,\n",
      "         4.9615e-03, 3.9544e-02, 1.4231e-03, 1.8903e-02, 2.1374e-02, 5.4451e-03,\n",
      "         2.7964e-01, 8.6042e-03, 1.1396e-01, 2.1819e-01, 1.2744e-01, 1.2733e-01,\n",
      "         1.4658e-02, 1.7520e-02],\n",
      "        [1.8642e-03, 4.0973e-04, 3.7969e-04, 3.7951e-04, 3.3230e-03, 1.4367e-03,\n",
      "         1.0877e-02, 2.5544e-02, 1.0241e-03, 2.8358e-02, 1.9247e-02, 3.3309e-03,\n",
      "         2.2482e-01, 9.9032e-03, 1.0033e-01, 1.5549e-01, 7.0792e-02, 1.5332e-01,\n",
      "         5.0978e-02, 1.3820e-01],\n",
      "        [1.1168e-03, 4.7989e-04, 6.8284e-04, 3.6631e-04, 1.3300e-03, 1.3287e-03,\n",
      "         7.3507e-03, 2.0166e-02, 9.2942e-04, 1.8276e-02, 1.8359e-02, 3.3411e-03,\n",
      "         1.9586e-01, 1.2043e-02, 1.2107e-01, 1.1803e-01, 6.3003e-02, 1.3137e-01,\n",
      "         9.7952e-02, 1.8695e-01],\n",
      "        [2.6635e-04, 5.8757e-05, 1.7139e-04, 1.0603e-04, 8.2321e-04, 7.7427e-04,\n",
      "         4.0678e-03, 7.6758e-03, 9.6278e-04, 2.5538e-02, 9.8323e-03, 2.8139e-03,\n",
      "         5.6990e-02, 3.3459e-03, 1.8296e-02, 3.7470e-02, 2.3357e-02, 6.4827e-02,\n",
      "         5.1276e-02, 6.9135e-01],\n",
      "        [6.3243e-04, 5.5788e-05, 2.1565e-04, 2.0748e-04, 7.1151e-04, 5.5226e-04,\n",
      "         4.1331e-03, 1.1484e-02, 7.3223e-04, 1.4057e-02, 1.1682e-02, 2.4059e-03,\n",
      "         1.1783e-01, 4.3713e-03, 5.1283e-02, 5.7751e-02, 2.7947e-02, 5.1145e-02,\n",
      "         2.9073e-02, 6.1373e-01],\n",
      "        [4.6971e-04, 6.4703e-05, 2.0995e-04, 1.6024e-04, 6.0771e-04, 5.5549e-04,\n",
      "         7.5950e-03, 1.3625e-02, 6.6908e-04, 1.4328e-02, 1.0252e-02, 2.5088e-03,\n",
      "         6.8471e-02, 4.0411e-03, 5.3566e-02, 3.8419e-02, 1.5171e-02, 2.9416e-02,\n",
      "         2.7498e-02, 7.1237e-01],\n",
      "        [1.8001e-03, 1.5061e-04, 3.2581e-04, 2.8203e-04, 9.2634e-04, 5.1466e-04,\n",
      "         3.8663e-03, 2.6136e-02, 9.0845e-04, 1.1518e-02, 1.3297e-02, 3.0764e-03,\n",
      "         4.0287e-01, 2.1761e-03, 8.1179e-02, 1.5623e-01, 6.3551e-02, 2.0621e-02,\n",
      "         5.0607e-03, 2.0552e-01],\n",
      "        [2.4710e-03, 2.3100e-04, 4.9512e-04, 4.3598e-04, 1.5267e-03, 6.4647e-04,\n",
      "         5.6103e-03, 5.3554e-02, 1.6269e-03, 1.2326e-02, 2.5457e-02, 4.3703e-03,\n",
      "         3.4076e-01, 3.5886e-03, 1.1413e-01, 1.9954e-01, 1.0011e-01, 2.7847e-02,\n",
      "         4.2304e-03, 1.0105e-01],\n",
      "        [1.0660e-02, 5.0929e-04, 7.8756e-04, 6.3214e-04, 4.4138e-03, 1.6755e-03,\n",
      "         1.2498e-02, 1.0966e-01, 6.1037e-03, 4.5738e-02, 4.9616e-02, 1.0095e-02,\n",
      "         2.6161e-01, 6.2298e-03, 1.0260e-01, 1.5879e-01, 1.5094e-01, 3.6111e-02,\n",
      "         3.2256e-03, 2.8110e-02]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5.27, Train Loss: 0.00, Val Loss: 5.11, Train BLEU: 0.00, Val BLEU: 5.31, Minutes Elapsed: 492.52\n",
      "Sampling from val predictions...\n",
      "Source: 我们 有志 志愿 志愿者 愿者 团队 帮助 创业 辅助 商 为 客户 集结 资源 及 人力 我们 发现 当地 当地人\n",
      "Reference: we have groups of volunteers supporting the enterprise facilitator to help you to find resources and people and we\n",
      "Model: <SOS> we we to to to , and and , and we us we . . . <EOS> . <EOS>\n",
      "Attention Weights: tensor([[9.8937e-01, 1.7815e-03, 4.1156e-03, 1.6221e-04, 2.6662e-04, 3.5262e-03,\n",
      "         5.0243e-04, 1.4222e-04, 7.6211e-05, 2.8987e-05, 6.0737e-06, 2.6304e-06,\n",
      "         1.6226e-06, 4.3517e-06, 4.2305e-06, 3.0836e-06, 2.1392e-06, 3.4254e-08,\n",
      "         1.2740e-08, 3.3305e-09],\n",
      "        [2.7851e-01, 2.4195e-01, 3.3535e-01, 2.2013e-02, 2.0651e-02, 4.9579e-02,\n",
      "         4.1706e-02, 7.4502e-03, 1.7363e-03, 5.7289e-04, 1.6415e-04, 7.3170e-05,\n",
      "         5.6580e-05, 5.7275e-05, 2.5127e-05, 3.6357e-05, 3.6886e-05, 2.4837e-05,\n",
      "         3.8830e-06, 1.2775e-06],\n",
      "        [1.0619e-01, 5.0449e-02, 2.8292e-01, 7.7765e-02, 5.9891e-02, 1.4417e-01,\n",
      "         1.6759e-01, 7.1694e-02, 1.7358e-02, 7.6530e-03, 4.9234e-03, 3.7272e-03,\n",
      "         1.2842e-03, 1.7366e-03, 5.3080e-04, 5.5718e-04, 7.4929e-04, 4.8681e-04,\n",
      "         2.0850e-04, 1.0647e-04],\n",
      "        [3.3836e-03, 9.6374e-03, 1.7983e-01, 5.0820e-02, 6.3164e-02, 2.7063e-01,\n",
      "         1.3657e-01, 1.8635e-01, 5.4285e-02, 1.7824e-02, 5.5464e-03, 1.4264e-02,\n",
      "         1.7410e-03, 4.1358e-03, 7.3990e-04, 6.6557e-04, 2.7018e-04, 5.6443e-05,\n",
      "         6.0602e-05, 2.7983e-05],\n",
      "        [8.4165e-03, 2.0985e-03, 8.0571e-02, 3.1551e-02, 4.0155e-02, 1.5971e-01,\n",
      "         2.2815e-01, 1.5091e-01, 1.4278e-01, 6.6478e-02, 2.9474e-02, 2.8741e-02,\n",
      "         7.1803e-03, 1.6848e-02, 3.4180e-03, 2.5207e-03, 8.8245e-04, 4.4716e-05,\n",
      "         5.4673e-05, 1.5074e-05],\n",
      "        [8.6742e-03, 7.9807e-04, 2.1418e-02, 8.1089e-03, 8.3010e-03, 4.4396e-02,\n",
      "         1.0114e-01, 1.2337e-01, 1.3303e-01, 1.5877e-01, 8.2670e-02, 1.5107e-01,\n",
      "         3.2567e-02, 9.9037e-02, 1.4074e-02, 9.1949e-03, 3.1812e-03, 1.3003e-04,\n",
      "         6.2212e-05, 9.0008e-06],\n",
      "        [2.8256e-03, 3.6637e-04, 8.4870e-03, 6.3610e-03, 6.4881e-03, 1.9048e-02,\n",
      "         6.7994e-02, 5.0104e-02, 1.0849e-01, 1.2613e-01, 9.9466e-02, 1.8826e-01,\n",
      "         6.9893e-02, 1.5484e-01, 4.8649e-02, 3.5269e-02, 6.8570e-03, 3.1906e-04,\n",
      "         1.3224e-04, 2.2181e-05],\n",
      "        [1.2943e-03, 3.5277e-04, 6.1899e-03, 2.3301e-03, 1.8652e-03, 8.3951e-03,\n",
      "         2.1357e-02, 5.1050e-02, 3.3710e-02, 9.6297e-02, 5.3498e-02, 3.6847e-01,\n",
      "         4.2283e-02, 1.7072e-01, 4.2671e-02, 5.2927e-02, 3.9552e-02, 5.2203e-03,\n",
      "         1.6642e-03, 1.5852e-04],\n",
      "        [6.2967e-04, 5.8470e-05, 1.7002e-03, 8.9662e-04, 9.9079e-04, 4.3200e-03,\n",
      "         6.4179e-03, 1.8712e-02, 2.5529e-02, 5.6019e-02, 3.9585e-02, 2.0615e-01,\n",
      "         3.6253e-02, 1.3890e-01, 7.6658e-02, 1.3137e-01, 2.4492e-01, 8.7920e-03,\n",
      "         1.9368e-03, 1.6655e-04],\n",
      "        [2.2058e-03, 4.8402e-04, 5.8518e-03, 3.6367e-03, 3.4577e-03, 7.5191e-03,\n",
      "         1.4251e-02, 2.9985e-02, 3.6738e-02, 5.2834e-02, 4.3469e-02, 2.1401e-01,\n",
      "         5.1065e-02, 1.7115e-01, 7.2747e-02, 1.2104e-01, 1.5634e-01, 1.1155e-02,\n",
      "         1.8947e-03, 1.7553e-04],\n",
      "        [1.5949e-03, 4.7424e-04, 3.6070e-03, 8.3243e-04, 5.9504e-04, 2.6990e-03,\n",
      "         5.0720e-03, 1.3518e-02, 4.1137e-03, 1.3088e-02, 8.0287e-03, 8.4565e-02,\n",
      "         7.4682e-03, 2.5610e-02, 8.3552e-03, 4.2421e-02, 6.2277e-01, 1.2928e-01,\n",
      "         2.4886e-02, 1.0244e-03],\n",
      "        [2.8112e-03, 1.1670e-03, 2.5070e-03, 6.1825e-04, 3.8635e-04, 1.2247e-03,\n",
      "         2.7659e-03, 5.7350e-03, 1.3596e-03, 4.0918e-03, 2.6013e-03, 2.1103e-02,\n",
      "         2.6051e-03, 6.3657e-03, 2.3453e-03, 1.1467e-02, 4.4939e-01, 4.3291e-01,\n",
      "         4.5961e-02, 2.5893e-03],\n",
      "        [5.3092e-04, 4.2103e-04, 1.5425e-03, 7.8855e-04, 6.2056e-04, 1.1602e-03,\n",
      "         1.3779e-03, 4.0285e-03, 1.6415e-03, 3.7701e-03, 2.4981e-03, 2.9747e-02,\n",
      "         5.3084e-03, 1.1553e-02, 7.9321e-03, 3.4984e-02, 2.6155e-01, 3.3794e-01,\n",
      "         2.5218e-01, 4.0414e-02],\n",
      "        [8.8604e-04, 5.5301e-04, 4.0645e-03, 1.9353e-03, 1.4015e-03, 2.3122e-03,\n",
      "         1.7028e-03, 7.8230e-03, 3.8287e-03, 6.3299e-03, 3.6758e-03, 5.2377e-02,\n",
      "         9.8547e-03, 2.1532e-02, 9.9264e-03, 3.0028e-02, 8.8337e-02, 1.1288e-01,\n",
      "         5.2868e-01, 1.1187e-01],\n",
      "        [4.1571e-04, 3.2730e-04, 2.2845e-03, 8.8850e-04, 5.1482e-04, 6.9700e-04,\n",
      "         1.0239e-03, 3.5324e-03, 8.5083e-04, 1.5373e-03, 1.4387e-03, 1.3444e-02,\n",
      "         2.0305e-03, 3.2251e-03, 1.4034e-03, 2.5920e-03, 1.6951e-02, 5.4836e-02,\n",
      "         7.4399e-01, 1.4802e-01],\n",
      "        [3.0018e-04, 1.0830e-04, 9.8376e-04, 4.2259e-04, 3.5408e-04, 7.1291e-04,\n",
      "         7.3598e-04, 2.1393e-03, 9.2284e-04, 1.5491e-03, 1.0495e-03, 1.7084e-02,\n",
      "         1.9518e-03, 4.5970e-03, 2.4164e-03, 6.2969e-03, 2.9578e-02, 2.7463e-02,\n",
      "         7.4496e-01, 1.5637e-01],\n",
      "        [1.1509e-03, 3.7591e-04, 4.1948e-03, 2.2792e-03, 1.5904e-03, 2.0391e-03,\n",
      "         2.1488e-03, 7.2189e-03, 3.3556e-03, 4.2622e-03, 3.3024e-03, 4.2751e-02,\n",
      "         7.1240e-03, 1.3140e-02, 7.7364e-03, 1.3327e-02, 3.2679e-02, 4.6893e-02,\n",
      "         5.4263e-01, 2.6181e-01],\n",
      "        [1.9166e-02, 3.7561e-03, 4.2892e-02, 1.2241e-02, 8.4172e-03, 1.7918e-02,\n",
      "         2.8844e-02, 6.7354e-02, 1.3706e-02, 2.9709e-02, 1.7199e-02, 1.4313e-01,\n",
      "         4.5803e-02, 3.9189e-02, 1.6151e-02, 3.2445e-02, 7.5072e-02, 7.2148e-02,\n",
      "         2.4769e-01, 6.7171e-02],\n",
      "        [1.1945e-02, 6.9332e-03, 5.6952e-02, 2.9743e-02, 1.6471e-02, 2.0277e-02,\n",
      "         2.7757e-02, 6.5025e-02, 1.8857e-02, 2.8054e-02, 1.9936e-02, 1.0209e-01,\n",
      "         4.9424e-02, 3.7500e-02, 2.5135e-02, 5.3384e-02, 1.0048e-01, 6.9682e-02,\n",
      "         1.6631e-01, 9.4044e-02]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 5.33, Train Loss: 0.00, Val Loss: 5.29, Train BLEU: 0.00, Val BLEU: 5.30, Minutes Elapsed: 497.68\n",
      "Sampling from val predictions...\n",
      "Source: 我们 在 被 跟踪 吗 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: were we being followed ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> are we have to ? ? <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.6507, 0.0221, 0.0186, 0.0008, 0.2962, 0.0117, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.3700, 0.1446, 0.4370, 0.0116, 0.0308, 0.0061, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2926, 0.0786, 0.4071, 0.1899, 0.0206, 0.0111, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0506, 0.0115, 0.1972, 0.6632, 0.0393, 0.0383, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0238, 0.0176, 0.1499, 0.5984, 0.0937, 0.1167, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1044, 0.0122, 0.1324, 0.2391, 0.2107, 0.3012, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0559, 0.0144, 0.1017, 0.1093, 0.2240, 0.4947, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0753, 0.1203, 0.2695, 0.2373, 0.0990, 0.1985, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0640, 0.1060, 0.2994, 0.2007, 0.1009, 0.2290, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0958, 0.0526, 0.1190, 0.0575, 0.1962, 0.4789, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1265, 0.0448, 0.0846, 0.0385, 0.1787, 0.5269, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1583, 0.0548, 0.0882, 0.0272, 0.1801, 0.4914, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1899, 0.0581, 0.0882, 0.0225, 0.1820, 0.4593, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2046, 0.0574, 0.0852, 0.0203, 0.1812, 0.4513, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2146, 0.0572, 0.0839, 0.0190, 0.1791, 0.4463, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2247, 0.0567, 0.0835, 0.0183, 0.1773, 0.4394, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2346, 0.0562, 0.0834, 0.0181, 0.1755, 0.4322, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2443, 0.0556, 0.0835, 0.0182, 0.1736, 0.4248, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2535, 0.0551, 0.0836, 0.0185, 0.1717, 0.4176, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5.38, Train Loss: 0.00, Val Loss: 5.21, Train BLEU: 0.00, Val BLEU: 4.83, Minutes Elapsed: 502.87\n",
      "Sampling from val predictions...\n",
      "Source: 我 过去 讨厌 狮子 但是 现在 就是 是因为 因为 我 的 发明 拯救 了 我 爸爸 的 牛 以及 狮子\n",
      "Reference: i used to hate lions , but now because my invention is saving my father &apos;s cows and the\n",
      "Model: <SOS> i i a because , because because i my my my is my my my . <EOS> . <EOS>\n",
      "Attention Weights: tensor([[6.9224e-01, 2.1632e-01, 2.8987e-03, 3.6074e-03, 3.3029e-02, 4.1466e-02,\n",
      "         1.0061e-02, 9.1840e-05, 2.5080e-04, 2.5800e-05, 3.2877e-06, 1.4915e-06,\n",
      "         9.2572e-07, 1.2300e-07, 4.6976e-07, 7.7521e-08, 6.9967e-08, 1.6382e-07,\n",
      "         1.4279e-07, 7.5868e-08],\n",
      "        [2.5985e-02, 7.0323e-01, 2.4858e-01, 2.0608e-02, 4.9580e-04, 2.9427e-04,\n",
      "         6.6117e-04, 5.0303e-05, 4.6492e-05, 2.4270e-05, 4.7069e-06, 1.1426e-05,\n",
      "         5.6976e-06, 1.0296e-06, 1.5715e-06, 2.1457e-06, 6.2677e-07, 6.6095e-07,\n",
      "         6.5426e-07, 5.3151e-07],\n",
      "        [7.6811e-02, 3.1334e-01, 2.7694e-01, 2.4710e-01, 1.8716e-02, 1.4021e-02,\n",
      "         3.5454e-02, 6.8609e-03, 3.6371e-03, 3.9581e-03, 2.9992e-04, 2.0274e-03,\n",
      "         5.3258e-04, 9.5170e-05, 7.8635e-05, 3.3141e-05, 2.3279e-05, 2.1147e-05,\n",
      "         2.5714e-05, 2.5390e-05],\n",
      "        [2.7811e-03, 1.9865e-02, 8.7034e-02, 6.5595e-01, 5.6251e-02, 2.3870e-02,\n",
      "         1.7127e-02, 4.4363e-02, 1.7974e-02, 3.2432e-02, 1.0548e-03, 3.1702e-02,\n",
      "         8.2283e-03, 1.7095e-04, 4.4095e-04, 3.7197e-04, 7.4309e-05, 1.6328e-04,\n",
      "         7.5718e-05, 7.3018e-05],\n",
      "        [2.7192e-03, 4.0324e-03, 2.4533e-03, 8.9248e-02, 4.5875e-01, 1.8743e-01,\n",
      "         1.7728e-02, 4.5596e-02, 7.0513e-02, 7.3544e-02, 1.5091e-03, 2.4941e-02,\n",
      "         1.8437e-02, 8.2693e-04, 1.2991e-03, 3.1550e-04, 1.1532e-04, 2.7641e-04,\n",
      "         1.6480e-04, 9.6845e-05],\n",
      "        [3.6816e-03, 4.9440e-03, 1.0050e-03, 4.7823e-02, 4.0707e-01, 2.7473e-01,\n",
      "         1.3479e-02, 4.9856e-02, 9.4436e-02, 5.2511e-02, 1.8395e-03, 3.0758e-02,\n",
      "         1.6007e-02, 3.0059e-04, 7.9613e-04, 2.9044e-04, 5.7154e-05, 2.6460e-04,\n",
      "         1.0000e-04, 5.4239e-05],\n",
      "        [9.9908e-03, 1.8874e-02, 1.6102e-03, 1.5341e-02, 9.8950e-02, 3.0573e-01,\n",
      "         3.3610e-02, 6.1066e-02, 1.6984e-01, 1.3720e-01, 8.1739e-03, 7.8786e-02,\n",
      "         5.0453e-02, 1.9137e-03, 4.5133e-03, 2.8520e-03, 1.3345e-04, 6.7248e-04,\n",
      "         1.7917e-04, 1.1127e-04],\n",
      "        [7.8211e-03, 1.3421e-02, 9.5941e-04, 2.4528e-03, 4.4122e-02, 1.6061e-01,\n",
      "         1.6801e-02, 4.1356e-02, 1.1148e-01, 2.9512e-01, 1.0448e-02, 1.1458e-01,\n",
      "         1.0553e-01, 6.2104e-03, 4.2991e-02, 2.3083e-02, 4.7555e-04, 1.7841e-03,\n",
      "         4.3856e-04, 3.0435e-04],\n",
      "        [1.8945e-03, 7.8141e-03, 1.3935e-03, 1.4672e-03, 7.9440e-03, 1.4553e-02,\n",
      "         1.1226e-02, 3.4868e-02, 4.1547e-02, 2.7009e-01, 1.5469e-02, 3.3703e-01,\n",
      "         1.9108e-01, 3.4905e-03, 3.0928e-02, 2.4784e-02, 3.2298e-04, 3.1220e-03,\n",
      "         4.1292e-04, 5.7248e-04],\n",
      "        [9.1592e-04, 1.9817e-03, 4.2569e-04, 7.8083e-04, 6.1820e-03, 1.0513e-02,\n",
      "         6.8212e-03, 1.3777e-02, 3.9520e-02, 2.3460e-01, 2.3874e-02, 1.9537e-01,\n",
      "         2.0070e-01, 1.9683e-02, 1.4799e-01, 6.7006e-02, 5.4236e-03, 1.6654e-02,\n",
      "         4.5456e-03, 3.2388e-03],\n",
      "        [9.0549e-04, 9.3748e-04, 1.6236e-04, 3.9746e-04, 2.7397e-03, 6.5348e-03,\n",
      "         1.5412e-03, 7.1951e-03, 3.7698e-02, 1.4548e-01, 1.3976e-02, 1.4121e-01,\n",
      "         1.8505e-01, 2.3455e-02, 1.6983e-01, 2.0498e-01, 6.5151e-03, 3.7500e-02,\n",
      "         8.4724e-03, 5.4162e-03],\n",
      "        [4.3091e-04, 3.9032e-04, 4.9364e-05, 1.8368e-04, 1.9471e-03, 2.8967e-03,\n",
      "         7.5849e-04, 1.8455e-03, 1.4519e-02, 4.4405e-02, 5.8763e-03, 2.7451e-02,\n",
      "         6.7363e-02, 6.0030e-02, 3.9749e-01, 2.1458e-01, 3.4900e-02, 5.7860e-02,\n",
      "         4.8417e-02, 1.8606e-02],\n",
      "        [7.5107e-05, 6.8123e-05, 3.3635e-05, 9.4925e-05, 2.0626e-03, 2.1771e-03,\n",
      "         3.3122e-04, 1.1303e-03, 1.0870e-02, 6.3454e-03, 1.7553e-03, 8.0596e-03,\n",
      "         2.5967e-02, 5.7876e-02, 2.3934e-01, 1.7176e-01, 6.9118e-02, 1.2995e-01,\n",
      "         1.8133e-01, 9.1647e-02],\n",
      "        [9.3616e-05, 1.0219e-04, 9.1162e-06, 4.9085e-05, 8.1981e-04, 1.4366e-03,\n",
      "         9.6248e-05, 2.8283e-04, 2.4990e-03, 4.0090e-03, 2.7596e-04, 1.0922e-03,\n",
      "         3.6757e-03, 5.3906e-03, 2.0940e-01, 3.5790e-01, 1.2866e-02, 4.7000e-02,\n",
      "         1.1707e-01, 2.3593e-01],\n",
      "        [1.9431e-04, 8.7588e-05, 9.4036e-06, 1.0758e-04, 6.5670e-04, 7.2039e-04,\n",
      "         4.0826e-05, 1.8092e-04, 1.1066e-03, 4.1528e-03, 1.3013e-04, 6.5671e-04,\n",
      "         2.5924e-03, 1.6718e-03, 1.7990e-01, 2.2673e-01, 7.6224e-03, 5.2956e-02,\n",
      "         1.4295e-01, 3.7753e-01],\n",
      "        [9.7882e-04, 4.0878e-04, 3.2448e-05, 3.7141e-04, 1.1852e-03, 1.9622e-03,\n",
      "         1.2796e-04, 4.2874e-04, 2.2243e-03, 6.8921e-03, 3.5586e-04, 1.1107e-03,\n",
      "         5.2732e-03, 3.5885e-03, 2.0369e-01, 2.7829e-01, 7.6515e-03, 3.7438e-02,\n",
      "         8.2850e-02, 3.6514e-01],\n",
      "        [3.5472e-03, 2.0493e-03, 1.9123e-04, 1.2012e-03, 7.4099e-03, 1.0868e-02,\n",
      "         9.6242e-04, 2.2316e-03, 1.9521e-02, 6.5988e-03, 1.8015e-03, 4.3114e-03,\n",
      "         1.3918e-02, 1.6110e-02, 7.7766e-02, 2.1885e-01, 1.4969e-02, 6.5605e-02,\n",
      "         1.9403e-01, 3.3805e-01],\n",
      "        [3.0483e-02, 1.6194e-02, 1.2011e-03, 6.7017e-03, 2.3531e-02, 3.7491e-02,\n",
      "         3.4452e-03, 1.0524e-02, 3.9494e-02, 3.5736e-02, 6.4568e-03, 1.1279e-02,\n",
      "         3.8308e-02, 2.6204e-02, 1.5085e-01, 3.2850e-01, 2.1290e-02, 2.7708e-02,\n",
      "         5.7492e-02, 1.2711e-01],\n",
      "        [7.2035e-02, 1.9634e-02, 1.4016e-03, 1.0330e-02, 4.8453e-02, 8.9557e-02,\n",
      "         5.7336e-03, 1.0999e-02, 4.6699e-02, 2.0166e-02, 7.2941e-03, 1.7509e-02,\n",
      "         4.9147e-02, 3.9134e-02, 1.0141e-01, 1.8170e-01, 2.0116e-02, 3.1512e-02,\n",
      "         6.9068e-02, 1.5810e-01]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 5.44, Train Loss: 0.00, Val Loss: 5.12, Train BLEU: 0.00, Val BLEU: 5.17, Minutes Elapsed: 508.05\n",
      "Sampling from val predictions...\n",
      "Source: 新大 新大陆 大陆 的 <UNK> 主要 生长 在 美洲 大陆 像是 美洲 <UNK> 和 委内瑞拉 瑞拉 <UNK> 而 在 其他\n",
      "Reference: there are the new world <UNK> that are mainly found in the americas , like the <UNK> and the\n",
      "Model: <SOS> in of a <UNK> of in the in in in the africa , , in they . . .\n",
      "Attention Weights: tensor([[6.1466e-04, 4.6268e-03, 5.6691e-01, 2.5747e-02, 1.2534e-02, 3.6737e-01,\n",
      "         1.0446e-03, 3.0277e-04, 9.5503e-03, 7.3166e-03, 1.8043e-03, 1.9706e-03,\n",
      "         1.4288e-05, 1.4971e-05, 2.4323e-05, 3.2493e-06, 7.5858e-06, 1.5472e-05,\n",
      "         6.9584e-06, 1.2829e-04],\n",
      "        [2.1596e-03, 3.7593e-02, 5.8556e-01, 4.7072e-02, 1.1672e-01, 1.5349e-01,\n",
      "         1.9442e-02, 2.2346e-03, 1.1823e-02, 1.2792e-02, 6.6131e-03, 2.8498e-03,\n",
      "         2.3769e-04, 3.4264e-04, 1.8806e-04, 8.2909e-05, 3.0737e-04, 2.8711e-04,\n",
      "         9.6126e-05, 1.0321e-04],\n",
      "        [2.1379e-03, 4.1683e-02, 3.0603e-01, 8.4346e-02, 1.4887e-01, 2.6560e-01,\n",
      "         5.2801e-02, 1.4378e-02, 2.2399e-02, 2.3353e-02, 2.6366e-02, 6.4319e-03,\n",
      "         1.2167e-03, 1.3110e-03, 4.7280e-04, 3.1655e-04, 6.8935e-04, 9.4090e-04,\n",
      "         3.0549e-04, 3.6434e-04],\n",
      "        [1.4341e-03, 3.4978e-02, 2.0880e-01, 1.7719e-02, 1.1519e-01, 2.2004e-01,\n",
      "         6.0973e-02, 1.5815e-02, 1.0204e-01, 7.5130e-02, 6.2355e-02, 5.8109e-02,\n",
      "         6.5395e-03, 2.6161e-03, 4.0179e-03, 2.1768e-03, 2.5312e-03, 1.0200e-03,\n",
      "         6.8479e-04, 7.8340e-03],\n",
      "        [6.6297e-04, 3.5103e-02, 3.0421e-01, 1.2625e-02, 7.0670e-02, 1.5118e-01,\n",
      "         5.5851e-02, 2.3407e-02, 1.2613e-01, 7.2824e-02, 7.3625e-02, 5.6739e-02,\n",
      "         6.2344e-03, 3.2601e-03, 2.8837e-03, 1.1108e-03, 1.5194e-03, 8.2130e-04,\n",
      "         2.7774e-04, 8.6302e-04],\n",
      "        [1.2508e-03, 3.9975e-02, 3.3419e-01, 1.7891e-02, 3.6730e-02, 1.2214e-01,\n",
      "         3.1053e-02, 3.2405e-02, 1.4447e-01, 1.0049e-01, 8.7127e-02, 4.2597e-02,\n",
      "         3.7196e-03, 2.5456e-03, 1.5863e-03, 4.1704e-04, 5.2520e-04, 3.7953e-04,\n",
      "         1.3793e-04, 3.6591e-04],\n",
      "        [8.8402e-04, 4.0019e-02, 2.5834e-01, 6.7753e-03, 2.1805e-02, 6.6042e-02,\n",
      "         2.3769e-02, 2.8448e-02, 2.4540e-01, 1.1543e-01, 9.2807e-02, 8.3188e-02,\n",
      "         7.6130e-03, 4.1941e-03, 2.9107e-03, 6.3077e-04, 7.2011e-04, 3.8921e-04,\n",
      "         1.2208e-04, 5.2044e-04],\n",
      "        [2.6728e-04, 1.5179e-02, 1.0202e-01, 2.4114e-03, 8.2090e-03, 2.9928e-02,\n",
      "         4.9803e-03, 1.0586e-02, 2.9437e-01, 2.7782e-01, 9.0624e-02, 1.3275e-01,\n",
      "         9.2951e-03, 5.2718e-03, 6.5563e-03, 1.0897e-03, 1.6221e-03, 1.0152e-03,\n",
      "         7.3348e-04, 5.2753e-03],\n",
      "        [2.7875e-04, 9.4802e-03, 6.6000e-02, 1.7444e-03, 5.3736e-03, 2.3318e-02,\n",
      "         3.2249e-03, 1.1460e-02, 2.5485e-01, 2.9501e-01, 8.2859e-02, 1.5579e-01,\n",
      "         1.4914e-02, 1.1635e-02, 2.1253e-02, 3.2714e-03, 4.6727e-03, 4.0652e-03,\n",
      "         3.7348e-03, 2.7064e-02],\n",
      "        [2.0699e-04, 6.0443e-03, 2.5346e-02, 1.7394e-03, 4.0328e-03, 1.0350e-02,\n",
      "         3.5190e-03, 9.9000e-03, 1.6943e-01, 1.3830e-01, 7.7374e-02, 2.1722e-01,\n",
      "         6.5281e-02, 4.8713e-02, 6.4327e-02, 1.7944e-02, 2.1826e-02, 1.3984e-02,\n",
      "         1.1608e-02, 9.2857e-02],\n",
      "        [9.4742e-05, 2.9220e-03, 1.8550e-02, 6.0748e-04, 1.4245e-03, 4.0388e-03,\n",
      "         1.4349e-03, 2.6940e-03, 1.9446e-01, 7.4257e-02, 3.5519e-02, 2.9312e-01,\n",
      "         6.1264e-02, 3.5464e-02, 9.6790e-02, 2.3589e-02, 1.9817e-02, 7.6924e-03,\n",
      "         4.0191e-03, 1.2224e-01],\n",
      "        [1.2155e-04, 5.0275e-03, 4.1265e-02, 8.6773e-04, 2.3298e-03, 7.8288e-03,\n",
      "         1.6828e-03, 3.2370e-03, 2.1017e-01, 1.3047e-01, 3.6800e-02, 2.0175e-01,\n",
      "         4.6543e-02, 4.4947e-02, 1.0664e-01, 2.2746e-02, 2.4292e-02, 1.2580e-02,\n",
      "         7.0791e-03, 9.3622e-02],\n",
      "        [1.7777e-04, 6.1523e-03, 3.5074e-02, 1.2074e-03, 2.3060e-03, 7.0816e-03,\n",
      "         1.5810e-03, 3.8907e-03, 1.6915e-01, 9.6643e-02, 1.7591e-02, 1.3654e-01,\n",
      "         3.6664e-02, 4.0607e-02, 1.5035e-01, 3.9911e-02, 4.0156e-02, 2.6093e-02,\n",
      "         1.7940e-02, 1.7089e-01],\n",
      "        [2.0135e-04, 4.6355e-03, 4.2214e-02, 2.3520e-03, 1.9520e-03, 7.7553e-03,\n",
      "         2.3838e-03, 1.0015e-02, 7.6095e-02, 9.8782e-02, 4.1194e-02, 6.4248e-02,\n",
      "         4.8107e-02, 1.5160e-01, 9.8048e-02, 4.3090e-02, 6.0662e-02, 1.2981e-01,\n",
      "         2.2997e-02, 9.3850e-02],\n",
      "        [2.9332e-04, 6.4009e-03, 2.6721e-02, 1.5344e-03, 2.5484e-03, 6.4444e-03,\n",
      "         1.7233e-03, 7.4140e-03, 1.2122e-01, 6.8916e-02, 1.9566e-02, 8.2498e-02,\n",
      "         4.3151e-02, 6.3138e-02, 1.2214e-01, 5.6435e-02, 5.6595e-02, 1.0422e-01,\n",
      "         3.6060e-02, 1.7299e-01],\n",
      "        [3.9294e-04, 5.8870e-03, 2.4156e-02, 1.2220e-03, 2.2675e-03, 7.8889e-03,\n",
      "         1.7772e-03, 9.5729e-03, 1.2821e-01, 9.7493e-02, 1.1455e-02, 6.6262e-02,\n",
      "         1.6433e-02, 2.2320e-02, 8.2980e-02, 2.9630e-02, 3.7193e-02, 7.3152e-02,\n",
      "         4.7622e-02, 3.3408e-01],\n",
      "        [4.4147e-05, 8.9434e-04, 2.3278e-03, 2.3726e-04, 2.6081e-04, 6.1189e-04,\n",
      "         2.5094e-04, 8.4839e-04, 9.0096e-03, 3.8071e-03, 1.5269e-03, 9.1653e-03,\n",
      "         4.3592e-03, 4.5324e-03, 3.5574e-02, 2.1338e-02, 2.3399e-02, 4.2621e-02,\n",
      "         5.1676e-02, 7.8752e-01],\n",
      "        [7.3442e-05, 1.3685e-03, 3.8347e-03, 5.3360e-04, 7.3119e-04, 1.5945e-03,\n",
      "         6.2533e-04, 2.9920e-03, 3.2629e-02, 8.2546e-03, 1.9411e-03, 3.3821e-02,\n",
      "         1.0720e-02, 5.8053e-03, 9.4771e-02, 4.1786e-02, 3.6043e-02, 3.1258e-02,\n",
      "         4.7356e-02, 6.4386e-01],\n",
      "        [4.2649e-04, 3.4313e-03, 7.7170e-03, 1.4940e-03, 3.1220e-03, 4.8345e-03,\n",
      "         3.3734e-03, 1.1840e-02, 7.1049e-02, 2.2503e-02, 6.9548e-03, 6.4258e-02,\n",
      "         2.9735e-02, 1.8720e-02, 1.1218e-01, 5.9445e-02, 7.4068e-02, 7.7127e-02,\n",
      "         7.7614e-02, 3.5011e-01]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5.49, Train Loss: 0.00, Val Loss: 5.15, Train BLEU: 0.00, Val BLEU: 5.70, Minutes Elapsed: 513.24\n",
      "Sampling from val predictions...\n",
      "Source: 而 可持续性 持续 持续性 的 搞笑 之处 处在 在于 你 必须 维持 它 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: the funny thing about sustainability , you have to sustain it . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> and the of of that , you can to it it . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0652, 0.2703, 0.4402, 0.1539, 0.0123, 0.0568, 0.0007, 0.0002, 0.0003,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0150, 0.0807, 0.3899, 0.1548, 0.0297, 0.3022, 0.0189, 0.0043, 0.0036,\n",
      "         0.0008, 0.0001, 0.0000, 0.0000, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0407, 0.0503, 0.2921, 0.2823, 0.0843, 0.1574, 0.0494, 0.0187, 0.0108,\n",
      "         0.0035, 0.0014, 0.0006, 0.0005, 0.0081, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0239, 0.0304, 0.4886, 0.2082, 0.0454, 0.0751, 0.0401, 0.0309, 0.0447,\n",
      "         0.0074, 0.0006, 0.0002, 0.0002, 0.0043, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0077, 0.0090, 0.2214, 0.1001, 0.0163, 0.0382, 0.0322, 0.0581, 0.3208,\n",
      "         0.1290, 0.0193, 0.0081, 0.0065, 0.0333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0021, 0.0028, 0.0333, 0.0319, 0.0032, 0.0133, 0.0184, 0.0475, 0.4812,\n",
      "         0.2586, 0.0574, 0.0195, 0.0077, 0.0232, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0012, 0.0011, 0.0050, 0.0042, 0.0008, 0.0024, 0.0046, 0.0314, 0.7264,\n",
      "         0.1851, 0.0278, 0.0048, 0.0018, 0.0032, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0003, 0.0002, 0.0009, 0.0010, 0.0002, 0.0006, 0.0013, 0.0103, 0.2835,\n",
      "         0.4354, 0.2041, 0.0408, 0.0140, 0.0074, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0001, 0.0001, 0.0004, 0.0005, 0.0003, 0.0004, 0.0008, 0.0030, 0.0420,\n",
      "         0.2294, 0.5681, 0.1077, 0.0381, 0.0089, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0001, 0.0001, 0.0002, 0.0004, 0.0003, 0.0005, 0.0009, 0.0024, 0.0284,\n",
      "         0.0584, 0.1601, 0.5210, 0.2089, 0.0182, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0001, 0.0001, 0.0002, 0.0003, 0.0003, 0.0004, 0.0011,\n",
      "         0.0123, 0.0145, 0.0887, 0.8324, 0.0496, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0001, 0.0001, 0.0004, 0.0003, 0.0002, 0.0005, 0.0003, 0.0004, 0.0011,\n",
      "         0.0199, 0.0519, 0.1447, 0.6966, 0.0834, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0015, 0.0031, 0.0093, 0.0060, 0.0033, 0.0076, 0.0043, 0.0057, 0.0175,\n",
      "         0.0232, 0.0667, 0.0911, 0.4132, 0.3475, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0007, 0.0028, 0.0117, 0.0066, 0.0013, 0.0068, 0.0036, 0.0035, 0.0062,\n",
      "         0.0204, 0.0567, 0.1603, 0.2728, 0.4466, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0003, 0.0007, 0.0032, 0.0022, 0.0007, 0.0018, 0.0016, 0.0016, 0.0057,\n",
      "         0.0140, 0.2790, 0.3107, 0.3189, 0.0595, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0001, 0.0001, 0.0005, 0.0004, 0.0002, 0.0004, 0.0004, 0.0004, 0.0020,\n",
      "         0.0196, 0.2195, 0.2597, 0.4410, 0.0558, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0003, 0.0006, 0.0024, 0.0018, 0.0007, 0.0018, 0.0026, 0.0037, 0.0232,\n",
      "         0.1293, 0.1604, 0.1541, 0.3887, 0.1304, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0006, 0.0012, 0.0053, 0.0043, 0.0012, 0.0052, 0.0046, 0.0054, 0.0278,\n",
      "         0.1686, 0.1992, 0.1060, 0.3605, 0.1100, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0009, 0.0019, 0.0082, 0.0063, 0.0016, 0.0083, 0.0062, 0.0064, 0.0308,\n",
      "         0.1824, 0.1987, 0.0774, 0.3683, 0.1027, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 5.55, Train Loss: 0.00, Val Loss: 5.08, Train BLEU: 0.00, Val BLEU: 5.32, Minutes Elapsed: 518.43\n",
      "Sampling from val predictions...\n",
      "Source: 今天 我 做到 了 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: and here i am today . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> i i i i . <EOS> <EOS> <EOS> know <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9412, 0.0569, 0.0012, 0.0001, 0.0007, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.5396, 0.1668, 0.2688, 0.0054, 0.0194, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1884, 0.2742, 0.4548, 0.0583, 0.0242, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0785, 0.2657, 0.5106, 0.1218, 0.0235, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2369, 0.4447, 0.2372, 0.0382, 0.0430, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1583, 0.2362, 0.2875, 0.1211, 0.1969, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.3664, 0.1589, 0.0948, 0.0357, 0.3441, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.3960, 0.1621, 0.1116, 0.0305, 0.2999, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0253, 0.1431, 0.6279, 0.1282, 0.0755, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0179, 0.1280, 0.6021, 0.1918, 0.0603, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0809, 0.3930, 0.3496, 0.0781, 0.0983, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1126, 0.3846, 0.3639, 0.0554, 0.0835, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1364, 0.4226, 0.3232, 0.0422, 0.0756, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1587, 0.4333, 0.3044, 0.0335, 0.0701, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1689, 0.4299, 0.3070, 0.0295, 0.0648, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1712, 0.4250, 0.3158, 0.0277, 0.0603, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1709, 0.4212, 0.3235, 0.0269, 0.0575, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1716, 0.4191, 0.3265, 0.0264, 0.0564, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1742, 0.4184, 0.3252, 0.0260, 0.0563, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 5.60, Train Loss: 0.00, Val Loss: 5.16, Train BLEU: 0.00, Val BLEU: 5.15, Minutes Elapsed: 523.62\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 祖父 在 他 的 年代 是 位非 非凡 的 人 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: my grandfather was an extraordinary man for his time . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> my father is in in in . <EOS> . . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.4811, 0.0103, 0.4802, 0.0073, 0.0037, 0.0023, 0.0146, 0.0004, 0.0000,\n",
      "         0.0000, 0.0000, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0155, 0.0096, 0.9083, 0.0036, 0.0072, 0.0033, 0.0505, 0.0007, 0.0003,\n",
      "         0.0002, 0.0001, 0.0006, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1195, 0.0323, 0.5053, 0.0756, 0.0887, 0.0269, 0.1081, 0.0110, 0.0061,\n",
      "         0.0052, 0.0024, 0.0089, 0.0101, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0363, 0.0119, 0.1399, 0.1534, 0.2551, 0.0515, 0.2740, 0.0229, 0.0224,\n",
      "         0.0101, 0.0028, 0.0123, 0.0072, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0129, 0.0023, 0.0161, 0.0185, 0.3126, 0.0328, 0.4206, 0.0274, 0.0537,\n",
      "         0.0609, 0.0100, 0.0221, 0.0101, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0045, 0.0002, 0.0019, 0.0022, 0.1002, 0.0088, 0.1936, 0.0260, 0.3104,\n",
      "         0.2100, 0.0208, 0.1067, 0.0147, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0116, 0.0007, 0.0049, 0.0039, 0.1667, 0.0035, 0.1366, 0.0874, 0.3436,\n",
      "         0.1357, 0.0147, 0.0800, 0.0107, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0578, 0.0065, 0.0208, 0.0132, 0.3877, 0.0073, 0.1832, 0.0243, 0.1253,\n",
      "         0.1334, 0.0037, 0.0232, 0.0136, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0566, 0.0084, 0.0386, 0.0114, 0.2634, 0.0086, 0.3764, 0.0083, 0.0486,\n",
      "         0.1387, 0.0015, 0.0219, 0.0176, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0537, 0.0087, 0.0258, 0.0270, 0.1256, 0.0102, 0.3080, 0.0190, 0.1353,\n",
      "         0.1696, 0.0056, 0.0342, 0.0771, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0320, 0.0065, 0.0232, 0.0248, 0.1082, 0.0080, 0.2819, 0.0216, 0.1559,\n",
      "         0.1606, 0.0062, 0.0308, 0.1405, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0419, 0.0136, 0.0460, 0.0208, 0.1674, 0.0143, 0.4163, 0.0103, 0.0387,\n",
      "         0.1113, 0.0041, 0.0302, 0.0850, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0047, 0.0038, 0.0149, 0.0083, 0.0266, 0.0075, 0.0880, 0.0111, 0.0844,\n",
      "         0.6015, 0.0164, 0.0571, 0.0756, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0084, 0.0035, 0.0159, 0.0135, 0.0585, 0.0105, 0.0944, 0.0149, 0.0542,\n",
      "         0.4971, 0.0233, 0.0604, 0.1455, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0179, 0.0018, 0.0046, 0.0113, 0.1441, 0.0106, 0.1553, 0.0114, 0.0360,\n",
      "         0.3747, 0.0234, 0.0529, 0.1560, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0232, 0.0034, 0.0102, 0.0125, 0.2002, 0.0102, 0.2169, 0.0101, 0.0233,\n",
      "         0.2800, 0.0154, 0.0546, 0.1401, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0272, 0.0045, 0.0131, 0.0128, 0.2228, 0.0092, 0.2301, 0.0100, 0.0221,\n",
      "         0.2447, 0.0134, 0.0514, 0.1387, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0319, 0.0054, 0.0150, 0.0128, 0.2262, 0.0087, 0.2433, 0.0097, 0.0220,\n",
      "         0.2242, 0.0125, 0.0506, 0.1376, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0358, 0.0062, 0.0164, 0.0126, 0.2193, 0.0086, 0.2527, 0.0098, 0.0222,\n",
      "         0.2153, 0.0121, 0.0511, 0.1379, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5.66, Train Loss: 0.00, Val Loss: 5.13, Train BLEU: 0.00, Val BLEU: 5.45, Minutes Elapsed: 528.81\n",
      "Sampling from val predictions...\n",
      "Source: 她们 带 着 我 走下 一段 <UNK> 狭窄 的 楼梯 到 了 一个 肮脏 昏暗 的 地下 地下室 <EOS> <PAD>\n",
      "Reference: they ushered me down a narrow set of stairs that led to this dirty , dimly fluorescent lit basement\n",
      "Model: <SOS> they they me a a a of , a , a a a . . . . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9588, 0.0384, 0.0026, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2591, 0.4584, 0.1129, 0.1571, 0.0097, 0.0010, 0.0002, 0.0003, 0.0002,\n",
      "         0.0005, 0.0001, 0.0001, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0002, 0.0000],\n",
      "        [0.0228, 0.0850, 0.1329, 0.6503, 0.0880, 0.0113, 0.0026, 0.0021, 0.0005,\n",
      "         0.0023, 0.0003, 0.0005, 0.0005, 0.0001, 0.0000, 0.0000, 0.0001, 0.0002,\n",
      "         0.0005, 0.0000],\n",
      "        [0.0376, 0.0121, 0.0209, 0.3662, 0.2293, 0.1024, 0.0827, 0.0588, 0.0076,\n",
      "         0.0492, 0.0014, 0.0032, 0.0065, 0.0030, 0.0017, 0.0006, 0.0051, 0.0074,\n",
      "         0.0045, 0.0000],\n",
      "        [0.0358, 0.0072, 0.0066, 0.1577, 0.1564, 0.0681, 0.1264, 0.1503, 0.0242,\n",
      "         0.1517, 0.0115, 0.0089, 0.0171, 0.0137, 0.0065, 0.0010, 0.0163, 0.0195,\n",
      "         0.0211, 0.0000],\n",
      "        [0.0033, 0.0006, 0.0010, 0.0511, 0.0477, 0.0852, 0.1527, 0.2509, 0.0232,\n",
      "         0.1635, 0.0102, 0.0105, 0.0291, 0.0354, 0.0226, 0.0022, 0.0459, 0.0508,\n",
      "         0.0140, 0.0000],\n",
      "        [0.0046, 0.0004, 0.0005, 0.0328, 0.0118, 0.0596, 0.0817, 0.1917, 0.0439,\n",
      "         0.2015, 0.0282, 0.0130, 0.0391, 0.0527, 0.0368, 0.0048, 0.0914, 0.0918,\n",
      "         0.0136, 0.0000],\n",
      "        [0.0214, 0.0010, 0.0009, 0.0325, 0.0156, 0.0303, 0.0734, 0.2249, 0.0543,\n",
      "         0.1834, 0.0903, 0.0149, 0.0134, 0.0320, 0.0388, 0.0073, 0.0690, 0.0780,\n",
      "         0.0186, 0.0000],\n",
      "        [0.0348, 0.0027, 0.0020, 0.0820, 0.0205, 0.0214, 0.0370, 0.0925, 0.0179,\n",
      "         0.1000, 0.0583, 0.0240, 0.0403, 0.1373, 0.0973, 0.0070, 0.0936, 0.1099,\n",
      "         0.0214, 0.0000],\n",
      "        [0.0493, 0.0022, 0.0013, 0.1032, 0.0361, 0.0227, 0.0295, 0.0513, 0.0109,\n",
      "         0.0641, 0.0179, 0.0089, 0.0324, 0.1856, 0.1373, 0.0042, 0.0978, 0.1218,\n",
      "         0.0235, 0.0000],\n",
      "        [0.0256, 0.0031, 0.0019, 0.0371, 0.0119, 0.0126, 0.0226, 0.0473, 0.0133,\n",
      "         0.0411, 0.0601, 0.0128, 0.0220, 0.1664, 0.2079, 0.0109, 0.1302, 0.1539,\n",
      "         0.0194, 0.0000],\n",
      "        [0.0262, 0.0030, 0.0020, 0.0399, 0.0274, 0.0138, 0.0190, 0.0228, 0.0047,\n",
      "         0.0228, 0.0210, 0.0126, 0.0565, 0.3486, 0.2139, 0.0050, 0.0611, 0.0777,\n",
      "         0.0219, 0.0000],\n",
      "        [0.0029, 0.0006, 0.0006, 0.0263, 0.0168, 0.0104, 0.0078, 0.0100, 0.0030,\n",
      "         0.0086, 0.0228, 0.0261, 0.0669, 0.2386, 0.2617, 0.0221, 0.1337, 0.1310,\n",
      "         0.0101, 0.0000],\n",
      "        [0.0007, 0.0001, 0.0001, 0.0045, 0.0023, 0.0057, 0.0035, 0.0036, 0.0011,\n",
      "         0.0036, 0.0018, 0.0039, 0.0328, 0.2452, 0.2700, 0.0072, 0.1589, 0.2397,\n",
      "         0.0152, 0.0000],\n",
      "        [0.0004, 0.0001, 0.0001, 0.0011, 0.0010, 0.0048, 0.0036, 0.0056, 0.0024,\n",
      "         0.0037, 0.0016, 0.0020, 0.0115, 0.1732, 0.2138, 0.0266, 0.1888, 0.3360,\n",
      "         0.0236, 0.0000],\n",
      "        [0.0054, 0.0025, 0.0013, 0.0096, 0.0089, 0.0060, 0.0084, 0.0116, 0.0047,\n",
      "         0.0087, 0.0105, 0.0027, 0.0057, 0.0974, 0.2058, 0.0058, 0.1519, 0.3260,\n",
      "         0.1271, 0.0000],\n",
      "        [0.0156, 0.0062, 0.0045, 0.0206, 0.0268, 0.0176, 0.0136, 0.0171, 0.0105,\n",
      "         0.0150, 0.0112, 0.0063, 0.0120, 0.0992, 0.1063, 0.0049, 0.0731, 0.1864,\n",
      "         0.3530, 0.0000],\n",
      "        [0.0106, 0.0046, 0.0019, 0.0130, 0.0204, 0.0145, 0.0100, 0.0137, 0.0035,\n",
      "         0.0153, 0.0114, 0.0127, 0.0346, 0.1527, 0.1899, 0.0216, 0.0982, 0.1868,\n",
      "         0.1845, 0.0000],\n",
      "        [0.0087, 0.0044, 0.0041, 0.0456, 0.0256, 0.0230, 0.0065, 0.0108, 0.0066,\n",
      "         0.0159, 0.0249, 0.0136, 0.0261, 0.0684, 0.0817, 0.0087, 0.0769, 0.2025,\n",
      "         0.3461, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 5.71, Train Loss: 0.00, Val Loss: 5.11, Train BLEU: 0.00, Val BLEU: 5.36, Minutes Elapsed: 534.00\n",
      "Sampling from val predictions...\n",
      "Source: 家庭 家庭暴力 暴力 模式 的 第三 第三阶段 三阶 阶段 就是 开始 用 暴力 威胁 受害 受害者 并 观察 她 的\n",
      "Reference: the next step in the domestic violence pattern is to introduce the threat of violence and see how she\n",
      "Model: <SOS> the first of of the , , , , the by her her . . . <EOS> . <EOS>\n",
      "Attention Weights: tensor([[2.1914e-02, 1.5735e-03, 1.5392e-03, 2.1394e-03, 3.7032e-03, 8.4228e-01,\n",
      "         3.5863e-03, 1.0838e-02, 1.0483e-01, 7.2279e-03, 2.1566e-04, 8.8327e-05,\n",
      "         4.9891e-05, 1.0302e-05, 7.5267e-06, 5.1855e-06, 2.5139e-07, 2.3105e-08,\n",
      "         2.3321e-08, 5.5456e-09],\n",
      "        [8.6285e-02, 2.7094e-02, 5.0958e-02, 2.9553e-02, 8.6014e-03, 4.7235e-01,\n",
      "         1.7982e-02, 4.5048e-02, 1.7334e-01, 5.6526e-02, 2.2587e-02, 3.2598e-03,\n",
      "         3.2879e-03, 2.5943e-03, 2.2698e-04, 2.7857e-04, 1.5339e-05, 7.9896e-06,\n",
      "         8.3791e-06, 2.7044e-07],\n",
      "        [1.4106e-01, 7.7247e-02, 1.0680e-01, 7.8845e-02, 6.6885e-03, 5.7117e-02,\n",
      "         5.9461e-03, 1.4654e-02, 1.1957e-01, 1.7295e-01, 1.1008e-01, 4.0060e-02,\n",
      "         2.5592e-02, 3.7594e-02, 3.3754e-03, 2.0494e-03, 1.1850e-04, 1.7732e-04,\n",
      "         7.0627e-05, 2.6326e-06],\n",
      "        [1.9806e-01, 7.7997e-02, 9.2827e-02, 3.2593e-02, 4.8943e-03, 1.9249e-02,\n",
      "         3.1465e-03, 7.2209e-03, 7.1057e-02, 2.0507e-01, 1.4677e-01, 6.2490e-02,\n",
      "         2.3508e-02, 4.7895e-02, 3.8295e-03, 2.1336e-03, 3.9432e-04, 6.0768e-04,\n",
      "         2.4077e-04, 6.5121e-06],\n",
      "        [2.0041e-01, 4.8880e-02, 7.3746e-02, 1.8589e-02, 5.9232e-04, 7.4994e-03,\n",
      "         9.1082e-04, 1.9152e-03, 2.2393e-02, 7.3473e-02, 2.1121e-01, 1.6242e-01,\n",
      "         6.6556e-02, 9.9801e-02, 4.6255e-03, 3.5396e-03, 1.2439e-03, 1.6868e-03,\n",
      "         4.9211e-04, 7.1784e-06],\n",
      "        [5.6030e-02, 9.1860e-03, 2.6154e-02, 3.4560e-03, 1.9646e-04, 5.2267e-03,\n",
      "         3.3357e-04, 2.9512e-04, 2.5382e-03, 2.0689e-02, 2.0860e-01, 2.3110e-01,\n",
      "         2.6536e-01, 1.3807e-01, 1.7022e-02, 9.5837e-03, 1.6046e-03, 2.6404e-03,\n",
      "         1.8877e-03, 2.3174e-05],\n",
      "        [1.4051e-02, 7.9695e-03, 1.2583e-02, 5.2630e-03, 8.1323e-04, 2.6311e-03,\n",
      "         2.4913e-04, 6.1664e-04, 7.8453e-03, 1.0435e-01, 6.9528e-02, 7.9524e-02,\n",
      "         1.0522e-01, 4.3805e-01, 7.6924e-02, 4.7624e-02, 1.6190e-02, 9.2364e-03,\n",
      "         1.2855e-03, 4.0533e-05],\n",
      "        [1.8220e-02, 7.2844e-03, 1.1751e-02, 2.2034e-03, 1.7483e-04, 4.0562e-04,\n",
      "         6.7807e-05, 1.5519e-04, 1.8913e-03, 2.3864e-02, 8.3973e-02, 7.0496e-02,\n",
      "         1.3286e-01, 4.5599e-01, 8.3005e-02, 5.2044e-02, 1.8304e-02, 3.3169e-02,\n",
      "         4.1017e-03, 4.0728e-05],\n",
      "        [6.1379e-04, 2.1450e-04, 4.0200e-04, 1.1760e-04, 2.4067e-05, 1.0850e-04,\n",
      "         1.8841e-05, 1.6893e-05, 1.2659e-04, 3.8844e-03, 3.6365e-02, 4.1025e-02,\n",
      "         7.3843e-02, 1.9421e-01, 1.9115e-01, 1.2317e-01, 9.8214e-02, 1.6270e-01,\n",
      "         7.3430e-02, 3.7010e-04],\n",
      "        [1.6150e-04, 4.2108e-05, 1.0312e-04, 3.6100e-05, 1.9571e-05, 9.2426e-05,\n",
      "         1.2715e-05, 9.7587e-06, 4.1834e-05, 6.1203e-04, 5.9701e-03, 8.7754e-03,\n",
      "         2.2741e-02, 4.0254e-02, 1.3280e-01, 1.2748e-01, 1.1431e-01, 2.5989e-01,\n",
      "         2.8422e-01, 2.4273e-03],\n",
      "        [1.7484e-04, 4.7556e-05, 1.2248e-04, 3.5180e-05, 1.9515e-05, 1.6719e-04,\n",
      "         1.8021e-05, 8.3075e-06, 3.8675e-05, 3.0511e-04, 2.5608e-03, 2.8459e-03,\n",
      "         1.5747e-02, 1.1666e-02, 6.1480e-02, 9.7634e-02, 6.3796e-02, 2.2080e-01,\n",
      "         5.1734e-01, 5.1910e-03],\n",
      "        [2.4286e-04, 7.2627e-05, 1.4090e-04, 5.3497e-05, 2.9499e-05, 1.0799e-04,\n",
      "         2.1143e-05, 1.5129e-05, 5.7655e-05, 8.6484e-05, 1.6621e-03, 1.3393e-03,\n",
      "         1.5180e-02, 1.2335e-02, 5.8689e-02, 9.7236e-02, 6.5107e-02, 3.3258e-01,\n",
      "         4.0429e-01, 1.0754e-02],\n",
      "        [2.0604e-04, 7.0914e-05, 1.6404e-04, 7.6427e-05, 4.1690e-05, 1.7415e-04,\n",
      "         4.4441e-05, 2.0528e-05, 4.5548e-05, 7.4648e-05, 5.6789e-04, 7.8833e-04,\n",
      "         1.8611e-02, 4.8373e-03, 3.8296e-02, 7.9643e-02, 2.5654e-02, 1.3895e-01,\n",
      "         6.7556e-01, 1.6173e-02],\n",
      "        [1.4564e-03, 7.7028e-04, 1.5619e-03, 1.3872e-03, 6.5254e-04, 1.3816e-03,\n",
      "         2.6198e-04, 2.0630e-04, 9.2435e-04, 5.8994e-04, 4.4490e-03, 6.0261e-03,\n",
      "         6.1827e-02, 2.1591e-02, 9.3338e-02, 1.7296e-01, 2.5400e-02, 1.4459e-01,\n",
      "         4.4437e-01, 1.6245e-02],\n",
      "        [2.8612e-03, 2.3227e-03, 2.3252e-03, 1.8368e-03, 1.8223e-04, 2.7121e-04,\n",
      "         7.6048e-05, 1.1085e-04, 6.5345e-04, 5.5169e-04, 6.6539e-03, 5.8704e-03,\n",
      "         4.1173e-02, 6.2999e-02, 6.8552e-02, 1.1247e-01, 7.6558e-02, 2.1807e-01,\n",
      "         3.9285e-01, 3.6042e-03],\n",
      "        [6.3013e-03, 4.0175e-03, 5.8311e-03, 2.5706e-03, 3.2139e-04, 1.4521e-03,\n",
      "         2.5345e-04, 2.6693e-04, 1.0756e-03, 9.0662e-04, 2.3737e-02, 1.7667e-02,\n",
      "         7.6610e-02, 3.6306e-02, 7.1254e-02, 1.0562e-01, 7.7340e-02, 2.3886e-01,\n",
      "         3.2394e-01, 5.6597e-03],\n",
      "        [5.7515e-03, 5.0035e-03, 6.5520e-03, 5.5412e-03, 7.6392e-04, 7.6127e-04,\n",
      "         1.6134e-04, 3.4179e-04, 1.8470e-03, 3.3331e-03, 1.7733e-02, 1.6081e-02,\n",
      "         7.6683e-02, 9.5708e-02, 8.9051e-02, 1.9904e-01, 1.4787e-01, 1.3899e-01,\n",
      "         1.8579e-01, 2.9946e-03],\n",
      "        [8.1099e-03, 4.5752e-03, 7.9246e-03, 5.3378e-03, 1.5474e-03, 6.2240e-03,\n",
      "         1.1242e-03, 1.6076e-03, 4.4065e-03, 3.0090e-03, 4.6992e-02, 2.5346e-02,\n",
      "         9.7126e-02, 4.6049e-02, 5.9719e-02, 1.2882e-01, 1.0154e-01, 1.6927e-01,\n",
      "         2.7555e-01, 5.7177e-03],\n",
      "        [6.9592e-03, 7.0756e-03, 8.9936e-03, 1.0494e-02, 2.5751e-03, 5.0019e-03,\n",
      "         1.0047e-03, 1.4085e-03, 7.8938e-03, 6.2076e-03, 5.7182e-02, 2.1801e-02,\n",
      "         7.7719e-02, 5.2531e-02, 5.9042e-02, 1.1258e-01, 1.8565e-01, 2.0682e-01,\n",
      "         1.5189e-01, 1.7176e-02]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5.77, Train Loss: 0.00, Val Loss: 5.29, Train BLEU: 0.00, Val BLEU: 5.54, Minutes Elapsed: 539.20\n",
      "Sampling from val predictions...\n",
      "Source: 图象 象是 强大 的 但 同时 又 是 表面 <UNK> 的 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: image is powerful , but also image is superficial . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> the is the , but it &apos;s the <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.5010, 0.2078, 0.2707, 0.0037, 0.0114, 0.0050, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000, 0.0001, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1179, 0.0639, 0.7049, 0.0138, 0.0728, 0.0231, 0.0005, 0.0002, 0.0000,\n",
      "         0.0000, 0.0003, 0.0026, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0443, 0.0544, 0.4674, 0.0339, 0.2880, 0.0832, 0.0110, 0.0032, 0.0003,\n",
      "         0.0006, 0.0025, 0.0112, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0065, 0.0093, 0.2648, 0.0065, 0.5594, 0.1346, 0.0119, 0.0021, 0.0003,\n",
      "         0.0003, 0.0007, 0.0037, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0165, 0.0092, 0.0724, 0.0040, 0.6722, 0.1751, 0.0298, 0.0085, 0.0022,\n",
      "         0.0010, 0.0014, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0050, 0.0038, 0.0219, 0.0009, 0.3627, 0.4416, 0.0983, 0.0284, 0.0163,\n",
      "         0.0039, 0.0015, 0.0157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0029, 0.0018, 0.0603, 0.0011, 0.1154, 0.4300, 0.1843, 0.0817, 0.0804,\n",
      "         0.0227, 0.0031, 0.0164, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0009, 0.0009, 0.0212, 0.0013, 0.0467, 0.1994, 0.1743, 0.1370, 0.3025,\n",
      "         0.0802, 0.0140, 0.0215, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0008, 0.0007, 0.0152, 0.0007, 0.0157, 0.0543, 0.0483, 0.0454, 0.6351,\n",
      "         0.1334, 0.0176, 0.0328, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0062, 0.0051, 0.0279, 0.0040, 0.0625, 0.0703, 0.0306, 0.0357, 0.5140,\n",
      "         0.1592, 0.0253, 0.0591, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0015, 0.0007, 0.0073, 0.0006, 0.0124, 0.0186, 0.0085, 0.0259, 0.5624,\n",
      "         0.2498, 0.0196, 0.0928, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0257, 0.0113, 0.0449, 0.0066, 0.1164, 0.0729, 0.0182, 0.0183, 0.1962,\n",
      "         0.0821, 0.0224, 0.3851, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0029, 0.0019, 0.0352, 0.0022, 0.0187, 0.0263, 0.0203, 0.0447, 0.3413,\n",
      "         0.3900, 0.0313, 0.0852, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0018, 0.0013, 0.0131, 0.0015, 0.0117, 0.0175, 0.0145, 0.0400, 0.3904,\n",
      "         0.3627, 0.0485, 0.0971, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0024, 0.0036, 0.0096, 0.0055, 0.0763, 0.0771, 0.0604, 0.0513, 0.2270,\n",
      "         0.1396, 0.0516, 0.2956, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0045, 0.0045, 0.0274, 0.0047, 0.1284, 0.1073, 0.0902, 0.0451, 0.1327,\n",
      "         0.0947, 0.0293, 0.3312, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0068, 0.0054, 0.0381, 0.0052, 0.1477, 0.1140, 0.0861, 0.0371, 0.0910,\n",
      "         0.0695, 0.0270, 0.3720, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0090, 0.0057, 0.0465, 0.0058, 0.1534, 0.1229, 0.0843, 0.0333, 0.0769,\n",
      "         0.0580, 0.0258, 0.3784, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0111, 0.0060, 0.0541, 0.0063, 0.1567, 0.1299, 0.0829, 0.0307, 0.0694,\n",
      "         0.0517, 0.0248, 0.3763, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 5.82, Train Loss: 0.00, Val Loss: 5.13, Train BLEU: 0.00, Val BLEU: 5.09, Minutes Elapsed: 544.40\n",
      "Sampling from val predictions...\n",
      "Source: 哈 他 早 有 准备 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: ha . he &apos;s ready . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> he he he &apos;s to . . &apos;s . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0312, 0.9151, 0.0262, 0.0179, 0.0076, 0.0019, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0243, 0.7608, 0.1265, 0.0648, 0.0201, 0.0036, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0148, 0.3950, 0.2413, 0.1297, 0.1799, 0.0392, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0023, 0.2209, 0.4037, 0.1115, 0.2210, 0.0407, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0012, 0.1819, 0.3417, 0.2087, 0.2171, 0.0494, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0036, 0.0199, 0.4809, 0.1009, 0.3212, 0.0735, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0200, 0.0804, 0.4424, 0.0595, 0.2767, 0.1210, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0472, 0.0791, 0.4153, 0.0521, 0.0833, 0.3229, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0058, 0.0593, 0.5024, 0.1806, 0.1322, 0.1197, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0060, 0.1093, 0.5197, 0.0914, 0.1265, 0.1471, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0037, 0.1712, 0.2425, 0.0427, 0.0811, 0.4588, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0048, 0.1614, 0.2504, 0.0410, 0.0892, 0.4532, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0057, 0.1581, 0.2750, 0.0483, 0.0996, 0.4133, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0066, 0.1616, 0.2804, 0.0525, 0.1016, 0.3973, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0073, 0.1652, 0.2849, 0.0561, 0.1020, 0.3845, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0078, 0.1672, 0.2878, 0.0582, 0.1009, 0.3780, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0083, 0.1685, 0.2892, 0.0595, 0.0997, 0.3748, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0087, 0.1699, 0.2899, 0.0604, 0.0987, 0.3724, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0090, 0.1713, 0.2905, 0.0612, 0.0979, 0.3700, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 5.88, Train Loss: 0.00, Val Loss: 5.08, Train BLEU: 0.00, Val BLEU: 5.59, Minutes Elapsed: 549.58\n",
      "Sampling from val predictions...\n",
      "Source: 刚好 当地 的 疏散 中心 正在 收集 人们 丢失 的 照片 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: this happened to also be a place in the town where the evacuation center was collecting the photos .\n",
      "Model: <SOS> and the is the the the in of the , , the found is . . . <EOS> .\n",
      "Attention Weights: tensor([[0.7220, 0.2305, 0.0332, 0.0064, 0.0043, 0.0018, 0.0007, 0.0002, 0.0000,\n",
      "         0.0001, 0.0003, 0.0005, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1946, 0.7005, 0.0101, 0.0680, 0.0218, 0.0003, 0.0002, 0.0004, 0.0001,\n",
      "         0.0002, 0.0026, 0.0013, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2013, 0.4488, 0.0220, 0.1558, 0.0724, 0.0057, 0.0021, 0.0039, 0.0021,\n",
      "         0.0027, 0.0592, 0.0241, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0659, 0.5437, 0.0190, 0.0972, 0.1318, 0.0114, 0.0058, 0.0124, 0.0073,\n",
      "         0.0072, 0.0682, 0.0301, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0498, 0.3904, 0.0220, 0.0640, 0.1528, 0.0160, 0.0070, 0.0145, 0.0105,\n",
      "         0.0167, 0.2077, 0.0486, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0388, 0.4113, 0.0165, 0.0838, 0.2570, 0.0110, 0.0053, 0.0133, 0.0069,\n",
      "         0.0095, 0.1305, 0.0160, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0350, 0.4685, 0.0087, 0.0604, 0.1816, 0.0222, 0.0090, 0.0290, 0.0143,\n",
      "         0.0095, 0.1293, 0.0324, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0685, 0.4138, 0.0090, 0.0472, 0.1311, 0.0437, 0.0176, 0.0750, 0.0164,\n",
      "         0.0117, 0.1003, 0.0658, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0472, 0.6453, 0.0057, 0.0463, 0.1177, 0.0810, 0.0082, 0.0307, 0.0029,\n",
      "         0.0009, 0.0071, 0.0072, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0486, 0.5872, 0.0048, 0.0663, 0.1358, 0.0454, 0.0130, 0.0505, 0.0141,\n",
      "         0.0024, 0.0117, 0.0202, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0370, 0.1175, 0.0072, 0.0176, 0.1314, 0.5666, 0.0219, 0.0793, 0.0067,\n",
      "         0.0014, 0.0042, 0.0093, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0252, 0.1581, 0.0037, 0.0153, 0.0389, 0.5263, 0.0392, 0.1745, 0.0126,\n",
      "         0.0007, 0.0023, 0.0033, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0089, 0.0689, 0.0011, 0.0096, 0.0197, 0.0688, 0.0611, 0.5625, 0.1454,\n",
      "         0.0073, 0.0192, 0.0274, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0020, 0.0067, 0.0004, 0.0014, 0.0053, 0.0221, 0.0689, 0.5066, 0.3196,\n",
      "         0.0153, 0.0317, 0.0200, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0010, 0.0063, 0.0003, 0.0010, 0.0047, 0.1244, 0.0374, 0.6330, 0.1793,\n",
      "         0.0035, 0.0046, 0.0045, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0005, 0.0042, 0.0001, 0.0003, 0.0010, 0.0054, 0.0088, 0.6055, 0.3313,\n",
      "         0.0076, 0.0217, 0.0137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0018, 0.0102, 0.0003, 0.0013, 0.0053, 0.0169, 0.0125, 0.4755, 0.3849,\n",
      "         0.0144, 0.0309, 0.0462, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0052, 0.0241, 0.0009, 0.0079, 0.0088, 0.0147, 0.0196, 0.4483, 0.3041,\n",
      "         0.0075, 0.0419, 0.1169, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0162, 0.0851, 0.0021, 0.0247, 0.0382, 0.0571, 0.0311, 0.3806, 0.1876,\n",
      "         0.0055, 0.0313, 0.1404, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5.93, Train Loss: 0.00, Val Loss: 5.24, Train BLEU: 0.00, Val BLEU: 5.31, Minutes Elapsed: 554.79\n",
      "Sampling from val predictions...\n",
      "Source: 见到 他 是 在 一个 收容 收容所 所里 free the <UNK> 组织 用于 <UNK> 奴役 受害 受害者 的 一个 地方\n",
      "Reference: i met him at a shelter where free the slaves <UNK> victims of slavery . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> she was a a a a of a a a of a the <EOS> . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.1885e-02, 9.7155e-01, 1.2684e-02, 2.4145e-03, 2.6639e-04, 5.8961e-04,\n",
      "         4.0956e-04, 2.3395e-05, 1.0759e-04, 1.6818e-05, 4.3100e-06, 1.4082e-05,\n",
      "         1.0797e-06, 1.8564e-07, 9.0339e-07, 6.6034e-06, 4.2451e-06, 5.9254e-06,\n",
      "         4.7520e-06, 6.4062e-06],\n",
      "        [8.4084e-03, 6.5557e-01, 2.1906e-01, 9.8239e-02, 7.5921e-03, 6.1119e-03,\n",
      "         1.6397e-03, 3.2996e-04, 1.3266e-03, 4.0070e-04, 1.8687e-04, 5.9743e-04,\n",
      "         8.5648e-05, 2.1979e-05, 4.2621e-05, 6.5949e-05, 5.9891e-05, 3.7297e-05,\n",
      "         1.2278e-04, 9.5450e-05],\n",
      "        [1.1580e-02, 1.3650e-01, 3.1564e-01, 3.5480e-01, 5.4646e-02, 3.4849e-02,\n",
      "         1.3621e-02, 3.8890e-03, 1.6487e-02, 8.0777e-03, 4.2872e-03, 1.1422e-02,\n",
      "         3.3397e-03, 1.2172e-03, 1.8683e-03, 3.8801e-03, 4.7213e-03, 4.4491e-03,\n",
      "         9.3273e-03, 5.3975e-03],\n",
      "        [1.2725e-03, 6.6096e-03, 7.8007e-03, 5.8590e-02, 2.5733e-01, 3.5380e-01,\n",
      "         1.1927e-01, 2.4486e-02, 7.7049e-02, 3.3679e-02, 8.1064e-03, 5.0409e-03,\n",
      "         1.9937e-03, 1.7300e-03, 1.3992e-03, 2.8831e-03, 5.6561e-03, 1.9622e-03,\n",
      "         2.1729e-02, 9.6134e-03],\n",
      "        [2.5109e-04, 1.4753e-03, 3.1921e-03, 1.8212e-02, 1.6279e-01, 2.8301e-01,\n",
      "         2.0514e-01, 3.3584e-02, 1.2230e-01, 4.8374e-02, 1.8975e-02, 1.8210e-02,\n",
      "         3.7154e-03, 1.9306e-03, 2.5058e-03, 5.6221e-03, 9.2236e-03, 5.3021e-03,\n",
      "         3.9207e-02, 1.6976e-02],\n",
      "        [9.6884e-05, 4.5899e-04, 9.9556e-04, 9.4731e-03, 1.2252e-01, 2.1208e-01,\n",
      "         2.0718e-01, 3.3635e-02, 1.3667e-01, 5.3836e-02, 2.2977e-02, 2.8369e-02,\n",
      "         9.4926e-03, 5.9823e-03, 7.3345e-03, 1.1260e-02, 2.6796e-02, 1.1602e-02,\n",
      "         6.3480e-02, 3.5761e-02],\n",
      "        [4.6230e-05, 3.4569e-04, 3.3515e-04, 2.9819e-03, 2.3907e-02, 8.5953e-02,\n",
      "         1.8945e-01, 6.6106e-02, 2.5162e-01, 1.0952e-01, 7.7962e-02, 7.9093e-02,\n",
      "         1.8304e-02, 5.4648e-03, 5.9446e-03, 9.4730e-03, 1.6372e-02, 1.0044e-02,\n",
      "         2.5062e-02, 2.2025e-02],\n",
      "        [4.3207e-04, 2.1302e-03, 1.1761e-03, 1.0994e-02, 7.5758e-03, 7.2065e-02,\n",
      "         1.6918e-01, 6.7293e-02, 2.8427e-01, 8.1221e-02, 8.6035e-02, 1.2971e-01,\n",
      "         4.6838e-02, 6.5351e-03, 1.0138e-02, 6.5218e-03, 8.6000e-03, 2.9916e-03,\n",
      "         2.1497e-03, 4.1506e-03],\n",
      "        [4.6929e-04, 3.4422e-03, 7.3743e-04, 7.8621e-03, 1.0138e-02, 3.4072e-02,\n",
      "         5.9301e-02, 1.4463e-02, 4.9954e-02, 2.2078e-02, 2.0082e-02, 2.8003e-01,\n",
      "         1.8275e-01, 2.3361e-02, 8.0672e-02, 6.5198e-02, 7.6040e-02, 1.0785e-02,\n",
      "         2.1481e-02, 3.7083e-02],\n",
      "        [2.5311e-05, 2.6973e-04, 2.2971e-04, 3.7476e-03, 1.6681e-02, 1.7235e-02,\n",
      "         2.1530e-02, 3.4644e-03, 1.4869e-02, 7.4597e-03, 7.3473e-03, 7.7321e-02,\n",
      "         1.2598e-01, 2.8192e-02, 4.7506e-02, 8.2627e-02, 1.3798e-01, 4.0180e-02,\n",
      "         2.2526e-01, 1.4210e-01],\n",
      "        [3.5862e-06, 3.9569e-05, 1.5672e-05, 3.8958e-04, 2.5943e-03, 1.1904e-02,\n",
      "         2.0198e-02, 4.4533e-03, 1.0847e-02, 4.1753e-03, 5.7884e-03, 3.3379e-02,\n",
      "         8.7574e-02, 4.3975e-02, 5.4684e-02, 9.8240e-02, 1.4397e-01, 5.3680e-02,\n",
      "         1.3752e-01, 2.8657e-01],\n",
      "        [2.0886e-05, 6.9628e-05, 2.7425e-05, 1.1701e-03, 9.6361e-04, 1.7162e-02,\n",
      "         2.9766e-02, 9.0616e-03, 1.7381e-02, 5.5581e-03, 1.1522e-02, 5.6350e-02,\n",
      "         1.4796e-01, 9.5145e-02, 1.8618e-01, 1.7713e-01, 1.6363e-01, 1.2656e-02,\n",
      "         1.0145e-02, 5.8105e-02],\n",
      "        [2.4303e-05, 2.1073e-04, 4.5002e-05, 1.1216e-03, 3.0941e-03, 1.9796e-02,\n",
      "         1.7791e-02, 3.0047e-03, 4.6928e-03, 2.2407e-03, 2.3735e-03, 1.0256e-02,\n",
      "         1.7669e-02, 3.6167e-02, 1.4679e-01, 2.6282e-01, 3.8071e-01, 2.4091e-03,\n",
      "         1.6807e-02, 7.1970e-02],\n",
      "        [6.5000e-05, 4.0108e-04, 1.3861e-04, 2.7774e-03, 5.5223e-03, 2.5453e-02,\n",
      "         2.0507e-02, 2.3463e-03, 4.3635e-03, 1.9492e-03, 1.7614e-03, 9.0509e-03,\n",
      "         1.0724e-02, 2.1948e-02, 1.2065e-01, 2.4698e-01, 4.6627e-01, 1.6950e-03,\n",
      "         1.0730e-02, 4.6681e-02],\n",
      "        [1.8559e-04, 4.9115e-04, 2.6342e-04, 2.6183e-03, 6.9702e-03, 2.4283e-02,\n",
      "         2.1607e-02, 2.2943e-03, 4.0395e-03, 2.1123e-03, 1.4054e-03, 7.3785e-03,\n",
      "         4.5305e-03, 1.4476e-02, 7.3493e-02, 1.8905e-01, 5.7594e-01, 1.5708e-03,\n",
      "         1.2019e-02, 5.5267e-02],\n",
      "        [1.9025e-04, 5.8363e-04, 2.7570e-04, 6.8977e-03, 3.4381e-03, 2.6215e-02,\n",
      "         2.9681e-02, 8.2428e-03, 1.8554e-02, 9.8752e-03, 1.0128e-02, 3.2836e-02,\n",
      "         4.0804e-02, 5.6872e-02, 1.1499e-01, 2.2864e-01, 3.7334e-01, 4.0009e-03,\n",
      "         4.9574e-03, 2.9482e-02],\n",
      "        [7.6442e-04, 1.9847e-03, 9.6866e-04, 2.0435e-02, 1.4287e-02, 3.7366e-02,\n",
      "         2.8051e-02, 5.2103e-03, 1.1112e-02, 4.8511e-03, 5.5882e-03, 2.3271e-02,\n",
      "         2.2916e-02, 3.7703e-02, 1.2194e-01, 2.2007e-01, 3.8255e-01, 3.6228e-03,\n",
      "         1.0749e-02, 4.6563e-02],\n",
      "        [2.1575e-03, 3.2167e-03, 3.1093e-03, 4.5944e-02, 2.2437e-02, 4.2502e-02,\n",
      "         2.2076e-02, 4.6559e-03, 7.7184e-03, 4.7418e-03, 4.0816e-03, 1.8316e-02,\n",
      "         3.3013e-02, 3.2477e-02, 7.8262e-02, 2.1653e-01, 2.1664e-01, 1.8996e-02,\n",
      "         7.2642e-02, 1.5048e-01],\n",
      "        [1.8380e-03, 9.3349e-03, 1.1685e-02, 1.1437e-01, 3.3216e-02, 2.2870e-02,\n",
      "         1.8224e-02, 4.5211e-03, 1.0112e-02, 7.8468e-03, 6.0261e-03, 2.0160e-02,\n",
      "         4.2011e-02, 3.5690e-02, 6.1314e-02, 1.4839e-01, 1.6035e-01, 3.6107e-02,\n",
      "         1.2388e-01, 1.3206e-01]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 5.99, Train Loss: 0.00, Val Loss: 5.20, Train BLEU: 0.00, Val BLEU: 5.21, Minutes Elapsed: 560.00\n",
      "Sampling from val predictions...\n",
      "Source: 十几 十几岁 几岁 时 我 跟 朋友 一起 起开 开车 她 是 个 糟糕 的 司机 <UNK> 了 红灯 我们\n",
      "Reference: when i was a teenager , i was driving with my friend who was an awful driver and she\n",
      "Model: <SOS> after years was my to , my was a a <UNK> , , <EOS> call . . . <EOS>\n",
      "Attention Weights: tensor([[3.9913e-03, 4.1203e-01, 1.0521e-02, 2.2161e-02, 5.0968e-01, 2.0159e-02,\n",
      "         6.9493e-03, 4.2338e-03, 2.4921e-03, 3.5999e-04, 7.1957e-03, 1.1573e-04,\n",
      "         3.0389e-05, 6.0061e-05, 1.2941e-06, 2.3836e-06, 3.6868e-07, 1.0799e-06,\n",
      "         2.1495e-06, 1.6393e-05],\n",
      "        [7.8353e-03, 6.6256e-01, 3.5277e-02, 1.3510e-02, 1.1150e-01, 1.3059e-01,\n",
      "         2.5597e-02, 5.4664e-03, 2.8153e-03, 1.3004e-03, 2.1381e-03, 6.6642e-04,\n",
      "         1.4420e-04, 5.6766e-04, 3.8747e-06, 5.5265e-06, 2.6094e-06, 2.3258e-06,\n",
      "         8.8939e-06, 1.0422e-05],\n",
      "        [6.7290e-03, 2.4786e-01, 4.8356e-02, 2.8091e-02, 3.3498e-01, 1.0166e-01,\n",
      "         1.3880e-01, 4.3398e-02, 1.7731e-02, 1.0280e-02, 9.9953e-03, 4.7400e-03,\n",
      "         2.2854e-03, 4.8341e-03, 3.8253e-05, 5.5579e-05, 4.3096e-05, 2.8987e-05,\n",
      "         7.4306e-05, 2.2546e-05],\n",
      "        [1.5951e-03, 6.4014e-02, 2.2317e-02, 1.0630e-02, 1.7189e-01, 1.0913e-01,\n",
      "         2.9394e-01, 1.2057e-01, 6.4212e-02, 5.9017e-02, 3.5435e-02, 1.0641e-02,\n",
      "         1.1038e-02, 2.4237e-02, 2.0064e-04, 2.8883e-04, 2.3214e-04, 1.3348e-04,\n",
      "         3.7317e-04, 1.0178e-04],\n",
      "        [2.5175e-04, 1.0148e-02, 2.7893e-03, 1.3328e-03, 6.4258e-03, 5.5718e-03,\n",
      "         6.0195e-01, 6.7324e-02, 8.4166e-02, 3.2635e-02, 5.4734e-02, 4.6424e-03,\n",
      "         1.7628e-02, 1.0137e-01, 1.4487e-03, 3.0593e-03, 1.0055e-03, 4.5454e-04,\n",
      "         2.7566e-03, 3.0736e-04],\n",
      "        [1.3079e-03, 2.1773e-02, 5.6599e-03, 5.7668e-03, 3.6296e-02, 9.9676e-03,\n",
      "         4.2368e-01, 1.0294e-01, 1.2152e-01, 2.9206e-02, 1.1828e-01, 1.3348e-02,\n",
      "         1.5025e-02, 8.2054e-02, 2.2123e-03, 3.8738e-03, 1.4106e-03, 1.3436e-03,\n",
      "         2.8446e-03, 1.4992e-03],\n",
      "        [1.7939e-03, 1.4344e-02, 5.3834e-03, 8.6650e-03, 6.0283e-02, 4.7329e-02,\n",
      "         5.4050e-02, 1.0543e-01, 1.1320e-01, 6.8060e-02, 3.3691e-01, 1.0443e-01,\n",
      "         5.6608e-03, 3.7756e-02, 3.3002e-03, 9.1689e-03, 7.4084e-03, 8.2600e-03,\n",
      "         2.9014e-03, 5.6616e-03],\n",
      "        [1.1527e-03, 1.2264e-02, 2.0780e-03, 2.0642e-03, 2.8867e-02, 2.2316e-02,\n",
      "         1.2519e-01, 3.2353e-02, 5.5952e-02, 5.5928e-02, 3.9357e-01, 1.4544e-01,\n",
      "         2.2763e-02, 6.7617e-02, 1.5726e-03, 6.6742e-03, 5.0690e-03, 4.1294e-03,\n",
      "         7.3406e-03, 7.6600e-03],\n",
      "        [1.2132e-04, 1.6022e-03, 7.5980e-04, 7.2626e-04, 2.8402e-03, 1.5712e-03,\n",
      "         1.4624e-02, 8.8446e-03, 2.1950e-02, 4.5769e-02, 1.1836e-01, 2.2116e-01,\n",
      "         1.4647e-01, 2.4988e-01, 8.5074e-03, 3.8335e-02, 2.9339e-02, 9.8420e-03,\n",
      "         6.7430e-02, 1.1868e-02],\n",
      "        [9.9574e-06, 1.3095e-04, 5.8064e-05, 2.0416e-05, 6.5501e-05, 8.6514e-05,\n",
      "         2.1602e-02, 3.8545e-03, 1.3963e-02, 1.1368e-02, 3.6485e-02, 8.2665e-03,\n",
      "         9.2803e-02, 7.1363e-01, 1.6924e-02, 4.3567e-02, 1.0850e-02, 1.6887e-03,\n",
      "         2.4105e-02, 5.1732e-04],\n",
      "        [3.4323e-05, 3.6393e-04, 1.5810e-04, 6.1577e-05, 1.1545e-04, 6.8920e-05,\n",
      "         1.1980e-02, 2.5349e-03, 9.5047e-03, 3.2142e-03, 4.4341e-02, 7.2465e-03,\n",
      "         2.9680e-02, 4.1584e-01, 3.4801e-02, 1.7618e-01, 5.6897e-02, 1.6768e-02,\n",
      "         1.7910e-01, 1.1109e-02],\n",
      "        [6.2224e-05, 7.0779e-04, 1.4288e-04, 1.2228e-04, 3.9148e-04, 4.9679e-05,\n",
      "         6.8992e-03, 1.7089e-03, 1.0212e-02, 1.5272e-03, 4.2672e-02, 5.6031e-03,\n",
      "         1.7715e-02, 1.4172e-01, 1.5998e-02, 1.2680e-01, 2.8197e-02, 2.1321e-02,\n",
      "         2.0110e-01, 3.7705e-01],\n",
      "        [3.1317e-04, 2.3434e-03, 3.8492e-04, 7.2296e-04, 2.0178e-03, 1.9858e-04,\n",
      "         1.9389e-03, 4.0208e-03, 1.4340e-02, 2.9064e-03, 3.0344e-02, 5.9707e-03,\n",
      "         2.7672e-03, 2.3747e-02, 9.0736e-03, 5.7243e-02, 2.0917e-02, 1.5946e-02,\n",
      "         6.4725e-02, 7.4008e-01],\n",
      "        [1.2643e-03, 9.3868e-03, 3.3567e-03, 3.0548e-03, 3.6913e-03, 2.3141e-03,\n",
      "         8.6524e-03, 2.0204e-02, 4.1691e-02, 1.2484e-02, 4.8193e-02, 1.3397e-02,\n",
      "         4.4383e-03, 3.8031e-02, 1.3812e-02, 5.4826e-02, 5.6687e-02, 4.1446e-02,\n",
      "         8.4050e-02, 5.3902e-01],\n",
      "        [6.6424e-03, 4.2961e-02, 6.3678e-03, 4.2940e-03, 1.6141e-02, 8.0364e-03,\n",
      "         8.2998e-02, 3.9094e-02, 7.3877e-02, 2.1981e-02, 1.3178e-01, 1.3981e-02,\n",
      "         1.0621e-02, 2.4912e-02, 4.5107e-03, 1.0470e-02, 1.3382e-02, 1.5980e-02,\n",
      "         6.2302e-02, 4.0967e-01],\n",
      "        [7.6333e-04, 1.0624e-02, 3.4021e-03, 3.0737e-03, 1.0177e-02, 9.6052e-03,\n",
      "         1.4599e-01, 8.0758e-02, 1.0133e-01, 3.1622e-02, 5.3630e-02, 2.0339e-02,\n",
      "         3.3314e-02, 6.0770e-02, 1.4993e-02, 1.7272e-02, 1.4603e-02, 1.8909e-02,\n",
      "         8.4493e-02, 2.8433e-01],\n",
      "        [1.7879e-03, 1.6290e-02, 4.1305e-03, 5.0064e-03, 1.0678e-02, 2.6982e-03,\n",
      "         1.7015e-01, 4.8587e-02, 1.1698e-01, 2.3322e-02, 4.5360e-02, 4.4058e-03,\n",
      "         7.9285e-03, 7.9778e-02, 1.0268e-02, 5.8889e-02, 2.7800e-02, 1.2833e-02,\n",
      "         1.6270e-01, 1.9040e-01],\n",
      "        [4.2536e-03, 4.0013e-02, 9.5231e-03, 8.9245e-03, 2.2565e-02, 5.4176e-03,\n",
      "         4.2476e-02, 6.6001e-02, 1.8897e-01, 4.8978e-02, 6.4672e-02, 6.0764e-03,\n",
      "         2.7644e-03, 2.3412e-02, 1.4286e-02, 9.1321e-02, 6.3762e-02, 2.1854e-02,\n",
      "         1.5449e-01, 1.2024e-01],\n",
      "        [6.7967e-03, 7.8374e-02, 1.6878e-02, 1.5044e-02, 3.3214e-02, 2.4861e-02,\n",
      "         7.8114e-02, 9.7948e-02, 1.5794e-01, 6.2421e-02, 8.6903e-02, 6.5309e-03,\n",
      "         2.3630e-03, 1.3603e-02, 3.4389e-03, 2.7742e-02, 4.3342e-02, 2.3170e-02,\n",
      "         9.7189e-02, 1.2413e-01]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6.00, Train Loss: 0.00, Val Loss: 5.19, Train BLEU: 0.00, Val BLEU: 5.12, Minutes Elapsed: 561.14\n",
      "Sampling from val predictions...\n",
      "Source: 这个 个人 还 得 去 <UNK> 条约 和 接见 <UNK> <UNK> <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: this guy has to go and sign treaties and meet foreign <UNK> . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> this person is a to with and and the <EOS> . <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.3968, 0.5792, 0.0225, 0.0012, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0309, 0.9279, 0.0224, 0.0132, 0.0036, 0.0003, 0.0007, 0.0001, 0.0003,\n",
      "         0.0001, 0.0001, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0616, 0.4068, 0.2330, 0.1209, 0.1031, 0.0133, 0.0154, 0.0046, 0.0093,\n",
      "         0.0080, 0.0113, 0.0128, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0332, 0.1177, 0.1903, 0.2929, 0.1925, 0.0456, 0.0395, 0.0111, 0.0281,\n",
      "         0.0134, 0.0168, 0.0187, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0087, 0.0540, 0.1113, 0.2039, 0.3024, 0.1364, 0.0883, 0.0184, 0.0362,\n",
      "         0.0102, 0.0121, 0.0181, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0080, 0.0181, 0.0156, 0.0210, 0.1529, 0.1439, 0.3951, 0.1167, 0.0600,\n",
      "         0.0184, 0.0247, 0.0253, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0041, 0.0115, 0.0058, 0.0026, 0.0284, 0.0786, 0.7306, 0.0989, 0.0146,\n",
      "         0.0076, 0.0106, 0.0067, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0115, 0.0121, 0.0054, 0.0013, 0.0212, 0.0412, 0.6211, 0.2280, 0.0273,\n",
      "         0.0088, 0.0098, 0.0123, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0075, 0.0085, 0.0049, 0.0014, 0.0108, 0.0273, 0.6865, 0.1713, 0.0272,\n",
      "         0.0136, 0.0193, 0.0217, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0365, 0.0179, 0.0035, 0.0005, 0.0059, 0.0220, 0.5156, 0.2555, 0.0516,\n",
      "         0.0241, 0.0332, 0.0336, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2665, 0.1669, 0.0205, 0.0035, 0.0274, 0.0302, 0.2027, 0.0739, 0.0319,\n",
      "         0.0200, 0.0398, 0.1166, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0366, 0.0834, 0.0219, 0.0096, 0.0423, 0.0547, 0.2607, 0.0713, 0.0447,\n",
      "         0.0630, 0.1346, 0.1774, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0296, 0.0243, 0.0061, 0.0047, 0.0176, 0.0545, 0.3094, 0.0654, 0.0451,\n",
      "         0.0484, 0.0874, 0.3075, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1304, 0.1250, 0.0192, 0.0068, 0.0328, 0.0362, 0.1580, 0.0595, 0.0367,\n",
      "         0.0263, 0.0475, 0.3215, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2409, 0.2844, 0.0398, 0.0115, 0.0294, 0.0158, 0.0709, 0.0281, 0.0261,\n",
      "         0.0153, 0.0263, 0.2116, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0383, 0.2856, 0.0940, 0.0700, 0.1072, 0.0408, 0.0832, 0.0436, 0.0540,\n",
      "         0.0330, 0.0446, 0.1055, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0115, 0.0509, 0.0674, 0.0574, 0.0976, 0.0398, 0.1083, 0.0678, 0.0898,\n",
      "         0.0698, 0.1344, 0.2054, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0820, 0.1002, 0.0616, 0.0290, 0.0705, 0.0190, 0.0743, 0.0852, 0.0850,\n",
      "         0.0513, 0.0759, 0.2660, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1387, 0.2125, 0.0636, 0.0286, 0.0450, 0.0155, 0.0701, 0.0448, 0.0388,\n",
      "         0.0279, 0.0498, 0.2647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, results = train_and_eval(\n",
    "    model=model, loaders_full=loaders_full, loaders_minibatch=loaders_minibatch, loaders_minitrain=loaders_minitrain, \n",
    "    params=params, vocab=vocab, print_intermediate=100, save_checkpoint=True, save_to_log=True, \n",
    "    lazy_eval=True, print_attn=True, inspect_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_results(load_experiment_log())[['dt_created', 'num_epochs', 'learning_rate', 'clip_grad_max_norm', 'val_loss']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_learning_curve(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch: 199.00, Train Loss: 0.32, Val Loss: 13.19, Train BLEU: 98.94, Val BLEU: 0.27\n",
    "plot_single_learning_curve(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with attention energies = v_broadcast.bmm(torch.tanh(self.attn(concat)).transpose(1, 2)) # switched order  \n",
    "# Epoch: 199.00, Train Loss: 0.63, Val Loss: 12.82, Train BLEU: 92.05, Val BLEU: 0.38\n",
    "plot_single_learning_curve(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, token in enumerate(vocab[SRC_LANG]['id2token']): \n",
    "    if i < 20: \n",
    "        print(\"{}: {}\".format(i, token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, token in enumerate(vocab[TARG_LANG]['id2token']): \n",
    "    if i < 20: \n",
    "        print(\"{}: {}\".format(i, token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.arange(0, 3*5*10).view(3, 5, 10)\n",
    "print(x)\n",
    "y = x[1:, :, :]\n",
    "print(y)\n",
    "z = y.view(-1, 10)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.arange(0, 2*5).view(5, 2)\n",
    "print(t)\n",
    "u = t.contiguous().view(-1)\n",
    "print(u)\n",
    "v = t.permute(1, 0)\n",
    "print(v)\n",
    "w = v.contiguous().view(-1)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(0, 2*1*300)\n",
    "print(a)\n",
    "b = a.view(-1, 1, 300)\n",
    "print(b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (src_idxs, targ_idxs, src_lens, targ_lens) in enumerate(full_loaders['train']):\n",
    "#     print(i)\n",
    "#     print(src_idxs.size())\n",
    "#     print(src_idxs)\n",
    "#     print(src_lens)\n",
    "#     print(targ_idxs.size())\n",
    "#     print(targ_idxs)\n",
    "#     print(targ_lens)\n",
    "    id2token = vocab[SRC_LANG]['id2token']\n",
    "    test_tensor = src_idxs\n",
    "    list_of_lists = test_tensor.numpy().astype(int).tolist()\n",
    "    to_token = lambda l: ' '.join([id2token[idx] for idx in l])\n",
    "    list_of_lists_tokens = [to_token(l) for l in list_of_lists] \n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
