{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from data_processing import generate_vocab, process_data, create_dataloaders \n",
    "from model import get_pretrained_emb, EncoderDecoder, EncoderRNN, DecoderRNN, DecoderSimpleRNN, \\\n",
    "    Attention, DecoderAttnRNN\n",
    "from train_eval import train_and_eval, inspect_model, count_parameters, summarize_results, \\\n",
    "    plot_single_learning_curve, load_experiment_log\n",
    "from train_eval import train_and_eval_V2, tensor2corpus_V2\n",
    "import importlib\n",
    "import pickle as pkl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model identification\n",
    "MODEL_NAME = 'test_model'\n",
    "SRC_LANG = 'zh'\n",
    "TARG_LANG = 'en'\n",
    "\n",
    "# data processing params  \n",
    "SRC_MAX_SENTENCE_LEN = 2\n",
    "TARG_MAX_SENTENCE_LEN = 2\n",
    "SRC_VOCAB_SIZE = 30000\n",
    "TARG_VOCAB_SIZE = 30000\n",
    "\n",
    "# model architecture params \n",
    "NUM_LAYERS = 1 #2 \n",
    "ENC_HIDDEN_DIM = 300 \n",
    "DEC_HIDDEN_DIM = 2 * ENC_HIDDEN_DIM \n",
    "TEACHER_FORCING_RATIO = 1\n",
    "CLIP_GRAD_MAX_NORM = 10\n",
    "ENC_DROPOUT = 0 # to actually implement\n",
    "DEC_DROPOUT = 0 # to actually implement\n",
    "\n",
    "# training params  \n",
    "BATCH_SIZE = 16 #32\n",
    "NUM_EPOCHS = 200\n",
    "LR = 0.001 # 0.0005\n",
    "OPTIMIZER = 'Adam'\n",
    "LAZY_TRAIN = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store as dict to save to results later \n",
    "params = {'model_name': MODEL_NAME, 'src_lang': SRC_LANG, 'targ_lang': TARG_LANG, \n",
    "          'src_max_sentence_len': SRC_MAX_SENTENCE_LEN, 'targ_max_sentence_len': TARG_MAX_SENTENCE_LEN, \n",
    "          'src_vocab_size': SRC_VOCAB_SIZE, 'targ_vocab_size': TARG_VOCAB_SIZE, \n",
    "          'num_layers': NUM_LAYERS, 'enc_hidden_dim': ENC_HIDDEN_DIM, 'dec_hidden_dim': DEC_HIDDEN_DIM,\n",
    "          'teacher_forcing_ratio': TEACHER_FORCING_RATIO, 'clip_grad_max_norm': CLIP_GRAD_MAX_NORM,\n",
    "          'enc_dropout': ENC_DROPOUT, 'dec_dropout': DEC_DROPOUT, \n",
    "          'batch_size': BATCH_SIZE, 'num_epochs': NUM_EPOCHS, 'learning_rate': LR, 'optimizer': OPTIMIZER, \n",
    "          'lazy_train': LAZY_TRAIN} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # takes a long time to process, save to pickle for reimport in future \n",
    "# vocab = generate_vocab(SRC_LANG, TARG_LANG, SRC_VOCAB_SIZE, TARG_VOCAB_SIZE)\n",
    "# vocab_filename = \"{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n",
    "# pkl.dump(vocab, open(vocab_filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload from pickle \n",
    "vocab_filename = \"{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n",
    "vocab = pkl.load(open(vocab_filename, \"rb\"))\n",
    "data = process_data(SRC_LANG, TARG_LANG, vocab)\n",
    "limited_data = process_data(SRC_LANG, TARG_LANG, vocab, sample_limit=BATCH_SIZE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders \n",
    "full_loaders = create_dataloaders(data, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)\n",
    "fast_loaders = create_dataloaders(limited_data, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model \n",
    "\n",
    "encoder = EncoderRNN(enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, src_max_sentence_len=SRC_MAX_SENTENCE_LEN,\n",
    "                     pretrained_word2vec=get_pretrained_emb(vocab[SRC_LANG]['word2vec'], vocab[SRC_LANG]['token2id']))\n",
    "# decoder = DecoderSimpleRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, \n",
    "#                            targ_vocab_size=TARG_VOCAB_SIZE, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "#                            pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "decoder = DecoderAttnRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, \n",
    "                         targ_vocab_size=TARG_VOCAB_SIZE, src_max_sentence_len=SRC_MAX_SENTENCE_LEN, \n",
    "                         targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "                         pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "model = EncoderDecoder(encoder, decoder, vocab[TARG_LANG]['token2id']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.00, Train Loss: 9.01, Val Loss: 9.94, Train BLEU: 44.31, Val BLEU: 1.00\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分\n",
      "Reference: most\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正\n",
      "Reference: a\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 1.00, Train Loss: 7.70, Val Loss: 9.60, Train BLEU: 31.94, Val BLEU: 1.00\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里\n",
      "Reference: the\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班\n",
      "Reference: &quot;\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 2.00, Train Loss: 6.30, Val Loss: 9.21, Train BLEU: 31.94, Val BLEU: 1.00\n",
      "Sampling from training predictions...\n",
      "Source: 原因 在于\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正\n",
      "Reference: a\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 3.00, Train Loss: 4.94, Val Loss: 8.83, Train BLEU: 31.94, Val BLEU: 1.00\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11\n",
      "Reference: when\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 4.00, Train Loss: 3.77, Val Loss: 8.61, Train BLEU: 31.94, Val BLEU: 1.00\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 这 是\n",
      "Reference: it\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 5.00, Train Loss: 2.97, Val Loss: 8.69, Train BLEU: 31.94, Val BLEU: 1.00\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这\n",
      "Reference: we\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很\n",
      "Reference: it\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 6.00, Train Loss: 2.50, Val Loss: 8.97, Train BLEU: 31.94, Val BLEU: 1.00\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里\n",
      "Reference: the\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在\n",
      "Reference: &quot;\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 7.00, Train Loss: 2.18, Val Loss: 9.22, Train BLEU: 44.31, Val BLEU: 1.00\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数\n",
      "Reference: most\n",
      "Model: <SOS> most\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 所以 在\n",
      "Reference: so\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 8.00, Train Loss: 1.92, Val Loss: 9.37, Train BLEU: 56.69, Val BLEU: 1.00\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本\n",
      "Reference: it\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班\n",
      "Reference: &quot;\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 9.00, Train Loss: 1.74, Val Loss: 9.45, Train BLEU: 50.50, Val BLEU: 7.19\n",
      "Sampling from training predictions...\n",
      "Source: 我们 将\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把\n",
      "Reference: we\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 10.00, Train Loss: 1.63, Val Loss: 9.55, Train BLEU: 44.31, Val BLEU: 1.00\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数\n",
      "Reference: most\n",
      "Model: <SOS> most\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把\n",
      "Reference: we\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 11.00, Train Loss: 1.60, Val Loss: 9.71, Train BLEU: 44.31, Val BLEU: 1.00\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这\n",
      "Reference: we\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 永远\n",
      "Reference: a\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 12.00, Train Loss: 1.59, Val Loss: 9.91, Train BLEU: 44.31, Val BLEU: 1.00\n",
      "Sampling from training predictions...\n",
      "Source: 地球 的\n",
      "Reference: most\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11\n",
      "Reference: when\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 13.00, Train Loss: 1.58, Val Loss: 10.12, Train BLEU: 50.50, Val BLEU: 1.00\n",
      "Sampling from training predictions...\n",
      "Source: 我们 将\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班\n",
      "Reference: &quot;\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 14.00, Train Loss: 1.55, Val Loss: 10.30, Train BLEU: 50.50, Val BLEU: 1.00\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的\n",
      "Reference: my\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 15.00, Train Loss: 1.51, Val Loss: 10.45, Train BLEU: 56.69, Val BLEU: 1.00\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK>\n",
      "Reference: with\n",
      "Model: <SOS> with\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11\n",
      "Reference: when\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 16.00, Train Loss: 1.47, Val Loss: 10.58, Train BLEU: 56.69, Val BLEU: 7.19\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本\n",
      "Reference: it\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6\n",
      "Reference: you\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 17.00, Train Loss: 1.42, Val Loss: 10.71, Train BLEU: 56.69, Val BLEU: 7.19\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这\n",
      "Reference: we\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把\n",
      "Reference: we\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 18.00, Train Loss: 1.38, Val Loss: 10.86, Train BLEU: 56.69, Val BLEU: 7.19\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正\n",
      "Reference: a\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 19.00, Train Loss: 1.34, Val Loss: 11.02, Train BLEU: 56.69, Val BLEU: 1.00\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 面带\n",
      "Reference: there\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 20.00, Train Loss: 1.30, Val Loss: 11.17, Train BLEU: 56.69, Val BLEU: 7.19\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6\n",
      "Reference: you\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 21.00, Train Loss: 1.25, Val Loss: 11.29, Train BLEU: 56.69, Val BLEU: 7.19\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本\n",
      "Reference: it\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 这 是\n",
      "Reference: it\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 22.00, Train Loss: 1.20, Val Loss: 11.41, Train BLEU: 56.69, Val BLEU: 7.19\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK>\n",
      "Reference: with\n",
      "Model: <SOS> with\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班\n",
      "Reference: &quot;\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 23.00, Train Loss: 1.16, Val Loss: 11.51, Train BLEU: 56.69, Val BLEU: 7.19\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 这 是\n",
      "Reference: it\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 24.00, Train Loss: 1.11, Val Loss: 11.55, Train BLEU: 56.69, Val BLEU: 7.19\n",
      "Sampling from training predictions...\n",
      "Source: 我们 将\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天\n",
      "Reference: each\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 25.00, Train Loss: 1.06, Val Loss: 11.59, Train BLEU: 56.69, Val BLEU: 7.19\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想\n",
      "Reference: when\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 26.00, Train Loss: 1.01, Val Loss: 11.62, Train BLEU: 56.69, Val BLEU: 7.19\n",
      "Sampling from training predictions...\n",
      "Source: 我们 将\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 不知\n",
      "Reference: i\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 27.00, Train Loss: 0.96, Val Loss: 11.64, Train BLEU: 56.69, Val BLEU: 7.19\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这\n",
      "Reference: we\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 永远\n",
      "Reference: a\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 28.00, Train Loss: 0.92, Val Loss: 11.64, Train BLEU: 69.06, Val BLEU: 7.19\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分\n",
      "Reference: most\n",
      "Model: <SOS> most\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在\n",
      "Reference: &quot;\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 29.00, Train Loss: 0.87, Val Loss: 11.66, Train BLEU: 69.06, Val BLEU: 7.19\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 所以 在\n",
      "Reference: so\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 30.00, Train Loss: 0.83, Val Loss: 11.69, Train BLEU: 69.06, Val BLEU: 7.19\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中\n",
      "Reference: life\n",
      "Model: <SOS> most\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在\n",
      "Reference: &quot;\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 31.00, Train Loss: 0.78, Val Loss: 11.71, Train BLEU: 75.25, Val BLEU: 7.19\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本\n",
      "Reference: it\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把\n",
      "Reference: we\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 32.00, Train Loss: 0.74, Val Loss: 11.74, Train BLEU: 75.25, Val BLEU: 7.19\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的\n",
      "Reference: my\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 33.00, Train Loss: 0.69, Val Loss: 11.77, Train BLEU: 81.44, Val BLEU: 7.19\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK>\n",
      "Reference: with\n",
      "Model: <SOS> this\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 所以 在\n",
      "Reference: so\n",
      "Model: <SOS> the\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34.00, Train Loss: 0.65, Val Loss: 11.80, Train BLEU: 81.44, Val BLEU: 7.19\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本\n",
      "Reference: it\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很\n",
      "Reference: it\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 35.00, Train Loss: 0.61, Val Loss: 11.83, Train BLEU: 87.63, Val BLEU: 7.19\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数\n",
      "Reference: most\n",
      "Model: <SOS> most\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6\n",
      "Reference: you\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 36.00, Train Loss: 0.57, Val Loss: 11.86, Train BLEU: 87.63, Val BLEU: 7.19\n",
      "Sampling from training predictions...\n",
      "Source: 当 你\n",
      "Reference: part\n",
      "Model: <SOS> part\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班\n",
      "Reference: &quot;\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 37.00, Train Loss: 0.53, Val Loss: 11.87, Train BLEU: 87.63, Val BLEU: 13.38\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想\n",
      "Reference: when\n",
      "Model: <SOS> when\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 面带\n",
      "Reference: there\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 38.00, Train Loss: 0.49, Val Loss: 11.87, Train BLEU: 87.63, Val BLEU: 13.38\n",
      "Sampling from training predictions...\n",
      "Source: 原因 在于\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Epoch: 39.00, Train Loss: 0.45, Val Loss: 11.87, Train BLEU: 87.63, Val BLEU: 13.38\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这\n",
      "Reference: we\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6\n",
      "Reference: you\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 40.00, Train Loss: 0.42, Val Loss: 11.87, Train BLEU: 87.63, Val BLEU: 13.38\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本\n",
      "Reference: it\n",
      "Model: <SOS> it\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Epoch: 41.00, Train Loss: 0.39, Val Loss: 11.89, Train BLEU: 87.63, Val BLEU: 13.38\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班\n",
      "Reference: &quot;\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 42.00, Train Loss: 0.36, Val Loss: 11.92, Train BLEU: 93.81, Val BLEU: 13.38\n",
      "Sampling from training predictions...\n",
      "Source: 原因 在于\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6\n",
      "Reference: you\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 43.00, Train Loss: 0.33, Val Loss: 11.96, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK>\n",
      "Reference: with\n",
      "Model: <SOS> this\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在\n",
      "Reference: &quot;\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 44.00, Train Loss: 0.31, Val Loss: 11.97, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 我们 将\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在\n",
      "Reference: &quot;\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 45.00, Train Loss: 0.29, Val Loss: 11.97, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中\n",
      "Reference: life\n",
      "Model: <SOS> life\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天\n",
      "Reference: each\n",
      "Model: <SOS> it\n",
      "\n",
      "Epoch: 46.00, Train Loss: 0.27, Val Loss: 11.97, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 都\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Epoch: 47.00, Train Loss: 0.25, Val Loss: 11.96, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 地球 的\n",
      "Reference: most\n",
      "Model: <SOS> most\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在\n",
      "Reference: &quot;\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 48.00, Train Loss: 0.23, Val Loss: 11.96, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 当 你\n",
      "Reference: part\n",
      "Model: <SOS> part\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在\n",
      "Reference: &quot;\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 49.00, Train Loss: 0.22, Val Loss: 11.95, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数\n",
      "Reference: most\n",
      "Model: <SOS> most\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很\n",
      "Reference: it\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 50.00, Train Loss: 0.20, Val Loss: 11.95, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 所以 在\n",
      "Reference: so\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 51.00, Train Loss: 0.19, Val Loss: 11.94, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中\n",
      "Reference: life\n",
      "Model: <SOS> life\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正\n",
      "Reference: a\n",
      "Model: <SOS> it\n",
      "\n",
      "Epoch: 52.00, Train Loss: 0.18, Val Loss: 11.93, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数\n",
      "Reference: most\n",
      "Model: <SOS> most\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 53.00, Train Loss: 0.17, Val Loss: 11.93, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK>\n",
      "Reference: with\n",
      "Model: <SOS> this\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6\n",
      "Reference: you\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 54.00, Train Loss: 0.16, Val Loss: 11.92, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很\n",
      "Reference: it\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 55.00, Train Loss: 0.16, Val Loss: 11.92, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天\n",
      "Reference: each\n",
      "Model: <SOS> it\n",
      "\n",
      "Epoch: 56.00, Train Loss: 0.15, Val Loss: 11.93, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 当 你\n",
      "Reference: part\n",
      "Model: <SOS> part\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6\n",
      "Reference: you\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 57.00, Train Loss: 0.14, Val Loss: 11.94, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Epoch: 58.00, Train Loss: 0.14, Val Loss: 11.96, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的\n",
      "Reference: my\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 59.00, Train Loss: 0.13, Val Loss: 11.98, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 原因 在于\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11\n",
      "Reference: when\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 60.00, Train Loss: 0.13, Val Loss: 12.00, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天\n",
      "Reference: each\n",
      "Model: <SOS> it\n",
      "\n",
      "Epoch: 61.00, Train Loss: 0.13, Val Loss: 12.00, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很\n",
      "Reference: it\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 62.00, Train Loss: 0.12, Val Loss: 12.00, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数\n",
      "Reference: most\n",
      "Model: <SOS> most\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正\n",
      "Reference: a\n",
      "Model: <SOS> it\n",
      "\n",
      "Epoch: 63.00, Train Loss: 0.12, Val Loss: 12.00, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 我们 将\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 所以 在\n",
      "Reference: so\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 64.00, Train Loss: 0.12, Val Loss: 12.00, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK>\n",
      "Reference: this\n",
      "Model: <SOS> with\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班\n",
      "Reference: &quot;\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 65.00, Train Loss: 0.12, Val Loss: 12.00, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6\n",
      "Reference: you\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 66.00, Train Loss: 0.11, Val Loss: 12.00, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6\n",
      "Reference: you\n",
      "Model: <SOS> most\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67.00, Train Loss: 0.11, Val Loss: 12.00, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Epoch: 68.00, Train Loss: 0.11, Val Loss: 12.00, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 不知\n",
      "Reference: i\n",
      "Model: <SOS> when\n",
      "\n",
      "Epoch: 69.00, Train Loss: 0.11, Val Loss: 12.00, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 这 是\n",
      "Reference: it\n",
      "Model: <SOS> part\n",
      "\n",
      "Epoch: 70.00, Train Loss: 0.11, Val Loss: 12.00, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 当 你\n",
      "Reference: part\n",
      "Model: <SOS> part\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11\n",
      "Reference: when\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 71.00, Train Loss: 0.11, Val Loss: 12.00, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 面带\n",
      "Reference: there\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 72.00, Train Loss: 0.11, Val Loss: 12.00, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很\n",
      "Reference: it\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 73.00, Train Loss: 0.10, Val Loss: 12.00, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本\n",
      "Reference: it\n",
      "Model: <SOS> it\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在\n",
      "Reference: &quot;\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 74.00, Train Loss: 0.10, Val Loss: 12.00, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 原因 在于\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在\n",
      "Reference: &quot;\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 75.00, Train Loss: 0.10, Val Loss: 12.00, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK>\n",
      "Reference: this\n",
      "Model: <SOS> this\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 所以 在\n",
      "Reference: so\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 76.00, Train Loss: 0.10, Val Loss: 12.01, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 原因 在于\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 77.00, Train Loss: 0.10, Val Loss: 12.01, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分\n",
      "Reference: most\n",
      "Model: <SOS> most\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 都\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Epoch: 78.00, Train Loss: 0.10, Val Loss: 12.02, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想\n",
      "Reference: when\n",
      "Model: <SOS> when\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在\n",
      "Reference: &quot;\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 79.00, Train Loss: 0.10, Val Loss: 12.02, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分\n",
      "Reference: most\n",
      "Model: <SOS> most\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 所以 在\n",
      "Reference: so\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 80.00, Train Loss: 0.10, Val Loss: 12.03, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 当 你\n",
      "Reference: part\n",
      "Model: <SOS> part\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正\n",
      "Reference: a\n",
      "Model: <SOS> it\n",
      "\n",
      "Epoch: 81.00, Train Loss: 0.10, Val Loss: 12.03, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数\n",
      "Reference: most\n",
      "Model: <SOS> most\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 面带\n",
      "Reference: there\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 82.00, Train Loss: 0.10, Val Loss: 12.04, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本\n",
      "Reference: it\n",
      "Model: <SOS> it\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天\n",
      "Reference: each\n",
      "Model: <SOS> it\n",
      "\n",
      "Epoch: 83.00, Train Loss: 0.10, Val Loss: 12.05, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本\n",
      "Reference: it\n",
      "Model: <SOS> it\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 都\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Epoch: 84.00, Train Loss: 0.10, Val Loss: 12.05, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数\n",
      "Reference: most\n",
      "Model: <SOS> most\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 85.00, Train Loss: 0.10, Val Loss: 12.05, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本\n",
      "Reference: it\n",
      "Model: <SOS> it\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 86.00, Train Loss: 0.10, Val Loss: 12.06, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 87.00, Train Loss: 0.10, Val Loss: 12.07, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 原因 在于\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在\n",
      "Reference: &quot;\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 88.00, Train Loss: 0.10, Val Loss: 12.07, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 地球 的\n",
      "Reference: most\n",
      "Model: <SOS> most\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天\n",
      "Reference: each\n",
      "Model: <SOS> it\n",
      "\n",
      "Epoch: 89.00, Train Loss: 0.10, Val Loss: 12.08, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本\n",
      "Reference: it\n",
      "Model: <SOS> it\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班\n",
      "Reference: &quot;\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 90.00, Train Loss: 0.10, Val Loss: 12.10, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班\n",
      "Reference: &quot;\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 91.00, Train Loss: 0.10, Val Loss: 12.11, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 92.00, Train Loss: 0.10, Val Loss: 12.12, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很\n",
      "Reference: it\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 93.00, Train Loss: 0.10, Val Loss: 12.13, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 这 是\n",
      "Reference: it\n",
      "Model: <SOS> part\n",
      "\n",
      "Epoch: 94.00, Train Loss: 0.10, Val Loss: 12.13, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 这 是\n",
      "Reference: it\n",
      "Model: <SOS> part\n",
      "\n",
      "Epoch: 95.00, Train Loss: 0.10, Val Loss: 12.14, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK>\n",
      "Reference: this\n",
      "Model: <SOS> this\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Epoch: 96.00, Train Loss: 0.10, Val Loss: 12.15, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 当 你\n",
      "Reference: part\n",
      "Model: <SOS> part\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 面带\n",
      "Reference: there\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 97.00, Train Loss: 0.09, Val Loss: 12.15, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK>\n",
      "Reference: with\n",
      "Model: <SOS> with\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 都\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Epoch: 98.00, Train Loss: 0.09, Val Loss: 12.16, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中\n",
      "Reference: life\n",
      "Model: <SOS> life\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6\n",
      "Reference: you\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 99.00, Train Loss: 0.09, Val Loss: 12.16, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK>\n",
      "Reference: with\n",
      "Model: <SOS> with\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 面带\n",
      "Reference: there\n",
      "Model: <SOS> most\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100.00, Train Loss: 0.09, Val Loss: 12.17, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分\n",
      "Reference: most\n",
      "Model: <SOS> most\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正\n",
      "Reference: a\n",
      "Model: <SOS> it\n",
      "\n",
      "Epoch: 101.00, Train Loss: 0.09, Val Loss: 12.17, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班\n",
      "Reference: &quot;\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 102.00, Train Loss: 0.09, Val Loss: 12.18, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正\n",
      "Reference: a\n",
      "Model: <SOS> it\n",
      "\n",
      "Epoch: 103.00, Train Loss: 0.09, Val Loss: 12.18, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天\n",
      "Reference: each\n",
      "Model: <SOS> it\n",
      "\n",
      "Epoch: 104.00, Train Loss: 0.09, Val Loss: 12.18, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 地球 的\n",
      "Reference: most\n",
      "Model: <SOS> most\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 这 是\n",
      "Reference: it\n",
      "Model: <SOS> part\n",
      "\n",
      "Epoch: 105.00, Train Loss: 0.09, Val Loss: 12.19, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 地球 的\n",
      "Reference: most\n",
      "Model: <SOS> most\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班\n",
      "Reference: &quot;\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 106.00, Train Loss: 0.09, Val Loss: 12.19, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 原因 在于\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 永远\n",
      "Reference: a\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 107.00, Train Loss: 0.09, Val Loss: 12.19, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正\n",
      "Reference: a\n",
      "Model: <SOS> it\n",
      "\n",
      "Epoch: 108.00, Train Loss: 0.09, Val Loss: 12.19, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK>\n",
      "Reference: with\n",
      "Model: <SOS> this\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 所以 在\n",
      "Reference: so\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 109.00, Train Loss: 0.09, Val Loss: 12.20, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中\n",
      "Reference: life\n",
      "Model: <SOS> life\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 永远\n",
      "Reference: a\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 110.00, Train Loss: 0.09, Val Loss: 12.20, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想\n",
      "Reference: when\n",
      "Model: <SOS> when\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 面带\n",
      "Reference: there\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 111.00, Train Loss: 0.09, Val Loss: 12.20, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中\n",
      "Reference: life\n",
      "Model: <SOS> life\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的\n",
      "Reference: my\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 112.00, Train Loss: 0.09, Val Loss: 12.20, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 地球 的\n",
      "Reference: most\n",
      "Model: <SOS> most\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的\n",
      "Reference: my\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 113.00, Train Loss: 0.09, Val Loss: 12.20, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 原因 在于\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11\n",
      "Reference: when\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 114.00, Train Loss: 0.09, Val Loss: 12.20, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本\n",
      "Reference: it\n",
      "Model: <SOS> it\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 这 是\n",
      "Reference: it\n",
      "Model: <SOS> part\n",
      "\n",
      "Epoch: 115.00, Train Loss: 0.09, Val Loss: 12.20, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数\n",
      "Reference: most\n",
      "Model: <SOS> most\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班\n",
      "Reference: &quot;\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 116.00, Train Loss: 0.09, Val Loss: 12.20, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正\n",
      "Reference: a\n",
      "Model: <SOS> it\n",
      "\n",
      "Epoch: 117.00, Train Loss: 0.09, Val Loss: 12.20, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK>\n",
      "Reference: this\n",
      "Model: <SOS> with\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班\n",
      "Reference: &quot;\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 118.00, Train Loss: 0.09, Val Loss: 12.21, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK>\n",
      "Reference: this\n",
      "Model: <SOS> this\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 所以 在\n",
      "Reference: so\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 119.00, Train Loss: 0.09, Val Loss: 12.21, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 都\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Epoch: 120.00, Train Loss: 0.09, Val Loss: 12.21, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 面带\n",
      "Reference: there\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 121.00, Train Loss: 0.09, Val Loss: 12.21, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分\n",
      "Reference: most\n",
      "Model: <SOS> most\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班\n",
      "Reference: &quot;\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 122.00, Train Loss: 0.09, Val Loss: 12.21, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 地球 的\n",
      "Reference: most\n",
      "Model: <SOS> most\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的\n",
      "Reference: my\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 123.00, Train Loss: 0.09, Val Loss: 12.21, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班\n",
      "Reference: &quot;\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 124.00, Train Loss: 0.09, Val Loss: 12.22, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正\n",
      "Reference: a\n",
      "Model: <SOS> it\n",
      "\n",
      "Epoch: 125.00, Train Loss: 0.09, Val Loss: 12.22, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 永远\n",
      "Reference: a\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 126.00, Train Loss: 0.09, Val Loss: 12.22, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 原因 在于\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 都\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Epoch: 127.00, Train Loss: 0.09, Val Loss: 12.22, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 原因 在于\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 128.00, Train Loss: 0.09, Val Loss: 12.22, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中\n",
      "Reference: life\n",
      "Model: <SOS> life\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 都\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Epoch: 129.00, Train Loss: 0.09, Val Loss: 12.23, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK>\n",
      "Reference: with\n",
      "Model: <SOS> this\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11\n",
      "Reference: when\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 130.00, Train Loss: 0.09, Val Loss: 12.23, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本\n",
      "Reference: it\n",
      "Model: <SOS> it\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 所以 在\n",
      "Reference: so\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 131.00, Train Loss: 0.09, Val Loss: 12.23, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 我们 将\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 面带\n",
      "Reference: there\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 132.00, Train Loss: 0.09, Val Loss: 12.24, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中\n",
      "Reference: life\n",
      "Model: <SOS> life\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班\n",
      "Reference: &quot;\n",
      "Model: <SOS> most\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 133.00, Train Loss: 0.09, Val Loss: 12.24, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 当 你\n",
      "Reference: part\n",
      "Model: <SOS> part\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天\n",
      "Reference: each\n",
      "Model: <SOS> it\n",
      "\n",
      "Epoch: 134.00, Train Loss: 0.09, Val Loss: 12.24, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK>\n",
      "Reference: this\n",
      "Model: <SOS> with\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很\n",
      "Reference: it\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 135.00, Train Loss: 0.09, Val Loss: 12.24, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分\n",
      "Reference: most\n",
      "Model: <SOS> most\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 都\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Epoch: 136.00, Train Loss: 0.09, Val Loss: 12.25, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 不知\n",
      "Reference: i\n",
      "Model: <SOS> when\n",
      "\n",
      "Epoch: 137.00, Train Loss: 0.09, Val Loss: 12.25, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 所以 在\n",
      "Reference: so\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 138.00, Train Loss: 0.09, Val Loss: 12.25, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK>\n",
      "Reference: with\n",
      "Model: <SOS> with\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正\n",
      "Reference: a\n",
      "Model: <SOS> it\n",
      "\n",
      "Epoch: 139.00, Train Loss: 0.09, Val Loss: 12.25, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中\n",
      "Reference: life\n",
      "Model: <SOS> life\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 所以 在\n",
      "Reference: so\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 140.00, Train Loss: 0.09, Val Loss: 12.25, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 地球 的\n",
      "Reference: most\n",
      "Model: <SOS> most\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Epoch: 141.00, Train Loss: 0.09, Val Loss: 12.26, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想\n",
      "Reference: when\n",
      "Model: <SOS> when\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 都\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Epoch: 142.00, Train Loss: 0.09, Val Loss: 12.26, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想\n",
      "Reference: when\n",
      "Model: <SOS> when\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班\n",
      "Reference: &quot;\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 143.00, Train Loss: 0.09, Val Loss: 12.26, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 原因 在于\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天\n",
      "Reference: each\n",
      "Model: <SOS> it\n",
      "\n",
      "Epoch: 144.00, Train Loss: 0.09, Val Loss: 12.26, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Epoch: 145.00, Train Loss: 0.09, Val Loss: 12.26, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想\n",
      "Reference: when\n",
      "Model: <SOS> when\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班\n",
      "Reference: &quot;\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 146.00, Train Loss: 0.09, Val Loss: 12.27, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本\n",
      "Reference: it\n",
      "Model: <SOS> it\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6\n",
      "Reference: you\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 147.00, Train Loss: 0.09, Val Loss: 12.27, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 当 你\n",
      "Reference: part\n",
      "Model: <SOS> part\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在\n",
      "Reference: &quot;\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 148.00, Train Loss: 0.09, Val Loss: 12.27, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK>\n",
      "Reference: with\n",
      "Model: <SOS> with\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 这 是\n",
      "Reference: it\n",
      "Model: <SOS> part\n",
      "\n",
      "Epoch: 149.00, Train Loss: 0.09, Val Loss: 12.27, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 原因 在于\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 永远\n",
      "Reference: a\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 150.00, Train Loss: 0.09, Val Loss: 12.27, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想\n",
      "Reference: when\n",
      "Model: <SOS> when\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天\n",
      "Reference: each\n",
      "Model: <SOS> it\n",
      "\n",
      "Epoch: 151.00, Train Loss: 0.09, Val Loss: 12.28, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 原因 在于\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在\n",
      "Reference: &quot;\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 152.00, Train Loss: 0.09, Val Loss: 12.28, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想\n",
      "Reference: when\n",
      "Model: <SOS> when\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班\n",
      "Reference: &quot;\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 153.00, Train Loss: 0.09, Val Loss: 12.28, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK>\n",
      "Reference: this\n",
      "Model: <SOS> with\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很\n",
      "Reference: it\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 154.00, Train Loss: 0.09, Val Loss: 12.28, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 原因 在于\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Epoch: 155.00, Train Loss: 0.09, Val Loss: 12.29, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 面带\n",
      "Reference: there\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 156.00, Train Loss: 0.09, Val Loss: 12.29, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 当 你\n",
      "Reference: part\n",
      "Model: <SOS> part\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11\n",
      "Reference: when\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 157.00, Train Loss: 0.09, Val Loss: 12.29, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本\n",
      "Reference: it\n",
      "Model: <SOS> it\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Epoch: 158.00, Train Loss: 0.09, Val Loss: 12.29, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分\n",
      "Reference: most\n",
      "Model: <SOS> most\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 159.00, Train Loss: 0.09, Val Loss: 12.30, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 地球 的\n",
      "Reference: most\n",
      "Model: <SOS> most\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11\n",
      "Reference: when\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 160.00, Train Loss: 0.09, Val Loss: 12.30, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6\n",
      "Reference: you\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 161.00, Train Loss: 0.09, Val Loss: 12.30, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6\n",
      "Reference: you\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 162.00, Train Loss: 0.09, Val Loss: 12.30, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分\n",
      "Reference: most\n",
      "Model: <SOS> most\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正\n",
      "Reference: a\n",
      "Model: <SOS> it\n",
      "\n",
      "Epoch: 163.00, Train Loss: 0.09, Val Loss: 12.31, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本\n",
      "Reference: it\n",
      "Model: <SOS> it\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天\n",
      "Reference: each\n",
      "Model: <SOS> it\n",
      "\n",
      "Epoch: 164.00, Train Loss: 0.09, Val Loss: 12.31, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6\n",
      "Reference: you\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 165.00, Train Loss: 0.09, Val Loss: 12.31, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 我们 将\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 永远\n",
      "Reference: a\n",
      "Model: <SOS> and\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 166.00, Train Loss: 0.09, Val Loss: 12.31, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天\n",
      "Reference: each\n",
      "Model: <SOS> it\n",
      "\n",
      "Epoch: 167.00, Train Loss: 0.09, Val Loss: 12.32, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本\n",
      "Reference: it\n",
      "Model: <SOS> it\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Epoch: 168.00, Train Loss: 0.09, Val Loss: 12.32, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 这 是\n",
      "Reference: it\n",
      "Model: <SOS> part\n",
      "\n",
      "Epoch: 169.00, Train Loss: 0.09, Val Loss: 12.32, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 原因 在于\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 永远\n",
      "Reference: a\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 170.00, Train Loss: 0.09, Val Loss: 12.32, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK>\n",
      "Reference: this\n",
      "Model: <SOS> this\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正\n",
      "Reference: a\n",
      "Model: <SOS> it\n",
      "\n",
      "Epoch: 171.00, Train Loss: 0.09, Val Loss: 12.32, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 这 是\n",
      "Reference: it\n",
      "Model: <SOS> part\n",
      "\n",
      "Epoch: 172.00, Train Loss: 0.09, Val Loss: 12.33, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK>\n",
      "Reference: this\n",
      "Model: <SOS> this\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 这 是\n",
      "Reference: it\n",
      "Model: <SOS> part\n",
      "\n",
      "Epoch: 173.00, Train Loss: 0.09, Val Loss: 12.33, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分\n",
      "Reference: most\n",
      "Model: <SOS> most\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 这 是\n",
      "Reference: it\n",
      "Model: <SOS> part\n",
      "\n",
      "Epoch: 174.00, Train Loss: 0.09, Val Loss: 12.33, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中\n",
      "Reference: life\n",
      "Model: <SOS> life\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很\n",
      "Reference: it\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 175.00, Train Loss: 0.09, Val Loss: 12.33, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想\n",
      "Reference: when\n",
      "Model: <SOS> when\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的\n",
      "Reference: my\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 176.00, Train Loss: 0.09, Val Loss: 12.33, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很\n",
      "Reference: it\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 177.00, Train Loss: 0.09, Val Loss: 12.33, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK>\n",
      "Reference: this\n",
      "Model: <SOS> this\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的\n",
      "Reference: my\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 178.00, Train Loss: 0.09, Val Loss: 12.33, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中\n",
      "Reference: life\n",
      "Model: <SOS> life\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 所以 在\n",
      "Reference: so\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 179.00, Train Loss: 0.09, Val Loss: 12.33, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在\n",
      "Reference: &quot;\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 180.00, Train Loss: 0.09, Val Loss: 12.33, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK>\n",
      "Reference: with\n",
      "Model: <SOS> with\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在\n",
      "Reference: &quot;\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 181.00, Train Loss: 0.09, Val Loss: 12.33, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数\n",
      "Reference: most\n",
      "Model: <SOS> most\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在\n",
      "Reference: &quot;\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 182.00, Train Loss: 0.09, Val Loss: 12.33, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的\n",
      "Reference: my\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 183.00, Train Loss: 0.09, Val Loss: 12.33, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 地球 的\n",
      "Reference: most\n",
      "Model: <SOS> most\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 永远\n",
      "Reference: a\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 184.00, Train Loss: 0.09, Val Loss: 12.33, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 当 你\n",
      "Reference: part\n",
      "Model: <SOS> part\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 永远\n",
      "Reference: a\n",
      "Model: <SOS> and\n",
      "\n",
      "Epoch: 185.00, Train Loss: 0.09, Val Loss: 12.33, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 186.00, Train Loss: 0.09, Val Loss: 12.33, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11\n",
      "Reference: when\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 187.00, Train Loss: 0.09, Val Loss: 12.33, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 不知\n",
      "Reference: i\n",
      "Model: <SOS> when\n",
      "\n",
      "Epoch: 188.00, Train Loss: 0.09, Val Loss: 12.34, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 所以 在\n",
      "Reference: so\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 189.00, Train Loss: 0.09, Val Loss: 12.34, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中\n",
      "Reference: life\n",
      "Model: <SOS> life\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的\n",
      "Reference: my\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 190.00, Train Loss: 0.09, Val Loss: 12.34, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天\n",
      "Reference: each\n",
      "Model: <SOS> it\n",
      "\n",
      "Epoch: 191.00, Train Loss: 0.09, Val Loss: 12.35, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 当 你\n",
      "Reference: part\n",
      "Model: <SOS> part\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Epoch: 192.00, Train Loss: 0.09, Val Loss: 12.35, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本\n",
      "Reference: it\n",
      "Model: <SOS> it\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 这 是\n",
      "Reference: it\n",
      "Model: <SOS> part\n",
      "\n",
      "Epoch: 193.00, Train Loss: 0.09, Val Loss: 12.35, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本\n",
      "Reference: it\n",
      "Model: <SOS> it\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 都\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Epoch: 194.00, Train Loss: 0.09, Val Loss: 12.35, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 面带\n",
      "Reference: there\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 195.00, Train Loss: 0.09, Val Loss: 12.36, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK>\n",
      "Reference: this\n",
      "Model: <SOS> with\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 这 是\n",
      "Reference: it\n",
      "Model: <SOS> part\n",
      "\n",
      "Epoch: 196.00, Train Loss: 0.09, Val Loss: 12.36, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分\n",
      "Reference: most\n",
      "Model: <SOS> most\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Epoch: 197.00, Train Loss: 0.09, Val Loss: 12.36, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 我们 将\n",
      "Reference: and\n",
      "Model: <SOS> and\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的\n",
      "Reference: my\n",
      "Model: <SOS> most\n",
      "\n",
      "Epoch: 198.00, Train Loss: 0.09, Val Loss: 12.36, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK>\n",
      "Reference: with\n",
      "Model: <SOS> this\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 这 是\n",
      "Reference: it\n",
      "Model: <SOS> part\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 199.00, Train Loss: 0.09, Val Loss: 12.36, Train BLEU: 93.81, Val BLEU: 19.56\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这\n",
      "Reference: we\n",
      "Model: <SOS> we\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在\n",
      "Reference: the\n",
      "Model: <SOS> the\n",
      "\n",
      "Experiment completed in 1 minutes with 8.61 best validation loss and 19.56 best validation BLEU.\n"
     ]
    }
   ],
   "source": [
    "model, results = train_and_eval_V2(\n",
    "    model=model, full_loaders=full_loaders, fast_loaders=fast_loaders, params=params, vocab=vocab, \n",
    "    print_intermediate=True, save_checkpoint=True, lazy_eval=False, inspect_iter=100, save_to_log=True, print_summary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt_created</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>hyperparams</th>\n",
       "      <th>results</th>\n",
       "      <th>runtime</th>\n",
       "      <th>model_type</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>enc_hidden_dim</th>\n",
       "      <th>dec_hidden_dim</th>\n",
       "      <th>...</th>\n",
       "      <th>targ_lang</th>\n",
       "      <th>src_vocab_size</th>\n",
       "      <th>targ_vocab_size</th>\n",
       "      <th>src_max_sentence_len</th>\n",
       "      <th>targ_max_sentence_len</th>\n",
       "      <th>model_name</th>\n",
       "      <th>teacher_forcing_ratio</th>\n",
       "      <th>lazy_train</th>\n",
       "      <th>clip_grad_max_norm</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-12-01 22:55:23</td>\n",
       "      <td>test_model</td>\n",
       "      <td>{'model_name': 'test_model', 'src_lang': 'zh',...</td>\n",
       "      <td>[{'epoch': 0.0, 'val_loss': 9.943002700805664,...</td>\n",
       "      <td>1.639537</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>test_model</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.607852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-12-01 22:48:41</td>\n",
       "      <td>test_model</td>\n",
       "      <td>{'model_name': 'test_model', 'src_lang': 'zh',...</td>\n",
       "      <td>[{'epoch': 0.0, 'val_loss': 10.132436752319336...</td>\n",
       "      <td>2.042285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>test_model</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.221855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-12-01 22:21:40</td>\n",
       "      <td>test_model</td>\n",
       "      <td>{'model_name': 'test_model', 'src_lang': 'zh',...</td>\n",
       "      <td>[{'epoch': 0.0, 'val_loss': 10.104202270507812...</td>\n",
       "      <td>1.560579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>test_model</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.778268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-12-01 21:52:06</td>\n",
       "      <td>test_model</td>\n",
       "      <td>{'model_name': 'test_model', 'src_lang': 'zh',...</td>\n",
       "      <td>[{'epoch': 0.0, 'val_loss': 10.228408813476562...</td>\n",
       "      <td>7.566348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>test_model</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.359420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-12-01 15:20:22</td>\n",
       "      <td>test_model</td>\n",
       "      <td>{'model_name': 'test_model', 'src_lang': 'vi',...</td>\n",
       "      <td>[{'epoch': 0.0, 'val_loss': 10.160977363586426...</td>\n",
       "      <td>8.699158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>test_model</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.283567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-12-01 02:57:58</td>\n",
       "      <td>test_model</td>\n",
       "      <td>{'model_name': 'test_model', 'src_lang': 'vi',...</td>\n",
       "      <td>[{'epoch': 0.0, 'val_loss': 10.246160507202148...</td>\n",
       "      <td>0.264690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>test_model</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.577247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-12-01 02:38:47</td>\n",
       "      <td>test_model</td>\n",
       "      <td>{'model_name': 'test_model', 'src_lang': 'vi',...</td>\n",
       "      <td>[{'epoch': 0.0, 'val_loss': 10.238265037536621...</td>\n",
       "      <td>0.309454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>test_model</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.337175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-12-01 02:29:11</td>\n",
       "      <td>test_model</td>\n",
       "      <td>{'model_name': 'test_model', 'num_epochs': 5, ...</td>\n",
       "      <td>[{'epoch': 0.0, 'val_loss': 10.221494674682617...</td>\n",
       "      <td>0.312100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>test_model</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.228798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-12-01 02:22:55</td>\n",
       "      <td>test_model</td>\n",
       "      <td>{'model_name': 'test_model', 'num_epochs': 5, ...</td>\n",
       "      <td>[{'epoch': 0.0, 'val_loss': 10.231721878051758...</td>\n",
       "      <td>0.381173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>test_model</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.330558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-11-28 17:55:24</td>\n",
       "      <td>test_run</td>\n",
       "      <td>{'model_type': 'attention_bahdanau', 'num_epoc...</td>\n",
       "      <td>[{'epoch': 0.0, 'val_loss': 10.21630573272705,...</td>\n",
       "      <td>6.029234</td>\n",
       "      <td>attention_bahdanau</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.507013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-11-28 13:52:27</td>\n",
       "      <td>test_run</td>\n",
       "      <td>{'model_type': 'attention_bahdanau', 'num_epoc...</td>\n",
       "      <td>[{'epoch': 0.0, 'val_loss': 10.062241554260254...</td>\n",
       "      <td>673.474022</td>\n",
       "      <td>attention_bahdanau</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.088548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-11-28 00:43:37</td>\n",
       "      <td>test_run</td>\n",
       "      <td>{'model_type': 'attention_bahdanau', 'num_epoc...</td>\n",
       "      <td>[{'epoch': 0.0, 'val_loss': 10.040691375732422...</td>\n",
       "      <td>31.569452</td>\n",
       "      <td>attention_bahdanau</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.985807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-11-27 05:10:18</td>\n",
       "      <td>test_run</td>\n",
       "      <td>{'model_type': 'attention_bahdanau', 'num_epoc...</td>\n",
       "      <td>[{'epoch': 0.0, 'val_loss': 8.919134140014648,...</td>\n",
       "      <td>155.873592</td>\n",
       "      <td>attention_bahdanau</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.484231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-27 02:30:44</td>\n",
       "      <td>test_run</td>\n",
       "      <td>{'model_type': 'without_attention', 'num_epoch...</td>\n",
       "      <td>[{'epoch': 0.0, 'val_loss': 8.855473518371582,...</td>\n",
       "      <td>1.179587</td>\n",
       "      <td>without_attention</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.390460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-27 02:28:19</td>\n",
       "      <td>test_run</td>\n",
       "      <td>{'model_type': 'without_attention', 'num_epoch...</td>\n",
       "      <td>[{'epoch': 0.0, 'val_loss': 8.887566566467285,...</td>\n",
       "      <td>1.302775</td>\n",
       "      <td>without_attention</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.335167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-27 00:43:43</td>\n",
       "      <td>test_run</td>\n",
       "      <td>{'model_type': 'attention_bahdanau', 'num_epoc...</td>\n",
       "      <td>[{'epoch': 0.0, 'val_loss': 8.989323210716247,...</td>\n",
       "      <td>52.872075</td>\n",
       "      <td>attention_bahdanau</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.436468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-26 23:17:44</td>\n",
       "      <td>test_run</td>\n",
       "      <td>{'model_type': 'attention_bahdanau', 'num_epoc...</td>\n",
       "      <td>[{'epoch': 0.0, 'val_loss': 8.783560848236084,...</td>\n",
       "      <td>53.518373</td>\n",
       "      <td>attention_bahdanau</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.433290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             dt_created experiment_name  \\\n",
       "16  2018-12-01 22:55:23      test_model   \n",
       "15  2018-12-01 22:48:41      test_model   \n",
       "14  2018-12-01 22:21:40      test_model   \n",
       "13  2018-12-01 21:52:06      test_model   \n",
       "12  2018-12-01 15:20:22      test_model   \n",
       "11  2018-12-01 02:57:58      test_model   \n",
       "10  2018-12-01 02:38:47      test_model   \n",
       "9   2018-12-01 02:29:11      test_model   \n",
       "8   2018-12-01 02:22:55      test_model   \n",
       "7   2018-11-28 17:55:24        test_run   \n",
       "6   2018-11-28 13:52:27        test_run   \n",
       "5   2018-11-28 00:43:37        test_run   \n",
       "4   2018-11-27 05:10:18        test_run   \n",
       "3   2018-11-27 02:30:44        test_run   \n",
       "2   2018-11-27 02:28:19        test_run   \n",
       "1   2018-11-27 00:43:43        test_run   \n",
       "0   2018-11-26 23:17:44        test_run   \n",
       "\n",
       "                                          hyperparams  \\\n",
       "16  {'model_name': 'test_model', 'src_lang': 'zh',...   \n",
       "15  {'model_name': 'test_model', 'src_lang': 'zh',...   \n",
       "14  {'model_name': 'test_model', 'src_lang': 'zh',...   \n",
       "13  {'model_name': 'test_model', 'src_lang': 'zh',...   \n",
       "12  {'model_name': 'test_model', 'src_lang': 'vi',...   \n",
       "11  {'model_name': 'test_model', 'src_lang': 'vi',...   \n",
       "10  {'model_name': 'test_model', 'src_lang': 'vi',...   \n",
       "9   {'model_name': 'test_model', 'num_epochs': 5, ...   \n",
       "8   {'model_name': 'test_model', 'num_epochs': 5, ...   \n",
       "7   {'model_type': 'attention_bahdanau', 'num_epoc...   \n",
       "6   {'model_type': 'attention_bahdanau', 'num_epoc...   \n",
       "5   {'model_type': 'attention_bahdanau', 'num_epoc...   \n",
       "4   {'model_type': 'attention_bahdanau', 'num_epoc...   \n",
       "3   {'model_type': 'without_attention', 'num_epoch...   \n",
       "2   {'model_type': 'without_attention', 'num_epoch...   \n",
       "1   {'model_type': 'attention_bahdanau', 'num_epoc...   \n",
       "0   {'model_type': 'attention_bahdanau', 'num_epoc...   \n",
       "\n",
       "                                              results     runtime  \\\n",
       "16  [{'epoch': 0.0, 'val_loss': 9.943002700805664,...    1.639537   \n",
       "15  [{'epoch': 0.0, 'val_loss': 10.132436752319336...    2.042285   \n",
       "14  [{'epoch': 0.0, 'val_loss': 10.104202270507812...    1.560579   \n",
       "13  [{'epoch': 0.0, 'val_loss': 10.228408813476562...    7.566348   \n",
       "12  [{'epoch': 0.0, 'val_loss': 10.160977363586426...    8.699158   \n",
       "11  [{'epoch': 0.0, 'val_loss': 10.246160507202148...    0.264690   \n",
       "10  [{'epoch': 0.0, 'val_loss': 10.238265037536621...    0.309454   \n",
       "9   [{'epoch': 0.0, 'val_loss': 10.221494674682617...    0.312100   \n",
       "8   [{'epoch': 0.0, 'val_loss': 10.231721878051758...    0.381173   \n",
       "7   [{'epoch': 0.0, 'val_loss': 10.21630573272705,...    6.029234   \n",
       "6   [{'epoch': 0.0, 'val_loss': 10.062241554260254...  673.474022   \n",
       "5   [{'epoch': 0.0, 'val_loss': 10.040691375732422...   31.569452   \n",
       "4   [{'epoch': 0.0, 'val_loss': 8.919134140014648,...  155.873592   \n",
       "3   [{'epoch': 0.0, 'val_loss': 8.855473518371582,...    1.179587   \n",
       "2   [{'epoch': 0.0, 'val_loss': 8.887566566467285,...    1.302775   \n",
       "1   [{'epoch': 0.0, 'val_loss': 8.989323210716247,...   52.872075   \n",
       "0   [{'epoch': 0.0, 'val_loss': 8.783560848236084,...   53.518373   \n",
       "\n",
       "            model_type  num_epochs  learning_rate  enc_hidden_dim  \\\n",
       "16                 NaN         200         0.0010             300   \n",
       "15                 NaN         200         0.0010             300   \n",
       "14                 NaN         200         0.0010             300   \n",
       "13                 NaN         200         0.0010             300   \n",
       "12                 NaN         200         0.0010             300   \n",
       "11                 NaN           5         0.0005             300   \n",
       "10                 NaN           5         0.0005             300   \n",
       "9                  NaN           5         0.0005             300   \n",
       "8                  NaN           5         0.0005             300   \n",
       "7   attention_bahdanau         100         0.0005             300   \n",
       "6   attention_bahdanau        2000         0.0005             300   \n",
       "5   attention_bahdanau         100         0.0005             300   \n",
       "4   attention_bahdanau        1000         0.0005             300   \n",
       "3    without_attention          10         0.0005             300   \n",
       "2    without_attention          10         0.0005             300   \n",
       "1   attention_bahdanau          10         0.0005             300   \n",
       "0   attention_bahdanau          10         0.0005             300   \n",
       "\n",
       "    dec_hidden_dim    ...     targ_lang src_vocab_size  targ_vocab_size  \\\n",
       "16             600    ...            en          30000            30000   \n",
       "15             600    ...            en          30000            30000   \n",
       "14             600    ...            en          30000            30000   \n",
       "13             600    ...            en          30000            30000   \n",
       "12             600    ...            en          30000            30000   \n",
       "11             600    ...            en          30000            30000   \n",
       "10             600    ...            en          30000            30000   \n",
       "9              600    ...            en          30000            30000   \n",
       "8              600    ...            en          30000            30000   \n",
       "7              600    ...            en          30000            30000   \n",
       "6              600    ...            en          30000            30000   \n",
       "5              600    ...            en          30000            30000   \n",
       "4              600    ...            en          10000            10000   \n",
       "3              600    ...            en          10000            10000   \n",
       "2              600    ...            en          10000            10000   \n",
       "1              600    ...            en          10000            10000   \n",
       "0              600    ...            en          10000            10000   \n",
       "\n",
       "    src_max_sentence_len  targ_max_sentence_len  model_name  \\\n",
       "16                     2                      2  test_model   \n",
       "15                     3                      3  test_model   \n",
       "14                     2                      2  test_model   \n",
       "13                    10                     10  test_model   \n",
       "12                    10                     10  test_model   \n",
       "11                    10                     10  test_model   \n",
       "10                    10                     10  test_model   \n",
       "9                     10                     10  test_model   \n",
       "8                     10                     10  test_model   \n",
       "7                     10                     10         NaN   \n",
       "6                     40                     40         NaN   \n",
       "5                     40                     40         NaN   \n",
       "4                     40                     40         NaN   \n",
       "3                     40                     40         NaN   \n",
       "2                     40                     40         NaN   \n",
       "1                     40                     40         NaN   \n",
       "0                     40                     40         NaN   \n",
       "\n",
       "   teacher_forcing_ratio  lazy_train  clip_grad_max_norm  val_loss  \n",
       "16                   1.0        True                10.0  8.607852  \n",
       "15                   1.0        True                10.0  9.221855  \n",
       "14                   0.5        True                10.0  8.778268  \n",
       "13                   0.5        True                10.0  9.359420  \n",
       "12                   0.5        True                10.0  8.283567  \n",
       "11                   0.5        True                10.0  9.577247  \n",
       "10                   0.5        True                10.0  9.337175  \n",
       "9                    0.5        True                10.0  9.228798  \n",
       "8                    0.5        True                 NaN  9.330558  \n",
       "7                    NaN         NaN                 NaN  8.507013  \n",
       "6                    NaN         NaN                 NaN  8.088548  \n",
       "5                    NaN         NaN                 NaN  7.985807  \n",
       "4                    NaN         NaN                 NaN  7.484231  \n",
       "3                    NaN         NaN                 NaN  7.390460  \n",
       "2                    NaN         NaN                 NaN  7.335167  \n",
       "1                    NaN         NaN                 NaN  5.436468  \n",
       "0                    NaN         NaN                 NaN  5.433290  \n",
       "\n",
       "[17 rows x 26 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_results(load_experiment_log())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_single_learning_curve(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (src_idxs, targ_idxs, src_lens, targ_lens) in enumerate(full_loaders['train']):\n",
    "#     print(i)\n",
    "#     print(src_idxs.size())\n",
    "#     print(src_idxs)\n",
    "#     print(src_lens)\n",
    "#     print(targ_idxs.size())\n",
    "#     print(targ_idxs)\n",
    "#     print(targ_lens)\n",
    "    id2token = vocab[SRC_LANG]['id2token']\n",
    "    test_tensor = src_idxs\n",
    "    list_of_lists = test_tensor.numpy().astype(int).tolist()\n",
    "    to_token = lambda l: ' '.join([id2token[idx] for idx in l])\n",
    "    list_of_lists_tokens = [to_token(l) for l in list_of_lists] \n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
