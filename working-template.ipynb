{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from data_processing import generate_vocab, process_data, create_dataloaders \n",
    "from model import get_pretrained_emb, EncoderDecoder, EncoderRNN, DecoderRNN, DecoderSimpleRNN, EncoderSimpleRNN, \\\n",
    "    Attention, DecoderAttnRNN, DecoderRNNV2, EncoderDecoderAttention, EncoderSimpleRNN_Test, DecoderAttnRNN_Test\n",
    "from train_eval import count_parameters, summarize_results, \\\n",
    "    plot_single_learning_curve, load_experiment_log\n",
    "from train_eval import train_and_eval, train_and_eval_attn \n",
    "import importlib\n",
    "import pickle as pkl \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model identification\n",
    "MODEL_NAME = 'zh-seq2seq-rnn-attention'\n",
    "SRC_LANG = 'zh'\n",
    "TARG_LANG = 'en'\n",
    "\n",
    "# data processing params  \n",
    "SRC_MAX_SENTENCE_LEN = 10\n",
    "TARG_MAX_SENTENCE_LEN = 10\n",
    "SRC_VOCAB_SIZE = 30000 #30000\n",
    "TARG_VOCAB_SIZE = 30000 #30000\n",
    "\n",
    "# model architecture params \n",
    "RNN_CELL_TYPE = 'gru'\n",
    "NUM_LAYERS = 2 #2 \n",
    "ENC_HIDDEN_DIM = 256 #512\n",
    "DEC_HIDDEN_DIM = 2 * ENC_HIDDEN_DIM #2 * ENC_HIDDEN_DIM \n",
    "TEACHER_FORCING_RATIO = 1\n",
    "CLIP_GRAD_MAX_NORM = 1\n",
    "ENC_DROPOUT = 0.2 # to actually implement\n",
    "DEC_DROPOUT = 0.2 # to actually implement\n",
    "\n",
    "# training params  \n",
    "BATCH_SIZE = 32 #32\n",
    "NUM_EPOCHS = 200\n",
    "LR = 0.0005 # 0.0005\n",
    "OPTIMIZER = 'Adam'\n",
    "LAZY_TRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store as dict to save to results later \n",
    "params = {'model_name': MODEL_NAME, 'src_lang': SRC_LANG, 'targ_lang': TARG_LANG, 'rnn_cell_type': RNN_CELL_TYPE, \n",
    "          'src_max_sentence_len': SRC_MAX_SENTENCE_LEN, 'targ_max_sentence_len': TARG_MAX_SENTENCE_LEN, \n",
    "          'src_vocab_size': SRC_VOCAB_SIZE, 'targ_vocab_size': TARG_VOCAB_SIZE, \n",
    "          'num_layers': NUM_LAYERS, 'enc_hidden_dim': ENC_HIDDEN_DIM, 'dec_hidden_dim': DEC_HIDDEN_DIM,\n",
    "          'teacher_forcing_ratio': TEACHER_FORCING_RATIO, 'clip_grad_max_norm': CLIP_GRAD_MAX_NORM,\n",
    "          'enc_dropout': ENC_DROPOUT, 'dec_dropout': DEC_DROPOUT, \n",
    "          'batch_size': BATCH_SIZE, 'num_epochs': NUM_EPOCHS, 'learning_rate': LR, 'optimizer': OPTIMIZER, \n",
    "          'lazy_train': LAZY_TRAIN} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab_test = generate_vocab(SRC_LANG, TARG_LANG, SRC_VOCAB_SIZE, TARG_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab['zh']['id2token'][987]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab['zh']['token2id']['森林']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab['en']['token2id']['activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab['en']['id2token'][987]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # takes a long time to process, save to pickle for reimport in future \n",
    "# vocab = generate_vocab(SRC_LANG, TARG_LANG, SRC_VOCAB_SIZE, TARG_VOCAB_SIZE)\n",
    "# vocab_filename = \"{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n",
    "# pkl.dump(vocab, open(vocab_filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload from pickle \n",
    "vocab_filename = \"{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n",
    "vocab = pkl.load(open(vocab_filename, \"rb\"))\n",
    "data = process_data(SRC_LANG, TARG_LANG, vocab)\n",
    "data_minibatch = process_data(SRC_LANG, TARG_LANG, vocab, sample_limit=BATCH_SIZE) \n",
    "data_minitrain = process_data(SRC_LANG, TARG_LANG, vocab, sample_limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # takes a long time to process, save to pickle for reimport in future \n",
    "# vocab = generate_vocab(SRC_LANG, TARG_LANG, SRC_VOCAB_SIZE, TARG_VOCAB_SIZE)\n",
    "# vocab_filename = \"{}-{}-vocab-fake.p\".format(SRC_LANG, TARG_LANG)\n",
    "# pkl.dump(vocab, open(vocab_filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_filename = \"{}-{}-vocab-fake.p\".format(SRC_LANG, TARG_LANG)\n",
    "# vocab = pkl.load(open(vocab_filename, \"rb\"))\n",
    "# data = process_data(SRC_LANG, TARG_LANG, vocab)\n",
    "# limited_data = process_data(SRC_LANG, TARG_LANG, vocab, sample_limit=BATCH_SIZE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders \n",
    "loaders_full = create_dataloaders(data, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)\n",
    "loaders_minibatch = create_dataloaders(data_minibatch, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)\n",
    "loaders_minitrain = create_dataloaders(data_minitrain, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model \n",
    "\n",
    "# encoder = EncoderRNN(enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, src_max_sentence_len=SRC_MAX_SENTENCE_LEN,\n",
    "#                      pretrained_word2vec=get_pretrained_emb(vocab[SRC_LANG]['word2vec'], vocab[SRC_LANG]['token2id']))\n",
    "# encoder = EncoderSimpleRNN(enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, src_max_sentence_len=SRC_MAX_SENTENCE_LEN,\n",
    "#                            pretrained_word2vec=get_pretrained_emb(vocab[SRC_LANG]['word2vec'], vocab[SRC_LANG]['token2id']))\n",
    "# encoder = EncoderSimpleRNN(enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, src_max_sentence_len=SRC_MAX_SENTENCE_LEN,\n",
    "#                            pretrained_word2vec=get_pretrained_emb(vocab[SRC_LANG]['word2vec'], vocab[SRC_LANG]['token2id']))\n",
    "encoder = EncoderSimpleRNN_Test(rnn_cell_type=RNN_CELL_TYPE, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, src_max_sentence_len=SRC_MAX_SENTENCE_LEN,\n",
    "                                enc_dropout=ENC_DROPOUT, pretrained_word2vec=get_pretrained_emb(vocab[SRC_LANG]['word2vec'], vocab[SRC_LANG]['token2id']))\n",
    "\n",
    "# decoder = DecoderRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS,\n",
    "#                       targ_vocab_size=TARG_VOCAB_SIZE, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "#                       pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "\n",
    "# decoder = DecoderRNNV2(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, \n",
    "#                        targ_vocab_size=TARG_VOCAB_SIZE, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "#                        pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "# decoder = DecoderSimpleRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, \n",
    "#                            targ_vocab_size=TARG_VOCAB_SIZE, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "#                            pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "# decoder = DecoderAttnRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, \n",
    "#                          targ_vocab_size=TARG_VOCAB_SIZE, src_max_sentence_len=SRC_MAX_SENTENCE_LEN, \n",
    "#                          targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "#                          pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "decoder = DecoderAttnRNN_Test(rnn_cell_type=RNN_CELL_TYPE, dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, \n",
    "                         targ_vocab_size=TARG_VOCAB_SIZE, src_max_sentence_len=SRC_MAX_SENTENCE_LEN, \n",
    "                         targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, dec_dropout=DEC_DROPOUT, \n",
    "                         pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "\n",
    "\n",
    "model = EncoderDecoderAttention(encoder, decoder, vocab[TARG_LANG]['token2id']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.00, Train Loss: 10.11, Val Loss: 10.24, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一只 水母 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: here &apos;s a jelly . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.1942, 0.2004, 0.2031, 0.2016, 0.1987, 0.0004, 0.0004, 0.0004, 0.0004,\n",
      "         0.0004],\n",
      "        [0.1942, 0.2004, 0.2031, 0.2016, 0.1987, 0.0004, 0.0004, 0.0004, 0.0004,\n",
      "         0.0004],\n",
      "        [0.1942, 0.2004, 0.2031, 0.2016, 0.1988, 0.0004, 0.0004, 0.0004, 0.0004,\n",
      "         0.0004],\n",
      "        [0.1942, 0.2003, 0.2031, 0.2016, 0.1989, 0.0004, 0.0004, 0.0004, 0.0004,\n",
      "         0.0004],\n",
      "        [0.1942, 0.2003, 0.2031, 0.2016, 0.1989, 0.0004, 0.0004, 0.0004, 0.0004,\n",
      "         0.0004],\n",
      "        [0.1942, 0.2004, 0.2031, 0.2016, 0.1988, 0.0004, 0.0004, 0.0004, 0.0004,\n",
      "         0.0004],\n",
      "        [0.1942, 0.2004, 0.2031, 0.2016, 0.1988, 0.0004, 0.0004, 0.0004, 0.0004,\n",
      "         0.0004],\n",
      "        [0.1942, 0.2004, 0.2031, 0.2016, 0.1988, 0.0004, 0.0004, 0.0004, 0.0004,\n",
      "         0.0004],\n",
      "        [0.1942, 0.2004, 0.2031, 0.2015, 0.1988, 0.0004, 0.0004, 0.0004, 0.0004,\n",
      "         0.0004]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在 可以 去 个 真正 的 学校 念书 了\n",
      "Reference: &quot; you can go to a real school now\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0982, 0.0975, 0.0969, 0.0943, 0.0974, 0.1015, 0.1035, 0.1043, 0.1040,\n",
      "         0.1024],\n",
      "        [0.0982, 0.0975, 0.0969, 0.0943, 0.0974, 0.1016, 0.1036, 0.1043, 0.1040,\n",
      "         0.1023],\n",
      "        [0.0983, 0.0976, 0.0969, 0.0943, 0.0975, 0.1016, 0.1035, 0.1042, 0.1039,\n",
      "         0.1023],\n",
      "        [0.0983, 0.0975, 0.0969, 0.0943, 0.0975, 0.1016, 0.1035, 0.1042, 0.1039,\n",
      "         0.1023],\n",
      "        [0.0983, 0.0975, 0.0969, 0.0943, 0.0975, 0.1016, 0.1035, 0.1042, 0.1039,\n",
      "         0.1023],\n",
      "        [0.0983, 0.0975, 0.0968, 0.0942, 0.0975, 0.1017, 0.1036, 0.1043, 0.1039,\n",
      "         0.1023],\n",
      "        [0.0982, 0.0974, 0.0968, 0.0942, 0.0975, 0.1017, 0.1036, 0.1043, 0.1039,\n",
      "         0.1023],\n",
      "        [0.0982, 0.0974, 0.0968, 0.0942, 0.0975, 0.1017, 0.1036, 0.1043, 0.1039,\n",
      "         0.1023],\n",
      "        [0.0982, 0.0974, 0.0968, 0.0942, 0.0975, 0.1017, 0.1036, 0.1043, 0.1039,\n",
      "         0.1023]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 1.00, Train Loss: 9.83, Val Loss: 10.14, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克 泰坦尼克号 坦尼 尼克 号 是 拿 了 不少\n",
      "Reference: the truth of the matter is that the titanic\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0907, 0.0889, 0.0905, 0.0910, 0.0997, 0.1076, 0.1107, 0.1113, 0.1086,\n",
      "         0.1011],\n",
      "        [0.0906, 0.0888, 0.0904, 0.0910, 0.0999, 0.1078, 0.1109, 0.1114, 0.1084,\n",
      "         0.1009],\n",
      "        [0.0907, 0.0889, 0.0904, 0.0910, 0.0999, 0.1078, 0.1109, 0.1113, 0.1083,\n",
      "         0.1008],\n",
      "        [0.0908, 0.0889, 0.0904, 0.0910, 0.1000, 0.1078, 0.1108, 0.1113, 0.1083,\n",
      "         0.1008],\n",
      "        [0.0908, 0.0889, 0.0904, 0.0910, 0.0999, 0.1077, 0.1108, 0.1113, 0.1083,\n",
      "         0.1008],\n",
      "        [0.0908, 0.0888, 0.0904, 0.0910, 0.0999, 0.1077, 0.1108, 0.1113, 0.1083,\n",
      "         0.1009],\n",
      "        [0.0908, 0.0888, 0.0904, 0.0910, 0.0999, 0.1077, 0.1108, 0.1113, 0.1084,\n",
      "         0.1009],\n",
      "        [0.0908, 0.0888, 0.0903, 0.0909, 0.0999, 0.1078, 0.1108, 0.1113, 0.1084,\n",
      "         0.1009],\n",
      "        [0.0908, 0.0888, 0.0903, 0.0909, 0.0999, 0.1078, 0.1109, 0.1114, 0.1084,\n",
      "         0.1009]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 不知 知道 那 意味 意味着 什么 但是 我 能\n",
      "Reference: i didn &apos;t know what it meant , but\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0942, 0.1022, 0.1073, 0.1083, 0.1087, 0.1078, 0.1023, 0.0944, 0.0867,\n",
      "         0.0881],\n",
      "        [0.0943, 0.1023, 0.1074, 0.1084, 0.1087, 0.1078, 0.1022, 0.0943, 0.0866,\n",
      "         0.0880],\n",
      "        [0.0944, 0.1024, 0.1074, 0.1084, 0.1086, 0.1077, 0.1022, 0.0942, 0.0866,\n",
      "         0.0881],\n",
      "        [0.0944, 0.1024, 0.1074, 0.1083, 0.1086, 0.1077, 0.1022, 0.0942, 0.0866,\n",
      "         0.0881],\n",
      "        [0.0944, 0.1024, 0.1074, 0.1084, 0.1086, 0.1077, 0.1022, 0.0942, 0.0866,\n",
      "         0.0881],\n",
      "        [0.0944, 0.1023, 0.1073, 0.1083, 0.1086, 0.1077, 0.1022, 0.0942, 0.0867,\n",
      "         0.0882],\n",
      "        [0.0944, 0.1023, 0.1073, 0.1083, 0.1086, 0.1077, 0.1022, 0.0942, 0.0867,\n",
      "         0.0882],\n",
      "        [0.0944, 0.1023, 0.1073, 0.1084, 0.1086, 0.1077, 0.1022, 0.0942, 0.0867,\n",
      "         0.0882],\n",
      "        [0.0944, 0.1023, 0.1073, 0.1084, 0.1086, 0.1077, 0.1022, 0.0942, 0.0867,\n",
      "         0.0882]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 2.00, Train Loss: 9.42, Val Loss: 9.98, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一种 种群 栖 动物 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: it &apos;s a colonial animal . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[1.3392e-01, 1.5246e-01, 1.5765e-01, 1.5929e-01, 1.5742e-01, 1.3494e-01,\n",
      "         1.0431e-01, 6.7591e-07, 6.7591e-07, 6.7591e-07],\n",
      "        [1.3432e-01, 1.5297e-01, 1.5797e-01, 1.5939e-01, 1.5731e-01, 1.3442e-01,\n",
      "         1.0362e-01, 6.1749e-07, 6.1749e-07, 6.1749e-07],\n",
      "        [1.3457e-01, 1.5310e-01, 1.5797e-01, 1.5931e-01, 1.5718e-01, 1.3427e-01,\n",
      "         1.0360e-01, 6.0223e-07, 6.0223e-07, 6.0223e-07],\n",
      "        [1.3470e-01, 1.5313e-01, 1.5793e-01, 1.5925e-01, 1.5711e-01, 1.3423e-01,\n",
      "         1.0365e-01, 5.9878e-07, 5.9878e-07, 5.9878e-07],\n",
      "        [1.3466e-01, 1.5306e-01, 1.5787e-01, 1.5922e-01, 1.5711e-01, 1.3429e-01,\n",
      "         1.0379e-01, 6.1655e-07, 6.1655e-07, 6.1655e-07],\n",
      "        [1.3466e-01, 1.5305e-01, 1.5785e-01, 1.5922e-01, 1.5711e-01, 1.3430e-01,\n",
      "         1.0382e-01, 6.1415e-07, 6.1415e-07, 6.1415e-07],\n",
      "        [1.3460e-01, 1.5301e-01, 1.5783e-01, 1.5922e-01, 1.5712e-01, 1.3435e-01,\n",
      "         1.0387e-01, 6.1738e-07, 6.1738e-07, 6.1738e-07],\n",
      "        [1.3455e-01, 1.5299e-01, 1.5782e-01, 1.5923e-01, 1.5713e-01, 1.3438e-01,\n",
      "         1.0390e-01, 6.1949e-07, 6.1949e-07, 6.1949e-07],\n",
      "        [1.3458e-01, 1.5299e-01, 1.5781e-01, 1.5922e-01, 1.5711e-01, 1.3437e-01,\n",
      "         1.0393e-01, 6.1360e-07, 6.1360e-07, 6.1360e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 在 塔利 塔利班 控制 阿富汗 的 那些 年 我 记得\n",
      "Reference: during taliban years , i remember there were times\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0818, 0.0937, 0.1054, 0.1117, 0.1150, 0.1136, 0.1130, 0.1024, 0.0899,\n",
      "         0.0735],\n",
      "        [0.0819, 0.0939, 0.1058, 0.1121, 0.1153, 0.1136, 0.1129, 0.1021, 0.0894,\n",
      "         0.0729],\n",
      "        [0.0820, 0.0940, 0.1059, 0.1122, 0.1153, 0.1135, 0.1128, 0.1020, 0.0893,\n",
      "         0.0728],\n",
      "        [0.0821, 0.0941, 0.1060, 0.1123, 0.1153, 0.1135, 0.1128, 0.1019, 0.0892,\n",
      "         0.0728],\n",
      "        [0.0821, 0.0941, 0.1060, 0.1123, 0.1153, 0.1135, 0.1127, 0.1018, 0.0892,\n",
      "         0.0728],\n",
      "        [0.0822, 0.0942, 0.1060, 0.1123, 0.1153, 0.1135, 0.1127, 0.1018, 0.0892,\n",
      "         0.0728],\n",
      "        [0.0821, 0.0941, 0.1060, 0.1123, 0.1153, 0.1135, 0.1127, 0.1018, 0.0892,\n",
      "         0.0729],\n",
      "        [0.0821, 0.0941, 0.1060, 0.1123, 0.1153, 0.1135, 0.1127, 0.1018, 0.0892,\n",
      "         0.0729],\n",
      "        [0.0821, 0.0941, 0.1060, 0.1122, 0.1153, 0.1135, 0.1127, 0.1019, 0.0893,\n",
      "         0.0729]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 3.00, Train Loss: 8.88, Val Loss: 9.78, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里 生物 的 多样 多样性 和 密度 要 比\n",
      "Reference: the biodiversity and the <UNK> in the ocean is\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0715, 0.0972, 0.1050, 0.1130, 0.1090, 0.0992, 0.1159, 0.1088, 0.1024,\n",
      "         0.0781],\n",
      "        [0.0715, 0.0977, 0.1055, 0.1135, 0.1090, 0.0987, 0.1161, 0.1088, 0.1021,\n",
      "         0.0771],\n",
      "        [0.0716, 0.0979, 0.1056, 0.1136, 0.1089, 0.0985, 0.1162, 0.1088, 0.1020,\n",
      "         0.0768],\n",
      "        [0.0717, 0.0980, 0.1056, 0.1136, 0.1089, 0.0985, 0.1162, 0.1088, 0.1020,\n",
      "         0.0768],\n",
      "        [0.0718, 0.0980, 0.1057, 0.1136, 0.1089, 0.0985, 0.1162, 0.1087, 0.1019,\n",
      "         0.0768],\n",
      "        [0.0718, 0.0980, 0.1056, 0.1136, 0.1088, 0.0984, 0.1162, 0.1087, 0.1019,\n",
      "         0.0768],\n",
      "        [0.0719, 0.0980, 0.1056, 0.1135, 0.1088, 0.0984, 0.1161, 0.1087, 0.1019,\n",
      "         0.0769],\n",
      "        [0.0718, 0.0980, 0.1056, 0.1135, 0.1088, 0.0984, 0.1161, 0.1087, 0.1020,\n",
      "         0.0769],\n",
      "        [0.0718, 0.0980, 0.1056, 0.1135, 0.1088, 0.0984, 0.1161, 0.1087, 0.1020,\n",
      "         0.0770]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6 岁 那年 塔利 塔利班 占领 阿富汗 并 规定\n",
      "Reference: you see , i was six when the taliban\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[8.2120e-02, 1.1104e-01, 1.2186e-01, 1.2654e-01, 1.3729e-01, 1.4271e-01,\n",
      "         1.2732e-01, 9.4380e-02, 5.6728e-02, 7.4995e-08],\n",
      "        [8.2161e-02, 1.1159e-01, 1.2229e-01, 1.2686e-01, 1.3773e-01, 1.4310e-01,\n",
      "         1.2710e-01, 9.3483e-02, 5.5678e-02, 7.0040e-08],\n",
      "        [8.2375e-02, 1.1187e-01, 1.2245e-01, 1.2695e-01, 1.3779e-01, 1.4311e-01,\n",
      "         1.2692e-01, 9.3134e-02, 5.5403e-02, 7.1383e-08],\n",
      "        [8.2491e-02, 1.1198e-01, 1.2250e-01, 1.2696e-01, 1.3779e-01, 1.4309e-01,\n",
      "         1.2684e-01, 9.3002e-02, 5.5351e-02, 7.2548e-08],\n",
      "        [8.2577e-02, 1.1204e-01, 1.2251e-01, 1.2694e-01, 1.3776e-01, 1.4304e-01,\n",
      "         1.2677e-01, 9.2955e-02, 5.5395e-02, 7.4050e-08],\n",
      "        [8.2614e-02, 1.1205e-01, 1.2251e-01, 1.2692e-01, 1.3773e-01, 1.4300e-01,\n",
      "         1.2674e-01, 9.2969e-02, 5.5474e-02, 7.5444e-08],\n",
      "        [8.2620e-02, 1.1205e-01, 1.2250e-01, 1.2690e-01, 1.3769e-01, 1.4297e-01,\n",
      "         1.2673e-01, 9.3000e-02, 5.5540e-02, 7.6433e-08],\n",
      "        [8.2636e-02, 1.1205e-01, 1.2249e-01, 1.2688e-01, 1.3767e-01, 1.4294e-01,\n",
      "         1.2672e-01, 9.3020e-02, 5.5606e-02, 7.7103e-08],\n",
      "        [8.2624e-02, 1.1203e-01, 1.2248e-01, 1.2687e-01, 1.3765e-01, 1.4292e-01,\n",
      "         1.2672e-01, 9.3051e-02, 5.5650e-02, 7.7574e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4.00, Train Loss: 8.31, Val Loss: 9.55, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 我 真 喜欢 这些 东西 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: i love that kind of stuff . <EOS> <PAD>\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[1.6000e-01, 2.2362e-01, 2.2518e-01, 1.9418e-01, 1.3665e-01, 6.0375e-02,\n",
      "         2.5261e-08, 2.5261e-08, 2.5261e-08, 2.5261e-08],\n",
      "        [1.6136e-01, 2.2644e-01, 2.2676e-01, 1.9358e-01, 1.3404e-01, 5.7830e-02,\n",
      "         2.6271e-08, 2.6271e-08, 2.6271e-08, 2.6271e-08],\n",
      "        [1.6178e-01, 2.2726e-01, 2.2719e-01, 1.9334e-01, 1.3322e-01, 5.7207e-02,\n",
      "         2.9012e-08, 2.9012e-08, 2.9012e-08, 2.9012e-08],\n",
      "        [1.6206e-01, 2.2763e-01, 2.2727e-01, 1.9312e-01, 1.3284e-01, 5.7073e-02,\n",
      "         3.0451e-08, 3.0451e-08, 3.0451e-08, 3.0451e-08],\n",
      "        [1.6218e-01, 2.2771e-01, 2.2722e-01, 1.9299e-01, 1.3275e-01, 5.7141e-02,\n",
      "         3.1667e-08, 3.1667e-08, 3.1667e-08, 3.1667e-08],\n",
      "        [1.6224e-01, 2.2770e-01, 2.2714e-01, 1.9291e-01, 1.3276e-01, 5.7250e-02,\n",
      "         3.2536e-08, 3.2536e-08, 3.2536e-08, 3.2536e-08],\n",
      "        [1.6226e-01, 2.2765e-01, 2.2706e-01, 1.9287e-01, 1.3281e-01, 5.7358e-02,\n",
      "         3.3060e-08, 3.3060e-08, 3.3060e-08, 3.3060e-08],\n",
      "        [1.6229e-01, 2.2761e-01, 2.2699e-01, 1.9282e-01, 1.3284e-01, 5.7447e-02,\n",
      "         3.3345e-08, 3.3345e-08, 3.3345e-08, 3.3345e-08],\n",
      "        [1.6227e-01, 2.2758e-01, 2.2696e-01, 1.9282e-01, 1.3288e-01, 5.7492e-02,\n",
      "         3.3547e-08, 3.3547e-08, 3.3547e-08, 3.3547e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 她 两年 年前 退休 了 结果 却 把 我家 变成\n",
      "Reference: she retired two years ago , only to turn\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[1.6000e-01, 2.2362e-01, 2.2518e-01, 1.9418e-01, 1.3665e-01, 6.0375e-02,\n",
      "         2.5261e-08, 2.5261e-08, 2.5261e-08, 2.5261e-08],\n",
      "        [1.6136e-01, 2.2644e-01, 2.2676e-01, 1.9358e-01, 1.3404e-01, 5.7830e-02,\n",
      "         2.6271e-08, 2.6271e-08, 2.6271e-08, 2.6271e-08],\n",
      "        [1.6178e-01, 2.2726e-01, 2.2719e-01, 1.9334e-01, 1.3322e-01, 5.7207e-02,\n",
      "         2.9012e-08, 2.9012e-08, 2.9012e-08, 2.9012e-08],\n",
      "        [1.6206e-01, 2.2763e-01, 2.2727e-01, 1.9312e-01, 1.3284e-01, 5.7073e-02,\n",
      "         3.0451e-08, 3.0451e-08, 3.0451e-08, 3.0451e-08],\n",
      "        [1.6218e-01, 2.2771e-01, 2.2722e-01, 1.9299e-01, 1.3275e-01, 5.7141e-02,\n",
      "         3.1667e-08, 3.1667e-08, 3.1667e-08, 3.1667e-08],\n",
      "        [1.6224e-01, 2.2770e-01, 2.2714e-01, 1.9291e-01, 1.3276e-01, 5.7250e-02,\n",
      "         3.2536e-08, 3.2536e-08, 3.2536e-08, 3.2536e-08],\n",
      "        [1.6226e-01, 2.2765e-01, 2.2706e-01, 1.9287e-01, 1.3281e-01, 5.7358e-02,\n",
      "         3.3060e-08, 3.3060e-08, 3.3060e-08, 3.3060e-08],\n",
      "        [1.6229e-01, 2.2761e-01, 2.2699e-01, 1.9282e-01, 1.3284e-01, 5.7447e-02,\n",
      "         3.3345e-08, 3.3345e-08, 3.3345e-08, 3.3345e-08],\n",
      "        [1.6227e-01, 2.2758e-01, 2.2696e-01, 1.9282e-01, 1.3288e-01, 5.7492e-02,\n",
      "         3.3547e-08, 3.3547e-08, 3.3547e-08, 3.3547e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 5.00, Train Loss: 7.76, Val Loss: 9.34, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 它 可以 伸展 <UNK> 150 英尺 长 <EOS> <PAD> <PAD>\n",
      "Reference: it gets up to about 150 feet long .\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[1.1579e-01, 1.6708e-01, 1.7709e-01, 1.3023e-01, 1.1612e-01, 1.4751e-01,\n",
      "         1.1241e-01, 3.3773e-02, 5.4754e-09, 5.4754e-09],\n",
      "        [1.1653e-01, 1.6938e-01, 1.7914e-01, 1.3026e-01, 1.1538e-01, 1.4776e-01,\n",
      "         1.1008e-01, 3.1464e-02, 6.7653e-09, 6.7653e-09],\n",
      "        [1.1665e-01, 1.6998e-01, 1.7983e-01, 1.3013e-01, 1.1499e-01, 1.4779e-01,\n",
      "         1.0958e-01, 3.1056e-02, 8.2164e-09, 8.2164e-09],\n",
      "        [1.1681e-01, 1.7025e-01, 1.8006e-01, 1.2996e-01, 1.1473e-01, 1.4770e-01,\n",
      "         1.0943e-01, 3.1054e-02, 8.9704e-09, 8.9704e-09],\n",
      "        [1.1692e-01, 1.7034e-01, 1.8010e-01, 1.2987e-01, 1.1461e-01, 1.4762e-01,\n",
      "         1.0941e-01, 3.1131e-02, 9.4330e-09, 9.4330e-09],\n",
      "        [1.1700e-01, 1.7037e-01, 1.8008e-01, 1.2983e-01, 1.1455e-01, 1.4756e-01,\n",
      "         1.0941e-01, 3.1206e-02, 9.6959e-09, 9.6959e-09],\n",
      "        [1.1706e-01, 1.7037e-01, 1.8004e-01, 1.2980e-01, 1.1452e-01, 1.4753e-01,\n",
      "         1.0942e-01, 3.1265e-02, 9.8288e-09, 9.8288e-09],\n",
      "        [1.1706e-01, 1.7037e-01, 1.8002e-01, 1.2979e-01, 1.1451e-01, 1.4751e-01,\n",
      "         1.0944e-01, 3.1296e-02, 9.9148e-09, 9.9148e-09],\n",
      "        [1.1703e-01, 1.7033e-01, 1.7999e-01, 1.2978e-01, 1.1451e-01, 1.4755e-01,\n",
      "         1.0949e-01, 3.1328e-02, 9.9317e-09, 9.9317e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 在 被 跟踪 吗 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: were we being followed ? <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0595, 0.1133, 0.1445, 0.1524, 0.1350, 0.1085, 0.0690, 0.0769, 0.0893,\n",
      "         0.0514],\n",
      "        [0.0590, 0.1150, 0.1474, 0.1551, 0.1358, 0.1078, 0.0673, 0.0756, 0.0881,\n",
      "         0.0490],\n",
      "        [0.0587, 0.1152, 0.1482, 0.1560, 0.1362, 0.1077, 0.0668, 0.0751, 0.0877,\n",
      "         0.0484],\n",
      "        [0.0586, 0.1154, 0.1486, 0.1564, 0.1363, 0.1076, 0.0665, 0.0748, 0.0875,\n",
      "         0.0482],\n",
      "        [0.0586, 0.1155, 0.1488, 0.1565, 0.1363, 0.1074, 0.0664, 0.0747, 0.0874,\n",
      "         0.0482],\n",
      "        [0.0587, 0.1156, 0.1489, 0.1566, 0.1362, 0.1074, 0.0663, 0.0747, 0.0874,\n",
      "         0.0482],\n",
      "        [0.0587, 0.1156, 0.1489, 0.1566, 0.1362, 0.1073, 0.0663, 0.0747, 0.0874,\n",
      "         0.0482],\n",
      "        [0.0587, 0.1156, 0.1489, 0.1565, 0.1362, 0.1073, 0.0663, 0.0747, 0.0874,\n",
      "         0.0482],\n",
      "        [0.0587, 0.1157, 0.1489, 0.1565, 0.1362, 0.1073, 0.0663, 0.0747, 0.0874,\n",
      "         0.0482]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 6.00, Train Loss: 7.25, Val Loss: 9.14, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 我们 得用 非常 特殊 的 仪器 才能 能到 到达 那个\n",
      "Reference: we have to have a very special technology to\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0402, 0.0633, 0.1258, 0.1562, 0.1696, 0.1479, 0.1186, 0.0676, 0.0746,\n",
      "         0.0362],\n",
      "        [0.0387, 0.0620, 0.1275, 0.1600, 0.1740, 0.1499, 0.1179, 0.0648, 0.0718,\n",
      "         0.0333],\n",
      "        [0.0381, 0.0612, 0.1275, 0.1609, 0.1754, 0.1508, 0.1180, 0.0643, 0.0711,\n",
      "         0.0327],\n",
      "        [0.0379, 0.0610, 0.1275, 0.1611, 0.1758, 0.1509, 0.1180, 0.0641, 0.0709,\n",
      "         0.0326],\n",
      "        [0.0379, 0.0609, 0.1276, 0.1612, 0.1760, 0.1510, 0.1179, 0.0640, 0.0709,\n",
      "         0.0326],\n",
      "        [0.0379, 0.0609, 0.1276, 0.1613, 0.1760, 0.1510, 0.1179, 0.0640, 0.0709,\n",
      "         0.0326],\n",
      "        [0.0379, 0.0609, 0.1276, 0.1613, 0.1760, 0.1510, 0.1179, 0.0640, 0.0709,\n",
      "         0.0326],\n",
      "        [0.0379, 0.0609, 0.1276, 0.1613, 0.1760, 0.1509, 0.1179, 0.0640, 0.0709,\n",
      "         0.0326],\n",
      "        [0.0379, 0.0609, 0.1276, 0.1613, 0.1760, 0.1509, 0.1179, 0.0640, 0.0709,\n",
      "         0.0326]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 在 被 跟踪 吗 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: were we being followed ? <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0505, 0.1101, 0.1460, 0.1566, 0.1413, 0.1146, 0.0711, 0.0795, 0.0875,\n",
      "         0.0427],\n",
      "        [0.0494, 0.1116, 0.1497, 0.1604, 0.1429, 0.1141, 0.0689, 0.0776, 0.0857,\n",
      "         0.0397],\n",
      "        [0.0488, 0.1116, 0.1505, 0.1616, 0.1435, 0.1142, 0.0684, 0.0770, 0.0852,\n",
      "         0.0391],\n",
      "        [0.0487, 0.1117, 0.1509, 0.1620, 0.1437, 0.1141, 0.0682, 0.0768, 0.0851,\n",
      "         0.0390],\n",
      "        [0.0487, 0.1118, 0.1511, 0.1622, 0.1437, 0.1140, 0.0680, 0.0767, 0.0850,\n",
      "         0.0389],\n",
      "        [0.0487, 0.1119, 0.1512, 0.1622, 0.1437, 0.1139, 0.0680, 0.0766, 0.0850,\n",
      "         0.0389],\n",
      "        [0.0487, 0.1119, 0.1512, 0.1622, 0.1437, 0.1139, 0.0679, 0.0766, 0.0850,\n",
      "         0.0389],\n",
      "        [0.0487, 0.1119, 0.1512, 0.1622, 0.1437, 0.1139, 0.0679, 0.0766, 0.0850,\n",
      "         0.0389],\n",
      "        [0.0487, 0.1120, 0.1512, 0.1623, 0.1437, 0.1138, 0.0679, 0.0766, 0.0850,\n",
      "         0.0389]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 7.00, Train Loss: 6.78, Val Loss: 8.97, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 看到 这些 在 动 的 东西 了 吗 <EOS> <PAD>\n",
      "Reference: but see all those different working things ? <EOS>\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[4.2933e-02, 1.0000e-01, 1.4679e-01, 1.6816e-01, 1.7108e-01, 1.5870e-01,\n",
      "         1.3092e-01, 6.9796e-02, 1.1624e-02, 3.8985e-10],\n",
      "        [4.0714e-02, 9.9409e-02, 1.4936e-01, 1.7213e-01, 1.7438e-01, 1.5985e-01,\n",
      "         1.2923e-01, 6.5199e-02, 9.7412e-03, 6.9634e-10],\n",
      "        [3.9898e-02, 9.8682e-02, 1.4960e-01, 1.7301e-01, 1.7530e-01, 1.6034e-01,\n",
      "         1.2919e-01, 6.4458e-02, 9.5345e-03, 8.5361e-10],\n",
      "        [3.9701e-02, 9.8501e-02, 1.4969e-01, 1.7325e-01, 1.7551e-01, 1.6040e-01,\n",
      "         1.2913e-01, 6.4280e-02, 9.5277e-03, 9.1210e-10],\n",
      "        [3.9653e-02, 9.8472e-02, 1.4975e-01, 1.7334e-01, 1.7557e-01, 1.6038e-01,\n",
      "         1.2908e-01, 6.4217e-02, 9.5350e-03, 9.4020e-10],\n",
      "        [3.9641e-02, 9.8477e-02, 1.4979e-01, 1.7338e-01, 1.7558e-01, 1.6036e-01,\n",
      "         1.2904e-01, 6.4189e-02, 9.5394e-03, 9.5256e-10],\n",
      "        [3.9637e-02, 9.8487e-02, 1.4982e-01, 1.7340e-01, 1.7559e-01, 1.6034e-01,\n",
      "         1.2902e-01, 6.4175e-02, 9.5421e-03, 9.5687e-10],\n",
      "        [3.9641e-02, 9.8501e-02, 1.4984e-01, 1.7341e-01, 1.7558e-01, 1.6032e-01,\n",
      "         1.2900e-01, 6.4167e-02, 9.5446e-03, 9.5789e-10],\n",
      "        [3.9644e-02, 9.8512e-02, 1.4985e-01, 1.7341e-01, 1.7558e-01, 1.6031e-01,\n",
      "         1.2899e-01, 6.4166e-02, 9.5468e-03, 9.5499e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 永远 不会 忘记 那个 早晨 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: a morning that i will never forget . <EOS>\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0454, 0.1053, 0.1508, 0.1732, 0.1861, 0.1658, 0.1094, 0.0481, 0.0122,\n",
      "         0.0037],\n",
      "        [0.0429, 0.1044, 0.1531, 0.1772, 0.1910, 0.1677, 0.1064, 0.0439, 0.0103,\n",
      "         0.0031],\n",
      "        [0.0420, 0.1036, 0.1533, 0.1782, 0.1925, 0.1685, 0.1057, 0.0431, 0.0101,\n",
      "         0.0030],\n",
      "        [0.0418, 0.1034, 0.1533, 0.1784, 0.1929, 0.1686, 0.1055, 0.0429, 0.0101,\n",
      "         0.0031],\n",
      "        [0.0418, 0.1034, 0.1534, 0.1785, 0.1930, 0.1686, 0.1054, 0.0429, 0.0101,\n",
      "         0.0031],\n",
      "        [0.0418, 0.1034, 0.1534, 0.1785, 0.1930, 0.1686, 0.1054, 0.0428, 0.0101,\n",
      "         0.0031],\n",
      "        [0.0418, 0.1034, 0.1534, 0.1785, 0.1930, 0.1686, 0.1054, 0.0429, 0.0101,\n",
      "         0.0031],\n",
      "        [0.0418, 0.1034, 0.1534, 0.1784, 0.1930, 0.1686, 0.1054, 0.0429, 0.0101,\n",
      "         0.0031],\n",
      "        [0.0418, 0.1034, 0.1534, 0.1784, 0.1929, 0.1686, 0.1054, 0.0429, 0.0101,\n",
      "         0.0031]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8.00, Train Loss: 6.35, Val Loss: 8.84, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 还有 这些 摇晃 着 旋转 转着 的 触角 <EOS> <PAD>\n",
      "Reference: it &apos;s got tentacles dangling , swirling around like\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[4.7451e-02, 1.1822e-01, 1.6615e-01, 1.8717e-01, 1.6840e-01, 1.2208e-01,\n",
      "         1.2361e-01, 5.8105e-02, 8.8227e-03, 2.2466e-10],\n",
      "        [4.4941e-02, 1.1841e-01, 1.7034e-01, 1.9336e-01, 1.7133e-01, 1.1949e-01,\n",
      "         1.2145e-01, 5.3369e-02, 7.3171e-03, 5.1302e-10],\n",
      "        [4.4194e-02, 1.1792e-01, 1.7086e-01, 1.9462e-01, 1.7198e-01, 1.1909e-01,\n",
      "         1.2129e-01, 5.2788e-02, 7.2469e-03, 6.3946e-10],\n",
      "        [4.4051e-02, 1.1786e-01, 1.7101e-01, 1.9490e-01, 1.7204e-01, 1.1895e-01,\n",
      "         1.2121e-01, 5.2709e-02, 7.2741e-03, 6.7713e-10],\n",
      "        [4.4028e-02, 1.1788e-01, 1.7108e-01, 1.9498e-01, 1.7203e-01, 1.1888e-01,\n",
      "         1.2115e-01, 5.2680e-02, 7.2854e-03, 6.9433e-10],\n",
      "        [4.4028e-02, 1.1791e-01, 1.7112e-01, 1.9501e-01, 1.7201e-01, 1.1884e-01,\n",
      "         1.2111e-01, 5.2672e-02, 7.2899e-03, 6.9900e-10],\n",
      "        [4.4033e-02, 1.1794e-01, 1.7115e-01, 1.9502e-01, 1.7200e-01, 1.1882e-01,\n",
      "         1.2109e-01, 5.2668e-02, 7.2924e-03, 6.9997e-10],\n",
      "        [4.4044e-02, 1.1796e-01, 1.7116e-01, 1.9501e-01, 1.7198e-01, 1.1880e-01,\n",
      "         1.2108e-01, 5.2671e-02, 7.2956e-03, 6.9808e-10],\n",
      "        [4.4061e-02, 1.1798e-01, 1.7116e-01, 1.9500e-01, 1.7196e-01, 1.1880e-01,\n",
      "         1.2107e-01, 5.2678e-02, 7.2980e-03, 6.9087e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 这 是 我们 俩 人 唯一 的 受教 教育 方式\n",
      "Reference: it was the only way we both could be\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0393, 0.0920, 0.1190, 0.1282, 0.1302, 0.1340, 0.1281, 0.1195, 0.0839,\n",
      "         0.0259],\n",
      "        [0.0371, 0.0916, 0.1207, 0.1307, 0.1324, 0.1363, 0.1290, 0.1191, 0.0805,\n",
      "         0.0226],\n",
      "        [0.0364, 0.0911, 0.1208, 0.1310, 0.1327, 0.1368, 0.1294, 0.1193, 0.0801,\n",
      "         0.0222],\n",
      "        [0.0363, 0.0911, 0.1209, 0.1311, 0.1328, 0.1369, 0.1294, 0.1193, 0.0801,\n",
      "         0.0222],\n",
      "        [0.0363, 0.0912, 0.1210, 0.1312, 0.1328, 0.1369, 0.1293, 0.1192, 0.0800,\n",
      "         0.0222],\n",
      "        [0.0363, 0.0912, 0.1210, 0.1312, 0.1328, 0.1369, 0.1293, 0.1192, 0.0800,\n",
      "         0.0221],\n",
      "        [0.0363, 0.0912, 0.1210, 0.1312, 0.1328, 0.1369, 0.1293, 0.1192, 0.0800,\n",
      "         0.0221],\n",
      "        [0.0363, 0.0912, 0.1211, 0.1312, 0.1327, 0.1369, 0.1293, 0.1192, 0.0799,\n",
      "         0.0221],\n",
      "        [0.0363, 0.0913, 0.1211, 0.1312, 0.1327, 0.1369, 0.1293, 0.1191, 0.0799,\n",
      "         0.0221]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 9.00, Train Loss: 5.97, Val Loss: 8.73, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 这位 是 比尔 <UNK> 我 是 大卫 <UNK>\n",
      "Reference: this is bill lange . i &apos;m dave gallo\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0349, 0.0711, 0.1222, 0.1422, 0.1146, 0.1281, 0.1566, 0.1394, 0.0768,\n",
      "         0.0142],\n",
      "        [0.0324, 0.0688, 0.1237, 0.1455, 0.1143, 0.1290, 0.1606, 0.1406, 0.0730,\n",
      "         0.0121],\n",
      "        [0.0319, 0.0681, 0.1235, 0.1461, 0.1143, 0.1290, 0.1613, 0.1410, 0.0727,\n",
      "         0.0120],\n",
      "        [0.0319, 0.0680, 0.1236, 0.1462, 0.1143, 0.1290, 0.1614, 0.1410, 0.0726,\n",
      "         0.0120],\n",
      "        [0.0319, 0.0681, 0.1236, 0.1463, 0.1143, 0.1290, 0.1614, 0.1410, 0.0726,\n",
      "         0.0120],\n",
      "        [0.0319, 0.0681, 0.1236, 0.1463, 0.1143, 0.1290, 0.1614, 0.1409, 0.0725,\n",
      "         0.0120],\n",
      "        [0.0319, 0.0681, 0.1237, 0.1463, 0.1143, 0.1290, 0.1614, 0.1409, 0.0725,\n",
      "         0.0120],\n",
      "        [0.0319, 0.0681, 0.1237, 0.1463, 0.1143, 0.1290, 0.1613, 0.1409, 0.0725,\n",
      "         0.0120],\n",
      "        [0.0319, 0.0682, 0.1237, 0.1463, 0.1143, 0.1290, 0.1613, 0.1409, 0.0725,\n",
      "         0.0120]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 那 就是 她 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: there she is . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[3.9972e-02, 1.0392e-01, 1.4657e-01, 1.6401e-01, 1.6750e-01, 1.5988e-01,\n",
      "         1.3678e-01, 7.2707e-02, 8.6715e-03, 1.1962e-10],\n",
      "        [3.7170e-02, 1.0267e-01, 1.4891e-01, 1.6800e-01, 1.7118e-01, 1.6171e-01,\n",
      "         1.3556e-01, 6.7712e-02, 7.0896e-03, 3.0978e-10],\n",
      "        [3.6520e-02, 1.0208e-01, 1.4906e-01, 1.6858e-01, 1.7181e-01, 1.6211e-01,\n",
      "         1.3561e-01, 6.7216e-02, 7.0229e-03, 3.6869e-10],\n",
      "        [3.6414e-02, 1.0203e-01, 1.4916e-01, 1.6872e-01, 1.7189e-01, 1.6209e-01,\n",
      "         1.3553e-01, 6.7126e-02, 7.0360e-03, 3.7936e-10],\n",
      "        [3.6413e-02, 1.0208e-01, 1.4924e-01, 1.6877e-01, 1.7189e-01, 1.6203e-01,\n",
      "         1.3545e-01, 6.7084e-02, 7.0416e-03, 3.8310e-10],\n",
      "        [3.6431e-02, 1.0213e-01, 1.4929e-01, 1.6878e-01, 1.7188e-01, 1.6198e-01,\n",
      "         1.3540e-01, 6.7063e-02, 7.0438e-03, 3.8248e-10],\n",
      "        [3.6448e-02, 1.0217e-01, 1.4932e-01, 1.6879e-01, 1.7186e-01, 1.6195e-01,\n",
      "         1.3536e-01, 6.7051e-02, 7.0449e-03, 3.8036e-10],\n",
      "        [3.6464e-02, 1.0219e-01, 1.4934e-01, 1.6880e-01, 1.7185e-01, 1.6193e-01,\n",
      "         1.3534e-01, 6.7043e-02, 7.0463e-03, 3.7801e-10],\n",
      "        [3.6477e-02, 1.0222e-01, 1.4935e-01, 1.6880e-01, 1.7184e-01, 1.6191e-01,\n",
      "         1.3532e-01, 6.7038e-02, 7.0473e-03, 3.7533e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 10.00, Train Loss: 5.63, Val Loss: 8.67, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这 有 不少 精彩 的 泰坦 泰坦尼克 坦尼 尼克\n",
      "Reference: we &apos;ve got some of the most incredible video\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0405, 0.1084, 0.1408, 0.1503, 0.1544, 0.1502, 0.1232, 0.0699, 0.0416,\n",
      "         0.0208],\n",
      "        [0.0382, 0.1090, 0.1447, 0.1547, 0.1588, 0.1533, 0.1220, 0.0642, 0.0371,\n",
      "         0.0180],\n",
      "        [0.0377, 0.1088, 0.1451, 0.1552, 0.1594, 0.1537, 0.1218, 0.0638, 0.0368,\n",
      "         0.0179],\n",
      "        [0.0376, 0.1089, 0.1452, 0.1553, 0.1594, 0.1537, 0.1217, 0.0637, 0.0367,\n",
      "         0.0179],\n",
      "        [0.0377, 0.1090, 0.1453, 0.1553, 0.1594, 0.1536, 0.1216, 0.0636, 0.0367,\n",
      "         0.0179],\n",
      "        [0.0377, 0.1091, 0.1454, 0.1553, 0.1593, 0.1536, 0.1215, 0.0636, 0.0367,\n",
      "         0.0179],\n",
      "        [0.0378, 0.1091, 0.1454, 0.1553, 0.1593, 0.1535, 0.1215, 0.0636, 0.0367,\n",
      "         0.0179],\n",
      "        [0.0378, 0.1092, 0.1454, 0.1553, 0.1593, 0.1535, 0.1215, 0.0636, 0.0367,\n",
      "         0.0179],\n",
      "        [0.0378, 0.1092, 0.1454, 0.1553, 0.1593, 0.1535, 0.1215, 0.0636, 0.0367,\n",
      "         0.0179]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正 的 学校 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: a real school . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0348, 0.0925, 0.1231, 0.1382, 0.1435, 0.1409, 0.1361, 0.1163, 0.0666,\n",
      "         0.0080],\n",
      "        [0.0324, 0.0912, 0.1243, 0.1412, 0.1469, 0.1433, 0.1373, 0.1147, 0.0622,\n",
      "         0.0067],\n",
      "        [0.0319, 0.0908, 0.1244, 0.1417, 0.1474, 0.1437, 0.1374, 0.1144, 0.0617,\n",
      "         0.0066],\n",
      "        [0.0318, 0.0908, 0.1245, 0.1419, 0.1475, 0.1437, 0.1373, 0.1142, 0.0616,\n",
      "         0.0066],\n",
      "        [0.0319, 0.0910, 0.1246, 0.1419, 0.1475, 0.1436, 0.1372, 0.1141, 0.0615,\n",
      "         0.0066],\n",
      "        [0.0319, 0.0910, 0.1246, 0.1419, 0.1475, 0.1436, 0.1372, 0.1141, 0.0615,\n",
      "         0.0066],\n",
      "        [0.0319, 0.0911, 0.1247, 0.1420, 0.1475, 0.1436, 0.1372, 0.1141, 0.0615,\n",
      "         0.0066],\n",
      "        [0.0320, 0.0911, 0.1247, 0.1420, 0.1475, 0.1436, 0.1371, 0.1140, 0.0615,\n",
      "         0.0066],\n",
      "        [0.0320, 0.0911, 0.1247, 0.1420, 0.1475, 0.1435, 0.1371, 0.1140, 0.0615,\n",
      "         0.0066]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 11.00, Train Loss: 5.34, Val Loss: 8.64, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 通过 潜水 潜水艇 拍下 的 影片 把 我们\n",
      "Reference: with vibrant video clips captured by submarines , david\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0342, 0.0749, 0.1137, 0.1237, 0.1079, 0.1359, 0.1433, 0.1342, 0.1028,\n",
      "         0.0293],\n",
      "        [0.0318, 0.0726, 0.1143, 0.1256, 0.1088, 0.1386, 0.1462, 0.1352, 0.1006,\n",
      "         0.0262],\n",
      "        [0.0315, 0.0722, 0.1142, 0.1258, 0.1088, 0.1390, 0.1467, 0.1354, 0.1004,\n",
      "         0.0261],\n",
      "        [0.0315, 0.0722, 0.1143, 0.1258, 0.1088, 0.1390, 0.1467, 0.1353, 0.1003,\n",
      "         0.0260],\n",
      "        [0.0315, 0.0723, 0.1144, 0.1258, 0.1088, 0.1390, 0.1467, 0.1352, 0.1002,\n",
      "         0.0260],\n",
      "        [0.0316, 0.0724, 0.1144, 0.1258, 0.1087, 0.1389, 0.1466, 0.1352, 0.1002,\n",
      "         0.0260],\n",
      "        [0.0316, 0.0724, 0.1145, 0.1258, 0.1087, 0.1389, 0.1466, 0.1352, 0.1002,\n",
      "         0.0261],\n",
      "        [0.0316, 0.0725, 0.1145, 0.1258, 0.1087, 0.1389, 0.1466, 0.1351, 0.1002,\n",
      "         0.0261],\n",
      "        [0.0316, 0.0725, 0.1145, 0.1258, 0.1087, 0.1389, 0.1466, 0.1351, 0.1002,\n",
      "         0.0261]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 很 害怕 但是 我们 仍然 渴望 望去 学校 <EOS>\n",
      "Reference: we were scared , but still , school was\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0376, 0.0900, 0.1145, 0.1255, 0.1282, 0.1313, 0.1275, 0.1193, 0.0944,\n",
      "         0.0316],\n",
      "        [0.0353, 0.0889, 0.1154, 0.1276, 0.1305, 0.1338, 0.1290, 0.1193, 0.0920,\n",
      "         0.0284],\n",
      "        [0.0349, 0.0886, 0.1154, 0.1279, 0.1307, 0.1341, 0.1292, 0.1193, 0.0918,\n",
      "         0.0282],\n",
      "        [0.0349, 0.0888, 0.1155, 0.1279, 0.1307, 0.1341, 0.1291, 0.1191, 0.0917,\n",
      "         0.0282],\n",
      "        [0.0349, 0.0889, 0.1156, 0.1280, 0.1307, 0.1340, 0.1291, 0.1191, 0.0916,\n",
      "         0.0282],\n",
      "        [0.0350, 0.0889, 0.1156, 0.1280, 0.1307, 0.1340, 0.1290, 0.1190, 0.0916,\n",
      "         0.0282],\n",
      "        [0.0350, 0.0890, 0.1157, 0.1280, 0.1307, 0.1340, 0.1290, 0.1190, 0.0915,\n",
      "         0.0282],\n",
      "        [0.0350, 0.0890, 0.1157, 0.1280, 0.1307, 0.1340, 0.1290, 0.1190, 0.0915,\n",
      "         0.0282],\n",
      "        [0.0351, 0.0890, 0.1157, 0.1280, 0.1307, 0.1339, 0.1289, 0.1190, 0.0915,\n",
      "         0.0282]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12.00, Train Loss: 5.09, Val Loss: 8.64, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 当 你 站 在 海滩 上 或是 当 你 看到\n",
      "Reference: part of the problem , i think , is\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0403, 0.0961, 0.1176, 0.1247, 0.1262, 0.1287, 0.1251, 0.1209, 0.0941,\n",
      "         0.0264],\n",
      "        [0.0381, 0.0955, 0.1190, 0.1268, 0.1280, 0.1305, 0.1261, 0.1210, 0.0914,\n",
      "         0.0235],\n",
      "        [0.0378, 0.0954, 0.1193, 0.1271, 0.1282, 0.1308, 0.1262, 0.1209, 0.0910,\n",
      "         0.0233],\n",
      "        [0.0378, 0.0957, 0.1194, 0.1271, 0.1282, 0.1308, 0.1261, 0.1208, 0.0908,\n",
      "         0.0233],\n",
      "        [0.0379, 0.0958, 0.1195, 0.1271, 0.1282, 0.1307, 0.1261, 0.1207, 0.0907,\n",
      "         0.0233],\n",
      "        [0.0380, 0.0959, 0.1195, 0.1271, 0.1282, 0.1307, 0.1260, 0.1206, 0.0907,\n",
      "         0.0233],\n",
      "        [0.0381, 0.0959, 0.1195, 0.1271, 0.1282, 0.1306, 0.1260, 0.1206, 0.0907,\n",
      "         0.0233],\n",
      "        [0.0381, 0.0960, 0.1195, 0.1271, 0.1282, 0.1306, 0.1260, 0.1206, 0.0907,\n",
      "         0.0233],\n",
      "        [0.0381, 0.0960, 0.1195, 0.1271, 0.1282, 0.1306, 0.1259, 0.1206, 0.0907,\n",
      "         0.0233]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他们 知道 我们 的 住处 吗 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: do they know where we live ? <EOS> <PAD>\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0117, 0.0286, 0.0723, 0.0994, 0.1131, 0.1676, 0.1763, 0.1665, 0.1284,\n",
      "         0.0360],\n",
      "        [0.0106, 0.0260, 0.0690, 0.0971, 0.1115, 0.1723, 0.1823, 0.1704, 0.1278,\n",
      "         0.0329],\n",
      "        [0.0106, 0.0259, 0.0687, 0.0969, 0.1109, 0.1727, 0.1830, 0.1708, 0.1277,\n",
      "         0.0329],\n",
      "        [0.0106, 0.0259, 0.0688, 0.0969, 0.1109, 0.1728, 0.1830, 0.1707, 0.1275,\n",
      "         0.0329],\n",
      "        [0.0106, 0.0259, 0.0689, 0.0970, 0.1109, 0.1729, 0.1830, 0.1706, 0.1274,\n",
      "         0.0329],\n",
      "        [0.0106, 0.0260, 0.0689, 0.0970, 0.1109, 0.1729, 0.1830, 0.1705, 0.1274,\n",
      "         0.0329],\n",
      "        [0.0106, 0.0260, 0.0690, 0.0970, 0.1109, 0.1729, 0.1829, 0.1704, 0.1273,\n",
      "         0.0329],\n",
      "        [0.0106, 0.0260, 0.0690, 0.0970, 0.1109, 0.1728, 0.1829, 0.1704, 0.1273,\n",
      "         0.0329],\n",
      "        [0.0106, 0.0260, 0.0690, 0.0970, 0.1109, 0.1728, 0.1829, 0.1704, 0.1273,\n",
      "         0.0329]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 13.00, Train Loss: 4.89, Val Loss: 8.69, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分 部分 的 动物 也 都 生活 在 海洋\n",
      "Reference: most of the animals are in the oceans .\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0344, 0.0881, 0.1147, 0.1265, 0.1279, 0.1319, 0.1307, 0.1220, 0.0966,\n",
      "         0.0272],\n",
      "        [0.0325, 0.0866, 0.1153, 0.1283, 0.1299, 0.1340, 0.1323, 0.1221, 0.0944,\n",
      "         0.0247],\n",
      "        [0.0322, 0.0865, 0.1155, 0.1287, 0.1302, 0.1343, 0.1325, 0.1219, 0.0938,\n",
      "         0.0244],\n",
      "        [0.0323, 0.0867, 0.1157, 0.1288, 0.1302, 0.1343, 0.1324, 0.1217, 0.0936,\n",
      "         0.0243],\n",
      "        [0.0324, 0.0869, 0.1158, 0.1288, 0.1302, 0.1342, 0.1323, 0.1216, 0.0935,\n",
      "         0.0243],\n",
      "        [0.0325, 0.0870, 0.1159, 0.1288, 0.1301, 0.1342, 0.1323, 0.1215, 0.0935,\n",
      "         0.0243],\n",
      "        [0.0325, 0.0870, 0.1159, 0.1288, 0.1301, 0.1341, 0.1322, 0.1215, 0.0934,\n",
      "         0.0244],\n",
      "        [0.0325, 0.0871, 0.1159, 0.1288, 0.1301, 0.1341, 0.1322, 0.1215, 0.0934,\n",
      "         0.0244],\n",
      "        [0.0326, 0.0871, 0.1159, 0.1288, 0.1301, 0.1341, 0.1322, 0.1214, 0.0934,\n",
      "         0.0244]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 那 就是 她 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: there she is . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[4.3999e-02, 1.1214e-01, 1.4346e-01, 1.5552e-01, 1.5776e-01, 1.5364e-01,\n",
      "         1.4089e-01, 8.5014e-02, 7.5887e-03, 3.2318e-11],\n",
      "        [4.1689e-02, 1.1120e-01, 1.4514e-01, 1.5823e-01, 1.6032e-01, 1.5515e-01,\n",
      "         1.4049e-01, 8.1153e-02, 6.6282e-03, 1.4553e-10],\n",
      "        [4.1349e-02, 1.1121e-01, 1.4553e-01, 1.5868e-01, 1.6066e-01, 1.5523e-01,\n",
      "         1.4018e-01, 8.0542e-02, 6.6252e-03, 1.7224e-10],\n",
      "        [4.1436e-02, 1.1149e-01, 1.4574e-01, 1.5876e-01, 1.6063e-01, 1.5510e-01,\n",
      "         1.3994e-01, 8.0316e-02, 6.5999e-03, 1.6622e-10],\n",
      "        [4.1544e-02, 1.1168e-01, 1.4584e-01, 1.5876e-01, 1.6057e-01, 1.5499e-01,\n",
      "         1.3980e-01, 8.0235e-02, 6.5902e-03, 1.5930e-10],\n",
      "        [4.1641e-02, 1.1180e-01, 1.4588e-01, 1.5874e-01, 1.6051e-01, 1.5491e-01,\n",
      "         1.3972e-01, 8.0222e-02, 6.5970e-03, 1.5433e-10],\n",
      "        [4.1709e-02, 1.1187e-01, 1.4589e-01, 1.5872e-01, 1.6046e-01, 1.5485e-01,\n",
      "         1.3967e-01, 8.0224e-02, 6.6059e-03, 1.5119e-10],\n",
      "        [4.1754e-02, 1.1191e-01, 1.4590e-01, 1.5870e-01, 1.6044e-01, 1.5482e-01,\n",
      "         1.3963e-01, 8.0225e-02, 6.6129e-03, 1.4920e-10],\n",
      "        [4.1783e-02, 1.1194e-01, 1.4591e-01, 1.5870e-01, 1.6042e-01, 1.5480e-01,\n",
      "         1.3961e-01, 8.0223e-02, 6.6173e-03, 1.4784e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 14.00, Train Loss: 4.72, Val Loss: 8.76, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 当 你 站 在 海滩 上 或是 当 你 看到\n",
      "Reference: part of the problem , i think , is\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0424, 0.0968, 0.1166, 0.1233, 0.1245, 0.1267, 0.1234, 0.1203, 0.0977,\n",
      "         0.0284],\n",
      "        [0.0407, 0.0965, 0.1179, 0.1249, 0.1260, 0.1281, 0.1242, 0.1203, 0.0956,\n",
      "         0.0259],\n",
      "        [0.0405, 0.0966, 0.1182, 0.1252, 0.1262, 0.1283, 0.1242, 0.1201, 0.0949,\n",
      "         0.0257],\n",
      "        [0.0406, 0.0969, 0.1184, 0.1253, 0.1262, 0.1283, 0.1241, 0.1199, 0.0947,\n",
      "         0.0256],\n",
      "        [0.0407, 0.0971, 0.1185, 0.1253, 0.1262, 0.1283, 0.1240, 0.1198, 0.0946,\n",
      "         0.0255],\n",
      "        [0.0408, 0.0972, 0.1185, 0.1253, 0.1261, 0.1282, 0.1240, 0.1198, 0.0945,\n",
      "         0.0256],\n",
      "        [0.0409, 0.0973, 0.1186, 0.1253, 0.1261, 0.1282, 0.1239, 0.1197, 0.0945,\n",
      "         0.0256],\n",
      "        [0.0409, 0.0973, 0.1186, 0.1253, 0.1261, 0.1281, 0.1239, 0.1197, 0.0945,\n",
      "         0.0256],\n",
      "        [0.0410, 0.0974, 0.1186, 0.1252, 0.1261, 0.1281, 0.1239, 0.1197, 0.0945,\n",
      "         0.0256]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班 走 了 父亲 大声 叫 着 <EOS> <PAD>\n",
      "Reference: &quot; the taliban are gone ! &quot; my father\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0388, 0.0960, 0.1178, 0.1238, 0.1269, 0.1288, 0.1276, 0.1200, 0.0931,\n",
      "         0.0271],\n",
      "        [0.0372, 0.0957, 0.1192, 0.1254, 0.1286, 0.1302, 0.1285, 0.1197, 0.0907,\n",
      "         0.0249],\n",
      "        [0.0369, 0.0959, 0.1196, 0.1258, 0.1288, 0.1304, 0.1285, 0.1194, 0.0900,\n",
      "         0.0246],\n",
      "        [0.0370, 0.0962, 0.1198, 0.1259, 0.1289, 0.1304, 0.1284, 0.1192, 0.0897,\n",
      "         0.0245],\n",
      "        [0.0372, 0.0964, 0.1199, 0.1259, 0.1288, 0.1303, 0.1284, 0.1191, 0.0896,\n",
      "         0.0245],\n",
      "        [0.0373, 0.0965, 0.1199, 0.1259, 0.1288, 0.1303, 0.1283, 0.1190, 0.0896,\n",
      "         0.0245],\n",
      "        [0.0373, 0.0965, 0.1200, 0.1259, 0.1288, 0.1302, 0.1282, 0.1190, 0.0895,\n",
      "         0.0245],\n",
      "        [0.0374, 0.0966, 0.1200, 0.1259, 0.1288, 0.1302, 0.1282, 0.1190, 0.0895,\n",
      "         0.0246],\n",
      "        [0.0374, 0.0966, 0.1200, 0.1259, 0.1287, 0.1302, 0.1282, 0.1189, 0.0895,\n",
      "         0.0246]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 15.00, Train Loss: 4.59, Val Loss: 8.86, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 是 我 最 喜欢 的 因为 它 哪 都 能动\n",
      "Reference: it &apos;s one of my favorites , because it\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0454, 0.1031, 0.1244, 0.1307, 0.1335, 0.1323, 0.1312, 0.1212, 0.0730,\n",
      "         0.0052],\n",
      "        [0.0439, 0.1030, 0.1255, 0.1321, 0.1351, 0.1335, 0.1319, 0.1205, 0.0698,\n",
      "         0.0047],\n",
      "        [0.0437, 0.1032, 0.1259, 0.1324, 0.1354, 0.1336, 0.1318, 0.1200, 0.0691,\n",
      "         0.0047],\n",
      "        [0.0439, 0.1035, 0.1261, 0.1325, 0.1354, 0.1336, 0.1317, 0.1197, 0.0688,\n",
      "         0.0047],\n",
      "        [0.0440, 0.1037, 0.1262, 0.1325, 0.1354, 0.1335, 0.1316, 0.1196, 0.0687,\n",
      "         0.0047],\n",
      "        [0.0442, 0.1039, 0.1263, 0.1325, 0.1353, 0.1334, 0.1316, 0.1195, 0.0687,\n",
      "         0.0047],\n",
      "        [0.0442, 0.1039, 0.1263, 0.1325, 0.1353, 0.1334, 0.1315, 0.1195, 0.0687,\n",
      "         0.0047],\n",
      "        [0.0443, 0.1040, 0.1263, 0.1325, 0.1353, 0.1334, 0.1315, 0.1194, 0.0687,\n",
      "         0.0047],\n",
      "        [0.0443, 0.1040, 0.1263, 0.1325, 0.1352, 0.1334, 0.1315, 0.1194, 0.0687,\n",
      "         0.0047]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他们 知道 我们 的 住处 吗 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: do they know where we live ? <EOS> <PAD>\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0158, 0.0429, 0.0925, 0.1134, 0.1210, 0.1524, 0.1555, 0.1485, 0.1216,\n",
      "         0.0362],\n",
      "        [0.0151, 0.0406, 0.0904, 0.1123, 0.1204, 0.1555, 0.1592, 0.1509, 0.1214,\n",
      "         0.0342],\n",
      "        [0.0150, 0.0405, 0.0902, 0.1121, 0.1200, 0.1560, 0.1598, 0.1512, 0.1211,\n",
      "         0.0341],\n",
      "        [0.0150, 0.0405, 0.0903, 0.1122, 0.1199, 0.1562, 0.1599, 0.1511, 0.1208,\n",
      "         0.0340],\n",
      "        [0.0151, 0.0406, 0.0904, 0.1123, 0.1199, 0.1563, 0.1598, 0.1510, 0.1207,\n",
      "         0.0340],\n",
      "        [0.0151, 0.0407, 0.0905, 0.1123, 0.1200, 0.1563, 0.1598, 0.1508, 0.1206,\n",
      "         0.0340],\n",
      "        [0.0151, 0.0408, 0.0906, 0.1124, 0.1200, 0.1562, 0.1597, 0.1508, 0.1205,\n",
      "         0.0340],\n",
      "        [0.0152, 0.0408, 0.0906, 0.1124, 0.1200, 0.1562, 0.1596, 0.1507, 0.1205,\n",
      "         0.0340],\n",
      "        [0.0152, 0.0408, 0.0906, 0.1124, 0.1200, 0.1562, 0.1596, 0.1507, 0.1204,\n",
      "         0.0340]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16.00, Train Loss: 4.48, Val Loss: 8.99, Train BLEU: 0.32, Val BLEU: 0.20\n",
      "Sampling from training predictions...\n",
      "Source: 其实 它们 都 是 由 单独 的 动物 结合 合在\n",
      "Reference: these are all individual animals banding together to make\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0431, 0.1005, 0.1242, 0.1331, 0.1361, 0.1339, 0.1323, 0.1177, 0.0716,\n",
      "         0.0077],\n",
      "        [0.0417, 0.1000, 0.1251, 0.1345, 0.1376, 0.1350, 0.1330, 0.1169, 0.0690,\n",
      "         0.0071],\n",
      "        [0.0415, 0.1003, 0.1256, 0.1349, 0.1379, 0.1351, 0.1329, 0.1163, 0.0683,\n",
      "         0.0072],\n",
      "        [0.0417, 0.1006, 0.1258, 0.1350, 0.1379, 0.1351, 0.1327, 0.1160, 0.0681,\n",
      "         0.0072],\n",
      "        [0.0418, 0.1008, 0.1259, 0.1350, 0.1379, 0.1350, 0.1326, 0.1159, 0.0680,\n",
      "         0.0072],\n",
      "        [0.0420, 0.1010, 0.1260, 0.1350, 0.1378, 0.1349, 0.1325, 0.1158, 0.0679,\n",
      "         0.0072],\n",
      "        [0.0421, 0.1011, 0.1260, 0.1350, 0.1378, 0.1349, 0.1324, 0.1157, 0.0679,\n",
      "         0.0072],\n",
      "        [0.0421, 0.1012, 0.1260, 0.1350, 0.1378, 0.1348, 0.1324, 0.1157, 0.0679,\n",
      "         0.0072],\n",
      "        [0.0422, 0.1012, 0.1260, 0.1350, 0.1378, 0.1348, 0.1324, 0.1156, 0.0679,\n",
      "         0.0072]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 有时 学校 <UNK> 突然 <UNK> 一周 因为 被 塔利 塔利班\n",
      "Reference: from time to time , the school would suddenly\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0432, 0.0946, 0.1136, 0.1195, 0.1239, 0.1239, 0.1230, 0.1190, 0.1021,\n",
      "         0.0372],\n",
      "        [0.0419, 0.0945, 0.1144, 0.1205, 0.1250, 0.1249, 0.1237, 0.1191, 0.1009,\n",
      "         0.0352],\n",
      "        [0.0417, 0.0947, 0.1147, 0.1208, 0.1253, 0.1250, 0.1237, 0.1189, 0.1003,\n",
      "         0.0349],\n",
      "        [0.0419, 0.0950, 0.1149, 0.1208, 0.1253, 0.1249, 0.1236, 0.1187, 0.1000,\n",
      "         0.0348],\n",
      "        [0.0421, 0.0952, 0.1150, 0.1208, 0.1253, 0.1249, 0.1235, 0.1186, 0.0998,\n",
      "         0.0348],\n",
      "        [0.0422, 0.0954, 0.1150, 0.1208, 0.1252, 0.1248, 0.1235, 0.1185, 0.0998,\n",
      "         0.0347],\n",
      "        [0.0423, 0.0954, 0.1151, 0.1208, 0.1252, 0.1248, 0.1234, 0.1185, 0.0997,\n",
      "         0.0347],\n",
      "        [0.0424, 0.0955, 0.1151, 0.1208, 0.1252, 0.1248, 0.1234, 0.1184, 0.0997,\n",
      "         0.0348],\n",
      "        [0.0424, 0.0955, 0.1151, 0.1208, 0.1252, 0.1248, 0.1234, 0.1184, 0.0997,\n",
      "         0.0348]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 17.00, Train Loss: 4.40, Val Loss: 9.12, Train BLEU: 0.33, Val BLEU: 0.21\n",
      "Sampling from training predictions...\n",
      "Source: 其实 它们 都 是 由 单独 的 动物 结合 合在\n",
      "Reference: these are all individual animals banding together to make\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0442, 0.1003, 0.1230, 0.1318, 0.1351, 0.1332, 0.1317, 0.1184, 0.0743,\n",
      "         0.0080],\n",
      "        [0.0430, 0.0999, 0.1238, 0.1330, 0.1363, 0.1341, 0.1323, 0.1179, 0.0722,\n",
      "         0.0076],\n",
      "        [0.0429, 0.1002, 0.1242, 0.1333, 0.1365, 0.1342, 0.1321, 0.1173, 0.0716,\n",
      "         0.0077],\n",
      "        [0.0431, 0.1005, 0.1244, 0.1334, 0.1365, 0.1341, 0.1319, 0.1170, 0.0714,\n",
      "         0.0077],\n",
      "        [0.0433, 0.1008, 0.1245, 0.1334, 0.1364, 0.1340, 0.1318, 0.1168, 0.0712,\n",
      "         0.0077],\n",
      "        [0.0434, 0.1009, 0.1246, 0.1334, 0.1364, 0.1339, 0.1317, 0.1167, 0.0712,\n",
      "         0.0077],\n",
      "        [0.0435, 0.1010, 0.1246, 0.1334, 0.1364, 0.1339, 0.1317, 0.1166, 0.0711,\n",
      "         0.0077],\n",
      "        [0.0435, 0.1011, 0.1247, 0.1334, 0.1364, 0.1339, 0.1317, 0.1166, 0.0711,\n",
      "         0.0077],\n",
      "        [0.0436, 0.1011, 0.1247, 0.1334, 0.1364, 0.1339, 0.1316, 0.1166, 0.0711,\n",
      "         0.0077]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在 可以 去 个 真正 的 学校 念书 了\n",
      "Reference: &quot; you can go to a real school now\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0353, 0.0713, 0.0952, 0.1126, 0.1320, 0.1364, 0.1371, 0.1338, 0.1113,\n",
      "         0.0350],\n",
      "        [0.0343, 0.0688, 0.0933, 0.1120, 0.1335, 0.1386, 0.1392, 0.1353, 0.1112,\n",
      "         0.0338],\n",
      "        [0.0342, 0.0687, 0.0933, 0.1121, 0.1338, 0.1390, 0.1394, 0.1352, 0.1107,\n",
      "         0.0337],\n",
      "        [0.0343, 0.0688, 0.0934, 0.1122, 0.1340, 0.1390, 0.1393, 0.1350, 0.1104,\n",
      "         0.0336],\n",
      "        [0.0345, 0.0690, 0.0935, 0.1123, 0.1341, 0.1390, 0.1392, 0.1348, 0.1102,\n",
      "         0.0335],\n",
      "        [0.0345, 0.0691, 0.0935, 0.1124, 0.1341, 0.1390, 0.1392, 0.1347, 0.1100,\n",
      "         0.0335],\n",
      "        [0.0346, 0.0691, 0.0935, 0.1124, 0.1341, 0.1390, 0.1392, 0.1347, 0.1100,\n",
      "         0.0334],\n",
      "        [0.0346, 0.0692, 0.0936, 0.1124, 0.1341, 0.1390, 0.1391, 0.1346, 0.1099,\n",
      "         0.0334],\n",
      "        [0.0347, 0.0692, 0.0936, 0.1124, 0.1341, 0.1389, 0.1391, 0.1346, 0.1099,\n",
      "         0.0334]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 18.00, Train Loss: 4.34, Val Loss: 9.27, Train BLEU: 0.36, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 当 你 站 在 海滩 上 或是 当 你 看到\n",
      "Reference: part of the problem , i think , is\n",
      "Model: <SOS> it the the the the the the , ,\n",
      "Attention Weights: tensor([[0.0461, 0.0956, 0.1137, 0.1205, 0.1228, 0.1247, 0.1220, 0.1191, 0.1019,\n",
      "         0.0336],\n",
      "        [0.0452, 0.0956, 0.1143, 0.1212, 0.1234, 0.1253, 0.1224, 0.1191, 0.1011,\n",
      "         0.0325],\n",
      "        [0.0450, 0.0958, 0.1146, 0.1214, 0.1235, 0.1254, 0.1223, 0.1189, 0.1007,\n",
      "         0.0324],\n",
      "        [0.0454, 0.0961, 0.1148, 0.1215, 0.1234, 0.1253, 0.1221, 0.1187, 0.1003,\n",
      "         0.0324],\n",
      "        [0.0456, 0.0964, 0.1149, 0.1215, 0.1234, 0.1252, 0.1220, 0.1186, 0.1001,\n",
      "         0.0323],\n",
      "        [0.0457, 0.0965, 0.1149, 0.1215, 0.1234, 0.1252, 0.1220, 0.1185, 0.1000,\n",
      "         0.0323],\n",
      "        [0.0458, 0.0966, 0.1150, 0.1215, 0.1234, 0.1251, 0.1219, 0.1184, 0.1000,\n",
      "         0.0322],\n",
      "        [0.0458, 0.0966, 0.1150, 0.1215, 0.1234, 0.1251, 0.1219, 0.1184, 0.0999,\n",
      "         0.0322],\n",
      "        [0.0459, 0.0967, 0.1150, 0.1215, 0.1234, 0.1251, 0.1219, 0.1184, 0.0999,\n",
      "         0.0322]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在 一个 房屋 房屋里 屋里 我们 100 多 人\n",
      "Reference: the school was in a house , more than\n",
      "Model: <SOS> it the the the the the the , ,\n",
      "Attention Weights: tensor([[0.0376, 0.0731, 0.1105, 0.1237, 0.1293, 0.1304, 0.1300, 0.1255, 0.1056,\n",
      "         0.0343],\n",
      "        [0.0368, 0.0715, 0.1103, 0.1243, 0.1304, 0.1313, 0.1308, 0.1261, 0.1053,\n",
      "         0.0333],\n",
      "        [0.0366, 0.0714, 0.1106, 0.1246, 0.1306, 0.1314, 0.1308, 0.1259, 0.1048,\n",
      "         0.0333],\n",
      "        [0.0369, 0.0718, 0.1109, 0.1247, 0.1306, 0.1313, 0.1305, 0.1256, 0.1045,\n",
      "         0.0333],\n",
      "        [0.0370, 0.0720, 0.1112, 0.1248, 0.1306, 0.1312, 0.1304, 0.1255, 0.1042,\n",
      "         0.0332],\n",
      "        [0.0371, 0.0722, 0.1113, 0.1248, 0.1306, 0.1311, 0.1303, 0.1254, 0.1041,\n",
      "         0.0331],\n",
      "        [0.0372, 0.0722, 0.1113, 0.1248, 0.1306, 0.1311, 0.1303, 0.1253, 0.1040,\n",
      "         0.0331],\n",
      "        [0.0372, 0.0723, 0.1114, 0.1248, 0.1306, 0.1311, 0.1303, 0.1253, 0.1040,\n",
      "         0.0331],\n",
      "        [0.0372, 0.0723, 0.1114, 0.1248, 0.1305, 0.1311, 0.1303, 0.1253, 0.1040,\n",
      "         0.0331]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 19.00, Train Loss: 4.30, Val Loss: 9.41, Train BLEU: 3.00, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 原来 它 是 海洋 洋中 最长 的 生物 <EOS> <PAD>\n",
      "Reference: this turns out to be the longest creature in\n",
      "Model: <SOS> it &apos;s the the the the , , ,\n",
      "Attention Weights: tensor([[5.4528e-02, 1.1930e-01, 1.4331e-01, 1.4991e-01, 1.4464e-01, 1.5064e-01,\n",
      "         1.4113e-01, 8.9517e-02, 7.0216e-03, 8.0159e-12],\n",
      "        [5.3501e-02, 1.1943e-01, 1.4412e-01, 1.5071e-01, 1.4425e-01, 1.5106e-01,\n",
      "         1.4122e-01, 8.8608e-02, 7.1140e-03, 5.9855e-11],\n",
      "        [5.3230e-02, 1.1966e-01, 1.4447e-01, 1.5091e-01, 1.4399e-01, 1.5103e-01,\n",
      "         1.4108e-01, 8.8355e-02, 7.2769e-03, 8.5329e-11],\n",
      "        [5.3658e-02, 1.2014e-01, 1.4462e-01, 1.5083e-01, 1.4380e-01, 1.5081e-01,\n",
      "         1.4073e-01, 8.8080e-02, 7.3412e-03, 8.8677e-11],\n",
      "        [5.3910e-02, 1.2045e-01, 1.4472e-01, 1.5078e-01, 1.4373e-01, 1.5073e-01,\n",
      "         1.4052e-01, 8.7833e-02, 7.3193e-03, 8.7850e-11],\n",
      "        [5.4028e-02, 1.2060e-01, 1.4478e-01, 1.5076e-01, 1.4370e-01, 1.5069e-01,\n",
      "         1.4043e-01, 8.7705e-02, 7.2972e-03, 8.5933e-11],\n",
      "        [5.4104e-02, 1.2069e-01, 1.4481e-01, 1.5075e-01, 1.4368e-01, 1.5067e-01,\n",
      "         1.4037e-01, 8.7644e-02, 7.2894e-03, 8.4281e-11],\n",
      "        [5.4163e-02, 1.2075e-01, 1.4483e-01, 1.5073e-01, 1.4366e-01, 1.5064e-01,\n",
      "         1.4033e-01, 8.7613e-02, 7.2885e-03, 8.2959e-11],\n",
      "        [5.4204e-02, 1.2079e-01, 1.4484e-01, 1.5072e-01, 1.4364e-01, 1.5062e-01,\n",
      "         1.4030e-01, 8.7596e-02, 7.2891e-03, 8.1962e-11]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 不知 知道 那 意味 意味着 什么 但是 我 能\n",
      "Reference: i didn &apos;t know what it meant , but\n",
      "Model: <SOS> it the the the the the the , ,\n",
      "Attention Weights: tensor([[0.0468, 0.1010, 0.1210, 0.1290, 0.1332, 0.1331, 0.1273, 0.1019, 0.0761,\n",
      "         0.0305],\n",
      "        [0.0461, 0.1013, 0.1219, 0.1299, 0.1341, 0.1341, 0.1279, 0.1001, 0.0747,\n",
      "         0.0299],\n",
      "        [0.0459, 0.1015, 0.1223, 0.1302, 0.1343, 0.1342, 0.1276, 0.0996, 0.0743,\n",
      "         0.0301],\n",
      "        [0.0463, 0.1020, 0.1225, 0.1302, 0.1342, 0.1340, 0.1272, 0.0993, 0.0741,\n",
      "         0.0301],\n",
      "        [0.0465, 0.1023, 0.1227, 0.1303, 0.1342, 0.1339, 0.1270, 0.0991, 0.0740,\n",
      "         0.0301],\n",
      "        [0.0467, 0.1025, 0.1227, 0.1303, 0.1342, 0.1338, 0.1269, 0.0990, 0.0739,\n",
      "         0.0300],\n",
      "        [0.0467, 0.1026, 0.1228, 0.1303, 0.1342, 0.1338, 0.1269, 0.0989, 0.0738,\n",
      "         0.0300],\n",
      "        [0.0468, 0.1026, 0.1228, 0.1303, 0.1341, 0.1338, 0.1269, 0.0989, 0.0738,\n",
      "         0.0300],\n",
      "        [0.0468, 0.1027, 0.1228, 0.1303, 0.1341, 0.1338, 0.1268, 0.0988, 0.0738,\n",
      "         0.0300]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20.00, Train Loss: 4.26, Val Loss: 9.56, Train BLEU: 6.11, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分 部分 的 动物 也 都 生活 在 海洋\n",
      "Reference: most of the animals are in the oceans .\n",
      "Model: <SOS> it the the the the the , , ,\n",
      "Attention Weights: tensor([[0.0426, 0.0916, 0.1116, 0.1208, 0.1234, 0.1261, 0.1249, 0.1196, 0.1034,\n",
      "         0.0360],\n",
      "        [0.0419, 0.0911, 0.1117, 0.1211, 0.1238, 0.1265, 0.1253, 0.1197, 0.1032,\n",
      "         0.0357],\n",
      "        [0.0415, 0.0910, 0.1118, 0.1213, 0.1239, 0.1266, 0.1253, 0.1196, 0.1032,\n",
      "         0.0360],\n",
      "        [0.0419, 0.0914, 0.1120, 0.1213, 0.1238, 0.1264, 0.1251, 0.1193, 0.1028,\n",
      "         0.0360],\n",
      "        [0.0421, 0.0916, 0.1121, 0.1214, 0.1238, 0.1264, 0.1250, 0.1191, 0.1026,\n",
      "         0.0359],\n",
      "        [0.0422, 0.0918, 0.1122, 0.1214, 0.1238, 0.1263, 0.1250, 0.1191, 0.1025,\n",
      "         0.0358],\n",
      "        [0.0422, 0.0918, 0.1122, 0.1214, 0.1238, 0.1263, 0.1250, 0.1190, 0.1024,\n",
      "         0.0358],\n",
      "        [0.0423, 0.0919, 0.1122, 0.1214, 0.1238, 0.1263, 0.1249, 0.1190, 0.1024,\n",
      "         0.0358],\n",
      "        [0.0423, 0.0919, 0.1123, 0.1214, 0.1238, 0.1263, 0.1249, 0.1190, 0.1024,\n",
      "         0.0358]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 很 害怕 但是 我们 仍然 渴望 望去 学校 <EOS>\n",
      "Reference: we were scared , but still , school was\n",
      "Model: <SOS> it &apos;s the the the the . , ,\n",
      "Attention Weights: tensor([[0.0466, 0.0928, 0.1111, 0.1192, 0.1220, 0.1238, 0.1219, 0.1172, 0.1034,\n",
      "         0.0419],\n",
      "        [0.0460, 0.0926, 0.1112, 0.1195, 0.1223, 0.1242, 0.1221, 0.1173, 0.1032,\n",
      "         0.0416],\n",
      "        [0.0457, 0.0926, 0.1113, 0.1196, 0.1223, 0.1242, 0.1221, 0.1172, 0.1032,\n",
      "         0.0419],\n",
      "        [0.0461, 0.0929, 0.1114, 0.1196, 0.1223, 0.1241, 0.1219, 0.1170, 0.1029,\n",
      "         0.0419],\n",
      "        [0.0463, 0.0932, 0.1115, 0.1196, 0.1222, 0.1240, 0.1218, 0.1168, 0.1027,\n",
      "         0.0418],\n",
      "        [0.0464, 0.0933, 0.1116, 0.1196, 0.1222, 0.1240, 0.1218, 0.1168, 0.1026,\n",
      "         0.0417],\n",
      "        [0.0464, 0.0934, 0.1116, 0.1196, 0.1222, 0.1240, 0.1217, 0.1167, 0.1026,\n",
      "         0.0417],\n",
      "        [0.0465, 0.0934, 0.1117, 0.1196, 0.1222, 0.1240, 0.1217, 0.1167, 0.1025,\n",
      "         0.0417],\n",
      "        [0.0465, 0.0934, 0.1117, 0.1196, 0.1222, 0.1239, 0.1217, 0.1167, 0.1025,\n",
      "         0.0417]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 21.00, Train Loss: 4.24, Val Loss: 9.71, Train BLEU: 7.45, Val BLEU: 1.04\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分 部分 的 动物 也 都 生活 在 海洋\n",
      "Reference: most of the animals are in the oceans .\n",
      "Model: <SOS> it &apos;s the the the the , , ,\n",
      "Attention Weights: tensor([[0.0435, 0.0914, 0.1110, 0.1202, 0.1232, 0.1258, 0.1246, 0.1194, 0.1038,\n",
      "         0.0372],\n",
      "        [0.0429, 0.0909, 0.1110, 0.1204, 0.1234, 0.1261, 0.1248, 0.1195, 0.1038,\n",
      "         0.0372],\n",
      "        [0.0425, 0.0906, 0.1110, 0.1205, 0.1235, 0.1261, 0.1249, 0.1195, 0.1038,\n",
      "         0.0376],\n",
      "        [0.0428, 0.0910, 0.1112, 0.1206, 0.1234, 0.1260, 0.1247, 0.1192, 0.1035,\n",
      "         0.0377],\n",
      "        [0.0430, 0.0912, 0.1113, 0.1206, 0.1234, 0.1259, 0.1246, 0.1190, 0.1033,\n",
      "         0.0376],\n",
      "        [0.0431, 0.0914, 0.1114, 0.1206, 0.1234, 0.1259, 0.1246, 0.1190, 0.1032,\n",
      "         0.0375],\n",
      "        [0.0432, 0.0914, 0.1114, 0.1206, 0.1234, 0.1259, 0.1245, 0.1189, 0.1032,\n",
      "         0.0375],\n",
      "        [0.0432, 0.0915, 0.1114, 0.1206, 0.1234, 0.1259, 0.1245, 0.1189, 0.1032,\n",
      "         0.0375],\n",
      "        [0.0432, 0.0915, 0.1114, 0.1206, 0.1234, 0.1258, 0.1245, 0.1189, 0.1031,\n",
      "         0.0375]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 出身 阿富汗 边远 <UNK> 地区 有着 与 他人 不同\n",
      "Reference: a total maverick from a remote province of afghanistan\n",
      "Model: <SOS> it &apos;s the the the the , , ,\n",
      "Attention Weights: tensor([[5.6623e-02, 1.1800e-01, 1.4114e-01, 1.4876e-01, 1.4485e-01, 1.4983e-01,\n",
      "         1.4090e-01, 9.2808e-02, 7.0956e-03, 5.4235e-12],\n",
      "        [5.5822e-02, 1.1794e-01, 1.4152e-01, 1.4916e-01, 1.4429e-01, 1.4993e-01,\n",
      "         1.4110e-01, 9.2732e-02, 7.5000e-03, 4.4428e-11],\n",
      "        [5.5392e-02, 1.1801e-01, 1.4175e-01, 1.4928e-01, 1.4390e-01, 1.4993e-01,\n",
      "         1.4115e-01, 9.2807e-02, 7.7838e-03, 6.9433e-11],\n",
      "        [5.5794e-02, 1.1842e-01, 1.4189e-01, 1.4918e-01, 1.4362e-01, 1.4972e-01,\n",
      "         1.4086e-01, 9.2612e-02, 7.9053e-03, 7.7828e-11],\n",
      "        [5.6048e-02, 1.1868e-01, 1.4196e-01, 1.4912e-01, 1.4356e-01, 1.4965e-01,\n",
      "         1.4069e-01, 9.2391e-02, 7.8949e-03, 7.7232e-11],\n",
      "        [5.6152e-02, 1.1880e-01, 1.4200e-01, 1.4910e-01, 1.4355e-01, 1.4964e-01,\n",
      "         1.4062e-01, 9.2270e-02, 7.8706e-03, 7.5805e-11],\n",
      "        [5.6224e-02, 1.1887e-01, 1.4201e-01, 1.4908e-01, 1.4354e-01, 1.4962e-01,\n",
      "         1.4057e-01, 9.2218e-02, 7.8636e-03, 7.4675e-11],\n",
      "        [5.6277e-02, 1.1891e-01, 1.4202e-01, 1.4906e-01, 1.4353e-01, 1.4960e-01,\n",
      "         1.4054e-01, 9.2196e-02, 7.8638e-03, 7.3796e-11],\n",
      "        [5.6310e-02, 1.1894e-01, 1.4202e-01, 1.4904e-01, 1.4353e-01, 1.4959e-01,\n",
      "         1.4052e-01, 9.2189e-02, 7.8653e-03, 7.3121e-11]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 22.00, Train Loss: 4.22, Val Loss: 9.85, Train BLEU: 7.45, Val BLEU: 1.04\n",
      "Sampling from training predictions...\n",
      "Source: 当 你 站 在 海滩 上 或是 当 你 看到\n",
      "Reference: part of the problem , i think , is\n",
      "Model: <SOS> it &apos;s the the the the , , ,\n",
      "Attention Weights: tensor([[0.0492, 0.0937, 0.1109, 0.1184, 0.1220, 0.1237, 0.1218, 0.1185, 0.1036,\n",
      "         0.0383],\n",
      "        [0.0489, 0.0937, 0.1111, 0.1186, 0.1219, 0.1237, 0.1217, 0.1185, 0.1035,\n",
      "         0.0384],\n",
      "        [0.0484, 0.0935, 0.1111, 0.1186, 0.1219, 0.1237, 0.1217, 0.1185, 0.1037,\n",
      "         0.0389],\n",
      "        [0.0487, 0.0938, 0.1112, 0.1186, 0.1218, 0.1236, 0.1215, 0.1183, 0.1034,\n",
      "         0.0391],\n",
      "        [0.0489, 0.0940, 0.1113, 0.1186, 0.1218, 0.1235, 0.1214, 0.1182, 0.1033,\n",
      "         0.0390],\n",
      "        [0.0490, 0.0941, 0.1113, 0.1186, 0.1217, 0.1235, 0.1214, 0.1182, 0.1032,\n",
      "         0.0390],\n",
      "        [0.0491, 0.0941, 0.1113, 0.1186, 0.1217, 0.1235, 0.1214, 0.1182, 0.1032,\n",
      "         0.0389],\n",
      "        [0.0491, 0.0942, 0.1113, 0.1186, 0.1217, 0.1235, 0.1213, 0.1181, 0.1032,\n",
      "         0.0389],\n",
      "        [0.0492, 0.0942, 0.1114, 0.1186, 0.1217, 0.1235, 0.1213, 0.1181, 0.1032,\n",
      "         0.0389]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 但是 我 那 受过 教育 的 母亲 成为 为了 一名\n",
      "Reference: but my educated mother became a teacher . <EOS>\n",
      "Model: <SOS> it &apos;s the the the the , , ,\n",
      "Attention Weights: tensor([[7.5126e-02, 1.4128e-01, 1.6609e-01, 1.6589e-01, 1.6441e-01, 1.6180e-01,\n",
      "         1.1708e-01, 8.3223e-03, 5.4579e-12, 5.4579e-12],\n",
      "        [7.4568e-02, 1.4112e-01, 1.6644e-01, 1.6552e-01, 1.6326e-01, 1.6219e-01,\n",
      "         1.1787e-01, 9.0423e-03, 4.6818e-11, 4.6818e-11],\n",
      "        [7.4072e-02, 1.4107e-01, 1.6653e-01, 1.6521e-01, 1.6310e-01, 1.6228e-01,\n",
      "         1.1829e-01, 9.4529e-03, 7.7597e-11, 7.7597e-11],\n",
      "        [7.4492e-02, 1.4139e-01, 1.6654e-01, 1.6483e-01, 1.6264e-01, 1.6211e-01,\n",
      "         1.1834e-01, 9.6571e-03, 9.0712e-11, 9.0712e-11],\n",
      "        [7.4751e-02, 1.4159e-01, 1.6658e-01, 1.6472e-01, 1.6246e-01, 1.6202e-01,\n",
      "         1.1822e-01, 9.6557e-03, 8.9923e-11, 8.9923e-11],\n",
      "        [7.4845e-02, 1.4169e-01, 1.6662e-01, 1.6471e-01, 1.6239e-01, 1.6198e-01,\n",
      "         1.1814e-01, 9.6287e-03, 8.8503e-11, 8.8503e-11],\n",
      "        [7.4913e-02, 1.4174e-01, 1.6663e-01, 1.6470e-01, 1.6235e-01, 1.6195e-01,\n",
      "         1.1810e-01, 9.6200e-03, 8.7323e-11, 8.7323e-11],\n",
      "        [7.4968e-02, 1.4177e-01, 1.6662e-01, 1.6469e-01, 1.6232e-01, 1.6193e-01,\n",
      "         1.1809e-01, 9.6199e-03, 8.6371e-11, 8.6371e-11],\n",
      "        [7.4993e-02, 1.4178e-01, 1.6662e-01, 1.6468e-01, 1.6230e-01, 1.6192e-01,\n",
      "         1.1809e-01, 9.6206e-03, 8.5648e-11, 8.5648e-11]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 23.00, Train Loss: 4.20, Val Loss: 9.98, Train BLEU: 7.45, Val BLEU: 1.04\n",
      "Sampling from training predictions...\n",
      "Source: 看到 这些 在 动 的 东西 了 吗 <EOS> <PAD>\n",
      "Reference: but see all those different working things ? <EOS>\n",
      "Model: <SOS> it &apos;s the the the . . . .\n",
      "Attention Weights: tensor([[5.6763e-02, 1.1302e-01, 1.3586e-01, 1.4635e-01, 1.4951e-01, 1.4789e-01,\n",
      "         1.4033e-01, 1.0261e-01, 7.6599e-03, 3.7873e-12],\n",
      "        [5.6134e-02, 1.1256e-01, 1.3577e-01, 1.4640e-01, 1.4950e-01, 1.4784e-01,\n",
      "         1.4043e-01, 1.0299e-01, 8.3759e-03, 3.2939e-11],\n",
      "        [5.5634e-02, 1.1244e-01, 1.3583e-01, 1.4642e-01, 1.4947e-01, 1.4777e-01,\n",
      "         1.4043e-01, 1.0326e-01, 8.7579e-03, 5.7806e-11],\n",
      "        [5.5904e-02, 1.1267e-01, 1.3587e-01, 1.4629e-01, 1.4924e-01, 1.4753e-01,\n",
      "         1.4023e-01, 1.0329e-01, 8.9686e-03, 7.0538e-11],\n",
      "        [5.6077e-02, 1.1282e-01, 1.3590e-01, 1.4626e-01, 1.4916e-01, 1.4744e-01,\n",
      "         1.4013e-01, 1.0323e-01, 8.9831e-03, 6.9807e-11],\n",
      "        [5.6115e-02, 1.1287e-01, 1.3592e-01, 1.4626e-01, 1.4914e-01, 1.4743e-01,\n",
      "         1.4011e-01, 1.0320e-01, 8.9597e-03, 6.8564e-11],\n",
      "        [5.6150e-02, 1.1291e-01, 1.3593e-01, 1.4625e-01, 1.4912e-01, 1.4741e-01,\n",
      "         1.4010e-01, 1.0318e-01, 8.9507e-03, 6.7611e-11],\n",
      "        [5.6179e-02, 1.1293e-01, 1.3593e-01, 1.4624e-01, 1.4911e-01, 1.4740e-01,\n",
      "         1.4009e-01, 1.0318e-01, 8.9491e-03, 6.6839e-11],\n",
      "        [5.6202e-02, 1.1294e-01, 1.3592e-01, 1.4623e-01, 1.4910e-01, 1.4739e-01,\n",
      "         1.4008e-01, 1.0319e-01, 8.9501e-03, 6.6241e-11]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 永远 不会 忘记 那个 早晨 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: a morning that i will never forget . <EOS>\n",
      "Model: <SOS> it &apos;s the the the . . . .\n",
      "Attention Weights: tensor([[0.0545, 0.1090, 0.1300, 0.1394, 0.1448, 0.1446, 0.1377, 0.1070, 0.0297,\n",
      "         0.0032],\n",
      "        [0.0537, 0.1085, 0.1300, 0.1395, 0.1451, 0.1449, 0.1379, 0.1069, 0.0298,\n",
      "         0.0036],\n",
      "        [0.0532, 0.1085, 0.1302, 0.1396, 0.1452, 0.1450, 0.1378, 0.1066, 0.0301,\n",
      "         0.0038],\n",
      "        [0.0535, 0.1087, 0.1303, 0.1396, 0.1451, 0.1448, 0.1375, 0.1063, 0.0303,\n",
      "         0.0039],\n",
      "        [0.0537, 0.1089, 0.1304, 0.1396, 0.1451, 0.1448, 0.1374, 0.1061, 0.0302,\n",
      "         0.0040],\n",
      "        [0.0537, 0.1090, 0.1304, 0.1396, 0.1451, 0.1448, 0.1373, 0.1060, 0.0301,\n",
      "         0.0039],\n",
      "        [0.0538, 0.1090, 0.1304, 0.1397, 0.1451, 0.1448, 0.1373, 0.1059, 0.0301,\n",
      "         0.0039],\n",
      "        [0.0538, 0.1091, 0.1305, 0.1397, 0.1451, 0.1448, 0.1373, 0.1059, 0.0301,\n",
      "         0.0039],\n",
      "        [0.0538, 0.1091, 0.1305, 0.1396, 0.1451, 0.1447, 0.1373, 0.1059, 0.0301,\n",
      "         0.0039]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24.00, Train Loss: 4.18, Val Loss: 10.10, Train BLEU: 7.50, Val BLEU: 1.04\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想 海洋 占 了 地球 球面 面积 的 75\n",
      "Reference: when you think about it , the oceans are\n",
      "Model: <SOS> it &apos;s the the the the , , ,\n",
      "Attention Weights: tensor([[0.0487, 0.0952, 0.1131, 0.1226, 0.1269, 0.1275, 0.1277, 0.1238, 0.0996,\n",
      "         0.0148],\n",
      "        [0.0484, 0.0949, 0.1131, 0.1227, 0.1271, 0.1276, 0.1277, 0.1235, 0.0993,\n",
      "         0.0156],\n",
      "        [0.0480, 0.0949, 0.1132, 0.1228, 0.1271, 0.1276, 0.1276, 0.1234, 0.0995,\n",
      "         0.0161],\n",
      "        [0.0482, 0.0951, 0.1133, 0.1228, 0.1269, 0.1274, 0.1274, 0.1232, 0.0994,\n",
      "         0.0163],\n",
      "        [0.0483, 0.0952, 0.1133, 0.1227, 0.1269, 0.1274, 0.1273, 0.1231, 0.0994,\n",
      "         0.0164],\n",
      "        [0.0484, 0.0952, 0.1133, 0.1228, 0.1269, 0.1274, 0.1273, 0.1231, 0.0993,\n",
      "         0.0163],\n",
      "        [0.0484, 0.0952, 0.1133, 0.1228, 0.1269, 0.1274, 0.1273, 0.1231, 0.0993,\n",
      "         0.0163],\n",
      "        [0.0484, 0.0953, 0.1134, 0.1228, 0.1269, 0.1274, 0.1273, 0.1231, 0.0993,\n",
      "         0.0163],\n",
      "        [0.0484, 0.0953, 0.1134, 0.1228, 0.1269, 0.1273, 0.1273, 0.1231, 0.0993,\n",
      "         0.0163]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 都 知道 自己 正 冒 着 生命 的 危险\n",
      "Reference: we all knew we were risking our lives --\n",
      "Model: <SOS> it &apos;s the the the the , , ,\n",
      "Attention Weights: tensor([[0.0469, 0.0910, 0.1081, 0.1177, 0.1216, 0.1237, 0.1225, 0.1188, 0.1038,\n",
      "         0.0461],\n",
      "        [0.0467, 0.0908, 0.1079, 0.1177, 0.1216, 0.1237, 0.1224, 0.1186, 0.1039,\n",
      "         0.0467],\n",
      "        [0.0462, 0.0907, 0.1079, 0.1177, 0.1215, 0.1237, 0.1223, 0.1186, 0.1040,\n",
      "         0.0474],\n",
      "        [0.0464, 0.0909, 0.1079, 0.1177, 0.1214, 0.1235, 0.1221, 0.1184, 0.1040,\n",
      "         0.0478],\n",
      "        [0.0465, 0.0909, 0.1079, 0.1176, 0.1213, 0.1234, 0.1221, 0.1184, 0.1039,\n",
      "         0.0479],\n",
      "        [0.0466, 0.0910, 0.1080, 0.1176, 0.1213, 0.1234, 0.1220, 0.1184, 0.1039,\n",
      "         0.0479],\n",
      "        [0.0466, 0.0910, 0.1080, 0.1176, 0.1213, 0.1234, 0.1220, 0.1184, 0.1039,\n",
      "         0.0479],\n",
      "        [0.0466, 0.0910, 0.1080, 0.1176, 0.1213, 0.1234, 0.1220, 0.1184, 0.1039,\n",
      "         0.0478],\n",
      "        [0.0466, 0.0910, 0.1080, 0.1176, 0.1213, 0.1234, 0.1220, 0.1184, 0.1039,\n",
      "         0.0478]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 25.00, Train Loss: 4.16, Val Loss: 10.22, Train BLEU: 7.45, Val BLEU: 1.02\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 通过 潜水 潜水艇 拍下 的 影片 把 我们\n",
      "Reference: with vibrant video clips captured by submarines , david\n",
      "Model: <SOS> it &apos;s the the the the , , ,\n",
      "Attention Weights: tensor([[0.0472, 0.0874, 0.1105, 0.1180, 0.1150, 0.1246, 0.1258, 0.1217, 0.1075,\n",
      "         0.0424],\n",
      "        [0.0471, 0.0863, 0.1100, 0.1182, 0.1152, 0.1245, 0.1258, 0.1218, 0.1078,\n",
      "         0.0434],\n",
      "        [0.0467, 0.0860, 0.1100, 0.1182, 0.1151, 0.1244, 0.1257, 0.1217, 0.1080,\n",
      "         0.0441],\n",
      "        [0.0469, 0.0860, 0.1100, 0.1181, 0.1150, 0.1243, 0.1255, 0.1216, 0.1081,\n",
      "         0.0446],\n",
      "        [0.0470, 0.0860, 0.1100, 0.1181, 0.1149, 0.1242, 0.1255, 0.1216, 0.1081,\n",
      "         0.0448],\n",
      "        [0.0470, 0.0860, 0.1100, 0.1180, 0.1148, 0.1242, 0.1255, 0.1216, 0.1081,\n",
      "         0.0448],\n",
      "        [0.0470, 0.0860, 0.1100, 0.1180, 0.1148, 0.1243, 0.1255, 0.1216, 0.1081,\n",
      "         0.0448],\n",
      "        [0.0470, 0.0860, 0.1100, 0.1180, 0.1148, 0.1243, 0.1255, 0.1216, 0.1081,\n",
      "         0.0447],\n",
      "        [0.0470, 0.0860, 0.1100, 0.1180, 0.1148, 0.1243, 0.1255, 0.1216, 0.1082,\n",
      "         0.0447]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班 走 了 父亲 大声 叫 着 <EOS> <PAD>\n",
      "Reference: &quot; the taliban are gone ! &quot; my father\n",
      "Model: <SOS> it &apos;s the the the , , , ,\n",
      "Attention Weights: tensor([[0.0490, 0.0932, 0.1094, 0.1170, 0.1220, 0.1244, 0.1235, 0.1187, 0.1028,\n",
      "         0.0399],\n",
      "        [0.0488, 0.0931, 0.1096, 0.1171, 0.1219, 0.1241, 0.1233, 0.1185, 0.1028,\n",
      "         0.0409],\n",
      "        [0.0485, 0.0931, 0.1096, 0.1171, 0.1218, 0.1239, 0.1231, 0.1184, 0.1030,\n",
      "         0.0416],\n",
      "        [0.0486, 0.0932, 0.1097, 0.1170, 0.1217, 0.1237, 0.1229, 0.1182, 0.1030,\n",
      "         0.0420],\n",
      "        [0.0487, 0.0932, 0.1097, 0.1169, 0.1216, 0.1236, 0.1228, 0.1182, 0.1030,\n",
      "         0.0422],\n",
      "        [0.0487, 0.0933, 0.1097, 0.1169, 0.1216, 0.1236, 0.1228, 0.1182, 0.1030,\n",
      "         0.0422],\n",
      "        [0.0487, 0.0933, 0.1097, 0.1169, 0.1216, 0.1236, 0.1228, 0.1182, 0.1030,\n",
      "         0.0422],\n",
      "        [0.0487, 0.0933, 0.1097, 0.1169, 0.1216, 0.1236, 0.1228, 0.1182, 0.1030,\n",
      "         0.0422],\n",
      "        [0.0487, 0.0933, 0.1097, 0.1169, 0.1216, 0.1236, 0.1228, 0.1182, 0.1030,\n",
      "         0.0422]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 26.00, Train Loss: 4.14, Val Loss: 10.32, Train BLEU: 6.01, Val BLEU: 0.26\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数 多数 地震 和 火山 喷发 也 都 发生\n",
      "Reference: most of the earthquakes and volcanoes are in the\n",
      "Model: <SOS> it the the the the the , , ,\n",
      "Attention Weights: tensor([[0.0447, 0.0758, 0.1073, 0.1189, 0.1248, 0.1266, 0.1273, 0.1238, 0.1082,\n",
      "         0.0425],\n",
      "        [0.0448, 0.0747, 0.1065, 0.1187, 0.1249, 0.1266, 0.1273, 0.1239, 0.1086,\n",
      "         0.0439],\n",
      "        [0.0446, 0.0746, 0.1066, 0.1187, 0.1248, 0.1264, 0.1270, 0.1238, 0.1088,\n",
      "         0.0447],\n",
      "        [0.0448, 0.0748, 0.1067, 0.1186, 0.1246, 0.1262, 0.1268, 0.1236, 0.1088,\n",
      "         0.0452],\n",
      "        [0.0449, 0.0748, 0.1067, 0.1185, 0.1245, 0.1260, 0.1267, 0.1236, 0.1089,\n",
      "         0.0455],\n",
      "        [0.0449, 0.0748, 0.1067, 0.1185, 0.1245, 0.1260, 0.1267, 0.1236, 0.1089,\n",
      "         0.0455],\n",
      "        [0.0448, 0.0748, 0.1067, 0.1185, 0.1245, 0.1260, 0.1267, 0.1236, 0.1089,\n",
      "         0.0455],\n",
      "        [0.0448, 0.0748, 0.1067, 0.1185, 0.1245, 0.1260, 0.1267, 0.1236, 0.1089,\n",
      "         0.0454],\n",
      "        [0.0448, 0.0748, 0.1067, 0.1185, 0.1245, 0.1260, 0.1267, 0.1236, 0.1089,\n",
      "         0.0454]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 在 塔利 塔利班 控制 阿富汗 的 那些 年 我 记得\n",
      "Reference: during taliban years , i remember there were times\n",
      "Model: <SOS> it the the the the the , , ,\n",
      "Attention Weights: tensor([[0.0525, 0.0981, 0.1165, 0.1252, 0.1297, 0.1303, 0.1296, 0.1213, 0.0877,\n",
      "         0.0091],\n",
      "        [0.0520, 0.0977, 0.1164, 0.1252, 0.1296, 0.1301, 0.1294, 0.1213, 0.0882,\n",
      "         0.0103],\n",
      "        [0.0519, 0.0977, 0.1165, 0.1251, 0.1295, 0.1299, 0.1292, 0.1211, 0.0884,\n",
      "         0.0107],\n",
      "        [0.0521, 0.0979, 0.1165, 0.1250, 0.1292, 0.1296, 0.1289, 0.1210, 0.0887,\n",
      "         0.0111],\n",
      "        [0.0521, 0.0979, 0.1165, 0.1249, 0.1292, 0.1296, 0.1289, 0.1210, 0.0888,\n",
      "         0.0112],\n",
      "        [0.0521, 0.0979, 0.1165, 0.1249, 0.1292, 0.1296, 0.1289, 0.1210, 0.0888,\n",
      "         0.0112],\n",
      "        [0.0520, 0.0979, 0.1165, 0.1249, 0.1292, 0.1296, 0.1289, 0.1210, 0.0888,\n",
      "         0.0112],\n",
      "        [0.0520, 0.0979, 0.1164, 0.1249, 0.1292, 0.1296, 0.1290, 0.1210, 0.0888,\n",
      "         0.0112],\n",
      "        [0.0520, 0.0979, 0.1164, 0.1249, 0.1292, 0.1296, 0.1290, 0.1210, 0.0888,\n",
      "         0.0111]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 27.00, Train Loss: 4.12, Val Loss: 10.41, Train BLEU: 6.01, Val BLEU: 0.26\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克 泰坦尼克号 坦尼 尼克 号 是 拿 了 不少\n",
      "Reference: the truth of the matter is that the titanic\n",
      "Model: <SOS> it the the the the the , , ,\n",
      "Attention Weights: tensor([[0.0456, 0.0811, 0.0976, 0.1104, 0.1239, 0.1289, 0.1296, 0.1267, 0.1115,\n",
      "         0.0447],\n",
      "        [0.0459, 0.0794, 0.0961, 0.1093, 0.1239, 0.1293, 0.1301, 0.1273, 0.1123,\n",
      "         0.0465],\n",
      "        [0.0459, 0.0793, 0.0960, 0.1091, 0.1238, 0.1291, 0.1298, 0.1271, 0.1125,\n",
      "         0.0475],\n",
      "        [0.0461, 0.0794, 0.0961, 0.1090, 0.1235, 0.1288, 0.1295, 0.1269, 0.1126,\n",
      "         0.0481],\n",
      "        [0.0461, 0.0794, 0.0960, 0.1089, 0.1235, 0.1287, 0.1295, 0.1269, 0.1127,\n",
      "         0.0484],\n",
      "        [0.0460, 0.0793, 0.0960, 0.1089, 0.1235, 0.1287, 0.1295, 0.1269, 0.1128,\n",
      "         0.0485],\n",
      "        [0.0459, 0.0792, 0.0959, 0.1088, 0.1235, 0.1288, 0.1295, 0.1270, 0.1128,\n",
      "         0.0484],\n",
      "        [0.0459, 0.0792, 0.0959, 0.1088, 0.1235, 0.1288, 0.1296, 0.1270, 0.1128,\n",
      "         0.0484],\n",
      "        [0.0459, 0.0791, 0.0958, 0.1088, 0.1235, 0.1288, 0.1296, 0.1271, 0.1129,\n",
      "         0.0484]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 不知 知道 那 意味 意味着 什么 但是 我 能\n",
      "Reference: i didn &apos;t know what it meant , but\n",
      "Model: <SOS> it the the the the the , , ,\n",
      "Attention Weights: tensor([[0.0532, 0.0983, 0.1147, 0.1227, 0.1281, 0.1298, 0.1268, 0.1060, 0.0822,\n",
      "         0.0381],\n",
      "        [0.0531, 0.0984, 0.1149, 0.1227, 0.1278, 0.1295, 0.1265, 0.1048, 0.0825,\n",
      "         0.0397],\n",
      "        [0.0531, 0.0986, 0.1150, 0.1227, 0.1277, 0.1293, 0.1262, 0.1043, 0.0826,\n",
      "         0.0405],\n",
      "        [0.0532, 0.0987, 0.1150, 0.1226, 0.1275, 0.1290, 0.1259, 0.1041, 0.0828,\n",
      "         0.0412],\n",
      "        [0.0533, 0.0987, 0.1150, 0.1225, 0.1274, 0.1290, 0.1258, 0.1040, 0.0828,\n",
      "         0.0415],\n",
      "        [0.0533, 0.0987, 0.1150, 0.1225, 0.1274, 0.1290, 0.1258, 0.1039, 0.0828,\n",
      "         0.0415],\n",
      "        [0.0532, 0.0987, 0.1150, 0.1226, 0.1274, 0.1290, 0.1258, 0.1039, 0.0828,\n",
      "         0.0415],\n",
      "        [0.0532, 0.0987, 0.1150, 0.1226, 0.1275, 0.1290, 0.1258, 0.1039, 0.0828,\n",
      "         0.0415],\n",
      "        [0.0532, 0.0987, 0.1150, 0.1226, 0.1275, 0.1290, 0.1258, 0.1039, 0.0828,\n",
      "         0.0415]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28.00, Train Loss: 4.10, Val Loss: 10.50, Train BLEU: 6.01, Val BLEU: 0.26\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的 平均 深度 是 两英里 英里 <EOS> <PAD> <PAD>\n",
      "Reference: the average depth is about two miles . <EOS>\n",
      "Model: <SOS> it &apos;s the the the , , , ,\n",
      "Attention Weights: tensor([[7.9342e-02, 1.4663e-01, 1.6981e-01, 1.7940e-01, 1.7954e-01, 1.3044e-01,\n",
      "         1.0812e-01, 6.7136e-03, 2.5560e-12, 2.5560e-12],\n",
      "        [7.8529e-02, 1.4583e-01, 1.6913e-01, 1.7864e-01, 1.7883e-01, 1.3072e-01,\n",
      "         1.0989e-01, 8.4387e-03, 2.7912e-11, 2.7912e-11],\n",
      "        [7.8719e-02, 1.4581e-01, 1.6887e-01, 1.7816e-01, 1.7826e-01, 1.3006e-01,\n",
      "         1.1085e-01, 9.2698e-03, 5.9222e-11, 5.9222e-11],\n",
      "        [7.8971e-02, 1.4586e-01, 1.6860e-01, 1.7770e-01, 1.7779e-01, 1.2977e-01,\n",
      "         1.1156e-01, 9.7346e-03, 7.9431e-11, 7.9431e-11],\n",
      "        [7.8785e-02, 1.4579e-01, 1.6857e-01, 1.7768e-01, 1.7781e-01, 1.2969e-01,\n",
      "         1.1189e-01, 9.7719e-03, 7.8683e-11, 7.8683e-11],\n",
      "        [7.8589e-02, 1.4575e-01, 1.6860e-01, 1.7775e-01, 1.7790e-01, 1.2967e-01,\n",
      "         1.1200e-01, 9.7342e-03, 7.7511e-11, 7.7511e-11],\n",
      "        [7.8451e-02, 1.4573e-01, 1.6863e-01, 1.7780e-01, 1.7797e-01, 1.2966e-01,\n",
      "         1.1206e-01, 9.7026e-03, 7.7002e-11, 7.7002e-11],\n",
      "        [7.8373e-02, 1.4571e-01, 1.6864e-01, 1.7783e-01, 1.7801e-01, 1.2966e-01,\n",
      "         1.1209e-01, 9.6811e-03, 7.6716e-11, 7.6716e-11],\n",
      "        [7.8333e-02, 1.4570e-01, 1.6864e-01, 1.7784e-01, 1.7804e-01, 1.2966e-01,\n",
      "         1.1211e-01, 9.6694e-03, 7.6462e-11, 7.6462e-11]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在 一个 房屋 房屋里 屋里 我们 100 多 人\n",
      "Reference: the school was in a house , more than\n",
      "Model: <SOS> it the the the the the the , ,\n",
      "Attention Weights: tensor([[0.0464, 0.0759, 0.1073, 0.1186, 0.1243, 0.1259, 0.1265, 0.1232, 0.1081,\n",
      "         0.0437],\n",
      "        [0.0466, 0.0750, 0.1065, 0.1182, 0.1242, 0.1257, 0.1263, 0.1232, 0.1086,\n",
      "         0.0456],\n",
      "        [0.0468, 0.0752, 0.1067, 0.1181, 0.1240, 0.1253, 0.1259, 0.1229, 0.1086,\n",
      "         0.0466],\n",
      "        [0.0470, 0.0754, 0.1068, 0.1180, 0.1237, 0.1250, 0.1255, 0.1226, 0.1087,\n",
      "         0.0473],\n",
      "        [0.0470, 0.0754, 0.1067, 0.1179, 0.1236, 0.1249, 0.1254, 0.1226, 0.1088,\n",
      "         0.0476],\n",
      "        [0.0469, 0.0754, 0.1067, 0.1179, 0.1235, 0.1249, 0.1254, 0.1226, 0.1089,\n",
      "         0.0477],\n",
      "        [0.0469, 0.0753, 0.1067, 0.1179, 0.1236, 0.1249, 0.1255, 0.1227, 0.1089,\n",
      "         0.0477],\n",
      "        [0.0468, 0.0753, 0.1067, 0.1179, 0.1236, 0.1249, 0.1255, 0.1227, 0.1090,\n",
      "         0.0477],\n",
      "        [0.0468, 0.0753, 0.1067, 0.1179, 0.1236, 0.1249, 0.1255, 0.1228, 0.1090,\n",
      "         0.0477]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 29.00, Train Loss: 4.08, Val Loss: 10.58, Train BLEU: 6.01, Val BLEU: 0.26\n",
      "Sampling from training predictions...\n",
      "Source: 底下 这些 都 是 <UNK> 它们 上上 上上下下 上下 下下\n",
      "Reference: it &apos;s got these fishing <UNK> on the bottom\n",
      "Model: <SOS> it &apos;s the the the , , , ,\n",
      "Attention Weights: tensor([[0.0597, 0.1076, 0.1258, 0.1329, 0.1243, 0.1347, 0.1149, 0.1171, 0.0790,\n",
      "         0.0040],\n",
      "        [0.0590, 0.1069, 0.1256, 0.1327, 0.1242, 0.1341, 0.1146, 0.1169, 0.0806,\n",
      "         0.0053],\n",
      "        [0.0593, 0.1071, 0.1256, 0.1325, 0.1239, 0.1337, 0.1139, 0.1166, 0.0815,\n",
      "         0.0059],\n",
      "        [0.0596, 0.1073, 0.1255, 0.1323, 0.1235, 0.1333, 0.1137, 0.1166, 0.0820,\n",
      "         0.0061],\n",
      "        [0.0595, 0.1073, 0.1255, 0.1323, 0.1234, 0.1333, 0.1135, 0.1167, 0.0822,\n",
      "         0.0062],\n",
      "        [0.0593, 0.1073, 0.1256, 0.1324, 0.1233, 0.1334, 0.1135, 0.1168, 0.0822,\n",
      "         0.0062],\n",
      "        [0.0592, 0.1073, 0.1256, 0.1324, 0.1233, 0.1334, 0.1134, 0.1169, 0.0822,\n",
      "         0.0061],\n",
      "        [0.0591, 0.1073, 0.1257, 0.1325, 0.1233, 0.1335, 0.1134, 0.1169, 0.0823,\n",
      "         0.0061],\n",
      "        [0.0591, 0.1073, 0.1257, 0.1325, 0.1233, 0.1335, 0.1134, 0.1169, 0.0823,\n",
      "         0.0061]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11 岁 那年 记得 得有 一天 早晨 醒来 听见\n",
      "Reference: when i was 11 , i remember waking up\n",
      "Model: <SOS> it the the the the the the the ,\n",
      "Attention Weights: tensor([[1.0088e-01, 1.8023e-01, 2.0990e-01, 2.1603e-01, 1.9993e-01, 8.6326e-02,\n",
      "         6.6993e-03, 2.9162e-12, 2.9162e-12, 2.9162e-12],\n",
      "        [9.9647e-02, 1.7855e-01, 2.0845e-01, 2.1454e-01, 1.9928e-01, 9.0672e-02,\n",
      "         8.8516e-03, 3.3542e-11, 3.3542e-11, 3.3542e-11],\n",
      "        [9.9985e-02, 1.7824e-01, 2.0764e-01, 2.1350e-01, 1.9862e-01, 9.2106e-02,\n",
      "         9.9128e-03, 7.2388e-11, 7.2388e-11, 7.2388e-11],\n",
      "        [1.0034e-01, 1.7820e-01, 2.0710e-01, 2.1280e-01, 1.9825e-01, 9.2834e-02,\n",
      "         1.0470e-02, 9.7428e-11, 9.7428e-11, 9.7428e-11],\n",
      "        [9.9991e-02, 1.7806e-01, 2.0709e-01, 2.1291e-01, 1.9853e-01, 9.2924e-02,\n",
      "         1.0490e-02, 9.6597e-11, 9.6597e-11, 9.6597e-11],\n",
      "        [9.9682e-02, 1.7801e-01, 2.0720e-01, 2.1309e-01, 1.9875e-01, 9.2845e-02,\n",
      "         1.0424e-02, 9.5976e-11, 9.5976e-11, 9.5976e-11],\n",
      "        [9.9487e-02, 1.7798e-01, 2.0727e-01, 2.1321e-01, 1.9889e-01, 9.2795e-02,\n",
      "         1.0377e-02, 9.5691e-11, 9.5691e-11, 9.5691e-11],\n",
      "        [9.9388e-02, 1.7795e-01, 2.0730e-01, 2.1327e-01, 1.9896e-01, 9.2775e-02,\n",
      "         1.0351e-02, 9.5380e-11, 9.5380e-11, 9.5380e-11],\n",
      "        [9.9341e-02, 1.7794e-01, 2.0732e-01, 2.1329e-01, 1.9900e-01, 9.2772e-02,\n",
      "         1.0335e-02, 9.5036e-11, 9.5036e-11, 9.5036e-11]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 30.00, Train Loss: 4.06, Val Loss: 10.65, Train BLEU: 5.99, Val BLEU: 0.20\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本 基本上 都 没有 被 开发 发过 但是 像\n",
      "Reference: it &apos;s mostly unexplored , and yet there are\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0527, 0.0924, 0.1070, 0.1163, 0.1197, 0.1218, 0.1204, 0.1167, 0.1032,\n",
      "         0.0496],\n",
      "        [0.0527, 0.0923, 0.1069, 0.1161, 0.1193, 0.1214, 0.1198, 0.1163, 0.1034,\n",
      "         0.0517],\n",
      "        [0.0530, 0.0925, 0.1069, 0.1159, 0.1190, 0.1210, 0.1194, 0.1160, 0.1035,\n",
      "         0.0531],\n",
      "        [0.0533, 0.0927, 0.1069, 0.1157, 0.1187, 0.1206, 0.1190, 0.1157, 0.1036,\n",
      "         0.0538],\n",
      "        [0.0532, 0.0926, 0.1068, 0.1156, 0.1185, 0.1205, 0.1190, 0.1158, 0.1038,\n",
      "         0.0542],\n",
      "        [0.0531, 0.0926, 0.1067, 0.1156, 0.1185, 0.1205, 0.1190, 0.1158, 0.1039,\n",
      "         0.0543],\n",
      "        [0.0530, 0.0925, 0.1067, 0.1155, 0.1185, 0.1205, 0.1190, 0.1159, 0.1039,\n",
      "         0.0543],\n",
      "        [0.0529, 0.0925, 0.1067, 0.1155, 0.1185, 0.1205, 0.1191, 0.1159, 0.1040,\n",
      "         0.0544],\n",
      "        [0.0529, 0.0925, 0.1067, 0.1155, 0.1185, 0.1205, 0.1191, 0.1159, 0.1040,\n",
      "         0.0544]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 有时 学校 <UNK> 突然 <UNK> 一周 因为 被 塔利 塔利班\n",
      "Reference: from time to time , the school would suddenly\n",
      "Model: <SOS> it &apos;s the the the the the , ,\n",
      "Attention Weights: tensor([[0.0556, 0.0932, 0.1072, 0.1139, 0.1188, 0.1203, 0.1199, 0.1166, 0.1044,\n",
      "         0.0500],\n",
      "        [0.0557, 0.0933, 0.1073, 0.1137, 0.1184, 0.1198, 0.1193, 0.1162, 0.1045,\n",
      "         0.0519],\n",
      "        [0.0560, 0.0934, 0.1072, 0.1135, 0.1181, 0.1193, 0.1189, 0.1158, 0.1046,\n",
      "         0.0532],\n",
      "        [0.0564, 0.0937, 0.1072, 0.1133, 0.1178, 0.1190, 0.1185, 0.1155, 0.1046,\n",
      "         0.0539],\n",
      "        [0.0563, 0.0936, 0.1071, 0.1132, 0.1177, 0.1189, 0.1185, 0.1156, 0.1048,\n",
      "         0.0543],\n",
      "        [0.0562, 0.0935, 0.1071, 0.1132, 0.1177, 0.1189, 0.1185, 0.1157, 0.1049,\n",
      "         0.0544],\n",
      "        [0.0561, 0.0935, 0.1071, 0.1132, 0.1177, 0.1189, 0.1185, 0.1157, 0.1050,\n",
      "         0.0544],\n",
      "        [0.0560, 0.0934, 0.1070, 0.1132, 0.1177, 0.1189, 0.1185, 0.1157, 0.1050,\n",
      "         0.0545],\n",
      "        [0.0560, 0.0934, 0.1070, 0.1132, 0.1177, 0.1189, 0.1186, 0.1158, 0.1051,\n",
      "         0.0545]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 31.00, Train Loss: 4.04, Val Loss: 10.73, Train BLEU: 5.94, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想 海洋 占 了 地球 球面 面积 的 75\n",
      "Reference: when you think about it , the oceans are\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0560, 0.0974, 0.1130, 0.1214, 0.1249, 0.1252, 0.1251, 0.1214, 0.1003,\n",
      "         0.0153],\n",
      "        [0.0559, 0.0973, 0.1128, 0.1211, 0.1245, 0.1248, 0.1246, 0.1208, 0.1005,\n",
      "         0.0178],\n",
      "        [0.0562, 0.0974, 0.1128, 0.1208, 0.1242, 0.1243, 0.1241, 0.1204, 0.1009,\n",
      "         0.0189],\n",
      "        [0.0567, 0.0977, 0.1127, 0.1206, 0.1238, 0.1239, 0.1237, 0.1202, 0.1012,\n",
      "         0.0195],\n",
      "        [0.0565, 0.0977, 0.1127, 0.1205, 0.1237, 0.1239, 0.1237, 0.1203, 0.1014,\n",
      "         0.0196],\n",
      "        [0.0564, 0.0976, 0.1127, 0.1205, 0.1237, 0.1239, 0.1237, 0.1204, 0.1015,\n",
      "         0.0196],\n",
      "        [0.0563, 0.0976, 0.1126, 0.1205, 0.1237, 0.1239, 0.1238, 0.1204, 0.1016,\n",
      "         0.0196],\n",
      "        [0.0562, 0.0975, 0.1126, 0.1205, 0.1237, 0.1239, 0.1238, 0.1205, 0.1016,\n",
      "         0.0196],\n",
      "        [0.0562, 0.0975, 0.1126, 0.1205, 0.1237, 0.1239, 0.1238, 0.1205, 0.1016,\n",
      "         0.0196]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 想 过 要 放弃 但 我 的 父亲 这时\n",
      "Reference: i would want to quit , but my father\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0628, 0.1102, 0.1281, 0.1352, 0.1395, 0.1385, 0.1341, 0.1184, 0.0297,\n",
      "         0.0036],\n",
      "        [0.0620, 0.1093, 0.1273, 0.1344, 0.1386, 0.1377, 0.1337, 0.1188, 0.0331,\n",
      "         0.0051],\n",
      "        [0.0624, 0.1094, 0.1271, 0.1340, 0.1381, 0.1372, 0.1333, 0.1189, 0.0339,\n",
      "         0.0056],\n",
      "        [0.0629, 0.1097, 0.1270, 0.1337, 0.1376, 0.1368, 0.1330, 0.1190, 0.0344,\n",
      "         0.0060],\n",
      "        [0.0628, 0.1097, 0.1270, 0.1337, 0.1376, 0.1368, 0.1331, 0.1191, 0.0343,\n",
      "         0.0060],\n",
      "        [0.0626, 0.1097, 0.1271, 0.1337, 0.1377, 0.1369, 0.1332, 0.1192, 0.0340,\n",
      "         0.0060],\n",
      "        [0.0624, 0.1096, 0.1271, 0.1338, 0.1378, 0.1370, 0.1333, 0.1192, 0.0339,\n",
      "         0.0059],\n",
      "        [0.0623, 0.1096, 0.1271, 0.1338, 0.1378, 0.1370, 0.1333, 0.1193, 0.0338,\n",
      "         0.0059],\n",
      "        [0.0623, 0.1096, 0.1271, 0.1338, 0.1378, 0.1370, 0.1333, 0.1193, 0.0338,\n",
      "         0.0059]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32.00, Train Loss: 4.02, Val Loss: 10.79, Train BLEU: 5.90, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 底下 这些 都 是 <UNK> 它们 上上 上上下下 上下 下下\n",
      "Reference: it &apos;s got these fishing <UNK> on the bottom\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[0.0643, 0.1111, 0.1282, 0.1338, 0.1183, 0.1344, 0.1121, 0.1161, 0.0784,\n",
      "         0.0034],\n",
      "        [0.0634, 0.1101, 0.1275, 0.1332, 0.1190, 0.1333, 0.1120, 0.1159, 0.0807,\n",
      "         0.0050],\n",
      "        [0.0639, 0.1101, 0.1271, 0.1327, 0.1188, 0.1327, 0.1113, 0.1157, 0.0819,\n",
      "         0.0057],\n",
      "        [0.0644, 0.1104, 0.1270, 0.1322, 0.1184, 0.1322, 0.1111, 0.1157, 0.0826,\n",
      "         0.0060],\n",
      "        [0.0643, 0.1104, 0.1270, 0.1323, 0.1182, 0.1322, 0.1109, 0.1159, 0.0829,\n",
      "         0.0061],\n",
      "        [0.0641, 0.1104, 0.1271, 0.1324, 0.1181, 0.1323, 0.1108, 0.1160, 0.0829,\n",
      "         0.0060],\n",
      "        [0.0639, 0.1104, 0.1272, 0.1324, 0.1180, 0.1324, 0.1107, 0.1160, 0.0829,\n",
      "         0.0060],\n",
      "        [0.0639, 0.1104, 0.1272, 0.1325, 0.1180, 0.1324, 0.1107, 0.1161, 0.0829,\n",
      "         0.0060],\n",
      "        [0.0638, 0.1104, 0.1272, 0.1325, 0.1180, 0.1324, 0.1107, 0.1161, 0.0829,\n",
      "         0.0060]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 面带 <UNK> <UNK> 笑容 这 很少 少见 因为 大部\n",
      "Reference: there was a big smile on his face which\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0561, 0.0876, 0.1182, 0.1263, 0.1195, 0.1167, 0.1312, 0.1252, 0.1008,\n",
      "         0.0184],\n",
      "        [0.0559, 0.0875, 0.1170, 0.1254, 0.1190, 0.1163, 0.1302, 0.1249, 0.1020,\n",
      "         0.0218],\n",
      "        [0.0564, 0.0880, 0.1168, 0.1250, 0.1185, 0.1160, 0.1295, 0.1244, 0.1023,\n",
      "         0.0232],\n",
      "        [0.0570, 0.0883, 0.1168, 0.1247, 0.1181, 0.1155, 0.1290, 0.1240, 0.1026,\n",
      "         0.0240],\n",
      "        [0.0569, 0.0881, 0.1167, 0.1246, 0.1180, 0.1153, 0.1290, 0.1242, 0.1029,\n",
      "         0.0243],\n",
      "        [0.0567, 0.0879, 0.1167, 0.1247, 0.1179, 0.1152, 0.1292, 0.1244, 0.1031,\n",
      "         0.0242],\n",
      "        [0.0565, 0.0877, 0.1167, 0.1247, 0.1179, 0.1152, 0.1293, 0.1245, 0.1032,\n",
      "         0.0242],\n",
      "        [0.0565, 0.0876, 0.1167, 0.1247, 0.1179, 0.1151, 0.1293, 0.1246, 0.1033,\n",
      "         0.0242],\n",
      "        [0.0565, 0.0876, 0.1167, 0.1247, 0.1179, 0.1151, 0.1293, 0.1246, 0.1033,\n",
      "         0.0242]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 33.00, Train Loss: 4.01, Val Loss: 10.85, Train BLEU: 5.89, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 我 真 喜欢 这些 东西 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: i love that kind of stuff . <EOS> <PAD>\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[1.3839e-01, 2.1879e-01, 2.3880e-01, 2.3201e-01, 1.6391e-01, 8.0946e-03,\n",
      "         2.6065e-12, 2.6065e-12, 2.6065e-12, 2.6065e-12],\n",
      "        [1.3687e-01, 2.1688e-01, 2.3687e-01, 2.3057e-01, 1.6700e-01, 1.1812e-02,\n",
      "         3.6607e-11, 3.6607e-11, 3.6607e-11, 3.6607e-11],\n",
      "        [1.3713e-01, 2.1564e-01, 2.3527e-01, 2.2953e-01, 1.6889e-01, 1.3548e-02,\n",
      "         8.0988e-11, 8.0988e-11, 8.0988e-11, 8.0988e-11],\n",
      "        [1.3761e-01, 2.1499e-01, 2.3406e-01, 2.2875e-01, 1.7002e-01, 1.4572e-02,\n",
      "         1.1580e-10, 1.1580e-10, 1.1580e-10, 1.1580e-10],\n",
      "        [1.3739e-01, 2.1491e-01, 2.3400e-01, 2.2885e-01, 1.7023e-01, 1.4612e-02,\n",
      "         1.1628e-10, 1.1628e-10, 1.1628e-10, 1.1628e-10],\n",
      "        [1.3702e-01, 2.1498e-01, 2.3419e-01, 2.2910e-01, 1.7025e-01, 1.4463e-02,\n",
      "         1.1580e-10, 1.1580e-10, 1.1580e-10, 1.1580e-10],\n",
      "        [1.3678e-01, 2.1500e-01, 2.3430e-01, 2.2925e-01, 1.7029e-01, 1.4379e-02,\n",
      "         1.1552e-10, 1.1552e-10, 1.1552e-10, 1.1552e-10],\n",
      "        [1.3669e-01, 2.1500e-01, 2.3433e-01, 2.2931e-01, 1.7032e-01, 1.4348e-02,\n",
      "         1.1547e-10, 1.1547e-10, 1.1547e-10, 1.1547e-10],\n",
      "        [1.3667e-01, 2.1499e-01, 2.3433e-01, 2.2932e-01, 1.7034e-01, 1.4341e-02,\n",
      "         1.1567e-10, 1.1567e-10, 1.1567e-10, 1.1567e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 她 两年 年前 退休 了 结果 却 把 我家 变成\n",
      "Reference: she retired two years ago , only to turn\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[1.3839e-01, 2.1879e-01, 2.3880e-01, 2.3201e-01, 1.6391e-01, 8.0946e-03,\n",
      "         2.6065e-12, 2.6065e-12, 2.6065e-12, 2.6065e-12],\n",
      "        [1.3687e-01, 2.1688e-01, 2.3687e-01, 2.3057e-01, 1.6700e-01, 1.1812e-02,\n",
      "         3.6607e-11, 3.6607e-11, 3.6607e-11, 3.6607e-11],\n",
      "        [1.3713e-01, 2.1564e-01, 2.3527e-01, 2.2953e-01, 1.6889e-01, 1.3548e-02,\n",
      "         8.0988e-11, 8.0988e-11, 8.0988e-11, 8.0988e-11],\n",
      "        [1.3761e-01, 2.1499e-01, 2.3406e-01, 2.2875e-01, 1.7002e-01, 1.4572e-02,\n",
      "         1.1580e-10, 1.1580e-10, 1.1580e-10, 1.1580e-10],\n",
      "        [1.3739e-01, 2.1491e-01, 2.3400e-01, 2.2885e-01, 1.7023e-01, 1.4612e-02,\n",
      "         1.1628e-10, 1.1628e-10, 1.1628e-10, 1.1628e-10],\n",
      "        [1.3702e-01, 2.1498e-01, 2.3419e-01, 2.2910e-01, 1.7025e-01, 1.4463e-02,\n",
      "         1.1580e-10, 1.1580e-10, 1.1580e-10, 1.1580e-10],\n",
      "        [1.3678e-01, 2.1500e-01, 2.3430e-01, 2.2925e-01, 1.7029e-01, 1.4379e-02,\n",
      "         1.1552e-10, 1.1552e-10, 1.1552e-10, 1.1552e-10],\n",
      "        [1.3669e-01, 2.1500e-01, 2.3433e-01, 2.2931e-01, 1.7032e-01, 1.4348e-02,\n",
      "         1.1547e-10, 1.1547e-10, 1.1547e-10, 1.1547e-10],\n",
      "        [1.3667e-01, 2.1499e-01, 2.3433e-01, 2.2932e-01, 1.7034e-01, 1.4341e-02,\n",
      "         1.1567e-10, 1.1567e-10, 1.1567e-10, 1.1567e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 34.00, Train Loss: 3.99, Val Loss: 10.90, Train BLEU: 5.89, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本 基本上 都 没有 被 开发 发过 但是 像\n",
      "Reference: it &apos;s mostly unexplored , and yet there are\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0566, 0.0950, 0.1087, 0.1173, 0.1195, 0.1206, 0.1179, 0.1135, 0.1004,\n",
      "         0.0506],\n",
      "        [0.0568, 0.0947, 0.1081, 0.1164, 0.1187, 0.1199, 0.1173, 0.1133, 0.1011,\n",
      "         0.0539],\n",
      "        [0.0573, 0.0947, 0.1078, 0.1159, 0.1180, 0.1192, 0.1168, 0.1130, 0.1015,\n",
      "         0.0559],\n",
      "        [0.0579, 0.0950, 0.1078, 0.1156, 0.1176, 0.1187, 0.1163, 0.1126, 0.1016,\n",
      "         0.0568],\n",
      "        [0.0579, 0.0950, 0.1077, 0.1155, 0.1174, 0.1185, 0.1162, 0.1126, 0.1017,\n",
      "         0.0573],\n",
      "        [0.0577, 0.0950, 0.1077, 0.1155, 0.1175, 0.1186, 0.1163, 0.1127, 0.1018,\n",
      "         0.0573],\n",
      "        [0.0576, 0.0949, 0.1077, 0.1155, 0.1175, 0.1186, 0.1163, 0.1127, 0.1019,\n",
      "         0.0573],\n",
      "        [0.0575, 0.0949, 0.1077, 0.1155, 0.1175, 0.1186, 0.1163, 0.1128, 0.1019,\n",
      "         0.0574],\n",
      "        [0.0575, 0.0949, 0.1076, 0.1155, 0.1175, 0.1186, 0.1163, 0.1128, 0.1019,\n",
      "         0.0574]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 不知 知道 那 意味 意味着 什么 但是 我 能\n",
      "Reference: i didn &apos;t know what it meant , but\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0603, 0.1016, 0.1159, 0.1224, 0.1263, 0.1270, 0.1226, 0.1014, 0.0814,\n",
      "         0.0412],\n",
      "        [0.0604, 0.1013, 0.1152, 0.1215, 0.1252, 0.1258, 0.1218, 0.1009, 0.0830,\n",
      "         0.0450],\n",
      "        [0.0610, 0.1013, 0.1149, 0.1209, 0.1245, 0.1252, 0.1212, 0.1005, 0.0836,\n",
      "         0.0470],\n",
      "        [0.0615, 0.1014, 0.1147, 0.1205, 0.1239, 0.1246, 0.1208, 0.1005, 0.0841,\n",
      "         0.0481],\n",
      "        [0.0616, 0.1014, 0.1146, 0.1204, 0.1238, 0.1244, 0.1206, 0.1004, 0.0843,\n",
      "         0.0485],\n",
      "        [0.0614, 0.1015, 0.1146, 0.1204, 0.1238, 0.1245, 0.1207, 0.1003, 0.0842,\n",
      "         0.0486],\n",
      "        [0.0613, 0.1014, 0.1147, 0.1205, 0.1239, 0.1246, 0.1207, 0.1003, 0.0842,\n",
      "         0.0485],\n",
      "        [0.0612, 0.1014, 0.1147, 0.1205, 0.1239, 0.1246, 0.1208, 0.1003, 0.0841,\n",
      "         0.0486],\n",
      "        [0.0612, 0.1014, 0.1147, 0.1205, 0.1239, 0.1246, 0.1208, 0.1003, 0.0842,\n",
      "         0.0486]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 35.00, Train Loss: 3.98, Val Loss: 10.96, Train BLEU: 5.89, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一种 种群 栖 动物 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: it &apos;s a colonial animal . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[1.1156e-01, 1.7509e-01, 1.9340e-01, 1.9790e-01, 1.8855e-01, 1.2782e-01,\n",
      "         5.6819e-03, 1.7599e-12, 1.7599e-12, 1.7599e-12],\n",
      "        [1.1059e-01, 1.7333e-01, 1.9148e-01, 1.9627e-01, 1.8780e-01, 1.3165e-01,\n",
      "         8.8835e-03, 2.7036e-11, 2.7036e-11, 2.7036e-11],\n",
      "        [1.1111e-01, 1.7248e-01, 1.9019e-01, 1.9492e-01, 1.8713e-01, 1.3373e-01,\n",
      "         1.0446e-02, 6.1488e-11, 6.1488e-11, 6.1488e-11],\n",
      "        [1.1182e-01, 1.7214e-01, 1.8921e-01, 1.9384e-01, 1.8652e-01, 1.3507e-01,\n",
      "         1.1408e-02, 9.0152e-11, 9.0152e-11, 9.0152e-11],\n",
      "        [1.1177e-01, 1.7207e-01, 1.8904e-01, 1.9374e-01, 1.8661e-01, 1.3528e-01,\n",
      "         1.1485e-02, 8.9693e-11, 8.9693e-11, 8.9693e-11],\n",
      "        [1.1142e-01, 1.7210e-01, 1.8915e-01, 1.9394e-01, 1.8687e-01, 1.3521e-01,\n",
      "         1.1308e-02, 8.7952e-11, 8.7952e-11, 8.7952e-11],\n",
      "        [1.1118e-01, 1.7211e-01, 1.8923e-01, 1.9407e-01, 1.8701e-01, 1.3518e-01,\n",
      "         1.1221e-02, 8.8048e-11, 8.8048e-11, 8.8048e-11],\n",
      "        [1.1109e-01, 1.7211e-01, 1.8925e-01, 1.9411e-01, 1.8707e-01, 1.3518e-01,\n",
      "         1.1193e-02, 8.8697e-11, 8.8697e-11, 8.8697e-11],\n",
      "        [1.1104e-01, 1.7210e-01, 1.8926e-01, 1.9413e-01, 1.8709e-01, 1.3520e-01,\n",
      "         1.1185e-02, 8.9448e-11, 8.9448e-11, 8.9448e-11]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班 走 了 父亲 大声 叫 着 <EOS> <PAD>\n",
      "Reference: &quot; the taliban are gone ! &quot; my father\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[0.0588, 0.0977, 0.1109, 0.1167, 0.1201, 0.1208, 0.1185, 0.1133, 0.0991,\n",
      "         0.0441],\n",
      "        [0.0590, 0.0972, 0.1102, 0.1158, 0.1190, 0.1199, 0.1178, 0.1132, 0.1000,\n",
      "         0.0479],\n",
      "        [0.0596, 0.0972, 0.1098, 0.1151, 0.1183, 0.1192, 0.1172, 0.1129, 0.1005,\n",
      "         0.0501],\n",
      "        [0.0603, 0.0975, 0.1097, 0.1149, 0.1178, 0.1186, 0.1167, 0.1125, 0.1006,\n",
      "         0.0512],\n",
      "        [0.0604, 0.0975, 0.1096, 0.1147, 0.1177, 0.1184, 0.1166, 0.1125, 0.1008,\n",
      "         0.0517],\n",
      "        [0.0602, 0.0975, 0.1096, 0.1147, 0.1177, 0.1185, 0.1167, 0.1126, 0.1009,\n",
      "         0.0516],\n",
      "        [0.0600, 0.0974, 0.1096, 0.1147, 0.1178, 0.1185, 0.1167, 0.1126, 0.1010,\n",
      "         0.0516],\n",
      "        [0.0599, 0.0974, 0.1096, 0.1147, 0.1178, 0.1185, 0.1167, 0.1127, 0.1010,\n",
      "         0.0516],\n",
      "        [0.0598, 0.0974, 0.1096, 0.1147, 0.1178, 0.1185, 0.1167, 0.1127, 0.1010,\n",
      "         0.0517]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36.00, Train Loss: 3.96, Val Loss: 11.00, Train BLEU: 5.89, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克 泰坦尼克号 坦尼 尼克 号 是 拿 了 不少\n",
      "Reference: the truth of the matter is that the titanic\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0536, 0.0855, 0.0989, 0.1118, 0.1245, 0.1270, 0.1249, 0.1201, 0.1059,\n",
      "         0.0478],\n",
      "        [0.0545, 0.0838, 0.0974, 0.1103, 0.1234, 0.1262, 0.1245, 0.1203, 0.1073,\n",
      "         0.0524],\n",
      "        [0.0554, 0.0839, 0.0973, 0.1097, 0.1226, 0.1252, 0.1237, 0.1197, 0.1076,\n",
      "         0.0548],\n",
      "        [0.0562, 0.0846, 0.0978, 0.1099, 0.1220, 0.1244, 0.1228, 0.1190, 0.1074,\n",
      "         0.0559],\n",
      "        [0.0563, 0.0846, 0.0977, 0.1097, 0.1219, 0.1242, 0.1227, 0.1190, 0.1076,\n",
      "         0.0563],\n",
      "        [0.0560, 0.0844, 0.0975, 0.1096, 0.1220, 0.1244, 0.1229, 0.1192, 0.1078,\n",
      "         0.0563],\n",
      "        [0.0557, 0.0842, 0.0973, 0.1095, 0.1221, 0.1246, 0.1230, 0.1193, 0.1079,\n",
      "         0.0563],\n",
      "        [0.0556, 0.0841, 0.0973, 0.1095, 0.1221, 0.1246, 0.1231, 0.1194, 0.1080,\n",
      "         0.0563],\n",
      "        [0.0556, 0.0841, 0.0972, 0.1094, 0.1221, 0.1246, 0.1231, 0.1194, 0.1080,\n",
      "         0.0564]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天 要 走 不同 的 路线 这样 才 没有\n",
      "Reference: each day , we took a different route so\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0579, 0.0964, 0.1102, 0.1176, 0.1196, 0.1207, 0.1181, 0.1139, 0.1004,\n",
      "         0.0453],\n",
      "        [0.0583, 0.0957, 0.1092, 0.1164, 0.1185, 0.1196, 0.1174, 0.1138, 0.1015,\n",
      "         0.0495],\n",
      "        [0.0591, 0.0958, 0.1088, 0.1157, 0.1176, 0.1188, 0.1168, 0.1135, 0.1019,\n",
      "         0.0519],\n",
      "        [0.0599, 0.0962, 0.1088, 0.1154, 0.1172, 0.1183, 0.1162, 0.1130, 0.1020,\n",
      "         0.0531],\n",
      "        [0.0600, 0.0962, 0.1088, 0.1153, 0.1170, 0.1181, 0.1161, 0.1130, 0.1021,\n",
      "         0.0535],\n",
      "        [0.0597, 0.0961, 0.1088, 0.1153, 0.1170, 0.1181, 0.1162, 0.1131, 0.1022,\n",
      "         0.0535],\n",
      "        [0.0595, 0.0961, 0.1088, 0.1153, 0.1171, 0.1182, 0.1162, 0.1131, 0.1023,\n",
      "         0.0534],\n",
      "        [0.0594, 0.0961, 0.1088, 0.1153, 0.1171, 0.1182, 0.1162, 0.1132, 0.1023,\n",
      "         0.0534],\n",
      "        [0.0594, 0.0961, 0.1087, 0.1153, 0.1171, 0.1182, 0.1162, 0.1132, 0.1024,\n",
      "         0.0535]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 37.00, Train Loss: 3.95, Val Loss: 11.05, Train BLEU: 6.04, Val BLEU: 0.20\n",
      "Sampling from training predictions...\n",
      "Source: 和 我们 合作 的 人们 帮 我们 找到 了 新\n",
      "Reference: people that have partnered with us have given us\n",
      "Model: <SOS> it of the the the the the the the\n",
      "Attention Weights: tensor([[0.0604, 0.0961, 0.1094, 0.1164, 0.1187, 0.1194, 0.1166, 0.1116, 0.1001,\n",
      "         0.0513],\n",
      "        [0.0609, 0.0955, 0.1083, 0.1151, 0.1174, 0.1183, 0.1161, 0.1116, 0.1013,\n",
      "         0.0555],\n",
      "        [0.0619, 0.0956, 0.1079, 0.1143, 0.1165, 0.1174, 0.1154, 0.1113, 0.1018,\n",
      "         0.0580],\n",
      "        [0.0627, 0.0959, 0.1078, 0.1140, 0.1161, 0.1169, 0.1148, 0.1109, 0.1018,\n",
      "         0.0591],\n",
      "        [0.0629, 0.0960, 0.1078, 0.1139, 0.1159, 0.1167, 0.1147, 0.1108, 0.1018,\n",
      "         0.0596],\n",
      "        [0.0626, 0.0959, 0.1078, 0.1139, 0.1159, 0.1167, 0.1147, 0.1109, 0.1019,\n",
      "         0.0596],\n",
      "        [0.0624, 0.0959, 0.1078, 0.1139, 0.1159, 0.1168, 0.1148, 0.1110, 0.1020,\n",
      "         0.0595],\n",
      "        [0.0623, 0.0958, 0.1078, 0.1139, 0.1160, 0.1168, 0.1148, 0.1110, 0.1021,\n",
      "         0.0595],\n",
      "        [0.0622, 0.0958, 0.1078, 0.1139, 0.1160, 0.1168, 0.1148, 0.1110, 0.1021,\n",
      "         0.0596]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11 岁 那年 记得 得有 一天 早晨 醒来 听见\n",
      "Reference: when i was 11 , i remember waking up\n",
      "Model: <SOS> it of the the the the the the the\n",
      "Attention Weights: tensor([[1.1905e-01, 1.9510e-01, 2.1842e-01, 2.1683e-01, 1.9082e-01, 5.5896e-02,\n",
      "         3.8857e-03, 1.6654e-12, 1.6654e-12, 1.6654e-12],\n",
      "        [1.1705e-01, 1.9087e-01, 2.1423e-01, 2.1387e-01, 1.9090e-01, 6.6337e-02,\n",
      "         6.7455e-03, 2.7422e-11, 2.7422e-11, 2.7422e-11],\n",
      "        [1.1791e-01, 1.8953e-01, 2.1202e-01, 2.1175e-01, 1.9036e-01, 7.0101e-02,\n",
      "         8.3267e-03, 6.5832e-11, 6.5832e-11, 6.5832e-11],\n",
      "        [1.1882e-01, 1.8902e-01, 2.1058e-01, 2.1031e-01, 1.8995e-01, 7.2030e-02,\n",
      "         9.2919e-03, 9.8233e-11, 9.8233e-11, 9.8233e-11],\n",
      "        [1.1885e-01, 1.8898e-01, 2.1046e-01, 2.1022e-01, 1.9007e-01, 7.2029e-02,\n",
      "         9.3930e-03, 9.6770e-11, 9.6770e-11, 9.6770e-11],\n",
      "        [1.1830e-01, 1.8908e-01, 2.1084e-01, 2.1065e-01, 1.9040e-01, 7.1544e-02,\n",
      "         9.1850e-03, 9.3651e-11, 9.3651e-11, 9.3651e-11],\n",
      "        [1.1793e-01, 1.8913e-01, 2.1104e-01, 2.1090e-01, 1.9060e-01, 7.1320e-02,\n",
      "         9.0884e-03, 9.4098e-11, 9.4098e-11, 9.4098e-11],\n",
      "        [1.1778e-01, 1.8915e-01, 2.1111e-01, 2.1098e-01, 1.9067e-01, 7.1239e-02,\n",
      "         9.0597e-03, 9.5340e-11, 9.5340e-11, 9.5340e-11],\n",
      "        [1.1774e-01, 1.8915e-01, 2.1113e-01, 2.1101e-01, 1.9069e-01, 7.1223e-02,\n",
      "         9.0574e-03, 9.6574e-11, 9.6574e-11, 9.6574e-11]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 38.00, Train Loss: 3.93, Val Loss: 11.09, Train BLEU: 6.13, Val BLEU: 0.20\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 这位 是 比尔 <UNK> 我 是 大卫 <UNK>\n",
      "Reference: this is bill lange . i &apos;m dave gallo\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[0.0618, 0.0820, 0.1247, 0.1319, 0.1185, 0.1051, 0.1345, 0.1264, 0.1002,\n",
      "         0.0147],\n",
      "        [0.0618, 0.0834, 0.1215, 0.1291, 0.1178, 0.1067, 0.1320, 0.1255, 0.1022,\n",
      "         0.0199],\n",
      "        [0.0629, 0.0847, 0.1206, 0.1278, 0.1169, 0.1069, 0.1307, 0.1246, 0.1029,\n",
      "         0.0222],\n",
      "        [0.0639, 0.0856, 0.1203, 0.1271, 0.1166, 0.1068, 0.1296, 0.1238, 0.1031,\n",
      "         0.0234],\n",
      "        [0.0639, 0.0856, 0.1202, 0.1270, 0.1165, 0.1067, 0.1295, 0.1238, 0.1033,\n",
      "         0.0236],\n",
      "        [0.0635, 0.0851, 0.1203, 0.1272, 0.1165, 0.1065, 0.1299, 0.1241, 0.1035,\n",
      "         0.0234],\n",
      "        [0.0633, 0.0848, 0.1204, 0.1274, 0.1165, 0.1063, 0.1301, 0.1243, 0.1036,\n",
      "         0.0233],\n",
      "        [0.0632, 0.0847, 0.1205, 0.1274, 0.1165, 0.1063, 0.1302, 0.1244, 0.1037,\n",
      "         0.0232],\n",
      "        [0.0631, 0.0846, 0.1205, 0.1275, 0.1166, 0.1062, 0.1302, 0.1245, 0.1037,\n",
      "         0.0232]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 她 两年 年前 退休 了 结果 却 把 我家 变成\n",
      "Reference: she retired two years ago , only to turn\n",
      "Model: <SOS> it of the the the the the the the\n",
      "Attention Weights: tensor([[1.4651e-01, 2.2380e-01, 2.3990e-01, 2.2811e-01, 1.5593e-01, 5.7598e-03,\n",
      "         1.8090e-12, 1.8090e-12, 1.8090e-12, 1.8090e-12],\n",
      "        [1.4437e-01, 2.2012e-01, 2.3687e-01, 2.2703e-01, 1.6173e-01, 9.8688e-03,\n",
      "         3.0697e-11, 3.0697e-11, 3.0697e-11, 3.0697e-11],\n",
      "        [1.4509e-01, 2.1816e-01, 2.3438e-01, 2.2563e-01, 1.6464e-01, 1.2105e-02,\n",
      "         7.5876e-11, 7.5876e-11, 7.5876e-11, 7.5876e-11],\n",
      "        [1.4592e-01, 2.1706e-01, 2.3260e-01, 2.2449e-01, 1.6637e-01, 1.3564e-02,\n",
      "         1.1749e-10, 1.1749e-10, 1.1749e-10, 1.1749e-10],\n",
      "        [1.4584e-01, 2.1690e-01, 2.3243e-01, 2.2449e-01, 1.6669e-01, 1.3649e-02,\n",
      "         1.1403e-10, 1.1403e-10, 1.1403e-10, 1.1403e-10],\n",
      "        [1.4527e-01, 2.1706e-01, 2.3278e-01, 2.2486e-01, 1.6665e-01, 1.3368e-02,\n",
      "         1.1009e-10, 1.1009e-10, 1.1009e-10, 1.1009e-10],\n",
      "        [1.4490e-01, 2.1716e-01, 2.3298e-01, 2.2508e-01, 1.6663e-01, 1.3238e-02,\n",
      "         1.1058e-10, 1.1058e-10, 1.1058e-10, 1.1058e-10],\n",
      "        [1.4477e-01, 2.1721e-01, 2.3306e-01, 2.2515e-01, 1.6662e-01, 1.3199e-02,\n",
      "         1.1212e-10, 1.1212e-10, 1.1212e-10, 1.1212e-10],\n",
      "        [1.4473e-01, 2.1722e-01, 2.3308e-01, 2.2517e-01, 1.6661e-01, 1.3192e-02,\n",
      "         1.1360e-10, 1.1360e-10, 1.1360e-10, 1.1360e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 39.00, Train Loss: 3.92, Val Loss: 11.12, Train BLEU: 6.13, Val BLEU: 0.20\n",
      "Sampling from training predictions...\n",
      "Source: 我 真 喜欢 这些 东西 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: i love that kind of stuff . <EOS> <PAD>\n",
      "Model: <SOS> it &apos;s the the the , , , ,\n",
      "Attention Weights: tensor([[1.4777e-01, 2.2456e-01, 2.4011e-01, 2.2764e-01, 1.5456e-01, 5.3646e-03,\n",
      "         1.6816e-12, 1.6816e-12, 1.6816e-12, 1.6816e-12],\n",
      "        [1.4545e-01, 2.2069e-01, 2.3704e-01, 2.2669e-01, 1.6072e-01, 9.4148e-03,\n",
      "         2.9175e-11, 2.9175e-11, 2.9175e-11, 2.9175e-11],\n",
      "        [1.4631e-01, 2.1859e-01, 2.3435e-01, 2.2520e-01, 1.6382e-01, 1.1723e-02,\n",
      "         7.4652e-11, 7.4652e-11, 7.4652e-11, 7.4652e-11],\n",
      "        [1.4720e-01, 2.1742e-01, 2.3251e-01, 2.2401e-01, 1.6562e-01, 1.3240e-02,\n",
      "         1.1733e-10, 1.1733e-10, 1.1733e-10, 1.1733e-10],\n",
      "        [1.4713e-01, 2.1719e-01, 2.3227e-01, 2.2398e-01, 1.6605e-01, 1.3381e-02,\n",
      "         1.1481e-10, 1.1481e-10, 1.1481e-10, 1.1481e-10],\n",
      "        [1.4653e-01, 2.1735e-01, 2.3261e-01, 2.2436e-01, 1.6605e-01, 1.3103e-02,\n",
      "         1.1032e-10, 1.1032e-10, 1.1032e-10, 1.1032e-10],\n",
      "        [1.4612e-01, 2.1746e-01, 2.3284e-01, 2.2459e-01, 1.6603e-01, 1.2957e-02,\n",
      "         1.1054e-10, 1.1054e-10, 1.1054e-10, 1.1054e-10],\n",
      "        [1.4597e-01, 2.1751e-01, 2.3293e-01, 2.2467e-01, 1.6601e-01, 1.2913e-02,\n",
      "         1.1201e-10, 1.1201e-10, 1.1201e-10, 1.1201e-10],\n",
      "        [1.4592e-01, 2.1752e-01, 2.3295e-01, 2.2469e-01, 1.6601e-01, 1.2904e-02,\n",
      "         1.1342e-10, 1.1342e-10, 1.1342e-10, 1.1342e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 想 过 要 放弃 但 我 的 父亲 这时\n",
      "Reference: i would want to quit , but my father\n",
      "Model: <SOS> it of the the the the the the the\n",
      "Attention Weights: tensor([[0.0706, 0.1164, 0.1324, 0.1384, 0.1407, 0.1381, 0.1311, 0.1116, 0.0188,\n",
      "         0.0020],\n",
      "        [0.0694, 0.1143, 0.1304, 0.1367, 0.1393, 0.1373, 0.1313, 0.1136, 0.0243,\n",
      "         0.0035],\n",
      "        [0.0706, 0.1142, 0.1296, 0.1356, 0.1381, 0.1363, 0.1308, 0.1144, 0.0261,\n",
      "         0.0044],\n",
      "        [0.0716, 0.1143, 0.1292, 0.1348, 0.1371, 0.1354, 0.1303, 0.1147, 0.0276,\n",
      "         0.0049],\n",
      "        [0.0718, 0.1144, 0.1291, 0.1346, 0.1369, 0.1352, 0.1302, 0.1149, 0.0278,\n",
      "         0.0051],\n",
      "        [0.0715, 0.1144, 0.1292, 0.1348, 0.1371, 0.1354, 0.1304, 0.1149, 0.0274,\n",
      "         0.0050],\n",
      "        [0.0711, 0.1144, 0.1293, 0.1349, 0.1372, 0.1355, 0.1305, 0.1150, 0.0271,\n",
      "         0.0049],\n",
      "        [0.0710, 0.1144, 0.1293, 0.1350, 0.1373, 0.1356, 0.1305, 0.1150, 0.0270,\n",
      "         0.0049],\n",
      "        [0.0710, 0.1144, 0.1294, 0.1350, 0.1373, 0.1356, 0.1305, 0.1150, 0.0270,\n",
      "         0.0049]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40.00, Train Loss: 3.90, Val Loss: 11.16, Train BLEU: 6.13, Val BLEU: 0.20\n",
      "Sampling from training predictions...\n",
      "Source: 我们 得用 非常 特殊 的 仪器 才能 能到 到达 那个\n",
      "Reference: we have to have a very special technology to\n",
      "Model: <SOS> it of the the the the the the the\n",
      "Attention Weights: tensor([[0.0583, 0.0913, 0.1138, 0.1209, 0.1243, 0.1233, 0.1198, 0.0996, 0.1019,\n",
      "         0.0467],\n",
      "        [0.0589, 0.0908, 0.1120, 0.1190, 0.1223, 0.1217, 0.1188, 0.1015, 0.1030,\n",
      "         0.0519],\n",
      "        [0.0605, 0.0917, 0.1115, 0.1178, 0.1208, 0.1202, 0.1175, 0.1014, 0.1035,\n",
      "         0.0552],\n",
      "        [0.0615, 0.0923, 0.1112, 0.1172, 0.1200, 0.1194, 0.1169, 0.1015, 0.1036,\n",
      "         0.0566],\n",
      "        [0.0616, 0.0923, 0.1111, 0.1170, 0.1197, 0.1192, 0.1167, 0.1015, 0.1037,\n",
      "         0.0571],\n",
      "        [0.0613, 0.0921, 0.1111, 0.1171, 0.1199, 0.1193, 0.1168, 0.1015, 0.1038,\n",
      "         0.0570],\n",
      "        [0.0611, 0.0920, 0.1112, 0.1172, 0.1200, 0.1194, 0.1169, 0.1014, 0.1039,\n",
      "         0.0570],\n",
      "        [0.0609, 0.0919, 0.1112, 0.1172, 0.1201, 0.1194, 0.1169, 0.1014, 0.1039,\n",
      "         0.0570],\n",
      "        [0.0609, 0.0919, 0.1112, 0.1172, 0.1201, 0.1195, 0.1169, 0.1013, 0.1040,\n",
      "         0.0570]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 想 过 要 放弃 但 我 的 父亲 这时\n",
      "Reference: i would want to quit , but my father\n",
      "Model: <SOS> it of the the the the the the the\n",
      "Attention Weights: tensor([[0.0712, 0.1168, 0.1326, 0.1386, 0.1409, 0.1383, 0.1312, 0.1110, 0.0177,\n",
      "         0.0018],\n",
      "        [0.0700, 0.1147, 0.1306, 0.1369, 0.1394, 0.1375, 0.1313, 0.1131, 0.0231,\n",
      "         0.0033],\n",
      "        [0.0714, 0.1146, 0.1297, 0.1357, 0.1381, 0.1364, 0.1308, 0.1140, 0.0251,\n",
      "         0.0042],\n",
      "        [0.0724, 0.1147, 0.1292, 0.1349, 0.1371, 0.1355, 0.1303, 0.1144, 0.0266,\n",
      "         0.0048],\n",
      "        [0.0727, 0.1147, 0.1291, 0.1346, 0.1368, 0.1353, 0.1302, 0.1146, 0.0270,\n",
      "         0.0050],\n",
      "        [0.0723, 0.1147, 0.1292, 0.1348, 0.1370, 0.1354, 0.1303, 0.1147, 0.0266,\n",
      "         0.0049],\n",
      "        [0.0720, 0.1148, 0.1293, 0.1349, 0.1372, 0.1356, 0.1305, 0.1147, 0.0263,\n",
      "         0.0048],\n",
      "        [0.0718, 0.1148, 0.1294, 0.1350, 0.1372, 0.1356, 0.1305, 0.1147, 0.0262,\n",
      "         0.0048],\n",
      "        [0.0718, 0.1148, 0.1294, 0.1350, 0.1373, 0.1356, 0.1305, 0.1147, 0.0262,\n",
      "         0.0048]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 41.00, Train Loss: 3.88, Val Loss: 11.19, Train BLEU: 6.13, Val BLEU: 0.20\n",
      "Sampling from training predictions...\n",
      "Source: 我们 将 用 一些 影片 来讲 讲述 一些 深海 海里\n",
      "Reference: and we &apos;re going to tell you some stories\n",
      "Model: <SOS> it of the the the the the the the\n",
      "Attention Weights: tensor([[0.0606, 0.0981, 0.1104, 0.1161, 0.1194, 0.1203, 0.1180, 0.1128, 0.0984,\n",
      "         0.0459],\n",
      "        [0.0612, 0.0972, 0.1092, 0.1148, 0.1179, 0.1189, 0.1171, 0.1126, 0.0998,\n",
      "         0.0513],\n",
      "        [0.0629, 0.0973, 0.1085, 0.1137, 0.1166, 0.1176, 0.1160, 0.1121, 0.1004,\n",
      "         0.0548],\n",
      "        [0.0639, 0.0976, 0.1083, 0.1133, 0.1161, 0.1170, 0.1154, 0.1117, 0.1006,\n",
      "         0.0562],\n",
      "        [0.0641, 0.0976, 0.1082, 0.1131, 0.1158, 0.1167, 0.1153, 0.1116, 0.1008,\n",
      "         0.0569],\n",
      "        [0.0638, 0.0975, 0.1082, 0.1131, 0.1159, 0.1168, 0.1153, 0.1116, 0.1008,\n",
      "         0.0568],\n",
      "        [0.0635, 0.0975, 0.1083, 0.1132, 0.1160, 0.1168, 0.1154, 0.1117, 0.1009,\n",
      "         0.0567],\n",
      "        [0.0634, 0.0975, 0.1083, 0.1132, 0.1160, 0.1169, 0.1154, 0.1117, 0.1009,\n",
      "         0.0567],\n",
      "        [0.0633, 0.0975, 0.1083, 0.1132, 0.1160, 0.1169, 0.1154, 0.1117, 0.1009,\n",
      "         0.0567]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 所以 在 那 之后 5 年 我 <UNK> <UNK> 陪\n",
      "Reference: so for the next five years , i dressed\n",
      "Model: <SOS> it of the the the the the the the\n",
      "Attention Weights: tensor([[9.9030e-02, 1.6053e-01, 1.7827e-01, 1.8232e-01, 1.7457e-01, 1.0497e-01,\n",
      "         9.7346e-02, 2.9607e-03, 1.0333e-12, 1.0333e-12],\n",
      "        [9.7365e-02, 1.5698e-01, 1.7474e-01, 1.7930e-01, 1.7291e-01, 1.1013e-01,\n",
      "         1.0298e-01, 5.5950e-03, 1.8353e-11, 1.8353e-11],\n",
      "        [9.8733e-02, 1.5572e-01, 1.7246e-01, 1.7681e-01, 1.7119e-01, 1.1132e-01,\n",
      "         1.0647e-01, 7.2960e-03, 4.9959e-11, 4.9959e-11],\n",
      "        [9.9741e-02, 1.5511e-01, 1.7107e-01, 1.7519e-01, 1.6986e-01, 1.1229e-01,\n",
      "         1.0835e-01, 8.3901e-03, 7.9945e-11, 7.9945e-11],\n",
      "        [9.9834e-02, 1.5489e-01, 1.7074e-01, 1.7486e-01, 1.6967e-01, 1.1241e-01,\n",
      "         1.0898e-01, 8.6163e-03, 8.0197e-11, 8.0197e-11],\n",
      "        [9.9317e-02, 1.5498e-01, 1.7098e-01, 1.7519e-01, 1.7001e-01, 1.1208e-01,\n",
      "         1.0900e-01, 8.4480e-03, 7.7543e-11, 7.7543e-11],\n",
      "        [9.8854e-02, 1.5506e-01, 1.7121e-01, 1.7546e-01, 1.7027e-01, 1.1184e-01,\n",
      "         1.0898e-01, 8.3289e-03, 7.7747e-11, 7.7747e-11],\n",
      "        [9.8698e-02, 1.5510e-01, 1.7128e-01, 1.7555e-01, 1.7035e-01, 1.1175e-01,\n",
      "         1.0898e-01, 8.2942e-03, 7.8717e-11, 7.8717e-11],\n",
      "        [9.8641e-02, 1.5511e-01, 1.7130e-01, 1.7558e-01, 1.7038e-01, 1.1172e-01,\n",
      "         1.0898e-01, 8.2880e-03, 7.9514e-11, 7.9514e-11]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 42.00, Train Loss: 3.87, Val Loss: 11.22, Train BLEU: 6.13, Val BLEU: 0.20\n",
      "Sampling from training predictions...\n",
      "Source: 和 我们 合作 的 人们 帮 我们 找到 了 新\n",
      "Reference: people that have partnered with us have given us\n",
      "Model: <SOS> and of the the the the the the the\n",
      "Attention Weights: tensor([[0.0617, 0.0959, 0.1082, 0.1151, 0.1179, 0.1191, 0.1168, 0.1120, 0.1000,\n",
      "         0.0532],\n",
      "        [0.0626, 0.0953, 0.1071, 0.1137, 0.1164, 0.1177, 0.1159, 0.1117, 0.1012,\n",
      "         0.0582],\n",
      "        [0.0644, 0.0956, 0.1066, 0.1127, 0.1152, 0.1163, 0.1148, 0.1111, 0.1017,\n",
      "         0.0617],\n",
      "        [0.0654, 0.0959, 0.1065, 0.1122, 0.1146, 0.1156, 0.1142, 0.1107, 0.1018,\n",
      "         0.0631],\n",
      "        [0.0657, 0.0959, 0.1064, 0.1120, 0.1143, 0.1153, 0.1140, 0.1106, 0.1019,\n",
      "         0.0638],\n",
      "        [0.0654, 0.0959, 0.1064, 0.1120, 0.1144, 0.1154, 0.1140, 0.1106, 0.1020,\n",
      "         0.0638],\n",
      "        [0.0652, 0.0959, 0.1064, 0.1121, 0.1144, 0.1155, 0.1141, 0.1107, 0.1020,\n",
      "         0.0637],\n",
      "        [0.0651, 0.0958, 0.1064, 0.1121, 0.1145, 0.1155, 0.1141, 0.1107, 0.1020,\n",
      "         0.0637],\n",
      "        [0.0650, 0.0958, 0.1064, 0.1121, 0.1145, 0.1155, 0.1141, 0.1107, 0.1021,\n",
      "         0.0637]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很 舒服 但 夏天 却 <UNK> <EOS> <PAD> <PAD>\n",
      "Reference: it was cozy in winter but extremely hot in\n",
      "Model: <SOS> it &apos;s the the the , , , ,\n",
      "Attention Weights: tensor([[0.0596, 0.0978, 0.1097, 0.1163, 0.1181, 0.1119, 0.1191, 0.1131, 0.1008,\n",
      "         0.0536],\n",
      "        [0.0604, 0.0970, 0.1086, 0.1149, 0.1167, 0.1109, 0.1179, 0.1129, 0.1021,\n",
      "         0.0587],\n",
      "        [0.0622, 0.0970, 0.1079, 0.1137, 0.1154, 0.1102, 0.1167, 0.1122, 0.1026,\n",
      "         0.0622],\n",
      "        [0.0632, 0.0973, 0.1077, 0.1132, 0.1148, 0.1100, 0.1160, 0.1117, 0.1025,\n",
      "         0.0636],\n",
      "        [0.0635, 0.0973, 0.1076, 0.1130, 0.1146, 0.1099, 0.1158, 0.1116, 0.1026,\n",
      "         0.0642],\n",
      "        [0.0632, 0.0973, 0.1076, 0.1130, 0.1146, 0.1097, 0.1159, 0.1117, 0.1028,\n",
      "         0.0642],\n",
      "        [0.0629, 0.0973, 0.1076, 0.1131, 0.1146, 0.1097, 0.1160, 0.1118, 0.1029,\n",
      "         0.0642],\n",
      "        [0.0628, 0.0973, 0.1076, 0.1131, 0.1147, 0.1096, 0.1160, 0.1118, 0.1029,\n",
      "         0.0642],\n",
      "        [0.0627, 0.0972, 0.1077, 0.1132, 0.1147, 0.1096, 0.1160, 0.1118, 0.1029,\n",
      "         0.0642]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 43.00, Train Loss: 3.85, Val Loss: 11.25, Train BLEU: 6.19, Val BLEU: 0.20\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这 有 不少 精彩 的 泰坦 泰坦尼克 坦尼 尼克\n",
      "Reference: we &apos;ve got some of the most incredible video\n",
      "Model: <SOS> and of the the the the the the the\n",
      "Attention Weights: tensor([[0.0640, 0.1032, 0.1157, 0.1219, 0.1254, 0.1262, 0.1225, 0.0984, 0.0791,\n",
      "         0.0435],\n",
      "        [0.0649, 0.1023, 0.1143, 0.1200, 0.1232, 0.1240, 0.1208, 0.0988, 0.0822,\n",
      "         0.0496],\n",
      "        [0.0667, 0.1020, 0.1131, 0.1184, 0.1214, 0.1221, 0.1193, 0.0991, 0.0843,\n",
      "         0.0537],\n",
      "        [0.0676, 0.1019, 0.1125, 0.1176, 0.1204, 0.1211, 0.1186, 0.0995, 0.0854,\n",
      "         0.0554],\n",
      "        [0.0679, 0.1018, 0.1122, 0.1172, 0.1201, 0.1207, 0.1184, 0.0997, 0.0858,\n",
      "         0.0562],\n",
      "        [0.0676, 0.1018, 0.1123, 0.1173, 0.1202, 0.1208, 0.1184, 0.0996, 0.0857,\n",
      "         0.0562],\n",
      "        [0.0673, 0.1018, 0.1124, 0.1174, 0.1203, 0.1210, 0.1186, 0.0995, 0.0856,\n",
      "         0.0561],\n",
      "        [0.0671, 0.1018, 0.1124, 0.1175, 0.1204, 0.1210, 0.1186, 0.0995, 0.0855,\n",
      "         0.0561],\n",
      "        [0.0671, 0.1018, 0.1124, 0.1175, 0.1204, 0.1210, 0.1186, 0.0995, 0.0855,\n",
      "         0.0561]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 出身 阿富汗 边远 <UNK> 地区 有着 与 他人 不同\n",
      "Reference: a total maverick from a remote province of afghanistan\n",
      "Model: <SOS> it of the the the the the the the\n",
      "Attention Weights: tensor([[8.0654e-02, 1.2926e-01, 1.4340e-01, 1.4744e-01, 1.3473e-01, 1.4515e-01,\n",
      "         1.3177e-01, 8.5222e-02, 2.3709e-03, 7.4125e-13],\n",
      "        [7.9799e-02, 1.2733e-01, 1.4150e-01, 1.4573e-01, 1.3444e-01, 1.4393e-01,\n",
      "         1.3236e-01, 9.0299e-02, 4.6129e-03, 1.3882e-11],\n",
      "        [8.1393e-02, 1.2659e-01, 1.3987e-01, 1.4387e-01, 1.3355e-01, 1.4266e-01,\n",
      "         1.3229e-01, 9.3554e-02, 6.2036e-03, 3.9321e-11],\n",
      "        [8.2621e-02, 1.2636e-01, 1.3891e-01, 1.4273e-01, 1.3306e-01, 1.4168e-01,\n",
      "         1.3201e-01, 9.5357e-02, 7.2735e-03, 6.4743e-11],\n",
      "        [8.2866e-02, 1.2621e-01, 1.3859e-01, 1.4237e-01, 1.3281e-01, 1.4142e-01,\n",
      "         1.3208e-01, 9.6073e-02, 7.5840e-03, 6.6485e-11],\n",
      "        [8.2445e-02, 1.2621e-01, 1.3870e-01, 1.4244e-01, 1.3264e-01, 1.4157e-01,\n",
      "         1.3233e-01, 9.6183e-02, 7.4812e-03, 6.5832e-11],\n",
      "        [8.1973e-02, 1.2620e-01, 1.3882e-01, 1.4258e-01, 1.3256e-01, 1.4176e-01,\n",
      "         1.3254e-01, 9.6189e-02, 7.3785e-03, 6.6845e-11],\n",
      "        [8.1824e-02, 1.2620e-01, 1.3886e-01, 1.4262e-01, 1.3251e-01, 1.4182e-01,\n",
      "         1.3260e-01, 9.6203e-02, 7.3552e-03, 6.7937e-11],\n",
      "        [8.1780e-02, 1.2620e-01, 1.3887e-01, 1.4262e-01, 1.3249e-01, 1.4183e-01,\n",
      "         1.3262e-01, 9.6222e-02, 7.3558e-03, 6.8644e-11]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44.00, Train Loss: 3.83, Val Loss: 11.27, Train BLEU: 6.34, Val BLEU: 0.20\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本 基本上 都 没有 被 开发 发过 但是 像\n",
      "Reference: it &apos;s mostly unexplored , and yet there are\n",
      "Model: <SOS> most of the the the the the the the\n",
      "Attention Weights: tensor([[0.0602, 0.0962, 0.1081, 0.1158, 0.1182, 0.1193, 0.1169, 0.1124, 0.0991,\n",
      "         0.0537],\n",
      "        [0.0613, 0.0957, 0.1072, 0.1144, 0.1168, 0.1178, 0.1157, 0.1119, 0.1003,\n",
      "         0.0590],\n",
      "        [0.0633, 0.0959, 0.1066, 0.1131, 0.1153, 0.1163, 0.1145, 0.1112, 0.1009,\n",
      "         0.0630],\n",
      "        [0.0645, 0.0962, 0.1064, 0.1125, 0.1146, 0.1155, 0.1138, 0.1108, 0.1011,\n",
      "         0.0646],\n",
      "        [0.0649, 0.0962, 0.1063, 0.1122, 0.1143, 0.1152, 0.1136, 0.1107, 0.1013,\n",
      "         0.0654],\n",
      "        [0.0646, 0.0961, 0.1063, 0.1123, 0.1143, 0.1152, 0.1137, 0.1107, 0.1014,\n",
      "         0.0654],\n",
      "        [0.0643, 0.0961, 0.1063, 0.1123, 0.1144, 0.1153, 0.1137, 0.1108, 0.1014,\n",
      "         0.0654],\n",
      "        [0.0642, 0.0961, 0.1063, 0.1123, 0.1144, 0.1153, 0.1138, 0.1108, 0.1015,\n",
      "         0.0654],\n",
      "        [0.0641, 0.0960, 0.1062, 0.1123, 0.1144, 0.1153, 0.1138, 0.1108, 0.1015,\n",
      "         0.0654]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在 一个 房屋 房屋里 屋里 我们 100 多 人\n",
      "Reference: the school was in a house , more than\n",
      "Model: <SOS> most of the the the the the the the\n",
      "Attention Weights: tensor([[0.0557, 0.0761, 0.1114, 0.1195, 0.1228, 0.1226, 0.1220, 0.1175, 0.1031,\n",
      "         0.0492],\n",
      "        [0.0574, 0.0770, 0.1093, 0.1175, 0.1210, 0.1209, 0.1207, 0.1169, 0.1043,\n",
      "         0.0552],\n",
      "        [0.0596, 0.0791, 0.1087, 0.1160, 0.1191, 0.1191, 0.1189, 0.1156, 0.1045,\n",
      "         0.0593],\n",
      "        [0.0609, 0.0803, 0.1084, 0.1153, 0.1182, 0.1183, 0.1181, 0.1149, 0.1045,\n",
      "         0.0610],\n",
      "        [0.0613, 0.0805, 0.1082, 0.1150, 0.1179, 0.1180, 0.1178, 0.1147, 0.1046,\n",
      "         0.0619],\n",
      "        [0.0610, 0.0803, 0.1082, 0.1151, 0.1179, 0.1180, 0.1179, 0.1149, 0.1048,\n",
      "         0.0618],\n",
      "        [0.0607, 0.0801, 0.1083, 0.1152, 0.1180, 0.1181, 0.1180, 0.1150, 0.1049,\n",
      "         0.0618],\n",
      "        [0.0605, 0.0800, 0.1083, 0.1152, 0.1181, 0.1182, 0.1180, 0.1150, 0.1049,\n",
      "         0.0618],\n",
      "        [0.0604, 0.0799, 0.1083, 0.1152, 0.1181, 0.1182, 0.1180, 0.1150, 0.1050,\n",
      "         0.0619]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 45.00, Train Loss: 3.82, Val Loss: 11.29, Train BLEU: 6.18, Val BLEU: 0.20\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一只 水母 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: here &apos;s a jelly . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the the , , , , ,\n",
      "Attention Weights: tensor([[2.0715e-01, 2.9690e-01, 2.9413e-01, 1.9702e-01, 4.7982e-03, 1.7879e-12,\n",
      "         1.7879e-12, 1.7879e-12, 1.7879e-12, 1.7879e-12],\n",
      "        [2.0309e-01, 2.9073e-01, 2.9070e-01, 2.0575e-01, 9.7290e-03, 3.5153e-11,\n",
      "         3.5153e-11, 3.5153e-11, 3.5153e-11, 3.5153e-11],\n",
      "        [2.0334e-01, 2.8515e-01, 2.8672e-01, 2.1123e-01, 1.3565e-02, 1.0058e-10,\n",
      "         1.0058e-10, 1.0058e-10, 1.0058e-10, 1.0058e-10],\n",
      "        [2.0424e-01, 2.8182e-01, 2.8396e-01, 2.1381e-01, 1.6177e-02, 1.6613e-10,\n",
      "         1.6613e-10, 1.6613e-10, 1.6613e-10, 1.6613e-10],\n",
      "        [2.0416e-01, 2.8081e-01, 2.8324e-01, 2.1485e-01, 1.6941e-02, 1.7276e-10,\n",
      "         1.7276e-10, 1.7276e-10, 1.7276e-10, 1.7276e-10],\n",
      "        [2.0344e-01, 2.8092e-01, 2.8361e-01, 2.1519e-01, 1.6849e-02, 1.7360e-10,\n",
      "         1.7360e-10, 1.7360e-10, 1.7360e-10, 1.7360e-10],\n",
      "        [2.0284e-01, 2.8110e-01, 2.8395e-01, 2.1536e-01, 1.6754e-02, 1.7923e-10,\n",
      "         1.7923e-10, 1.7923e-10, 1.7923e-10, 1.7923e-10],\n",
      "        [2.0267e-01, 2.8112e-01, 2.8401e-01, 2.1543e-01, 1.6762e-02, 1.8308e-10,\n",
      "         1.8308e-10, 1.8308e-10, 1.8308e-10, 1.8308e-10],\n",
      "        [2.0261e-01, 2.8110e-01, 2.8401e-01, 2.1549e-01, 1.6788e-02, 1.8547e-10,\n",
      "         1.8547e-10, 1.8547e-10, 1.8547e-10, 1.8547e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很 舒服 但 夏天 却 <UNK> <EOS> <PAD> <PAD>\n",
      "Reference: it was cozy in winter but extremely hot in\n",
      "Model: <SOS> it &apos;s the the , , , , ,\n",
      "Attention Weights: tensor([[0.0611, 0.0984, 0.1094, 0.1156, 0.1171, 0.1103, 0.1187, 0.1133, 0.1013,\n",
      "         0.0548],\n",
      "        [0.0623, 0.0978, 0.1084, 0.1142, 0.1156, 0.1092, 0.1173, 0.1127, 0.1023,\n",
      "         0.0602],\n",
      "        [0.0644, 0.0977, 0.1075, 0.1128, 0.1142, 0.1087, 0.1158, 0.1118, 0.1027,\n",
      "         0.0643],\n",
      "        [0.0656, 0.0979, 0.1072, 0.1121, 0.1135, 0.1086, 0.1150, 0.1113, 0.1027,\n",
      "         0.0660],\n",
      "        [0.0660, 0.0979, 0.1070, 0.1118, 0.1132, 0.1085, 0.1147, 0.1111, 0.1028,\n",
      "         0.0668],\n",
      "        [0.0658, 0.0978, 0.1070, 0.1119, 0.1132, 0.1083, 0.1148, 0.1112, 0.1030,\n",
      "         0.0669],\n",
      "        [0.0655, 0.0978, 0.1070, 0.1119, 0.1133, 0.1082, 0.1149, 0.1113, 0.1031,\n",
      "         0.0669],\n",
      "        [0.0654, 0.0978, 0.1071, 0.1119, 0.1133, 0.1082, 0.1149, 0.1113, 0.1032,\n",
      "         0.0669],\n",
      "        [0.0653, 0.0978, 0.1071, 0.1120, 0.1133, 0.1081, 0.1150, 0.1114, 0.1032,\n",
      "         0.0670]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 46.00, Train Loss: 3.80, Val Loss: 11.32, Train BLEU: 6.35, Val BLEU: 0.21\n",
      "Sampling from training predictions...\n",
      "Source: 底下 这些 都 是 <UNK> 它们 上上 上上下下 上下 下下\n",
      "Reference: it &apos;s got these fishing <UNK> on the bottom\n",
      "Model: <SOS> it &apos;s the the the , , , ,\n",
      "Attention Weights: tensor([[0.0778, 0.1228, 0.1365, 0.1398, 0.0841, 0.1404, 0.1023, 0.1178, 0.0770,\n",
      "         0.0016],\n",
      "        [0.0765, 0.1199, 0.1335, 0.1370, 0.0909, 0.1369, 0.1033, 0.1171, 0.0817,\n",
      "         0.0033],\n",
      "        [0.0782, 0.1182, 0.1306, 0.1339, 0.0936, 0.1341, 0.1041, 0.1172, 0.0853,\n",
      "         0.0048],\n",
      "        [0.0794, 0.1174, 0.1289, 0.1321, 0.0948, 0.1325, 0.1051, 0.1172, 0.0870,\n",
      "         0.0057],\n",
      "        [0.0796, 0.1170, 0.1283, 0.1315, 0.0954, 0.1319, 0.1054, 0.1171, 0.0877,\n",
      "         0.0061],\n",
      "        [0.0794, 0.1170, 0.1284, 0.1315, 0.0953, 0.1320, 0.1052, 0.1173, 0.0879,\n",
      "         0.0061],\n",
      "        [0.0791, 0.1171, 0.1285, 0.1317, 0.0951, 0.1321, 0.1050, 0.1174, 0.0881,\n",
      "         0.0061],\n",
      "        [0.0790, 0.1171, 0.1286, 0.1317, 0.0950, 0.1322, 0.1049, 0.1174, 0.0881,\n",
      "         0.0061],\n",
      "        [0.0789, 0.1171, 0.1286, 0.1317, 0.0949, 0.1322, 0.1049, 0.1174, 0.0882,\n",
      "         0.0061]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 那 就是 她 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: there she is . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the the , , , <EOS> <EOS>\n",
      "Attention Weights: tensor([[8.1058e-02, 1.2610e-01, 1.4051e-01, 1.4542e-01, 1.4532e-01, 1.4033e-01,\n",
      "         1.2886e-01, 9.0290e-02, 2.1035e-03, 6.7423e-13],\n",
      "        [8.0540e-02, 1.2454e-01, 1.3892e-01, 1.4387e-01, 1.4395e-01, 1.3961e-01,\n",
      "         1.2940e-01, 9.4814e-02, 4.3490e-03, 1.3658e-11],\n",
      "        [8.2555e-02, 1.2385e-01, 1.3715e-01, 1.4177e-01, 1.4200e-01, 1.3836e-01,\n",
      "         1.2951e-01, 9.8540e-02, 6.2543e-03, 4.0527e-11],\n",
      "        [8.4273e-02, 1.2374e-01, 1.3610e-01, 1.4040e-01, 1.4061e-01, 1.3738e-01,\n",
      "         1.2931e-01, 1.0054e-01, 7.6456e-03, 6.9331e-11],\n",
      "        [8.4593e-02, 1.2358e-01, 1.3573e-01, 1.3997e-01, 1.4023e-01, 1.3714e-01,\n",
      "         1.2936e-01, 1.0133e-01, 8.0701e-03, 7.2339e-11],\n",
      "        [8.4273e-02, 1.2345e-01, 1.3568e-01, 1.3995e-01, 1.4024e-01, 1.3721e-01,\n",
      "         1.2955e-01, 1.0159e-01, 8.0700e-03, 7.2629e-11],\n",
      "        [8.3838e-02, 1.2335e-01, 1.3571e-01, 1.4003e-01, 1.4035e-01, 1.3733e-01,\n",
      "         1.2970e-01, 1.0166e-01, 8.0247e-03, 7.4949e-11],\n",
      "        [8.3696e-02, 1.2332e-01, 1.3571e-01, 1.4005e-01, 1.4038e-01, 1.3736e-01,\n",
      "         1.2974e-01, 1.0171e-01, 8.0286e-03, 7.6877e-11],\n",
      "        [8.3659e-02, 1.2331e-01, 1.3570e-01, 1.4005e-01, 1.4038e-01, 1.3736e-01,\n",
      "         1.2976e-01, 1.0175e-01, 8.0464e-03, 7.7976e-11]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 47.00, Train Loss: 3.79, Val Loss: 11.34, Train BLEU: 6.89, Val BLEU: 0.24\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克 泰坦尼克号 坦尼 尼克 号 是 拿 了 不少\n",
      "Reference: the truth of the matter is that the titanic\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0581, 0.0828, 0.0915, 0.1064, 0.1254, 0.1284, 0.1265, 0.1216, 0.1072,\n",
      "         0.0523],\n",
      "        [0.0603, 0.0824, 0.0917, 0.1053, 0.1229, 0.1260, 0.1244, 0.1202, 0.1078,\n",
      "         0.0591],\n",
      "        [0.0630, 0.0840, 0.0930, 0.1054, 0.1205, 0.1230, 0.1217, 0.1181, 0.1076,\n",
      "         0.0639],\n",
      "        [0.0647, 0.0853, 0.0940, 0.1056, 0.1192, 0.1213, 0.1201, 0.1168, 0.1072,\n",
      "         0.0657],\n",
      "        [0.0650, 0.0855, 0.0940, 0.1054, 0.1188, 0.1209, 0.1197, 0.1166, 0.1073,\n",
      "         0.0666],\n",
      "        [0.0648, 0.0853, 0.0936, 0.1053, 0.1189, 0.1211, 0.1199, 0.1168, 0.1075,\n",
      "         0.0667],\n",
      "        [0.0645, 0.0851, 0.0933, 0.1052, 0.1190, 0.1213, 0.1201, 0.1170, 0.1077,\n",
      "         0.0668],\n",
      "        [0.0643, 0.0850, 0.0932, 0.1051, 0.1191, 0.1213, 0.1202, 0.1172, 0.1079,\n",
      "         0.0669],\n",
      "        [0.0642, 0.0849, 0.0931, 0.1050, 0.1191, 0.1214, 0.1202, 0.1172, 0.1079,\n",
      "         0.0670]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正 的 学校 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: a real school . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the the , , <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0666, 0.1046, 0.1165, 0.1222, 0.1244, 0.1245, 0.1233, 0.1177, 0.0939,\n",
      "         0.0064],\n",
      "        [0.0678, 0.1041, 0.1157, 0.1211, 0.1231, 0.1230, 0.1219, 0.1168, 0.0958,\n",
      "         0.0108],\n",
      "        [0.0701, 0.1040, 0.1146, 0.1195, 0.1214, 0.1215, 0.1207, 0.1164, 0.0980,\n",
      "         0.0138],\n",
      "        [0.0718, 0.1041, 0.1141, 0.1186, 0.1204, 0.1206, 0.1199, 0.1160, 0.0990,\n",
      "         0.0155],\n",
      "        [0.0720, 0.1040, 0.1139, 0.1184, 0.1202, 0.1204, 0.1197, 0.1160, 0.0994,\n",
      "         0.0160],\n",
      "        [0.0716, 0.1039, 0.1139, 0.1184, 0.1202, 0.1205, 0.1198, 0.1162, 0.0996,\n",
      "         0.0159],\n",
      "        [0.0713, 0.1039, 0.1139, 0.1184, 0.1203, 0.1205, 0.1199, 0.1163, 0.0997,\n",
      "         0.0158],\n",
      "        [0.0711, 0.1039, 0.1139, 0.1184, 0.1203, 0.1205, 0.1199, 0.1163, 0.0997,\n",
      "         0.0159],\n",
      "        [0.0711, 0.1039, 0.1139, 0.1184, 0.1203, 0.1205, 0.1199, 0.1163, 0.0998,\n",
      "         0.0159]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48.00, Train Loss: 3.77, Val Loss: 11.35, Train BLEU: 6.89, Val BLEU: 0.24\n",
      "Sampling from training predictions...\n",
      "Source: 我们 将 用 一些 影片 来讲 讲述 一些 深海 海里\n",
      "Reference: and we &apos;re going to tell you some stories\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0643, 0.1001, 0.1104, 0.1150, 0.1177, 0.1182, 0.1165, 0.1119, 0.0984,\n",
      "         0.0476],\n",
      "        [0.0658, 0.0998, 0.1095, 0.1136, 0.1159, 0.1164, 0.1149, 0.1109, 0.0992,\n",
      "         0.0539],\n",
      "        [0.0683, 0.0995, 0.1083, 0.1121, 0.1142, 0.1147, 0.1135, 0.1101, 0.1001,\n",
      "         0.0591],\n",
      "        [0.0699, 0.0996, 0.1078, 0.1114, 0.1134, 0.1138, 0.1127, 0.1097, 0.1004,\n",
      "         0.0614],\n",
      "        [0.0703, 0.0995, 0.1076, 0.1111, 0.1130, 0.1135, 0.1125, 0.1095, 0.1006,\n",
      "         0.0624],\n",
      "        [0.0702, 0.0994, 0.1075, 0.1110, 0.1130, 0.1135, 0.1125, 0.1096, 0.1008,\n",
      "         0.0625],\n",
      "        [0.0700, 0.0994, 0.1075, 0.1110, 0.1130, 0.1135, 0.1126, 0.1096, 0.1008,\n",
      "         0.0625],\n",
      "        [0.0698, 0.0994, 0.1075, 0.1110, 0.1131, 0.1135, 0.1126, 0.1097, 0.1009,\n",
      "         0.0626],\n",
      "        [0.0697, 0.0993, 0.1075, 0.1110, 0.1131, 0.1135, 0.1126, 0.1097, 0.1009,\n",
      "         0.0627]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 出身 阿富汗 边远 <UNK> 地区 有着 与 他人 不同\n",
      "Reference: a total maverick from a remote province of afghanistan\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[8.5566e-02, 1.3323e-01, 1.4509e-01, 1.4725e-01, 1.2939e-01, 1.4391e-01,\n",
      "         1.3084e-01, 8.2996e-02, 1.7325e-03, 6.8055e-13],\n",
      "        [8.4953e-02, 1.3135e-01, 1.4313e-01, 1.4528e-01, 1.2973e-01, 1.4223e-01,\n",
      "         1.3100e-01, 8.8549e-02, 3.7934e-03, 1.4137e-11],\n",
      "        [8.6848e-02, 1.2976e-01, 1.4064e-01, 1.4287e-01, 1.2943e-01, 1.4069e-01,\n",
      "         1.3100e-01, 9.3030e-02, 5.7287e-03, 4.3022e-11],\n",
      "        [8.8571e-02, 1.2910e-01, 1.3915e-01, 1.4136e-01, 1.2914e-01, 1.3943e-01,\n",
      "         1.3063e-01, 9.5452e-02, 7.1772e-03, 7.4076e-11],\n",
      "        [8.8968e-02, 1.2881e-01, 1.3866e-01, 1.4087e-01, 1.2895e-01, 1.3904e-01,\n",
      "         1.3061e-01, 9.6413e-02, 7.6724e-03, 7.8091e-11],\n",
      "        [8.8819e-02, 1.2872e-01, 1.3858e-01, 1.4078e-01, 1.2869e-01, 1.3908e-01,\n",
      "         1.3083e-01, 9.6762e-02, 7.7458e-03, 7.8591e-11],\n",
      "        [8.8446e-02, 1.2867e-01, 1.3861e-01, 1.4081e-01, 1.2852e-01, 1.3925e-01,\n",
      "         1.3105e-01, 9.6908e-02, 7.7413e-03, 8.1232e-11],\n",
      "        [8.8279e-02, 1.2863e-01, 1.3861e-01, 1.4080e-01, 1.2846e-01, 1.3929e-01,\n",
      "         1.3113e-01, 9.7017e-02, 7.7743e-03, 8.4167e-11],\n",
      "        [8.8240e-02, 1.2861e-01, 1.3858e-01, 1.4078e-01, 1.2843e-01, 1.3929e-01,\n",
      "         1.3116e-01, 9.7093e-02, 7.8118e-03, 8.5789e-11]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 49.00, Train Loss: 3.75, Val Loss: 11.36, Train BLEU: 7.08, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里 生物 的 多样 多样性 和 密度 要 比\n",
      "Reference: the biodiversity and the <UNK> in the ocean is\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0635, 0.1006, 0.1106, 0.1156, 0.1163, 0.1082, 0.1175, 0.1123, 0.1004,\n",
      "         0.0551],\n",
      "        [0.0653, 0.1004, 0.1096, 0.1141, 0.1147, 0.1072, 0.1157, 0.1112, 0.1009,\n",
      "         0.0609],\n",
      "        [0.0679, 0.1000, 0.1083, 0.1123, 0.1130, 0.1068, 0.1140, 0.1102, 0.1016,\n",
      "         0.0659],\n",
      "        [0.0696, 0.1000, 0.1078, 0.1115, 0.1122, 0.1067, 0.1131, 0.1096, 0.1016,\n",
      "         0.0679],\n",
      "        [0.0701, 0.0999, 0.1076, 0.1111, 0.1119, 0.1067, 0.1127, 0.1094, 0.1017,\n",
      "         0.0689],\n",
      "        [0.0700, 0.0998, 0.1075, 0.1111, 0.1119, 0.1065, 0.1128, 0.1095, 0.1019,\n",
      "         0.0691],\n",
      "        [0.0697, 0.0998, 0.1075, 0.1111, 0.1119, 0.1064, 0.1129, 0.1096, 0.1020,\n",
      "         0.0691],\n",
      "        [0.0696, 0.0998, 0.1075, 0.1111, 0.1118, 0.1063, 0.1129, 0.1096, 0.1021,\n",
      "         0.0693],\n",
      "        [0.0695, 0.0997, 0.1075, 0.1111, 0.1119, 0.1063, 0.1129, 0.1096, 0.1021,\n",
      "         0.0694]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6 岁 那年 塔利 塔利班 占领 阿富汗 并 规定\n",
      "Reference: you see , i was six when the taliban\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[8.3987e-02, 1.3042e-01, 1.4207e-01, 1.4574e-01, 1.4672e-01, 1.4180e-01,\n",
      "         1.2770e-01, 7.9976e-02, 1.5991e-03, 6.6389e-13],\n",
      "        [8.3756e-02, 1.2907e-01, 1.4038e-01, 1.4367e-01, 1.4483e-01, 1.4076e-01,\n",
      "         1.2824e-01, 8.5717e-02, 3.5799e-03, 1.4058e-11],\n",
      "        [8.5933e-02, 1.2780e-01, 1.3828e-01, 1.4149e-01, 1.4266e-01, 1.3926e-01,\n",
      "         1.2855e-01, 9.0493e-02, 5.5337e-03, 4.3589e-11],\n",
      "        [8.7937e-02, 1.2731e-01, 1.3703e-01, 1.4010e-01, 1.4111e-01, 1.3797e-01,\n",
      "         1.2834e-01, 9.3162e-02, 7.0499e-03, 7.5297e-11],\n",
      "        [8.8471e-02, 1.2707e-01, 1.3657e-01, 1.3958e-01, 1.4058e-01, 1.3756e-01,\n",
      "         1.2833e-01, 9.4242e-02, 7.6039e-03, 7.9095e-11],\n",
      "        [8.8288e-02, 1.2691e-01, 1.3642e-01, 1.3945e-01, 1.4053e-01, 1.3761e-01,\n",
      "         1.2852e-01, 9.4580e-02, 7.6881e-03, 8.0649e-11],\n",
      "        [8.7889e-02, 1.2681e-01, 1.3638e-01, 1.3944e-01, 1.4060e-01, 1.3775e-01,\n",
      "         1.2870e-01, 9.4727e-02, 7.6978e-03, 8.3750e-11],\n",
      "        [8.7756e-02, 1.2676e-01, 1.3634e-01, 1.3941e-01, 1.4060e-01, 1.3777e-01,\n",
      "         1.2876e-01, 9.4851e-02, 7.7495e-03, 8.6791e-11],\n",
      "        [8.7730e-02, 1.2673e-01, 1.3631e-01, 1.3938e-01, 1.4057e-01, 1.3777e-01,\n",
      "         1.2878e-01, 9.4942e-02, 7.7965e-03, 8.8506e-11]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 50.00, Train Loss: 3.73, Val Loss: 11.38, Train BLEU: 7.08, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中 的 生命 大卫 <UNK> <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: life in the deep oceans <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the the , <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.3887e-01, 2.1253e-01, 2.2899e-01, 2.2258e-01, 1.7912e-01, 1.6655e-02,\n",
      "         1.2715e-03, 1.0510e-12, 1.0510e-12, 1.0510e-12],\n",
      "        [1.3738e-01, 2.0790e-01, 2.2434e-01, 2.1881e-01, 1.8160e-01, 2.6695e-02,\n",
      "         3.2871e-03, 2.3335e-11, 2.3335e-11, 2.3335e-11],\n",
      "        [1.3933e-01, 2.0349e-01, 2.1860e-01, 2.1463e-01, 1.8328e-01, 3.5092e-02,\n",
      "         5.5746e-03, 7.4438e-11, 7.4438e-11, 7.4438e-11],\n",
      "        [1.4169e-01, 2.0108e-01, 2.1469e-01, 2.1140e-01, 1.8341e-01, 4.0349e-02,\n",
      "         7.3875e-03, 1.2691e-10, 1.2691e-10, 1.2691e-10],\n",
      "        [1.4204e-01, 2.0011e-01, 2.1339e-01, 2.1042e-01, 1.8377e-01, 4.2274e-02,\n",
      "         7.9964e-03, 1.3041e-10, 1.3041e-10, 1.3041e-10],\n",
      "        [1.4167e-01, 1.9998e-01, 2.1342e-01, 2.1057e-01, 1.8403e-01, 4.2301e-02,\n",
      "         8.0236e-03, 1.3403e-10, 1.3403e-10, 1.3403e-10],\n",
      "        [1.4117e-01, 1.9995e-01, 2.1355e-01, 2.1077e-01, 1.8423e-01, 4.2300e-02,\n",
      "         8.0374e-03, 1.4007e-10, 1.4007e-10, 1.4007e-10],\n",
      "        [1.4104e-01, 1.9985e-01, 2.1349e-01, 2.1075e-01, 1.8431e-01, 4.2459e-02,\n",
      "         8.1031e-03, 1.4456e-10, 1.4456e-10, 1.4456e-10],\n",
      "        [1.4102e-01, 1.9978e-01, 2.1341e-01, 2.1070e-01, 1.8435e-01, 4.2594e-02,\n",
      "         8.1578e-03, 1.4705e-10, 1.4705e-10, 1.4705e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 很 害怕 但是 我们 仍然 渴望 望去 学校 <EOS>\n",
      "Reference: we were scared , but still , school was\n",
      "Model: <SOS> it &apos;s the the , <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0666, 0.0995, 0.1098, 0.1146, 0.1163, 0.1164, 0.1143, 0.1099, 0.0983,\n",
      "         0.0543],\n",
      "        [0.0688, 0.0995, 0.1089, 0.1132, 0.1145, 0.1147, 0.1127, 0.1087, 0.0988,\n",
      "         0.0601],\n",
      "        [0.0713, 0.0993, 0.1077, 0.1115, 0.1128, 0.1129, 0.1114, 0.1080, 0.0997,\n",
      "         0.0653],\n",
      "        [0.0731, 0.0995, 0.1072, 0.1107, 0.1119, 0.1120, 0.1106, 0.1076, 0.1000,\n",
      "         0.0675],\n",
      "        [0.0736, 0.0994, 0.1070, 0.1103, 0.1115, 0.1116, 0.1103, 0.1074, 0.1001,\n",
      "         0.0686],\n",
      "        [0.0735, 0.0993, 0.1069, 0.1103, 0.1115, 0.1116, 0.1103, 0.1075, 0.1003,\n",
      "         0.0688],\n",
      "        [0.0733, 0.0992, 0.1069, 0.1103, 0.1115, 0.1116, 0.1104, 0.1076, 0.1004,\n",
      "         0.0688],\n",
      "        [0.0732, 0.0992, 0.1068, 0.1102, 0.1115, 0.1116, 0.1104, 0.1076, 0.1004,\n",
      "         0.0690],\n",
      "        [0.0731, 0.0992, 0.1068, 0.1102, 0.1115, 0.1116, 0.1104, 0.1076, 0.1005,\n",
      "         0.0691]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 51.00, Train Loss: 3.71, Val Loss: 11.39, Train BLEU: 7.10, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本 基本上 都 没有 被 开发 发过 但是 像\n",
      "Reference: it &apos;s mostly unexplored , and yet there are\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0640, 0.1002, 0.1105, 0.1159, 0.1171, 0.1170, 0.1142, 0.1096, 0.0973,\n",
      "         0.0542],\n",
      "        [0.0664, 0.1002, 0.1095, 0.1144, 0.1153, 0.1151, 0.1125, 0.1085, 0.0978,\n",
      "         0.0602],\n",
      "        [0.0693, 0.0999, 0.1082, 0.1124, 0.1133, 0.1132, 0.1111, 0.1079, 0.0990,\n",
      "         0.0657],\n",
      "        [0.0713, 0.1000, 0.1077, 0.1114, 0.1123, 0.1121, 0.1103, 0.1074, 0.0993,\n",
      "         0.0681],\n",
      "        [0.0719, 0.0999, 0.1074, 0.1110, 0.1119, 0.1118, 0.1100, 0.1073, 0.0995,\n",
      "         0.0692],\n",
      "        [0.0717, 0.0998, 0.1073, 0.1110, 0.1119, 0.1118, 0.1101, 0.1074, 0.0996,\n",
      "         0.0693],\n",
      "        [0.0716, 0.0998, 0.1073, 0.1110, 0.1119, 0.1118, 0.1101, 0.1074, 0.0997,\n",
      "         0.0695],\n",
      "        [0.0714, 0.0997, 0.1072, 0.1110, 0.1119, 0.1118, 0.1101, 0.1074, 0.0998,\n",
      "         0.0696],\n",
      "        [0.0713, 0.0997, 0.1072, 0.1109, 0.1118, 0.1118, 0.1101, 0.1074, 0.0999,\n",
      "         0.0698]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很 舒服 但 夏天 却 <UNK> <EOS> <PAD> <PAD>\n",
      "Reference: it was cozy in winter but extremely hot in\n",
      "Model: <SOS> it &apos;s the the , <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0643, 0.1019, 0.1116, 0.1158, 0.1161, 0.1073, 0.1166, 0.1115, 0.0997,\n",
      "         0.0553],\n",
      "        [0.0666, 0.1018, 0.1105, 0.1143, 0.1144, 0.1063, 0.1146, 0.1102, 0.1001,\n",
      "         0.0613],\n",
      "        [0.0695, 0.1012, 0.1090, 0.1123, 0.1126, 0.1059, 0.1129, 0.1092, 0.1008,\n",
      "         0.0666],\n",
      "        [0.0714, 0.1011, 0.1083, 0.1113, 0.1117, 0.1058, 0.1119, 0.1086, 0.1010,\n",
      "         0.0689],\n",
      "        [0.0720, 0.1010, 0.1080, 0.1109, 0.1113, 0.1058, 0.1115, 0.1084, 0.1010,\n",
      "         0.0700],\n",
      "        [0.0719, 0.1009, 0.1079, 0.1109, 0.1113, 0.1057, 0.1116, 0.1085, 0.1012,\n",
      "         0.0702],\n",
      "        [0.0717, 0.1008, 0.1079, 0.1109, 0.1113, 0.1055, 0.1117, 0.1086, 0.1013,\n",
      "         0.0703],\n",
      "        [0.0716, 0.1008, 0.1078, 0.1108, 0.1112, 0.1055, 0.1117, 0.1086, 0.1014,\n",
      "         0.0705],\n",
      "        [0.0715, 0.1008, 0.1078, 0.1108, 0.1112, 0.1055, 0.1117, 0.1086, 0.1015,\n",
      "         0.0706]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52.00, Train Loss: 3.69, Val Loss: 11.40, Train BLEU: 7.09, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 我 真 喜欢 这些 东西 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: i love that kind of stuff . <EOS> <PAD>\n",
      "Model: <SOS> it &apos;s the the , <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.5984e-01, 2.2995e-01, 2.4014e-01, 2.2372e-01, 1.4411e-01, 2.2454e-03,\n",
      "         1.1927e-12, 1.1927e-12, 1.1927e-12, 1.1927e-12],\n",
      "        [1.5902e-01, 2.2647e-01, 2.3600e-01, 2.2134e-01, 1.5188e-01, 5.2992e-03,\n",
      "         2.6446e-11, 2.6446e-11, 2.6446e-11, 2.6446e-11],\n",
      "        [1.6063e-01, 2.2149e-01, 2.3086e-01, 2.1923e-01, 1.5901e-01, 8.7832e-03,\n",
      "         8.5534e-11, 8.5534e-11, 8.5534e-11, 8.5534e-11],\n",
      "        [1.6310e-01, 2.1834e-01, 2.2688e-01, 2.1693e-01, 1.6288e-01, 1.1871e-02,\n",
      "         1.4949e-10, 1.4949e-10, 1.4949e-10, 1.4949e-10],\n",
      "        [1.6361e-01, 2.1725e-01, 2.2557e-01, 2.1618e-01, 1.6443e-01, 1.2973e-02,\n",
      "         1.5633e-10, 1.5633e-10, 1.5633e-10, 1.5633e-10],\n",
      "        [1.6335e-01, 2.1692e-01, 2.2532e-01, 2.1622e-01, 1.6501e-01, 1.3160e-02,\n",
      "         1.6281e-10, 1.6281e-10, 1.6281e-10, 1.6281e-10],\n",
      "        [1.6285e-01, 2.1683e-01, 2.2534e-01, 2.1638e-01, 1.6536e-01, 1.3243e-02,\n",
      "         1.7008e-10, 1.7008e-10, 1.7008e-10, 1.7008e-10],\n",
      "        [1.6280e-01, 2.1670e-01, 2.2521e-01, 2.1633e-01, 1.6558e-01, 1.3399e-02,\n",
      "         1.7726e-10, 1.7726e-10, 1.7726e-10, 1.7726e-10],\n",
      "        [1.6279e-01, 2.1661e-01, 2.2511e-01, 2.1628e-01, 1.6570e-01, 1.3506e-02,\n",
      "         1.8127e-10, 1.8127e-10, 1.8127e-10, 1.8127e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 很 害怕 但是 我们 仍然 渴望 望去 学校 <EOS>\n",
      "Reference: we were scared , but still , school was\n",
      "Model: <SOS> it &apos;s the the , <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0671, 0.1006, 0.1108, 0.1150, 0.1162, 0.1158, 0.1136, 0.1092, 0.0975,\n",
      "         0.0542],\n",
      "        [0.0697, 0.1008, 0.1099, 0.1135, 0.1144, 0.1141, 0.1119, 0.1078, 0.0979,\n",
      "         0.0601],\n",
      "        [0.0724, 0.1004, 0.1084, 0.1116, 0.1125, 0.1122, 0.1105, 0.1072, 0.0990,\n",
      "         0.0657],\n",
      "        [0.0744, 0.1005, 0.1078, 0.1107, 0.1115, 0.1112, 0.1097, 0.1067, 0.0993,\n",
      "         0.0681],\n",
      "        [0.0751, 0.1005, 0.1075, 0.1103, 0.1111, 0.1108, 0.1094, 0.1065, 0.0994,\n",
      "         0.0694],\n",
      "        [0.0750, 0.1003, 0.1074, 0.1102, 0.1111, 0.1108, 0.1094, 0.1066, 0.0996,\n",
      "         0.0696],\n",
      "        [0.0749, 0.1003, 0.1074, 0.1102, 0.1110, 0.1108, 0.1095, 0.1067, 0.0997,\n",
      "         0.0697],\n",
      "        [0.0748, 0.1002, 0.1073, 0.1101, 0.1110, 0.1108, 0.1095, 0.1067, 0.0997,\n",
      "         0.0698],\n",
      "        [0.0747, 0.1002, 0.1073, 0.1101, 0.1110, 0.1108, 0.1095, 0.1067, 0.0998,\n",
      "         0.0700]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 53.00, Train Loss: 3.67, Val Loss: 11.41, Train BLEU: 7.07, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 但 我 想 告诉 你 的 是 当 你 站\n",
      "Reference: but when you &apos;re standing at the beach ,\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0675, 0.1016, 0.1111, 0.1148, 0.1161, 0.1154, 0.1131, 0.1086, 0.0971,\n",
      "         0.0548],\n",
      "        [0.0703, 0.1020, 0.1104, 0.1132, 0.1143, 0.1134, 0.1113, 0.1073, 0.0973,\n",
      "         0.0605],\n",
      "        [0.0732, 0.1014, 0.1088, 0.1113, 0.1123, 0.1116, 0.1099, 0.1067, 0.0986,\n",
      "         0.0663],\n",
      "        [0.0754, 0.1013, 0.1080, 0.1103, 0.1112, 0.1106, 0.1091, 0.1062, 0.0989,\n",
      "         0.0690],\n",
      "        [0.0761, 0.1012, 0.1077, 0.1100, 0.1107, 0.1102, 0.1087, 0.1060, 0.0991,\n",
      "         0.0703],\n",
      "        [0.0760, 0.1011, 0.1076, 0.1099, 0.1107, 0.1102, 0.1088, 0.1061, 0.0992,\n",
      "         0.0704],\n",
      "        [0.0759, 0.1010, 0.1075, 0.1098, 0.1107, 0.1102, 0.1088, 0.1061, 0.0993,\n",
      "         0.0706],\n",
      "        [0.0758, 0.1010, 0.1075, 0.1098, 0.1107, 0.1102, 0.1088, 0.1062, 0.0994,\n",
      "         0.0707],\n",
      "        [0.0757, 0.1010, 0.1075, 0.1098, 0.1106, 0.1102, 0.1088, 0.1062, 0.0994,\n",
      "         0.0709]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 父亲 在 用 他 的 灰色 小 收音\n",
      "Reference: my father was listening to bbc news on his\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0572, 0.0368, 0.1224, 0.1275, 0.1049, 0.1319, 0.1300, 0.1242, 0.1096,\n",
      "         0.0557],\n",
      "        [0.0621, 0.0471, 0.1189, 0.1239, 0.1051, 0.1270, 0.1255, 0.1203, 0.1082,\n",
      "         0.0619],\n",
      "        [0.0662, 0.0547, 0.1159, 0.1204, 0.1050, 0.1229, 0.1217, 0.1176, 0.1079,\n",
      "         0.0678],\n",
      "        [0.0687, 0.0586, 0.1146, 0.1187, 0.1050, 0.1208, 0.1197, 0.1161, 0.1074,\n",
      "         0.0704],\n",
      "        [0.0695, 0.0597, 0.1141, 0.1180, 0.1050, 0.1201, 0.1190, 0.1156, 0.1073,\n",
      "         0.0716],\n",
      "        [0.0691, 0.0595, 0.1140, 0.1180, 0.1049, 0.1203, 0.1192, 0.1158, 0.1075,\n",
      "         0.0717],\n",
      "        [0.0689, 0.0592, 0.1139, 0.1179, 0.1048, 0.1203, 0.1193, 0.1160, 0.1077,\n",
      "         0.0719],\n",
      "        [0.0688, 0.0592, 0.1139, 0.1179, 0.1048, 0.1203, 0.1193, 0.1160, 0.1078,\n",
      "         0.0721],\n",
      "        [0.0687, 0.0592, 0.1138, 0.1179, 0.1047, 0.1203, 0.1193, 0.1160, 0.1079,\n",
      "         0.0723]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 54.00, Train Loss: 3.65, Val Loss: 11.43, Train BLEU: 7.01, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 这位 是 比尔 <UNK> 我 是 大卫 <UNK>\n",
      "Reference: this is bill lange . i &apos;m dave gallo\n",
      "Model: <SOS> it &apos;s the the , , , , ,\n",
      "Attention Weights: tensor([[0.0702, 0.0401, 0.1511, 0.1575, 0.1123, 0.0527, 0.1589, 0.1491, 0.1048,\n",
      "         0.0034],\n",
      "        [0.0728, 0.0502, 0.1438, 0.1508, 0.1129, 0.0633, 0.1503, 0.1427, 0.1061,\n",
      "         0.0070],\n",
      "        [0.0763, 0.0584, 0.1377, 0.1437, 0.1126, 0.0713, 0.1434, 0.1376, 0.1079,\n",
      "         0.0111],\n",
      "        [0.0789, 0.0632, 0.1340, 0.1394, 0.1130, 0.0758, 0.1390, 0.1341, 0.1084,\n",
      "         0.0141],\n",
      "        [0.0794, 0.0642, 0.1328, 0.1381, 0.1131, 0.0769, 0.1380, 0.1334, 0.1090,\n",
      "         0.0151],\n",
      "        [0.0789, 0.0638, 0.1327, 0.1382, 0.1128, 0.0766, 0.1385, 0.1340, 0.1095,\n",
      "         0.0150],\n",
      "        [0.0786, 0.0637, 0.1326, 0.1381, 0.1127, 0.0766, 0.1386, 0.1341, 0.1098,\n",
      "         0.0151],\n",
      "        [0.0786, 0.0637, 0.1326, 0.1381, 0.1127, 0.0766, 0.1386, 0.1342, 0.1099,\n",
      "         0.0152],\n",
      "        [0.0785, 0.0637, 0.1325, 0.1380, 0.1127, 0.0767, 0.1386, 0.1342, 0.1100,\n",
      "         0.0153]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 永远 不会 忘记 那个 早晨 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: a morning that i will never forget . <EOS>\n",
      "Model: <SOS> it &apos;s the the , <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0796, 0.1270, 0.1400, 0.1445, 0.1453, 0.1420, 0.1316, 0.0857, 0.0043,\n",
      "         0.0002],\n",
      "        [0.0810, 0.1263, 0.1386, 0.1424, 0.1432, 0.1401, 0.1306, 0.0897, 0.0072,\n",
      "         0.0008],\n",
      "        [0.0847, 0.1250, 0.1358, 0.1392, 0.1400, 0.1377, 0.1302, 0.0949, 0.0108,\n",
      "         0.0016],\n",
      "        [0.0875, 0.1244, 0.1341, 0.1372, 0.1378, 0.1358, 0.1293, 0.0978, 0.0136,\n",
      "         0.0023],\n",
      "        [0.0883, 0.1241, 0.1335, 0.1366, 0.1372, 0.1353, 0.1291, 0.0987, 0.0146,\n",
      "         0.0026],\n",
      "        [0.0882, 0.1240, 0.1334, 0.1365, 0.1372, 0.1353, 0.1292, 0.0990, 0.0148,\n",
      "         0.0026],\n",
      "        [0.0881, 0.1239, 0.1333, 0.1363, 0.1371, 0.1353, 0.1292, 0.0992, 0.0150,\n",
      "         0.0026],\n",
      "        [0.0880, 0.1239, 0.1332, 0.1363, 0.1370, 0.1352, 0.1292, 0.0994, 0.0151,\n",
      "         0.0027],\n",
      "        [0.0880, 0.1238, 0.1332, 0.1362, 0.1370, 0.1352, 0.1292, 0.0995, 0.0152,\n",
      "         0.0027]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 55.00, Train Loss: 3.64, Val Loss: 11.44, Train BLEU: 7.14, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 还有 这些 摇晃 着 旋转 转着 的 触角 <EOS> <PAD>\n",
      "Reference: it &apos;s got tentacles dangling , swirling around like\n",
      "Model: <SOS> it &apos;s the the , <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[8.5242e-02, 1.3772e-01, 1.5154e-01, 1.5328e-01, 1.4797e-01, 1.1753e-01,\n",
      "         1.2601e-01, 7.9676e-02, 1.0350e-03, 6.1161e-13],\n",
      "        [8.6015e-02, 1.3641e-01, 1.4916e-01, 1.5094e-01, 1.4586e-01, 1.1757e-01,\n",
      "         1.2637e-01, 8.5157e-02, 2.5276e-03, 1.4212e-11],\n",
      "        [8.8750e-02, 1.3411e-01, 1.4555e-01, 1.4738e-01, 1.4332e-01, 1.1793e-01,\n",
      "         1.2717e-01, 9.1175e-02, 4.6101e-03, 5.0557e-11],\n",
      "        [9.1844e-02, 1.3274e-01, 1.4284e-01, 1.4444e-01, 1.4097e-01, 1.1873e-01,\n",
      "         1.2694e-01, 9.4795e-02, 6.6913e-03, 9.1839e-11],\n",
      "        [9.2798e-02, 1.3207e-01, 1.4174e-01, 1.4325e-01, 1.4005e-01, 1.1912e-01,\n",
      "         1.2690e-01, 9.6447e-02, 7.6334e-03, 9.7894e-11],\n",
      "        [9.2696e-02, 1.3171e-01, 1.4135e-01, 1.4292e-01, 1.3984e-01, 1.1924e-01,\n",
      "         1.2720e-01, 9.7196e-02, 7.8571e-03, 1.0080e-10],\n",
      "        [9.2427e-02, 1.3152e-01, 1.4117e-01, 1.4278e-01, 1.3975e-01, 1.1936e-01,\n",
      "         1.2739e-01, 9.7623e-02, 7.9908e-03, 1.0674e-10],\n",
      "        [9.2440e-02, 1.3145e-01, 1.4106e-01, 1.4267e-01, 1.3966e-01, 1.1941e-01,\n",
      "         1.2740e-01, 9.7811e-02, 8.0902e-03, 1.1093e-10],\n",
      "        [9.2467e-02, 1.3142e-01, 1.4101e-01, 1.4261e-01, 1.3961e-01, 1.1943e-01,\n",
      "         1.2740e-01, 9.7897e-02, 8.1476e-03, 1.1327e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 所以 在 那 之后 5 年 我 <UNK> <UNK> 陪\n",
      "Reference: so for the next five years , i dressed\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[1.0846e-01, 1.7284e-01, 1.8738e-01, 1.8718e-01, 1.7365e-01, 8.0271e-02,\n",
      "         8.9071e-02, 1.1449e-03, 7.9326e-13, 7.9326e-13],\n",
      "        [1.0811e-01, 1.6967e-01, 1.8295e-01, 1.8268e-01, 1.7129e-01, 8.6890e-02,\n",
      "         9.5550e-02, 2.8580e-03, 1.8108e-11, 1.8108e-11],\n",
      "        [1.1040e-01, 1.6524e-01, 1.7723e-01, 1.7750e-01, 1.6834e-01, 9.3257e-02,\n",
      "         1.0279e-01, 5.2512e-03, 6.3560e-11, 6.3560e-11],\n",
      "        [1.1331e-01, 1.6240e-01, 1.7299e-01, 1.7330e-01, 1.6535e-01, 9.8035e-02,\n",
      "         1.0704e-01, 7.5863e-03, 1.1386e-10, 1.1386e-10],\n",
      "        [1.1424e-01, 1.6125e-01, 1.7138e-01, 1.7173e-01, 1.6425e-01, 9.9681e-02,\n",
      "         1.0886e-01, 8.6074e-03, 1.2059e-10, 1.2059e-10],\n",
      "        [1.1431e-01, 1.6078e-01, 1.7085e-01, 1.7131e-01, 1.6406e-01, 1.0008e-01,\n",
      "         1.0970e-01, 8.9072e-03, 1.2515e-10, 1.2515e-10],\n",
      "        [1.1384e-01, 1.6057e-01, 1.7069e-01, 1.7123e-01, 1.6410e-01, 1.0030e-01,\n",
      "         1.1025e-01, 9.0166e-03, 1.3027e-10, 1.3027e-10],\n",
      "        [1.1377e-01, 1.6043e-01, 1.7051e-01, 1.7106e-01, 1.6399e-01, 1.0057e-01,\n",
      "         1.1053e-01, 9.1355e-03, 1.3588e-10, 1.3588e-10],\n",
      "        [1.1378e-01, 1.6036e-01, 1.7041e-01, 1.7097e-01, 1.6393e-01, 1.0070e-01,\n",
      "         1.1065e-01, 9.2035e-03, 1.3895e-10, 1.3895e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56.00, Train Loss: 3.62, Val Loss: 11.46, Train BLEU: 7.12, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一种 种群 栖 动物 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: it &apos;s a colonial animal . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the the . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.2428e-01, 1.8626e-01, 1.9932e-01, 1.9752e-01, 1.7952e-01, 1.1178e-01,\n",
      "         1.3155e-03, 8.3292e-13, 8.3292e-13, 8.3292e-13],\n",
      "        [1.2510e-01, 1.8510e-01, 1.9662e-01, 1.9433e-01, 1.7818e-01, 1.1752e-01,\n",
      "         3.1443e-03, 1.9546e-11, 1.9546e-11, 1.9546e-11],\n",
      "        [1.2769e-01, 1.8136e-01, 1.9197e-01, 1.9060e-01, 1.7750e-01, 1.2502e-01,\n",
      "         5.8487e-03, 7.0047e-11, 7.0047e-11, 7.0047e-11],\n",
      "        [1.3133e-01, 1.7888e-01, 1.8823e-01, 1.8721e-01, 1.7600e-01, 1.2964e-01,\n",
      "         8.7106e-03, 1.2819e-10, 1.2819e-10, 1.2819e-10],\n",
      "        [1.3245e-01, 1.7777e-01, 1.8667e-01, 1.8580e-01, 1.7537e-01, 1.3185e-01,\n",
      "         1.0080e-02, 1.3816e-10, 1.3816e-10, 1.3816e-10],\n",
      "        [1.3239e-01, 1.7719e-01, 1.8610e-01, 1.8547e-01, 1.7547e-01, 1.3289e-01,\n",
      "         1.0485e-02, 1.4217e-10, 1.4217e-10, 1.4217e-10],\n",
      "        [1.3216e-01, 1.7697e-01, 1.8588e-01, 1.8534e-01, 1.7553e-01, 1.3342e-01,\n",
      "         1.0708e-02, 1.5116e-10, 1.5116e-10, 1.5116e-10],\n",
      "        [1.3221e-01, 1.7688e-01, 1.8575e-01, 1.8522e-01, 1.7548e-01, 1.3363e-01,\n",
      "         1.0842e-02, 1.5656e-10, 1.5656e-10, 1.5656e-10],\n",
      "        [1.3225e-01, 1.7683e-01, 1.8568e-01, 1.8516e-01, 1.7545e-01, 1.3371e-01,\n",
      "         1.0912e-02, 1.5950e-10, 1.5950e-10, 1.5950e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在 可以 去 个 真正 的 学校 念书 了\n",
      "Reference: &quot; you can go to a real school now\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0579, 0.0741, 0.0825, 0.1005, 0.1318, 0.1335, 0.1306, 0.1245, 0.1094,\n",
      "         0.0553],\n",
      "        [0.0628, 0.0774, 0.0856, 0.1005, 0.1271, 0.1288, 0.1263, 0.1210, 0.1084,\n",
      "         0.0619],\n",
      "        [0.0672, 0.0807, 0.0880, 0.1006, 0.1227, 0.1242, 0.1222, 0.1181, 0.1081,\n",
      "         0.0682],\n",
      "        [0.0703, 0.0832, 0.0898, 0.1012, 0.1202, 0.1214, 0.1197, 0.1160, 0.1073,\n",
      "         0.0709],\n",
      "        [0.0713, 0.0840, 0.0903, 0.1012, 0.1193, 0.1204, 0.1188, 0.1153, 0.1071,\n",
      "         0.0724],\n",
      "        [0.0711, 0.0838, 0.0901, 0.1012, 0.1193, 0.1204, 0.1188, 0.1154, 0.1072,\n",
      "         0.0727],\n",
      "        [0.0708, 0.0837, 0.0900, 0.1012, 0.1193, 0.1204, 0.1188, 0.1155, 0.1074,\n",
      "         0.0729],\n",
      "        [0.0707, 0.0836, 0.0899, 0.1011, 0.1193, 0.1204, 0.1188, 0.1155, 0.1075,\n",
      "         0.0731],\n",
      "        [0.0706, 0.0836, 0.0898, 0.1011, 0.1193, 0.1204, 0.1188, 0.1156, 0.1076,\n",
      "         0.0733]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 57.00, Train Loss: 3.60, Val Loss: 11.47, Train BLEU: 7.15, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想 海洋 占 了 地球 球面 面积 的 75\n",
      "Reference: when you think about it , the oceans are\n",
      "Model: <SOS> and &apos;s the the , , , , the\n",
      "Attention Weights: tensor([[0.0677, 0.1106, 0.1220, 0.1252, 0.1258, 0.1247, 0.1215, 0.1136, 0.0863,\n",
      "         0.0026],\n",
      "        [0.0706, 0.1108, 0.1210, 0.1240, 0.1242, 0.1227, 0.1197, 0.1126, 0.0890,\n",
      "         0.0055],\n",
      "        [0.0743, 0.1101, 0.1191, 0.1216, 0.1219, 0.1208, 0.1183, 0.1125, 0.0926,\n",
      "         0.0088],\n",
      "        [0.0776, 0.1099, 0.1178, 0.1200, 0.1202, 0.1193, 0.1171, 0.1122, 0.0945,\n",
      "         0.0114],\n",
      "        [0.0785, 0.1096, 0.1172, 0.1194, 0.1196, 0.1188, 0.1168, 0.1121, 0.0954,\n",
      "         0.0125],\n",
      "        [0.0782, 0.1094, 0.1171, 0.1193, 0.1196, 0.1188, 0.1169, 0.1123, 0.0958,\n",
      "         0.0127],\n",
      "        [0.0781, 0.1093, 0.1169, 0.1192, 0.1195, 0.1188, 0.1169, 0.1124, 0.0960,\n",
      "         0.0128],\n",
      "        [0.0780, 0.1092, 0.1169, 0.1191, 0.1195, 0.1188, 0.1169, 0.1125, 0.0962,\n",
      "         0.0130],\n",
      "        [0.0780, 0.1092, 0.1168, 0.1191, 0.1194, 0.1187, 0.1169, 0.1125, 0.0963,\n",
      "         0.0130]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正 的 学校 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: a real school . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the the . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0677, 0.1106, 0.1220, 0.1252, 0.1258, 0.1247, 0.1215, 0.1136, 0.0863,\n",
      "         0.0026],\n",
      "        [0.0706, 0.1108, 0.1210, 0.1240, 0.1242, 0.1227, 0.1197, 0.1126, 0.0890,\n",
      "         0.0055],\n",
      "        [0.0743, 0.1101, 0.1191, 0.1216, 0.1219, 0.1208, 0.1183, 0.1125, 0.0926,\n",
      "         0.0088],\n",
      "        [0.0776, 0.1099, 0.1178, 0.1200, 0.1202, 0.1193, 0.1171, 0.1122, 0.0945,\n",
      "         0.0114],\n",
      "        [0.0785, 0.1096, 0.1172, 0.1194, 0.1196, 0.1188, 0.1168, 0.1121, 0.0954,\n",
      "         0.0125],\n",
      "        [0.0782, 0.1094, 0.1171, 0.1193, 0.1196, 0.1188, 0.1169, 0.1123, 0.0958,\n",
      "         0.0127],\n",
      "        [0.0781, 0.1093, 0.1169, 0.1192, 0.1195, 0.1188, 0.1169, 0.1124, 0.0960,\n",
      "         0.0128],\n",
      "        [0.0780, 0.1092, 0.1169, 0.1191, 0.1195, 0.1188, 0.1169, 0.1125, 0.0962,\n",
      "         0.0130],\n",
      "        [0.0780, 0.1092, 0.1168, 0.1191, 0.1194, 0.1187, 0.1169, 0.1125, 0.0963,\n",
      "         0.0130]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 58.00, Train Loss: 3.57, Val Loss: 11.49, Train BLEU: 7.14, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想 海洋 占 了 地球 球面 面积 的 75\n",
      "Reference: when you think about it , the oceans are\n",
      "Model: <SOS> and &apos;s the the , , , , the\n",
      "Attention Weights: tensor([[0.0678, 0.1114, 0.1226, 0.1257, 0.1261, 0.1248, 0.1212, 0.1129, 0.0852,\n",
      "         0.0024],\n",
      "        [0.0704, 0.1115, 0.1218, 0.1245, 0.1245, 0.1229, 0.1195, 0.1121, 0.0879,\n",
      "         0.0050],\n",
      "        [0.0742, 0.1108, 0.1198, 0.1222, 0.1223, 0.1209, 0.1182, 0.1120, 0.0916,\n",
      "         0.0081],\n",
      "        [0.0776, 0.1105, 0.1184, 0.1205, 0.1206, 0.1195, 0.1170, 0.1117, 0.0936,\n",
      "         0.0106],\n",
      "        [0.0786, 0.1102, 0.1178, 0.1198, 0.1199, 0.1189, 0.1166, 0.1117, 0.0947,\n",
      "         0.0118],\n",
      "        [0.0784, 0.1100, 0.1176, 0.1196, 0.1198, 0.1189, 0.1167, 0.1119, 0.0951,\n",
      "         0.0120],\n",
      "        [0.0783, 0.1099, 0.1174, 0.1195, 0.1197, 0.1189, 0.1167, 0.1120, 0.0954,\n",
      "         0.0122],\n",
      "        [0.0783, 0.1098, 0.1173, 0.1194, 0.1197, 0.1188, 0.1167, 0.1120, 0.0956,\n",
      "         0.0124],\n",
      "        [0.0782, 0.1098, 0.1173, 0.1194, 0.1196, 0.1188, 0.1167, 0.1121, 0.0957,\n",
      "         0.0124]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 父亲 在 用 他 的 灰色 小 收音\n",
      "Reference: my father was listening to bbc news on his\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0510, 0.0213, 0.1266, 0.1318, 0.1030, 0.1369, 0.1344, 0.1272, 0.1109,\n",
      "         0.0569],\n",
      "        [0.0580, 0.0311, 0.1238, 0.1286, 0.1040, 0.1311, 0.1290, 0.1226, 0.1092,\n",
      "         0.0625],\n",
      "        [0.0635, 0.0400, 0.1201, 0.1244, 0.1043, 0.1261, 0.1244, 0.1194, 0.1088,\n",
      "         0.0691],\n",
      "        [0.0673, 0.0452, 0.1181, 0.1219, 0.1045, 0.1233, 0.1218, 0.1174, 0.1081,\n",
      "         0.0723],\n",
      "        [0.0685, 0.0469, 0.1172, 0.1209, 0.1045, 0.1222, 0.1208, 0.1168, 0.1080,\n",
      "         0.0740],\n",
      "        [0.0683, 0.0469, 0.1170, 0.1207, 0.1045, 0.1222, 0.1209, 0.1169, 0.1082,\n",
      "         0.0744],\n",
      "        [0.0681, 0.0468, 0.1168, 0.1206, 0.1045, 0.1223, 0.1209, 0.1169, 0.1084,\n",
      "         0.0748],\n",
      "        [0.0680, 0.0468, 0.1167, 0.1205, 0.1045, 0.1222, 0.1209, 0.1169, 0.1085,\n",
      "         0.0750],\n",
      "        [0.0679, 0.0469, 0.1166, 0.1204, 0.1045, 0.1222, 0.1208, 0.1169, 0.1085,\n",
      "         0.0753]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 59.00, Train Loss: 3.55, Val Loss: 11.50, Train BLEU: 7.16, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地 地球 上 最长 的 山脉 都 在 海洋\n",
      "Reference: and in the oceans , there are the longest\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0632, 0.1047, 0.1155, 0.1186, 0.1187, 0.1173, 0.1136, 0.1075, 0.0939,\n",
      "         0.0468],\n",
      "        [0.0666, 0.1052, 0.1145, 0.1169, 0.1165, 0.1150, 0.1115, 0.1062, 0.0946,\n",
      "         0.0529],\n",
      "        [0.0705, 0.1042, 0.1122, 0.1143, 0.1140, 0.1128, 0.1099, 0.1057, 0.0963,\n",
      "         0.0600],\n",
      "        [0.0738, 0.1040, 0.1109, 0.1127, 0.1125, 0.1114, 0.1089, 0.1052, 0.0969,\n",
      "         0.0639],\n",
      "        [0.0750, 0.1037, 0.1103, 0.1120, 0.1117, 0.1108, 0.1084, 0.1049, 0.0973,\n",
      "         0.0660],\n",
      "        [0.0751, 0.1035, 0.1101, 0.1118, 0.1116, 0.1107, 0.1084, 0.1050, 0.0975,\n",
      "         0.0665],\n",
      "        [0.0751, 0.1034, 0.1099, 0.1117, 0.1115, 0.1106, 0.1084, 0.1050, 0.0976,\n",
      "         0.0669],\n",
      "        [0.0750, 0.1033, 0.1098, 0.1116, 0.1115, 0.1106, 0.1084, 0.1050, 0.0977,\n",
      "         0.0672],\n",
      "        [0.0749, 0.1032, 0.1098, 0.1115, 0.1114, 0.1105, 0.1084, 0.1050, 0.0978,\n",
      "         0.0675]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把 书 放在 食品 杂货 袋中 这样 别人 就\n",
      "Reference: we would cover our books in grocery bags so\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0610, 0.1031, 0.1157, 0.1192, 0.1195, 0.1180, 0.1144, 0.1082, 0.0940,\n",
      "         0.0469],\n",
      "        [0.0647, 0.1035, 0.1145, 0.1175, 0.1172, 0.1157, 0.1124, 0.1068, 0.0948,\n",
      "         0.0530],\n",
      "        [0.0688, 0.1029, 0.1123, 0.1148, 0.1145, 0.1133, 0.1107, 0.1061, 0.0965,\n",
      "         0.0601],\n",
      "        [0.0721, 0.1028, 0.1110, 0.1131, 0.1130, 0.1119, 0.1095, 0.1056, 0.0971,\n",
      "         0.0640],\n",
      "        [0.0735, 0.1026, 0.1103, 0.1123, 0.1122, 0.1112, 0.1090, 0.1053, 0.0974,\n",
      "         0.0661],\n",
      "        [0.0736, 0.1024, 0.1101, 0.1122, 0.1121, 0.1111, 0.1090, 0.1054, 0.0976,\n",
      "         0.0666],\n",
      "        [0.0735, 0.1023, 0.1100, 0.1120, 0.1120, 0.1110, 0.1089, 0.1054, 0.0978,\n",
      "         0.0670],\n",
      "        [0.0735, 0.1023, 0.1099, 0.1119, 0.1119, 0.1110, 0.1089, 0.1054, 0.0979,\n",
      "         0.0673],\n",
      "        [0.0734, 0.1022, 0.1098, 0.1119, 0.1119, 0.1110, 0.1089, 0.1055, 0.0979,\n",
      "         0.0675]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60.00, Train Loss: 3.53, Val Loss: 11.52, Train BLEU: 7.17, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 和 我们 合作 的 人们 帮 我们 找到 了 新\n",
      "Reference: people that have partnered with us have given us\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0664, 0.1045, 0.1148, 0.1179, 0.1179, 0.1160, 0.1124, 0.1060, 0.0926,\n",
      "         0.0515],\n",
      "        [0.0698, 0.1052, 0.1139, 0.1162, 0.1157, 0.1139, 0.1104, 0.1046, 0.0933,\n",
      "         0.0570],\n",
      "        [0.0733, 0.1043, 0.1117, 0.1137, 0.1133, 0.1118, 0.1089, 0.1042, 0.0951,\n",
      "         0.0637],\n",
      "        [0.0764, 0.1040, 0.1105, 0.1122, 0.1119, 0.1104, 0.1080, 0.1038, 0.0957,\n",
      "         0.0672],\n",
      "        [0.0777, 0.1037, 0.1099, 0.1115, 0.1112, 0.1098, 0.1075, 0.1036, 0.0961,\n",
      "         0.0692],\n",
      "        [0.0778, 0.1035, 0.1096, 0.1112, 0.1110, 0.1097, 0.1074, 0.1036, 0.0963,\n",
      "         0.0699],\n",
      "        [0.0778, 0.1034, 0.1095, 0.1111, 0.1109, 0.1096, 0.1074, 0.1037, 0.0964,\n",
      "         0.0702],\n",
      "        [0.0778, 0.1033, 0.1094, 0.1110, 0.1108, 0.1095, 0.1074, 0.1037, 0.0965,\n",
      "         0.0706],\n",
      "        [0.0777, 0.1032, 0.1093, 0.1109, 0.1107, 0.1095, 0.1074, 0.1037, 0.0966,\n",
      "         0.0709]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 有时 学校 <UNK> 突然 <UNK> 一周 因为 被 塔利 塔利班\n",
      "Reference: from time to time , the school would suddenly\n",
      "Model: <SOS> and of the the , , , , ,\n",
      "Attention Weights: tensor([[0.0670, 0.1051, 0.1147, 0.1174, 0.1177, 0.1159, 0.1120, 0.1056, 0.0926,\n",
      "         0.0520],\n",
      "        [0.0704, 0.1058, 0.1139, 0.1156, 0.1156, 0.1136, 0.1100, 0.1044, 0.0933,\n",
      "         0.0574],\n",
      "        [0.0738, 0.1047, 0.1117, 0.1132, 0.1131, 0.1116, 0.1086, 0.1041, 0.0951,\n",
      "         0.0641],\n",
      "        [0.0769, 0.1043, 0.1104, 0.1117, 0.1116, 0.1102, 0.1076, 0.1037, 0.0958,\n",
      "         0.0677],\n",
      "        [0.0781, 0.1040, 0.1098, 0.1110, 0.1109, 0.1096, 0.1072, 0.1035, 0.0962,\n",
      "         0.0697],\n",
      "        [0.0782, 0.1038, 0.1095, 0.1108, 0.1108, 0.1095, 0.1072, 0.1035, 0.0964,\n",
      "         0.0703],\n",
      "        [0.0782, 0.1037, 0.1094, 0.1107, 0.1107, 0.1095, 0.1071, 0.1036, 0.0965,\n",
      "         0.0706],\n",
      "        [0.0782, 0.1036, 0.1093, 0.1106, 0.1106, 0.1094, 0.1071, 0.1036, 0.0966,\n",
      "         0.0710],\n",
      "        [0.0782, 0.1036, 0.1092, 0.1105, 0.1105, 0.1094, 0.1071, 0.1036, 0.0967,\n",
      "         0.0713]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 61.00, Train Loss: 3.51, Val Loss: 11.53, Train BLEU: 7.17, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的 平均 深度 是 两英里 英里 <EOS> <PAD> <PAD>\n",
      "Reference: the average depth is about two miles . <EOS>\n",
      "Model: <SOS> it &apos;s the the . . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.0875e-01, 1.7972e-01, 1.9339e-01, 1.8989e-01, 1.7211e-01, 7.2384e-02,\n",
      "         8.3024e-02, 7.2695e-04, 7.5987e-13, 7.5987e-13],\n",
      "        [1.0790e-01, 1.7776e-01, 1.9034e-01, 1.8688e-01, 1.7109e-01, 7.6248e-02,\n",
      "         8.8046e-02, 1.7170e-03, 1.7000e-11, 1.7000e-11],\n",
      "        [1.1077e-01, 1.7250e-01, 1.8376e-01, 1.8126e-01, 1.6845e-01, 8.3356e-02,\n",
      "         9.6297e-02, 3.6140e-03, 6.5034e-11, 6.5034e-11],\n",
      "        [1.1504e-01, 1.6808e-01, 1.7766e-01, 1.7563e-01, 1.6485e-01, 9.0510e-02,\n",
      "         1.0214e-01, 6.0896e-03, 1.2364e-10, 1.2364e-10],\n",
      "        [1.1643e-01, 1.6599e-01, 1.7498e-01, 1.7318e-01, 1.6330e-01, 9.3727e-02,\n",
      "         1.0490e-01, 7.4999e-03, 1.3603e-10, 1.3603e-10],\n",
      "        [1.1678e-01, 1.6475e-01, 1.7359e-01, 1.7203e-01, 1.6269e-01, 9.5375e-02,\n",
      "         1.0660e-01, 8.1906e-03, 1.4342e-10, 1.4342e-10],\n",
      "        [1.1631e-01, 1.6420e-01, 1.7305e-01, 1.7164e-01, 1.6257e-01, 9.6112e-02,\n",
      "         1.0762e-01, 8.5016e-03, 1.4688e-10, 1.4688e-10],\n",
      "        [1.1634e-01, 1.6390e-01, 1.7266e-01, 1.7128e-01, 1.6235e-01, 9.6650e-02,\n",
      "         1.0810e-01, 8.7198e-03, 1.5389e-10, 1.5389e-10],\n",
      "        [1.1641e-01, 1.6379e-01, 1.7251e-01, 1.7114e-01, 1.6226e-01, 9.6832e-02,\n",
      "         1.0824e-01, 8.8044e-03, 1.5725e-10, 1.5725e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 父亲 在 用 他 的 灰色 小 收音\n",
      "Reference: my father was listening to bbc news on his\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0468, 0.0149, 0.1292, 0.1345, 0.1023, 0.1400, 0.1367, 0.1284, 0.1108,\n",
      "         0.0565],\n",
      "        [0.0546, 0.0232, 0.1266, 0.1315, 0.1038, 0.1340, 0.1311, 0.1239, 0.1094,\n",
      "         0.0619],\n",
      "        [0.0611, 0.0319, 0.1227, 0.1270, 0.1042, 0.1283, 0.1262, 0.1205, 0.1091,\n",
      "         0.0689],\n",
      "        [0.0655, 0.0375, 0.1204, 0.1241, 0.1047, 0.1251, 0.1231, 0.1183, 0.1085,\n",
      "         0.0727],\n",
      "        [0.0672, 0.0397, 0.1192, 0.1229, 0.1047, 0.1238, 0.1220, 0.1175, 0.1084,\n",
      "         0.0747],\n",
      "        [0.0670, 0.0398, 0.1188, 0.1226, 0.1047, 0.1237, 0.1219, 0.1175, 0.1086,\n",
      "         0.0752],\n",
      "        [0.0669, 0.0400, 0.1186, 0.1224, 0.1048, 0.1236, 0.1218, 0.1175, 0.1087,\n",
      "         0.0757],\n",
      "        [0.0668, 0.0401, 0.1184, 0.1223, 0.1048, 0.1235, 0.1218, 0.1175, 0.1088,\n",
      "         0.0761],\n",
      "        [0.0668, 0.0401, 0.1183, 0.1222, 0.1048, 0.1234, 0.1217, 0.1175, 0.1088,\n",
      "         0.0763]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 62.00, Train Loss: 3.49, Val Loss: 11.54, Train BLEU: 6.96, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 其实 它们 都 是 由 单独 的 动物 结合 合在\n",
      "Reference: these are all individual animals banding together to make\n",
      "Model: <SOS> and &apos;s the the , , , , ,\n",
      "Attention Weights: tensor([[0.0713, 0.1170, 0.1277, 0.1301, 0.1298, 0.1267, 0.1213, 0.1084, 0.0669,\n",
      "         0.0007],\n",
      "        [0.0720, 0.1172, 0.1275, 0.1293, 0.1287, 0.1254, 0.1203, 0.1083, 0.0699,\n",
      "         0.0014],\n",
      "        [0.0759, 0.1159, 0.1249, 0.1266, 0.1261, 0.1234, 0.1192, 0.1092, 0.0758,\n",
      "         0.0027],\n",
      "        [0.0798, 0.1152, 0.1230, 0.1245, 0.1241, 0.1218, 0.1181, 0.1095, 0.0797,\n",
      "         0.0042],\n",
      "        [0.0814, 0.1147, 0.1220, 0.1234, 0.1231, 0.1209, 0.1176, 0.1097, 0.0821,\n",
      "         0.0051],\n",
      "        [0.0817, 0.1143, 0.1215, 0.1230, 0.1227, 0.1207, 0.1175, 0.1099, 0.0831,\n",
      "         0.0055],\n",
      "        [0.0818, 0.1141, 0.1212, 0.1227, 0.1225, 0.1206, 0.1175, 0.1101, 0.0838,\n",
      "         0.0057],\n",
      "        [0.0819, 0.1139, 0.1210, 0.1225, 0.1223, 0.1204, 0.1174, 0.1102, 0.0844,\n",
      "         0.0060],\n",
      "        [0.0819, 0.1139, 0.1209, 0.1224, 0.1222, 0.1204, 0.1173, 0.1102, 0.0847,\n",
      "         0.0061]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 在 塔利 塔利班 控制 阿富汗 的 那些 年 我 记得\n",
      "Reference: during taliban years , i remember there were times\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0713, 0.1170, 0.1277, 0.1301, 0.1298, 0.1267, 0.1213, 0.1084, 0.0669,\n",
      "         0.0007],\n",
      "        [0.0720, 0.1172, 0.1275, 0.1293, 0.1287, 0.1254, 0.1203, 0.1083, 0.0699,\n",
      "         0.0014],\n",
      "        [0.0759, 0.1159, 0.1249, 0.1266, 0.1261, 0.1234, 0.1192, 0.1092, 0.0758,\n",
      "         0.0027],\n",
      "        [0.0798, 0.1152, 0.1230, 0.1245, 0.1241, 0.1218, 0.1181, 0.1095, 0.0797,\n",
      "         0.0042],\n",
      "        [0.0814, 0.1147, 0.1220, 0.1234, 0.1231, 0.1209, 0.1176, 0.1097, 0.0821,\n",
      "         0.0051],\n",
      "        [0.0817, 0.1143, 0.1215, 0.1230, 0.1227, 0.1207, 0.1175, 0.1099, 0.0831,\n",
      "         0.0055],\n",
      "        [0.0818, 0.1141, 0.1212, 0.1227, 0.1225, 0.1206, 0.1175, 0.1101, 0.0838,\n",
      "         0.0057],\n",
      "        [0.0819, 0.1139, 0.1210, 0.1225, 0.1223, 0.1204, 0.1174, 0.1102, 0.0844,\n",
      "         0.0060],\n",
      "        [0.0819, 0.1139, 0.1209, 0.1224, 0.1222, 0.1204, 0.1173, 0.1102, 0.0847,\n",
      "         0.0061]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 63.00, Train Loss: 3.47, Val Loss: 11.55, Train BLEU: 7.00, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一只 水母 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: here &apos;s a jelly . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the to . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[2.0499e-01, 3.1114e-01, 3.0074e-01, 1.8171e-01, 1.4205e-03, 1.4938e-12,\n",
      "         1.4938e-12, 1.4938e-12, 1.4938e-12, 1.4938e-12],\n",
      "        [2.0370e-01, 3.0863e-01, 2.9760e-01, 1.8703e-01, 3.0416e-03, 3.2753e-11,\n",
      "         3.2753e-11, 3.2753e-11, 3.2753e-11, 3.2753e-11],\n",
      "        [2.0618e-01, 2.9864e-01, 2.9116e-01, 1.9772e-01, 6.2953e-03, 1.2336e-10,\n",
      "         1.2336e-10, 1.2336e-10, 1.2336e-10, 1.2336e-10],\n",
      "        [2.1135e-01, 2.8944e-01, 2.8374e-01, 2.0458e-01, 1.0887e-02, 2.3505e-10,\n",
      "         2.3505e-10, 2.3505e-10, 2.3505e-10, 2.3505e-10],\n",
      "        [2.1269e-01, 2.8437e-01, 2.8000e-01, 2.0884e-01, 1.4095e-02, 2.6829e-10,\n",
      "         2.6829e-10, 2.6829e-10, 2.6829e-10, 2.6829e-10],\n",
      "        [2.1248e-01, 2.8207e-01, 2.7876e-01, 2.1123e-01, 1.5457e-02, 2.7153e-10,\n",
      "         2.7153e-10, 2.7153e-10, 2.7153e-10, 2.7153e-10],\n",
      "        [2.1207e-01, 2.8108e-01, 2.7821e-01, 2.1245e-01, 1.6198e-02, 2.8943e-10,\n",
      "         2.8943e-10, 2.8943e-10, 2.8943e-10, 2.8943e-10],\n",
      "        [2.1219e-01, 2.8067e-01, 2.7785e-01, 2.1276e-01, 1.6527e-02, 2.9992e-10,\n",
      "         2.9992e-10, 2.9992e-10, 2.9992e-10, 2.9992e-10],\n",
      "        [2.1228e-01, 2.8048e-01, 2.7768e-01, 2.1289e-01, 1.6678e-02, 3.0618e-10,\n",
      "         3.0618e-10, 3.0618e-10, 3.0618e-10, 3.0618e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 不知 知道 那 意味 意味着 什么 但是 我 能\n",
      "Reference: i didn &apos;t know what it meant , but\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0691, 0.1153, 0.1259, 0.1293, 0.1297, 0.1269, 0.1193, 0.0779, 0.0637,\n",
      "         0.0430],\n",
      "        [0.0719, 0.1153, 0.1246, 0.1269, 0.1269, 0.1244, 0.1174, 0.0785, 0.0659,\n",
      "         0.0484],\n",
      "        [0.0755, 0.1134, 0.1214, 0.1233, 0.1233, 0.1213, 0.1155, 0.0811, 0.0699,\n",
      "         0.0552],\n",
      "        [0.0786, 0.1117, 0.1186, 0.1204, 0.1204, 0.1187, 0.1140, 0.0843, 0.0737,\n",
      "         0.0595],\n",
      "        [0.0798, 0.1109, 0.1174, 0.1191, 0.1191, 0.1176, 0.1134, 0.0857, 0.0754,\n",
      "         0.0617],\n",
      "        [0.0800, 0.1105, 0.1169, 0.1186, 0.1187, 0.1172, 0.1132, 0.0863, 0.0761,\n",
      "         0.0627],\n",
      "        [0.0799, 0.1102, 0.1166, 0.1184, 0.1185, 0.1170, 0.1131, 0.0866, 0.0766,\n",
      "         0.0632],\n",
      "        [0.0799, 0.1099, 0.1162, 0.1180, 0.1182, 0.1168, 0.1130, 0.0871, 0.0771,\n",
      "         0.0638],\n",
      "        [0.0797, 0.1097, 0.1160, 0.1178, 0.1180, 0.1166, 0.1129, 0.0874, 0.0774,\n",
      "         0.0642]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64.00, Train Loss: 3.45, Val Loss: 11.57, Train BLEU: 7.06, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这 有 不少 精彩 的 泰坦 泰坦尼克 坦尼 尼克\n",
      "Reference: we &apos;ve got some of the most incredible video\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0694, 0.1157, 0.1263, 0.1298, 0.1303, 0.1274, 0.1194, 0.0762, 0.0627,\n",
      "         0.0429],\n",
      "        [0.0722, 0.1157, 0.1250, 0.1274, 0.1274, 0.1248, 0.1175, 0.0771, 0.0649,\n",
      "         0.0481],\n",
      "        [0.0761, 0.1137, 0.1217, 0.1237, 0.1236, 0.1216, 0.1156, 0.0799, 0.0691,\n",
      "         0.0551],\n",
      "        [0.0792, 0.1119, 0.1188, 0.1206, 0.1206, 0.1189, 0.1140, 0.0833, 0.0731,\n",
      "         0.0596],\n",
      "        [0.0804, 0.1110, 0.1175, 0.1192, 0.1193, 0.1177, 0.1133, 0.0849, 0.0749,\n",
      "         0.0619],\n",
      "        [0.0806, 0.1106, 0.1169, 0.1187, 0.1188, 0.1173, 0.1132, 0.0854, 0.0756,\n",
      "         0.0629],\n",
      "        [0.0805, 0.1103, 0.1166, 0.1184, 0.1185, 0.1171, 0.1131, 0.0858, 0.0761,\n",
      "         0.0635],\n",
      "        [0.0804, 0.1100, 0.1162, 0.1181, 0.1182, 0.1168, 0.1130, 0.0864, 0.0767,\n",
      "         0.0641],\n",
      "        [0.0803, 0.1098, 0.1160, 0.1179, 0.1181, 0.1167, 0.1129, 0.0867, 0.0770,\n",
      "         0.0646]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在 一个 房屋 房屋里 屋里 我们 100 多 人\n",
      "Reference: the school was in a house , more than\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0538, 0.0624, 0.1236, 0.1292, 0.1281, 0.1256, 0.1210, 0.1126, 0.0964,\n",
      "         0.0474],\n",
      "        [0.0585, 0.0665, 0.1207, 0.1260, 0.1252, 0.1227, 0.1185, 0.1114, 0.0974,\n",
      "         0.0532],\n",
      "        [0.0641, 0.0711, 0.1172, 0.1218, 0.1212, 0.1192, 0.1157, 0.1101, 0.0989,\n",
      "         0.0606],\n",
      "        [0.0685, 0.0749, 0.1150, 0.1190, 0.1185, 0.1169, 0.1138, 0.1089, 0.0994,\n",
      "         0.0652],\n",
      "        [0.0706, 0.0767, 0.1138, 0.1176, 0.1171, 0.1156, 0.1129, 0.1083, 0.0996,\n",
      "         0.0679],\n",
      "        [0.0707, 0.0770, 0.1134, 0.1172, 0.1168, 0.1154, 0.1127, 0.1083, 0.0999,\n",
      "         0.0686],\n",
      "        [0.0708, 0.0773, 0.1132, 0.1169, 0.1166, 0.1152, 0.1126, 0.1082, 0.1000,\n",
      "         0.0693],\n",
      "        [0.0707, 0.0774, 0.1131, 0.1168, 0.1164, 0.1151, 0.1125, 0.1082, 0.1001,\n",
      "         0.0698],\n",
      "        [0.0707, 0.0775, 0.1130, 0.1167, 0.1163, 0.1150, 0.1125, 0.1082, 0.1002,\n",
      "         0.0701]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 65.00, Train Loss: 3.43, Val Loss: 11.57, Train BLEU: 6.81, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 还有 前面 的 这个 是 推进 引擎 它 一会 一会儿\n",
      "Reference: and it &apos;s got these jet thrusters up in\n",
      "Model: <SOS> it &apos;s &apos;s the the , , . <EOS>\n",
      "Attention Weights: tensor([[0.0800, 0.1327, 0.1434, 0.1451, 0.1424, 0.1366, 0.1256, 0.0919, 0.0020,\n",
      "         0.0001],\n",
      "        [0.0781, 0.1330, 0.1442, 0.1453, 0.1425, 0.1364, 0.1251, 0.0926, 0.0027,\n",
      "         0.0002],\n",
      "        [0.0810, 0.1315, 0.1418, 0.1428, 0.1405, 0.1352, 0.1255, 0.0968, 0.0044,\n",
      "         0.0006],\n",
      "        [0.0854, 0.1303, 0.1393, 0.1403, 0.1383, 0.1337, 0.1252, 0.0999, 0.0065,\n",
      "         0.0011],\n",
      "        [0.0879, 0.1296, 0.1378, 0.1388, 0.1368, 0.1327, 0.1250, 0.1018, 0.0081,\n",
      "         0.0015],\n",
      "        [0.0894, 0.1288, 0.1365, 0.1375, 0.1357, 0.1320, 0.1250, 0.1036, 0.0096,\n",
      "         0.0019],\n",
      "        [0.0900, 0.1283, 0.1358, 0.1369, 0.1352, 0.1317, 0.1251, 0.1045, 0.0104,\n",
      "         0.0021],\n",
      "        [0.0900, 0.1280, 0.1354, 0.1366, 0.1350, 0.1316, 0.1252, 0.1051, 0.0108,\n",
      "         0.0022],\n",
      "        [0.0903, 0.1278, 0.1352, 0.1363, 0.1348, 0.1315, 0.1252, 0.1055, 0.0113,\n",
      "         0.0023]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 总是 担心 会 被 塔利 塔利班 发现 <EOS> <PAD>\n",
      "Reference: we always wondered what they knew about us .\n",
      "Model: <SOS> it &apos;s the the to . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0630, 0.0939, 0.1265, 0.1305, 0.1298, 0.1249, 0.1152, 0.0691, 0.0987,\n",
      "         0.0484],\n",
      "        [0.0664, 0.0965, 0.1242, 0.1276, 0.1268, 0.1225, 0.1140, 0.0721, 0.0971,\n",
      "         0.0527],\n",
      "        [0.0710, 0.0975, 0.1205, 0.1233, 0.1227, 0.1192, 0.1123, 0.0762, 0.0977,\n",
      "         0.0595],\n",
      "        [0.0747, 0.0981, 0.1177, 0.1201, 0.1196, 0.1167, 0.1110, 0.0797, 0.0981,\n",
      "         0.0642],\n",
      "        [0.0763, 0.0985, 0.1163, 0.1186, 0.1181, 0.1155, 0.1104, 0.0813, 0.0983,\n",
      "         0.0667],\n",
      "        [0.0765, 0.0983, 0.1158, 0.1181, 0.1177, 0.1152, 0.1103, 0.0817, 0.0986,\n",
      "         0.0677],\n",
      "        [0.0765, 0.0982, 0.1155, 0.1178, 0.1174, 0.1150, 0.1102, 0.0821, 0.0989,\n",
      "         0.0685],\n",
      "        [0.0764, 0.0981, 0.1152, 0.1175, 0.1172, 0.1149, 0.1102, 0.0824, 0.0991,\n",
      "         0.0691],\n",
      "        [0.0763, 0.0980, 0.1151, 0.1174, 0.1171, 0.1148, 0.1101, 0.0826, 0.0992,\n",
      "         0.0694]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 66.00, Train Loss: 3.41, Val Loss: 11.59, Train BLEU: 6.87, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 还有 这些 摇晃 着 旋转 转着 的 触角 <EOS> <PAD>\n",
      "Reference: it &apos;s got tentacles dangling , swirling around like\n",
      "Model: <SOS> it &apos;s the to . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[8.6813e-02, 1.4780e-01, 1.6025e-01, 1.5815e-01, 1.4951e-01, 1.0913e-01,\n",
      "         1.1854e-01, 6.9261e-02, 5.4008e-04, 6.5873e-13],\n",
      "        [8.6563e-02, 1.4792e-01, 1.5953e-01, 1.5746e-01, 1.4859e-01, 1.0792e-01,\n",
      "         1.1858e-01, 7.2320e-02, 1.1080e-03, 1.3298e-11],\n",
      "        [9.0273e-02, 1.4493e-01, 1.5516e-01, 1.5346e-01, 1.4599e-01, 1.0889e-01,\n",
      "         1.1980e-01, 7.9094e-02, 2.3909e-03, 5.3225e-11],\n",
      "        [9.5189e-02, 1.4158e-01, 1.5011e-01, 1.4869e-01, 1.4258e-01, 1.1148e-01,\n",
      "         1.2055e-01, 8.5265e-02, 4.5471e-03, 1.0835e-10],\n",
      "        [9.7176e-02, 1.3953e-01, 1.4734e-01, 1.4606e-01, 1.4075e-01, 1.1307e-01,\n",
      "         1.2089e-01, 8.8963e-02, 6.2254e-03, 1.2730e-10],\n",
      "        [9.7479e-02, 1.3827e-01, 1.4594e-01, 1.4486e-01, 1.3997e-01, 1.1386e-01,\n",
      "         1.2151e-01, 9.1114e-02, 6.9988e-03, 1.2842e-10],\n",
      "        [9.7213e-02, 1.3766e-01, 1.4529e-01, 1.4434e-01, 1.3963e-01, 1.1435e-01,\n",
      "         1.2189e-01, 9.2205e-02, 7.4173e-03, 1.3452e-10],\n",
      "        [9.7325e-02, 1.3745e-01, 1.4501e-01, 1.4409e-01, 1.3945e-01, 1.1455e-01,\n",
      "         1.2194e-01, 9.2572e-02, 7.6111e-03, 1.3987e-10],\n",
      "        [9.7366e-02, 1.3740e-01, 1.4494e-01, 1.4404e-01, 1.3941e-01, 1.1460e-01,\n",
      "         1.2195e-01, 9.2637e-02, 7.6578e-03, 1.4134e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 总是 担心 会 被 塔利 塔利班 发现 <EOS> <PAD>\n",
      "Reference: we always wondered what they knew about us .\n",
      "Model: <SOS> it &apos;s the the to <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0633, 0.0941, 0.1272, 0.1312, 0.1302, 0.1252, 0.1149, 0.0666, 0.0989,\n",
      "         0.0484],\n",
      "        [0.0668, 0.0969, 0.1250, 0.1283, 0.1273, 0.1228, 0.1138, 0.0696, 0.0970,\n",
      "         0.0525],\n",
      "        [0.0715, 0.0978, 0.1211, 0.1239, 0.1231, 0.1194, 0.1122, 0.0741, 0.0975,\n",
      "         0.0593],\n",
      "        [0.0753, 0.0984, 0.1181, 0.1205, 0.1198, 0.1168, 0.1109, 0.0779, 0.0980,\n",
      "         0.0642],\n",
      "        [0.0770, 0.0988, 0.1167, 0.1189, 0.1183, 0.1156, 0.1102, 0.0796, 0.0982,\n",
      "         0.0668],\n",
      "        [0.0772, 0.0986, 0.1161, 0.1184, 0.1179, 0.1153, 0.1101, 0.0800, 0.0985,\n",
      "         0.0679],\n",
      "        [0.0771, 0.0985, 0.1158, 0.1180, 0.1175, 0.1151, 0.1100, 0.0805, 0.0988,\n",
      "         0.0687],\n",
      "        [0.0770, 0.0983, 0.1155, 0.1178, 0.1173, 0.1149, 0.1100, 0.0808, 0.0990,\n",
      "         0.0693],\n",
      "        [0.0769, 0.0982, 0.1154, 0.1176, 0.1172, 0.1149, 0.1100, 0.0809, 0.0991,\n",
      "         0.0697]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 67.00, Train Loss: 3.39, Val Loss: 11.60, Train BLEU: 7.11, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这 有 不少 精彩 的 泰坦 泰坦尼克 坦尼 尼克\n",
      "Reference: we &apos;ve got some of the most incredible video\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0713, 0.1172, 0.1281, 0.1323, 0.1326, 0.1287, 0.1196, 0.0693, 0.0585,\n",
      "         0.0423],\n",
      "        [0.0737, 0.1178, 0.1274, 0.1303, 0.1301, 0.1265, 0.1179, 0.0701, 0.0598,\n",
      "         0.0464],\n",
      "        [0.0777, 0.1158, 0.1240, 0.1263, 0.1261, 0.1232, 0.1162, 0.0736, 0.0643,\n",
      "         0.0529],\n",
      "        [0.0811, 0.1138, 0.1207, 0.1228, 0.1226, 0.1203, 0.1145, 0.0776, 0.0686,\n",
      "         0.0578],\n",
      "        [0.0823, 0.1128, 0.1193, 0.1213, 0.1211, 0.1190, 0.1139, 0.0795, 0.0706,\n",
      "         0.0603],\n",
      "        [0.0826, 0.1122, 0.1185, 0.1205, 0.1205, 0.1184, 0.1137, 0.0804, 0.0716,\n",
      "         0.0616],\n",
      "        [0.0825, 0.1118, 0.1181, 0.1202, 0.1201, 0.1182, 0.1136, 0.0808, 0.0722,\n",
      "         0.0624],\n",
      "        [0.0823, 0.1114, 0.1177, 0.1198, 0.1198, 0.1179, 0.1135, 0.0815, 0.0729,\n",
      "         0.0632],\n",
      "        [0.0822, 0.1112, 0.1174, 0.1195, 0.1196, 0.1178, 0.1134, 0.0819, 0.0733,\n",
      "         0.0637]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天 要 走 不同 的 路线 这样 才 没有\n",
      "Reference: each day , we took a different route so\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0643, 0.1072, 0.1180, 0.1197, 0.1201, 0.1179, 0.1137, 0.1055, 0.0901,\n",
      "         0.0435],\n",
      "        [0.0667, 0.1079, 0.1174, 0.1187, 0.1184, 0.1161, 0.1119, 0.1045, 0.0906,\n",
      "         0.0478],\n",
      "        [0.0712, 0.1069, 0.1149, 0.1159, 0.1156, 0.1135, 0.1100, 0.1040, 0.0928,\n",
      "         0.0551],\n",
      "        [0.0752, 0.1062, 0.1130, 0.1137, 0.1135, 0.1117, 0.1087, 0.1035, 0.0940,\n",
      "         0.0603],\n",
      "        [0.0770, 0.1057, 0.1120, 0.1127, 0.1125, 0.1108, 0.1081, 0.1033, 0.0946,\n",
      "         0.0634],\n",
      "        [0.0772, 0.1053, 0.1116, 0.1123, 0.1121, 0.1106, 0.1079, 0.1034, 0.0950,\n",
      "         0.0646],\n",
      "        [0.0772, 0.1051, 0.1113, 0.1120, 0.1119, 0.1104, 0.1079, 0.1034, 0.0953,\n",
      "         0.0654],\n",
      "        [0.0772, 0.1050, 0.1111, 0.1119, 0.1118, 0.1103, 0.1078, 0.1035, 0.0955,\n",
      "         0.0660],\n",
      "        [0.0771, 0.1049, 0.1110, 0.1117, 0.1117, 0.1102, 0.1078, 0.1035, 0.0957,\n",
      "         0.0664]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68.00, Train Loss: 3.37, Val Loss: 11.60, Train BLEU: 7.29, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 我 真 喜欢 这些 东西 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: i love that kind of stuff . <EOS> <PAD>\n",
      "Model: <SOS> it &apos;s the the to <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.6016e-01, 2.4557e-01, 2.4882e-01, 2.1814e-01, 1.2635e-01, 9.5458e-04,\n",
      "         1.3346e-12, 1.3346e-12, 1.3346e-12, 1.3346e-12],\n",
      "        [1.5887e-01, 2.4541e-01, 2.4742e-01, 2.1699e-01, 1.2955e-01, 1.7643e-03,\n",
      "         2.5161e-11, 2.5161e-11, 2.5161e-11, 2.5161e-11],\n",
      "        [1.6261e-01, 2.3886e-01, 2.4106e-01, 2.1537e-01, 1.3847e-01, 3.6264e-03,\n",
      "         9.7127e-11, 9.7127e-11, 9.7127e-11, 9.7127e-11],\n",
      "        [1.6847e-01, 2.3168e-01, 2.3347e-01, 2.1236e-01, 1.4691e-01, 7.1099e-03,\n",
      "         1.9939e-10, 1.9939e-10, 1.9939e-10, 1.9939e-10],\n",
      "        [1.7021e-01, 2.2802e-01, 2.2987e-01, 2.1102e-01, 1.5141e-01, 9.4721e-03,\n",
      "         2.2271e-10, 2.2271e-10, 2.2271e-10, 2.2271e-10],\n",
      "        [1.7047e-01, 2.2576e-01, 2.2794e-01, 2.1061e-01, 1.5438e-01, 1.0847e-02,\n",
      "         2.3805e-10, 2.3805e-10, 2.3805e-10, 2.3805e-10],\n",
      "        [1.6986e-01, 2.2459e-01, 2.2708e-01, 2.1062e-01, 1.5628e-01, 1.1574e-02,\n",
      "         2.3214e-10, 2.3214e-10, 2.3214e-10, 2.3214e-10],\n",
      "        [1.6981e-01, 2.2393e-01, 2.2647e-01, 2.1046e-01, 1.5723e-01, 1.2091e-02,\n",
      "         2.4257e-10, 2.4257e-10, 2.4257e-10, 2.4257e-10],\n",
      "        [1.6990e-01, 2.2370e-01, 2.2623e-01, 2.1036e-01, 1.5752e-01, 1.2296e-02,\n",
      "         2.5031e-10, 2.5031e-10, 2.5031e-10, 2.5031e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在 可以 去 个 真正 的 学校 念书 了\n",
      "Reference: &quot; you can go to a real school now\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0546, 0.0608, 0.0730, 0.0934, 0.1449, 0.1434, 0.1386, 0.1287, 0.1093,\n",
      "         0.0535],\n",
      "        [0.0602, 0.0650, 0.0759, 0.0932, 0.1399, 0.1391, 0.1347, 0.1258, 0.1085,\n",
      "         0.0577],\n",
      "        [0.0669, 0.0705, 0.0799, 0.0944, 0.1329, 0.1323, 0.1288, 0.1218, 0.1081,\n",
      "         0.0645],\n",
      "        [0.0717, 0.0750, 0.0830, 0.0958, 0.1280, 0.1275, 0.1245, 0.1186, 0.1071,\n",
      "         0.0688],\n",
      "        [0.0739, 0.0771, 0.0846, 0.0962, 0.1257, 0.1252, 0.1225, 0.1171, 0.1066,\n",
      "         0.0712],\n",
      "        [0.0744, 0.0776, 0.0850, 0.0963, 0.1247, 0.1243, 0.1218, 0.1166, 0.1067,\n",
      "         0.0725],\n",
      "        [0.0741, 0.0778, 0.0851, 0.0964, 0.1243, 0.1240, 0.1215, 0.1165, 0.1069,\n",
      "         0.0733],\n",
      "        [0.0740, 0.0779, 0.0851, 0.0965, 0.1241, 0.1238, 0.1214, 0.1165, 0.1070,\n",
      "         0.0738],\n",
      "        [0.0738, 0.0779, 0.0851, 0.0964, 0.1240, 0.1237, 0.1213, 0.1165, 0.1071,\n",
      "         0.0742]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 69.00, Train Loss: 3.35, Val Loss: 11.61, Train BLEU: 7.60, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 我们 将 用 一些 影片 来讲 讲述 一些 深海 海里\n",
      "Reference: and we &apos;re going to tell you some stories\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0660, 0.1062, 0.1159, 0.1206, 0.1209, 0.1176, 0.1138, 0.1066, 0.0898,\n",
      "         0.0426],\n",
      "        [0.0681, 0.1080, 0.1167, 0.1198, 0.1193, 0.1160, 0.1119, 0.1048, 0.0894,\n",
      "         0.0460],\n",
      "        [0.0726, 0.1072, 0.1145, 0.1170, 0.1164, 0.1135, 0.1100, 0.1041, 0.0915,\n",
      "         0.0530],\n",
      "        [0.0768, 0.1065, 0.1127, 0.1148, 0.1142, 0.1117, 0.1087, 0.1036, 0.0928,\n",
      "         0.0582],\n",
      "        [0.0785, 0.1060, 0.1117, 0.1137, 0.1131, 0.1108, 0.1080, 0.1034, 0.0935,\n",
      "         0.0613],\n",
      "        [0.0787, 0.1057, 0.1113, 0.1133, 0.1128, 0.1106, 0.1079, 0.1034, 0.0939,\n",
      "         0.0624],\n",
      "        [0.0787, 0.1054, 0.1110, 0.1130, 0.1126, 0.1104, 0.1079, 0.1035, 0.0942,\n",
      "         0.0632],\n",
      "        [0.0786, 0.1052, 0.1108, 0.1128, 0.1124, 0.1103, 0.1078, 0.1036, 0.0945,\n",
      "         0.0640],\n",
      "        [0.0786, 0.1051, 0.1106, 0.1126, 0.1123, 0.1102, 0.1078, 0.1037, 0.0947,\n",
      "         0.0645]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 在 塔利 塔利班 控制 阿富汗 的 那些 年 我 记得\n",
      "Reference: during taliban years , i remember there were times\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0740, 0.1189, 0.1280, 0.1307, 0.1306, 0.1281, 0.1212, 0.1072, 0.0610,\n",
      "         0.0003],\n",
      "        [0.0743, 0.1200, 0.1291, 0.1311, 0.1302, 0.1270, 0.1201, 0.1060, 0.0618,\n",
      "         0.0006],\n",
      "        [0.0788, 0.1189, 0.1267, 0.1284, 0.1276, 0.1247, 0.1188, 0.1070, 0.0678,\n",
      "         0.0013],\n",
      "        [0.0832, 0.1179, 0.1246, 0.1260, 0.1252, 0.1228, 0.1177, 0.1076, 0.0728,\n",
      "         0.0022],\n",
      "        [0.0848, 0.1172, 0.1233, 0.1247, 0.1240, 0.1218, 0.1172, 0.1081, 0.0760,\n",
      "         0.0029],\n",
      "        [0.0850, 0.1167, 0.1228, 0.1241, 0.1236, 0.1215, 0.1172, 0.1085, 0.0775,\n",
      "         0.0031],\n",
      "        [0.0852, 0.1163, 0.1223, 0.1237, 0.1233, 0.1213, 0.1171, 0.1088, 0.0786,\n",
      "         0.0034],\n",
      "        [0.0853, 0.1160, 0.1220, 0.1234, 0.1230, 0.1211, 0.1171, 0.1090, 0.0795,\n",
      "         0.0036],\n",
      "        [0.0853, 0.1159, 0.1218, 0.1232, 0.1228, 0.1210, 0.1171, 0.1091, 0.0800,\n",
      "         0.0037]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 70.00, Train Loss: 3.32, Val Loss: 11.62, Train BLEU: 7.59, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中 的 生命 大卫 <UNK> <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: life in the deep oceans <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the to . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.6161e-01, 2.5667e-01, 2.5291e-01, 2.1391e-01, 1.1383e-01, 7.9288e-04,\n",
      "         2.8920e-04, 1.0652e-12, 1.0652e-12, 1.0652e-12],\n",
      "        [1.5749e-01, 2.5511e-01, 2.5237e-01, 2.1411e-01, 1.1877e-01, 1.5271e-03,\n",
      "         6.2787e-04, 2.1793e-11, 2.1793e-11, 2.1793e-11],\n",
      "        [1.6189e-01, 2.4599e-01, 2.4417e-01, 2.1289e-01, 1.2999e-01, 3.4806e-03,\n",
      "         1.5924e-03, 9.7600e-11, 9.7600e-11, 9.7600e-11],\n",
      "        [1.6818e-01, 2.3633e-01, 2.3481e-01, 2.0985e-01, 1.4034e-01, 6.9587e-03,\n",
      "         3.5263e-03, 2.0730e-10, 2.0730e-10, 2.0730e-10],\n",
      "        [1.6925e-01, 2.3137e-01, 2.3047e-01, 2.0877e-01, 1.4597e-01, 9.3459e-03,\n",
      "         4.8211e-03, 2.2785e-10, 2.2785e-10, 2.2785e-10],\n",
      "        [1.6909e-01, 2.2919e-01, 2.2885e-01, 2.0856e-01, 1.4854e-01, 1.0340e-02,\n",
      "         5.4228e-03, 2.1903e-10, 2.1903e-10, 2.1903e-10],\n",
      "        [1.6848e-01, 2.2821e-01, 2.2821e-01, 2.0859e-01, 1.4989e-01, 1.0846e-02,\n",
      "         5.7747e-03, 2.2526e-10, 2.2526e-10, 2.2526e-10],\n",
      "        [1.6848e-01, 2.2777e-01, 2.2784e-01, 2.0847e-01, 1.5039e-01, 1.1105e-02,\n",
      "         5.9397e-03, 2.3481e-10, 2.3481e-10, 2.3481e-10],\n",
      "        [1.6852e-01, 2.2761e-01, 2.2769e-01, 2.0842e-01, 1.5055e-01, 1.1205e-02,\n",
      "         6.0030e-03, 2.3965e-10, 2.3965e-10, 2.3965e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 祖父 在 他 的 年代 是 位非 非凡\n",
      "Reference: my grandfather was an extraordinary man for his time\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0786, 0.1186, 0.1280, 0.1318, 0.1301, 0.1266, 0.1184, 0.1042, 0.0636,\n",
      "         0.0002],\n",
      "        [0.0776, 0.1205, 0.1296, 0.1322, 0.1299, 0.1256, 0.1172, 0.1030, 0.0640,\n",
      "         0.0004],\n",
      "        [0.0811, 0.1198, 0.1278, 0.1299, 0.1277, 0.1237, 0.1163, 0.1039, 0.0688,\n",
      "         0.0009],\n",
      "        [0.0859, 0.1189, 0.1256, 0.1272, 0.1252, 0.1217, 0.1153, 0.1047, 0.0738,\n",
      "         0.0017],\n",
      "        [0.0882, 0.1180, 0.1239, 0.1254, 0.1236, 0.1206, 0.1148, 0.1054, 0.0776,\n",
      "         0.0025],\n",
      "        [0.0884, 0.1173, 0.1231, 0.1247, 0.1230, 0.1202, 0.1149, 0.1061, 0.0794,\n",
      "         0.0029],\n",
      "        [0.0885, 0.1168, 0.1225, 0.1241, 0.1226, 0.1200, 0.1149, 0.1065, 0.0808,\n",
      "         0.0032],\n",
      "        [0.0886, 0.1166, 0.1222, 0.1238, 0.1224, 0.1199, 0.1149, 0.1067, 0.0815,\n",
      "         0.0034],\n",
      "        [0.0887, 0.1165, 0.1221, 0.1237, 0.1223, 0.1198, 0.1149, 0.1067, 0.0818,\n",
      "         0.0035]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 71.00, Train Loss: 3.30, Val Loss: 11.64, Train BLEU: 7.62, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中 的 生命 大卫 <UNK> <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: life in the deep oceans <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the to . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.6555e-01, 2.5889e-01, 2.5252e-01, 2.1164e-01, 1.1042e-01, 6.9539e-04,\n",
      "         2.7974e-04, 1.1126e-12, 1.1126e-12, 1.1126e-12],\n",
      "        [1.6083e-01, 2.5787e-01, 2.5260e-01, 2.1201e-01, 1.1481e-01, 1.3032e-03,\n",
      "         5.7661e-04, 2.1975e-11, 2.1975e-11, 2.1975e-11],\n",
      "        [1.6522e-01, 2.4874e-01, 2.4460e-01, 2.1107e-01, 1.2592e-01, 3.0035e-03,\n",
      "         1.4595e-03, 9.8847e-11, 9.8847e-11, 9.8847e-11],\n",
      "        [1.7140e-01, 2.3876e-01, 2.3529e-01, 2.0841e-01, 1.3671e-01, 6.1512e-03,\n",
      "         3.2798e-03, 2.1214e-10, 2.1214e-10, 2.1214e-10],\n",
      "        [1.7234e-01, 2.3360e-01, 2.3094e-01, 2.0754e-01, 1.4268e-01, 8.3687e-03,\n",
      "         4.5254e-03, 2.3403e-10, 2.3403e-10, 2.3403e-10],\n",
      "        [1.7215e-01, 2.3118e-01, 2.2921e-01, 2.0739e-01, 1.4555e-01, 9.3751e-03,\n",
      "         5.1469e-03, 2.2416e-10, 2.2416e-10, 2.2416e-10],\n",
      "        [1.7144e-01, 2.3010e-01, 2.2853e-01, 2.0746e-01, 1.4706e-01, 9.8967e-03,\n",
      "         5.5201e-03, 2.2919e-10, 2.2919e-10, 2.2919e-10],\n",
      "        [1.7142e-01, 2.2960e-01, 2.2813e-01, 2.0736e-01, 1.4763e-01, 1.0162e-02,\n",
      "         5.6945e-03, 2.3938e-10, 2.3938e-10, 2.3938e-10],\n",
      "        [1.7145e-01, 2.2943e-01, 2.2799e-01, 2.0731e-01, 1.4780e-01, 1.0257e-02,\n",
      "         5.7572e-03, 2.4435e-10, 2.4435e-10, 2.4435e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 有时 学校 <UNK> 突然 <UNK> 一周 因为 被 塔利 塔利班\n",
      "Reference: from time to time , the school would suddenly\n",
      "Model: <SOS> and &apos;s the the , , , , the\n",
      "Attention Weights: tensor([[0.0705, 0.1072, 0.1165, 0.1203, 0.1189, 0.1171, 0.1116, 0.1029, 0.0877,\n",
      "         0.0474],\n",
      "        [0.0723, 0.1089, 0.1171, 0.1197, 0.1178, 0.1155, 0.1100, 0.1017, 0.0873,\n",
      "         0.0495],\n",
      "        [0.0767, 0.1081, 0.1149, 0.1168, 0.1151, 0.1131, 0.1084, 0.1014, 0.0895,\n",
      "         0.0559],\n",
      "        [0.0808, 0.1074, 0.1130, 0.1145, 0.1130, 0.1112, 0.1071, 0.1011, 0.0909,\n",
      "         0.0610],\n",
      "        [0.0823, 0.1069, 0.1120, 0.1134, 0.1120, 0.1103, 0.1066, 0.1010, 0.0917,\n",
      "         0.0639],\n",
      "        [0.0824, 0.1064, 0.1115, 0.1129, 0.1116, 0.1100, 0.1065, 0.1011, 0.0923,\n",
      "         0.0652],\n",
      "        [0.0824, 0.1062, 0.1112, 0.1127, 0.1114, 0.1099, 0.1064, 0.1012, 0.0926,\n",
      "         0.0659],\n",
      "        [0.0824, 0.1060, 0.1110, 0.1125, 0.1112, 0.1098, 0.1064, 0.1013, 0.0928,\n",
      "         0.0666],\n",
      "        [0.0823, 0.1058, 0.1108, 0.1123, 0.1111, 0.1097, 0.1064, 0.1014, 0.0931,\n",
      "         0.0672]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72.00, Train Loss: 3.28, Val Loss: 11.65, Train BLEU: 7.74, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 地球 的 大部 大部分 部分 都 是 海水 <EOS> <PAD>\n",
      "Reference: most of the planet is ocean water . <EOS>\n",
      "Model: <SOS> it &apos;s the to . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[9.0671e-02, 1.4514e-01, 1.5504e-01, 1.5599e-01, 1.4684e-01, 1.3233e-01,\n",
      "         1.1091e-01, 6.2577e-02, 5.0479e-04, 8.2600e-13],\n",
      "        [8.9112e-02, 1.4722e-01, 1.5627e-01, 1.5521e-01, 1.4591e-01, 1.3171e-01,\n",
      "         1.1053e-01, 6.3230e-02, 8.1249e-04, 1.3809e-11],\n",
      "        [9.3583e-02, 1.4552e-01, 1.5320e-01, 1.5179e-01, 1.4321e-01, 1.3063e-01,\n",
      "         1.1188e-01, 6.8557e-02, 1.6340e-03, 5.6132e-11],\n",
      "        [9.9288e-02, 1.4273e-01, 1.4884e-01, 1.4745e-01, 1.4013e-01, 1.2949e-01,\n",
      "         1.1352e-01, 7.5221e-02, 3.3373e-03, 1.2307e-10],\n",
      "        [1.0144e-01, 1.4078e-01, 1.4633e-01, 1.4516e-01, 1.3854e-01, 1.2896e-01,\n",
      "         1.1460e-01, 7.9459e-02, 4.7239e-03, 1.3786e-10],\n",
      "        [1.0185e-01, 1.3929e-01, 1.4472e-01, 1.4384e-01, 1.3782e-01, 1.2899e-01,\n",
      "         1.1562e-01, 8.2289e-02, 5.5876e-03, 1.4197e-10],\n",
      "        [1.0148e-01, 1.3841e-01, 1.4383e-01, 1.4315e-01, 1.3752e-01, 1.2912e-01,\n",
      "         1.1631e-01, 8.4070e-02, 6.1305e-03, 1.3943e-10],\n",
      "        [1.0160e-01, 1.3804e-01, 1.4337e-01, 1.4274e-01, 1.3727e-01, 1.2908e-01,\n",
      "         1.1654e-01, 8.4892e-02, 6.4602e-03, 1.4759e-10],\n",
      "        [1.0167e-01, 1.3793e-01, 1.4324e-01, 1.4262e-01, 1.3720e-01, 1.2906e-01,\n",
      "         1.1660e-01, 8.5107e-02, 6.5613e-03, 1.5191e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 那 就是 她 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: there she is . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the to . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[9.0329e-02, 1.4467e-01, 1.5306e-01, 1.5101e-01, 1.4503e-01, 1.3273e-01,\n",
      "         1.1266e-01, 6.9967e-02, 5.4350e-04, 8.2788e-13],\n",
      "        [8.8564e-02, 1.4584e-01, 1.5415e-01, 1.5140e-01, 1.4465e-01, 1.3198e-01,\n",
      "         1.1207e-01, 7.0481e-02, 8.5864e-04, 1.3806e-11],\n",
      "        [9.3002e-02, 1.4405e-01, 1.5107e-01, 1.4835e-01, 1.4225e-01, 1.3094e-01,\n",
      "         1.1321e-01, 7.5410e-02, 1.7045e-03, 5.5785e-11],\n",
      "        [9.8656e-02, 1.4130e-01, 1.4689e-01, 1.4449e-01, 1.3930e-01, 1.2977e-01,\n",
      "         1.1468e-01, 8.1439e-02, 3.4878e-03, 1.2280e-10],\n",
      "        [1.0071e-01, 1.3955e-01, 1.4463e-01, 1.4250e-01, 1.3785e-01, 1.2928e-01,\n",
      "         1.1559e-01, 8.5044e-02, 4.8454e-03, 1.3762e-10],\n",
      "        [1.0111e-01, 1.3819e-01, 1.4323e-01, 1.4141e-01, 1.3717e-01, 1.2926e-01,\n",
      "         1.1648e-01, 8.7460e-02, 5.6933e-03, 1.4430e-10],\n",
      "        [1.0081e-01, 1.3728e-01, 1.4237e-01, 1.4078e-01, 1.3681e-01, 1.2932e-01,\n",
      "         1.1715e-01, 8.9219e-02, 6.2721e-03, 1.3868e-10],\n",
      "        [1.0095e-01, 1.3687e-01, 1.4188e-01, 1.4037e-01, 1.3652e-01, 1.2924e-01,\n",
      "         1.1740e-01, 9.0105e-02, 6.6646e-03, 1.4724e-10],\n",
      "        [1.0104e-01, 1.3675e-01, 1.4174e-01, 1.4025e-01, 1.3643e-01, 1.2921e-01,\n",
      "         1.1746e-01, 9.0332e-02, 6.7881e-03, 1.5193e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 73.00, Train Loss: 3.26, Val Loss: 11.67, Train BLEU: 7.71, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 地球 的 大部 大部分 部分 都 是 海水 <EOS> <PAD>\n",
      "Reference: most of the planet is ocean water . <EOS>\n",
      "Model: <SOS> it &apos;s the to . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[9.1935e-02, 1.4547e-01, 1.5545e-01, 1.5669e-01, 1.4666e-01, 1.3153e-01,\n",
      "         1.0982e-01, 6.1930e-02, 5.0165e-04, 8.5800e-13],\n",
      "        [9.0202e-02, 1.4782e-01, 1.5696e-01, 1.5605e-01, 1.4585e-01, 1.3094e-01,\n",
      "         1.0923e-01, 6.2168e-02, 7.7967e-04, 1.3904e-11],\n",
      "        [9.4791e-02, 1.4631e-01, 1.5400e-01, 1.5265e-01, 1.4319e-01, 1.2985e-01,\n",
      "         1.1048e-01, 6.7170e-02, 1.5500e-03, 5.6719e-11],\n",
      "        [1.0048e-01, 1.4355e-01, 1.4961e-01, 1.4823e-01, 1.4013e-01, 1.2882e-01,\n",
      "         1.1225e-01, 7.3765e-02, 3.1735e-03, 1.2612e-10],\n",
      "        [1.0267e-01, 1.4154e-01, 1.4702e-01, 1.4584e-01, 1.3853e-01, 1.2834e-01,\n",
      "         1.1344e-01, 7.8090e-02, 4.5231e-03, 1.4114e-10],\n",
      "        [1.0306e-01, 1.3998e-01, 1.4532e-01, 1.4443e-01, 1.3778e-01, 1.2842e-01,\n",
      "         1.1456e-01, 8.1044e-02, 5.4029e-03, 1.4713e-10],\n",
      "        [1.0269e-01, 1.3900e-01, 1.4431e-01, 1.4363e-01, 1.3744e-01, 1.2857e-01,\n",
      "         1.1535e-01, 8.3019e-02, 5.9873e-03, 1.4219e-10],\n",
      "        [1.0282e-01, 1.3859e-01, 1.4380e-01, 1.4317e-01, 1.3718e-01, 1.2854e-01,\n",
      "         1.1563e-01, 8.3928e-02, 6.3423e-03, 1.5063e-10],\n",
      "        [1.0289e-01, 1.3848e-01, 1.4366e-01, 1.4304e-01, 1.3710e-01, 1.2853e-01,\n",
      "         1.1569e-01, 8.4158e-02, 6.4467e-03, 1.5521e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 父亲 那 就是 他 他 是 他家 家族\n",
      "Reference: and my father -- that &apos;s him -- he\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.1051, 0.1591, 0.1506, 0.1144, 0.0069, 0.1743, 0.0642, 0.1517, 0.0735,\n",
      "         0.0001],\n",
      "        [0.1042, 0.1664, 0.1594, 0.1222, 0.0081, 0.1694, 0.0603, 0.1403, 0.0696,\n",
      "         0.0002],\n",
      "        [0.1076, 0.1630, 0.1579, 0.1262, 0.0123, 0.1624, 0.0647, 0.1333, 0.0721,\n",
      "         0.0004],\n",
      "        [0.1119, 0.1574, 0.1532, 0.1272, 0.0183, 0.1545, 0.0709, 0.1291, 0.0765,\n",
      "         0.0009],\n",
      "        [0.1127, 0.1527, 0.1493, 0.1270, 0.0229, 0.1500, 0.0756, 0.1276, 0.0807,\n",
      "         0.0014],\n",
      "        [0.1127, 0.1503, 0.1472, 0.1262, 0.0250, 0.1479, 0.0776, 0.1280, 0.0836,\n",
      "         0.0017],\n",
      "        [0.1119, 0.1486, 0.1457, 0.1255, 0.0261, 0.1471, 0.0786, 0.1288, 0.0858,\n",
      "         0.0019],\n",
      "        [0.1116, 0.1477, 0.1450, 0.1254, 0.0269, 0.1463, 0.0794, 0.1287, 0.0869,\n",
      "         0.0021],\n",
      "        [0.1116, 0.1474, 0.1448, 0.1254, 0.0272, 0.1460, 0.0796, 0.1287, 0.0872,\n",
      "         0.0021]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 74.00, Train Loss: 3.24, Val Loss: 11.68, Train BLEU: 7.59, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 还有 前面 的 这个 是 推进 引擎 它 一会 一会儿\n",
      "Reference: and it &apos;s got these jet thrusters up in\n",
      "Model: <SOS> it &apos;s &apos;s got to to , <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0844, 0.1341, 0.1435, 0.1480, 0.1425, 0.1381, 0.1246, 0.0838, 0.0009,\n",
      "         0.0000],\n",
      "        [0.0812, 0.1362, 0.1464, 0.1496, 0.1437, 0.1377, 0.1226, 0.0814, 0.0010,\n",
      "         0.0001],\n",
      "        [0.0843, 0.1356, 0.1450, 0.1477, 0.1421, 0.1365, 0.1226, 0.0844, 0.0017,\n",
      "         0.0002],\n",
      "        [0.0895, 0.1349, 0.1428, 0.1450, 0.1399, 0.1348, 0.1223, 0.0877, 0.0027,\n",
      "         0.0004],\n",
      "        [0.0928, 0.1343, 0.1412, 0.1431, 0.1383, 0.1336, 0.1223, 0.0902, 0.0036,\n",
      "         0.0006],\n",
      "        [0.0948, 0.1331, 0.1394, 0.1412, 0.1369, 0.1329, 0.1228, 0.0935, 0.0047,\n",
      "         0.0008],\n",
      "        [0.0956, 0.1323, 0.1384, 0.1402, 0.1362, 0.1325, 0.1231, 0.0954, 0.0054,\n",
      "         0.0010],\n",
      "        [0.0958, 0.1317, 0.1377, 0.1395, 0.1358, 0.1323, 0.1234, 0.0966, 0.0059,\n",
      "         0.0011],\n",
      "        [0.0961, 0.1313, 0.1372, 0.1390, 0.1354, 0.1321, 0.1235, 0.0977, 0.0064,\n",
      "         0.0012]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 很 害怕 但是 我们 仍然 渴望 望去 学校 <EOS>\n",
      "Reference: we were scared , but still , school was\n",
      "Model: <SOS> it &apos;s the to to <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0697, 0.1071, 0.1195, 0.1204, 0.1220, 0.1155, 0.1134, 0.1043, 0.0840,\n",
      "         0.0441],\n",
      "        [0.0715, 0.1091, 0.1201, 0.1206, 0.1209, 0.1147, 0.1117, 0.1025, 0.0834,\n",
      "         0.0456],\n",
      "        [0.0765, 0.1085, 0.1176, 0.1177, 0.1178, 0.1124, 0.1098, 0.1021, 0.0858,\n",
      "         0.0517],\n",
      "        [0.0811, 0.1080, 0.1155, 0.1154, 0.1153, 0.1106, 0.1083, 0.1016, 0.0875,\n",
      "         0.0567],\n",
      "        [0.0827, 0.1075, 0.1143, 0.1142, 0.1141, 0.1097, 0.1077, 0.1015, 0.0885,\n",
      "         0.0597],\n",
      "        [0.0830, 0.1070, 0.1137, 0.1136, 0.1136, 0.1094, 0.1075, 0.1017, 0.0892,\n",
      "         0.0614],\n",
      "        [0.0830, 0.1068, 0.1133, 0.1132, 0.1133, 0.1092, 0.1074, 0.1017, 0.0897,\n",
      "         0.0624],\n",
      "        [0.0831, 0.1065, 0.1130, 0.1129, 0.1130, 0.1091, 0.1073, 0.1018, 0.0900,\n",
      "         0.0633],\n",
      "        [0.0830, 0.1063, 0.1127, 0.1127, 0.1128, 0.1090, 0.1073, 0.1019, 0.0904,\n",
      "         0.0640]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 75.00, Train Loss: 3.22, Val Loss: 11.70, Train BLEU: 7.74, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 当 你 站 在 海滩 上 或是 当 你 看到\n",
      "Reference: part of the problem , i think , is\n",
      "Model: <SOS> we of the the , the the the the\n",
      "Attention Weights: tensor([[0.0701, 0.1052, 0.1163, 0.1209, 0.1241, 0.1183, 0.1166, 0.1013, 0.0846,\n",
      "         0.0427],\n",
      "        [0.0721, 0.1075, 0.1175, 0.1209, 0.1226, 0.1169, 0.1142, 0.1001, 0.0841,\n",
      "         0.0443],\n",
      "        [0.0774, 0.1071, 0.1153, 0.1179, 0.1191, 0.1141, 0.1119, 0.0999, 0.0866,\n",
      "         0.0508],\n",
      "        [0.0821, 0.1067, 0.1134, 0.1154, 0.1163, 0.1119, 0.1100, 0.0997, 0.0883,\n",
      "         0.0561],\n",
      "        [0.0836, 0.1061, 0.1122, 0.1141, 0.1148, 0.1108, 0.1092, 0.0998, 0.0895,\n",
      "         0.0598],\n",
      "        [0.0837, 0.1057, 0.1116, 0.1135, 0.1143, 0.1105, 0.1090, 0.1000, 0.0902,\n",
      "         0.0615],\n",
      "        [0.0838, 0.1055, 0.1113, 0.1131, 0.1139, 0.1103, 0.1088, 0.1001, 0.0907,\n",
      "         0.0626],\n",
      "        [0.0836, 0.1052, 0.1110, 0.1128, 0.1136, 0.1101, 0.1088, 0.1003, 0.0910,\n",
      "         0.0634],\n",
      "        [0.0836, 0.1051, 0.1109, 0.1127, 0.1135, 0.1101, 0.1087, 0.1003, 0.0912,\n",
      "         0.0639]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 出身 阿富汗 边远 <UNK> 地区 有着 与 他人 不同\n",
      "Reference: a total maverick from a remote province of afghanistan\n",
      "Model: <SOS> we of the the , the the the the\n",
      "Attention Weights: tensor([[9.9879e-02, 1.5435e-01, 1.6033e-01, 1.5709e-01, 1.0222e-01, 1.4267e-01,\n",
      "         1.1601e-01, 6.6918e-02, 5.3949e-04, 9.7237e-13],\n",
      "        [9.9166e-02, 1.5868e-01, 1.6461e-01, 1.5908e-01, 1.0056e-01, 1.3806e-01,\n",
      "         1.1321e-01, 6.5819e-02, 8.1680e-04, 1.5118e-11],\n",
      "        [1.0436e-01, 1.5671e-01, 1.6159e-01, 1.5677e-01, 1.0326e-01, 1.3381e-01,\n",
      "         1.1226e-01, 6.9614e-02, 1.6230e-03, 6.3286e-11],\n",
      "        [1.0952e-01, 1.5236e-01, 1.5608e-01, 1.5213e-01, 1.0699e-01, 1.3104e-01,\n",
      "         1.1293e-01, 7.5590e-02, 3.3646e-03, 1.4517e-10],\n",
      "        [1.1092e-01, 1.4944e-01, 1.5285e-01, 1.4966e-01, 1.0882e-01, 1.3000e-01,\n",
      "         1.1387e-01, 7.9700e-02, 4.7315e-03, 1.6308e-10],\n",
      "        [1.1097e-01, 1.4722e-01, 1.5059e-01, 1.4781e-01, 1.0961e-01, 1.2999e-01,\n",
      "         1.1517e-01, 8.2938e-02, 5.7124e-03, 1.6692e-10],\n",
      "        [1.1021e-01, 1.4581e-01, 1.4922e-01, 1.4662e-01, 1.0986e-01, 1.3037e-01,\n",
      "         1.1628e-01, 8.5247e-02, 6.3929e-03, 1.5900e-10],\n",
      "        [1.1022e-01, 1.4527e-01, 1.4862e-01, 1.4607e-01, 1.1013e-01, 1.3035e-01,\n",
      "         1.1654e-01, 8.6066e-02, 6.7286e-03, 1.6829e-10],\n",
      "        [1.1025e-01, 1.4514e-01, 1.4847e-01, 1.4593e-01, 1.1020e-01, 1.3035e-01,\n",
      "         1.1660e-01, 8.6251e-02, 6.8095e-03, 1.7236e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76.00, Train Loss: 3.19, Val Loss: 11.71, Train BLEU: 8.45, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 底下 这些 都 是 <UNK> 它们 上上 上上下下 上下 下下\n",
      "Reference: it &apos;s got these fishing <UNK> on the bottom\n",
      "Model: <SOS> it &apos;s got to to , <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.1064, 0.1585, 0.1476, 0.1092, 0.0054, 0.1809, 0.0599, 0.1580, 0.0740,\n",
      "         0.0001],\n",
      "        [0.1065, 0.1677, 0.1576, 0.1165, 0.0062, 0.1758, 0.0557, 0.1450, 0.0689,\n",
      "         0.0001],\n",
      "        [0.1110, 0.1656, 0.1573, 0.1214, 0.0097, 0.1684, 0.0605, 0.1361, 0.0698,\n",
      "         0.0003],\n",
      "        [0.1158, 0.1602, 0.1534, 0.1238, 0.0151, 0.1596, 0.0673, 0.1304, 0.0735,\n",
      "         0.0008],\n",
      "        [0.1167, 0.1555, 0.1498, 0.1244, 0.0196, 0.1544, 0.0724, 0.1284, 0.0776,\n",
      "         0.0012],\n",
      "        [0.1166, 0.1528, 0.1476, 0.1240, 0.0218, 0.1516, 0.0746, 0.1285, 0.0809,\n",
      "         0.0015],\n",
      "        [0.1158, 0.1509, 0.1461, 0.1234, 0.0231, 0.1505, 0.0757, 0.1294, 0.0835,\n",
      "         0.0017],\n",
      "        [0.1154, 0.1497, 0.1452, 0.1234, 0.0240, 0.1495, 0.0766, 0.1294, 0.0849,\n",
      "         0.0018],\n",
      "        [0.1153, 0.1494, 0.1449, 0.1235, 0.0244, 0.1491, 0.0769, 0.1293, 0.0853,\n",
      "         0.0019]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 在 被 跟踪 吗 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: were we being followed ? <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the to about <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0977, 0.1506, 0.1600, 0.1545, 0.1431, 0.0991, 0.0080, 0.0031, 0.1227,\n",
      "         0.0610],\n",
      "        [0.0988, 0.1524, 0.1611, 0.1558, 0.1439, 0.1023, 0.0104, 0.0048, 0.1115,\n",
      "         0.0589],\n",
      "        [0.1035, 0.1473, 0.1545, 0.1504, 0.1414, 0.1071, 0.0161, 0.0086, 0.1080,\n",
      "         0.0630],\n",
      "        [0.1075, 0.1428, 0.1483, 0.1449, 0.1376, 0.1090, 0.0220, 0.0129, 0.1072,\n",
      "         0.0678],\n",
      "        [0.1082, 0.1401, 0.1452, 0.1422, 0.1359, 0.1099, 0.0254, 0.0155, 0.1071,\n",
      "         0.0706],\n",
      "        [0.1080, 0.1388, 0.1437, 0.1408, 0.1349, 0.1102, 0.0271, 0.0168, 0.1073,\n",
      "         0.0724],\n",
      "        [0.1077, 0.1379, 0.1427, 0.1399, 0.1340, 0.1100, 0.0281, 0.0176, 0.1079,\n",
      "         0.0740],\n",
      "        [0.1075, 0.1373, 0.1420, 0.1393, 0.1336, 0.1102, 0.0288, 0.0182, 0.1082,\n",
      "         0.0750],\n",
      "        [0.1071, 0.1368, 0.1415, 0.1389, 0.1333, 0.1103, 0.0293, 0.0185, 0.1085,\n",
      "         0.0758]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 77.00, Train Loss: 3.17, Val Loss: 11.72, Train BLEU: 8.50, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 和 我们 合作 的 人们 帮 我们 找到 了 新\n",
      "Reference: people that have partnered with us have given us\n",
      "Model: <SOS> we of the the the , the the the\n",
      "Attention Weights: tensor([[0.0698, 0.1066, 0.1201, 0.1212, 0.1235, 0.1161, 0.1144, 0.1043, 0.0818,\n",
      "         0.0422],\n",
      "        [0.0720, 0.1087, 0.1208, 0.1214, 0.1225, 0.1154, 0.1126, 0.1024, 0.0810,\n",
      "         0.0432],\n",
      "        [0.0778, 0.1084, 0.1183, 0.1184, 0.1192, 0.1128, 0.1106, 0.1019, 0.0835,\n",
      "         0.0492],\n",
      "        [0.0827, 0.1081, 0.1160, 0.1159, 0.1164, 0.1109, 0.1088, 0.1014, 0.0855,\n",
      "         0.0544],\n",
      "        [0.0842, 0.1075, 0.1148, 0.1146, 0.1150, 0.1100, 0.1082, 0.1014, 0.0867,\n",
      "         0.0575],\n",
      "        [0.0845, 0.1071, 0.1142, 0.1140, 0.1144, 0.1096, 0.1079, 0.1015, 0.0875,\n",
      "         0.0594],\n",
      "        [0.0846, 0.1069, 0.1137, 0.1136, 0.1140, 0.1094, 0.1077, 0.1015, 0.0880,\n",
      "         0.0605],\n",
      "        [0.0847, 0.1066, 0.1134, 0.1133, 0.1137, 0.1092, 0.1076, 0.1016, 0.0884,\n",
      "         0.0614],\n",
      "        [0.0845, 0.1064, 0.1131, 0.1131, 0.1135, 0.1091, 0.1076, 0.1017, 0.0888,\n",
      "         0.0622]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11 岁 那年 记得 得有 一天 早晨 醒来 听见\n",
      "Reference: when i was 11 , i remember waking up\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[1.8290e-01, 2.6566e-01, 2.5094e-01, 2.0588e-01, 9.4021e-02, 3.7815e-04,\n",
      "         2.2022e-04, 1.3239e-12, 1.3239e-12, 1.3239e-12],\n",
      "        [1.7811e-01, 2.6790e-01, 2.5268e-01, 2.0453e-01, 9.5758e-02, 6.4810e-04,\n",
      "         3.8298e-04, 2.3460e-11, 2.3460e-11, 2.3460e-11],\n",
      "        [1.8388e-01, 2.5871e-01, 2.4470e-01, 2.0356e-01, 1.0643e-01, 1.6796e-03,\n",
      "         1.0333e-03, 1.1137e-10, 1.1137e-10, 1.1137e-10],\n",
      "        [1.8886e-01, 2.4736e-01, 2.3563e-01, 2.0236e-01, 1.1933e-01, 3.9292e-03,\n",
      "         2.5380e-03, 2.6056e-10, 2.6056e-10, 2.6056e-10],\n",
      "        [1.8874e-01, 2.4116e-01, 2.3119e-01, 2.0238e-01, 1.2717e-01, 5.6857e-03,\n",
      "         3.6668e-03, 2.9342e-10, 2.9342e-10, 2.9342e-10],\n",
      "        [1.8792e-01, 2.3773e-01, 2.2913e-01, 2.0267e-01, 1.3152e-01, 6.6731e-03,\n",
      "         4.3533e-03, 2.7631e-10, 2.7631e-10, 2.7631e-10],\n",
      "        [1.8679e-01, 2.3634e-01, 2.2843e-01, 2.0297e-01, 1.3355e-01, 7.1636e-03,\n",
      "         4.7548e-03, 2.7260e-10, 2.7260e-10, 2.7260e-10],\n",
      "        [1.8670e-01, 2.3581e-01, 2.2806e-01, 2.0293e-01, 1.3422e-01, 7.3705e-03,\n",
      "         4.9071e-03, 2.8333e-10, 2.8333e-10, 2.8333e-10],\n",
      "        [1.8670e-01, 2.3563e-01, 2.2793e-01, 2.0290e-01, 1.3442e-01, 7.4454e-03,\n",
      "         4.9620e-03, 2.8940e-10, 2.8940e-10, 2.8940e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 78.00, Train Loss: 3.15, Val Loss: 11.74, Train BLEU: 9.83, Val BLEU: 0.33\n",
      "Sampling from training predictions...\n",
      "Source: 地球 的 大部 大部分 部分 都 是 海水 <EOS> <PAD>\n",
      "Reference: most of the planet is ocean water . <EOS>\n",
      "Model: <SOS> it &apos;s the to . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[9.7639e-02, 1.4685e-01, 1.5631e-01, 1.5853e-01, 1.4554e-01, 1.2856e-01,\n",
      "         1.0621e-01, 5.9852e-02, 5.0096e-04, 1.0420e-12],\n",
      "        [9.6756e-02, 1.5055e-01, 1.5858e-01, 1.5802e-01, 1.4457e-01, 1.2737e-01,\n",
      "         1.0450e-01, 5.8937e-02, 7.2518e-04, 1.5653e-11],\n",
      "        [1.0274e-01, 1.4940e-01, 1.5568e-01, 1.5437e-01, 1.4169e-01, 1.2604e-01,\n",
      "         1.0535e-01, 6.3277e-02, 1.4626e-03, 6.5789e-11],\n",
      "        [1.0848e-01, 1.4640e-01, 1.5099e-01, 1.4951e-01, 1.3867e-01, 1.2536e-01,\n",
      "         1.0753e-01, 6.9951e-02, 3.1235e-03, 1.5561e-10],\n",
      "        [1.1010e-01, 1.4397e-01, 1.4806e-01, 1.4678e-01, 1.3712e-01, 1.2526e-01,\n",
      "         1.0932e-01, 7.4840e-02, 4.5701e-03, 1.7921e-10],\n",
      "        [1.1011e-01, 1.4188e-01, 1.4589e-01, 1.4492e-01, 1.3633e-01, 1.2561e-01,\n",
      "         1.1101e-01, 7.8615e-02, 5.6314e-03, 1.7665e-10],\n",
      "        [1.0950e-01, 1.4082e-01, 1.4481e-01, 1.4399e-01, 1.3598e-01, 1.2586e-01,\n",
      "         1.1197e-01, 8.0752e-02, 6.3200e-03, 1.6955e-10],\n",
      "        [1.0958e-01, 1.4048e-01, 1.4438e-01, 1.4358e-01, 1.3577e-01, 1.2586e-01,\n",
      "         1.1223e-01, 8.1495e-02, 6.6184e-03, 1.7769e-10],\n",
      "        [1.0963e-01, 1.4039e-01, 1.4427e-01, 1.4346e-01, 1.3571e-01, 1.2586e-01,\n",
      "         1.1229e-01, 8.1682e-02, 6.7068e-03, 1.8233e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11 岁 那年 记得 得有 一天 早晨 醒来 听见\n",
      "Reference: when i was 11 , i remember waking up\n",
      "Model: <SOS> we of the the , the the the the\n",
      "Attention Weights: tensor([[1.8507e-01, 2.6655e-01, 2.5114e-01, 2.0525e-01, 9.1422e-02, 3.5103e-04,\n",
      "         2.1585e-04, 1.3627e-12, 1.3627e-12, 1.3627e-12],\n",
      "        [1.8091e-01, 2.6857e-01, 2.5238e-01, 2.0356e-01, 9.3580e-02, 6.1845e-04,\n",
      "         3.8223e-04, 2.4521e-11, 2.4521e-11, 2.4521e-11],\n",
      "        [1.8716e-01, 2.5880e-01, 2.4394e-01, 2.0256e-01, 1.0480e-01, 1.6775e-03,\n",
      "         1.0704e-03, 1.1937e-10, 1.1937e-10, 1.1937e-10],\n",
      "        [1.9176e-01, 2.4689e-01, 2.3462e-01, 2.0152e-01, 1.1847e-01, 4.0543e-03,\n",
      "         2.6886e-03, 2.7852e-10, 2.7852e-10, 2.7852e-10],\n",
      "        [1.9110e-01, 2.4045e-01, 2.3016e-01, 2.0171e-01, 1.2679e-01, 5.8978e-03,\n",
      "         3.8983e-03, 3.1535e-10, 3.1535e-10, 3.1535e-10],\n",
      "        [1.8974e-01, 2.3721e-01, 2.2840e-01, 2.0217e-01, 1.3106e-01, 6.8405e-03,\n",
      "         4.5773e-03, 2.8664e-10, 2.8664e-10, 2.8664e-10],\n",
      "        [1.8892e-01, 2.3586e-01, 2.2762e-01, 2.0233e-01, 1.3295e-01, 7.3316e-03,\n",
      "         4.9784e-03, 2.9159e-10, 2.9159e-10, 2.9159e-10],\n",
      "        [1.8886e-01, 2.3542e-01, 2.2730e-01, 2.0228e-01, 1.3350e-01, 7.5168e-03,\n",
      "         5.1159e-03, 3.0270e-10, 3.0270e-10, 3.0270e-10],\n",
      "        [1.8887e-01, 2.3524e-01, 2.2717e-01, 2.0225e-01, 1.3370e-01, 7.5930e-03,\n",
      "         5.1724e-03, 3.0895e-10, 3.0895e-10, 3.0895e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 79.00, Train Loss: 3.12, Val Loss: 11.75, Train BLEU: 9.82, Val BLEU: 0.32\n",
      "Sampling from training predictions...\n",
      "Source: 其实 它们 都 是 由 单独 的 动物 结合 合在\n",
      "Reference: these are all individual animals banding together to make\n",
      "Model: <SOS> and &apos;s the to , , , , ,\n",
      "Attention Weights: tensor([[0.0757, 0.1188, 0.1265, 0.1315, 0.1323, 0.1315, 0.1207, 0.1069, 0.0559,\n",
      "         0.0001],\n",
      "        [0.0762, 0.1208, 0.1289, 0.1331, 0.1330, 0.1308, 0.1196, 0.1039, 0.0535,\n",
      "         0.0002],\n",
      "        [0.0830, 0.1202, 0.1268, 0.1303, 0.1300, 0.1280, 0.1181, 0.1045, 0.0587,\n",
      "         0.0006],\n",
      "        [0.0880, 0.1196, 0.1249, 0.1277, 0.1273, 0.1256, 0.1170, 0.1052, 0.0635,\n",
      "         0.0012],\n",
      "        [0.0896, 0.1188, 0.1236, 0.1262, 0.1259, 0.1244, 0.1166, 0.1061, 0.0672,\n",
      "         0.0016],\n",
      "        [0.0902, 0.1183, 0.1229, 0.1254, 0.1251, 0.1237, 0.1164, 0.1066, 0.0695,\n",
      "         0.0019],\n",
      "        [0.0906, 0.1180, 0.1224, 0.1248, 0.1246, 0.1232, 0.1163, 0.1070, 0.0710,\n",
      "         0.0021],\n",
      "        [0.0907, 0.1176, 0.1220, 0.1243, 0.1242, 0.1229, 0.1163, 0.1073, 0.0724,\n",
      "         0.0023],\n",
      "        [0.0906, 0.1173, 0.1217, 0.1241, 0.1239, 0.1227, 0.1163, 0.1076, 0.0734,\n",
      "         0.0024]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 所以 在 那 之后 5 年 我 <UNK> <UNK> 陪\n",
      "Reference: so for the next five years , i dressed\n",
      "Model: <SOS> we of the the , the the the the\n",
      "Attention Weights: tensor([[1.3138e-01, 1.9527e-01, 2.0273e-01, 1.9360e-01, 1.6208e-01, 5.0516e-02,\n",
      "         6.3913e-02, 5.1333e-04, 1.5645e-12, 1.5645e-12],\n",
      "        [1.3015e-01, 1.9951e-01, 2.0501e-01, 1.9348e-01, 1.6127e-01, 4.7500e-02,\n",
      "         6.2313e-02, 7.6772e-04, 2.1874e-11, 2.1874e-11],\n",
      "        [1.3648e-01, 1.9532e-01, 1.9901e-01, 1.8814e-01, 1.5926e-01, 5.3185e-02,\n",
      "         6.7040e-02, 1.5632e-03, 8.8254e-11, 8.8254e-11],\n",
      "        [1.4155e-01, 1.8847e-01, 1.9063e-01, 1.8123e-01, 1.5694e-01, 6.3018e-02,\n",
      "         7.4837e-02, 3.3203e-03, 2.0145e-10, 2.0145e-10],\n",
      "        [1.4235e-01, 1.8432e-01, 1.8620e-01, 1.7785e-01, 1.5613e-01, 6.8810e-02,\n",
      "         7.9676e-02, 4.6614e-03, 2.2491e-10, 2.2491e-10],\n",
      "        [1.4169e-01, 1.8135e-01, 1.8344e-01, 1.7594e-01, 1.5598e-01, 7.2618e-02,\n",
      "         8.3288e-02, 5.6959e-03, 2.4357e-10, 2.4357e-10],\n",
      "        [1.4046e-01, 1.7880e-01, 1.8115e-01, 1.7439e-01, 1.5594e-01, 7.5804e-02,\n",
      "         8.6899e-02, 6.5618e-03, 2.1091e-10, 2.1091e-10],\n",
      "        [1.4002e-01, 1.7762e-01, 1.7993e-01, 1.7345e-01, 1.5572e-01, 7.7489e-02,\n",
      "         8.8661e-02, 7.1196e-03, 2.1580e-10, 2.1580e-10],\n",
      "        [1.4000e-01, 1.7727e-01, 1.7955e-01, 1.7314e-01, 1.5562e-01, 7.7992e-02,\n",
      "         8.9142e-02, 7.2964e-03, 2.2306e-10, 2.2306e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80.00, Train Loss: 3.10, Val Loss: 11.76, Train BLEU: 9.65, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 是 我 最 喜欢 的 因为 它 哪 都 能动\n",
      "Reference: it &apos;s one of my favorites , because it\n",
      "Model: <SOS> it &apos;s &apos;s to , , . . .\n",
      "Attention Weights: tensor([[0.0814, 0.1195, 0.1289, 0.1364, 0.1335, 0.1300, 0.1164, 0.0983, 0.0556,\n",
      "         0.0001],\n",
      "        [0.0809, 0.1228, 0.1319, 0.1379, 0.1341, 0.1291, 0.1146, 0.0954, 0.0531,\n",
      "         0.0001],\n",
      "        [0.0866, 0.1232, 0.1309, 0.1356, 0.1316, 0.1267, 0.1132, 0.0957, 0.0563,\n",
      "         0.0003],\n",
      "        [0.0927, 0.1226, 0.1285, 0.1323, 0.1284, 0.1241, 0.1122, 0.0969, 0.0614,\n",
      "         0.0008],\n",
      "        [0.0953, 0.1215, 0.1265, 0.1297, 0.1263, 0.1225, 0.1120, 0.0986, 0.0663,\n",
      "         0.0013],\n",
      "        [0.0957, 0.1206, 0.1254, 0.1284, 0.1253, 0.1218, 0.1122, 0.0999, 0.0692,\n",
      "         0.0016],\n",
      "        [0.0957, 0.1199, 0.1245, 0.1274, 0.1246, 0.1214, 0.1124, 0.1008, 0.0715,\n",
      "         0.0019],\n",
      "        [0.0958, 0.1194, 0.1240, 0.1267, 0.1241, 0.1210, 0.1125, 0.1013, 0.0730,\n",
      "         0.0021],\n",
      "        [0.0959, 0.1193, 0.1237, 0.1265, 0.1239, 0.1209, 0.1125, 0.1015, 0.0735,\n",
      "         0.0022]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很 舒服 但 夏天 却 <UNK> <EOS> <PAD> <PAD>\n",
      "Reference: it was cozy in winter but extremely hot in\n",
      "Model: <SOS> it &apos;s the to . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0698, 0.1100, 0.1240, 0.1241, 0.1269, 0.1073, 0.1126, 0.1043, 0.0805,\n",
      "         0.0406],\n",
      "        [0.0727, 0.1128, 0.1252, 0.1250, 0.1265, 0.1063, 0.1096, 0.1014, 0.0790,\n",
      "         0.0415],\n",
      "        [0.0797, 0.1120, 0.1223, 0.1216, 0.1230, 0.1060, 0.1067, 0.1002, 0.0812,\n",
      "         0.0473],\n",
      "        [0.0849, 0.1113, 0.1194, 0.1186, 0.1197, 0.1050, 0.1052, 0.0997, 0.0834,\n",
      "         0.0527],\n",
      "        [0.0861, 0.1105, 0.1181, 0.1173, 0.1183, 0.1045, 0.1047, 0.0999, 0.0848,\n",
      "         0.0558],\n",
      "        [0.0863, 0.1100, 0.1173, 0.1166, 0.1175, 0.1039, 0.1046, 0.1002, 0.0858,\n",
      "         0.0577],\n",
      "        [0.0865, 0.1096, 0.1165, 0.1159, 0.1168, 0.1035, 0.1047, 0.1004, 0.0867,\n",
      "         0.0595],\n",
      "        [0.0865, 0.1093, 0.1161, 0.1156, 0.1164, 0.1035, 0.1047, 0.1005, 0.0871,\n",
      "         0.0604],\n",
      "        [0.0861, 0.1090, 0.1158, 0.1153, 0.1162, 0.1034, 0.1047, 0.1007, 0.0876,\n",
      "         0.0611]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 81.00, Train Loss: 3.08, Val Loss: 11.78, Train BLEU: 9.57, Val BLEU: 0.32\n",
      "Sampling from training predictions...\n",
      "Source: 是 我 最 喜欢 的 因为 它 哪 都 能动\n",
      "Reference: it &apos;s one of my favorites , because it\n",
      "Model: <SOS> it &apos;s &apos;s to , , . . .\n",
      "Attention Weights: tensor([[0.0817, 0.1198, 0.1288, 0.1364, 0.1334, 0.1301, 0.1163, 0.0982, 0.0554,\n",
      "         0.0001],\n",
      "        [0.0818, 0.1231, 0.1317, 0.1377, 0.1337, 0.1290, 0.1144, 0.0953, 0.0532,\n",
      "         0.0001],\n",
      "        [0.0882, 0.1233, 0.1304, 0.1351, 0.1309, 0.1263, 0.1129, 0.0957, 0.0568,\n",
      "         0.0004],\n",
      "        [0.0946, 0.1225, 0.1277, 0.1313, 0.1275, 0.1235, 0.1120, 0.0973, 0.0627,\n",
      "         0.0009],\n",
      "        [0.0967, 0.1211, 0.1256, 0.1287, 0.1254, 0.1220, 0.1119, 0.0992, 0.0678,\n",
      "         0.0015],\n",
      "        [0.0970, 0.1202, 0.1245, 0.1274, 0.1244, 0.1213, 0.1121, 0.1005, 0.0708,\n",
      "         0.0019],\n",
      "        [0.0969, 0.1195, 0.1236, 0.1264, 0.1237, 0.1209, 0.1123, 0.1014, 0.0731,\n",
      "         0.0022],\n",
      "        [0.0969, 0.1191, 0.1232, 0.1259, 0.1234, 0.1206, 0.1124, 0.1018, 0.0742,\n",
      "         0.0024],\n",
      "        [0.0970, 0.1190, 0.1231, 0.1258, 0.1232, 0.1205, 0.1124, 0.1019, 0.0746,\n",
      "         0.0024]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很 舒服 但 夏天 却 <UNK> <EOS> <PAD> <PAD>\n",
      "Reference: it was cozy in winter but extremely hot in\n",
      "Model: <SOS> it &apos;s the to . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0704, 0.1103, 0.1240, 0.1238, 0.1267, 0.1065, 0.1126, 0.1045, 0.0806,\n",
      "         0.0406],\n",
      "        [0.0741, 0.1130, 0.1249, 0.1242, 0.1259, 0.1058, 0.1092, 0.1014, 0.0793,\n",
      "         0.0422],\n",
      "        [0.0817, 0.1119, 0.1215, 0.1205, 0.1221, 0.1056, 0.1062, 0.1002, 0.0817,\n",
      "         0.0486],\n",
      "        [0.0866, 0.1111, 0.1185, 0.1175, 0.1186, 0.1046, 0.1048, 0.0998, 0.0842,\n",
      "         0.0544],\n",
      "        [0.0876, 0.1102, 0.1172, 0.1161, 0.1173, 0.1042, 0.1043, 0.1000, 0.0856,\n",
      "         0.0575],\n",
      "        [0.0878, 0.1096, 0.1164, 0.1154, 0.1165, 0.1034, 0.1042, 0.1003, 0.0867,\n",
      "         0.0597],\n",
      "        [0.0877, 0.1092, 0.1157, 0.1149, 0.1159, 0.1031, 0.1043, 0.1006, 0.0875,\n",
      "         0.0612],\n",
      "        [0.0875, 0.1089, 0.1153, 0.1146, 0.1156, 0.1030, 0.1043, 0.1007, 0.0880,\n",
      "         0.0621],\n",
      "        [0.0872, 0.1086, 0.1151, 0.1143, 0.1154, 0.1030, 0.1044, 0.1009, 0.0883,\n",
      "         0.0628]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 82.00, Train Loss: 3.06, Val Loss: 11.79, Train BLEU: 9.62, Val BLEU: 0.32\n",
      "Sampling from training predictions...\n",
      "Source: 还有 前面 的 这个 是 推进 引擎 它 一会 一会儿\n",
      "Reference: and it &apos;s got these jet thrusters up in\n",
      "Model: <SOS> and &apos;s &apos;s got to , . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0859, 0.1367, 0.1448, 0.1511, 0.1442, 0.1397, 0.1223, 0.0748, 0.0005,\n",
      "         0.0000],\n",
      "        [0.0847, 0.1393, 0.1476, 0.1526, 0.1450, 0.1388, 0.1195, 0.0719, 0.0005,\n",
      "         0.0000],\n",
      "        [0.0901, 0.1393, 0.1463, 0.1504, 0.1429, 0.1369, 0.1188, 0.0742, 0.0010,\n",
      "         0.0001],\n",
      "        [0.0962, 0.1384, 0.1439, 0.1472, 0.1402, 0.1349, 0.1188, 0.0782, 0.0019,\n",
      "         0.0003],\n",
      "        [0.1006, 0.1374, 0.1417, 0.1445, 0.1382, 0.1334, 0.1191, 0.0817, 0.0028,\n",
      "         0.0005],\n",
      "        [0.1020, 0.1356, 0.1396, 0.1423, 0.1367, 0.1328, 0.1202, 0.0861, 0.0039,\n",
      "         0.0007],\n",
      "        [0.1026, 0.1345, 0.1384, 0.1409, 0.1359, 0.1324, 0.1208, 0.0888, 0.0047,\n",
      "         0.0009],\n",
      "        [0.1027, 0.1338, 0.1377, 0.1401, 0.1355, 0.1321, 0.1213, 0.0906, 0.0052,\n",
      "         0.0011],\n",
      "        [0.1029, 0.1333, 0.1371, 0.1394, 0.1351, 0.1319, 0.1215, 0.0919, 0.0057,\n",
      "         0.0012]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 父亲 在 用 他 的 灰色 小 收音\n",
      "Reference: my father was listening to bbc news on his\n",
      "Model: <SOS> we of the the , the the the the\n",
      "Attention Weights: tensor([[0.0142, 0.0013, 0.1473, 0.1447, 0.0834, 0.1589, 0.1479, 0.1395, 0.1079,\n",
      "         0.0549],\n",
      "        [0.0206, 0.0025, 0.1504, 0.1477, 0.0875, 0.1542, 0.1438, 0.1346, 0.1047,\n",
      "         0.0542],\n",
      "        [0.0321, 0.0059, 0.1483, 0.1447, 0.0957, 0.1450, 0.1361, 0.1288, 0.1037,\n",
      "         0.0596],\n",
      "        [0.0424, 0.0104, 0.1436, 0.1398, 0.0999, 0.1382, 0.1309, 0.1250, 0.1042,\n",
      "         0.0656],\n",
      "        [0.0464, 0.0127, 0.1405, 0.1373, 0.1010, 0.1353, 0.1289, 0.1239, 0.1050,\n",
      "         0.0691],\n",
      "        [0.0476, 0.0139, 0.1379, 0.1358, 0.1009, 0.1342, 0.1284, 0.1238, 0.1061,\n",
      "         0.0714],\n",
      "        [0.0483, 0.0146, 0.1364, 0.1348, 0.1007, 0.1336, 0.1282, 0.1237, 0.1067,\n",
      "         0.0730],\n",
      "        [0.0488, 0.0150, 0.1355, 0.1341, 0.1007, 0.1331, 0.1279, 0.1236, 0.1071,\n",
      "         0.0741],\n",
      "        [0.0491, 0.0153, 0.1349, 0.1337, 0.1007, 0.1328, 0.1278, 0.1236, 0.1074,\n",
      "         0.0747]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 83.00, Train Loss: 3.04, Val Loss: 11.80, Train BLEU: 9.57, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 地球 的 大部 大部分 部分 都 是 海水 <EOS> <PAD>\n",
      "Reference: most of the planet is ocean water . <EOS>\n",
      "Model: <SOS> it &apos;s the to about <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.0045e-01, 1.5125e-01, 1.5919e-01, 1.6099e-01, 1.4517e-01, 1.2534e-01,\n",
      "         1.0077e-01, 5.6362e-02, 4.8060e-04, 1.1776e-12],\n",
      "        [1.0183e-01, 1.5601e-01, 1.6167e-01, 1.6004e-01, 1.4332e-01, 1.2319e-01,\n",
      "         9.8351e-02, 5.4915e-02, 6.6850e-04, 1.7078e-11],\n",
      "        [1.0990e-01, 1.5482e-01, 1.5858e-01, 1.5606e-01, 1.4001e-01, 1.2152e-01,\n",
      "         9.8969e-02, 5.8792e-02, 1.3625e-03, 7.2845e-11],\n",
      "        [1.1536e-01, 1.5148e-01, 1.5375e-01, 1.5120e-01, 1.3725e-01, 1.2126e-01,\n",
      "         1.0156e-01, 6.5249e-02, 2.8991e-03, 1.7504e-10],\n",
      "        [1.1639e-01, 1.4894e-01, 1.5093e-01, 1.4867e-01, 1.3601e-01, 1.2154e-01,\n",
      "         1.0361e-01, 6.9788e-02, 4.1194e-03, 1.9628e-10],\n",
      "        [1.1600e-01, 1.4683e-01, 1.4894e-01, 1.4700e-01, 1.3545e-01, 1.2211e-01,\n",
      "         1.0541e-01, 7.3173e-02, 5.0884e-03, 2.1144e-10],\n",
      "        [1.1519e-01, 1.4508e-01, 1.4728e-01, 1.4559e-01, 1.3509e-01, 1.2274e-01,\n",
      "         1.0704e-01, 7.6125e-02, 5.8667e-03, 1.7925e-10],\n",
      "        [1.1509e-01, 1.4420e-01, 1.4630e-01, 1.4467e-01, 1.3472e-01, 1.2291e-01,\n",
      "         1.0782e-01, 7.7802e-02, 6.5008e-03, 1.8311e-10],\n",
      "        [1.1516e-01, 1.4390e-01, 1.4595e-01, 1.4435e-01, 1.3458e-01, 1.2294e-01,\n",
      "         1.0805e-01, 7.8330e-02, 6.7344e-03, 1.9178e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 她 两年 年前 退休 了 结果 却 把 我家 变成\n",
      "Reference: she retired two years ago , only to turn\n",
      "Model: <SOS> we of the the the , the the the\n",
      "Attention Weights: tensor([[1.8565e-01, 2.5274e-01, 2.4363e-01, 2.0326e-01, 1.1373e-01, 9.9784e-04,\n",
      "         2.4548e-12, 2.4548e-12, 2.4548e-12, 2.4548e-12],\n",
      "        [1.8677e-01, 2.5635e-01, 2.4311e-01, 2.0004e-01, 1.1235e-01, 1.3813e-03,\n",
      "         3.6831e-11, 3.6831e-11, 3.6831e-11, 3.6831e-11],\n",
      "        [1.9588e-01, 2.5038e-01, 2.3664e-01, 1.9714e-01, 1.1725e-01, 2.7116e-03,\n",
      "         1.5000e-10, 1.5000e-10, 1.5000e-10, 1.5000e-10],\n",
      "        [2.0058e-01, 2.4257e-01, 2.2984e-01, 1.9583e-01, 1.2560e-01, 5.5790e-03,\n",
      "         3.4337e-10, 3.4337e-10, 3.4337e-10, 3.4337e-10],\n",
      "        [2.0031e-01, 2.3832e-01, 2.2686e-01, 1.9600e-01, 1.3098e-01, 7.5366e-03,\n",
      "         3.7841e-10, 3.7841e-10, 3.7841e-10, 3.7841e-10],\n",
      "        [1.9892e-01, 2.3542e-01, 2.2518e-01, 1.9653e-01, 1.3491e-01, 9.0492e-03,\n",
      "         4.1582e-10, 4.1582e-10, 4.1582e-10, 4.1582e-10],\n",
      "        [1.9734e-01, 2.3242e-01, 2.2344e-01, 1.9717e-01, 1.3919e-01, 1.0444e-02,\n",
      "         3.5579e-10, 3.5579e-10, 3.5579e-10, 3.5579e-10],\n",
      "        [1.9610e-01, 2.3059e-01, 2.2222e-01, 1.9744e-01, 1.4195e-01, 1.1701e-02,\n",
      "         3.3967e-10, 3.3967e-10, 3.3967e-10, 3.3967e-10],\n",
      "        [1.9596e-01, 2.2984e-01, 2.2165e-01, 1.9741e-01, 1.4290e-01, 1.2246e-02,\n",
      "         3.5785e-10, 3.5785e-10, 3.5785e-10, 3.5785e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84.00, Train Loss: 3.01, Val Loss: 11.82, Train BLEU: 9.84, Val BLEU: 0.33\n",
      "Sampling from training predictions...\n",
      "Source: 但 我 想 告诉 你 的 是 当 你 站\n",
      "Reference: but when you &apos;re standing at the beach ,\n",
      "Model: <SOS> we of the the , , the the the\n",
      "Attention Weights: tensor([[0.0736, 0.1090, 0.1173, 0.1241, 0.1208, 0.1201, 0.1129, 0.1003, 0.0811,\n",
      "         0.0408],\n",
      "        [0.0785, 0.1114, 0.1182, 0.1232, 0.1194, 0.1179, 0.1106, 0.0984, 0.0801,\n",
      "         0.0422],\n",
      "        [0.0863, 0.1106, 0.1154, 0.1194, 0.1157, 0.1144, 0.1083, 0.0981, 0.0828,\n",
      "         0.0489],\n",
      "        [0.0904, 0.1095, 0.1130, 0.1161, 0.1130, 0.1119, 0.1069, 0.0984, 0.0856,\n",
      "         0.0552],\n",
      "        [0.0910, 0.1086, 0.1119, 0.1148, 0.1119, 0.1110, 0.1065, 0.0988, 0.0871,\n",
      "         0.0585],\n",
      "        [0.0908, 0.1080, 0.1113, 0.1141, 0.1114, 0.1107, 0.1064, 0.0991, 0.0880,\n",
      "         0.0603],\n",
      "        [0.0907, 0.1077, 0.1110, 0.1137, 0.1111, 0.1104, 0.1063, 0.0992, 0.0885,\n",
      "         0.0613],\n",
      "        [0.0907, 0.1075, 0.1107, 0.1134, 0.1109, 0.1102, 0.1062, 0.0993, 0.0889,\n",
      "         0.0623],\n",
      "        [0.0904, 0.1072, 0.1105, 0.1131, 0.1107, 0.1101, 0.1062, 0.0995, 0.0893,\n",
      "         0.0632]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 所以 在 那 之后 5 年 我 <UNK> <UNK> 陪\n",
      "Reference: so for the next five years , i dressed\n",
      "Model: <SOS> we of the the , the the the the\n",
      "Attention Weights: tensor([[1.3605e-01, 2.0226e-01, 2.0742e-01, 1.9564e-01, 1.5835e-01, 4.2337e-02,\n",
      "         5.7472e-02, 4.7929e-04, 1.8305e-12, 1.8305e-12],\n",
      "        [1.3811e-01, 2.0608e-01, 2.0813e-01, 1.9366e-01, 1.5646e-01, 4.0439e-02,\n",
      "         5.6342e-02, 7.7186e-04, 2.6712e-11, 2.6712e-11],\n",
      "        [1.4697e-01, 2.0027e-01, 2.0039e-01, 1.8708e-01, 1.5433e-01, 4.7778e-02,\n",
      "         6.1490e-02, 1.6880e-03, 1.1091e-10, 1.1091e-10],\n",
      "        [1.5125e-01, 1.9218e-01, 1.9126e-01, 1.7998e-01, 1.5270e-01, 5.9014e-02,\n",
      "         6.9908e-02, 3.7124e-03, 2.6106e-10, 2.6106e-10],\n",
      "        [1.5093e-01, 1.8779e-01, 1.8703e-01, 1.7704e-01, 1.5256e-01, 6.4932e-02,\n",
      "         7.4624e-02, 5.0966e-03, 2.8825e-10, 2.8825e-10],\n",
      "        [1.4976e-01, 1.8461e-01, 1.8426e-01, 1.7524e-01, 1.5272e-01, 6.8873e-02,\n",
      "         7.8319e-02, 6.2077e-03, 3.0975e-10, 3.0975e-10],\n",
      "        [1.4798e-01, 1.8183e-01, 1.8190e-01, 1.7379e-01, 1.5308e-01, 7.2020e-02,\n",
      "         8.2257e-02, 7.1375e-03, 2.5050e-10, 2.5050e-10],\n",
      "        [1.4740e-01, 1.8028e-01, 1.8035e-01, 1.7263e-01, 1.5289e-01, 7.4145e-02,\n",
      "         8.4435e-02, 7.8742e-03, 2.5631e-10, 2.5631e-10],\n",
      "        [1.4731e-01, 1.7980e-01, 1.7985e-01, 1.7225e-01, 1.5280e-01, 7.4824e-02,\n",
      "         8.5056e-02, 8.1160e-03, 2.6604e-10, 2.6604e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 85.00, Train Loss: 2.99, Val Loss: 11.83, Train BLEU: 10.10, Val BLEU: 0.32\n",
      "Sampling from training predictions...\n",
      "Source: 当 你 站 在 海滩 上 或是 当 你 看到\n",
      "Reference: part of the problem , i think , is\n",
      "Model: <SOS> we of the the , the the the the\n",
      "Attention Weights: tensor([[0.0714, 0.1064, 0.1154, 0.1207, 0.1272, 0.1187, 0.1197, 0.0996, 0.0807,\n",
      "         0.0403],\n",
      "        [0.0771, 0.1092, 0.1166, 0.1204, 0.1250, 0.1166, 0.1163, 0.0976, 0.0796,\n",
      "         0.0418],\n",
      "        [0.0853, 0.1087, 0.1140, 0.1168, 0.1205, 0.1131, 0.1131, 0.0973, 0.0824,\n",
      "         0.0488],\n",
      "        [0.0894, 0.1078, 0.1118, 0.1140, 0.1170, 0.1108, 0.1109, 0.0977, 0.0852,\n",
      "         0.0554],\n",
      "        [0.0900, 0.1069, 0.1107, 0.1127, 0.1156, 0.1098, 0.1103, 0.0980, 0.0868,\n",
      "         0.0590],\n",
      "        [0.0899, 0.1064, 0.1102, 0.1121, 0.1148, 0.1095, 0.1099, 0.0984, 0.0879,\n",
      "         0.0610],\n",
      "        [0.0899, 0.1061, 0.1098, 0.1117, 0.1142, 0.1092, 0.1096, 0.0986, 0.0885,\n",
      "         0.0623],\n",
      "        [0.0896, 0.1058, 0.1095, 0.1114, 0.1139, 0.1091, 0.1095, 0.0988, 0.0890,\n",
      "         0.0634],\n",
      "        [0.0894, 0.1057, 0.1093, 0.1112, 0.1137, 0.1089, 0.1094, 0.0989, 0.0893,\n",
      "         0.0640]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 想 过 要 放弃 但 我 的 父亲 这时\n",
      "Reference: i would want to quit , but my father\n",
      "Model: <SOS> we of the the , the the the the\n",
      "Attention Weights: tensor([[0.0847, 0.1360, 0.1444, 0.1520, 0.1447, 0.1414, 0.1232, 0.0732, 0.0004,\n",
      "         0.0000],\n",
      "        [0.0849, 0.1388, 0.1472, 0.1532, 0.1451, 0.1400, 0.1201, 0.0701, 0.0005,\n",
      "         0.0000],\n",
      "        [0.0915, 0.1388, 0.1457, 0.1508, 0.1427, 0.1378, 0.1193, 0.0724, 0.0010,\n",
      "         0.0001],\n",
      "        [0.0979, 0.1380, 0.1432, 0.1474, 0.1400, 0.1357, 0.1192, 0.0766, 0.0019,\n",
      "         0.0003],\n",
      "        [0.1029, 0.1368, 0.1408, 0.1443, 0.1376, 0.1339, 0.1194, 0.0807, 0.0030,\n",
      "         0.0005],\n",
      "        [0.1041, 0.1349, 0.1386, 0.1421, 0.1361, 0.1333, 0.1206, 0.0852, 0.0042,\n",
      "         0.0008],\n",
      "        [0.1047, 0.1337, 0.1373, 0.1406, 0.1353, 0.1328, 0.1213, 0.0882, 0.0051,\n",
      "         0.0010],\n",
      "        [0.1047, 0.1331, 0.1367, 0.1397, 0.1349, 0.1325, 0.1216, 0.0901, 0.0056,\n",
      "         0.0012],\n",
      "        [0.1049, 0.1326, 0.1361, 0.1390, 0.1345, 0.1322, 0.1218, 0.0914, 0.0062,\n",
      "         0.0013]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 86.00, Train Loss: 2.96, Val Loss: 11.84, Train BLEU: 9.85, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 其实 它们 都 是 由 单独 的 动物 结合 合在\n",
      "Reference: these are all individual animals banding together to make\n",
      "Model: <SOS> these &apos;s the to , , , , ,\n",
      "Attention Weights: tensor([[0.0748, 0.1191, 0.1260, 0.1314, 0.1328, 0.1339, 0.1210, 0.1083, 0.0527,\n",
      "         0.0001],\n",
      "        [0.0789, 0.1215, 0.1278, 0.1323, 0.1326, 0.1324, 0.1189, 0.1048, 0.0507,\n",
      "         0.0002],\n",
      "        [0.0872, 0.1208, 0.1256, 0.1293, 0.1292, 0.1292, 0.1172, 0.1052, 0.0558,\n",
      "         0.0005],\n",
      "        [0.0919, 0.1199, 0.1235, 0.1266, 0.1265, 0.1266, 0.1163, 0.1061, 0.0615,\n",
      "         0.0011],\n",
      "        [0.0934, 0.1190, 0.1222, 0.1251, 0.1251, 0.1254, 0.1160, 0.1071, 0.0652,\n",
      "         0.0014],\n",
      "        [0.0939, 0.1183, 0.1215, 0.1243, 0.1243, 0.1246, 0.1159, 0.1077, 0.0677,\n",
      "         0.0017],\n",
      "        [0.0945, 0.1180, 0.1211, 0.1237, 0.1238, 0.1240, 0.1158, 0.1078, 0.0693,\n",
      "         0.0020],\n",
      "        [0.0946, 0.1176, 0.1206, 0.1232, 0.1233, 0.1236, 0.1158, 0.1082, 0.0708,\n",
      "         0.0021],\n",
      "        [0.0946, 0.1173, 0.1203, 0.1229, 0.1230, 0.1233, 0.1158, 0.1085, 0.0719,\n",
      "         0.0023]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 在 被 跟踪 吗 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: were we being followed ? <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a to about <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.1089, 0.1655, 0.1694, 0.1574, 0.1410, 0.0767, 0.0020, 0.0010, 0.1238,\n",
      "         0.0543],\n",
      "        [0.1160, 0.1661, 0.1683, 0.1570, 0.1411, 0.0829, 0.0039, 0.0025, 0.1101,\n",
      "         0.0521],\n",
      "        [0.1231, 0.1579, 0.1591, 0.1509, 0.1400, 0.0922, 0.0083, 0.0059, 0.1062,\n",
      "         0.0563],\n",
      "        [0.1244, 0.1509, 0.1517, 0.1455, 0.1378, 0.0986, 0.0135, 0.0101, 0.1054,\n",
      "         0.0618],\n",
      "        [0.1236, 0.1475, 0.1486, 0.1434, 0.1372, 0.1015, 0.0162, 0.0123, 0.1051,\n",
      "         0.0646],\n",
      "        [0.1228, 0.1460, 0.1473, 0.1424, 0.1365, 0.1023, 0.0175, 0.0134, 0.1053,\n",
      "         0.0666],\n",
      "        [0.1221, 0.1447, 0.1460, 0.1413, 0.1355, 0.1027, 0.0185, 0.0143, 0.1061,\n",
      "         0.0687],\n",
      "        [0.1217, 0.1439, 0.1452, 0.1406, 0.1349, 0.1030, 0.0192, 0.0149, 0.1066,\n",
      "         0.0700],\n",
      "        [0.1210, 0.1433, 0.1446, 0.1402, 0.1347, 0.1033, 0.0196, 0.0152, 0.1071,\n",
      "         0.0711]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 87.00, Train Loss: 2.94, Val Loss: 11.86, Train BLEU: 9.89, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中 的 生命 大卫 <UNK> <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: life in the deep oceans <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> life &apos;s the to . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[2.0000e-01, 2.8415e-01, 2.5628e-01, 1.9274e-01, 6.6549e-02, 1.4691e-04,\n",
      "         1.2855e-04, 1.5168e-12, 1.5168e-12, 1.5168e-12],\n",
      "        [2.0323e-01, 2.8487e-01, 2.5402e-01, 1.8850e-01, 6.8808e-02, 3.1557e-04,\n",
      "         2.5889e-04, 2.7306e-11, 2.7306e-11, 2.7306e-11],\n",
      "        [2.1349e-01, 2.7115e-01, 2.4265e-01, 1.8827e-01, 8.2422e-02, 1.1283e-03,\n",
      "         8.9685e-04, 1.4719e-10, 1.4719e-10, 1.4719e-10],\n",
      "        [2.1405e-01, 2.5576e-01, 2.3319e-01, 1.9091e-01, 1.0027e-01, 3.2532e-03,\n",
      "         2.5642e-03, 3.8140e-10, 3.8140e-10, 3.8140e-10],\n",
      "        [2.1154e-01, 2.4824e-01, 2.2915e-01, 1.9267e-01, 1.0970e-01, 4.9186e-03,\n",
      "         3.7792e-03, 4.2732e-10, 4.2732e-10, 4.2732e-10],\n",
      "        [2.0886e-01, 2.4359e-01, 2.2717e-01, 1.9404e-01, 1.1575e-01, 5.9845e-03,\n",
      "         4.6046e-03, 3.8775e-10, 3.8775e-10, 3.8775e-10],\n",
      "        [2.0664e-01, 2.4151e-01, 2.2639e-01, 1.9482e-01, 1.1880e-01, 6.6294e-03,\n",
      "         5.2024e-03, 3.6113e-10, 3.6113e-10, 3.6113e-10],\n",
      "        [2.0619e-01, 2.4058e-01, 2.2582e-01, 1.9493e-01, 1.2006e-01, 6.9524e-03,\n",
      "         5.4685e-03, 3.7884e-10, 3.7884e-10, 3.7884e-10],\n",
      "        [2.0611e-01, 2.4030e-01, 2.2564e-01, 1.9494e-01, 1.2040e-01, 7.0575e-03,\n",
      "         5.5526e-03, 3.8937e-10, 3.8937e-10, 3.8937e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 不知 知道 那 意味 意味着 什么 但是 我 能\n",
      "Reference: i didn &apos;t know what it meant , but\n",
      "Model: <SOS> we of the the the , the the the\n",
      "Attention Weights: tensor([[0.0866, 0.1372, 0.1474, 0.1590, 0.1524, 0.1310, 0.1105, 0.0180, 0.0225,\n",
      "         0.0353],\n",
      "        [0.0930, 0.1362, 0.1438, 0.1528, 0.1472, 0.1293, 0.1117, 0.0240, 0.0273,\n",
      "         0.0348],\n",
      "        [0.1002, 0.1309, 0.1361, 0.1437, 0.1396, 0.1258, 0.1134, 0.0338, 0.0365,\n",
      "         0.0400],\n",
      "        [0.1029, 0.1269, 0.1308, 0.1371, 0.1340, 0.1229, 0.1135, 0.0423, 0.0436,\n",
      "         0.0459],\n",
      "        [0.1032, 0.1251, 0.1287, 0.1347, 0.1319, 0.1218, 0.1137, 0.0456, 0.0465,\n",
      "         0.0487],\n",
      "        [0.1032, 0.1244, 0.1281, 0.1338, 0.1311, 0.1215, 0.1138, 0.0468, 0.0474,\n",
      "         0.0499],\n",
      "        [0.1031, 0.1238, 0.1275, 0.1330, 0.1305, 0.1213, 0.1137, 0.0478, 0.0480,\n",
      "         0.0512],\n",
      "        [0.1028, 0.1231, 0.1268, 0.1320, 0.1296, 0.1210, 0.1135, 0.0491, 0.0491,\n",
      "         0.0530],\n",
      "        [0.1023, 0.1226, 0.1263, 0.1314, 0.1292, 0.1209, 0.1137, 0.0497, 0.0498,\n",
      "         0.0540]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 88.00, Train Loss: 2.92, Val Loss: 11.88, Train BLEU: 10.11, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 我们 用 的 是 深海 潜水 潜水艇 <UNK> 号 和\n",
      "Reference: we use the submarine alvin and we use cameras\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.1099, 0.1661, 0.1697, 0.1569, 0.1395, 0.0722, 0.0016, 0.0009, 0.1278,\n",
      "         0.0554],\n",
      "        [0.1189, 0.1658, 0.1673, 0.1557, 0.1394, 0.0800, 0.0036, 0.0025, 0.1133,\n",
      "         0.0534],\n",
      "        [0.1259, 0.1567, 0.1574, 0.1493, 0.1388, 0.0906, 0.0083, 0.0064, 0.1088,\n",
      "         0.0578],\n",
      "        [0.1263, 0.1491, 0.1496, 0.1437, 0.1368, 0.0980, 0.0140, 0.0112, 0.1075,\n",
      "         0.0637],\n",
      "        [0.1251, 0.1455, 0.1463, 0.1414, 0.1363, 0.1011, 0.0169, 0.0137, 0.1070,\n",
      "         0.0666],\n",
      "        [0.1243, 0.1439, 0.1449, 0.1404, 0.1354, 0.1020, 0.0183, 0.0150, 0.1072,\n",
      "         0.0689],\n",
      "        [0.1233, 0.1425, 0.1435, 0.1392, 0.1342, 0.1025, 0.0194, 0.0161, 0.1081,\n",
      "         0.0713],\n",
      "        [0.1226, 0.1417, 0.1428, 0.1387, 0.1338, 0.1029, 0.0200, 0.0165, 0.1086,\n",
      "         0.0726],\n",
      "        [0.1219, 0.1410, 0.1422, 0.1382, 0.1335, 0.1033, 0.0205, 0.0169, 0.1090,\n",
      "         0.0737]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 有时 学校 <UNK> 突然 <UNK> 一周 因为 被 塔利 塔利班\n",
      "Reference: from time to time , the school would suddenly\n",
      "Model: <SOS> and &apos;s the the , , , , ,\n",
      "Attention Weights: tensor([[0.0730, 0.1087, 0.1174, 0.1251, 0.1212, 0.1210, 0.1134, 0.1003, 0.0805,\n",
      "         0.0395],\n",
      "        [0.0805, 0.1114, 0.1178, 0.1237, 0.1192, 0.1180, 0.1105, 0.0981, 0.0794,\n",
      "         0.0414],\n",
      "        [0.0895, 0.1105, 0.1147, 0.1192, 0.1151, 0.1141, 0.1080, 0.0977, 0.0823,\n",
      "         0.0487],\n",
      "        [0.0931, 0.1092, 0.1122, 0.1158, 0.1123, 0.1115, 0.1065, 0.0981, 0.0854,\n",
      "         0.0559],\n",
      "        [0.0937, 0.1082, 0.1110, 0.1144, 0.1111, 0.1106, 0.1061, 0.0984, 0.0870,\n",
      "         0.0594],\n",
      "        [0.0933, 0.1075, 0.1104, 0.1136, 0.1106, 0.1102, 0.1060, 0.0988, 0.0881,\n",
      "         0.0615],\n",
      "        [0.0931, 0.1072, 0.1100, 0.1131, 0.1103, 0.1099, 0.1059, 0.0991, 0.0887,\n",
      "         0.0626],\n",
      "        [0.0930, 0.1069, 0.1097, 0.1127, 0.1100, 0.1097, 0.1059, 0.0992, 0.0892,\n",
      "         0.0637],\n",
      "        [0.0926, 0.1065, 0.1094, 0.1124, 0.1098, 0.1095, 0.1059, 0.0994, 0.0897,\n",
      "         0.0647]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 89.00, Train Loss: 2.89, Val Loss: 11.89, Train BLEU: 11.03, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 还有 前面 的 这个 是 推进 引擎 它 一会 一会儿\n",
      "Reference: and it &apos;s got these jet thrusters up in\n",
      "Model: <SOS> and &apos;s &apos;s got these about , . <EOS>\n",
      "Attention Weights: tensor([[0.0829, 0.1352, 0.1441, 0.1532, 0.1453, 0.1437, 0.1246, 0.0706, 0.0004,\n",
      "         0.0000],\n",
      "        [0.0849, 0.1380, 0.1463, 0.1541, 0.1453, 0.1422, 0.1214, 0.0673, 0.0004,\n",
      "         0.0000],\n",
      "        [0.0928, 0.1381, 0.1447, 0.1514, 0.1425, 0.1396, 0.1202, 0.0695, 0.0009,\n",
      "         0.0001],\n",
      "        [0.0999, 0.1375, 0.1422, 0.1479, 0.1397, 0.1371, 0.1199, 0.0737, 0.0018,\n",
      "         0.0002],\n",
      "        [0.1059, 0.1363, 0.1395, 0.1443, 0.1369, 0.1348, 0.1199, 0.0786, 0.0032,\n",
      "         0.0006],\n",
      "        [0.1071, 0.1343, 0.1373, 0.1418, 0.1352, 0.1339, 0.1211, 0.0837, 0.0047,\n",
      "         0.0009],\n",
      "        [0.1076, 0.1329, 0.1358, 0.1400, 0.1343, 0.1332, 0.1218, 0.0873, 0.0058,\n",
      "         0.0012],\n",
      "        [0.1076, 0.1322, 0.1352, 0.1389, 0.1339, 0.1328, 0.1221, 0.0895, 0.0065,\n",
      "         0.0014],\n",
      "        [0.1078, 0.1316, 0.1345, 0.1380, 0.1334, 0.1323, 0.1223, 0.0912, 0.0072,\n",
      "         0.0016]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 祖父 在 他 的 年代 是 位非 非凡\n",
      "Reference: my grandfather was an extraordinary man for his time\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0800, 0.1205, 0.1300, 0.1393, 0.1358, 0.1333, 0.1162, 0.0953, 0.0494,\n",
      "         0.0000],\n",
      "        [0.0841, 0.1247, 0.1329, 0.1405, 0.1353, 0.1314, 0.1129, 0.0911, 0.0469,\n",
      "         0.0001],\n",
      "        [0.0937, 0.1251, 0.1311, 0.1371, 0.1317, 0.1279, 0.1109, 0.0913, 0.0507,\n",
      "         0.0003],\n",
      "        [0.1008, 0.1239, 0.1279, 0.1326, 0.1277, 0.1246, 0.1101, 0.0936, 0.0579,\n",
      "         0.0009],\n",
      "        [0.1025, 0.1222, 0.1255, 0.1297, 0.1254, 0.1230, 0.1103, 0.0961, 0.0638,\n",
      "         0.0016],\n",
      "        [0.1023, 0.1208, 0.1241, 0.1279, 0.1243, 0.1221, 0.1109, 0.0980, 0.0675,\n",
      "         0.0021],\n",
      "        [0.1018, 0.1199, 0.1232, 0.1267, 0.1235, 0.1215, 0.1113, 0.0994, 0.0703,\n",
      "         0.0024],\n",
      "        [0.1019, 0.1194, 0.1225, 0.1259, 0.1229, 0.1210, 0.1114, 0.1001, 0.0721,\n",
      "         0.0027],\n",
      "        [0.1019, 0.1192, 0.1223, 0.1256, 0.1227, 0.1209, 0.1115, 0.1003, 0.0728,\n",
      "         0.0029]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 90.00, Train Loss: 2.87, Val Loss: 11.89, Train BLEU: 11.09, Val BLEU: 0.26\n",
      "Sampling from training predictions...\n",
      "Source: 看到 这些 在 动 的 东西 了 吗 <EOS> <PAD>\n",
      "Reference: but see all those different working things ? <EOS>\n",
      "Model: <SOS> it &apos;s a to about . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.0446e-01, 1.5821e-01, 1.6024e-01, 1.5326e-01, 1.4363e-01, 1.2572e-01,\n",
      "         9.7946e-02, 5.6040e-02, 5.0040e-04, 1.4644e-12],\n",
      "        [1.1112e-01, 1.6185e-01, 1.6125e-01, 1.5245e-01, 1.4084e-01, 1.2199e-01,\n",
      "         9.4749e-02, 5.4963e-02, 7.9176e-04, 2.3407e-11],\n",
      "        [1.2267e-01, 1.5909e-01, 1.5629e-01, 1.4767e-01, 1.3703e-01, 1.2020e-01,\n",
      "         9.5768e-02, 5.9527e-02, 1.7588e-03, 1.0122e-10],\n",
      "        [1.2676e-01, 1.5366e-01, 1.5057e-01, 1.4323e-01, 1.3442e-01, 1.2042e-01,\n",
      "         9.9601e-02, 6.7281e-02, 4.0614e-03, 2.6477e-10],\n",
      "        [1.2650e-01, 1.5064e-01, 1.4792e-01, 1.4137e-01, 1.3350e-01, 1.2091e-01,\n",
      "         1.0190e-01, 7.1652e-02, 5.6112e-03, 3.0583e-10],\n",
      "        [1.2505e-01, 1.4798e-01, 1.4590e-01, 1.4017e-01, 1.3309e-01, 1.2163e-01,\n",
      "         1.0402e-01, 7.5303e-02, 6.8548e-03, 3.2773e-10],\n",
      "        [1.2329e-01, 1.4547e-01, 1.4399e-01, 1.3903e-01, 1.3266e-01, 1.2223e-01,\n",
      "         1.0608e-01, 7.9074e-02, 8.1696e-03, 2.7241e-10],\n",
      "        [1.2276e-01, 1.4417e-01, 1.4284e-01, 1.3818e-01, 1.3218e-01, 1.2233e-01,\n",
      "         1.0707e-01, 8.1221e-02, 9.2536e-03, 2.8298e-10],\n",
      "        [1.2270e-01, 1.4380e-01, 1.4249e-01, 1.3792e-01, 1.3202e-01, 1.2234e-01,\n",
      "         1.0733e-01, 8.1805e-02, 9.5891e-03, 2.9624e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 但是 我 那 受过 教育 的 母亲 成为 为了 一名\n",
      "Reference: but my educated mother became a teacher . <EOS>\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[1.9924e-01, 2.2957e-01, 1.2564e-01, 1.9950e-03, 7.7355e-02, 2.3955e-01,\n",
      "         1.2568e-01, 9.7429e-04, 3.2190e-12, 3.2190e-12],\n",
      "        [2.1669e-01, 2.4393e-01, 1.3816e-01, 3.2464e-03, 7.4031e-02, 2.0944e-01,\n",
      "         1.1311e-01, 1.3969e-03, 4.0060e-11, 4.0060e-11],\n",
      "        [2.2869e-01, 2.3953e-01, 1.4963e-01, 8.0170e-03, 8.8629e-02, 1.7879e-01,\n",
      "         1.0385e-01, 2.8709e-03, 1.6548e-10, 1.6548e-10],\n",
      "        [2.2292e-01, 2.2892e-01, 1.5864e-01, 1.5911e-02, 1.0209e-01, 1.6267e-01,\n",
      "         1.0310e-01, 5.7659e-03, 3.9331e-10, 3.9331e-10],\n",
      "        [2.1752e-01, 2.2366e-01, 1.6108e-01, 2.0208e-02, 1.0664e-01, 1.5834e-01,\n",
      "         1.0499e-01, 7.5647e-03, 4.3953e-10, 4.3953e-10],\n",
      "        [2.1186e-01, 2.1868e-01, 1.6185e-01, 2.3164e-02, 1.0895e-01, 1.5788e-01,\n",
      "         1.0844e-01, 9.1815e-03, 4.8029e-10, 4.8029e-10],\n",
      "        [2.0503e-01, 2.1247e-01, 1.6094e-01, 2.5465e-02, 1.1111e-01, 1.6004e-01,\n",
      "         1.1397e-01, 1.0974e-02, 3.9560e-10, 3.9560e-10],\n",
      "        [2.0079e-01, 2.0857e-01, 1.6052e-01, 2.7533e-02, 1.1257e-01, 1.6062e-01,\n",
      "         1.1690e-01, 1.2510e-02, 3.9424e-10, 3.9424e-10],\n",
      "        [1.9967e-01, 2.0747e-01, 1.6061e-01, 2.8276e-02, 1.1316e-01, 1.6041e-01,\n",
      "         1.1744e-01, 1.2970e-02, 4.1084e-10, 4.1084e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 91.00, Train Loss: 2.85, Val Loss: 11.91, Train BLEU: 12.18, Val BLEU: 0.26\n",
      "Sampling from training predictions...\n",
      "Source: 还有 前面 的 这个 是 推进 引擎 它 一会 一会儿\n",
      "Reference: and it &apos;s got these jet thrusters up in\n",
      "Model: <SOS> and it &apos;s got these about , . <EOS>\n",
      "Attention Weights: tensor([[0.0811, 0.1337, 0.1434, 0.1545, 0.1460, 0.1461, 0.1254, 0.0693, 0.0003,\n",
      "         0.0000],\n",
      "        [0.0837, 0.1364, 0.1455, 0.1554, 0.1459, 0.1447, 0.1223, 0.0657, 0.0004,\n",
      "         0.0000],\n",
      "        [0.0922, 0.1368, 0.1439, 0.1526, 0.1430, 0.1418, 0.1209, 0.0678, 0.0008,\n",
      "         0.0001],\n",
      "        [0.0998, 0.1364, 0.1415, 0.1490, 0.1401, 0.1391, 0.1204, 0.0719, 0.0016,\n",
      "         0.0002],\n",
      "        [0.1062, 0.1354, 0.1389, 0.1452, 0.1372, 0.1365, 0.1203, 0.0769, 0.0029,\n",
      "         0.0005],\n",
      "        [0.1074, 0.1336, 0.1368, 0.1427, 0.1355, 0.1354, 0.1215, 0.0820, 0.0043,\n",
      "         0.0008],\n",
      "        [0.1079, 0.1322, 0.1354, 0.1409, 0.1346, 0.1347, 0.1222, 0.0856, 0.0054,\n",
      "         0.0011],\n",
      "        [0.1080, 0.1316, 0.1347, 0.1397, 0.1341, 0.1340, 0.1224, 0.0879, 0.0061,\n",
      "         0.0013],\n",
      "        [0.1082, 0.1310, 0.1341, 0.1387, 0.1337, 0.1335, 0.1226, 0.0899, 0.0068,\n",
      "         0.0015]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6 岁 那年 塔利 塔利班 占领 阿富汗 并 规定\n",
      "Reference: you see , i was six when the taliban\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[1.0361e-01, 1.5669e-01, 1.6374e-01, 1.6778e-01, 1.4330e-01, 1.1866e-01,\n",
      "         9.3002e-02, 5.2778e-02, 4.3925e-04, 1.4343e-12],\n",
      "        [1.1156e-01, 1.6178e-01, 1.6484e-01, 1.6480e-01, 1.3963e-01, 1.1533e-01,\n",
      "         8.9944e-02, 5.1394e-02, 7.2764e-04, 2.2795e-11],\n",
      "        [1.2368e-01, 1.5904e-01, 1.5967e-01, 1.5888e-01, 1.3546e-01, 1.1376e-01,\n",
      "         9.1354e-02, 5.6468e-02, 1.6969e-03, 1.0295e-10],\n",
      "        [1.2763e-01, 1.5347e-01, 1.5333e-01, 1.5271e-01, 1.3308e-01, 1.1488e-01,\n",
      "         9.5835e-02, 6.5052e-02, 4.0141e-03, 2.7763e-10],\n",
      "        [1.2708e-01, 1.5016e-01, 1.5024e-01, 1.4995e-01, 1.3227e-01, 1.1590e-01,\n",
      "         9.8622e-02, 7.0125e-02, 5.6527e-03, 3.2253e-10],\n",
      "        [1.2536e-01, 1.4697e-01, 1.4744e-01, 1.4740e-01, 1.3193e-01, 1.1736e-01,\n",
      "         1.0160e-01, 7.4768e-02, 7.1635e-03, 3.2110e-10],\n",
      "        [1.2367e-01, 1.4488e-01, 1.4546e-01, 1.4533e-01, 1.3163e-01, 1.1841e-01,\n",
      "         1.0379e-01, 7.8244e-02, 8.5853e-03, 2.8289e-10],\n",
      "        [1.2340e-01, 1.4396e-01, 1.4448e-01, 1.4430e-01, 1.3132e-01, 1.1870e-01,\n",
      "         1.0463e-01, 7.9799e-02, 9.4157e-03, 3.0476e-10],\n",
      "        [1.2337e-01, 1.4374e-01, 1.4425e-01, 1.4405e-01, 1.3124e-01, 1.1875e-01,\n",
      "         1.0481e-01, 8.0154e-02, 9.6273e-03, 3.1563e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92.00, Train Loss: 2.82, Val Loss: 11.92, Train BLEU: 13.25, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 这位 是 比尔 <UNK> 我 是 大卫 <UNK>\n",
      "Reference: this is bill lange . i &apos;m dave gallo\n",
      "Model: <SOS> this is bill lange , , , , ,\n",
      "Attention Weights: tensor([[0.0254, 0.0018, 0.2376, 0.1621, 0.0150, 0.0022, 0.3081, 0.1886, 0.0590,\n",
      "         0.0001],\n",
      "        [0.0354, 0.0031, 0.2496, 0.1727, 0.0182, 0.0036, 0.2857, 0.1739, 0.0576,\n",
      "         0.0002],\n",
      "        [0.0547, 0.0087, 0.2467, 0.1752, 0.0316, 0.0095, 0.2495, 0.1581, 0.0649,\n",
      "         0.0010],\n",
      "        [0.0699, 0.0163, 0.2290, 0.1725, 0.0452, 0.0173, 0.2207, 0.1514, 0.0750,\n",
      "         0.0026],\n",
      "        [0.0771, 0.0216, 0.2143, 0.1686, 0.0538, 0.0228, 0.2061, 0.1496, 0.0819,\n",
      "         0.0040],\n",
      "        [0.0805, 0.0251, 0.2029, 0.1653, 0.0589, 0.0266, 0.1975, 0.1499, 0.0879,\n",
      "         0.0054],\n",
      "        [0.0817, 0.0267, 0.1978, 0.1638, 0.0610, 0.0284, 0.1937, 0.1499, 0.0908,\n",
      "         0.0061],\n",
      "        [0.0826, 0.0276, 0.1954, 0.1631, 0.0621, 0.0293, 0.1917, 0.1496, 0.0921,\n",
      "         0.0065],\n",
      "        [0.0830, 0.0280, 0.1946, 0.1628, 0.0625, 0.0297, 0.1909, 0.1494, 0.0925,\n",
      "         0.0066]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把 书 放在 食品 杂货 袋中 这样 别人 就\n",
      "Reference: we would cover our books in grocery bags so\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0648, 0.1105, 0.1195, 0.1192, 0.1316, 0.1154, 0.1096, 0.1125, 0.0792,\n",
      "         0.0377],\n",
      "        [0.0750, 0.1123, 0.1189, 0.1177, 0.1283, 0.1129, 0.1072, 0.1089, 0.0783,\n",
      "         0.0405],\n",
      "        [0.0863, 0.1111, 0.1148, 0.1134, 0.1220, 0.1092, 0.1047, 0.1069, 0.0819,\n",
      "         0.0497],\n",
      "        [0.0904, 0.1096, 0.1121, 0.1107, 0.1178, 0.1072, 0.1036, 0.1059, 0.0852,\n",
      "         0.0576],\n",
      "        [0.0910, 0.1083, 0.1107, 0.1095, 0.1163, 0.1064, 0.1034, 0.1060, 0.0870,\n",
      "         0.0616],\n",
      "        [0.0909, 0.1074, 0.1099, 0.1089, 0.1149, 0.1062, 0.1035, 0.1057, 0.0886,\n",
      "         0.0640],\n",
      "        [0.0906, 0.1069, 0.1093, 0.1085, 0.1142, 0.1061, 0.1036, 0.1057, 0.0894,\n",
      "         0.0656],\n",
      "        [0.0903, 0.1065, 0.1090, 0.1083, 0.1138, 0.1060, 0.1036, 0.1057, 0.0900,\n",
      "         0.0667],\n",
      "        [0.0902, 0.1063, 0.1089, 0.1082, 0.1136, 0.1060, 0.1036, 0.1057, 0.0902,\n",
      "         0.0673]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 93.00, Train Loss: 2.80, Val Loss: 11.93, Train BLEU: 13.71, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 我们 将 用 一些 影片 来讲 讲述 一些 深海 海里\n",
      "Reference: and we &apos;re going to tell you some stories\n",
      "Model: <SOS> and of the the the , the the the\n",
      "Attention Weights: tensor([[0.0640, 0.0987, 0.1077, 0.1262, 0.1290, 0.1220, 0.1183, 0.1103, 0.0883,\n",
      "         0.0354],\n",
      "        [0.0742, 0.1022, 0.1087, 0.1245, 0.1259, 0.1190, 0.1147, 0.1067, 0.0860,\n",
      "         0.0381],\n",
      "        [0.0857, 0.1027, 0.1066, 0.1194, 0.1202, 0.1145, 0.1109, 0.1048, 0.0885,\n",
      "         0.0467],\n",
      "        [0.0899, 0.1025, 0.1054, 0.1160, 0.1164, 0.1116, 0.1088, 0.1040, 0.0908,\n",
      "         0.0547],\n",
      "        [0.0906, 0.1018, 0.1046, 0.1146, 0.1150, 0.1106, 0.1082, 0.1041, 0.0922,\n",
      "         0.0583],\n",
      "        [0.0904, 0.1016, 0.1045, 0.1142, 0.1145, 0.1103, 0.1080, 0.1042, 0.0928,\n",
      "         0.0596],\n",
      "        [0.0906, 0.1016, 0.1045, 0.1134, 0.1137, 0.1099, 0.1077, 0.1041, 0.0933,\n",
      "         0.0612],\n",
      "        [0.0906, 0.1015, 0.1043, 0.1127, 0.1131, 0.1095, 0.1075, 0.1040, 0.0939,\n",
      "         0.0629],\n",
      "        [0.0903, 0.1013, 0.1041, 0.1123, 0.1127, 0.1093, 0.1074, 0.1041, 0.0944,\n",
      "         0.0642]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正 的 学校 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: a real school . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a to about <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0671, 0.1081, 0.1351, 0.1221, 0.1260, 0.1397, 0.1302, 0.1108, 0.0608,\n",
      "         0.0002],\n",
      "        [0.0766, 0.1111, 0.1348, 0.1217, 0.1246, 0.1367, 0.1265, 0.1075, 0.0600,\n",
      "         0.0005],\n",
      "        [0.0879, 0.1117, 0.1302, 0.1190, 0.1211, 0.1314, 0.1229, 0.1077, 0.0667,\n",
      "         0.0016],\n",
      "        [0.0917, 0.1114, 0.1270, 0.1172, 0.1191, 0.1282, 0.1212, 0.1087, 0.0727,\n",
      "         0.0028],\n",
      "        [0.0927, 0.1108, 0.1257, 0.1162, 0.1182, 0.1270, 0.1206, 0.1094, 0.0759,\n",
      "         0.0036],\n",
      "        [0.0932, 0.1107, 0.1245, 0.1160, 0.1179, 0.1259, 0.1200, 0.1096, 0.0780,\n",
      "         0.0042],\n",
      "        [0.0936, 0.1106, 0.1236, 0.1158, 0.1176, 0.1250, 0.1196, 0.1098, 0.0798,\n",
      "         0.0048],\n",
      "        [0.0935, 0.1103, 0.1229, 0.1155, 0.1173, 0.1245, 0.1194, 0.1101, 0.0813,\n",
      "         0.0052],\n",
      "        [0.0936, 0.1102, 0.1225, 0.1153, 0.1171, 0.1241, 0.1192, 0.1102, 0.0822,\n",
      "         0.0056]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 94.00, Train Loss: 2.77, Val Loss: 11.94, Train BLEU: 13.73, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中 的 生命 大卫 <UNK> <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: life in the deep oceans <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> life in the to . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[2.1632e-01, 2.9486e-01, 2.5094e-01, 1.8577e-01, 5.1981e-02, 7.2420e-05,\n",
      "         5.9076e-05, 1.7806e-12, 1.7806e-12, 1.7806e-12],\n",
      "        [2.2765e-01, 2.9303e-01, 2.4544e-01, 1.7900e-01, 5.4531e-02, 2.0050e-04,\n",
      "         1.5858e-04, 2.9980e-11, 2.9980e-11, 2.9980e-11],\n",
      "        [2.3907e-01, 2.7353e-01, 2.3250e-01, 1.8100e-01, 7.2083e-02, 1.0276e-03,\n",
      "         7.8139e-04, 1.8324e-10, 1.8324e-10, 1.8324e-10],\n",
      "        [2.3284e-01, 2.5439e-01, 2.2452e-01, 1.8738e-01, 9.4705e-02, 3.5253e-03,\n",
      "         2.6353e-03, 5.4807e-10, 5.4807e-10, 5.4807e-10],\n",
      "        [2.2777e-01, 2.4638e-01, 2.2142e-01, 1.9006e-01, 1.0510e-01, 5.3766e-03,\n",
      "         3.8946e-03, 6.4906e-10, 6.4906e-10, 6.4906e-10],\n",
      "        [2.2289e-01, 2.4113e-01, 2.1991e-01, 1.9198e-01, 1.1250e-01, 6.6913e-03,\n",
      "         4.8929e-03, 5.8083e-10, 5.8083e-10, 5.8083e-10],\n",
      "        [2.1932e-01, 2.3820e-01, 2.1899e-01, 1.9294e-01, 1.1698e-01, 7.7668e-03,\n",
      "         5.8024e-03, 5.6547e-10, 5.6547e-10, 5.6547e-10],\n",
      "        [2.1844e-01, 2.3709e-01, 2.1846e-01, 1.9312e-01, 1.1856e-01, 8.1942e-03,\n",
      "         6.1356e-03, 5.9718e-10, 5.9718e-10, 5.9718e-10],\n",
      "        [2.1824e-01, 2.3678e-01, 2.1831e-01, 1.9315e-01, 1.1897e-01, 8.3152e-03,\n",
      "         6.2292e-03, 6.1413e-10, 6.1413e-10, 6.1413e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 出身 阿富汗 边远 <UNK> 地区 有着 与 他人 不同\n",
      "Reference: a total maverick from a remote province of afghanistan\n",
      "Model: <SOS> we of the the the , the the the\n",
      "Attention Weights: tensor([[1.2383e-01, 1.8481e-01, 1.7842e-01, 1.7831e-01, 4.5487e-02, 1.3603e-01,\n",
      "         9.7061e-02, 5.5594e-02, 4.4722e-04, 1.8618e-12],\n",
      "        [1.3617e-01, 1.9129e-01, 1.8165e-01, 1.7801e-01, 5.0244e-02, 1.2244e-01,\n",
      "         8.8278e-02, 5.1165e-02, 7.4651e-04, 2.5913e-11],\n",
      "        [1.4975e-01, 1.8360e-01, 1.7376e-01, 1.7417e-01, 6.7017e-02, 1.1253e-01,\n",
      "         8.4310e-02, 5.3083e-02, 1.7781e-03, 1.2166e-10],\n",
      "        [1.5011e-01, 1.7252e-01, 1.6480e-01, 1.6825e-01, 8.3616e-02, 1.1017e-01,\n",
      "         8.6715e-02, 5.9769e-02, 4.0555e-03, 3.4194e-10],\n",
      "        [1.4746e-01, 1.6741e-01, 1.6113e-01, 1.6585e-01, 8.9677e-02, 1.1025e-01,\n",
      "         8.9026e-02, 6.3766e-02, 5.4333e-03, 3.9054e-10],\n",
      "        [1.4447e-01, 1.6349e-01, 1.5835e-01, 1.6311e-01, 9.2884e-02, 1.1163e-01,\n",
      "         9.1869e-02, 6.7570e-02, 6.6358e-03, 4.3232e-10],\n",
      "        [1.4090e-01, 1.5967e-01, 1.5552e-01, 1.5910e-01, 9.3926e-02, 1.1414e-01,\n",
      "         9.5983e-02, 7.2633e-02, 8.1236e-03, 3.4756e-10],\n",
      "        [1.3899e-01, 1.5708e-01, 1.5332e-01, 1.5620e-01, 9.5183e-02, 1.1543e-01,\n",
      "         9.8319e-02, 7.5910e-02, 9.5716e-03, 3.6420e-10],\n",
      "        [1.3863e-01, 1.5638e-01, 1.5272e-01, 1.5547e-01, 9.5699e-02, 1.1563e-01,\n",
      "         9.8785e-02, 7.6679e-02, 1.0001e-02, 3.8453e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 95.00, Train Loss: 2.75, Val Loss: 11.96, Train BLEU: 13.88, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: <UNK> 塞尔 <UNK> <UNK> 斯特 说 过 真正 的 探索\n",
      "Reference: marcel proust said , &quot; the true voyage of\n",
      "Model: <SOS> marcel proust said , , , , true true\n",
      "Attention Weights: tensor([[4.0033e-07, 2.2823e-07, 1.1238e-06, 8.7735e-06, 9.6567e-04, 1.9762e-01,\n",
      "         2.5481e-01, 2.4837e-01, 1.9821e-01, 1.0001e-01],\n",
      "        [2.3672e-06, 1.4496e-06, 5.5140e-06, 3.2248e-05, 1.9587e-03, 2.2279e-01,\n",
      "         2.5813e-01, 2.4005e-01, 1.8661e-01, 9.0427e-02],\n",
      "        [4.4203e-05, 2.9642e-05, 9.2951e-05, 4.0588e-04, 9.1949e-03, 2.4064e-01,\n",
      "         2.4330e-01, 2.2424e-01, 1.8063e-01, 1.0142e-01],\n",
      "        [2.3838e-04, 1.6878e-04, 4.5050e-04, 1.5920e-03, 1.9604e-02, 2.3748e-01,\n",
      "         2.2988e-01, 2.1415e-01, 1.8031e-01, 1.1613e-01],\n",
      "        [4.6619e-04, 3.3282e-04, 8.4502e-04, 2.7534e-03, 2.6347e-02, 2.2900e-01,\n",
      "         2.2235e-01, 2.0992e-01, 1.8215e-01, 1.2583e-01],\n",
      "        [6.2377e-04, 4.4440e-04, 1.1066e-03, 3.4830e-03, 2.9794e-02, 2.2389e-01,\n",
      "         2.1879e-01, 2.0785e-01, 1.8321e-01, 1.3081e-01],\n",
      "        [7.3576e-04, 5.2743e-04, 1.2905e-03, 3.9599e-03, 3.1663e-02, 2.2122e-01,\n",
      "         2.1704e-01, 2.0686e-01, 1.8355e-01, 1.3317e-01],\n",
      "        [7.8333e-04, 5.6314e-04, 1.3664e-03, 4.1440e-03, 3.2320e-02, 2.2023e-01,\n",
      "         2.1644e-01, 2.0653e-01, 1.8366e-01, 1.3396e-01],\n",
      "        [8.1336e-04, 5.8598e-04, 1.4157e-03, 4.2610e-03, 3.2704e-02, 2.1957e-01,\n",
      "         2.1612e-01, 2.0635e-01, 1.8373e-01, 1.3445e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 面带 <UNK> <UNK> 笑容 这 很少 少见 因为 大部\n",
      "Reference: there was a big smile on his face which\n",
      "Model: <SOS> with vibrant the the , the the the the\n",
      "Attention Weights: tensor([[0.0249, 0.0017, 0.2384, 0.1585, 0.0122, 0.0020, 0.3166, 0.1910, 0.0546,\n",
      "         0.0001],\n",
      "        [0.0360, 0.0032, 0.2521, 0.1688, 0.0161, 0.0036, 0.2917, 0.1743, 0.0539,\n",
      "         0.0003],\n",
      "        [0.0575, 0.0099, 0.2503, 0.1717, 0.0305, 0.0106, 0.2504, 0.1560, 0.0621,\n",
      "         0.0011],\n",
      "        [0.0728, 0.0185, 0.2322, 0.1690, 0.0443, 0.0193, 0.2201, 0.1485, 0.0722,\n",
      "         0.0030],\n",
      "        [0.0799, 0.0243, 0.2175, 0.1655, 0.0528, 0.0252, 0.2050, 0.1463, 0.0788,\n",
      "         0.0046],\n",
      "        [0.0838, 0.0283, 0.2047, 0.1624, 0.0584, 0.0294, 0.1951, 0.1463, 0.0853,\n",
      "         0.0062],\n",
      "        [0.0852, 0.0302, 0.1989, 0.1608, 0.0608, 0.0316, 0.1907, 0.1462, 0.0885,\n",
      "         0.0071],\n",
      "        [0.0862, 0.0313, 0.1960, 0.1600, 0.0620, 0.0327, 0.1883, 0.1459, 0.0900,\n",
      "         0.0076],\n",
      "        [0.0866, 0.0318, 0.1950, 0.1597, 0.0625, 0.0332, 0.1873, 0.1456, 0.0905,\n",
      "         0.0078]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96.00, Train Loss: 2.73, Val Loss: 11.97, Train BLEU: 13.88, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 是 我 最 喜欢 的 因为 它 哪 都 能动\n",
      "Reference: it &apos;s one of my favorites , because it\n",
      "Model: <SOS> it &apos;s one to , , , , <EOS>\n",
      "Attention Weights: tensor([[0.0820, 0.1232, 0.1321, 0.1426, 0.1386, 0.1369, 0.1138, 0.0893, 0.0416,\n",
      "         0.0000],\n",
      "        [0.0898, 0.1272, 0.1339, 0.1427, 0.1369, 0.1344, 0.1100, 0.0851, 0.0400,\n",
      "         0.0001],\n",
      "        [0.1029, 0.1273, 0.1309, 0.1379, 0.1319, 0.1299, 0.1078, 0.0861, 0.0451,\n",
      "         0.0003],\n",
      "        [0.1102, 0.1251, 0.1268, 0.1324, 0.1271, 0.1259, 0.1076, 0.0898, 0.0540,\n",
      "         0.0011],\n",
      "        [0.1108, 0.1229, 0.1244, 0.1292, 0.1248, 0.1241, 0.1083, 0.0930, 0.0605,\n",
      "         0.0020],\n",
      "        [0.1100, 0.1214, 0.1230, 0.1274, 0.1237, 0.1231, 0.1091, 0.0953, 0.0644,\n",
      "         0.0025],\n",
      "        [0.1089, 0.1205, 0.1221, 0.1260, 0.1229, 0.1223, 0.1098, 0.0970, 0.0675,\n",
      "         0.0030],\n",
      "        [0.1086, 0.1198, 0.1213, 0.1249, 0.1222, 0.1216, 0.1101, 0.0981, 0.0700,\n",
      "         0.0035],\n",
      "        [0.1085, 0.1195, 0.1210, 0.1245, 0.1218, 0.1213, 0.1102, 0.0985, 0.0710,\n",
      "         0.0037]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 因此 毫无 毫无疑问 无疑 疑问 他 的 孩子 应当 受到\n",
      "Reference: there was no question that his children would receive\n",
      "Model: <SOS> and of the the , the the the the\n",
      "Attention Weights: tensor([[1.2622e-01, 1.9947e-01, 2.0693e-01, 1.7985e-01, 1.5776e-01, 2.6031e-02,\n",
      "         6.6284e-02, 3.7130e-02, 3.2723e-04, 2.1653e-12],\n",
      "        [1.3916e-01, 2.0004e-01, 2.0235e-01, 1.7565e-01, 1.5442e-01, 2.9782e-02,\n",
      "         6.1861e-02, 3.6068e-02, 6.6499e-04, 2.8841e-11],\n",
      "        [1.5511e-01, 1.9058e-01, 1.8934e-01, 1.6674e-01, 1.5175e-01, 4.2704e-02,\n",
      "         6.2377e-02, 3.9638e-02, 1.7592e-03, 1.3975e-10],\n",
      "        [1.5682e-01, 1.7866e-01, 1.7716e-01, 1.5958e-01, 1.4988e-01, 5.8024e-02,\n",
      "         6.8330e-02, 4.7387e-02, 4.1619e-03, 4.1761e-10],\n",
      "        [1.5288e-01, 1.7194e-01, 1.7135e-01, 1.5652e-01, 1.4933e-01, 6.5739e-02,\n",
      "         7.3299e-02, 5.3066e-02, 5.8743e-03, 5.0895e-10],\n",
      "        [1.4877e-01, 1.6583e-01, 1.6575e-01, 1.5362e-01, 1.4757e-01, 7.1429e-02,\n",
      "         7.9371e-02, 5.9832e-02, 7.8355e-03, 4.9113e-10],\n",
      "        [1.4508e-01, 1.6204e-01, 1.6209e-01, 1.5173e-01, 1.4581e-01, 7.4561e-02,\n",
      "         8.4062e-02, 6.5085e-02, 9.5415e-03, 4.4974e-10],\n",
      "        [1.4398e-01, 1.6038e-01, 1.6041e-01, 1.5070e-01, 1.4492e-01, 7.6168e-02,\n",
      "         8.5760e-02, 6.7194e-02, 1.0480e-02, 4.7564e-10],\n",
      "        [1.4377e-01, 1.5994e-01, 1.5996e-01, 1.5041e-01, 1.4470e-01, 7.6649e-02,\n",
      "         8.6144e-02, 6.7692e-02, 1.0731e-02, 4.9180e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 97.00, Train Loss: 2.70, Val Loss: 11.98, Train BLEU: 13.84, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 地球 的 大部 大部分 部分 都 是 海水 <EOS> <PAD>\n",
      "Reference: most of the planet is ocean water . <EOS>\n",
      "Model: <SOS> it &apos;s a to about . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.1542e-01, 1.6432e-01, 1.6625e-01, 1.7059e-01, 1.3782e-01, 1.1061e-01,\n",
      "         8.5464e-02, 4.9122e-02, 4.1168e-04, 1.8367e-12],\n",
      "        [1.2783e-01, 1.6874e-01, 1.6555e-01, 1.6584e-01, 1.3320e-01, 1.0702e-01,\n",
      "         8.2525e-02, 4.8507e-02, 8.0103e-04, 3.0609e-11],\n",
      "        [1.4240e-01, 1.6382e-01, 1.5843e-01, 1.5826e-01, 1.2888e-01, 1.0617e-01,\n",
      "         8.4974e-02, 5.4911e-02, 2.1540e-03, 1.5689e-10],\n",
      "        [1.4413e-01, 1.5620e-01, 1.5149e-01, 1.5218e-01, 1.2741e-01, 1.0845e-01,\n",
      "         9.0531e-02, 6.4414e-02, 5.1858e-03, 4.7581e-10],\n",
      "        [1.4181e-01, 1.5251e-01, 1.4868e-01, 1.4969e-01, 1.2718e-01, 1.0998e-01,\n",
      "         9.3565e-02, 6.9430e-02, 7.1347e-03, 5.7097e-10],\n",
      "        [1.3888e-01, 1.4905e-01, 1.4591e-01, 1.4694e-01, 1.2723e-01, 1.1193e-01,\n",
      "         9.6959e-02, 7.4229e-02, 8.8884e-03, 5.7117e-10],\n",
      "        [1.3573e-01, 1.4646e-01, 1.4365e-01, 1.4427e-01, 1.2724e-01, 1.1366e-01,\n",
      "         9.9962e-02, 7.8263e-02, 1.0766e-02, 4.8428e-10],\n",
      "        [1.3476e-01, 1.4514e-01, 1.4246e-01, 1.4296e-01, 1.2704e-01, 1.1422e-01,\n",
      "         1.0117e-01, 8.0247e-02, 1.2002e-02, 5.1244e-10],\n",
      "        [1.3462e-01, 1.4487e-01, 1.4222e-01, 1.4271e-01, 1.2698e-01, 1.1431e-01,\n",
      "         1.0138e-01, 8.0636e-02, 1.2275e-02, 5.3006e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 面带 <UNK> <UNK> 笑容 这 很少 少见 因为 大部\n",
      "Reference: there was a big smile on his face which\n",
      "Model: <SOS> with vibrant the the , the the the the\n",
      "Attention Weights: tensor([[0.0243, 0.0016, 0.2369, 0.1566, 0.0107, 0.0018, 0.3233, 0.1934, 0.0512,\n",
      "         0.0001],\n",
      "        [0.0359, 0.0033, 0.2518, 0.1668, 0.0149, 0.0037, 0.2965, 0.1756, 0.0511,\n",
      "         0.0003],\n",
      "        [0.0584, 0.0107, 0.2510, 0.1701, 0.0297, 0.0113, 0.2519, 0.1559, 0.0597,\n",
      "         0.0012],\n",
      "        [0.0735, 0.0198, 0.2336, 0.1672, 0.0434, 0.0205, 0.2214, 0.1478, 0.0696,\n",
      "         0.0032],\n",
      "        [0.0801, 0.0257, 0.2200, 0.1640, 0.0514, 0.0264, 0.2065, 0.1454, 0.0755,\n",
      "         0.0049],\n",
      "        [0.0843, 0.0301, 0.2072, 0.1612, 0.0571, 0.0309, 0.1959, 0.1449, 0.0820,\n",
      "         0.0065],\n",
      "        [0.0860, 0.0323, 0.2006, 0.1596, 0.0598, 0.0333, 0.1906, 0.1446, 0.0855,\n",
      "         0.0075],\n",
      "        [0.0871, 0.0336, 0.1972, 0.1587, 0.0613, 0.0347, 0.1878, 0.1442, 0.0872,\n",
      "         0.0082],\n",
      "        [0.0876, 0.0342, 0.1959, 0.1583, 0.0620, 0.0353, 0.1865, 0.1439, 0.0878,\n",
      "         0.0085]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 98.00, Train Loss: 2.68, Val Loss: 11.99, Train BLEU: 13.87, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本 基本上 都 没有 被 开发 发过 但是 像\n",
      "Reference: it &apos;s mostly unexplored , and yet there are\n",
      "Model: <SOS> we of the the , the the the the\n",
      "Attention Weights: tensor([[0.0695, 0.1079, 0.1258, 0.1179, 0.1262, 0.1173, 0.1184, 0.1035, 0.0828,\n",
      "         0.0307],\n",
      "        [0.0846, 0.1100, 0.1237, 0.1144, 0.1215, 0.1124, 0.1139, 0.1007, 0.0828,\n",
      "         0.0359],\n",
      "        [0.0969, 0.1091, 0.1189, 0.1101, 0.1159, 0.1081, 0.1099, 0.0996, 0.0861,\n",
      "         0.0454],\n",
      "        [0.1000, 0.1074, 0.1156, 0.1074, 0.1127, 0.1059, 0.1080, 0.0998, 0.0895,\n",
      "         0.0537],\n",
      "        [0.0998, 0.1063, 0.1140, 0.1063, 0.1114, 0.1052, 0.1076, 0.1002, 0.0914,\n",
      "         0.0578],\n",
      "        [0.0997, 0.1057, 0.1126, 0.1060, 0.1104, 0.1050, 0.1070, 0.1005, 0.0925,\n",
      "         0.0605],\n",
      "        [0.0994, 0.1054, 0.1119, 0.1058, 0.1100, 0.1050, 0.1068, 0.1006, 0.0930,\n",
      "         0.0621],\n",
      "        [0.0988, 0.1050, 0.1112, 0.1056, 0.1095, 0.1049, 0.1066, 0.1009, 0.0937,\n",
      "         0.0638],\n",
      "        [0.0985, 0.1048, 0.1109, 0.1055, 0.1093, 0.1048, 0.1066, 0.1010, 0.0940,\n",
      "         0.0647]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 在 塔利 塔利班 控制 阿富汗 的 那些 年 我 记得\n",
      "Reference: during taliban years , i remember there were times\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0777, 0.1193, 0.1243, 0.1300, 0.1327, 0.1387, 0.1216, 0.1100, 0.0457,\n",
      "         0.0000],\n",
      "        [0.0897, 0.1211, 0.1238, 0.1281, 0.1298, 0.1357, 0.1180, 0.1071, 0.0464,\n",
      "         0.0002],\n",
      "        [0.1022, 0.1197, 0.1202, 0.1234, 0.1246, 0.1303, 0.1154, 0.1080, 0.0553,\n",
      "         0.0008],\n",
      "        [0.1057, 0.1181, 0.1179, 0.1205, 0.1215, 0.1269, 0.1145, 0.1095, 0.0635,\n",
      "         0.0018],\n",
      "        [0.1064, 0.1170, 0.1168, 0.1192, 0.1202, 0.1254, 0.1143, 0.1105, 0.0677,\n",
      "         0.0024],\n",
      "        [0.1067, 0.1163, 0.1161, 0.1184, 0.1194, 0.1242, 0.1142, 0.1110, 0.0707,\n",
      "         0.0029],\n",
      "        [0.1069, 0.1160, 0.1158, 0.1180, 0.1189, 0.1231, 0.1141, 0.1109, 0.0729,\n",
      "         0.0034],\n",
      "        [0.1065, 0.1155, 0.1155, 0.1175, 0.1185, 0.1225, 0.1141, 0.1112, 0.0748,\n",
      "         0.0038],\n",
      "        [0.1063, 0.1152, 0.1152, 0.1172, 0.1182, 0.1221, 0.1141, 0.1114, 0.0763,\n",
      "         0.0041]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 99.00, Train Loss: 2.66, Val Loss: 12.01, Train BLEU: 13.88, Val BLEU: 0.32\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 通过 潜水 潜水艇 拍下 的 影片 把 我们\n",
      "Reference: with vibrant video clips captured by submarines , david\n",
      "Model: <SOS> with vibrant the the , , the the the\n",
      "Attention Weights: tensor([[0.0052, 0.0005, 0.1648, 0.1453, 0.0550, 0.1692, 0.1550, 0.1460, 0.1084,\n",
      "         0.0505],\n",
      "        [0.0131, 0.0025, 0.1785, 0.1510, 0.0744, 0.1567, 0.1419, 0.1321, 0.0996,\n",
      "         0.0502],\n",
      "        [0.0282, 0.0090, 0.1759, 0.1483, 0.0960, 0.1412, 0.1284, 0.1211, 0.0956,\n",
      "         0.0564],\n",
      "        [0.0419, 0.0179, 0.1657, 0.1421, 0.1071, 0.1307, 0.1203, 0.1152, 0.0952,\n",
      "         0.0638],\n",
      "        [0.0470, 0.0224, 0.1596, 0.1388, 0.1089, 0.1272, 0.1183, 0.1141, 0.0963,\n",
      "         0.0676],\n",
      "        [0.0503, 0.0248, 0.1549, 0.1360, 0.1085, 0.1255, 0.1176, 0.1140, 0.0979,\n",
      "         0.0705],\n",
      "        [0.0534, 0.0273, 0.1507, 0.1335, 0.1078, 0.1242, 0.1170, 0.1138, 0.0991,\n",
      "         0.0732],\n",
      "        [0.0548, 0.0288, 0.1486, 0.1322, 0.1076, 0.1233, 0.1165, 0.1136, 0.0998,\n",
      "         0.0748],\n",
      "        [0.0557, 0.0296, 0.1474, 0.1313, 0.1075, 0.1229, 0.1163, 0.1134, 0.1001,\n",
      "         0.0758]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 那 就是 她 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: there she is . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a to . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.2053e-01, 1.6919e-01, 1.6243e-01, 1.5160e-01, 1.3869e-01, 1.1869e-01,\n",
      "         8.9060e-02, 4.9333e-02, 4.6979e-04, 2.1815e-12],\n",
      "        [1.3459e-01, 1.7156e-01, 1.6112e-01, 1.4847e-01, 1.3407e-01, 1.1397e-01,\n",
      "         8.5883e-02, 4.9356e-02, 9.8297e-04, 3.9881e-11],\n",
      "        [1.4931e-01, 1.6511e-01, 1.5335e-01, 1.4195e-01, 1.2965e-01, 1.1282e-01,\n",
      "         8.8708e-02, 5.6347e-02, 2.7471e-03, 2.0749e-10],\n",
      "        [1.4976e-01, 1.5648e-01, 1.4663e-01, 1.3760e-01, 1.2799e-01, 1.1463e-01,\n",
      "         9.4417e-02, 6.5860e-02, 6.6263e-03, 6.6645e-10],\n",
      "        [1.4687e-01, 1.5279e-01, 1.4431e-01, 1.3634e-01, 1.2777e-01, 1.1571e-01,\n",
      "         9.7099e-02, 7.0274e-02, 8.8365e-03, 8.0635e-10],\n",
      "        [1.4399e-01, 1.4960e-01, 1.4222e-01, 1.3524e-01, 1.2759e-01, 1.1669e-01,\n",
      "         9.9738e-02, 7.4353e-02, 1.0586e-02, 8.2899e-10],\n",
      "        [1.4027e-01, 1.4652e-01, 1.4024e-01, 1.3421e-01, 1.2741e-01, 1.1754e-01,\n",
      "         1.0246e-01, 7.8744e-02, 1.2602e-02, 6.5249e-10],\n",
      "        [1.3874e-01, 1.4489e-01, 1.3907e-01, 1.3345e-01, 1.2708e-01, 1.1779e-01,\n",
      "         1.0369e-01, 8.1122e-02, 1.4162e-02, 6.8743e-10],\n",
      "        [1.3847e-01, 1.4455e-01, 1.3883e-01, 1.3329e-01, 1.2701e-01, 1.1783e-01,\n",
      "         1.0392e-01, 8.1591e-02, 1.4513e-02, 7.1502e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100.00, Train Loss: 2.63, Val Loss: 12.02, Train BLEU: 14.04, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 原来 它 是 海洋 洋中 最长 的 生物 <EOS> <PAD>\n",
      "Reference: this turns out to be the longest creature in\n",
      "Model: <SOS> it &apos;s a to about . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.3990e-01, 2.0174e-01, 1.8730e-01, 1.7837e-01, 3.0431e-02, 1.2862e-01,\n",
      "         8.5545e-02, 4.7682e-02, 4.1929e-04, 2.5043e-12],\n",
      "        [1.5692e-01, 2.0531e-01, 1.8713e-01, 1.7629e-01, 3.8932e-02, 1.1362e-01,\n",
      "         7.6886e-02, 4.4077e-02, 8.3468e-04, 3.6580e-11],\n",
      "        [1.7153e-01, 1.9225e-01, 1.7522e-01, 1.7132e-01, 6.1266e-02, 1.0456e-01,\n",
      "         7.4336e-02, 4.7225e-02, 2.2960e-03, 1.8776e-10],\n",
      "        [1.6821e-01, 1.7743e-01, 1.6481e-01, 1.6741e-01, 8.2842e-02, 1.0276e-01,\n",
      "         7.7255e-02, 5.4052e-02, 5.2316e-03, 6.0303e-10],\n",
      "        [1.6395e-01, 1.7188e-01, 1.6142e-01, 1.6591e-01, 8.9998e-02, 1.0278e-01,\n",
      "         7.9513e-02, 5.7727e-02, 6.8238e-03, 7.2021e-10],\n",
      "        [1.5990e-01, 1.6722e-01, 1.5823e-01, 1.6286e-01, 9.4352e-02, 1.0473e-01,\n",
      "         8.2781e-02, 6.1660e-02, 8.2619e-03, 8.1572e-10],\n",
      "        [1.5499e-01, 1.6260e-01, 1.5494e-01, 1.5820e-01, 9.5977e-02, 1.0814e-01,\n",
      "         8.7839e-02, 6.7263e-02, 1.0049e-02, 6.2081e-10],\n",
      "        [1.5163e-01, 1.5913e-01, 1.5222e-01, 1.5465e-01, 9.7635e-02, 1.1030e-01,\n",
      "         9.1131e-02, 7.1305e-02, 1.2002e-02, 6.3801e-10],\n",
      "        [1.5096e-01, 1.5833e-01, 1.5161e-01, 1.5394e-01, 9.8184e-02, 1.1063e-01,\n",
      "         9.1713e-02, 7.2135e-02, 1.2503e-02, 6.7132e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 那 就是 她 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: there she is . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a to about <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.2181e-01, 1.7039e-01, 1.6285e-01, 1.5174e-01, 1.3842e-01, 1.1809e-01,\n",
      "         8.8128e-02, 4.8118e-02, 4.5203e-04, 2.2504e-12],\n",
      "        [1.3672e-01, 1.7310e-01, 1.6168e-01, 1.4854e-01, 1.3360e-01, 1.1304e-01,\n",
      "         8.4551e-02, 4.7836e-02, 9.3900e-04, 4.0136e-11],\n",
      "        [1.5221e-01, 1.6681e-01, 1.5388e-01, 1.4190e-01, 1.2903e-01, 1.1173e-01,\n",
      "         8.7194e-02, 5.4615e-02, 2.6294e-03, 2.0477e-10],\n",
      "        [1.5278e-01, 1.5816e-01, 1.4725e-01, 1.3768e-01, 1.2753e-01, 1.1365e-01,\n",
      "         9.2852e-02, 6.3834e-02, 6.2643e-03, 6.6596e-10],\n",
      "        [1.4989e-01, 1.5451e-01, 1.4501e-01, 1.3652e-01, 1.2741e-01, 1.1479e-01,\n",
      "         9.5492e-02, 6.8077e-02, 8.3092e-03, 8.0587e-10],\n",
      "        [1.4719e-01, 1.5158e-01, 1.4316e-01, 1.3557e-01, 1.2731e-01, 1.1575e-01,\n",
      "         9.7884e-02, 7.1681e-02, 9.8815e-03, 8.7566e-10],\n",
      "        [1.4337e-01, 1.4833e-01, 1.4114e-01, 1.3459e-01, 1.2726e-01, 1.1677e-01,\n",
      "         1.0076e-01, 7.6085e-02, 1.1685e-02, 6.7182e-10],\n",
      "        [1.4117e-01, 1.4616e-01, 1.3963e-01, 1.3366e-01, 1.2691e-01, 1.1717e-01,\n",
      "         1.0249e-01, 7.9227e-02, 1.3594e-02, 6.9194e-10],\n",
      "        [1.4071e-01, 1.4563e-01, 1.3925e-01, 1.3342e-01, 1.2680e-01, 1.1725e-01,\n",
      "         1.0286e-01, 7.9961e-02, 1.4109e-02, 7.2839e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 101.00, Train Loss: 2.61, Val Loss: 12.04, Train BLEU: 14.03, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 原来 它 是 海洋 洋中 最长 的 生物 <EOS> <PAD>\n",
      "Reference: this turns out to be the longest creature in\n",
      "Model: <SOS> it &apos;s a to about . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.4167e-01, 2.0298e-01, 1.8754e-01, 1.8055e-01, 2.8858e-02, 1.2713e-01,\n",
      "         8.3669e-02, 4.7181e-02, 4.2266e-04, 2.6242e-12],\n",
      "        [1.5944e-01, 2.0582e-01, 1.8675e-01, 1.7775e-01, 3.8143e-02, 1.1218e-01,\n",
      "         7.5316e-02, 4.3730e-02, 8.7599e-04, 3.9483e-11],\n",
      "        [1.7372e-01, 1.9164e-01, 1.7406e-01, 1.7214e-01, 6.1880e-02, 1.0353e-01,\n",
      "         7.3258e-02, 4.7278e-02, 2.4986e-03, 2.0836e-10],\n",
      "        [1.6964e-01, 1.7620e-01, 1.6339e-01, 1.6811e-01, 8.4625e-02, 1.0181e-01,\n",
      "         7.6274e-02, 5.4237e-02, 5.7200e-03, 6.9658e-10],\n",
      "        [1.6511e-01, 1.7055e-01, 1.5998e-01, 1.6658e-01, 9.2049e-02, 1.0179e-01,\n",
      "         7.8532e-02, 5.7964e-02, 7.4463e-03, 8.3806e-10],\n",
      "        [1.6083e-01, 1.6571e-01, 1.5664e-01, 1.6311e-01, 9.6591e-02, 1.0395e-01,\n",
      "         8.2024e-02, 6.2098e-02, 9.0437e-03, 9.5112e-10],\n",
      "        [1.5568e-01, 1.6107e-01, 1.5331e-01, 1.5806e-01, 9.8148e-02, 1.0760e-01,\n",
      "         8.7301e-02, 6.7819e-02, 1.1009e-02, 7.1684e-10],\n",
      "        [1.5235e-01, 1.5776e-01, 1.5073e-01, 1.5455e-01, 9.9749e-02, 1.0972e-01,\n",
      "         9.0484e-02, 7.1660e-02, 1.2994e-02, 7.4722e-10],\n",
      "        [1.5174e-01, 1.5706e-01, 1.5021e-01, 1.5391e-01, 1.0023e-01, 1.1001e-01,\n",
      "         9.1003e-02, 7.2379e-02, 1.3456e-02, 7.8300e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 父亲 那 就是 他 他 是 他家 家族\n",
      "Reference: and my father -- that &apos;s him -- he\n",
      "Model: <SOS> and of the the , , the the the\n",
      "Attention Weights: tensor([[0.1227, 0.1741, 0.1257, 0.0512, 0.0013, 0.2262, 0.0365, 0.2035, 0.0589,\n",
      "         0.0000],\n",
      "        [0.1366, 0.1792, 0.1312, 0.0596, 0.0026, 0.2206, 0.0439, 0.1754, 0.0509,\n",
      "         0.0001],\n",
      "        [0.1509, 0.1693, 0.1298, 0.0724, 0.0079, 0.2057, 0.0647, 0.1487, 0.0502,\n",
      "         0.0003],\n",
      "        [0.1505, 0.1570, 0.1291, 0.0849, 0.0181, 0.1875, 0.0854, 0.1322, 0.0544,\n",
      "         0.0010],\n",
      "        [0.1462, 0.1519, 0.1286, 0.0899, 0.0243, 0.1773, 0.0931, 0.1280, 0.0590,\n",
      "         0.0018],\n",
      "        [0.1434, 0.1480, 0.1274, 0.0922, 0.0284, 0.1711, 0.0975, 0.1267, 0.0627,\n",
      "         0.0024],\n",
      "        [0.1408, 0.1454, 0.1267, 0.0940, 0.0306, 0.1670, 0.0993, 0.1271, 0.0663,\n",
      "         0.0029],\n",
      "        [0.1385, 0.1436, 0.1264, 0.0955, 0.0326, 0.1638, 0.1001, 0.1270, 0.0692,\n",
      "         0.0032],\n",
      "        [0.1372, 0.1423, 0.1262, 0.0967, 0.0344, 0.1618, 0.1006, 0.1265, 0.0708,\n",
      "         0.0036]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 102.00, Train Loss: 2.58, Val Loss: 12.06, Train BLEU: 14.04, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的 平均 深度 是 两英里 英里 <EOS> <PAD> <PAD>\n",
      "Reference: the average depth is about two miles . <EOS>\n",
      "Model: <SOS> it &apos;s the to about . . <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.7153e-01, 2.2539e-01, 2.1859e-01, 2.0432e-01, 1.3637e-01, 1.4482e-02,\n",
      "         2.9085e-02, 2.2581e-04, 3.2512e-12, 3.2512e-12],\n",
      "        [1.9063e-01, 2.2462e-01, 2.1016e-01, 1.9199e-01, 1.3117e-01, 1.9395e-02,\n",
      "         3.1367e-02, 6.7339e-04, 5.9381e-11, 5.9381e-11],\n",
      "        [2.0519e-01, 2.1064e-01, 1.9506e-01, 1.8008e-01, 1.3183e-01, 3.3776e-02,\n",
      "         4.1147e-02, 2.2770e-03, 3.0546e-10, 3.0546e-10],\n",
      "        [2.0115e-01, 1.9679e-01, 1.8495e-01, 1.7418e-01, 1.3497e-01, 5.0345e-02,\n",
      "         5.1966e-02, 5.6535e-03, 1.0148e-09, 1.0148e-09],\n",
      "        [1.9595e-01, 1.9172e-01, 1.8181e-01, 1.7258e-01, 1.3685e-01, 5.7126e-02,\n",
      "         5.6508e-02, 7.4563e-03, 1.2311e-09, 1.2311e-09],\n",
      "        [1.9184e-01, 1.8789e-01, 1.7907e-01, 1.7083e-01, 1.3820e-01, 6.2226e-02,\n",
      "         6.0905e-02, 9.0321e-03, 1.4155e-09, 1.4155e-09],\n",
      "        [1.8591e-01, 1.8380e-01, 1.7600e-01, 1.6876e-01, 1.4016e-01, 6.7403e-02,\n",
      "         6.7150e-02, 1.0817e-02, 1.0449e-09, 1.0449e-09],\n",
      "        [1.8196e-01, 1.8044e-01, 1.7324e-01, 1.6659e-01, 1.4082e-01, 7.2096e-02,\n",
      "         7.2029e-02, 1.2822e-02, 1.0635e-09, 1.0635e-09],\n",
      "        [1.8117e-01, 1.7967e-01, 1.7262e-01, 1.6607e-01, 1.4088e-01, 7.3187e-02,\n",
      "         7.3080e-02, 1.3324e-02, 1.1159e-09, 1.1159e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 总是 担心 会 被 塔利 塔利班 发现 <EOS> <PAD>\n",
      "Reference: we always wondered what they knew about us .\n",
      "Model: <SOS> it &apos;s got to about about . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0738, 0.0981, 0.1659, 0.1649, 0.1508, 0.1410, 0.0947, 0.0037, 0.0767,\n",
      "         0.0304],\n",
      "        [0.0942, 0.1124, 0.1471, 0.1447, 0.1353, 0.1318, 0.1027, 0.0163, 0.0786,\n",
      "         0.0369],\n",
      "        [0.1039, 0.1179, 0.1331, 0.1306, 0.1243, 0.1245, 0.1064, 0.0335, 0.0817,\n",
      "         0.0440],\n",
      "        [0.1057, 0.1183, 0.1239, 0.1223, 0.1180, 0.1206, 0.1092, 0.0470, 0.0842,\n",
      "         0.0507],\n",
      "        [0.1054, 0.1174, 0.1209, 0.1198, 0.1162, 0.1194, 0.1101, 0.0519, 0.0852,\n",
      "         0.0537],\n",
      "        [0.1055, 0.1164, 0.1194, 0.1184, 0.1153, 0.1186, 0.1104, 0.0543, 0.0861,\n",
      "         0.0556],\n",
      "        [0.1049, 0.1151, 0.1181, 0.1173, 0.1148, 0.1178, 0.1103, 0.0561, 0.0874,\n",
      "         0.0581],\n",
      "        [0.1046, 0.1144, 0.1173, 0.1165, 0.1143, 0.1171, 0.1102, 0.0570, 0.0884,\n",
      "         0.0601],\n",
      "        [0.1042, 0.1140, 0.1169, 0.1162, 0.1141, 0.1169, 0.1102, 0.0575, 0.0888,\n",
      "         0.0611]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 103.00, Train Loss: 2.56, Val Loss: 12.07, Train BLEU: 14.91, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数 多数 地震 和 火山 喷发 也 都 发生\n",
      "Reference: most of the earthquakes and volcanoes are in the\n",
      "Model: <SOS> most of the the the the the the the\n",
      "Attention Weights: tensor([[0.0380, 0.0121, 0.1443, 0.1431, 0.1325, 0.1535, 0.1434, 0.1076, 0.0838,\n",
      "         0.0419],\n",
      "        [0.0642, 0.0336, 0.1409, 0.1340, 0.1246, 0.1401, 0.1314, 0.1018, 0.0819,\n",
      "         0.0475],\n",
      "        [0.0880, 0.0627, 0.1317, 0.1218, 0.1139, 0.1262, 0.1198, 0.0969, 0.0824,\n",
      "         0.0566],\n",
      "        [0.0957, 0.0770, 0.1248, 0.1153, 0.1086, 0.1197, 0.1151, 0.0958, 0.0842,\n",
      "         0.0639],\n",
      "        [0.0970, 0.0809, 0.1211, 0.1128, 0.1069, 0.1176, 0.1136, 0.0960, 0.0859,\n",
      "         0.0682],\n",
      "        [0.0973, 0.0824, 0.1190, 0.1114, 0.1062, 0.1159, 0.1125, 0.0968, 0.0876,\n",
      "         0.0709],\n",
      "        [0.0972, 0.0833, 0.1177, 0.1106, 0.1058, 0.1148, 0.1117, 0.0974, 0.0889,\n",
      "         0.0727],\n",
      "        [0.0967, 0.0833, 0.1168, 0.1100, 0.1056, 0.1143, 0.1114, 0.0978, 0.0897,\n",
      "         0.0743],\n",
      "        [0.0964, 0.0833, 0.1163, 0.1098, 0.1055, 0.1140, 0.1113, 0.0980, 0.0902,\n",
      "         0.0752]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很 舒服 但 夏天 却 <UNK> <EOS> <PAD> <PAD>\n",
      "Reference: it was cozy in winter but extremely hot in\n",
      "Model: <SOS> life in the about . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0783, 0.1122, 0.1308, 0.1251, 0.1377, 0.0847, 0.1146, 0.1077, 0.0755,\n",
      "         0.0335],\n",
      "        [0.0968, 0.1125, 0.1242, 0.1180, 0.1287, 0.1024, 0.1050, 0.0985, 0.0740,\n",
      "         0.0399],\n",
      "        [0.1069, 0.1097, 0.1174, 0.1115, 0.1210, 0.1122, 0.1002, 0.0955, 0.0767,\n",
      "         0.0490],\n",
      "        [0.1082, 0.1070, 0.1133, 0.1082, 0.1169, 0.1141, 0.0992, 0.0962, 0.0804,\n",
      "         0.0565],\n",
      "        [0.1074, 0.1057, 0.1118, 0.1070, 0.1154, 0.1144, 0.0990, 0.0969, 0.0823,\n",
      "         0.0602],\n",
      "        [0.1072, 0.1049, 0.1105, 0.1062, 0.1140, 0.1141, 0.0992, 0.0976, 0.0839,\n",
      "         0.0624],\n",
      "        [0.1063, 0.1042, 0.1094, 0.1056, 0.1127, 0.1134, 0.0997, 0.0982, 0.0855,\n",
      "         0.0649],\n",
      "        [0.1056, 0.1038, 0.1089, 0.1052, 0.1122, 0.1131, 0.0998, 0.0985, 0.0864,\n",
      "         0.0664],\n",
      "        [0.1050, 0.1036, 0.1086, 0.1050, 0.1119, 0.1128, 0.1000, 0.0988, 0.0870,\n",
      "         0.0673]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 104.00, Train Loss: 2.54, Val Loss: 12.09, Train BLEU: 15.84, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克 泰坦尼克号 坦尼 尼克 号 是 拿 了 不少\n",
      "Reference: the truth of the matter is that the titanic\n",
      "Model: <SOS> the of the the the the the the the\n",
      "Attention Weights: tensor([[0.0270, 0.0066, 0.0132, 0.0305, 0.2137, 0.1877, 0.1728, 0.1563, 0.1268,\n",
      "         0.0653],\n",
      "        [0.0547, 0.0250, 0.0396, 0.0728, 0.1888, 0.1623, 0.1477, 0.1336, 0.1103,\n",
      "         0.0653],\n",
      "        [0.0785, 0.0493, 0.0686, 0.1078, 0.1576, 0.1344, 0.1234, 0.1137, 0.0984,\n",
      "         0.0683],\n",
      "        [0.0862, 0.0629, 0.0823, 0.1185, 0.1415, 0.1221, 0.1134, 0.1061, 0.0947,\n",
      "         0.0724],\n",
      "        [0.0877, 0.0674, 0.0859, 0.1185, 0.1356, 0.1186, 0.1110, 0.1048, 0.0949,\n",
      "         0.0755],\n",
      "        [0.0880, 0.0696, 0.0870, 0.1173, 0.1323, 0.1168, 0.1102, 0.1048, 0.0960,\n",
      "         0.0781],\n",
      "        [0.0881, 0.0711, 0.0876, 0.1156, 0.1296, 0.1157, 0.1098, 0.1050, 0.0972,\n",
      "         0.0804],\n",
      "        [0.0881, 0.0716, 0.0875, 0.1145, 0.1285, 0.1153, 0.1097, 0.1053, 0.0978,\n",
      "         0.0818],\n",
      "        [0.0880, 0.0717, 0.0873, 0.1140, 0.1280, 0.1152, 0.1097, 0.1054, 0.0982,\n",
      "         0.0825]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 有时 学校 <UNK> 突然 <UNK> 一周 因为 被 塔利 塔利班\n",
      "Reference: from time to time , the school would suddenly\n",
      "Model: <SOS> it &apos;s the , , , , , ,\n",
      "Attention Weights: tensor([[0.0808, 0.1108, 0.1149, 0.1255, 0.1201, 0.1230, 0.1143, 0.0984, 0.0770,\n",
      "         0.0352],\n",
      "        [0.0991, 0.1132, 0.1136, 0.1204, 0.1145, 0.1157, 0.1084, 0.0954, 0.0776,\n",
      "         0.0421],\n",
      "        [0.1105, 0.1114, 0.1095, 0.1143, 0.1090, 0.1100, 0.1047, 0.0951, 0.0819,\n",
      "         0.0534],\n",
      "        [0.1114, 0.1087, 0.1068, 0.1110, 0.1065, 0.1077, 0.1037, 0.0961, 0.0858,\n",
      "         0.0623],\n",
      "        [0.1103, 0.1074, 0.1058, 0.1099, 0.1057, 0.1070, 0.1035, 0.0967, 0.0875,\n",
      "         0.0662],\n",
      "        [0.1100, 0.1067, 0.1052, 0.1091, 0.1053, 0.1067, 0.1035, 0.0971, 0.0885,\n",
      "         0.0679],\n",
      "        [0.1092, 0.1063, 0.1050, 0.1088, 0.1052, 0.1066, 0.1036, 0.0974, 0.0891,\n",
      "         0.0688],\n",
      "        [0.1089, 0.1059, 0.1047, 0.1083, 0.1050, 0.1063, 0.1035, 0.0977, 0.0897,\n",
      "         0.0701],\n",
      "        [0.1081, 0.1055, 0.1043, 0.1078, 0.1047, 0.1061, 0.1035, 0.0980, 0.0904,\n",
      "         0.0714]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 105.00, Train Loss: 2.51, Val Loss: 12.10, Train BLEU: 16.62, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这 有 不少 精彩 的 泰坦 泰坦尼克 坦尼 尼克\n",
      "Reference: we &apos;ve got some of the most incredible video\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.1083, 0.1510, 0.1530, 0.1739, 0.1619, 0.1193, 0.0899, 0.0063, 0.0099,\n",
      "         0.0264],\n",
      "        [0.1215, 0.1367, 0.1349, 0.1499, 0.1442, 0.1167, 0.1026, 0.0245, 0.0318,\n",
      "         0.0372],\n",
      "        [0.1240, 0.1253, 0.1221, 0.1342, 0.1316, 0.1129, 0.1069, 0.0434, 0.0531,\n",
      "         0.0464],\n",
      "        [0.1206, 0.1178, 0.1150, 0.1257, 0.1247, 0.1102, 0.1089, 0.0569, 0.0659,\n",
      "         0.0542],\n",
      "        [0.1180, 0.1149, 0.1125, 0.1224, 0.1219, 0.1093, 0.1094, 0.0626, 0.0707,\n",
      "         0.0582],\n",
      "        [0.1176, 0.1142, 0.1119, 0.1216, 0.1212, 0.1090, 0.1095, 0.0639, 0.0719,\n",
      "         0.0592],\n",
      "        [0.1170, 0.1134, 0.1113, 0.1205, 0.1201, 0.1089, 0.1093, 0.0655, 0.0730,\n",
      "         0.0610],\n",
      "        [0.1161, 0.1127, 0.1108, 0.1194, 0.1192, 0.1087, 0.1091, 0.0668, 0.0744,\n",
      "         0.0629],\n",
      "        [0.1153, 0.1122, 0.1105, 0.1188, 0.1187, 0.1087, 0.1092, 0.0675, 0.0749,\n",
      "         0.0641]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6 岁 那年 塔利 塔利班 占领 阿富汗 并 规定\n",
      "Reference: you see , i was six when the taliban\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[1.2363e-01, 1.6463e-01, 1.6556e-01, 1.8524e-01, 1.3604e-01, 1.0150e-01,\n",
      "         7.6624e-02, 4.6330e-02, 4.3072e-04, 2.6536e-12],\n",
      "        [1.4234e-01, 1.6815e-01, 1.6324e-01, 1.7652e-01, 1.2970e-01, 9.7832e-02,\n",
      "         7.4307e-02, 4.6849e-02, 1.0677e-03, 5.1175e-11],\n",
      "        [1.5933e-01, 1.6226e-01, 1.5436e-01, 1.6429e-01, 1.2456e-01, 9.8062e-02,\n",
      "         7.8415e-02, 5.5278e-02, 3.4500e-03, 2.9411e-10],\n",
      "        [1.5848e-01, 1.5314e-01, 1.4746e-01, 1.5761e-01, 1.2363e-01, 1.0107e-01,\n",
      "         8.4480e-02, 6.5843e-02, 8.2829e-03, 1.1054e-09],\n",
      "        [1.5483e-01, 1.4936e-01, 1.4525e-01, 1.5529e-01, 1.2355e-01, 1.0262e-01,\n",
      "         8.7297e-02, 7.0749e-02, 1.1052e-02, 1.4280e-09],\n",
      "        [1.5165e-01, 1.4642e-01, 1.4278e-01, 1.5199e-01, 1.2354e-01, 1.0465e-01,\n",
      "         9.0518e-02, 7.5304e-02, 1.3146e-02, 1.3466e-09],\n",
      "        [1.4756e-01, 1.4401e-01, 1.4040e-01, 1.4826e-01, 1.2362e-01, 1.0698e-01,\n",
      "         9.4004e-02, 7.9532e-02, 1.5630e-02, 1.1619e-09],\n",
      "        [1.4632e-01, 1.4302e-01, 1.3952e-01, 1.4693e-01, 1.2354e-01, 1.0763e-01,\n",
      "         9.5111e-02, 8.1094e-02, 1.6844e-02, 1.2454e-09],\n",
      "        [1.4613e-01, 1.4287e-01, 1.3939e-01, 1.4672e-01, 1.2352e-01, 1.0773e-01,\n",
      "         9.5272e-02, 8.1333e-02, 1.7050e-02, 1.2752e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 106.00, Train Loss: 2.49, Val Loss: 12.11, Train BLEU: 16.77, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 但 我 想 告诉 你 的 是 当 你 站\n",
      "Reference: but when you &apos;re standing at the beach ,\n",
      "Model: <SOS> most of the the , , the the the\n",
      "Attention Weights: tensor([[0.0822, 0.1131, 0.1164, 0.1250, 0.1201, 0.1219, 0.1132, 0.0977, 0.0761,\n",
      "         0.0344],\n",
      "        [0.1010, 0.1150, 0.1146, 0.1199, 0.1144, 0.1147, 0.1074, 0.0947, 0.0769,\n",
      "         0.0414],\n",
      "        [0.1132, 0.1132, 0.1104, 0.1136, 0.1087, 0.1089, 0.1037, 0.0944, 0.0812,\n",
      "         0.0526],\n",
      "        [0.1139, 0.1101, 0.1075, 0.1104, 0.1062, 0.1068, 0.1027, 0.0954, 0.0852,\n",
      "         0.0618],\n",
      "        [0.1127, 0.1087, 0.1064, 0.1093, 0.1054, 0.1061, 0.1026, 0.0961, 0.0870,\n",
      "         0.0657],\n",
      "        [0.1125, 0.1080, 0.1059, 0.1088, 0.1051, 0.1059, 0.1026, 0.0964, 0.0877,\n",
      "         0.0672],\n",
      "        [0.1116, 0.1075, 0.1056, 0.1085, 0.1050, 0.1059, 0.1028, 0.0967, 0.0883,\n",
      "         0.0680],\n",
      "        [0.1112, 0.1070, 0.1053, 0.1080, 0.1048, 0.1057, 0.1027, 0.0970, 0.0890,\n",
      "         0.0694],\n",
      "        [0.1104, 0.1065, 0.1049, 0.1076, 0.1046, 0.1055, 0.1027, 0.0973, 0.0897,\n",
      "         0.0708]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在 可以 去 个 真正 的 学校 念书 了\n",
      "Reference: &quot; you can go to a real school now\n",
      "Model: <SOS> we of the the the , the the the\n",
      "Attention Weights: tensor([[0.0254, 0.0061, 0.0122, 0.0286, 0.2138, 0.1934, 0.1746, 0.1555, 0.1248,\n",
      "         0.0655],\n",
      "        [0.0524, 0.0245, 0.0388, 0.0722, 0.1902, 0.1668, 0.1491, 0.1328, 0.1084,\n",
      "         0.0648],\n",
      "        [0.0770, 0.0501, 0.0701, 0.1109, 0.1585, 0.1363, 0.1228, 0.1117, 0.0956,\n",
      "         0.0670],\n",
      "        [0.0851, 0.0642, 0.0843, 0.1222, 0.1418, 0.1231, 0.1125, 0.1040, 0.0920,\n",
      "         0.0709],\n",
      "        [0.0866, 0.0691, 0.0883, 0.1224, 0.1357, 0.1192, 0.1100, 0.1026, 0.0922,\n",
      "         0.0740],\n",
      "        [0.0868, 0.0712, 0.0895, 0.1214, 0.1325, 0.1173, 0.1091, 0.1025, 0.0931,\n",
      "         0.0764],\n",
      "        [0.0870, 0.0728, 0.0901, 0.1196, 0.1296, 0.1160, 0.1086, 0.1029, 0.0945,\n",
      "         0.0790],\n",
      "        [0.0870, 0.0733, 0.0899, 0.1182, 0.1285, 0.1156, 0.1086, 0.1032, 0.0952,\n",
      "         0.0806],\n",
      "        [0.0869, 0.0734, 0.0897, 0.1175, 0.1280, 0.1155, 0.1086, 0.1034, 0.0957,\n",
      "         0.0813]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 107.00, Train Loss: 2.46, Val Loss: 12.12, Train BLEU: 18.45, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 这位 是 比尔 <UNK> 我 是 大卫 <UNK>\n",
      "Reference: this is bill lange . i &apos;m dave gallo\n",
      "Model: <SOS> this is bill lange , , . . .\n",
      "Attention Weights: tensor([[0.0291, 0.0023, 0.2015, 0.1610, 0.0102, 0.0025, 0.3287, 0.2146, 0.0499,\n",
      "         0.0001],\n",
      "        [0.0451, 0.0061, 0.2220, 0.1697, 0.0175, 0.0066, 0.2935, 0.1871, 0.0517,\n",
      "         0.0005],\n",
      "        [0.0724, 0.0206, 0.2226, 0.1657, 0.0381, 0.0216, 0.2392, 0.1564, 0.0607,\n",
      "         0.0027],\n",
      "        [0.0867, 0.0351, 0.2048, 0.1567, 0.0547, 0.0364, 0.2061, 0.1434, 0.0694,\n",
      "         0.0067],\n",
      "        [0.0906, 0.0431, 0.1943, 0.1517, 0.0625, 0.0444, 0.1924, 0.1385, 0.0731,\n",
      "         0.0094],\n",
      "        [0.0932, 0.0486, 0.1847, 0.1484, 0.0677, 0.0499, 0.1813, 0.1363, 0.0780,\n",
      "         0.0120],\n",
      "        [0.0945, 0.0511, 0.1793, 0.1466, 0.0702, 0.0526, 0.1756, 0.1352, 0.0812,\n",
      "         0.0137],\n",
      "        [0.0953, 0.0525, 0.1766, 0.1456, 0.0715, 0.0541, 0.1728, 0.1344, 0.0826,\n",
      "         0.0147],\n",
      "        [0.0956, 0.0533, 0.1755, 0.1451, 0.0722, 0.0549, 0.1714, 0.1339, 0.0831,\n",
      "         0.0151]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 永远 不会 忘记 那个 早晨 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: a morning that i will never forget . <EOS>\n",
      "Model: <SOS> it &apos;s a to about . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[9.1329e-02, 1.3532e-01, 1.4231e-01, 1.7182e-01, 1.4116e-01, 1.3540e-01,\n",
      "         1.4372e-01, 3.8858e-02, 9.5368e-05, 4.8589e-06],\n",
      "        [1.1209e-01, 1.3740e-01, 1.4025e-01, 1.6678e-01, 1.3532e-01, 1.2869e-01,\n",
      "         1.3635e-01, 4.2487e-02, 5.6371e-04, 8.0534e-05],\n",
      "        [1.3033e-01, 1.3423e-01, 1.3344e-01, 1.5251e-01, 1.2771e-01, 1.2294e-01,\n",
      "         1.3286e-01, 6.1416e-02, 3.6260e-03, 9.4388e-04],\n",
      "        [1.3083e-01, 1.3164e-01, 1.3088e-01, 1.4798e-01, 1.2566e-01, 1.2202e-01,\n",
      "         1.3292e-01, 6.9930e-02, 6.2639e-03, 1.8743e-03],\n",
      "        [1.3123e-01, 1.3000e-01, 1.2927e-01, 1.4522e-01, 1.2453e-01, 1.2153e-01,\n",
      "         1.3295e-01, 7.4563e-02, 8.1282e-03, 2.5805e-03],\n",
      "        [1.3076e-01, 1.2899e-01, 1.2834e-01, 1.4339e-01, 1.2412e-01, 1.2148e-01,\n",
      "         1.3265e-01, 7.7795e-02, 9.3978e-03, 3.0825e-03],\n",
      "        [1.2984e-01, 1.2813e-01, 1.2761e-01, 1.4241e-01, 1.2374e-01, 1.2142e-01,\n",
      "         1.3298e-01, 8.0146e-02, 1.0297e-02, 3.4212e-03],\n",
      "        [1.2921e-01, 1.2750e-01, 1.2706e-01, 1.4161e-01, 1.2340e-01, 1.2130e-01,\n",
      "         1.3314e-01, 8.1880e-02, 1.1124e-02, 3.7742e-03],\n",
      "        [1.2873e-01, 1.2720e-01, 1.2684e-01, 1.4116e-01, 1.2331e-01, 1.2131e-01,\n",
      "         1.3307e-01, 8.2791e-02, 1.1601e-02, 3.9904e-03]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 108.00, Train Loss: 2.44, Val Loss: 12.13, Train BLEU: 20.51, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 我们 用 的 是 深海 潜水 潜水艇 <UNK> 号 和\n",
      "Reference: we use the submarine alvin and we use cameras\n",
      "Model: <SOS> we of the the , , the the the\n",
      "Attention Weights: tensor([[0.1328, 0.1840, 0.1720, 0.1525, 0.1331, 0.0421, 0.0005, 0.0006, 0.1286,\n",
      "         0.0538],\n",
      "        [0.1485, 0.1668, 0.1545, 0.1406, 0.1322, 0.0635, 0.0041, 0.0061, 0.1242,\n",
      "         0.0596],\n",
      "        [0.1508, 0.1506, 0.1401, 0.1312, 0.1317, 0.0790, 0.0118, 0.0174, 0.1215,\n",
      "         0.0659],\n",
      "        [0.1441, 0.1391, 0.1313, 0.1255, 0.1309, 0.0896, 0.0215, 0.0294, 0.1173,\n",
      "         0.0715],\n",
      "        [0.1401, 0.1348, 0.1283, 0.1236, 0.1300, 0.0931, 0.0263, 0.0349, 0.1151,\n",
      "         0.0738],\n",
      "        [0.1388, 0.1331, 0.1271, 0.1228, 0.1295, 0.0941, 0.0282, 0.0371, 0.1146,\n",
      "         0.0746],\n",
      "        [0.1368, 0.1313, 0.1262, 0.1226, 0.1292, 0.0953, 0.0296, 0.0384, 0.1141,\n",
      "         0.0763],\n",
      "        [0.1355, 0.1303, 0.1255, 0.1223, 0.1289, 0.0962, 0.0307, 0.0394, 0.1139,\n",
      "         0.0774],\n",
      "        [0.1342, 0.1293, 0.1250, 0.1221, 0.1287, 0.0969, 0.0315, 0.0401, 0.1138,\n",
      "         0.0784]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 那 就是 她 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: there she is . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a to about <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.2677e-01, 1.7594e-01, 1.6313e-01, 1.4949e-01, 1.3785e-01, 1.1805e-01,\n",
      "         8.3679e-02, 4.4592e-02, 5.0195e-04, 3.3160e-12],\n",
      "        [1.4580e-01, 1.7637e-01, 1.6036e-01, 1.4565e-01, 1.3225e-01, 1.1255e-01,\n",
      "         8.0734e-02, 4.5106e-02, 1.1808e-03, 6.0107e-11],\n",
      "        [1.6437e-01, 1.6936e-01, 1.5169e-01, 1.3828e-01, 1.2658e-01, 1.1030e-01,\n",
      "         8.3540e-02, 5.2312e-02, 3.5527e-03, 3.2058e-10],\n",
      "        [1.6446e-01, 1.5926e-01, 1.4480e-01, 1.3415e-01, 1.2501e-01, 1.1223e-01,\n",
      "         8.9393e-02, 6.2055e-02, 8.6396e-03, 1.2964e-09],\n",
      "        [1.6121e-01, 1.5546e-01, 1.4282e-01, 1.3323e-01, 1.2492e-01, 1.1328e-01,\n",
      "         9.1806e-02, 6.6036e-02, 1.1237e-02, 1.7253e-09],\n",
      "        [1.5922e-01, 1.5298e-01, 1.4139e-01, 1.3253e-01, 1.2474e-01, 1.1386e-01,\n",
      "         9.3522e-02, 6.8813e-02, 1.2945e-02, 1.8940e-09],\n",
      "        [1.5461e-01, 1.4990e-01, 1.3986e-01, 1.3205e-01, 1.2493e-01, 1.1489e-01,\n",
      "         9.6254e-02, 7.2698e-02, 1.4804e-02, 1.4804e-09],\n",
      "        [1.5160e-01, 1.4744e-01, 1.3834e-01, 1.3122e-01, 1.2468e-01, 1.1537e-01,\n",
      "         9.8236e-02, 7.6046e-02, 1.7059e-02, 1.5348e-09],\n",
      "        [1.5105e-01, 1.4695e-01, 1.3804e-01, 1.3105e-01, 1.2462e-01, 1.1546e-01,\n",
      "         9.8582e-02, 7.6678e-02, 1.7579e-02, 1.6078e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 109.00, Train Loss: 2.41, Val Loss: 12.13, Train BLEU: 20.83, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地 地球 上 最长 的 山脉 都 在 海洋\n",
      "Reference: and in the oceans , there are the longest\n",
      "Model: <SOS> and of the the , the the the the\n",
      "Attention Weights: tensor([[0.0719, 0.1095, 0.1291, 0.1126, 0.1315, 0.1141, 0.1287, 0.0907, 0.0745,\n",
      "         0.0374],\n",
      "        [0.0929, 0.1118, 0.1236, 0.1097, 0.1243, 0.1088, 0.1206, 0.0892, 0.0749,\n",
      "         0.0441],\n",
      "        [0.1082, 0.1104, 0.1169, 0.1050, 0.1164, 0.1038, 0.1140, 0.0895, 0.0792,\n",
      "         0.0567],\n",
      "        [0.1101, 0.1074, 0.1130, 0.1026, 0.1127, 0.1019, 0.1115, 0.0907, 0.0830,\n",
      "         0.0671],\n",
      "        [0.1094, 0.1060, 0.1116, 0.1018, 0.1116, 0.1015, 0.1108, 0.0913, 0.0846,\n",
      "         0.0714],\n",
      "        [0.1088, 0.1050, 0.1106, 0.1015, 0.1108, 0.1014, 0.1103, 0.0920, 0.0859,\n",
      "         0.0738],\n",
      "        [0.1077, 0.1042, 0.1097, 0.1013, 0.1101, 0.1014, 0.1098, 0.0928, 0.0870,\n",
      "         0.0759],\n",
      "        [0.1072, 0.1038, 0.1093, 0.1011, 0.1098, 0.1013, 0.1096, 0.0931, 0.0876,\n",
      "         0.0772],\n",
      "        [0.1067, 0.1036, 0.1091, 0.1011, 0.1097, 0.1013, 0.1095, 0.0932, 0.0879,\n",
      "         0.0778]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 总是 担心 会 被 塔利 塔利班 发现 <EOS> <PAD>\n",
      "Reference: we always wondered what they knew about us .\n",
      "Model: <SOS> it &apos;s got to to about . . <EOS>\n",
      "Attention Weights: tensor([[0.0708, 0.0968, 0.1801, 0.1735, 0.1552, 0.1482, 0.0880, 0.0026, 0.0603,\n",
      "         0.0245],\n",
      "        [0.0924, 0.1157, 0.1539, 0.1473, 0.1355, 0.1347, 0.0986, 0.0161, 0.0717,\n",
      "         0.0341],\n",
      "        [0.1029, 0.1228, 0.1370, 0.1308, 0.1227, 0.1256, 0.1036, 0.0353, 0.0777,\n",
      "         0.0417],\n",
      "        [0.1047, 0.1228, 0.1262, 0.1214, 0.1157, 0.1207, 0.1071, 0.0512, 0.0816,\n",
      "         0.0485],\n",
      "        [0.1044, 0.1216, 0.1225, 0.1184, 0.1137, 0.1189, 0.1077, 0.0576, 0.0834,\n",
      "         0.0518],\n",
      "        [0.1045, 0.1211, 0.1209, 0.1170, 0.1127, 0.1181, 0.1079, 0.0603, 0.0842,\n",
      "         0.0532],\n",
      "        [0.1043, 0.1203, 0.1193, 0.1159, 0.1122, 0.1176, 0.1083, 0.0621, 0.0851,\n",
      "         0.0551],\n",
      "        [0.1040, 0.1198, 0.1181, 0.1150, 0.1117, 0.1170, 0.1083, 0.0631, 0.0859,\n",
      "         0.0570],\n",
      "        [0.1038, 0.1194, 0.1176, 0.1147, 0.1116, 0.1169, 0.1085, 0.0634, 0.0862,\n",
      "         0.0580]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 110.00, Train Loss: 2.39, Val Loss: 12.15, Train BLEU: 22.26, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 我们 用 的 是 深海 潜水 潜水艇 <UNK> 号 和\n",
      "Reference: we use the submarine alvin and we use cameras\n",
      "Model: <SOS> we of the the , , the the the\n",
      "Attention Weights: tensor([[0.1326, 0.1865, 0.1751, 0.1555, 0.1325, 0.0407, 0.0004, 0.0006, 0.1236,\n",
      "         0.0525],\n",
      "        [0.1486, 0.1683, 0.1562, 0.1420, 0.1308, 0.0621, 0.0038, 0.0062, 0.1227,\n",
      "         0.0592],\n",
      "        [0.1512, 0.1517, 0.1411, 0.1318, 0.1307, 0.0780, 0.0113, 0.0177, 0.1208,\n",
      "         0.0657],\n",
      "        [0.1444, 0.1395, 0.1316, 0.1256, 0.1302, 0.0893, 0.0212, 0.0303, 0.1165,\n",
      "         0.0713],\n",
      "        [0.1406, 0.1350, 0.1283, 0.1233, 0.1291, 0.0928, 0.0262, 0.0362, 0.1147,\n",
      "         0.0737],\n",
      "        [0.1395, 0.1332, 0.1270, 0.1224, 0.1285, 0.0937, 0.0283, 0.0385, 0.1144,\n",
      "         0.0744],\n",
      "        [0.1375, 0.1315, 0.1261, 0.1222, 0.1284, 0.0950, 0.0297, 0.0397, 0.1138,\n",
      "         0.0759],\n",
      "        [0.1362, 0.1303, 0.1254, 0.1218, 0.1280, 0.0959, 0.0309, 0.0409, 0.1136,\n",
      "         0.0770],\n",
      "        [0.1348, 0.1294, 0.1248, 0.1216, 0.1279, 0.0967, 0.0317, 0.0415, 0.1134,\n",
      "         0.0781]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他们 知道 我们 的 住处 吗 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: do they know where we live ? <EOS> <PAD>\n",
      "Model: <SOS> it &apos;s a to about . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[6.0484e-07, 3.5736e-07, 1.6586e-06, 1.0646e-05, 8.0665e-04, 1.6974e-01,\n",
      "         2.7558e-01, 2.5395e-01, 1.9773e-01, 1.0219e-01],\n",
      "        [4.1049e-06, 2.5005e-06, 9.8511e-06, 5.0608e-05, 2.3400e-03, 2.0885e-01,\n",
      "         2.7641e-01, 2.4003e-01, 1.8174e-01, 9.0560e-02],\n",
      "        [1.4254e-04, 9.7606e-05, 3.0126e-04, 1.1246e-03, 1.7538e-02, 2.4660e-01,\n",
      "         2.5187e-01, 2.1479e-01, 1.6859e-01, 9.8946e-02],\n",
      "        [8.3170e-04, 6.0974e-04, 1.5655e-03, 4.7367e-03, 4.0013e-02, 2.4628e-01,\n",
      "         2.3012e-01, 2.0009e-01, 1.6455e-01, 1.1120e-01],\n",
      "        [1.7733e-03, 1.3348e-03, 3.1910e-03, 8.7170e-03, 5.4599e-02, 2.3755e-01,\n",
      "         2.1666e-01, 1.9206e-01, 1.6386e-01, 1.2026e-01],\n",
      "        [2.6342e-03, 1.9984e-03, 4.6129e-03, 1.1883e-02, 6.2801e-02, 2.2864e-01,\n",
      "         2.0948e-01, 1.8799e-01, 1.6396e-01, 1.2601e-01],\n",
      "        [3.2627e-03, 2.4974e-03, 5.6299e-03, 1.4041e-02, 6.7398e-02, 2.2401e-01,\n",
      "         2.0577e-01, 1.8555e-01, 1.6335e-01, 1.2848e-01],\n",
      "        [3.4910e-03, 2.6791e-03, 5.9809e-03, 1.4731e-02, 6.8735e-02, 2.2263e-01,\n",
      "         2.0458e-01, 1.8479e-01, 1.6313e-01, 1.2925e-01],\n",
      "        [3.6184e-03, 2.7803e-03, 6.1728e-03, 1.5082e-02, 6.9195e-02, 2.2177e-01,\n",
      "         2.0410e-01, 1.8449e-01, 1.6308e-01, 1.2971e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 111.00, Train Loss: 2.36, Val Loss: 12.17, Train BLEU: 22.26, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 原来 它 是 海洋 洋中 最长 的 生物 <EOS> <PAD>\n",
      "Reference: this turns out to be the longest creature in\n",
      "Model: <SOS> it &apos;s a to about . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.5512e-01, 2.2733e-01, 2.0128e-01, 1.9020e-01, 1.4297e-02, 1.0399e-01,\n",
      "         7.0042e-02, 3.7352e-02, 3.9637e-04, 4.0020e-12],\n",
      "        [1.7475e-01, 2.2396e-01, 1.9591e-01, 1.8206e-01, 2.4607e-02, 9.5921e-02,\n",
      "         6.5724e-02, 3.6196e-02, 8.7942e-04, 5.0780e-11],\n",
      "        [1.8969e-01, 2.0340e-01, 1.7744e-01, 1.7337e-01, 5.2681e-02, 9.4332e-02,\n",
      "         6.5950e-02, 4.0383e-02, 2.7467e-03, 2.7785e-10],\n",
      "        [1.8259e-01, 1.8140e-01, 1.6302e-01, 1.7033e-01, 8.4995e-02, 9.3622e-02,\n",
      "         6.9060e-02, 4.8136e-02, 6.8541e-03, 1.3084e-09],\n",
      "        [1.7792e-01, 1.7501e-01, 1.5944e-01, 1.7006e-01, 9.5113e-02, 9.2576e-02,\n",
      "         7.0091e-02, 5.1066e-02, 8.7222e-03, 1.7956e-09],\n",
      "        [1.7345e-01, 1.6949e-01, 1.5581e-01, 1.6768e-01, 1.0245e-01, 9.3984e-02,\n",
      "         7.2387e-02, 5.4276e-02, 1.0474e-02, 2.2567e-09],\n",
      "        [1.6718e-01, 1.6456e-01, 1.5288e-01, 1.6429e-01, 1.0544e-01, 9.7025e-02,\n",
      "         7.6861e-02, 5.9345e-02, 1.2415e-02, 1.7662e-09],\n",
      "        [1.6256e-01, 1.6032e-01, 1.4985e-01, 1.6013e-01, 1.0794e-01, 1.0012e-01,\n",
      "         8.0774e-02, 6.3680e-02, 1.4630e-02, 1.7995e-09],\n",
      "        [1.6170e-01, 1.5956e-01, 1.4936e-01, 1.5936e-01, 1.0846e-01, 1.0054e-01,\n",
      "         8.1403e-02, 6.4465e-02, 1.5151e-02, 1.8842e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 父亲 那 就是 他 他 是 他家 家族\n",
      "Reference: and my father -- that &apos;s him -- he\n",
      "Model: <SOS> and of the the , , the the the\n",
      "Attention Weights: tensor([[0.1116, 0.1765, 0.1310, 0.0574, 0.0015, 0.2216, 0.0444, 0.2064, 0.0497,\n",
      "         0.0000],\n",
      "        [0.1246, 0.1753, 0.1325, 0.0660, 0.0034, 0.2196, 0.0572, 0.1772, 0.0441,\n",
      "         0.0001],\n",
      "        [0.1396, 0.1615, 0.1276, 0.0784, 0.0109, 0.2043, 0.0849, 0.1476, 0.0449,\n",
      "         0.0004],\n",
      "        [0.1388, 0.1455, 0.1232, 0.0891, 0.0259, 0.1840, 0.1132, 0.1293, 0.0496,\n",
      "         0.0014],\n",
      "        [0.1368, 0.1400, 0.1206, 0.0911, 0.0328, 0.1755, 0.1221, 0.1260, 0.0529,\n",
      "         0.0023],\n",
      "        [0.1343, 0.1344, 0.1170, 0.0913, 0.0384, 0.1700, 0.1288, 0.1254, 0.0570,\n",
      "         0.0033],\n",
      "        [0.1318, 0.1313, 0.1156, 0.0924, 0.0413, 0.1655, 0.1315, 0.1257, 0.0609,\n",
      "         0.0041],\n",
      "        [0.1296, 0.1295, 0.1153, 0.0939, 0.0437, 0.1616, 0.1316, 0.1256, 0.0644,\n",
      "         0.0048],\n",
      "        [0.1283, 0.1282, 0.1150, 0.0951, 0.0464, 0.1589, 0.1315, 0.1248, 0.0664,\n",
      "         0.0054]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 112.00, Train Loss: 2.34, Val Loss: 12.18, Train BLEU: 22.57, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 是 我 最 喜欢 的 因为 它 哪 都 能动\n",
      "Reference: it &apos;s one of my favorites , because it\n",
      "Model: <SOS> it &apos;s one one my , , , ,\n",
      "Attention Weights: tensor([[0.0873, 0.1296, 0.1332, 0.1442, 0.1380, 0.1447, 0.1083, 0.0813, 0.0332,\n",
      "         0.0000],\n",
      "        [0.1011, 0.1330, 0.1340, 0.1419, 0.1344, 0.1399, 0.1043, 0.0780, 0.0334,\n",
      "         0.0001],\n",
      "        [0.1205, 0.1337, 0.1303, 0.1351, 0.1270, 0.1327, 0.1013, 0.0791, 0.0397,\n",
      "         0.0006],\n",
      "        [0.1275, 0.1296, 0.1253, 0.1298, 0.1225, 0.1292, 0.1015, 0.0833, 0.0490,\n",
      "         0.0023],\n",
      "        [0.1276, 0.1266, 0.1229, 0.1273, 0.1206, 0.1275, 0.1023, 0.0863, 0.0549,\n",
      "         0.0039],\n",
      "        [0.1270, 0.1249, 0.1215, 0.1258, 0.1197, 0.1266, 0.1029, 0.0881, 0.0584,\n",
      "         0.0051],\n",
      "        [0.1249, 0.1233, 0.1204, 0.1246, 0.1191, 0.1258, 0.1039, 0.0902, 0.0619,\n",
      "         0.0059],\n",
      "        [0.1236, 0.1220, 0.1194, 0.1234, 0.1184, 0.1247, 0.1046, 0.0919, 0.0651,\n",
      "         0.0070],\n",
      "        [0.1230, 0.1214, 0.1188, 0.1227, 0.1180, 0.1240, 0.1049, 0.0927, 0.0668,\n",
      "         0.0077]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 面带 <UNK> <UNK> 笑容 这 很少 少见 因为 大部\n",
      "Reference: there was a big smile on his face which\n",
      "Model: <SOS> with vibrant video clips , the the the the\n",
      "Attention Weights: tensor([[0.0318, 0.0027, 0.1929, 0.1605, 0.0102, 0.0029, 0.3271, 0.2210, 0.0506,\n",
      "         0.0001],\n",
      "        [0.0483, 0.0067, 0.2148, 0.1690, 0.0176, 0.0073, 0.2926, 0.1915, 0.0518,\n",
      "         0.0005],\n",
      "        [0.0757, 0.0224, 0.2180, 0.1637, 0.0386, 0.0237, 0.2383, 0.1577, 0.0592,\n",
      "         0.0028],\n",
      "        [0.0897, 0.0383, 0.2009, 0.1535, 0.0568, 0.0399, 0.2040, 0.1423, 0.0675,\n",
      "         0.0070],\n",
      "        [0.0934, 0.0471, 0.1909, 0.1477, 0.0652, 0.0490, 0.1902, 0.1359, 0.0705,\n",
      "         0.0100],\n",
      "        [0.0964, 0.0530, 0.1820, 0.1443, 0.0708, 0.0551, 0.1783, 0.1323, 0.0748,\n",
      "         0.0130],\n",
      "        [0.0981, 0.0558, 0.1764, 0.1423, 0.0735, 0.0581, 0.1719, 0.1308, 0.0781,\n",
      "         0.0150],\n",
      "        [0.0989, 0.0577, 0.1733, 0.1410, 0.0752, 0.0600, 0.1685, 0.1297, 0.0795,\n",
      "         0.0162],\n",
      "        [0.0993, 0.0587, 0.1720, 0.1403, 0.0761, 0.0610, 0.1669, 0.1290, 0.0799,\n",
      "         0.0168]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 113.00, Train Loss: 2.32, Val Loss: 12.20, Train BLEU: 22.48, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 其实 它们 都 是 由 单独 的 动物 结合 合在\n",
      "Reference: these are all individual animals banding together to make\n",
      "Model: <SOS> these are all individual animals , , , ,\n",
      "Attention Weights: tensor([[0.0803, 0.1160, 0.1205, 0.1252, 0.1297, 0.1503, 0.1207, 0.1164, 0.0408,\n",
      "         0.0000],\n",
      "        [0.1009, 0.1187, 0.1196, 0.1219, 0.1242, 0.1422, 0.1150, 0.1119, 0.0453,\n",
      "         0.0003],\n",
      "        [0.1157, 0.1175, 0.1152, 0.1160, 0.1174, 0.1340, 0.1112, 0.1130, 0.0579,\n",
      "         0.0020],\n",
      "        [0.1184, 0.1148, 0.1121, 0.1128, 0.1141, 0.1297, 0.1097, 0.1146, 0.0686,\n",
      "         0.0051],\n",
      "        [0.1190, 0.1136, 0.1109, 0.1115, 0.1128, 0.1279, 0.1091, 0.1152, 0.0729,\n",
      "         0.0072],\n",
      "        [0.1196, 0.1128, 0.1101, 0.1107, 0.1120, 0.1268, 0.1086, 0.1155, 0.0754,\n",
      "         0.0086],\n",
      "        [0.1189, 0.1120, 0.1096, 0.1104, 0.1117, 0.1260, 0.1086, 0.1156, 0.0776,\n",
      "         0.0097],\n",
      "        [0.1179, 0.1113, 0.1092, 0.1101, 0.1114, 0.1252, 0.1087, 0.1158, 0.0798,\n",
      "         0.0106],\n",
      "        [0.1173, 0.1109, 0.1089, 0.1098, 0.1111, 0.1244, 0.1087, 0.1158, 0.0814,\n",
      "         0.0116]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 在 塔利 塔利班 控制 阿富汗 的 那些 年 我 记得\n",
      "Reference: during taliban years , i remember there were times\n",
      "Model: <SOS> most of the the the the the the the\n",
      "Attention Weights: tensor([[0.0803, 0.1160, 0.1205, 0.1252, 0.1297, 0.1503, 0.1207, 0.1164, 0.0408,\n",
      "         0.0000],\n",
      "        [0.1009, 0.1187, 0.1196, 0.1219, 0.1242, 0.1422, 0.1150, 0.1119, 0.0453,\n",
      "         0.0003],\n",
      "        [0.1157, 0.1175, 0.1152, 0.1160, 0.1174, 0.1340, 0.1112, 0.1130, 0.0579,\n",
      "         0.0020],\n",
      "        [0.1184, 0.1148, 0.1121, 0.1128, 0.1141, 0.1297, 0.1097, 0.1146, 0.0686,\n",
      "         0.0051],\n",
      "        [0.1190, 0.1136, 0.1109, 0.1115, 0.1128, 0.1279, 0.1091, 0.1152, 0.0729,\n",
      "         0.0072],\n",
      "        [0.1196, 0.1128, 0.1101, 0.1107, 0.1120, 0.1268, 0.1086, 0.1155, 0.0754,\n",
      "         0.0086],\n",
      "        [0.1189, 0.1120, 0.1096, 0.1104, 0.1117, 0.1260, 0.1086, 0.1156, 0.0776,\n",
      "         0.0097],\n",
      "        [0.1179, 0.1113, 0.1092, 0.1101, 0.1114, 0.1252, 0.1087, 0.1158, 0.0798,\n",
      "         0.0106],\n",
      "        [0.1173, 0.1109, 0.1089, 0.1098, 0.1111, 0.1244, 0.1087, 0.1158, 0.0814,\n",
      "         0.0116]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 114.00, Train Loss: 2.30, Val Loss: 12.20, Train BLEU: 22.78, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: <UNK> 塞尔 <UNK> <UNK> 斯特 说 过 真正 的 探索\n",
      "Reference: marcel proust said , &quot; the true voyage of\n",
      "Model: <SOS> marcel proust said , &quot; true true true true\n",
      "Attention Weights: tensor([[7.0072e-07, 4.1361e-07, 1.9101e-06, 1.2338e-05, 9.6037e-04, 1.6623e-01,\n",
      "         2.7108e-01, 2.5574e-01, 2.0159e-01, 1.0438e-01],\n",
      "        [3.4692e-06, 2.0986e-06, 8.5553e-06, 4.5520e-05, 2.3925e-03, 2.0685e-01,\n",
      "         2.7396e-01, 2.4161e-01, 1.8403e-01, 9.1102e-02],\n",
      "        [1.1976e-04, 8.1415e-05, 2.6133e-04, 1.0153e-03, 1.8195e-02, 2.5114e-01,\n",
      "         2.5194e-01, 2.1394e-01, 1.6706e-01, 9.6235e-02],\n",
      "        [8.1379e-04, 5.9494e-04, 1.5536e-03, 4.7939e-03, 4.3620e-02, 2.5127e-01,\n",
      "         2.2895e-01, 1.9739e-01, 1.6184e-01, 1.0916e-01],\n",
      "        [1.8403e-03, 1.3845e-03, 3.3446e-03, 9.2435e-03, 6.0562e-02, 2.4116e-01,\n",
      "         2.1430e-01, 1.8901e-01, 1.6071e-01, 1.1845e-01],\n",
      "        [2.7771e-03, 2.1090e-03, 4.9111e-03, 1.2782e-02, 6.9891e-02, 2.3142e-01,\n",
      "         2.0645e-01, 1.8469e-01, 1.6060e-01, 1.2437e-01],\n",
      "        [3.5739e-03, 2.7404e-03, 6.2033e-03, 1.5553e-02, 7.5786e-02, 2.2598e-01,\n",
      "         2.0200e-01, 1.8164e-01, 1.5963e-01, 1.2690e-01],\n",
      "        [3.8640e-03, 2.9731e-03, 6.6546e-03, 1.6452e-02, 7.7522e-02, 2.2429e-01,\n",
      "         2.0061e-01, 1.8070e-01, 1.5928e-01, 1.2766e-01],\n",
      "        [4.0191e-03, 3.0977e-03, 6.8891e-03, 1.6886e-02, 7.8096e-02, 2.2325e-01,\n",
      "         2.0005e-01, 1.8036e-01, 1.5922e-01, 1.2814e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6 岁 那年 塔利 塔利班 占领 阿富汗 并 规定\n",
      "Reference: you see , i was six when the taliban\n",
      "Model: <SOS> most of the the the the the the the\n",
      "Attention Weights: tensor([[1.2845e-01, 1.7366e-01, 1.7677e-01, 1.9891e-01, 1.3198e-01, 8.8895e-02,\n",
      "         6.3581e-02, 3.7389e-02, 3.6362e-04, 3.7122e-12],\n",
      "        [1.4850e-01, 1.7572e-01, 1.7232e-01, 1.8851e-01, 1.2567e-01, 8.6846e-02,\n",
      "         6.2861e-02, 3.8722e-02, 8.6064e-04, 5.1853e-11],\n",
      "        [1.7207e-01, 1.7162e-01, 1.6165e-01, 1.7350e-01, 1.1968e-01, 8.6815e-02,\n",
      "         6.6188e-02, 4.5667e-02, 2.8102e-03, 2.8193e-10],\n",
      "        [1.7118e-01, 1.5961e-01, 1.5280e-01, 1.6671e-01, 1.1967e-01, 9.1138e-02,\n",
      "         7.3510e-02, 5.7782e-02, 7.6030e-03, 1.4151e-09],\n",
      "        [1.6829e-01, 1.5509e-01, 1.5023e-01, 1.6538e-01, 1.1973e-01, 9.2584e-02,\n",
      "         7.6162e-02, 6.2489e-02, 1.0039e-02, 2.0421e-09],\n",
      "        [1.6540e-01, 1.5207e-01, 1.4825e-01, 1.6399e-01, 1.1966e-01, 9.3845e-02,\n",
      "         7.8479e-02, 6.6499e-02, 1.1802e-02, 2.2584e-09],\n",
      "        [1.6022e-01, 1.4945e-01, 1.4600e-01, 1.6053e-01, 1.2015e-01, 9.6600e-02,\n",
      "         8.2189e-02, 7.1004e-02, 1.3857e-02, 1.9496e-09],\n",
      "        [1.5795e-01, 1.4775e-01, 1.4449e-01, 1.5823e-01, 1.2023e-01, 9.7934e-02,\n",
      "         8.4193e-02, 7.3692e-02, 1.5535e-02, 2.1404e-09],\n",
      "        [1.5752e-01, 1.4743e-01, 1.4425e-01, 1.5783e-01, 1.2024e-01, 9.8163e-02,\n",
      "         8.4536e-02, 7.4145e-02, 1.5885e-02, 2.2447e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 115.00, Train Loss: 2.28, Val Loss: 12.22, Train BLEU: 24.70, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 是 我 最 喜欢 的 因为 它 哪 都 能动\n",
      "Reference: it &apos;s one of my favorites , because it\n",
      "Model: <SOS> it &apos;s one of my , , , ,\n",
      "Attention Weights: tensor([[0.0897, 0.1294, 0.1332, 0.1414, 0.1379, 0.1423, 0.1097, 0.0831, 0.0333,\n",
      "         0.0000],\n",
      "        [0.1047, 0.1328, 0.1337, 0.1387, 0.1337, 0.1373, 0.1055, 0.0797, 0.0338,\n",
      "         0.0001],\n",
      "        [0.1251, 0.1338, 0.1297, 0.1316, 0.1259, 0.1299, 0.1021, 0.0807, 0.0406,\n",
      "         0.0007],\n",
      "        [0.1314, 0.1290, 0.1244, 0.1264, 0.1211, 0.1265, 0.1022, 0.0852, 0.0509,\n",
      "         0.0029],\n",
      "        [0.1313, 0.1261, 0.1220, 0.1241, 0.1193, 0.1251, 0.1028, 0.0879, 0.0567,\n",
      "         0.0048],\n",
      "        [0.1305, 0.1243, 0.1206, 0.1229, 0.1184, 0.1246, 0.1032, 0.0894, 0.0600,\n",
      "         0.0062],\n",
      "        [0.1281, 0.1228, 0.1197, 0.1222, 0.1181, 0.1242, 0.1041, 0.0911, 0.0629,\n",
      "         0.0069],\n",
      "        [0.1268, 0.1216, 0.1188, 0.1211, 0.1174, 0.1233, 0.1046, 0.0925, 0.0659,\n",
      "         0.0081],\n",
      "        [0.1261, 0.1210, 0.1183, 0.1206, 0.1170, 0.1228, 0.1048, 0.0932, 0.0674,\n",
      "         0.0088]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 想 过 要 放弃 但 我 的 父亲 这时\n",
      "Reference: i would want to quit , but my father\n",
      "Model: <SOS> and of the the , , the the the\n",
      "Attention Weights: tensor([[0.0916, 0.1371, 0.1401, 0.1524, 0.1389, 0.1546, 0.1289, 0.0561, 0.0003,\n",
      "         0.0000],\n",
      "        [0.1004, 0.1377, 0.1391, 0.1504, 0.1360, 0.1523, 0.1284, 0.0550, 0.0005,\n",
      "         0.0000],\n",
      "        [0.1195, 0.1392, 0.1360, 0.1439, 0.1305, 0.1453, 0.1253, 0.0584, 0.0017,\n",
      "         0.0002],\n",
      "        [0.1328, 0.1382, 0.1320, 0.1382, 0.1257, 0.1400, 0.1242, 0.0639, 0.0042,\n",
      "         0.0007],\n",
      "        [0.1370, 0.1326, 0.1269, 0.1334, 0.1221, 0.1368, 0.1256, 0.0730, 0.0103,\n",
      "         0.0025],\n",
      "        [0.1356, 0.1291, 0.1243, 0.1316, 0.1205, 0.1365, 0.1274, 0.0771, 0.0141,\n",
      "         0.0039],\n",
      "        [0.1346, 0.1263, 0.1222, 0.1296, 0.1190, 0.1354, 0.1282, 0.0809, 0.0182,\n",
      "         0.0056],\n",
      "        [0.1328, 0.1252, 0.1216, 0.1290, 0.1189, 0.1349, 0.1284, 0.0831, 0.0197,\n",
      "         0.0063],\n",
      "        [0.1318, 0.1242, 0.1209, 0.1279, 0.1186, 0.1337, 0.1282, 0.0855, 0.0220,\n",
      "         0.0073]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 116.00, Train Loss: 2.25, Val Loss: 12.21, Train BLEU: 23.63, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 它 可以 伸展 <UNK> 150 英尺 长 <EOS> <PAD> <PAD>\n",
      "Reference: it gets up to about 150 feet long .\n",
      "Model: <SOS> it gets up to about . . . .\n",
      "Attention Weights: tensor([[2.5731e-01, 2.8561e-01, 1.4633e-01, 2.4624e-03, 4.4747e-02, 1.8217e-01,\n",
      "         8.0577e-02, 7.9240e-04, 1.8015e-11, 1.8015e-11],\n",
      "        [2.8027e-01, 2.8115e-01, 1.5526e-01, 5.4777e-03, 5.4829e-02, 1.5223e-01,\n",
      "         6.9447e-02, 1.3402e-03, 1.3265e-10, 1.3265e-10],\n",
      "        [2.8787e-01, 2.5393e-01, 1.5995e-01, 1.6660e-02, 8.4363e-02, 1.2922e-01,\n",
      "         6.4579e-02, 3.4280e-03, 4.7629e-10, 4.7629e-10],\n",
      "        [2.6832e-01, 2.3112e-01, 1.6543e-01, 3.7176e-02, 1.0998e-01, 1.1513e-01,\n",
      "         6.5221e-02, 7.6292e-03, 1.7807e-09, 1.7807e-09],\n",
      "        [2.5938e-01, 2.2414e-01, 1.6610e-01, 4.4386e-02, 1.1717e-01, 1.1265e-01,\n",
      "         6.6694e-02, 9.4905e-03, 2.5076e-09, 2.5076e-09],\n",
      "        [2.4925e-01, 2.1601e-01, 1.6427e-01, 5.0448e-02, 1.2444e-01, 1.1411e-01,\n",
      "         6.9909e-02, 1.1571e-02, 3.3389e-09, 3.3389e-09],\n",
      "        [2.4069e-01, 2.1194e-01, 1.6368e-01, 5.2204e-02, 1.2653e-01, 1.1752e-01,\n",
      "         7.4316e-02, 1.3111e-02, 2.9833e-09, 2.9833e-09],\n",
      "        [2.2817e-01, 2.0389e-01, 1.6220e-01, 5.6929e-02, 1.3005e-01, 1.2229e-01,\n",
      "         8.0454e-02, 1.6019e-02, 3.1353e-09, 3.1353e-09],\n",
      "        [2.2395e-01, 2.0077e-01, 1.6152e-01, 5.9356e-02, 1.3162e-01, 1.2341e-01,\n",
      "         8.2247e-02, 1.7123e-02, 3.3624e-09, 3.3624e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在 可以 去 个 真正 的 学校 念书 了\n",
      "Reference: &quot; you can go to a real school now\n",
      "Model: <SOS> people of the the the , the the the\n",
      "Attention Weights: tensor([[0.0217, 0.0046, 0.0085, 0.0222, 0.2217, 0.1916, 0.1779, 0.1587, 0.1266,\n",
      "         0.0665],\n",
      "        [0.0449, 0.0205, 0.0313, 0.0644, 0.2100, 0.1706, 0.1528, 0.1346, 0.1080,\n",
      "         0.0628],\n",
      "        [0.0723, 0.0505, 0.0694, 0.1187, 0.1728, 0.1365, 0.1209, 0.1075, 0.0898,\n",
      "         0.0615],\n",
      "        [0.0841, 0.0719, 0.0908, 0.1369, 0.1463, 0.1174, 0.1060, 0.0966, 0.0843,\n",
      "         0.0656],\n",
      "        [0.0867, 0.0795, 0.0973, 0.1385, 0.1375, 0.1121, 0.1023, 0.0941, 0.0836,\n",
      "         0.0684],\n",
      "        [0.0867, 0.0825, 0.0992, 0.1383, 0.1343, 0.1100, 0.1010, 0.0935, 0.0838,\n",
      "         0.0706],\n",
      "        [0.0868, 0.0835, 0.0988, 0.1346, 0.1313, 0.1091, 0.1012, 0.0946, 0.0859,\n",
      "         0.0742],\n",
      "        [0.0870, 0.0838, 0.0981, 0.1320, 0.1298, 0.1089, 0.1015, 0.0953, 0.0872,\n",
      "         0.0765],\n",
      "        [0.0869, 0.0838, 0.0977, 0.1308, 0.1290, 0.1089, 0.1018, 0.0957, 0.0878,\n",
      "         0.0776]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 117.00, Train Loss: 2.22, Val Loss: 12.23, Train BLEU: 24.20, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 底下 这些 都 是 <UNK> 它们 上上 上上下下 上下 下下\n",
      "Reference: it &apos;s got these fishing <UNK> on the bottom\n",
      "Model: <SOS> it &apos;s got these fishing fishing , bottom bottom\n",
      "Attention Weights: tensor([[0.1112, 0.1735, 0.1283, 0.0590, 0.0016, 0.2224, 0.0566, 0.2039, 0.0434,\n",
      "         0.0000],\n",
      "        [0.1245, 0.1715, 0.1298, 0.0682, 0.0039, 0.2183, 0.0721, 0.1727, 0.0389,\n",
      "         0.0001],\n",
      "        [0.1407, 0.1569, 0.1233, 0.0792, 0.0129, 0.2013, 0.1032, 0.1417, 0.0404,\n",
      "         0.0004],\n",
      "        [0.1388, 0.1395, 0.1177, 0.0885, 0.0315, 0.1787, 0.1352, 0.1228, 0.0457,\n",
      "         0.0017],\n",
      "        [0.1366, 0.1335, 0.1145, 0.0897, 0.0390, 0.1716, 0.1451, 0.1194, 0.0480,\n",
      "         0.0027],\n",
      "        [0.1334, 0.1272, 0.1104, 0.0895, 0.0452, 0.1664, 0.1525, 0.1193, 0.0520,\n",
      "         0.0040],\n",
      "        [0.1308, 0.1241, 0.1089, 0.0903, 0.0481, 0.1624, 0.1547, 0.1201, 0.0557,\n",
      "         0.0050],\n",
      "        [0.1286, 0.1224, 0.1087, 0.0917, 0.0502, 0.1588, 0.1543, 0.1204, 0.0590,\n",
      "         0.0058],\n",
      "        [0.1271, 0.1212, 0.1086, 0.0930, 0.0532, 0.1560, 0.1530, 0.1199, 0.0614,\n",
      "         0.0067]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 在 塔利 塔利班 控制 阿富汗 的 那些 年 我 记得\n",
      "Reference: during taliban years , i remember there were times\n",
      "Model: <SOS> the of the the the the the the the\n",
      "Attention Weights: tensor([[0.0851, 0.1169, 0.1222, 0.1248, 0.1272, 0.1411, 0.1156, 0.1231, 0.0441,\n",
      "         0.0000],\n",
      "        [0.1079, 0.1196, 0.1204, 0.1207, 0.1211, 0.1336, 0.1096, 0.1178, 0.0488,\n",
      "         0.0004],\n",
      "        [0.1231, 0.1183, 0.1156, 0.1146, 0.1144, 0.1257, 0.1060, 0.1177, 0.0621,\n",
      "         0.0025],\n",
      "        [0.1250, 0.1151, 0.1121, 0.1112, 0.1111, 0.1220, 0.1049, 0.1187, 0.0733,\n",
      "         0.0066],\n",
      "        [0.1252, 0.1139, 0.1107, 0.1098, 0.1098, 0.1206, 0.1043, 0.1190, 0.0775,\n",
      "         0.0092],\n",
      "        [0.1257, 0.1131, 0.1099, 0.1090, 0.1090, 0.1199, 0.1038, 0.1192, 0.0796,\n",
      "         0.0109],\n",
      "        [0.1248, 0.1122, 0.1094, 0.1087, 0.1088, 0.1196, 0.1039, 0.1194, 0.0812,\n",
      "         0.0119],\n",
      "        [0.1235, 0.1115, 0.1090, 0.1085, 0.1086, 0.1192, 0.1042, 0.1195, 0.0831,\n",
      "         0.0128],\n",
      "        [0.1227, 0.1111, 0.1087, 0.1083, 0.1084, 0.1188, 0.1043, 0.1194, 0.0845,\n",
      "         0.0138]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 118.00, Train Loss: 2.20, Val Loss: 12.25, Train BLEU: 24.39, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 通过 潜水 潜水艇 拍下 的 影片 把 我们\n",
      "Reference: with vibrant video clips captured by submarines , david\n",
      "Model: <SOS> with vibrant video clips , , the the the\n",
      "Attention Weights: tensor([[0.0057, 0.0008, 0.1611, 0.1568, 0.0440, 0.1799, 0.1554, 0.1437, 0.1041,\n",
      "         0.0485],\n",
      "        [0.0155, 0.0046, 0.1861, 0.1598, 0.0725, 0.1624, 0.1379, 0.1231, 0.0916,\n",
      "         0.0465],\n",
      "        [0.0364, 0.0188, 0.1851, 0.1534, 0.1099, 0.1389, 0.1176, 0.1057, 0.0834,\n",
      "         0.0506],\n",
      "        [0.0571, 0.0393, 0.1659, 0.1394, 0.1307, 0.1225, 0.1062, 0.0978, 0.0822,\n",
      "         0.0588],\n",
      "        [0.0621, 0.0471, 0.1584, 0.1349, 0.1348, 0.1182, 0.1036, 0.0965, 0.0824,\n",
      "         0.0619],\n",
      "        [0.0642, 0.0499, 0.1548, 0.1326, 0.1365, 0.1163, 0.1026, 0.0962, 0.0828,\n",
      "         0.0640],\n",
      "        [0.0670, 0.0528, 0.1501, 0.1300, 0.1356, 0.1147, 0.1022, 0.0966, 0.0841,\n",
      "         0.0669],\n",
      "        [0.0686, 0.0542, 0.1478, 0.1285, 0.1344, 0.1139, 0.1020, 0.0968, 0.0850,\n",
      "         0.0688],\n",
      "        [0.0701, 0.0557, 0.1460, 0.1273, 0.1335, 0.1132, 0.1017, 0.0968, 0.0855,\n",
      "         0.0701]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11 岁 那年 记得 得有 一天 早晨 醒来 听见\n",
      "Reference: when i was 11 , i remember waking up\n",
      "Model: <SOS> most of the the , the the the the\n",
      "Attention Weights: tensor([[2.6891e-01, 3.0227e-01, 2.2666e-01, 1.7044e-01, 3.1667e-02, 3.9995e-05,\n",
      "         1.9871e-05, 4.8442e-12, 4.8442e-12, 4.8442e-12],\n",
      "        [3.0045e-01, 2.8976e-01, 2.1199e-01, 1.5944e-01, 3.8098e-02, 1.7478e-04,\n",
      "         8.8622e-05, 6.8515e-11, 6.8515e-11, 6.8515e-11],\n",
      "        [3.1856e-01, 2.6518e-01, 1.9670e-01, 1.5793e-01, 5.9115e-02, 1.6339e-03,\n",
      "         8.7776e-04, 5.5918e-10, 5.5918e-10, 5.5918e-10],\n",
      "        [2.9586e-01, 2.3967e-01, 1.9195e-01, 1.6922e-01, 8.9943e-02, 8.6943e-03,\n",
      "         4.6540e-03, 3.6673e-09, 3.6673e-09, 3.6673e-09],\n",
      "        [2.8233e-01, 2.2964e-01, 1.9013e-01, 1.7340e-01, 1.0233e-01, 1.4423e-02,\n",
      "         7.7531e-03, 6.2645e-09, 6.2645e-09, 6.2645e-09],\n",
      "        [2.7499e-01, 2.2681e-01, 1.9091e-01, 1.7585e-01, 1.0688e-01, 1.5804e-02,\n",
      "         8.7506e-03, 5.6783e-09, 5.6783e-09, 5.6783e-09],\n",
      "        [2.6784e-01, 2.2329e-01, 1.9055e-01, 1.7692e-01, 1.1266e-01, 1.8350e-02,\n",
      "         1.0390e-02, 5.9285e-09, 5.9285e-09, 5.9285e-09],\n",
      "        [2.6619e-01, 2.2217e-01, 1.9025e-01, 1.7711e-01, 1.1420e-01, 1.9178e-02,\n",
      "         1.0904e-02, 6.4158e-09, 6.4158e-09, 6.4158e-09],\n",
      "        [2.6569e-01, 2.2178e-01, 1.9013e-01, 1.7716e-01, 1.1466e-01, 1.9483e-02,\n",
      "         1.1095e-02, 6.6704e-09, 6.6704e-09, 6.6704e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 119.00, Train Loss: 2.17, Val Loss: 12.25, Train BLEU: 25.01, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 还有 这些 摇晃 着 旋转 转着 的 触角 <EOS> <PAD>\n",
      "Reference: it &apos;s got tentacles dangling , swirling around like\n",
      "Model: <SOS> it &apos;s got tentacles dangling . . <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.3157e-01, 2.0206e-01, 2.1508e-01, 2.0003e-01, 1.9905e-01, 1.2100e-02,\n",
      "         2.8195e-02, 1.1768e-02, 1.4842e-04, 4.4513e-12],\n",
      "        [1.5714e-01, 1.9951e-01, 2.0235e-01, 1.8602e-01, 1.8833e-01, 2.1618e-02,\n",
      "         3.0301e-02, 1.4248e-02, 4.8470e-04, 4.9025e-11],\n",
      "        [1.8144e-01, 1.8897e-01, 1.8204e-01, 1.6769e-01, 1.7609e-01, 4.5111e-02,\n",
      "         3.7235e-02, 1.9658e-02, 1.7548e-03, 2.4427e-10],\n",
      "        [1.7842e-01, 1.6968e-01, 1.6436e-01, 1.5501e-01, 1.7330e-01, 8.0559e-02,\n",
      "         4.5700e-02, 2.7719e-02, 5.2579e-03, 1.6210e-09],\n",
      "        [1.7392e-01, 1.6263e-01, 1.5910e-01, 1.5084e-01, 1.7352e-01, 9.4533e-02,\n",
      "         4.8102e-02, 3.0465e-02, 6.8881e-03, 2.7574e-09],\n",
      "        [1.7001e-01, 1.5674e-01, 1.5410e-01, 1.4642e-01, 1.7172e-01, 1.0539e-01,\n",
      "         5.2292e-02, 3.4456e-02, 8.8672e-03, 3.7365e-09],\n",
      "        [1.6503e-01, 1.5344e-01, 1.5180e-01, 1.4500e-01, 1.6962e-01, 1.0936e-01,\n",
      "         5.6684e-02, 3.8673e-02, 1.0385e-02, 3.3080e-09],\n",
      "        [1.6173e-01, 1.5066e-01, 1.4954e-01, 1.4350e-01, 1.6718e-01, 1.1302e-01,\n",
      "         6.0226e-02, 4.2194e-02, 1.1938e-02, 3.4506e-09],\n",
      "        [1.6051e-01, 1.4967e-01, 1.4880e-01, 1.4298e-01, 1.6641e-01, 1.1421e-01,\n",
      "         6.1366e-02, 4.3443e-02, 1.2604e-02, 3.6424e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 面带 <UNK> <UNK> 笑容 这 很少 少见 因为 大部\n",
      "Reference: there was a big smile on his face which\n",
      "Model: <SOS> with vibrant video clips , the the the the\n",
      "Attention Weights: tensor([[0.0403, 0.0037, 0.2023, 0.1701, 0.0140, 0.0041, 0.2996, 0.2148, 0.0509,\n",
      "         0.0002],\n",
      "        [0.0607, 0.0090, 0.2226, 0.1755, 0.0239, 0.0100, 0.2651, 0.1820, 0.0506,\n",
      "         0.0006],\n",
      "        [0.0876, 0.0278, 0.2202, 0.1638, 0.0479, 0.0299, 0.2168, 0.1477, 0.0552,\n",
      "         0.0032],\n",
      "        [0.0996, 0.0467, 0.1989, 0.1498, 0.0682, 0.0494, 0.1852, 0.1316, 0.0624,\n",
      "         0.0081],\n",
      "        [0.1016, 0.0565, 0.1881, 0.1427, 0.0771, 0.0596, 0.1726, 0.1250, 0.0651,\n",
      "         0.0117],\n",
      "        [0.1046, 0.0625, 0.1797, 0.1388, 0.0825, 0.0657, 0.1622, 0.1208, 0.0685,\n",
      "         0.0148],\n",
      "        [0.1065, 0.0657, 0.1735, 0.1362, 0.0851, 0.0691, 0.1563, 0.1190, 0.0715,\n",
      "         0.0172],\n",
      "        [0.1070, 0.0678, 0.1699, 0.1346, 0.0867, 0.0711, 0.1532, 0.1180, 0.0730,\n",
      "         0.0187],\n",
      "        [0.1072, 0.0688, 0.1685, 0.1338, 0.0875, 0.0722, 0.1518, 0.1173, 0.0734,\n",
      "         0.0194]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 120.00, Train Loss: 2.15, Val Loss: 12.28, Train BLEU: 25.38, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 这位 是 比尔 <UNK> 我 是 大卫 <UNK>\n",
      "Reference: this is bill lange . i &apos;m dave gallo\n",
      "Model: <SOS> this is bill lange is &apos;m &apos;m &apos;m gallo\n",
      "Attention Weights: tensor([[0.0418, 0.0040, 0.2036, 0.1719, 0.0148, 0.0044, 0.2941, 0.2141, 0.0510,\n",
      "         0.0002],\n",
      "        [0.0635, 0.0099, 0.2234, 0.1764, 0.0257, 0.0109, 0.2590, 0.1800, 0.0505,\n",
      "         0.0007],\n",
      "        [0.0904, 0.0300, 0.2190, 0.1630, 0.0510, 0.0323, 0.2109, 0.1450, 0.0548,\n",
      "         0.0035],\n",
      "        [0.1016, 0.0499, 0.1966, 0.1482, 0.0717, 0.0527, 0.1798, 0.1288, 0.0619,\n",
      "         0.0089],\n",
      "        [0.1033, 0.0602, 0.1852, 0.1406, 0.0808, 0.0635, 0.1671, 0.1219, 0.0646,\n",
      "         0.0128],\n",
      "        [0.1062, 0.0662, 0.1768, 0.1365, 0.0859, 0.0696, 0.1570, 0.1176, 0.0680,\n",
      "         0.0163],\n",
      "        [0.1079, 0.0694, 0.1706, 0.1338, 0.0883, 0.0729, 0.1514, 0.1159, 0.0709,\n",
      "         0.0188],\n",
      "        [0.1083, 0.0715, 0.1672, 0.1322, 0.0898, 0.0749, 0.1485, 0.1148, 0.0722,\n",
      "         0.0204],\n",
      "        [0.1085, 0.0725, 0.1660, 0.1315, 0.0906, 0.0759, 0.1472, 0.1142, 0.0726,\n",
      "         0.0211]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 这 是 我们 俩 人 唯一 的 受教 教育 方式\n",
      "Reference: it was the only way we both could be\n",
      "Model: <SOS> we of the the , the the the the\n",
      "Attention Weights: tensor([[0.0807, 0.1032, 0.1048, 0.1100, 0.1529, 0.1096, 0.1447, 0.0866, 0.0687,\n",
      "         0.0388],\n",
      "        [0.1045, 0.1078, 0.1047, 0.1064, 0.1402, 0.1038, 0.1335, 0.0850, 0.0692,\n",
      "         0.0449],\n",
      "        [0.1221, 0.1085, 0.1017, 0.1011, 0.1282, 0.0981, 0.1237, 0.0849, 0.0735,\n",
      "         0.0581],\n",
      "        [0.1222, 0.1052, 0.0993, 0.0990, 0.1224, 0.0966, 0.1196, 0.0865, 0.0782,\n",
      "         0.0712],\n",
      "        [0.1205, 0.1038, 0.0985, 0.0983, 0.1207, 0.0963, 0.1185, 0.0873, 0.0800,\n",
      "         0.0761],\n",
      "        [0.1193, 0.1027, 0.0980, 0.0982, 0.1212, 0.0962, 0.1193, 0.0873, 0.0802,\n",
      "         0.0776],\n",
      "        [0.1174, 0.1018, 0.0978, 0.0983, 0.1205, 0.0966, 0.1189, 0.0880, 0.0812,\n",
      "         0.0795],\n",
      "        [0.1158, 0.1012, 0.0976, 0.0982, 0.1198, 0.0967, 0.1184, 0.0886, 0.0822,\n",
      "         0.0815],\n",
      "        [0.1150, 0.1009, 0.0975, 0.0982, 0.1195, 0.0967, 0.1182, 0.0889, 0.0827,\n",
      "         0.0823]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 121.00, Train Loss: 2.12, Val Loss: 12.30, Train BLEU: 26.37, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 它 可以 伸展 <UNK> 150 英尺 长 <EOS> <PAD> <PAD>\n",
      "Reference: it gets up to about 150 feet long .\n",
      "Model: <SOS> it gets up to about . . . .\n",
      "Attention Weights: tensor([[2.7122e-01, 3.0492e-01, 1.7773e-01, 3.5366e-03, 4.3097e-02, 1.3771e-01,\n",
      "         6.1118e-02, 6.6351e-04, 2.7902e-11, 2.7902e-11],\n",
      "        [3.0046e-01, 2.9530e-01, 1.8420e-01, 7.8726e-03, 5.1591e-02, 1.0914e-01,\n",
      "         5.0246e-02, 1.1866e-03, 1.8048e-10, 1.8048e-10],\n",
      "        [3.0566e-01, 2.6208e-01, 1.8162e-01, 2.3262e-02, 7.9933e-02, 9.5627e-02,\n",
      "         4.8554e-02, 3.2655e-03, 6.5033e-10, 6.5033e-10],\n",
      "        [2.8075e-01, 2.3332e-01, 1.8093e-01, 5.1088e-02, 1.0650e-01, 8.8431e-02,\n",
      "         5.1288e-02, 7.6938e-03, 2.7886e-09, 2.7886e-09],\n",
      "        [2.6762e-01, 2.2243e-01, 1.7865e-01, 6.1913e-02, 1.1707e-01, 8.8578e-02,\n",
      "         5.3767e-02, 9.9789e-03, 4.4448e-09, 4.4448e-09],\n",
      "        [2.5338e-01, 2.1143e-01, 1.7448e-01, 7.0441e-02, 1.2689e-01, 9.2586e-02,\n",
      "         5.8201e-02, 1.2594e-02, 6.3133e-09, 6.3133e-09],\n",
      "        [2.4221e-01, 2.0576e-01, 1.7286e-01, 7.2214e-02, 1.3035e-01, 9.8306e-02,\n",
      "         6.3671e-02, 1.4622e-02, 5.3782e-09, 5.3782e-09],\n",
      "        [2.2912e-01, 1.9737e-01, 1.7011e-01, 7.7552e-02, 1.3450e-01, 1.0395e-01,\n",
      "         6.9657e-02, 1.7740e-02, 5.8967e-09, 5.8967e-09],\n",
      "        [2.2566e-01, 1.9489e-01, 1.6919e-01, 7.9793e-02, 1.3584e-01, 1.0499e-01,\n",
      "         7.0981e-02, 1.8652e-02, 6.4959e-09, 6.4959e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 她 两年 年前 退休 了 结果 却 把 我家 变成\n",
      "Reference: she retired two years ago , only to turn\n",
      "Model: <SOS> most of the the , , the the the\n",
      "Attention Weights: tensor([[2.5073e-01, 2.8707e-01, 2.0938e-01, 1.6052e-01, 9.1176e-02, 1.1258e-03,\n",
      "         1.7956e-11, 1.7956e-11, 1.7956e-11, 1.7956e-11],\n",
      "        [2.7924e-01, 2.7573e-01, 1.9968e-01, 1.5172e-01, 9.1079e-02, 2.5515e-03,\n",
      "         1.9761e-10, 1.9761e-10, 1.9761e-10, 1.9761e-10],\n",
      "        [3.0293e-01, 2.5938e-01, 1.8729e-01, 1.4535e-01, 9.7375e-02, 7.6740e-03,\n",
      "         9.8005e-10, 9.8005e-10, 9.8005e-10, 9.8005e-10],\n",
      "        [2.8820e-01, 2.3822e-01, 1.8369e-01, 1.5153e-01, 1.1702e-01, 2.1340e-02,\n",
      "         5.8843e-09, 5.8843e-09, 5.8843e-09, 5.8843e-09],\n",
      "        [2.8071e-01, 2.3165e-01, 1.8289e-01, 1.5376e-01, 1.2349e-01, 2.7494e-02,\n",
      "         9.9238e-09, 9.9238e-09, 9.9238e-09, 9.9238e-09],\n",
      "        [2.7493e-01, 2.2715e-01, 1.8234e-01, 1.5547e-01, 1.2814e-01, 3.1977e-02,\n",
      "         1.3316e-08, 1.3316e-08, 1.3316e-08, 1.3316e-08],\n",
      "        [2.6713e-01, 2.2413e-01, 1.8351e-01, 1.5836e-01, 1.3279e-01, 3.4079e-02,\n",
      "         1.0082e-08, 1.0082e-08, 1.0082e-08, 1.0082e-08],\n",
      "        [2.5934e-01, 2.2038e-01, 1.8382e-01, 1.6073e-01, 1.3717e-01, 3.8564e-02,\n",
      "         1.0575e-08, 1.0575e-08, 1.0575e-08, 1.0575e-08],\n",
      "        [2.5771e-01, 2.1947e-01, 1.8385e-01, 1.6120e-01, 1.3806e-01, 3.9721e-02,\n",
      "         1.1579e-08, 1.1579e-08, 1.1579e-08, 1.1579e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 122.00, Train Loss: 2.10, Val Loss: 12.29, Train BLEU: 29.15, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 还有 前面 的 这个 是 推进 引擎 它 一会 一会儿\n",
      "Reference: and it &apos;s got these jet thrusters up in\n",
      "Model: <SOS> and it &apos;s got these jet thrusters thrusters in\n",
      "Attention Weights: tensor([[0.0984, 0.1381, 0.1367, 0.1493, 0.1355, 0.1613, 0.1325, 0.0480, 0.0003,\n",
      "         0.0000],\n",
      "        [0.1096, 0.1380, 0.1347, 0.1463, 0.1314, 0.1589, 0.1329, 0.0475, 0.0006,\n",
      "         0.0000],\n",
      "        [0.1304, 0.1391, 0.1314, 0.1397, 0.1258, 0.1507, 0.1295, 0.0513, 0.0019,\n",
      "         0.0002],\n",
      "        [0.1452, 0.1382, 0.1275, 0.1335, 0.1205, 0.1436, 0.1279, 0.0573, 0.0054,\n",
      "         0.0010],\n",
      "        [0.1472, 0.1318, 0.1225, 0.1287, 0.1172, 0.1394, 0.1298, 0.0670, 0.0129,\n",
      "         0.0035],\n",
      "        [0.1452, 0.1283, 0.1203, 0.1271, 0.1160, 0.1388, 0.1317, 0.0704, 0.0170,\n",
      "         0.0051],\n",
      "        [0.1433, 0.1253, 0.1182, 0.1252, 0.1146, 0.1374, 0.1325, 0.0741, 0.0221,\n",
      "         0.0074],\n",
      "        [0.1408, 0.1239, 0.1176, 0.1246, 0.1145, 0.1367, 0.1326, 0.0763, 0.0243,\n",
      "         0.0086],\n",
      "        [0.1389, 0.1226, 0.1169, 0.1239, 0.1143, 0.1360, 0.1326, 0.0785, 0.0266,\n",
      "         0.0097]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很 舒服 但 夏天 却 <UNK> <EOS> <PAD> <PAD>\n",
      "Reference: it was cozy in winter but extremely hot in\n",
      "Model: <SOS> life in the deep about <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0891, 0.1137, 0.1281, 0.1141, 0.1487, 0.0757, 0.1263, 0.1061, 0.0700,\n",
      "         0.0283],\n",
      "        [0.1125, 0.1086, 0.1139, 0.1026, 0.1331, 0.1263, 0.1104, 0.0922, 0.0664,\n",
      "         0.0340],\n",
      "        [0.1216, 0.1018, 0.1034, 0.0940, 0.1220, 0.1650, 0.1004, 0.0848, 0.0661,\n",
      "         0.0410],\n",
      "        [0.1192, 0.0968, 0.0985, 0.0909, 0.1167, 0.1784, 0.0967, 0.0842, 0.0695,\n",
      "         0.0490],\n",
      "        [0.1172, 0.0953, 0.0973, 0.0903, 0.1151, 0.1786, 0.0965, 0.0852, 0.0717,\n",
      "         0.0528],\n",
      "        [0.1156, 0.0937, 0.0968, 0.0898, 0.1149, 0.1816, 0.0960, 0.0854, 0.0722,\n",
      "         0.0540],\n",
      "        [0.1140, 0.0932, 0.0969, 0.0904, 0.1146, 0.1784, 0.0959, 0.0864, 0.0738,\n",
      "         0.0564],\n",
      "        [0.1131, 0.0934, 0.0974, 0.0910, 0.1148, 0.1743, 0.0958, 0.0870, 0.0751,\n",
      "         0.0582],\n",
      "        [0.1126, 0.0935, 0.0975, 0.0913, 0.1147, 0.1720, 0.0959, 0.0874, 0.0757,\n",
      "         0.0592]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 123.00, Train Loss: 2.07, Val Loss: 12.30, Train BLEU: 28.40, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 当 你 站 在 海滩 上 或是 当 你 看到\n",
      "Reference: part of the problem , i think , is\n",
      "Model: <SOS> and of the the , , the the the\n",
      "Attention Weights: tensor([[0.0808, 0.1041, 0.1029, 0.1076, 0.1547, 0.1088, 0.1499, 0.0853, 0.0665,\n",
      "         0.0394],\n",
      "        [0.1050, 0.1087, 0.1032, 0.1044, 0.1421, 0.1029, 0.1383, 0.0834, 0.0666,\n",
      "         0.0455],\n",
      "        [0.1242, 0.1095, 0.1005, 0.0993, 0.1297, 0.0969, 0.1272, 0.0831, 0.0709,\n",
      "         0.0587],\n",
      "        [0.1238, 0.1059, 0.0982, 0.0975, 0.1240, 0.0954, 0.1228, 0.0848, 0.0757,\n",
      "         0.0720],\n",
      "        [0.1217, 0.1042, 0.0975, 0.0970, 0.1223, 0.0952, 0.1217, 0.0857, 0.0776,\n",
      "         0.0771],\n",
      "        [0.1205, 0.1032, 0.0972, 0.0971, 0.1223, 0.0954, 0.1218, 0.0860, 0.0781,\n",
      "         0.0785],\n",
      "        [0.1186, 0.1022, 0.0971, 0.0972, 0.1215, 0.0958, 0.1212, 0.0868, 0.0793,\n",
      "         0.0804],\n",
      "        [0.1171, 0.1016, 0.0969, 0.0972, 0.1207, 0.0959, 0.1206, 0.0874, 0.0803,\n",
      "         0.0823],\n",
      "        [0.1163, 0.1013, 0.0969, 0.0972, 0.1203, 0.0960, 0.1203, 0.0878, 0.0808,\n",
      "         0.0831]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11 岁 那年 记得 得有 一天 早晨 醒来 听见\n",
      "Reference: when i was 11 , i remember waking up\n",
      "Model: <SOS> most of the the , the the the the\n",
      "Attention Weights: tensor([[2.8615e-01, 3.0638e-01, 2.1401e-01, 1.6202e-01, 3.1365e-02, 5.3252e-05,\n",
      "         2.0572e-05, 5.9908e-12, 5.9908e-12, 5.9908e-12],\n",
      "        [3.2098e-01, 2.8877e-01, 1.9774e-01, 1.5390e-01, 3.8305e-02, 2.1553e-04,\n",
      "         8.7091e-05, 7.5052e-11, 7.5052e-11, 7.5052e-11],\n",
      "        [3.3833e-01, 2.6290e-01, 1.8338e-01, 1.5266e-01, 5.9770e-02, 2.0440e-03,\n",
      "         9.1058e-04, 6.7349e-10, 6.7349e-10, 6.7349e-10],\n",
      "        [3.1051e-01, 2.3702e-01, 1.8087e-01, 1.6523e-01, 9.0794e-02, 1.0651e-02,\n",
      "         4.9206e-03, 4.9825e-09, 4.9825e-09, 4.9825e-09],\n",
      "        [2.9460e-01, 2.2659e-01, 1.7979e-01, 1.6963e-01, 1.0312e-01, 1.7802e-02,\n",
      "         8.4600e-03, 8.8285e-09, 8.8285e-09, 8.8285e-09],\n",
      "        [2.8684e-01, 2.2336e-01, 1.8074e-01, 1.7174e-01, 1.0757e-01, 1.9987e-02,\n",
      "         9.7773e-03, 8.1921e-09, 8.1921e-09, 8.1921e-09],\n",
      "        [2.7743e-01, 2.1958e-01, 1.8101e-01, 1.7305e-01, 1.1369e-01, 2.3415e-02,\n",
      "         1.1831e-02, 8.6275e-09, 8.6275e-09, 8.6275e-09],\n",
      "        [2.7569e-01, 2.1859e-01, 1.8086e-01, 1.7321e-01, 1.1505e-01, 2.4269e-02,\n",
      "         1.2327e-02, 9.2917e-09, 9.2917e-09, 9.2917e-09],\n",
      "        [2.7504e-01, 2.1813e-01, 1.8076e-01, 1.7329e-01, 1.1558e-01, 2.4650e-02,\n",
      "         1.2548e-02, 9.7450e-09, 9.7450e-09, 9.7450e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 124.00, Train Loss: 2.05, Val Loss: 12.31, Train BLEU: 28.03, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本 基本上 都 没有 被 开发 发过 但是 像\n",
      "Reference: it &apos;s mostly unexplored , and yet there are\n",
      "Model: <SOS> people of the the , , the the the\n",
      "Attention Weights: tensor([[0.0781, 0.1060, 0.1398, 0.1080, 0.1219, 0.1054, 0.1242, 0.0998, 0.0959,\n",
      "         0.0210],\n",
      "        [0.1054, 0.1095, 0.1336, 0.1035, 0.1143, 0.0996, 0.1159, 0.0960, 0.0945,\n",
      "         0.0277],\n",
      "        [0.1248, 0.1098, 0.1265, 0.0983, 0.1074, 0.0945, 0.1092, 0.0939, 0.0969,\n",
      "         0.0387],\n",
      "        [0.1251, 0.1062, 0.1216, 0.0965, 0.1050, 0.0935, 0.1072, 0.0946, 0.1006,\n",
      "         0.0497],\n",
      "        [0.1231, 0.1044, 0.1202, 0.0959, 0.1045, 0.0934, 0.1070, 0.0953, 0.1024,\n",
      "         0.0538],\n",
      "        [0.1215, 0.1034, 0.1195, 0.0959, 0.1046, 0.0937, 0.1072, 0.0958, 0.1030,\n",
      "         0.0553],\n",
      "        [0.1202, 0.1028, 0.1188, 0.0961, 0.1046, 0.0941, 0.1072, 0.0962, 0.1032,\n",
      "         0.0567],\n",
      "        [0.1185, 0.1021, 0.1178, 0.0962, 0.1045, 0.0944, 0.1072, 0.0967, 0.1038,\n",
      "         0.0588],\n",
      "        [0.1177, 0.1019, 0.1175, 0.0963, 0.1045, 0.0946, 0.1072, 0.0969, 0.1039,\n",
      "         0.0596]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把 书 放在 食品 杂货 袋中 这样 别人 就\n",
      "Reference: we would cover our books in grocery bags so\n",
      "Model: <SOS> we of the the the , the the the\n",
      "Attention Weights: tensor([[0.0802, 0.1112, 0.1085, 0.1045, 0.1542, 0.1009, 0.0964, 0.1417, 0.0646,\n",
      "         0.0379],\n",
      "        [0.1072, 0.1129, 0.1055, 0.1009, 0.1423, 0.0966, 0.0925, 0.1320, 0.0651,\n",
      "         0.0449],\n",
      "        [0.1284, 0.1119, 0.1007, 0.0953, 0.1296, 0.0915, 0.0885, 0.1240, 0.0698,\n",
      "         0.0603],\n",
      "        [0.1274, 0.1078, 0.0986, 0.0940, 0.1236, 0.0908, 0.0885, 0.1207, 0.0748,\n",
      "         0.0737],\n",
      "        [0.1248, 0.1059, 0.0979, 0.0937, 0.1226, 0.0907, 0.0888, 0.1207, 0.0763,\n",
      "         0.0786],\n",
      "        [0.1225, 0.1047, 0.0979, 0.0941, 0.1216, 0.0914, 0.0896, 0.1198, 0.0776,\n",
      "         0.0808],\n",
      "        [0.1199, 0.1037, 0.0978, 0.0944, 0.1206, 0.0919, 0.0903, 0.1193, 0.0790,\n",
      "         0.0831],\n",
      "        [0.1187, 0.1033, 0.0977, 0.0945, 0.1200, 0.0922, 0.0906, 0.1189, 0.0798,\n",
      "         0.0844],\n",
      "        [0.1179, 0.1031, 0.0977, 0.0946, 0.1198, 0.0924, 0.0908, 0.1187, 0.0801,\n",
      "         0.0849]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 125.00, Train Loss: 2.02, Val Loss: 12.31, Train BLEU: 30.07, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数 多数 地震 和 火山 喷发 也 都 发生\n",
      "Reference: most of the earthquakes and volcanoes are in the\n",
      "Model: <SOS> most of the the , the the the the\n",
      "Attention Weights: tensor([[0.0228, 0.0104, 0.1441, 0.1479, 0.1254, 0.1793, 0.1639, 0.0922, 0.0693,\n",
      "         0.0446],\n",
      "        [0.0441, 0.0345, 0.1526, 0.1401, 0.1181, 0.1621, 0.1488, 0.0859, 0.0661,\n",
      "         0.0478],\n",
      "        [0.0787, 0.0965, 0.1458, 0.1214, 0.1016, 0.1353, 0.1259, 0.0771, 0.0633,\n",
      "         0.0545],\n",
      "        [0.0915, 0.1289, 0.1302, 0.1091, 0.0938, 0.1242, 0.1177, 0.0758, 0.0653,\n",
      "         0.0635],\n",
      "        [0.0942, 0.1365, 0.1238, 0.1053, 0.0920, 0.1207, 0.1155, 0.0763, 0.0672,\n",
      "         0.0686],\n",
      "        [0.0942, 0.1384, 0.1205, 0.1036, 0.0916, 0.1198, 0.1152, 0.0774, 0.0687,\n",
      "         0.0708],\n",
      "        [0.0943, 0.1371, 0.1181, 0.1027, 0.0918, 0.1191, 0.1149, 0.0787, 0.0704,\n",
      "         0.0730],\n",
      "        [0.0941, 0.1346, 0.1162, 0.1020, 0.0920, 0.1186, 0.1148, 0.0800, 0.0721,\n",
      "         0.0756],\n",
      "        [0.0938, 0.1327, 0.1152, 0.1018, 0.0923, 0.1184, 0.1148, 0.0808, 0.0732,\n",
      "         0.0770]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 出身 阿富汗 边远 <UNK> 地区 有着 与 他人 不同\n",
      "Reference: a total maverick from a remote province of afghanistan\n",
      "Model: <SOS> with vibrant the clips , , , the the\n",
      "Attention Weights: tensor([[1.8090e-01, 2.8305e-01, 2.2726e-01, 2.0252e-01, 7.2371e-03, 5.0209e-02,\n",
      "         3.3509e-02, 1.5097e-02, 2.1669e-04, 8.5601e-12],\n",
      "        [2.0788e-01, 2.6766e-01, 2.1407e-01, 1.9659e-01, 1.6354e-02, 4.8852e-02,\n",
      "         3.2572e-02, 1.5510e-02, 5.1860e-04, 6.6798e-11],\n",
      "        [2.2600e-01, 2.3695e-01, 1.8906e-01, 1.8714e-01, 4.6658e-02, 5.6129e-02,\n",
      "         3.6659e-02, 1.9580e-02, 1.8231e-03, 3.6080e-10],\n",
      "        [2.0803e-01, 1.9925e-01, 1.6875e-01, 1.8965e-01, 9.5533e-02, 6.2747e-02,\n",
      "         4.3035e-02, 2.7429e-02, 5.5783e-03, 2.5053e-09],\n",
      "        [1.9981e-01, 1.8802e-01, 1.6206e-01, 1.8879e-01, 1.1279e-01, 6.4988e-02,\n",
      "         4.5566e-02, 3.0515e-02, 7.4649e-03, 4.2068e-09],\n",
      "        [1.9179e-01, 1.7849e-01, 1.5600e-01, 1.8611e-01, 1.2579e-01, 6.8941e-02,\n",
      "         4.9197e-02, 3.4148e-02, 9.5363e-03, 6.2671e-09],\n",
      "        [1.8429e-01, 1.7261e-01, 1.5369e-01, 1.8445e-01, 1.3039e-01, 7.2172e-02,\n",
      "         5.2966e-02, 3.8195e-02, 1.1228e-02, 5.3817e-09],\n",
      "        [1.7784e-01, 1.6690e-01, 1.5044e-01, 1.8038e-01, 1.3388e-01, 7.6610e-02,\n",
      "         5.7539e-02, 4.2807e-02, 1.3594e-02, 5.7817e-09],\n",
      "        [1.7679e-01, 1.6591e-01, 1.4995e-01, 1.7960e-01, 1.3451e-01, 7.7274e-02,\n",
      "         5.8305e-02, 4.3572e-02, 1.4081e-02, 6.1674e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 126.00, Train Loss: 2.00, Val Loss: 12.32, Train BLEU: 30.07, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地 地球 上 最长 的 山脉 都 在 海洋\n",
      "Reference: and in the oceans , there are the longest\n",
      "Model: <SOS> and of the the , the the the the\n",
      "Attention Weights: tensor([[0.0757, 0.1043, 0.1325, 0.1044, 0.1413, 0.1074, 0.1472, 0.0827, 0.0659,\n",
      "         0.0385],\n",
      "        [0.1007, 0.1072, 0.1263, 0.1010, 0.1332, 0.1016, 0.1389, 0.0807, 0.0655,\n",
      "         0.0450],\n",
      "        [0.1228, 0.1070, 0.1190, 0.0955, 0.1222, 0.0954, 0.1284, 0.0801, 0.0693,\n",
      "         0.0602],\n",
      "        [0.1222, 0.1030, 0.1141, 0.0939, 0.1174, 0.0941, 0.1238, 0.0821, 0.0743,\n",
      "         0.0750],\n",
      "        [0.1202, 0.1012, 0.1128, 0.0934, 0.1164, 0.0939, 0.1230, 0.0828, 0.0759,\n",
      "         0.0802],\n",
      "        [0.1188, 0.1005, 0.1120, 0.0938, 0.1157, 0.0944, 0.1219, 0.0838, 0.0772,\n",
      "         0.0820],\n",
      "        [0.1165, 0.0996, 0.1111, 0.0941, 0.1149, 0.0947, 0.1209, 0.0848, 0.0788,\n",
      "         0.0846],\n",
      "        [0.1154, 0.0992, 0.1105, 0.0942, 0.1144, 0.0948, 0.1204, 0.0853, 0.0796,\n",
      "         0.0862],\n",
      "        [0.1144, 0.0990, 0.1103, 0.0943, 0.1142, 0.0950, 0.1201, 0.0857, 0.0801,\n",
      "         0.0869]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 都 知道 自己 正 冒 着 生命 的 危险\n",
      "Reference: we all knew we were risking our lives --\n",
      "Model: <SOS> and of the the , , the the the\n",
      "Attention Weights: tensor([[0.0741, 0.1013, 0.1452, 0.1057, 0.1248, 0.1030, 0.1290, 0.1015, 0.0957,\n",
      "         0.0198],\n",
      "        [0.1000, 0.1046, 0.1398, 0.1008, 0.1176, 0.0970, 0.1215, 0.0982, 0.0950,\n",
      "         0.0256],\n",
      "        [0.1209, 0.1057, 0.1323, 0.0957, 0.1102, 0.0920, 0.1140, 0.0957, 0.0975,\n",
      "         0.0359],\n",
      "        [0.1216, 0.1026, 0.1269, 0.0941, 0.1075, 0.0913, 0.1114, 0.0963, 0.1017,\n",
      "         0.0466],\n",
      "        [0.1199, 0.1009, 0.1250, 0.0935, 0.1068, 0.0912, 0.1110, 0.0970, 0.1037,\n",
      "         0.0509],\n",
      "        [0.1186, 0.1002, 0.1238, 0.0937, 0.1067, 0.0916, 0.1108, 0.0975, 0.1042,\n",
      "         0.0528],\n",
      "        [0.1175, 0.0998, 0.1229, 0.0940, 0.1066, 0.0920, 0.1107, 0.0978, 0.1044,\n",
      "         0.0543],\n",
      "        [0.1159, 0.0992, 0.1217, 0.0941, 0.1064, 0.0924, 0.1105, 0.0982, 0.1049,\n",
      "         0.0566],\n",
      "        [0.1151, 0.0990, 0.1213, 0.0942, 0.1064, 0.0926, 0.1105, 0.0984, 0.1051,\n",
      "         0.0574]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 127.00, Train Loss: 1.98, Val Loss: 12.34, Train BLEU: 30.49, Val BLEU: 0.32\n",
      "Sampling from training predictions...\n",
      "Source: 我们 用 的 是 深海 潜水 潜水艇 <UNK> 号 和\n",
      "Reference: we use the submarine alvin and we use cameras\n",
      "Model: <SOS> we use the the alvin , the the the\n",
      "Attention Weights: tensor([[0.1591, 0.2067, 0.1761, 0.1449, 0.1385, 0.0448, 0.0004, 0.0010, 0.0903,\n",
      "         0.0382],\n",
      "        [0.1754, 0.1733, 0.1468, 0.1265, 0.1395, 0.0694, 0.0051, 0.0119, 0.1042,\n",
      "         0.0479],\n",
      "        [0.1707, 0.1481, 0.1265, 0.1138, 0.1380, 0.0871, 0.0165, 0.0347, 0.1090,\n",
      "         0.0556],\n",
      "        [0.1540, 0.1304, 0.1156, 0.1076, 0.1366, 0.0994, 0.0337, 0.0565, 0.1046,\n",
      "         0.0617],\n",
      "        [0.1477, 0.1251, 0.1122, 0.1054, 0.1346, 0.1020, 0.0414, 0.0647, 0.1028,\n",
      "         0.0641],\n",
      "        [0.1454, 0.1226, 0.1109, 0.1043, 0.1333, 0.1027, 0.0450, 0.0681, 0.1027,\n",
      "         0.0650],\n",
      "        [0.1434, 0.1212, 0.1109, 0.1048, 0.1324, 0.1036, 0.0471, 0.0689, 0.1017,\n",
      "         0.0660],\n",
      "        [0.1408, 0.1196, 0.1103, 0.1048, 0.1316, 0.1048, 0.0497, 0.0706, 0.1008,\n",
      "         0.0670],\n",
      "        [0.1383, 0.1183, 0.1100, 0.1049, 0.1312, 0.1058, 0.0514, 0.0713, 0.1005,\n",
      "         0.0684]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 因此 毫无 毫无疑问 无疑 疑问 他 的 孩子 应当 受到\n",
      "Reference: there was no question that his children would receive\n",
      "Model: <SOS> most of the the , the the the the\n",
      "Attention Weights: tensor([[1.2866e-01, 2.0249e-01, 2.1912e-01, 2.0398e-01, 2.1461e-01, 9.8394e-03,\n",
      "         1.5539e-02, 5.6565e-03, 1.1333e-04, 5.8558e-12],\n",
      "        [1.5748e-01, 2.0089e-01, 2.0519e-01, 1.8720e-01, 2.0425e-01, 1.9833e-02,\n",
      "         1.7428e-02, 7.3434e-03, 3.8036e-04, 5.4337e-11],\n",
      "        [1.8531e-01, 1.9120e-01, 1.8471e-01, 1.6837e-01, 1.9052e-01, 4.4157e-02,\n",
      "         2.3305e-02, 1.1056e-02, 1.3668e-03, 2.8513e-10],\n",
      "        [1.8018e-01, 1.6879e-01, 1.6569e-01, 1.5569e-01, 1.8852e-01, 8.7119e-02,\n",
      "         3.1583e-02, 1.7838e-02, 4.5994e-03, 2.3045e-09],\n",
      "        [1.7427e-01, 1.5972e-01, 1.5917e-01, 1.5057e-01, 1.8817e-01, 1.0616e-01,\n",
      "         3.4621e-02, 2.0810e-02, 6.4965e-03, 4.5934e-09],\n",
      "        [1.6976e-01, 1.5365e-01, 1.5397e-01, 1.4605e-01, 1.8414e-01, 1.1737e-01,\n",
      "         4.0384e-02, 2.5647e-02, 9.0274e-03, 7.0701e-09],\n",
      "        [1.6495e-01, 1.5039e-01, 1.5137e-01, 1.4446e-01, 1.8143e-01, 1.2237e-01,\n",
      "         4.4637e-02, 2.9524e-02, 1.0863e-02, 6.6067e-09],\n",
      "        [1.6179e-01, 1.4799e-01, 1.4946e-01, 1.4340e-01, 1.7911e-01, 1.2568e-01,\n",
      "         4.7817e-02, 3.2417e-02, 1.2339e-02, 6.7651e-09],\n",
      "        [1.6056e-01, 1.4706e-01, 1.4884e-01, 1.4301e-01, 1.7830e-01, 1.2680e-01,\n",
      "         4.8911e-02, 3.3504e-02, 1.3014e-02, 7.0838e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 128.00, Train Loss: 1.95, Val Loss: 12.36, Train BLEU: 31.88, Val BLEU: 0.32\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想 海洋 占 了 地球 球面 面积 的 75\n",
      "Reference: when you think about it , the oceans are\n",
      "Model: <SOS> when you think about , , , , the\n",
      "Attention Weights: tensor([[0.0750, 0.0950, 0.1559, 0.1013, 0.1024, 0.1662, 0.1395, 0.1178, 0.0466,\n",
      "         0.0003],\n",
      "        [0.1014, 0.0992, 0.1484, 0.0968, 0.0965, 0.1577, 0.1331, 0.1138, 0.0503,\n",
      "         0.0028],\n",
      "        [0.1157, 0.0967, 0.1373, 0.0909, 0.0907, 0.1485, 0.1281, 0.1153, 0.0625,\n",
      "         0.0142],\n",
      "        [0.1147, 0.0939, 0.1297, 0.0892, 0.0893, 0.1427, 0.1252, 0.1160, 0.0710,\n",
      "         0.0283],\n",
      "        [0.1138, 0.0927, 0.1272, 0.0883, 0.0885, 0.1399, 0.1235, 0.1155, 0.0737,\n",
      "         0.0370],\n",
      "        [0.1128, 0.0921, 0.1254, 0.0881, 0.0884, 0.1383, 0.1227, 0.1153, 0.0752,\n",
      "         0.0418],\n",
      "        [0.1117, 0.0919, 0.1237, 0.0883, 0.0887, 0.1361, 0.1216, 0.1149, 0.0770,\n",
      "         0.0460],\n",
      "        [0.1100, 0.0913, 0.1223, 0.0884, 0.0888, 0.1349, 0.1213, 0.1152, 0.0789,\n",
      "         0.0487],\n",
      "        [0.1089, 0.0911, 0.1217, 0.0886, 0.0891, 0.1344, 0.1212, 0.1153, 0.0799,\n",
      "         0.0498]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 她 两年 年前 退休 了 结果 却 把 我家 变成\n",
      "Reference: she retired two years ago , only to turn\n",
      "Model: <SOS> most of the the the , the the the\n",
      "Attention Weights: tensor([[2.6750e-01, 2.9952e-01, 1.9946e-01, 1.4920e-01, 8.2861e-02, 1.4640e-03,\n",
      "         3.1064e-11, 3.1064e-11, 3.1064e-11, 3.1064e-11],\n",
      "        [2.9746e-01, 2.8604e-01, 1.8995e-01, 1.4054e-01, 8.3037e-02, 2.9807e-03,\n",
      "         2.5758e-10, 2.5758e-10, 2.5758e-10, 2.5758e-10],\n",
      "        [3.2518e-01, 2.6844e-01, 1.7724e-01, 1.3308e-01, 8.7935e-02, 8.1240e-03,\n",
      "         1.2496e-09, 1.2496e-09, 1.2496e-09, 1.2496e-09],\n",
      "        [3.0597e-01, 2.4415e-01, 1.7595e-01, 1.4190e-01, 1.0900e-01, 2.3024e-02,\n",
      "         7.7516e-09, 7.7516e-09, 7.7516e-09, 7.7516e-09],\n",
      "        [2.9521e-01, 2.3530e-01, 1.7592e-01, 1.4561e-01, 1.1733e-01, 3.0620e-02,\n",
      "         1.3874e-08, 1.3874e-08, 1.3874e-08, 1.3874e-08],\n",
      "        [2.8635e-01, 2.2898e-01, 1.7581e-01, 1.4863e-01, 1.2386e-01, 3.6377e-02,\n",
      "         1.9236e-08, 1.9236e-08, 1.9236e-08, 1.9236e-08],\n",
      "        [2.7733e-01, 2.2511e-01, 1.7693e-01, 1.5199e-01, 1.2922e-01, 3.9423e-02,\n",
      "         1.5592e-08, 1.5592e-08, 1.5592e-08, 1.5592e-08],\n",
      "        [2.6723e-01, 2.2065e-01, 1.7791e-01, 1.5522e-01, 1.3436e-01, 4.4644e-02,\n",
      "         1.5915e-08, 1.5915e-08, 1.5915e-08, 1.5915e-08],\n",
      "        [2.6461e-01, 2.1940e-01, 1.7811e-01, 1.5599e-01, 1.3566e-01, 4.6239e-02,\n",
      "         1.7882e-08, 1.7882e-08, 1.7882e-08, 1.7882e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 129.00, Train Loss: 1.93, Val Loss: 12.37, Train BLEU: 33.81, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 这位 是 比尔 <UNK> 我 是 大卫 <UNK>\n",
      "Reference: this is bill lange . i &apos;m dave gallo\n",
      "Model: <SOS> this is bill lange . i &apos;m dave gallo\n",
      "Attention Weights: tensor([[0.0548, 0.0067, 0.1981, 0.1891, 0.0218, 0.0073, 0.2553, 0.2129, 0.0536,\n",
      "         0.0004],\n",
      "        [0.0795, 0.0146, 0.2136, 0.1874, 0.0356, 0.0161, 0.2265, 0.1756, 0.0500,\n",
      "         0.0010],\n",
      "        [0.1032, 0.0396, 0.2071, 0.1643, 0.0638, 0.0429, 0.1868, 0.1370, 0.0509,\n",
      "         0.0044],\n",
      "        [0.1087, 0.0607, 0.1849, 0.1469, 0.0855, 0.0646, 0.1613, 0.1213, 0.0560,\n",
      "         0.0103],\n",
      "        [0.1075, 0.0725, 0.1738, 0.1370, 0.0954, 0.0770, 0.1505, 0.1137, 0.0578,\n",
      "         0.0148],\n",
      "        [0.1098, 0.0800, 0.1663, 0.1310, 0.1010, 0.0845, 0.1402, 0.1076, 0.0604,\n",
      "         0.0192],\n",
      "        [0.1111, 0.0843, 0.1599, 0.1277, 0.1029, 0.0891, 0.1344, 0.1051, 0.0629,\n",
      "         0.0226],\n",
      "        [0.1116, 0.0867, 0.1565, 0.1257, 0.1043, 0.0915, 0.1313, 0.1036, 0.0641,\n",
      "         0.0247],\n",
      "        [0.1117, 0.0877, 0.1554, 0.1250, 0.1048, 0.0926, 0.1302, 0.1029, 0.0643,\n",
      "         0.0254]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 她 两年 年前 退休 了 结果 却 把 我家 变成\n",
      "Reference: she retired two years ago , only to turn\n",
      "Model: <SOS> most of the the the , the the the\n",
      "Attention Weights: tensor([[2.6822e-01, 3.0159e-01, 2.0012e-01, 1.4648e-01, 8.2043e-02, 1.5442e-03,\n",
      "         3.4104e-11, 3.4104e-11, 3.4104e-11, 3.4104e-11],\n",
      "        [2.9827e-01, 2.8757e-01, 1.9042e-01, 1.3825e-01, 8.2390e-02, 3.1017e-03,\n",
      "         2.7291e-10, 2.7291e-10, 2.7291e-10, 2.7291e-10],\n",
      "        [3.2669e-01, 2.6949e-01, 1.7728e-01, 1.3102e-01, 8.7186e-02, 8.3368e-03,\n",
      "         1.3019e-09, 1.3019e-09, 1.3019e-09, 1.3019e-09],\n",
      "        [3.0784e-01, 2.4494e-01, 1.7599e-01, 1.3986e-01, 1.0796e-01, 2.3410e-02,\n",
      "         7.9774e-09, 7.9774e-09, 7.9774e-09, 7.9774e-09],\n",
      "        [2.9729e-01, 2.3598e-01, 1.7592e-01, 1.4354e-01, 1.1620e-01, 3.1077e-02,\n",
      "         1.4246e-08, 1.4246e-08, 1.4246e-08, 1.4246e-08],\n",
      "        [2.8864e-01, 2.2981e-01, 1.7585e-01, 1.4653e-01, 1.2251e-01, 3.6663e-02,\n",
      "         1.9498e-08, 1.9498e-08, 1.9498e-08, 1.9498e-08],\n",
      "        [2.7900e-01, 2.2577e-01, 1.7708e-01, 1.5016e-01, 1.2810e-01, 3.9891e-02,\n",
      "         1.5802e-08, 1.5802e-08, 1.5802e-08, 1.5802e-08],\n",
      "        [2.6880e-01, 2.2126e-01, 1.7803e-01, 1.5352e-01, 1.3324e-01, 4.5146e-02,\n",
      "         1.6231e-08, 1.6231e-08, 1.6231e-08, 1.6231e-08],\n",
      "        [2.6610e-01, 2.1998e-01, 1.7825e-01, 1.5436e-01, 1.3457e-01, 4.6745e-02,\n",
      "         1.8204e-08, 1.8204e-08, 1.8204e-08, 1.8204e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 130.00, Train Loss: 1.90, Val Loss: 12.38, Train BLEU: 34.80, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本 基本上 都 没有 被 开发 发过 但是 像\n",
      "Reference: it &apos;s mostly unexplored , and yet there are\n",
      "Model: <SOS> people of the unexplored , and the the the\n",
      "Attention Weights: tensor([[0.0786, 0.1044, 0.1522, 0.1118, 0.1214, 0.1060, 0.1220, 0.0958, 0.0897,\n",
      "         0.0182],\n",
      "        [0.1057, 0.1068, 0.1461, 0.1050, 0.1149, 0.0989, 0.1162, 0.0933, 0.0902,\n",
      "         0.0229],\n",
      "        [0.1300, 0.1081, 0.1374, 0.0987, 0.1073, 0.0930, 0.1091, 0.0909, 0.0930,\n",
      "         0.0324],\n",
      "        [0.1290, 0.1043, 0.1324, 0.0963, 0.1053, 0.0921, 0.1079, 0.0924, 0.0982,\n",
      "         0.0421],\n",
      "        [0.1264, 0.1026, 0.1304, 0.0956, 0.1049, 0.0920, 0.1078, 0.0934, 0.1007,\n",
      "         0.0462],\n",
      "        [0.1247, 0.1020, 0.1285, 0.0960, 0.1048, 0.0926, 0.1075, 0.0941, 0.1012,\n",
      "         0.0487],\n",
      "        [0.1229, 0.1016, 0.1274, 0.0962, 0.1048, 0.0930, 0.1076, 0.0946, 0.1016,\n",
      "         0.0504],\n",
      "        [0.1212, 0.1011, 0.1262, 0.0962, 0.1046, 0.0932, 0.1074, 0.0951, 0.1024,\n",
      "         0.0526],\n",
      "        [0.1203, 0.1009, 0.1258, 0.0962, 0.1046, 0.0934, 0.1075, 0.0953, 0.1026,\n",
      "         0.0534]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天 要 走 不同 的 路线 这样 才 没有\n",
      "Reference: each day , we took a different route so\n",
      "Model: <SOS> and of the the , , , the the\n",
      "Attention Weights: tensor([[0.0794, 0.1064, 0.1401, 0.1085, 0.1353, 0.1069, 0.1412, 0.0804, 0.0624,\n",
      "         0.0395],\n",
      "        [0.1055, 0.1086, 0.1321, 0.1041, 0.1288, 0.1010, 0.1352, 0.0780, 0.0613,\n",
      "         0.0453],\n",
      "        [0.1312, 0.1084, 0.1231, 0.0973, 0.1178, 0.0942, 0.1251, 0.0773, 0.0650,\n",
      "         0.0605],\n",
      "        [0.1287, 0.1040, 0.1181, 0.0953, 0.1142, 0.0932, 0.1222, 0.0795, 0.0699,\n",
      "         0.0750],\n",
      "        [0.1261, 0.1023, 0.1166, 0.0948, 0.1133, 0.0931, 0.1215, 0.0804, 0.0717,\n",
      "         0.0801],\n",
      "        [0.1238, 0.1016, 0.1153, 0.0954, 0.1127, 0.0937, 0.1202, 0.0817, 0.0735,\n",
      "         0.0820],\n",
      "        [0.1211, 0.1008, 0.1143, 0.0955, 0.1121, 0.0941, 0.1193, 0.0828, 0.0752,\n",
      "         0.0848],\n",
      "        [0.1198, 0.1003, 0.1136, 0.0954, 0.1116, 0.0941, 0.1189, 0.0833, 0.0761,\n",
      "         0.0868],\n",
      "        [0.1185, 0.1000, 0.1133, 0.0955, 0.1115, 0.0943, 0.1186, 0.0838, 0.0768,\n",
      "         0.0877]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 131.00, Train Loss: 1.88, Val Loss: 12.40, Train BLEU: 34.85, Val BLEU: 0.32\n",
      "Sampling from training predictions...\n",
      "Source: <UNK> 塞尔 <UNK> <UNK> 斯特 说 过 真正 的 探索\n",
      "Reference: marcel proust said , &quot; the true voyage of\n",
      "Model: <SOS> marcel proust said , &quot; true true voyage voyage\n",
      "Attention Weights: tensor([[2.2598e-06, 1.4724e-06, 6.2049e-06, 3.8673e-05, 1.9483e-03, 1.5917e-01,\n",
      "         2.8547e-01, 2.6318e-01, 1.9069e-01, 9.9491e-02],\n",
      "        [5.8465e-06, 3.7917e-06, 1.6694e-05, 9.8984e-05, 4.2795e-03, 2.1429e-01,\n",
      "         2.9162e-01, 2.4172e-01, 1.6558e-01, 8.2397e-02],\n",
      "        [2.1301e-04, 1.5559e-04, 5.3721e-04, 2.2754e-03, 3.6073e-02, 2.9286e-01,\n",
      "         2.5907e-01, 1.9629e-01, 1.3602e-01, 7.6512e-02],\n",
      "        [1.6821e-03, 1.3363e-03, 3.4896e-03, 1.1075e-02, 8.7094e-02, 2.8776e-01,\n",
      "         2.2248e-01, 1.7189e-01, 1.2696e-01, 8.6244e-02],\n",
      "        [4.9479e-03, 4.0639e-03, 9.1083e-03, 2.3925e-02, 1.2099e-01, 2.6067e-01,\n",
      "         1.9604e-01, 1.5922e-01, 1.2552e-01, 9.5510e-02],\n",
      "        [8.0446e-03, 6.7269e-03, 1.4192e-02, 3.3986e-02, 1.3630e-01, 2.4035e-01,\n",
      "         1.8229e-01, 1.5243e-01, 1.2468e-01, 1.0100e-01],\n",
      "        [1.0560e-02, 8.8919e-03, 1.8004e-02, 4.0913e-02, 1.4385e-01, 2.2875e-01,\n",
      "         1.7453e-01, 1.4795e-01, 1.2321e-01, 1.0334e-01],\n",
      "        [1.1661e-02, 9.8635e-03, 1.9579e-02, 4.3505e-02, 1.4608e-01, 2.2461e-01,\n",
      "         1.7178e-01, 1.4629e-01, 1.2262e-01, 1.0402e-01],\n",
      "        [1.2162e-02, 1.0311e-02, 2.0268e-02, 4.4553e-02, 1.4664e-01, 2.2259e-01,\n",
      "         1.7071e-01, 1.4571e-01, 1.2255e-01, 1.0452e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 不知 知道 那 意味 意味着 什么 但是 我 能\n",
      "Reference: i didn &apos;t know what it meant , but\n",
      "Model: <SOS> we of the the the , the the the\n",
      "Attention Weights: tensor([[0.1273, 0.1605, 0.1633, 0.1931, 0.1737, 0.0915, 0.0706, 0.0031, 0.0046,\n",
      "         0.0122],\n",
      "        [0.1503, 0.1409, 0.1367, 0.1626, 0.1542, 0.0893, 0.0917, 0.0222, 0.0281,\n",
      "         0.0240],\n",
      "        [0.1472, 0.1188, 0.1122, 0.1336, 0.1341, 0.0879, 0.1045, 0.0584, 0.0692,\n",
      "         0.0342],\n",
      "        [0.1320, 0.1036, 0.0990, 0.1201, 0.1239, 0.0872, 0.1127, 0.0883, 0.0930,\n",
      "         0.0402],\n",
      "        [0.1267, 0.0989, 0.0950, 0.1155, 0.1202, 0.0865, 0.1145, 0.0989, 0.1000,\n",
      "         0.0438],\n",
      "        [0.1256, 0.0980, 0.0945, 0.1148, 0.1196, 0.0867, 0.1147, 0.1005, 0.1010,\n",
      "         0.0445],\n",
      "        [0.1247, 0.0978, 0.0949, 0.1148, 0.1196, 0.0874, 0.1147, 0.1006, 0.1002,\n",
      "         0.0454],\n",
      "        [0.1232, 0.0976, 0.0953, 0.1141, 0.1187, 0.0880, 0.1142, 0.1009, 0.1005,\n",
      "         0.0475],\n",
      "        [0.1215, 0.0973, 0.0954, 0.1137, 0.1183, 0.0886, 0.1146, 0.1009, 0.1007,\n",
      "         0.0491]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 132.00, Train Loss: 1.86, Val Loss: 12.41, Train BLEU: 34.77, Val BLEU: 0.32\n",
      "Sampling from training predictions...\n",
      "Source: 我们 用 的 是 深海 潜水 潜水艇 <UNK> 号 和\n",
      "Reference: we use the submarine alvin and we use cameras\n",
      "Model: <SOS> we use the submarine alvin and the the the\n",
      "Attention Weights: tensor([[0.1611, 0.2036, 0.1775, 0.1455, 0.1482, 0.0491, 0.0004, 0.0012, 0.0786,\n",
      "         0.0347],\n",
      "        [0.1798, 0.1706, 0.1468, 0.1257, 0.1483, 0.0732, 0.0054, 0.0127, 0.0941,\n",
      "         0.0434],\n",
      "        [0.1764, 0.1443, 0.1235, 0.1098, 0.1424, 0.0902, 0.0184, 0.0395, 0.1035,\n",
      "         0.0520],\n",
      "        [0.1569, 0.1259, 0.1119, 0.1032, 0.1408, 0.1033, 0.0376, 0.0642, 0.0988,\n",
      "         0.0573],\n",
      "        [0.1500, 0.1206, 0.1086, 0.1010, 0.1383, 0.1058, 0.0462, 0.0731, 0.0969,\n",
      "         0.0595],\n",
      "        [0.1475, 0.1180, 0.1070, 0.0999, 0.1368, 0.1064, 0.0502, 0.0771, 0.0968,\n",
      "         0.0604],\n",
      "        [0.1441, 0.1160, 0.1066, 0.1002, 0.1353, 0.1077, 0.0538, 0.0791, 0.0955,\n",
      "         0.0617],\n",
      "        [0.1410, 0.1144, 0.1059, 0.1001, 0.1340, 0.1089, 0.0570, 0.0813, 0.0947,\n",
      "         0.0626],\n",
      "        [0.1380, 0.1130, 0.1054, 0.1001, 0.1333, 0.1100, 0.0592, 0.0829, 0.0944,\n",
      "         0.0638]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 在 塔利 塔利班 控制 阿富汗 的 那些 年 我 记得\n",
      "Reference: during taliban years , i remember there were times\n",
      "Model: <SOS> the of the the the the the the the\n",
      "Attention Weights: tensor([[0.0916, 0.1129, 0.1170, 0.1194, 0.1216, 0.1498, 0.1084, 0.1358, 0.0435,\n",
      "         0.0001],\n",
      "        [0.1166, 0.1150, 0.1150, 0.1152, 0.1154, 0.1427, 0.1016, 0.1294, 0.0485,\n",
      "         0.0006],\n",
      "        [0.1372, 0.1130, 0.1092, 0.1081, 0.1076, 0.1318, 0.0973, 0.1278, 0.0636,\n",
      "         0.0044],\n",
      "        [0.1365, 0.1089, 0.1052, 0.1045, 0.1043, 0.1270, 0.0963, 0.1287, 0.0767,\n",
      "         0.0119],\n",
      "        [0.1360, 0.1070, 0.1032, 0.1026, 0.1024, 0.1247, 0.0953, 0.1286, 0.0823,\n",
      "         0.0178],\n",
      "        [0.1355, 0.1059, 0.1021, 0.1015, 0.1014, 0.1231, 0.0948, 0.1281, 0.0851,\n",
      "         0.0224],\n",
      "        [0.1333, 0.1052, 0.1019, 0.1014, 0.1014, 0.1223, 0.0951, 0.1275, 0.0870,\n",
      "         0.0250],\n",
      "        [0.1308, 0.1045, 0.1015, 0.1011, 0.1011, 0.1214, 0.0954, 0.1272, 0.0893,\n",
      "         0.0277],\n",
      "        [0.1291, 0.1040, 0.1011, 0.1009, 0.1010, 0.1208, 0.0956, 0.1269, 0.0910,\n",
      "         0.0296]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 133.00, Train Loss: 1.83, Val Loss: 12.43, Train BLEU: 37.62, Val BLEU: 0.32\n",
      "Sampling from training predictions...\n",
      "Source: 地球 的 大部 大部分 部分 都 是 海水 <EOS> <PAD>\n",
      "Reference: most of the planet is ocean water . <EOS>\n",
      "Model: <SOS> most &apos;s a planet different . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.5975e-01, 1.8733e-01, 1.9535e-01, 2.7307e-01, 9.3277e-02, 4.2503e-02,\n",
      "         2.6594e-02, 2.1728e-02, 3.9565e-04, 1.1132e-11],\n",
      "        [1.8563e-01, 1.8457e-01, 1.8573e-01, 2.6022e-01, 8.9649e-02, 4.2430e-02,\n",
      "         2.7124e-02, 2.3753e-02, 8.8415e-04, 9.4052e-11],\n",
      "        [2.2789e-01, 1.8136e-01, 1.6981e-01, 2.2957e-01, 8.5037e-02, 4.4233e-02,\n",
      "         3.0198e-02, 2.8890e-02, 3.0027e-03, 5.4326e-10],\n",
      "        [2.2141e-01, 1.6407e-01, 1.5884e-01, 2.1939e-01, 9.0450e-02, 5.2787e-02,\n",
      "         3.9704e-02, 4.3434e-02, 9.9189e-03, 4.4172e-09],\n",
      "        [2.1439e-01, 1.5584e-01, 1.5354e-01, 2.1723e-01, 9.2628e-02, 5.6519e-02,\n",
      "         4.4201e-02, 5.1008e-02, 1.4644e-02, 8.3856e-09],\n",
      "        [2.0447e-01, 1.4925e-01, 1.4890e-01, 2.1256e-01, 9.5800e-02, 6.1227e-02,\n",
      "         4.9557e-02, 5.8757e-02, 1.9486e-02, 1.0801e-08],\n",
      "        [1.9486e-01, 1.4597e-01, 1.4675e-01, 2.0683e-01, 9.8741e-02, 6.5441e-02,\n",
      "         5.4096e-02, 6.4225e-02, 2.3081e-02, 1.0005e-08],\n",
      "        [1.8945e-01, 1.4392e-01, 1.4531e-01, 2.0274e-01, 1.0051e-01, 6.8029e-02,\n",
      "         5.6895e-02, 6.7547e-02, 2.5596e-02, 1.1794e-08],\n",
      "        [1.8849e-01, 1.4351e-01, 1.4507e-01, 2.0201e-01, 1.0082e-01, 6.8498e-02,\n",
      "         5.7399e-02, 6.8094e-02, 2.6108e-02, 1.2687e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把 书 放在 食品 杂货 袋中 这样 别人 就\n",
      "Reference: we would cover our books in grocery bags so\n",
      "Model: <SOS> we biodiversity the the the , the the the\n",
      "Attention Weights: tensor([[0.0782, 0.1062, 0.1072, 0.1005, 0.1778, 0.0940, 0.0882, 0.1539, 0.0559,\n",
      "         0.0381],\n",
      "        [0.1054, 0.1065, 0.1027, 0.0959, 0.1682, 0.0895, 0.0843, 0.1477, 0.0553,\n",
      "         0.0445],\n",
      "        [0.1361, 0.1072, 0.0971, 0.0893, 0.1491, 0.0836, 0.0798, 0.1372, 0.0596,\n",
      "         0.0611],\n",
      "        [0.1336, 0.1031, 0.0949, 0.0880, 0.1414, 0.0830, 0.0801, 0.1352, 0.0645,\n",
      "         0.0762],\n",
      "        [0.1309, 0.1016, 0.0944, 0.0878, 0.1384, 0.0832, 0.0807, 0.1341, 0.0666,\n",
      "         0.0823],\n",
      "        [0.1267, 0.1009, 0.0948, 0.0887, 0.1352, 0.0844, 0.0822, 0.1316, 0.0693,\n",
      "         0.0861],\n",
      "        [0.1234, 0.1003, 0.0949, 0.0892, 0.1336, 0.0852, 0.0832, 0.1306, 0.0711,\n",
      "         0.0886],\n",
      "        [0.1217, 0.1001, 0.0950, 0.0894, 0.1327, 0.0856, 0.0836, 0.1300, 0.0720,\n",
      "         0.0899],\n",
      "        [0.1209, 0.1000, 0.0950, 0.0896, 0.1323, 0.0858, 0.0839, 0.1297, 0.0724,\n",
      "         0.0904]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 134.00, Train Loss: 1.81, Val Loss: 12.44, Train BLEU: 37.85, Val BLEU: 0.32\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克 泰坦尼克号 坦尼 尼克 号 是 拿 了 不少\n",
      "Reference: the truth of the matter is that the titanic\n",
      "Model: <SOS> the truth of the matter the the the the\n",
      "Attention Weights: tensor([[0.0175, 0.0036, 0.0046, 0.0179, 0.2087, 0.2017, 0.1825, 0.1533, 0.1227,\n",
      "         0.0874],\n",
      "        [0.0338, 0.0160, 0.0204, 0.0596, 0.2327, 0.1852, 0.1540, 0.1254, 0.0976,\n",
      "         0.0752],\n",
      "        [0.0645, 0.0594, 0.0767, 0.1694, 0.1909, 0.1303, 0.1018, 0.0825, 0.0661,\n",
      "         0.0585],\n",
      "        [0.0774, 0.0908, 0.1095, 0.2039, 0.1528, 0.1011, 0.0810, 0.0681, 0.0574,\n",
      "         0.0580],\n",
      "        [0.0833, 0.1065, 0.1226, 0.2045, 0.1360, 0.0909, 0.0750, 0.0647, 0.0562,\n",
      "         0.0603],\n",
      "        [0.0875, 0.1153, 0.1276, 0.1973, 0.1266, 0.0864, 0.0730, 0.0646, 0.0575,\n",
      "         0.0642],\n",
      "        [0.0893, 0.1160, 0.1259, 0.1868, 0.1217, 0.0860, 0.0747, 0.0677, 0.0616,\n",
      "         0.0702],\n",
      "        [0.0907, 0.1160, 0.1245, 0.1799, 0.1192, 0.0862, 0.0760, 0.0697, 0.0642,\n",
      "         0.0738],\n",
      "        [0.0911, 0.1157, 0.1236, 0.1764, 0.1182, 0.0864, 0.0767, 0.0707, 0.0655,\n",
      "         0.0757]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 总是 担心 会 被 塔利 塔利班 发现 <EOS> <PAD>\n",
      "Reference: we always wondered what they knew about us .\n",
      "Model: <SOS> it &apos;s got to about about . . <EOS>\n",
      "Attention Weights: tensor([[0.0791, 0.1264, 0.2081, 0.1791, 0.1502, 0.1561, 0.0741, 0.0020, 0.0195,\n",
      "         0.0054],\n",
      "        [0.1045, 0.1647, 0.1674, 0.1421, 0.1238, 0.1380, 0.0921, 0.0193, 0.0363,\n",
      "         0.0118],\n",
      "        [0.1130, 0.1771, 0.1386, 0.1169, 0.1051, 0.1229, 0.1040, 0.0575, 0.0473,\n",
      "         0.0177],\n",
      "        [0.1095, 0.1714, 0.1229, 0.1072, 0.0990, 0.1181, 0.1113, 0.0859, 0.0523,\n",
      "         0.0225],\n",
      "        [0.1082, 0.1678, 0.1177, 0.1040, 0.0968, 0.1157, 0.1121, 0.0976, 0.0551,\n",
      "         0.0251],\n",
      "        [0.1079, 0.1661, 0.1145, 0.1021, 0.0958, 0.1144, 0.1127, 0.1032, 0.0567,\n",
      "         0.0265],\n",
      "        [0.1077, 0.1641, 0.1118, 0.1007, 0.0952, 0.1133, 0.1131, 0.1072, 0.0582,\n",
      "         0.0286],\n",
      "        [0.1075, 0.1607, 0.1094, 0.0995, 0.0948, 0.1126, 0.1137, 0.1111, 0.0599,\n",
      "         0.0308],\n",
      "        [0.1073, 0.1591, 0.1086, 0.0993, 0.0949, 0.1126, 0.1140, 0.1118, 0.0605,\n",
      "         0.0318]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 135.00, Train Loss: 1.78, Val Loss: 12.44, Train BLEU: 39.91, Val BLEU: 0.32\n",
      "Sampling from training predictions...\n",
      "Source: 其实 它们 都 是 由 单独 的 动物 结合 合在\n",
      "Reference: these are all individual animals banding together to make\n",
      "Model: <SOS> these are all individual animals banding together make make\n",
      "Attention Weights: tensor([[0.0889, 0.1052, 0.1101, 0.1144, 0.1184, 0.1696, 0.1091, 0.1419, 0.0424,\n",
      "         0.0001],\n",
      "        [0.1113, 0.1070, 0.1087, 0.1109, 0.1130, 0.1629, 0.1021, 0.1364, 0.0471,\n",
      "         0.0006],\n",
      "        [0.1318, 0.1056, 0.1035, 0.1041, 0.1053, 0.1499, 0.0976, 0.1357, 0.0627,\n",
      "         0.0039],\n",
      "        [0.1309, 0.1018, 0.0998, 0.1008, 0.1020, 0.1436, 0.0961, 0.1370, 0.0767,\n",
      "         0.0112],\n",
      "        [0.1305, 0.1002, 0.0979, 0.0990, 0.1002, 0.1405, 0.0952, 0.1369, 0.0826,\n",
      "         0.0169],\n",
      "        [0.1301, 0.0992, 0.0969, 0.0979, 0.0991, 0.1381, 0.0947, 0.1362, 0.0861,\n",
      "         0.0217],\n",
      "        [0.1283, 0.0988, 0.0967, 0.0978, 0.0990, 0.1360, 0.0949, 0.1350, 0.0885,\n",
      "         0.0251],\n",
      "        [0.1259, 0.0982, 0.0964, 0.0975, 0.0987, 0.1344, 0.0952, 0.1345, 0.0910,\n",
      "         0.0282],\n",
      "        [0.1243, 0.0978, 0.0961, 0.0974, 0.0986, 0.1333, 0.0954, 0.1340, 0.0928,\n",
      "         0.0303]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在 一个 房屋 房屋里 屋里 我们 100 多 人\n",
      "Reference: the school was in a house , more than\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0170, 0.0095, 0.1367, 0.1370, 0.1157, 0.2193, 0.1797, 0.0823, 0.0589,\n",
      "         0.0440],\n",
      "        [0.0300, 0.0270, 0.1462, 0.1308, 0.1097, 0.2077, 0.1699, 0.0770, 0.0556,\n",
      "         0.0463],\n",
      "        [0.0655, 0.1016, 0.1476, 0.1145, 0.0930, 0.1672, 0.1404, 0.0667, 0.0517,\n",
      "         0.0518],\n",
      "        [0.0781, 0.1391, 0.1304, 0.1018, 0.0853, 0.1534, 0.1319, 0.0652, 0.0534,\n",
      "         0.0614],\n",
      "        [0.0814, 0.1472, 0.1234, 0.0985, 0.0840, 0.1476, 0.1292, 0.0661, 0.0557,\n",
      "         0.0669],\n",
      "        [0.0835, 0.1522, 0.1186, 0.0960, 0.0836, 0.1436, 0.1276, 0.0675, 0.0576,\n",
      "         0.0696],\n",
      "        [0.0850, 0.1532, 0.1155, 0.0952, 0.0839, 0.1405, 0.1260, 0.0689, 0.0596,\n",
      "         0.0723],\n",
      "        [0.0851, 0.1506, 0.1133, 0.0947, 0.0843, 0.1394, 0.1258, 0.0703, 0.0614,\n",
      "         0.0752],\n",
      "        [0.0854, 0.1486, 0.1118, 0.0945, 0.0847, 0.1383, 0.1254, 0.0714, 0.0628,\n",
      "         0.0771]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 136.00, Train Loss: 1.76, Val Loss: 12.45, Train BLEU: 39.39, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这 有 不少 精彩 的 泰坦 泰坦尼克 坦尼 尼克\n",
      "Reference: we &apos;ve got some of the most incredible video\n",
      "Model: <SOS> we &apos;ve got of of the the the the\n",
      "Attention Weights: tensor([[0.1191, 0.1354, 0.1466, 0.2314, 0.1989, 0.0830, 0.0705, 0.0027, 0.0039,\n",
      "         0.0085],\n",
      "        [0.1385, 0.1205, 0.1244, 0.2057, 0.1838, 0.0809, 0.0915, 0.0173, 0.0211,\n",
      "         0.0162],\n",
      "        [0.1387, 0.1027, 0.1026, 0.1687, 0.1619, 0.0816, 0.1070, 0.0517, 0.0602,\n",
      "         0.0249],\n",
      "        [0.1237, 0.0890, 0.0901, 0.1504, 0.1490, 0.0820, 0.1167, 0.0840, 0.0849,\n",
      "         0.0301],\n",
      "        [0.1180, 0.0845, 0.0859, 0.1425, 0.1429, 0.0818, 0.1195, 0.0978, 0.0935,\n",
      "         0.0336],\n",
      "        [0.1167, 0.0837, 0.0854, 0.1411, 0.1420, 0.0823, 0.1201, 0.0997, 0.0947,\n",
      "         0.0343],\n",
      "        [0.1153, 0.0836, 0.0856, 0.1393, 0.1407, 0.0832, 0.1206, 0.1011, 0.0949,\n",
      "         0.0356],\n",
      "        [0.1138, 0.0837, 0.0860, 0.1366, 0.1385, 0.0842, 0.1205, 0.1026, 0.0962,\n",
      "         0.0380],\n",
      "        [0.1120, 0.0836, 0.0861, 0.1351, 0.1374, 0.0849, 0.1212, 0.1029, 0.0969,\n",
      "         0.0399]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 因此 毫无 毫无疑问 无疑 疑问 他 的 孩子 应当 受到\n",
      "Reference: there was no question that his children would receive\n",
      "Model: <SOS> most of the the , the the the the\n",
      "Attention Weights: tensor([[1.4192e-01, 1.9702e-01, 2.1818e-01, 2.0147e-01, 2.2380e-01, 8.6011e-03,\n",
      "         6.3754e-03, 2.5482e-03, 8.9482e-05, 7.7451e-12],\n",
      "        [1.6768e-01, 1.9615e-01, 2.0665e-01, 1.8659e-01, 2.1715e-01, 1.5432e-02,\n",
      "         7.0343e-03, 3.0990e-03, 2.1932e-04, 4.8304e-11],\n",
      "        [2.0106e-01, 1.8781e-01, 1.8679e-01, 1.6777e-01, 2.0480e-01, 3.6162e-02,\n",
      "         1.0035e-02, 4.7825e-03, 7.8229e-04, 2.5357e-10],\n",
      "        [1.9199e-01, 1.6329e-01, 1.6730e-01, 1.5455e-01, 2.1096e-01, 8.4369e-02,\n",
      "         1.5797e-02, 8.7880e-03, 2.9624e-03, 2.2704e-09],\n",
      "        [1.8197e-01, 1.5076e-01, 1.5876e-01, 1.4784e-01, 2.1296e-01, 1.1310e-01,\n",
      "         1.8601e-02, 1.1151e-02, 4.8612e-03, 5.0768e-09],\n",
      "        [1.7457e-01, 1.4340e-01, 1.5205e-01, 1.4239e-01, 2.0816e-01, 1.3209e-01,\n",
      "         2.4189e-02, 1.5400e-02, 7.7504e-03, 9.0762e-09],\n",
      "        [1.6812e-01, 1.3984e-01, 1.4862e-01, 1.4050e-01, 2.0383e-01, 1.4071e-01,\n",
      "         2.8849e-02, 1.9277e-02, 1.0267e-02, 9.7204e-09],\n",
      "        [1.6417e-01, 1.3798e-01, 1.4712e-01, 1.4011e-01, 2.0185e-01, 1.4410e-01,\n",
      "         3.1545e-02, 2.1511e-02, 1.1607e-02, 1.0015e-08],\n",
      "        [1.6290e-01, 1.3751e-01, 1.4682e-01, 1.4004e-01, 2.0110e-01, 1.4473e-01,\n",
      "         3.2454e-02, 2.2294e-02, 1.2143e-02, 1.0233e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 137.00, Train Loss: 1.73, Val Loss: 12.45, Train BLEU: 40.25, Val BLEU: 0.32\n",
      "Sampling from training predictions...\n",
      "Source: 其实 它们 都 是 由 单独 的 动物 结合 合在\n",
      "Reference: these are all individual animals banding together to make\n",
      "Model: <SOS> these are all individual animals banding together make make\n",
      "Attention Weights: tensor([[0.0911, 0.1037, 0.1093, 0.1141, 0.1178, 0.1652, 0.1066, 0.1485, 0.0437,\n",
      "         0.0001],\n",
      "        [0.1127, 0.1051, 0.1079, 0.1107, 0.1127, 0.1586, 0.1003, 0.1430, 0.0486,\n",
      "         0.0006],\n",
      "        [0.1336, 0.1038, 0.1025, 0.1036, 0.1046, 0.1455, 0.0957, 0.1417, 0.0647,\n",
      "         0.0043],\n",
      "        [0.1325, 0.1000, 0.0985, 0.0999, 0.1011, 0.1396, 0.0943, 0.1424, 0.0792,\n",
      "         0.0126],\n",
      "        [0.1319, 0.0983, 0.0965, 0.0980, 0.0991, 0.1366, 0.0933, 0.1421, 0.0852,\n",
      "         0.0189],\n",
      "        [0.1314, 0.0972, 0.0953, 0.0967, 0.0978, 0.1343, 0.0928, 0.1411, 0.0887,\n",
      "         0.0246],\n",
      "        [0.1294, 0.0968, 0.0951, 0.0965, 0.0976, 0.1322, 0.0931, 0.1393, 0.0912,\n",
      "         0.0289],\n",
      "        [0.1269, 0.0963, 0.0948, 0.0963, 0.0974, 0.1305, 0.0933, 0.1384, 0.0936,\n",
      "         0.0324],\n",
      "        [0.1251, 0.0959, 0.0946, 0.0962, 0.0973, 0.1295, 0.0936, 0.1377, 0.0954,\n",
      "         0.0346]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 想 过 要 放弃 但 我 的 父亲 这时\n",
      "Reference: i would want to quit , but my father\n",
      "Model: <SOS> and of the the animals , , , are\n",
      "Attention Weights: tensor([[0.1024, 0.1263, 0.1307, 0.1527, 0.1327, 0.1696, 0.1507, 0.0342, 0.0007,\n",
      "         0.0000],\n",
      "        [0.1116, 0.1252, 0.1284, 0.1499, 0.1282, 0.1684, 0.1533, 0.0340, 0.0009,\n",
      "         0.0000],\n",
      "        [0.1299, 0.1237, 0.1237, 0.1433, 0.1222, 0.1632, 0.1546, 0.0365, 0.0026,\n",
      "         0.0003],\n",
      "        [0.1493, 0.1234, 0.1190, 0.1354, 0.1156, 0.1542, 0.1526, 0.0417, 0.0075,\n",
      "         0.0012],\n",
      "        [0.1503, 0.1156, 0.1118, 0.1283, 0.1100, 0.1482, 0.1558, 0.0530, 0.0217,\n",
      "         0.0053],\n",
      "        [0.1461, 0.1106, 0.1080, 0.1252, 0.1073, 0.1463, 0.1583, 0.0578, 0.0315,\n",
      "         0.0089],\n",
      "        [0.1408, 0.1067, 0.1049, 0.1215, 0.1050, 0.1417, 0.1558, 0.0636, 0.0448,\n",
      "         0.0153],\n",
      "        [0.1364, 0.1049, 0.1037, 0.1197, 0.1042, 0.1391, 0.1539, 0.0672, 0.0516,\n",
      "         0.0194],\n",
      "        [0.1326, 0.1032, 0.1025, 0.1183, 0.1035, 0.1377, 0.1536, 0.0700, 0.0563,\n",
      "         0.0223]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 138.00, Train Loss: 1.71, Val Loss: 12.48, Train BLEU: 41.00, Val BLEU: 0.32\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数 多数 地震 和 火山 喷发 也 都 发生\n",
      "Reference: most of the earthquakes and volcanoes are in the\n",
      "Model: <SOS> most of the the , the the the the\n",
      "Attention Weights: tensor([[0.0165, 0.0109, 0.1388, 0.1333, 0.1102, 0.2272, 0.1870, 0.0764, 0.0544,\n",
      "         0.0452],\n",
      "        [0.0281, 0.0293, 0.1461, 0.1266, 0.1045, 0.2163, 0.1773, 0.0722, 0.0518,\n",
      "         0.0479],\n",
      "        [0.0627, 0.1124, 0.1480, 0.1106, 0.0883, 0.1722, 0.1434, 0.0619, 0.0478,\n",
      "         0.0528],\n",
      "        [0.0758, 0.1551, 0.1299, 0.0977, 0.0804, 0.1562, 0.1322, 0.0604, 0.0496,\n",
      "         0.0626],\n",
      "        [0.0793, 0.1634, 0.1231, 0.0945, 0.0792, 0.1503, 0.1290, 0.0613, 0.0518,\n",
      "         0.0681],\n",
      "        [0.0817, 0.1679, 0.1179, 0.0922, 0.0789, 0.1459, 0.1270, 0.0629, 0.0541,\n",
      "         0.0714],\n",
      "        [0.0831, 0.1686, 0.1147, 0.0915, 0.0794, 0.1429, 0.1255, 0.0643, 0.0560,\n",
      "         0.0741],\n",
      "        [0.0835, 0.1654, 0.1123, 0.0911, 0.0800, 0.1413, 0.1251, 0.0659, 0.0580,\n",
      "         0.0773],\n",
      "        [0.0840, 0.1632, 0.1108, 0.0909, 0.0804, 0.1399, 0.1247, 0.0671, 0.0595,\n",
      "         0.0794]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 在 塔利 塔利班 控制 阿富汗 的 那些 年 我 记得\n",
      "Reference: during taliban years , i remember there were times\n",
      "Model: <SOS> the of the the the the the the the\n",
      "Attention Weights: tensor([[0.0955, 0.1038, 0.1094, 0.1143, 0.1180, 0.1573, 0.1055, 0.1508, 0.0454,\n",
      "         0.0001],\n",
      "        [0.1179, 0.1051, 0.1078, 0.1109, 0.1128, 0.1499, 0.0995, 0.1447, 0.0507,\n",
      "         0.0008],\n",
      "        [0.1391, 0.1037, 0.1021, 0.1033, 0.1043, 0.1371, 0.0948, 0.1427, 0.0676,\n",
      "         0.0054],\n",
      "        [0.1375, 0.0997, 0.0978, 0.0992, 0.1002, 0.1312, 0.0933, 0.1425, 0.0827,\n",
      "         0.0159],\n",
      "        [0.1365, 0.0978, 0.0956, 0.0969, 0.0980, 0.1282, 0.0921, 0.1416, 0.0890,\n",
      "         0.0243],\n",
      "        [0.1358, 0.0966, 0.0943, 0.0955, 0.0965, 0.1259, 0.0914, 0.1401, 0.0923,\n",
      "         0.0315],\n",
      "        [0.1332, 0.0961, 0.0941, 0.0954, 0.0963, 0.1240, 0.0917, 0.1381, 0.0945,\n",
      "         0.0366],\n",
      "        [0.1303, 0.0957, 0.0939, 0.0952, 0.0962, 0.1227, 0.0920, 0.1371, 0.0967,\n",
      "         0.0403],\n",
      "        [0.1281, 0.0953, 0.0937, 0.0951, 0.0961, 0.1219, 0.0923, 0.1364, 0.0985,\n",
      "         0.0427]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 139.00, Train Loss: 1.69, Val Loss: 12.48, Train BLEU: 42.10, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分 部分 的 动物 也 都 生活 在 海洋\n",
      "Reference: most of the animals are in the oceans .\n",
      "Model: <SOS> and of the , , the the the the\n",
      "Attention Weights: tensor([[0.0772, 0.1013, 0.1033, 0.0942, 0.1842, 0.0891, 0.0835, 0.1775, 0.0505,\n",
      "         0.0390],\n",
      "        [0.1001, 0.1004, 0.0986, 0.0902, 0.1769, 0.0852, 0.0799, 0.1737, 0.0496,\n",
      "         0.0454],\n",
      "        [0.1355, 0.1035, 0.0936, 0.0838, 0.1547, 0.0789, 0.0750, 0.1578, 0.0536,\n",
      "         0.0636],\n",
      "        [0.1353, 0.0998, 0.0911, 0.0821, 0.1454, 0.0779, 0.0750, 0.1538, 0.0585,\n",
      "         0.0811],\n",
      "        [0.1323, 0.0984, 0.0905, 0.0818, 0.1418, 0.0780, 0.0756, 0.1518, 0.0610,\n",
      "         0.0889],\n",
      "        [0.1281, 0.0978, 0.0909, 0.0830, 0.1374, 0.0795, 0.0774, 0.1473, 0.0644,\n",
      "         0.0943],\n",
      "        [0.1239, 0.0973, 0.0912, 0.0837, 0.1353, 0.0804, 0.0786, 0.1453, 0.0665,\n",
      "         0.0978],\n",
      "        [0.1220, 0.0970, 0.0913, 0.0841, 0.1343, 0.0809, 0.0792, 0.1443, 0.0675,\n",
      "         0.0994],\n",
      "        [0.1212, 0.0970, 0.0914, 0.0843, 0.1339, 0.0811, 0.0795, 0.1438, 0.0679,\n",
      "         0.1000]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班 走 了 父亲 大声 叫 着 <EOS> <PAD>\n",
      "Reference: &quot; the taliban are gone ! &quot; my father\n",
      "Model: <SOS> it &apos;s the of of . . . .\n",
      "Attention Weights: tensor([[0.0657, 0.0719, 0.0755, 0.1459, 0.1475, 0.0964, 0.0976, 0.1399, 0.1251,\n",
      "         0.0344],\n",
      "        [0.0853, 0.0746, 0.0755, 0.1405, 0.1415, 0.0921, 0.0931, 0.1350, 0.1230,\n",
      "         0.0394],\n",
      "        [0.1101, 0.0784, 0.0754, 0.1300, 0.1299, 0.0861, 0.0870, 0.1255, 0.1234,\n",
      "         0.0540],\n",
      "        [0.1111, 0.0769, 0.0746, 0.1251, 0.1244, 0.0845, 0.0861, 0.1230, 0.1260,\n",
      "         0.0683],\n",
      "        [0.1102, 0.0768, 0.0749, 0.1230, 0.1223, 0.0845, 0.0862, 0.1220, 0.1262,\n",
      "         0.0738],\n",
      "        [0.1091, 0.0761, 0.0747, 0.1227, 0.1221, 0.0845, 0.0865, 0.1222, 0.1268,\n",
      "         0.0752],\n",
      "        [0.1091, 0.0769, 0.0756, 0.1212, 0.1207, 0.0851, 0.0869, 0.1209, 0.1260,\n",
      "         0.0776],\n",
      "        [0.1073, 0.0772, 0.0764, 0.1196, 0.1194, 0.0858, 0.0876, 0.1199, 0.1258,\n",
      "         0.0811],\n",
      "        [0.1055, 0.0771, 0.0767, 0.1188, 0.1188, 0.0861, 0.0879, 0.1196, 0.1261,\n",
      "         0.0834]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 140.00, Train Loss: 1.66, Val Loss: 12.50, Train BLEU: 42.22, Val BLEU: 0.45\n",
      "Sampling from training predictions...\n",
      "Source: 是 我 最 喜欢 的 因为 它 哪 都 能动\n",
      "Reference: it &apos;s one of my favorites , because it\n",
      "Model: <SOS> it &apos;s one of my favorites , because because\n",
      "Attention Weights: tensor([[0.1075, 0.1204, 0.1271, 0.1435, 0.1401, 0.1597, 0.1070, 0.0711, 0.0236,\n",
      "         0.0001],\n",
      "        [0.1247, 0.1217, 0.1265, 0.1404, 0.1352, 0.1561, 0.1024, 0.0684, 0.0242,\n",
      "         0.0003],\n",
      "        [0.1522, 0.1243, 0.1229, 0.1318, 0.1257, 0.1454, 0.0977, 0.0691, 0.0294,\n",
      "         0.0015],\n",
      "        [0.1573, 0.1193, 0.1170, 0.1254, 0.1194, 0.1404, 0.0982, 0.0753, 0.0410,\n",
      "         0.0068],\n",
      "        [0.1557, 0.1158, 0.1140, 0.1222, 0.1163, 0.1378, 0.0984, 0.0784, 0.0481,\n",
      "         0.0132],\n",
      "        [0.1515, 0.1128, 0.1117, 0.1199, 0.1142, 0.1352, 0.0986, 0.0812, 0.0542,\n",
      "         0.0206],\n",
      "        [0.1472, 0.1111, 0.1105, 0.1183, 0.1130, 0.1331, 0.0991, 0.0834, 0.0586,\n",
      "         0.0257],\n",
      "        [0.1440, 0.1097, 0.1096, 0.1174, 0.1124, 0.1321, 0.0994, 0.0847, 0.0615,\n",
      "         0.0293],\n",
      "        [0.1419, 0.1089, 0.1090, 0.1169, 0.1121, 0.1315, 0.0998, 0.0857, 0.0633,\n",
      "         0.0311]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 出身 阿富汗 边远 <UNK> 地区 有着 与 他人 不同\n",
      "Reference: a total maverick from a remote province of afghanistan\n",
      "Model: <SOS> with vibrant the clips captured , , the the\n",
      "Attention Weights: tensor([[2.0472e-01, 2.4917e-01, 2.1552e-01, 2.9035e-01, 9.0228e-03, 1.6547e-02,\n",
      "         9.8244e-03, 4.6861e-03, 1.6156e-04, 1.3647e-11],\n",
      "        [2.2649e-01, 2.3485e-01, 2.0222e-01, 2.9173e-01, 1.5776e-02, 1.5427e-02,\n",
      "         8.9323e-03, 4.3397e-03, 2.3381e-04, 5.4572e-11],\n",
      "        [2.5443e-01, 2.1003e-01, 1.7775e-01, 2.7490e-01, 4.8160e-02, 1.8417e-02,\n",
      "         1.0259e-02, 5.3236e-03, 7.3119e-04, 2.6232e-10],\n",
      "        [2.2678e-01, 1.7142e-01, 1.5204e-01, 2.7610e-01, 1.2551e-01, 2.3596e-02,\n",
      "         1.3665e-02, 8.3440e-03, 2.5491e-03, 1.9526e-09],\n",
      "        [2.0587e-01, 1.5173e-01, 1.3751e-01, 2.7051e-01, 1.7598e-01, 2.7102e-02,\n",
      "         1.6207e-02, 1.0757e-02, 4.3334e-03, 4.1777e-09],\n",
      "        [1.9042e-01, 1.3869e-01, 1.2747e-01, 2.5926e-01, 2.1339e-01, 3.1533e-02,\n",
      "         1.9275e-02, 1.3526e-02, 6.4341e-03, 7.1737e-09],\n",
      "        [1.7725e-01, 1.3128e-01, 1.2323e-01, 2.4923e-01, 2.3132e-01, 3.6960e-02,\n",
      "         2.3706e-02, 1.7657e-02, 9.3665e-03, 8.2688e-09],\n",
      "        [1.6898e-01, 1.2841e-01, 1.2275e-01, 2.4485e-01, 2.3312e-01, 4.1528e-02,\n",
      "         2.7530e-02, 2.1136e-02, 1.1693e-02, 9.6003e-09],\n",
      "        [1.6748e-01, 1.2810e-01, 1.2292e-01, 2.4395e-01, 2.3291e-01, 4.2211e-02,\n",
      "         2.8242e-02, 2.1875e-02, 1.2311e-02, 1.0421e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 141.00, Train Loss: 1.64, Val Loss: 12.51, Train BLEU: 44.53, Val BLEU: 0.44\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克 泰坦尼克号 坦尼 尼克 号 是 拿 了 不少\n",
      "Reference: the truth of the matter is that the titanic\n",
      "Model: <SOS> the truth of the matter the the the the\n",
      "Attention Weights: tensor([[0.0185, 0.0044, 0.0055, 0.0229, 0.2175, 0.2025, 0.1771, 0.1460, 0.1148,\n",
      "         0.0907],\n",
      "        [0.0334, 0.0177, 0.0224, 0.0718, 0.2377, 0.1812, 0.1477, 0.1193, 0.0916,\n",
      "         0.0772],\n",
      "        [0.0602, 0.0631, 0.0829, 0.2001, 0.1898, 0.1221, 0.0929, 0.0745, 0.0587,\n",
      "         0.0557],\n",
      "        [0.0697, 0.0937, 0.1157, 0.2374, 0.1522, 0.0946, 0.0731, 0.0604, 0.0498,\n",
      "         0.0533],\n",
      "        [0.0753, 0.1129, 0.1318, 0.2389, 0.1333, 0.0827, 0.0659, 0.0562, 0.0480,\n",
      "         0.0550],\n",
      "        [0.0800, 0.1257, 0.1404, 0.2303, 0.1217, 0.0767, 0.0627, 0.0551, 0.0486,\n",
      "         0.0588],\n",
      "        [0.0834, 0.1277, 0.1389, 0.2170, 0.1168, 0.0761, 0.0641, 0.0580, 0.0527,\n",
      "         0.0652],\n",
      "        [0.0855, 0.1287, 0.1378, 0.2078, 0.1140, 0.0763, 0.0654, 0.0599, 0.0553,\n",
      "         0.0692],\n",
      "        [0.0861, 0.1286, 0.1370, 0.2035, 0.1132, 0.0766, 0.0661, 0.0610, 0.0567,\n",
      "         0.0713]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正 的 学校 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: a real school . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> here &apos;s a kind different . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0694, 0.0711, 0.1857, 0.0845, 0.0843, 0.2117, 0.1449, 0.1109, 0.0367,\n",
      "         0.0006],\n",
      "        [0.0899, 0.0733, 0.1785, 0.0807, 0.0798, 0.2082, 0.1396, 0.1069, 0.0386,\n",
      "         0.0045],\n",
      "        [0.1056, 0.0729, 0.1629, 0.0744, 0.0739, 0.1967, 0.1323, 0.1071, 0.0485,\n",
      "         0.0257],\n",
      "        [0.1055, 0.0720, 0.1503, 0.0724, 0.0726, 0.1847, 0.1256, 0.1063, 0.0567,\n",
      "         0.0539],\n",
      "        [0.1050, 0.0715, 0.1439, 0.0713, 0.0717, 0.1762, 0.1217, 0.1049, 0.0601,\n",
      "         0.0739],\n",
      "        [0.1038, 0.0712, 0.1391, 0.0708, 0.0714, 0.1705, 0.1192, 0.1035, 0.0619,\n",
      "         0.0885],\n",
      "        [0.1025, 0.0714, 0.1355, 0.0711, 0.0717, 0.1656, 0.1175, 0.1030, 0.0638,\n",
      "         0.0979],\n",
      "        [0.0998, 0.0710, 0.1334, 0.0712, 0.0719, 0.1638, 0.1173, 0.1036, 0.0658,\n",
      "         0.1021],\n",
      "        [0.0981, 0.0711, 0.1323, 0.0717, 0.0725, 0.1625, 0.1174, 0.1042, 0.0673,\n",
      "         0.1030]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 142.00, Train Loss: 1.62, Val Loss: 12.53, Train BLEU: 45.22, Val BLEU: 0.44\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一只 水母 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: here &apos;s a jelly . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> here &apos;s a jelly . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[3.5614e-01, 2.8472e-01, 1.8950e-01, 1.6437e-01, 5.2736e-03, 2.6538e-10,\n",
      "         2.6538e-10, 2.6538e-10, 2.6538e-10, 2.6538e-10],\n",
      "        [3.8202e-01, 2.6707e-01, 1.7956e-01, 1.6227e-01, 9.0883e-03, 1.3623e-09,\n",
      "         1.3623e-09, 1.3623e-09, 1.3623e-09, 1.3623e-09],\n",
      "        [4.0949e-01, 2.4901e-01, 1.6451e-01, 1.5735e-01, 1.9646e-02, 5.6197e-09,\n",
      "         5.6197e-09, 5.6197e-09, 5.6197e-09, 5.6197e-09],\n",
      "        [3.7047e-01, 2.2772e-01, 1.6685e-01, 1.8149e-01, 5.3465e-02, 3.2899e-08,\n",
      "         3.2899e-08, 3.2899e-08, 3.2899e-08, 3.2899e-08],\n",
      "        [3.3545e-01, 2.1553e-01, 1.7104e-01, 1.9745e-01, 8.0537e-02, 5.9901e-08,\n",
      "         5.9901e-08, 5.9901e-08, 5.9901e-08, 5.9901e-08],\n",
      "        [3.0874e-01, 2.0707e-01, 1.7600e-01, 2.0709e-01, 1.0110e-01, 5.8972e-08,\n",
      "         5.8972e-08, 5.8972e-08, 5.8972e-08, 5.8972e-08],\n",
      "        [2.9881e-01, 2.0589e-01, 1.7795e-01, 2.0881e-01, 1.0854e-01, 6.8629e-08,\n",
      "         6.8629e-08, 6.8629e-08, 6.8629e-08, 6.8629e-08],\n",
      "        [2.9694e-01, 2.0559e-01, 1.7829e-01, 2.0907e-01, 1.1011e-01, 7.6074e-08,\n",
      "         7.6074e-08, 7.6074e-08, 7.6074e-08, 7.6074e-08],\n",
      "        [2.9622e-01, 2.0526e-01, 1.7822e-01, 2.0939e-01, 1.1091e-01, 7.9338e-08,\n",
      "         7.9338e-08, 7.9338e-08, 7.9338e-08, 7.9338e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 很 幸运 幸运地 成长 在 一个 珍视 教育 也\n",
      "Reference: i was very lucky to grow up in a\n",
      "Model: <SOS> we biodiversity the the the and the the the\n",
      "Attention Weights: tensor([[3.5614e-01, 2.8472e-01, 1.8950e-01, 1.6437e-01, 5.2736e-03, 2.6538e-10,\n",
      "         2.6538e-10, 2.6538e-10, 2.6538e-10, 2.6538e-10],\n",
      "        [3.8202e-01, 2.6707e-01, 1.7956e-01, 1.6227e-01, 9.0883e-03, 1.3623e-09,\n",
      "         1.3623e-09, 1.3623e-09, 1.3623e-09, 1.3623e-09],\n",
      "        [4.0949e-01, 2.4901e-01, 1.6451e-01, 1.5735e-01, 1.9646e-02, 5.6197e-09,\n",
      "         5.6197e-09, 5.6197e-09, 5.6197e-09, 5.6197e-09],\n",
      "        [3.7047e-01, 2.2772e-01, 1.6685e-01, 1.8149e-01, 5.3465e-02, 3.2899e-08,\n",
      "         3.2899e-08, 3.2899e-08, 3.2899e-08, 3.2899e-08],\n",
      "        [3.3545e-01, 2.1553e-01, 1.7104e-01, 1.9745e-01, 8.0537e-02, 5.9901e-08,\n",
      "         5.9901e-08, 5.9901e-08, 5.9901e-08, 5.9901e-08],\n",
      "        [3.0874e-01, 2.0707e-01, 1.7600e-01, 2.0709e-01, 1.0110e-01, 5.8972e-08,\n",
      "         5.8972e-08, 5.8972e-08, 5.8972e-08, 5.8972e-08],\n",
      "        [2.9881e-01, 2.0589e-01, 1.7795e-01, 2.0881e-01, 1.0854e-01, 6.8629e-08,\n",
      "         6.8629e-08, 6.8629e-08, 6.8629e-08, 6.8629e-08],\n",
      "        [2.9694e-01, 2.0559e-01, 1.7829e-01, 2.0907e-01, 1.1011e-01, 7.6074e-08,\n",
      "         7.6074e-08, 7.6074e-08, 7.6074e-08, 7.6074e-08],\n",
      "        [2.9622e-01, 2.0526e-01, 1.7822e-01, 2.0939e-01, 1.1091e-01, 7.9338e-08,\n",
      "         7.9338e-08, 7.9338e-08, 7.9338e-08, 7.9338e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143.00, Train Loss: 1.59, Val Loss: 12.54, Train BLEU: 45.33, Val BLEU: 0.43\n",
      "Sampling from training predictions...\n",
      "Source: 当 你 站 在 海滩 上 或是 当 你 看到\n",
      "Reference: part of the problem , i think , is\n",
      "Model: <SOS> and of the the , , , , the\n",
      "Attention Weights: tensor([[0.0706, 0.0718, 0.0788, 0.0899, 0.2376, 0.0968, 0.1920, 0.0705, 0.0485,\n",
      "         0.0438],\n",
      "        [0.0861, 0.0735, 0.0789, 0.0878, 0.2288, 0.0924, 0.1865, 0.0685, 0.0482,\n",
      "         0.0492],\n",
      "        [0.1138, 0.0797, 0.0801, 0.0857, 0.2038, 0.0870, 0.1670, 0.0678, 0.0515,\n",
      "         0.0637],\n",
      "        [0.1162, 0.0787, 0.0790, 0.0843, 0.1907, 0.0845, 0.1601, 0.0689, 0.0559,\n",
      "         0.0817],\n",
      "        [0.1150, 0.0787, 0.0793, 0.0845, 0.1834, 0.0843, 0.1560, 0.0702, 0.0587,\n",
      "         0.0900],\n",
      "        [0.1145, 0.0788, 0.0797, 0.0846, 0.1788, 0.0844, 0.1535, 0.0711, 0.0604,\n",
      "         0.0941],\n",
      "        [0.1124, 0.0790, 0.0803, 0.0853, 0.1743, 0.0850, 0.1506, 0.0725, 0.0625,\n",
      "         0.0981],\n",
      "        [0.1102, 0.0788, 0.0805, 0.0855, 0.1719, 0.0853, 0.1492, 0.0733, 0.0639,\n",
      "         0.1015],\n",
      "        [0.1089, 0.0788, 0.0807, 0.0857, 0.1705, 0.0856, 0.1483, 0.0738, 0.0647,\n",
      "         0.1029]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 因此 毫无 毫无疑问 无疑 疑问 他 的 孩子 应当 受到\n",
      "Reference: there was no question that his children would receive\n",
      "Model: <SOS> most of the the , the the the the\n",
      "Attention Weights: tensor([[1.4839e-01, 1.8080e-01, 2.1992e-01, 1.9239e-01, 2.4176e-01, 1.1229e-02,\n",
      "         4.0038e-03, 1.4330e-03, 6.8056e-05, 8.7942e-12],\n",
      "        [1.7169e-01, 1.7932e-01, 2.1020e-01, 1.8013e-01, 2.3344e-01, 1.9136e-02,\n",
      "         4.2555e-03, 1.6721e-03, 1.5178e-04, 4.9049e-11],\n",
      "        [2.0256e-01, 1.7462e-01, 1.9221e-01, 1.6405e-01, 2.1819e-01, 3.9465e-02,\n",
      "         5.8813e-03, 2.5389e-03, 4.9046e-04, 2.5046e-10],\n",
      "        [1.9333e-01, 1.5246e-01, 1.6999e-01, 1.4909e-01, 2.2408e-01, 9.5143e-02,\n",
      "         9.3218e-03, 4.6826e-03, 1.9072e-03, 2.2146e-09],\n",
      "        [1.7933e-01, 1.3850e-01, 1.5832e-01, 1.4010e-01, 2.2587e-01, 1.3607e-01,\n",
      "         1.1770e-02, 6.5070e-03, 3.5317e-03, 4.8604e-09],\n",
      "        [1.7153e-01, 1.2987e-01, 1.4903e-01, 1.3252e-01, 2.2011e-01, 1.6611e-01,\n",
      "         1.5594e-02, 9.2968e-03, 5.9456e-03, 9.4050e-09],\n",
      "        [1.6443e-01, 1.2550e-01, 1.4380e-01, 1.2962e-01, 2.1347e-01, 1.8216e-01,\n",
      "         1.9842e-02, 1.2585e-02, 8.5931e-03, 1.1551e-08],\n",
      "        [1.5918e-01, 1.2324e-01, 1.4174e-01, 1.2921e-01, 2.1116e-01, 1.8862e-01,\n",
      "         2.2275e-02, 1.4514e-02, 1.0055e-02, 1.2389e-08],\n",
      "        [1.5738e-01, 1.2294e-01, 1.4162e-01, 1.2952e-01, 2.1040e-01, 1.8882e-01,\n",
      "         2.3299e-02, 1.5329e-02, 1.0695e-02, 1.2218e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 144.00, Train Loss: 1.57, Val Loss: 12.56, Train BLEU: 47.37, Val BLEU: 0.44\n",
      "Sampling from training predictions...\n",
      "Source: 我 真 喜欢 这些 东西 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: i love that kind of stuff . <EOS> <PAD>\n",
      "Model: <SOS> here &apos;s a kind about stuff <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[3.2065e-01, 2.7122e-01, 1.7403e-01, 1.4999e-01, 8.1310e-02, 2.8045e-03,\n",
      "         1.8719e-10, 1.8719e-10, 1.8719e-10, 1.8719e-10],\n",
      "        [3.4570e-01, 2.5701e-01, 1.6667e-01, 1.4304e-01, 8.2865e-02, 4.7140e-03,\n",
      "         8.8178e-10, 8.8178e-10, 8.8178e-10, 8.8178e-10],\n",
      "        [3.7619e-01, 2.4272e-01, 1.5384e-01, 1.3197e-01, 8.5082e-02, 1.0202e-02,\n",
      "         3.6597e-09, 3.6597e-09, 3.6597e-09, 3.6597e-09],\n",
      "        [3.5157e-01, 2.2314e-01, 1.5379e-01, 1.3857e-01, 1.0415e-01, 2.8779e-02,\n",
      "         2.1054e-08, 2.1054e-08, 2.1054e-08, 2.1054e-08],\n",
      "        [3.2436e-01, 2.1125e-01, 1.5595e-01, 1.4591e-01, 1.1767e-01, 4.4864e-02,\n",
      "         4.1874e-08, 4.1874e-08, 4.1874e-08, 4.1874e-08],\n",
      "        [3.0693e-01, 2.0144e-01, 1.5643e-01, 1.5061e-01, 1.2696e-01, 5.7620e-02,\n",
      "         6.4650e-08, 6.4650e-08, 6.4650e-08, 6.4650e-08],\n",
      "        [2.9053e-01, 1.9555e-01, 1.5780e-01, 1.5492e-01, 1.3452e-01, 6.6690e-02,\n",
      "         5.6003e-08, 5.6003e-08, 5.6003e-08, 5.6003e-08],\n",
      "        [2.7306e-01, 1.9086e-01, 1.5977e-01, 1.5870e-01, 1.4147e-01, 7.6132e-02,\n",
      "         5.4201e-08, 5.4201e-08, 5.4201e-08, 5.4201e-08],\n",
      "        [2.6836e-01, 1.8979e-01, 1.6025e-01, 1.5959e-01, 1.4318e-01, 7.8834e-02,\n",
      "         6.2198e-08, 6.2198e-08, 6.2198e-08, 6.2198e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 很 害怕 但是 我们 仍然 渴望 望去 学校 <EOS>\n",
      "Reference: we were scared , but still , school was\n",
      "Model: <SOS> it &apos;s all those about is . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0723, 0.0740, 0.1334, 0.0963, 0.1476, 0.0961, 0.1295, 0.1918, 0.0451,\n",
      "         0.0140],\n",
      "        [0.0915, 0.0764, 0.1277, 0.0932, 0.1427, 0.0916, 0.1254, 0.1886, 0.0459,\n",
      "         0.0169],\n",
      "        [0.1198, 0.0827, 0.1231, 0.0895, 0.1303, 0.0864, 0.1159, 0.1756, 0.0519,\n",
      "         0.0248],\n",
      "        [0.1228, 0.0824, 0.1190, 0.0880, 0.1255, 0.0846, 0.1135, 0.1723, 0.0577,\n",
      "         0.0341],\n",
      "        [0.1223, 0.0829, 0.1174, 0.0880, 0.1232, 0.0847, 0.1125, 0.1686, 0.0610,\n",
      "         0.0394],\n",
      "        [0.1211, 0.0826, 0.1166, 0.0876, 0.1225, 0.0845, 0.1124, 0.1686, 0.0624,\n",
      "         0.0415],\n",
      "        [0.1195, 0.0833, 0.1159, 0.0884, 0.1217, 0.0854, 0.1122, 0.1650, 0.0643,\n",
      "         0.0443],\n",
      "        [0.1182, 0.0835, 0.1155, 0.0887, 0.1211, 0.0857, 0.1119, 0.1636, 0.0655,\n",
      "         0.0462],\n",
      "        [0.1161, 0.0835, 0.1152, 0.0890, 0.1206, 0.0861, 0.1118, 0.1627, 0.0668,\n",
      "         0.0482]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 145.00, Train Loss: 1.55, Val Loss: 12.57, Train BLEU: 47.90, Val BLEU: 0.44\n",
      "Sampling from training predictions...\n",
      "Source: 还有 这些 摇晃 着 旋转 转着 的 触角 <EOS> <PAD>\n",
      "Reference: it &apos;s got tentacles dangling , swirling around like\n",
      "Model: <SOS> it &apos;s got tentacles dangling dangling swirling like like\n",
      "Attention Weights: tensor([[1.4499e-01, 1.7354e-01, 2.1301e-01, 1.9254e-01, 2.5835e-01, 1.2753e-02,\n",
      "         3.4726e-03, 1.2698e-03, 6.7945e-05, 9.9272e-12],\n",
      "        [1.6610e-01, 1.7174e-01, 2.0405e-01, 1.8101e-01, 2.5088e-01, 2.0934e-02,\n",
      "         3.6649e-03, 1.4688e-03, 1.4326e-04, 5.3583e-11],\n",
      "        [1.9565e-01, 1.6804e-01, 1.8741e-01, 1.6534e-01, 2.3439e-01, 4.1585e-02,\n",
      "         4.9564e-03, 2.1824e-03, 4.4814e-04, 2.8303e-10],\n",
      "        [1.8770e-01, 1.4737e-01, 1.6556e-01, 1.4966e-01, 2.3808e-01, 9.7930e-02,\n",
      "         7.9030e-03, 4.0387e-03, 1.7448e-03, 2.5143e-09],\n",
      "        [1.7355e-01, 1.3286e-01, 1.5304e-01, 1.3964e-01, 2.3919e-01, 1.4230e-01,\n",
      "         1.0270e-02, 5.7735e-03, 3.3760e-03, 5.5615e-09],\n",
      "        [1.6552e-01, 1.2417e-01, 1.4346e-01, 1.3147e-01, 2.3109e-01, 1.7566e-01,\n",
      "         1.4125e-02, 8.5965e-03, 5.9120e-03, 1.0858e-08],\n",
      "        [1.5849e-01, 1.1965e-01, 1.3788e-01, 1.2787e-01, 2.2220e-01, 1.9471e-01,\n",
      "         1.8413e-02, 1.1954e-02, 8.8265e-03, 1.3835e-08],\n",
      "        [1.5313e-01, 1.1752e-01, 1.3598e-01, 1.2740e-01, 2.1914e-01, 2.0175e-01,\n",
      "         2.0795e-02, 1.3884e-02, 1.0405e-02, 1.4954e-08],\n",
      "        [1.5149e-01, 1.1729e-01, 1.3590e-01, 1.2771e-01, 2.1794e-01, 2.0212e-01,\n",
      "         2.1813e-02, 1.4686e-02, 1.1066e-02, 1.4817e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 面带 <UNK> <UNK> 笑容 这 很少 少见 因为 大部\n",
      "Reference: there was a big smile on his face which\n",
      "Model: <SOS> with vibrant video clips captured submarines the the the\n",
      "Attention Weights: tensor([[0.0706, 0.0191, 0.1983, 0.1957, 0.0557, 0.0238, 0.2129, 0.1740, 0.0488,\n",
      "         0.0011],\n",
      "        [0.0964, 0.0305, 0.2034, 0.1890, 0.0740, 0.0376, 0.1810, 0.1426, 0.0437,\n",
      "         0.0017],\n",
      "        [0.1180, 0.0605, 0.1915, 0.1608, 0.1017, 0.0716, 0.1443, 0.1074, 0.0396,\n",
      "         0.0045],\n",
      "        [0.1177, 0.0838, 0.1702, 0.1411, 0.1240, 0.0948, 0.1236, 0.0942, 0.0410,\n",
      "         0.0096],\n",
      "        [0.1123, 0.1042, 0.1541, 0.1248, 0.1391, 0.1167, 0.1090, 0.0834, 0.0410,\n",
      "         0.0155],\n",
      "        [0.1080, 0.1295, 0.1367, 0.1070, 0.1513, 0.1429, 0.0903, 0.0690, 0.0400,\n",
      "         0.0252],\n",
      "        [0.1065, 0.1397, 0.1275, 0.0994, 0.1519, 0.1537, 0.0839, 0.0647, 0.0408,\n",
      "         0.0318],\n",
      "        [0.1056, 0.1442, 0.1224, 0.0961, 0.1526, 0.1576, 0.0807, 0.0632, 0.0418,\n",
      "         0.0358],\n",
      "        [0.1050, 0.1462, 0.1202, 0.0944, 0.1530, 0.1597, 0.0793, 0.0624, 0.0421,\n",
      "         0.0377]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 146.00, Train Loss: 1.52, Val Loss: 12.57, Train BLEU: 48.86, Val BLEU: 0.44\n",
      "Sampling from training predictions...\n",
      "Source: 是 我 最 喜欢 的 因为 它 哪 都 能动\n",
      "Reference: it &apos;s one of my favorites , because it\n",
      "Model: <SOS> it &apos;s one of my favorites , because because\n",
      "Attention Weights: tensor([[0.1027, 0.1078, 0.1200, 0.1481, 0.1444, 0.1757, 0.1065, 0.0696, 0.0253,\n",
      "         0.0001],\n",
      "        [0.1173, 0.1079, 0.1189, 0.1457, 0.1403, 0.1738, 0.1029, 0.0673, 0.0256,\n",
      "         0.0003],\n",
      "        [0.1438, 0.1118, 0.1166, 0.1374, 0.1309, 0.1621, 0.0981, 0.0673, 0.0301,\n",
      "         0.0018],\n",
      "        [0.1506, 0.1089, 0.1119, 0.1301, 0.1236, 0.1550, 0.0977, 0.0730, 0.0414,\n",
      "         0.0078],\n",
      "        [0.1495, 0.1059, 0.1092, 0.1267, 0.1199, 0.1519, 0.0973, 0.0759, 0.0485,\n",
      "         0.0152],\n",
      "        [0.1461, 0.1031, 0.1066, 0.1232, 0.1165, 0.1478, 0.0969, 0.0787, 0.0556,\n",
      "         0.0254],\n",
      "        [0.1413, 0.1014, 0.1051, 0.1205, 0.1142, 0.1438, 0.0973, 0.0816, 0.0613,\n",
      "         0.0335],\n",
      "        [0.1374, 0.0998, 0.1040, 0.1193, 0.1131, 0.1421, 0.0976, 0.0832, 0.0648,\n",
      "         0.0386],\n",
      "        [0.1349, 0.0989, 0.1033, 0.1185, 0.1125, 0.1411, 0.0980, 0.0843, 0.0670,\n",
      "         0.0415]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 但是 我 那 受过 教育 的 母亲 成为 为了 一名\n",
      "Reference: but my educated mother became a teacher . <EOS>\n",
      "Model: <SOS> most of the the the and the the the\n",
      "Attention Weights: tensor([[3.0110e-01, 2.7871e-01, 2.2890e-01, 1.6415e-02, 9.8216e-02, 5.0813e-02,\n",
      "         2.4940e-02, 9.0143e-04, 1.4371e-10, 1.4371e-10],\n",
      "        [3.2591e-01, 2.6481e-01, 2.3047e-01, 2.4503e-02, 9.4139e-02, 3.9235e-02,\n",
      "         1.9837e-02, 1.1079e-03, 4.7804e-10, 4.7804e-10],\n",
      "        [3.2491e-01, 2.2986e-01, 2.0547e-01, 4.7818e-02, 1.3119e-01, 3.8774e-02,\n",
      "         1.9611e-02, 2.3592e-03, 1.7151e-09, 1.7151e-09],\n",
      "        [2.9097e-01, 1.9856e-01, 1.9020e-01, 9.8336e-02, 1.5761e-01, 3.7898e-02,\n",
      "         2.0966e-02, 5.4665e-03, 7.0136e-09, 7.0136e-09],\n",
      "        [2.4842e-01, 1.7080e-01, 1.7357e-01, 1.4150e-01, 1.9208e-01, 4.0878e-02,\n",
      "         2.3715e-02, 9.0481e-03, 1.4264e-08, 1.4264e-08],\n",
      "        [2.1587e-01, 1.4839e-01, 1.5699e-01, 1.7284e-01, 2.1956e-01, 4.5967e-02,\n",
      "         2.7424e-02, 1.2960e-02, 2.2619e-08, 2.2619e-08],\n",
      "        [1.9688e-01, 1.3841e-01, 1.5025e-01, 1.9022e-01, 2.2581e-01, 5.0401e-02,\n",
      "         3.1284e-02, 1.6753e-02, 2.2712e-08, 2.2712e-08],\n",
      "        [1.8290e-01, 1.3282e-01, 1.4740e-01, 1.9966e-01, 2.2452e-01, 5.5430e-02,\n",
      "         3.5883e-02, 2.1375e-02, 2.6326e-08, 2.6326e-08],\n",
      "        [1.7933e-01, 1.3209e-01, 1.4750e-01, 2.0257e-01, 2.2207e-01, 5.6544e-02,\n",
      "         3.7162e-02, 2.2719e-02, 2.8913e-08, 2.8913e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 147.00, Train Loss: 1.50, Val Loss: 12.59, Train BLEU: 51.17, Val BLEU: 0.45\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中 的 生命 大卫 <UNK> <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: life in the deep oceans <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> life in the deep oceans <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[4.2552e-01, 2.5447e-01, 1.3500e-01, 1.4921e-01, 3.5533e-02, 2.2461e-04,\n",
      "         4.9111e-05, 3.5682e-11, 3.5682e-11, 3.5682e-11],\n",
      "        [4.5248e-01, 2.3678e-01, 1.2843e-01, 1.4153e-01, 4.0097e-02, 5.5732e-04,\n",
      "         1.2602e-04, 2.1012e-10, 2.1012e-10, 2.1012e-10],\n",
      "        [4.7109e-01, 2.1430e-01, 1.1948e-01, 1.3320e-01, 5.5694e-02, 4.8978e-03,\n",
      "         1.3353e-03, 2.1176e-09, 2.1176e-09, 2.1176e-09],\n",
      "        [3.9540e-01, 1.9436e-01, 1.2657e-01, 1.5139e-01, 9.2403e-02, 3.0497e-02,\n",
      "         9.3755e-03, 2.2438e-08, 2.2438e-08, 2.2438e-08],\n",
      "        [3.4594e-01, 1.7688e-01, 1.2526e-01, 1.5676e-01, 1.1043e-01, 6.3498e-02,\n",
      "         2.1228e-02, 4.4889e-08, 4.4889e-08, 4.4889e-08],\n",
      "        [3.1284e-01, 1.6917e-01, 1.2615e-01, 1.5932e-01, 1.1920e-01, 8.3441e-02,\n",
      "         2.9877e-02, 5.1293e-08, 5.1293e-08, 5.1293e-08],\n",
      "        [2.9193e-01, 1.6568e-01, 1.2743e-01, 1.6093e-01, 1.2416e-01, 9.4880e-02,\n",
      "         3.4979e-02, 5.4980e-08, 5.4980e-08, 5.4980e-08],\n",
      "        [2.8904e-01, 1.6512e-01, 1.2752e-01, 1.6134e-01, 1.2532e-01, 9.6134e-02,\n",
      "         3.5516e-02, 5.6707e-08, 5.6707e-08, 5.6707e-08],\n",
      "        [2.8747e-01, 1.6455e-01, 1.2738e-01, 1.6140e-01, 1.2598e-01, 9.7256e-02,\n",
      "         3.5958e-02, 5.8671e-08, 5.8671e-08, 5.8671e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 祖父 在 他 的 年代 是 位非 非凡\n",
      "Reference: my grandfather was an extraordinary man for his time\n",
      "Model: <SOS> we &apos;s the the to , and , the\n",
      "Attention Weights: tensor([[0.1048, 0.1060, 0.1189, 0.1466, 0.1449, 0.1742, 0.1076, 0.0705, 0.0263,\n",
      "         0.0001],\n",
      "        [0.1199, 0.1063, 0.1179, 0.1440, 0.1408, 0.1721, 0.1039, 0.0681, 0.0267,\n",
      "         0.0004],\n",
      "        [0.1474, 0.1104, 0.1155, 0.1354, 0.1308, 0.1599, 0.0987, 0.0682, 0.0316,\n",
      "         0.0023],\n",
      "        [0.1539, 0.1075, 0.1106, 0.1276, 0.1229, 0.1518, 0.0981, 0.0740, 0.0437,\n",
      "         0.0099],\n",
      "        [0.1526, 0.1045, 0.1077, 0.1236, 0.1186, 0.1479, 0.0975, 0.0768, 0.0512,\n",
      "         0.0196],\n",
      "        [0.1480, 0.1012, 0.1047, 0.1196, 0.1146, 0.1435, 0.0969, 0.0798, 0.0589,\n",
      "         0.0329],\n",
      "        [0.1421, 0.0993, 0.1030, 0.1169, 0.1122, 0.1396, 0.0972, 0.0825, 0.0646,\n",
      "         0.0425],\n",
      "        [0.1379, 0.0977, 0.1019, 0.1156, 0.1111, 0.1379, 0.0974, 0.0841, 0.0680,\n",
      "         0.0484],\n",
      "        [0.1353, 0.0969, 0.1012, 0.1149, 0.1105, 0.1370, 0.0977, 0.0851, 0.0700,\n",
      "         0.0515]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 148.00, Train Loss: 1.49, Val Loss: 12.59, Train BLEU: 50.24, Val BLEU: 0.45\n",
      "Sampling from training predictions...\n",
      "Source: 当 你 站 在 海滩 上 或是 当 你 看到\n",
      "Reference: part of the problem , i think , is\n",
      "Model: <SOS> and of the problem , , , , are\n",
      "Attention Weights: tensor([[0.0603, 0.0606, 0.0700, 0.0804, 0.2600, 0.0949, 0.2029, 0.0698, 0.0474,\n",
      "         0.0537],\n",
      "        [0.0701, 0.0609, 0.0696, 0.0789, 0.2544, 0.0905, 0.2004, 0.0679, 0.0470,\n",
      "         0.0603],\n",
      "        [0.0933, 0.0668, 0.0709, 0.0775, 0.2301, 0.0851, 0.1813, 0.0669, 0.0499,\n",
      "         0.0781],\n",
      "        [0.0984, 0.0680, 0.0713, 0.0773, 0.2112, 0.0827, 0.1704, 0.0683, 0.0548,\n",
      "         0.0977],\n",
      "        [0.0986, 0.0688, 0.0721, 0.0779, 0.2008, 0.0825, 0.1645, 0.0697, 0.0578,\n",
      "         0.1073],\n",
      "        [0.0988, 0.0690, 0.0725, 0.0780, 0.1945, 0.0820, 0.1613, 0.0705, 0.0599,\n",
      "         0.1135],\n",
      "        [0.0975, 0.0692, 0.0731, 0.0785, 0.1886, 0.0823, 0.1578, 0.0717, 0.0621,\n",
      "         0.1192],\n",
      "        [0.0964, 0.0694, 0.0734, 0.0789, 0.1849, 0.0824, 0.1554, 0.0723, 0.0635,\n",
      "         0.1235],\n",
      "        [0.0956, 0.0694, 0.0737, 0.0792, 0.1831, 0.0826, 0.1544, 0.0728, 0.0643,\n",
      "         0.1250]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 面带 <UNK> <UNK> 笑容 这 很少 少见 因为 大部\n",
      "Reference: there was a big smile on his face which\n",
      "Model: <SOS> with vibrant video clips captured by the the the\n",
      "Attention Weights: tensor([[0.0696, 0.0211, 0.2028, 0.1949, 0.0674, 0.0269, 0.2038, 0.1641, 0.0480,\n",
      "         0.0012],\n",
      "        [0.0924, 0.0307, 0.2070, 0.1902, 0.0850, 0.0385, 0.1746, 0.1367, 0.0431,\n",
      "         0.0017],\n",
      "        [0.1142, 0.0562, 0.1947, 0.1651, 0.1118, 0.0675, 0.1413, 0.1059, 0.0393,\n",
      "         0.0040],\n",
      "        [0.1157, 0.0767, 0.1750, 0.1471, 0.1330, 0.0871, 0.1224, 0.0940, 0.0406,\n",
      "         0.0081],\n",
      "        [0.1104, 0.0955, 0.1596, 0.1311, 0.1482, 0.1073, 0.1095, 0.0844, 0.0408,\n",
      "         0.0132],\n",
      "        [0.1054, 0.1221, 0.1402, 0.1117, 0.1626, 0.1348, 0.0903, 0.0697, 0.0401,\n",
      "         0.0230],\n",
      "        [0.1038, 0.1349, 0.1294, 0.1023, 0.1633, 0.1483, 0.0826, 0.0642, 0.0406,\n",
      "         0.0305],\n",
      "        [0.1030, 0.1410, 0.1233, 0.0979, 0.1637, 0.1541, 0.0785, 0.0619, 0.0414,\n",
      "         0.0350],\n",
      "        [0.1025, 0.1433, 0.1207, 0.0961, 0.1643, 0.1562, 0.0770, 0.0610, 0.0418,\n",
      "         0.0371]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 149.00, Train Loss: 1.48, Val Loss: 12.63, Train BLEU: 50.82, Val BLEU: 0.45\n",
      "Sampling from training predictions...\n",
      "Source: 原来 它 是 海洋 洋中 最长 的 生物 <EOS> <PAD>\n",
      "Reference: this turns out to be the longest creature in\n",
      "Model: <SOS> this turns out to be . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.5585e-01, 1.7538e-01, 1.7395e-01, 4.5874e-01, 2.1391e-02, 8.6538e-03,\n",
      "         3.8832e-03, 2.0274e-03, 1.2620e-04, 1.4004e-11],\n",
      "        [1.6865e-01, 1.6150e-01, 1.5720e-01, 4.6555e-01, 3.3943e-02, 7.7919e-03,\n",
      "         3.4340e-03, 1.7808e-03, 1.4931e-04, 5.4260e-11],\n",
      "        [1.8743e-01, 1.4372e-01, 1.3686e-01, 4.3114e-01, 8.6600e-02, 8.2274e-03,\n",
      "         3.6383e-03, 2.0055e-03, 3.8254e-04, 2.3703e-10],\n",
      "        [1.6622e-01, 1.1529e-01, 1.1216e-01, 3.9366e-01, 1.9358e-01, 1.0089e-02,\n",
      "         4.7407e-03, 3.0136e-03, 1.2519e-03, 1.8423e-09],\n",
      "        [1.4186e-01, 9.5562e-02, 9.4865e-02, 3.6296e-01, 2.8058e-01, 1.1866e-02,\n",
      "         5.8736e-03, 4.1049e-03, 2.3301e-03, 4.4998e-09],\n",
      "        [1.2665e-01, 8.4853e-02, 8.5566e-02, 3.3091e-01, 3.3983e-01, 1.4783e-02,\n",
      "         7.7429e-03, 5.7895e-03, 3.8834e-03, 8.5985e-09],\n",
      "        [1.1735e-01, 8.1457e-02, 8.4560e-02, 3.1180e-01, 3.5811e-01, 1.9647e-02,\n",
      "         1.1210e-02, 9.0357e-03, 6.8370e-03, 1.1242e-08],\n",
      "        [1.1525e-01, 8.2023e-02, 8.6636e-02, 3.0674e-01, 3.5357e-01, 2.2524e-02,\n",
      "         1.3369e-02, 1.1115e-02, 8.7686e-03, 1.3436e-08],\n",
      "        [1.1475e-01, 8.2008e-02, 8.6835e-02, 3.0567e-01, 3.5356e-01, 2.2893e-02,\n",
      "         1.3696e-02, 1.1453e-02, 9.1330e-03, 1.4373e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班 走 了 父亲 大声 叫 着 <EOS> <PAD>\n",
      "Reference: &quot; the taliban are gone ! &quot; my father\n",
      "Model: <SOS> it of the of . . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0442, 0.0396, 0.0440, 0.1543, 0.1704, 0.0795, 0.0834, 0.1703, 0.1685,\n",
      "         0.0460],\n",
      "        [0.0560, 0.0418, 0.0452, 0.1497, 0.1663, 0.0767, 0.0808, 0.1657, 0.1655,\n",
      "         0.0523],\n",
      "        [0.0748, 0.0467, 0.0475, 0.1397, 0.1546, 0.0725, 0.0759, 0.1545, 0.1642,\n",
      "         0.0697],\n",
      "        [0.0797, 0.0488, 0.0497, 0.1340, 0.1457, 0.0719, 0.0758, 0.1480, 0.1615,\n",
      "         0.0848],\n",
      "        [0.0806, 0.0498, 0.0510, 0.1324, 0.1421, 0.0723, 0.0764, 0.1454, 0.1591,\n",
      "         0.0907],\n",
      "        [0.0805, 0.0498, 0.0513, 0.1311, 0.1408, 0.0722, 0.0767, 0.1447, 0.1593,\n",
      "         0.0937],\n",
      "        [0.0814, 0.0515, 0.0532, 0.1288, 0.1383, 0.0732, 0.0776, 0.1421, 0.1568,\n",
      "         0.0969],\n",
      "        [0.0805, 0.0521, 0.0542, 0.1267, 0.1361, 0.0738, 0.0782, 0.1403, 0.1560,\n",
      "         0.1021],\n",
      "        [0.0798, 0.0524, 0.0547, 0.1258, 0.1352, 0.0741, 0.0785, 0.1396, 0.1557,\n",
      "         0.1042]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 150.00, Train Loss: 1.44, Val Loss: 12.62, Train BLEU: 51.04, Val BLEU: 0.45\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想 海洋 占 了 地球 球面 面积 的 75\n",
      "Reference: when you think about it , the oceans are\n",
      "Model: <SOS> when you think about , , , oceans are\n",
      "Attention Weights: tensor([[0.0469, 0.0452, 0.1948, 0.0617, 0.0619, 0.2353, 0.1829, 0.1385, 0.0321,\n",
      "         0.0007],\n",
      "        [0.0585, 0.0462, 0.1889, 0.0587, 0.0584, 0.2384, 0.1789, 0.1344, 0.0332,\n",
      "         0.0045],\n",
      "        [0.0714, 0.0482, 0.1771, 0.0555, 0.0555, 0.2300, 0.1660, 0.1308, 0.0408,\n",
      "         0.0246],\n",
      "        [0.0736, 0.0494, 0.1664, 0.0550, 0.0556, 0.2170, 0.1546, 0.1278, 0.0483,\n",
      "         0.0523],\n",
      "        [0.0738, 0.0497, 0.1573, 0.0541, 0.0550, 0.2064, 0.1480, 0.1256, 0.0524,\n",
      "         0.0779],\n",
      "        [0.0732, 0.0496, 0.1493, 0.0538, 0.0548, 0.1979, 0.1430, 0.1233, 0.0554,\n",
      "         0.0996],\n",
      "        [0.0731, 0.0501, 0.1439, 0.0541, 0.0553, 0.1909, 0.1394, 0.1216, 0.0579,\n",
      "         0.1134],\n",
      "        [0.0715, 0.0501, 0.1414, 0.0544, 0.0556, 0.1877, 0.1382, 0.1215, 0.0601,\n",
      "         0.1196],\n",
      "        [0.0705, 0.0503, 0.1396, 0.0549, 0.0562, 0.1849, 0.1373, 0.1214, 0.0619,\n",
      "         0.1229]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 都 知道 自己 正 冒 着 生命 的 危险\n",
      "Reference: we all knew we were risking our lives --\n",
      "Model: <SOS> and of the &apos;re , , , , are\n",
      "Attention Weights: tensor([[0.0542, 0.0588, 0.2169, 0.0819, 0.1163, 0.0813, 0.1467, 0.0970, 0.1354,\n",
      "         0.0116],\n",
      "        [0.0685, 0.0607, 0.2120, 0.0787, 0.1132, 0.0780, 0.1426, 0.0958, 0.1364,\n",
      "         0.0140],\n",
      "        [0.0920, 0.0671, 0.2070, 0.0748, 0.1053, 0.0733, 0.1310, 0.0918, 0.1376,\n",
      "         0.0200],\n",
      "        [0.0979, 0.0685, 0.1980, 0.0733, 0.1030, 0.0725, 0.1270, 0.0922, 0.1402,\n",
      "         0.0273],\n",
      "        [0.0983, 0.0700, 0.1918, 0.0735, 0.1024, 0.0732, 0.1251, 0.0930, 0.1404,\n",
      "         0.0323],\n",
      "        [0.0987, 0.0716, 0.1839, 0.0745, 0.1024, 0.0746, 0.1240, 0.0942, 0.1400,\n",
      "         0.0361],\n",
      "        [0.0978, 0.0720, 0.1805, 0.0752, 0.1025, 0.0754, 0.1235, 0.0948, 0.1400,\n",
      "         0.0383],\n",
      "        [0.0972, 0.0724, 0.1778, 0.0754, 0.1021, 0.0758, 0.1225, 0.0952, 0.1405,\n",
      "         0.0412],\n",
      "        [0.0967, 0.0727, 0.1766, 0.0758, 0.1020, 0.0761, 0.1221, 0.0954, 0.1403,\n",
      "         0.0423]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 151.00, Train Loss: 1.42, Val Loss: 12.64, Train BLEU: 49.59, Val BLEU: 0.44\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的 平均 深度 是 两英里 英里 <EOS> <PAD> <PAD>\n",
      "Reference: the average depth is about two miles . <EOS>\n",
      "Model: <SOS> the average depth is about two . <EOS> <EOS>\n",
      "Attention Weights: tensor([[3.5052e-01, 2.0972e-01, 1.7436e-01, 2.1807e-01, 4.1671e-02, 4.1927e-03,\n",
      "         1.4138e-03, 5.1387e-05, 1.9522e-11, 1.9522e-11],\n",
      "        [3.8399e-01, 1.9906e-01, 1.6321e-01, 2.0060e-01, 4.2551e-02, 8.2902e-03,\n",
      "         2.1204e-03, 1.8105e-04, 2.0115e-10, 2.0115e-10],\n",
      "        [4.1136e-01, 1.9039e-01, 1.5044e-01, 1.8287e-01, 4.5024e-02, 1.5792e-02,\n",
      "         3.5662e-03, 5.5772e-04, 8.8157e-10, 8.8157e-10],\n",
      "        [3.9673e-01, 1.7728e-01, 1.4739e-01, 1.8419e-01, 5.3805e-02, 3.2519e-02,\n",
      "         6.3247e-03, 1.7614e-03, 5.7347e-09, 5.7347e-09],\n",
      "        [3.7554e-01, 1.6774e-01, 1.4629e-01, 1.8799e-01, 6.1001e-02, 4.9206e-02,\n",
      "         8.9880e-03, 3.2435e-03, 1.1378e-08, 1.1378e-08],\n",
      "        [3.5694e-01, 1.6022e-01, 1.4403e-01, 1.8921e-01, 6.6664e-02, 6.5656e-02,\n",
      "         1.2180e-02, 5.0954e-03, 2.0071e-08, 2.0071e-08],\n",
      "        [3.2977e-01, 1.5595e-01, 1.4464e-01, 1.9019e-01, 7.3915e-02, 8.1868e-02,\n",
      "         1.6203e-02, 7.4719e-03, 2.1107e-08, 2.1107e-08],\n",
      "        [2.9864e-01, 1.4950e-01, 1.4352e-01, 1.8888e-01, 8.2258e-02, 1.0269e-01,\n",
      "         2.2710e-02, 1.1806e-02, 2.6180e-08, 2.6180e-08],\n",
      "        [2.9228e-01, 1.4817e-01, 1.4291e-01, 1.8744e-01, 8.3829e-02, 1.0750e-01,\n",
      "         2.4694e-02, 1.3155e-02, 2.6611e-08, 2.6611e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在 一个 房屋 房屋里 屋里 我们 100 多 人\n",
      "Reference: the school was in a house , more than\n",
      "Model: <SOS> we biodiversity the the the the the the the\n",
      "Attention Weights: tensor([[0.0100, 0.0108, 0.0994, 0.0999, 0.0759, 0.2736, 0.2722, 0.0644, 0.0409,\n",
      "         0.0528],\n",
      "        [0.0173, 0.0302, 0.1033, 0.0935, 0.0729, 0.2655, 0.2610, 0.0609, 0.0396,\n",
      "         0.0559],\n",
      "        [0.0383, 0.1064, 0.1112, 0.0870, 0.0653, 0.2245, 0.2161, 0.0528, 0.0372,\n",
      "         0.0613],\n",
      "        [0.0451, 0.1319, 0.1042, 0.0809, 0.0625, 0.2112, 0.2007, 0.0529, 0.0396,\n",
      "         0.0710],\n",
      "        [0.0480, 0.1377, 0.1013, 0.0801, 0.0629, 0.2044, 0.1926, 0.0540, 0.0418,\n",
      "         0.0772],\n",
      "        [0.0521, 0.1460, 0.0975, 0.0776, 0.0629, 0.1967, 0.1859, 0.0551, 0.0440,\n",
      "         0.0822],\n",
      "        [0.0561, 0.1530, 0.0942, 0.0761, 0.0627, 0.1890, 0.1804, 0.0559, 0.0459,\n",
      "         0.0868],\n",
      "        [0.0577, 0.1576, 0.0929, 0.0753, 0.0624, 0.1847, 0.1770, 0.0561, 0.0468,\n",
      "         0.0894],\n",
      "        [0.0602, 0.1625, 0.0922, 0.0751, 0.0628, 0.1789, 0.1719, 0.0569, 0.0482,\n",
      "         0.0914]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 152.00, Train Loss: 1.40, Val Loss: 12.65, Train BLEU: 49.35, Val BLEU: 0.44\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的 平均 深度 是 两英里 英里 <EOS> <PAD> <PAD>\n",
      "Reference: the average depth is about two miles . <EOS>\n",
      "Model: <SOS> the average depth is about two . <EOS> <EOS>\n",
      "Attention Weights: tensor([[3.6840e-01, 2.0499e-01, 1.6589e-01, 2.1240e-01, 4.1623e-02, 5.0788e-03,\n",
      "         1.5501e-03, 6.3973e-05, 2.4857e-11, 2.4857e-11],\n",
      "        [4.0163e-01, 1.9380e-01, 1.5475e-01, 1.9400e-01, 4.2849e-02, 1.0319e-02,\n",
      "         2.4166e-03, 2.3694e-04, 2.6684e-10, 2.6684e-10],\n",
      "        [4.2709e-01, 1.8444e-01, 1.4220e-01, 1.7657e-01, 4.5365e-02, 1.9549e-02,\n",
      "         4.0608e-03, 7.2574e-04, 1.1712e-09, 1.1712e-09],\n",
      "        [4.0840e-01, 1.7119e-01, 1.3943e-01, 1.7732e-01, 5.4199e-02, 3.9943e-02,\n",
      "         7.2245e-03, 2.2851e-03, 7.8958e-09, 7.8958e-09],\n",
      "        [3.8254e-01, 1.6138e-01, 1.3864e-01, 1.8121e-01, 6.1554e-02, 6.0088e-02,\n",
      "         1.0344e-02, 4.2370e-03, 1.6368e-08, 1.6368e-08],\n",
      "        [3.6102e-01, 1.5387e-01, 1.3663e-01, 1.8210e-01, 6.7065e-02, 7.8936e-02,\n",
      "         1.3855e-02, 6.5139e-03, 2.8574e-08, 2.8574e-08],\n",
      "        [3.2827e-01, 1.4891e-01, 1.3747e-01, 1.8329e-01, 7.4899e-02, 9.8649e-02,\n",
      "         1.8751e-02, 9.7559e-03, 2.9056e-08, 2.9056e-08],\n",
      "        [2.9813e-01, 1.4304e-01, 1.3619e-01, 1.8109e-01, 8.2004e-02, 1.1940e-01,\n",
      "         2.5443e-02, 1.4696e-02, 3.5482e-08, 3.5482e-08],\n",
      "        [2.9264e-01, 1.4214e-01, 1.3584e-01, 1.8001e-01, 8.3236e-02, 1.2304e-01,\n",
      "         2.7142e-02, 1.5958e-02, 3.6617e-08, 3.6617e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6 岁 那年 塔利 塔利班 占领 阿富汗 并 规定\n",
      "Reference: you see , i was six when the taliban\n",
      "Model: <SOS> the of the the matter the the the the\n",
      "Attention Weights: tensor([[1.3514e-01, 1.1409e-01, 2.1671e-01, 4.3115e-01, 7.0353e-02, 1.4477e-02,\n",
      "         8.0539e-03, 9.7956e-03, 2.2824e-04, 1.8345e-11],\n",
      "        [1.4923e-01, 1.1051e-01, 2.0776e-01, 4.2996e-01, 6.6895e-02, 1.5070e-02,\n",
      "         8.7374e-03, 1.1348e-02, 4.8456e-04, 1.5254e-10],\n",
      "        [1.8964e-01, 1.1594e-01, 1.9521e-01, 3.9620e-01, 6.2340e-02, 1.5642e-02,\n",
      "         9.5592e-03, 1.3998e-02, 1.4738e-03, 7.8897e-10],\n",
      "        [1.9690e-01, 1.1105e-01, 1.8422e-01, 3.7945e-01, 6.6690e-02, 1.9902e-02,\n",
      "         1.3528e-02, 2.3303e-02, 4.9529e-03, 7.0684e-09],\n",
      "        [1.9419e-01, 1.0741e-01, 1.7874e-01, 3.7007e-01, 6.9902e-02, 2.3017e-02,\n",
      "         1.6649e-02, 3.1531e-02, 8.4856e-03, 1.2514e-08],\n",
      "        [1.8707e-01, 1.0522e-01, 1.7251e-01, 3.5438e-01, 7.5353e-02, 2.8135e-02,\n",
      "         2.1683e-02, 4.2051e-02, 1.3591e-02, 1.9570e-08],\n",
      "        [1.7702e-01, 1.0463e-01, 1.6611e-01, 3.3313e-01, 8.1974e-02, 3.4809e-02,\n",
      "         2.8156e-02, 5.3899e-02, 2.0266e-02, 2.1466e-08],\n",
      "        [1.7342e-01, 1.0427e-01, 1.6312e-01, 3.2352e-01, 8.4516e-02, 3.7564e-02,\n",
      "         3.0934e-02, 5.8868e-02, 2.3785e-02, 2.4882e-08],\n",
      "        [1.7278e-01, 1.0437e-01, 1.6251e-01, 3.2042e-01, 8.5089e-02, 3.8307e-02,\n",
      "         3.1676e-02, 6.0117e-02, 2.4734e-02, 2.7561e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 153.00, Train Loss: 1.38, Val Loss: 12.66, Train BLEU: 53.24, Val BLEU: 0.43\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本 基本上 都 没有 被 开发 发过 但是 像\n",
      "Reference: it &apos;s mostly unexplored , and yet there are\n",
      "Model: <SOS> people &apos;s mostly unexplored , and , are are\n",
      "Attention Weights: tensor([[0.0551, 0.0566, 0.2219, 0.0810, 0.1088, 0.0792, 0.1392, 0.0981, 0.1483,\n",
      "         0.0117],\n",
      "        [0.0718, 0.0598, 0.2143, 0.0779, 0.1056, 0.0760, 0.1345, 0.0969, 0.1484,\n",
      "         0.0148],\n",
      "        [0.0957, 0.0663, 0.2083, 0.0742, 0.0986, 0.0717, 0.1238, 0.0927, 0.1475,\n",
      "         0.0213],\n",
      "        [0.1014, 0.0678, 0.1992, 0.0728, 0.0967, 0.0710, 0.1203, 0.0929, 0.1493,\n",
      "         0.0286],\n",
      "        [0.1015, 0.0687, 0.1948, 0.0725, 0.0964, 0.0714, 0.1192, 0.0932, 0.1492,\n",
      "         0.0331],\n",
      "        [0.1024, 0.0700, 0.1877, 0.0731, 0.0967, 0.0724, 0.1188, 0.0942, 0.1486,\n",
      "         0.0361],\n",
      "        [0.1015, 0.0705, 0.1842, 0.0736, 0.0970, 0.0732, 0.1186, 0.0948, 0.1482,\n",
      "         0.0384],\n",
      "        [0.1005, 0.0709, 0.1814, 0.0739, 0.0969, 0.0738, 0.1179, 0.0951, 0.1484,\n",
      "         0.0413],\n",
      "        [0.0999, 0.0711, 0.1802, 0.0743, 0.0969, 0.0742, 0.1177, 0.0953, 0.1481,\n",
      "         0.0424]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 很 幸运 幸运地 成长 在 一个 珍视 教育 也\n",
      "Reference: i was very lucky to grow up in a\n",
      "Model: <SOS> we biodiversity have the the and and the are\n",
      "Attention Weights: tensor([[3.6145e-01, 2.4583e-01, 1.8183e-01, 2.0194e-01, 8.9586e-03, 6.0690e-10,\n",
      "         6.0690e-10, 6.0690e-10, 6.0690e-10, 6.0690e-10],\n",
      "        [3.8219e-01, 2.3445e-01, 1.7270e-01, 1.9682e-01, 1.3839e-02, 2.7752e-09,\n",
      "         2.7752e-09, 2.7752e-09, 2.7752e-09, 2.7752e-09],\n",
      "        [4.0646e-01, 2.2147e-01, 1.5780e-01, 1.8739e-01, 2.6879e-02, 1.1291e-08,\n",
      "         1.1291e-08, 1.1291e-08, 1.1291e-08, 1.1291e-08],\n",
      "        [3.6514e-01, 2.0118e-01, 1.5594e-01, 2.0945e-01, 6.8280e-02, 6.4711e-08,\n",
      "         6.4711e-08, 6.4711e-08, 6.4711e-08, 6.4711e-08],\n",
      "        [3.2134e-01, 1.8971e-01, 1.5839e-01, 2.2608e-01, 1.0448e-01, 1.2117e-07,\n",
      "         1.2117e-07, 1.2117e-07, 1.2117e-07, 1.2117e-07],\n",
      "        [2.7976e-01, 1.8128e-01, 1.6655e-01, 2.3941e-01, 1.3300e-01, 1.2211e-07,\n",
      "         1.2211e-07, 1.2211e-07, 1.2211e-07, 1.2211e-07],\n",
      "        [2.6678e-01, 1.7909e-01, 1.6829e-01, 2.3944e-01, 1.4640e-01, 1.4891e-07,\n",
      "         1.4891e-07, 1.4891e-07, 1.4891e-07, 1.4891e-07],\n",
      "        [2.6504e-01, 1.7885e-01, 1.6859e-01, 2.3938e-01, 1.4815e-01, 1.6576e-07,\n",
      "         1.6576e-07, 1.6576e-07, 1.6576e-07, 1.6576e-07],\n",
      "        [2.6476e-01, 1.7865e-01, 1.6844e-01, 2.3929e-01, 1.4885e-01, 1.7182e-07,\n",
      "         1.7182e-07, 1.7182e-07, 1.7182e-07, 1.7182e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 154.00, Train Loss: 1.36, Val Loss: 12.66, Train BLEU: 56.05, Val BLEU: 0.43\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 这位 是 比尔 <UNK> 我 是 大卫 <UNK>\n",
      "Reference: this is bill lange . i &apos;m dave gallo\n",
      "Model: <SOS> this is bill lange . i &apos;m dave gallo\n",
      "Attention Weights: tensor([[0.0762, 0.0312, 0.1944, 0.1793, 0.0877, 0.0411, 0.1943, 0.1486, 0.0454,\n",
      "         0.0019],\n",
      "        [0.0995, 0.0434, 0.1957, 0.1713, 0.1049, 0.0564, 0.1647, 0.1220, 0.0396,\n",
      "         0.0025],\n",
      "        [0.1174, 0.0744, 0.1785, 0.1459, 0.1308, 0.0919, 0.1285, 0.0921, 0.0352,\n",
      "         0.0054],\n",
      "        [0.1157, 0.0977, 0.1581, 0.1287, 0.1491, 0.1137, 0.1102, 0.0805, 0.0360,\n",
      "         0.0103],\n",
      "        [0.1076, 0.1181, 0.1427, 0.1129, 0.1612, 0.1370, 0.0978, 0.0712, 0.0353,\n",
      "         0.0160],\n",
      "        [0.0980, 0.1502, 0.1205, 0.0920, 0.1739, 0.1708, 0.0772, 0.0566, 0.0337,\n",
      "         0.0272],\n",
      "        [0.0946, 0.1636, 0.1102, 0.0838, 0.1732, 0.1844, 0.0695, 0.0517, 0.0339,\n",
      "         0.0351],\n",
      "        [0.0931, 0.1697, 0.1048, 0.0799, 0.1723, 0.1899, 0.0659, 0.0498, 0.0345,\n",
      "         0.0402],\n",
      "        [0.0925, 0.1717, 0.1028, 0.0786, 0.1722, 0.1913, 0.0646, 0.0491, 0.0347,\n",
      "         0.0424]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他们 知道 我们 的 住处 吗 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: do they know where we live ? <EOS> <PAD>\n",
      "Model: <SOS> but &apos;s a those different working . <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.5681e-05, 1.2359e-05, 5.3168e-05, 3.5122e-04, 1.7319e-02, 2.4992e-01,\n",
      "         2.0709e-01, 1.9306e-01, 1.3829e-01, 1.9390e-01],\n",
      "        [1.2052e-05, 9.4116e-06, 4.7433e-05, 3.4409e-04, 2.1084e-02, 2.9735e-01,\n",
      "         1.9851e-01, 1.7877e-01, 1.2473e-01, 1.7915e-01],\n",
      "        [2.8588e-04, 2.4156e-04, 9.7859e-04, 5.3171e-03, 1.1515e-01, 3.4977e-01,\n",
      "         1.6351e-01, 1.3112e-01, 9.2219e-02, 1.4141e-01],\n",
      "        [1.6250e-03, 1.4306e-03, 4.5141e-03, 1.8466e-02, 1.9602e-01, 3.1479e-01,\n",
      "         1.3522e-01, 1.0862e-01, 8.0680e-02, 1.3863e-01],\n",
      "        [5.8686e-03, 5.2880e-03, 1.3196e-02, 4.1767e-02, 2.5527e-01, 2.6091e-01,\n",
      "         1.1112e-01, 9.3741e-02, 7.4482e-02, 1.3836e-01],\n",
      "        [1.3804e-02, 1.2870e-02, 2.7826e-02, 7.3093e-02, 2.9322e-01, 2.1311e-01,\n",
      "         9.2297e-02, 7.9635e-02, 6.6580e-02, 1.2756e-01],\n",
      "        [1.9487e-02, 1.8101e-02, 3.6902e-02, 8.9513e-02, 3.0059e-01, 1.9075e-01,\n",
      "         8.4482e-02, 7.3763e-02, 6.3354e-02, 1.2306e-01],\n",
      "        [2.2072e-02, 2.0547e-02, 4.0717e-02, 9.5304e-02, 2.9931e-01, 1.8317e-01,\n",
      "         8.2258e-02, 7.2166e-02, 6.2612e-02, 1.2184e-01],\n",
      "        [2.3066e-02, 2.1527e-02, 4.2212e-02, 9.7397e-02, 2.9868e-01, 1.7994e-01,\n",
      "         8.1434e-02, 7.1690e-02, 6.2529e-02, 1.2153e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 155.00, Train Loss: 1.34, Val Loss: 12.68, Train BLEU: 54.57, Val BLEU: 0.45\n",
      "Sampling from training predictions...\n",
      "Source: 是 我 最 喜欢 的 因为 它 哪 都 能动\n",
      "Reference: it &apos;s one of my favorites , because it\n",
      "Model: <SOS> it &apos;s one of my favorites , because because\n",
      "Attention Weights: tensor([[0.1097, 0.1002, 0.1136, 0.1448, 0.1429, 0.1932, 0.1058, 0.0642, 0.0253,\n",
      "         0.0003],\n",
      "        [0.1276, 0.1015, 0.1131, 0.1418, 0.1383, 0.1902, 0.1009, 0.0609, 0.0250,\n",
      "         0.0007],\n",
      "        [0.1565, 0.1059, 0.1105, 0.1324, 0.1276, 0.1745, 0.0963, 0.0623, 0.0304,\n",
      "         0.0034],\n",
      "        [0.1635, 0.1042, 0.1067, 0.1248, 0.1195, 0.1642, 0.0952, 0.0676, 0.0414,\n",
      "         0.0129],\n",
      "        [0.1604, 0.1013, 0.1043, 0.1213, 0.1156, 0.1605, 0.0948, 0.0704, 0.0479,\n",
      "         0.0234],\n",
      "        [0.1554, 0.0980, 0.1012, 0.1174, 0.1116, 0.1567, 0.0938, 0.0727, 0.0548,\n",
      "         0.0383],\n",
      "        [0.1478, 0.0956, 0.0990, 0.1141, 0.1088, 0.1512, 0.0942, 0.0762, 0.0617,\n",
      "         0.0515],\n",
      "        [0.1424, 0.0936, 0.0976, 0.1126, 0.1075, 0.1484, 0.0945, 0.0782, 0.0657,\n",
      "         0.0594],\n",
      "        [0.1392, 0.0926, 0.0968, 0.1116, 0.1068, 0.1467, 0.0949, 0.0795, 0.0681,\n",
      "         0.0638]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在 一个 房屋 房屋里 屋里 我们 100 多 人\n",
      "Reference: the school was in a house , more than\n",
      "Model: <SOS> we biodiversity the the the the the the the\n",
      "Attention Weights: tensor([[0.0096, 0.0163, 0.0949, 0.0884, 0.0674, 0.2743, 0.3068, 0.0575, 0.0330,\n",
      "         0.0517],\n",
      "        [0.0186, 0.0534, 0.1010, 0.0837, 0.0653, 0.2566, 0.2786, 0.0543, 0.0327,\n",
      "         0.0559],\n",
      "        [0.0392, 0.1653, 0.1043, 0.0754, 0.0565, 0.2068, 0.2168, 0.0460, 0.0305,\n",
      "         0.0592],\n",
      "        [0.0452, 0.1919, 0.0979, 0.0708, 0.0548, 0.1927, 0.1992, 0.0467, 0.0331,\n",
      "         0.0679],\n",
      "        [0.0471, 0.1945, 0.0957, 0.0700, 0.0550, 0.1886, 0.1930, 0.0474, 0.0347,\n",
      "         0.0739],\n",
      "        [0.0500, 0.2030, 0.0918, 0.0675, 0.0544, 0.1832, 0.1868, 0.0478, 0.0363,\n",
      "         0.0791],\n",
      "        [0.0533, 0.2091, 0.0889, 0.0663, 0.0541, 0.1772, 0.1810, 0.0483, 0.0380,\n",
      "         0.0840],\n",
      "        [0.0552, 0.2120, 0.0879, 0.0660, 0.0542, 0.1729, 0.1765, 0.0490, 0.0394,\n",
      "         0.0869],\n",
      "        [0.0577, 0.2157, 0.0873, 0.0662, 0.0549, 0.1673, 0.1704, 0.0500, 0.0411,\n",
      "         0.0892]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 156.00, Train Loss: 1.32, Val Loss: 12.70, Train BLEU: 56.97, Val BLEU: 0.44\n",
      "Sampling from training predictions...\n",
      "Source: 地球 的 大部 大部分 部分 都 是 海水 <EOS> <PAD>\n",
      "Reference: most of the planet is ocean water . <EOS>\n",
      "Model: <SOS> most of the planet is . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.2585e-01, 1.0383e-01, 2.0208e-01, 4.7488e-01, 6.6371e-02, 1.1835e-02,\n",
      "         6.2082e-03, 8.6979e-03, 2.4040e-04, 2.3154e-11],\n",
      "        [1.4224e-01, 1.0221e-01, 1.9428e-01, 4.6701e-01, 6.3365e-02, 1.2681e-02,\n",
      "         7.0248e-03, 1.0618e-02, 5.7178e-04, 2.0144e-10],\n",
      "        [1.8329e-01, 1.0759e-01, 1.8236e-01, 4.3075e-01, 5.9227e-02, 1.3362e-02,\n",
      "         7.8764e-03, 1.3764e-02, 1.7848e-03, 9.2887e-10],\n",
      "        [1.9183e-01, 1.0440e-01, 1.7326e-01, 4.0668e-01, 6.4525e-02, 1.7776e-02,\n",
      "         1.1786e-02, 2.3857e-02, 5.8770e-03, 8.5010e-09],\n",
      "        [1.8921e-01, 1.0100e-01, 1.6828e-01, 3.9560e-01, 6.7761e-02, 2.0845e-02,\n",
      "         1.4752e-02, 3.2715e-02, 9.8349e-03, 1.5634e-08],\n",
      "        [1.8170e-01, 9.8849e-02, 1.6222e-01, 3.7571e-01, 7.3601e-02, 2.6534e-02,\n",
      "         2.0250e-02, 4.5036e-02, 1.6107e-02, 2.5902e-08],\n",
      "        [1.7176e-01, 9.8275e-02, 1.5687e-01, 3.4937e-01, 8.0034e-02, 3.3522e-02,\n",
      "         2.7135e-02, 5.8470e-02, 2.4563e-02, 3.1420e-08],\n",
      "        [1.6839e-01, 9.7993e-02, 1.5478e-01, 3.3851e-01, 8.2249e-02, 3.6093e-02,\n",
      "         2.9798e-02, 6.3613e-02, 2.8574e-02, 3.5540e-08],\n",
      "        [1.6793e-01, 9.8088e-02, 1.5444e-01, 3.3529e-01, 8.2754e-02, 3.6752e-02,\n",
      "         3.0453e-02, 6.4783e-02, 2.9513e-02, 3.8957e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 出身 阿富汗 边远 <UNK> 地区 有着 与 他人 不同\n",
      "Reference: a total maverick from a remote province of afghanistan\n",
      "Model: <SOS> with vibrant video clips captured , , the the\n",
      "Attention Weights: tensor([[1.4514e-01, 1.5075e-01, 1.5604e-01, 4.9880e-01, 3.8847e-02, 6.4114e-03,\n",
      "         2.5031e-03, 1.3862e-03, 1.1435e-04, 1.2150e-11],\n",
      "        [1.5827e-01, 1.3897e-01, 1.3913e-01, 4.9649e-01, 5.8238e-02, 5.5092e-03,\n",
      "         2.1145e-03, 1.1410e-03, 1.2426e-04, 4.1331e-11],\n",
      "        [1.7099e-01, 1.2165e-01, 1.1816e-01, 4.4565e-01, 1.3414e-01, 5.6187e-03,\n",
      "         2.1999e-03, 1.2763e-03, 3.0962e-04, 1.6520e-10],\n",
      "        [1.4878e-01, 9.5870e-02, 9.4559e-02, 3.9474e-01, 2.5454e-01, 6.3029e-03,\n",
      "         2.6176e-03, 1.7377e-03, 8.5150e-04, 1.1000e-09],\n",
      "        [1.2392e-01, 7.7839e-02, 7.8409e-02, 3.5879e-01, 3.4694e-01, 7.2272e-03,\n",
      "         3.1521e-03, 2.2521e-03, 1.4762e-03, 2.8218e-09],\n",
      "        [1.0614e-01, 6.6108e-02, 6.7494e-02, 3.2384e-01, 4.1847e-01, 8.7049e-03,\n",
      "         3.9765e-03, 2.9864e-03, 2.2784e-03, 5.5883e-09],\n",
      "        [9.3273e-02, 5.9108e-02, 6.1555e-02, 2.9340e-01, 4.6639e-01, 1.1516e-02,\n",
      "         5.8503e-03, 4.7795e-03, 4.1250e-03, 8.9612e-09],\n",
      "        [9.1843e-02, 6.0354e-02, 6.4151e-02, 2.8872e-01, 4.5978e-01, 1.4444e-02,\n",
      "         7.8498e-03, 6.7307e-03, 6.1343e-03, 1.1944e-08],\n",
      "        [9.1876e-02, 6.0939e-02, 6.5136e-02, 2.8854e-01, 4.5605e-01, 1.5147e-02,\n",
      "         8.3557e-03, 7.2474e-03, 6.7103e-03, 1.3264e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 157.00, Train Loss: 1.30, Val Loss: 12.70, Train BLEU: 58.90, Val BLEU: 0.43\n",
      "Sampling from training predictions...\n",
      "Source: 底下 这些 都 是 <UNK> 它们 上上 上上下下 上下 下下\n",
      "Reference: it &apos;s got these fishing <UNK> on the bottom\n",
      "Model: <SOS> it &apos;s got these fishing <UNK> on on bottom\n",
      "Attention Weights: tensor([[0.0802, 0.0782, 0.0653, 0.0453, 0.0078, 0.1805, 0.3895, 0.1348, 0.0183,\n",
      "         0.0002],\n",
      "        [0.0830, 0.0734, 0.0631, 0.0482, 0.0139, 0.1675, 0.4211, 0.1131, 0.0162,\n",
      "         0.0004],\n",
      "        [0.0910, 0.0675, 0.0585, 0.0513, 0.0330, 0.1472, 0.4481, 0.0865, 0.0155,\n",
      "         0.0014],\n",
      "        [0.0837, 0.0570, 0.0520, 0.0515, 0.0749, 0.1282, 0.4570, 0.0726, 0.0181,\n",
      "         0.0050],\n",
      "        [0.0754, 0.0494, 0.0461, 0.0471, 0.1007, 0.1197, 0.4638, 0.0693, 0.0199,\n",
      "         0.0087],\n",
      "        [0.0688, 0.0440, 0.0418, 0.0445, 0.1280, 0.1129, 0.4483, 0.0699, 0.0242,\n",
      "         0.0175],\n",
      "        [0.0674, 0.0426, 0.0408, 0.0451, 0.1476, 0.1071, 0.4235, 0.0698, 0.0282,\n",
      "         0.0280],\n",
      "        [0.0684, 0.0442, 0.0429, 0.0482, 0.1541, 0.1052, 0.3944, 0.0730, 0.0331,\n",
      "         0.0366],\n",
      "        [0.0699, 0.0464, 0.0454, 0.0516, 0.1601, 0.1040, 0.3682, 0.0747, 0.0372,\n",
      "         0.0425]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 有时 学校 <UNK> 突然 <UNK> 一周 因为 被 塔利 塔利班\n",
      "Reference: from time to time , the school would suddenly\n",
      "Model: <SOS> it &apos;s got clips , , , the the\n",
      "Attention Weights: tensor([[0.1021, 0.0925, 0.1040, 0.1408, 0.1298, 0.1317, 0.1204, 0.0936, 0.0618,\n",
      "         0.0232],\n",
      "        [0.1249, 0.0945, 0.1031, 0.1352, 0.1228, 0.1243, 0.1145, 0.0910, 0.0624,\n",
      "         0.0274],\n",
      "        [0.1527, 0.0981, 0.1002, 0.1241, 0.1126, 0.1140, 0.1065, 0.0884, 0.0664,\n",
      "         0.0369],\n",
      "        [0.1551, 0.0968, 0.0981, 0.1192, 0.1080, 0.1099, 0.1041, 0.0892, 0.0717,\n",
      "         0.0478],\n",
      "        [0.1513, 0.0962, 0.0976, 0.1171, 0.1063, 0.1085, 0.1035, 0.0903, 0.0750,\n",
      "         0.0544],\n",
      "        [0.1516, 0.0950, 0.0968, 0.1163, 0.1052, 0.1078, 0.1031, 0.0906, 0.0763,\n",
      "         0.0574],\n",
      "        [0.1479, 0.0936, 0.0961, 0.1155, 0.1043, 0.1074, 0.1033, 0.0918, 0.0787,\n",
      "         0.0615],\n",
      "        [0.1456, 0.0934, 0.0961, 0.1151, 0.1039, 0.1070, 0.1031, 0.0922, 0.0798,\n",
      "         0.0638],\n",
      "        [0.1434, 0.0927, 0.0958, 0.1144, 0.1034, 0.1066, 0.1029, 0.0926, 0.0812,\n",
      "         0.0670]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 158.00, Train Loss: 1.27, Val Loss: 12.72, Train BLEU: 58.89, Val BLEU: 0.44\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克 泰坦尼克号 坦尼 尼克 号 是 拿 了 不少\n",
      "Reference: the truth of the matter is that the titanic\n",
      "Model: <SOS> the truth of the matter the the the the\n",
      "Attention Weights: tensor([[0.0292, 0.0125, 0.0115, 0.0493, 0.2106, 0.1570, 0.1522, 0.1323, 0.1020,\n",
      "         0.1435],\n",
      "        [0.0521, 0.0491, 0.0482, 0.1562, 0.2019, 0.1246, 0.1074, 0.0904, 0.0688,\n",
      "         0.1013],\n",
      "        [0.0658, 0.1083, 0.1155, 0.2936, 0.1392, 0.0728, 0.0576, 0.0483, 0.0381,\n",
      "         0.0609],\n",
      "        [0.0669, 0.1279, 0.1349, 0.3033, 0.1206, 0.0623, 0.0493, 0.0422, 0.0345,\n",
      "         0.0581],\n",
      "        [0.0689, 0.1452, 0.1483, 0.2988, 0.1067, 0.0560, 0.0450, 0.0394, 0.0334,\n",
      "         0.0584],\n",
      "        [0.0677, 0.1609, 0.1670, 0.3040, 0.0919, 0.0478, 0.0382, 0.0344, 0.0303,\n",
      "         0.0577],\n",
      "        [0.0726, 0.1679, 0.1726, 0.2866, 0.0852, 0.0459, 0.0376, 0.0352, 0.0326,\n",
      "         0.0639],\n",
      "        [0.0759, 0.1688, 0.1722, 0.2732, 0.0845, 0.0471, 0.0391, 0.0369, 0.0348,\n",
      "         0.0675],\n",
      "        [0.0773, 0.1688, 0.1711, 0.2670, 0.0849, 0.0480, 0.0399, 0.0378, 0.0360,\n",
      "         0.0692]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 有时 学校 <UNK> 突然 <UNK> 一周 因为 被 塔利 塔利班\n",
      "Reference: from time to time , the school would suddenly\n",
      "Model: <SOS> it &apos;s got clips , , , the the\n",
      "Attention Weights: tensor([[0.1032, 0.0902, 0.1005, 0.1458, 0.1283, 0.1326, 0.1203, 0.0925, 0.0621,\n",
      "         0.0245],\n",
      "        [0.1264, 0.0923, 0.0999, 0.1395, 0.1212, 0.1248, 0.1142, 0.0899, 0.0628,\n",
      "         0.0290],\n",
      "        [0.1549, 0.0962, 0.0974, 0.1273, 0.1109, 0.1141, 0.1060, 0.0874, 0.0668,\n",
      "         0.0391],\n",
      "        [0.1567, 0.0951, 0.0956, 0.1217, 0.1063, 0.1098, 0.1036, 0.0883, 0.0722,\n",
      "         0.0507],\n",
      "        [0.1527, 0.0945, 0.0952, 0.1191, 0.1045, 0.1082, 0.1028, 0.0894, 0.0757,\n",
      "         0.0580],\n",
      "        [0.1526, 0.0932, 0.0944, 0.1182, 0.1033, 0.1073, 0.1024, 0.0898, 0.0772,\n",
      "         0.0616],\n",
      "        [0.1483, 0.0919, 0.0939, 0.1171, 0.1025, 0.1069, 0.1026, 0.0910, 0.0797,\n",
      "         0.0661],\n",
      "        [0.1460, 0.0917, 0.0939, 0.1166, 0.1022, 0.1066, 0.1024, 0.0914, 0.0808,\n",
      "         0.0684],\n",
      "        [0.1435, 0.0911, 0.0937, 0.1160, 0.1017, 0.1062, 0.1023, 0.0918, 0.0821,\n",
      "         0.0716]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 159.00, Train Loss: 1.26, Val Loss: 12.71, Train BLEU: 59.16, Val BLEU: 0.44\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这 有 不少 精彩 的 泰坦 泰坦尼克 坦尼 尼克\n",
      "Reference: we &apos;ve got some of the most incredible video\n",
      "Model: <SOS> we &apos;ve got some of the the incredible the\n",
      "Attention Weights: tensor([[0.0688, 0.0585, 0.0703, 0.2642, 0.3368, 0.0690, 0.1207, 0.0057, 0.0038,\n",
      "         0.0021],\n",
      "        [0.0735, 0.0506, 0.0590, 0.2352, 0.3125, 0.0641, 0.1549, 0.0279, 0.0180,\n",
      "         0.0043],\n",
      "        [0.0755, 0.0446, 0.0503, 0.1942, 0.2658, 0.0620, 0.1735, 0.0772, 0.0497,\n",
      "         0.0073],\n",
      "        [0.0716, 0.0423, 0.0478, 0.1727, 0.2300, 0.0619, 0.1749, 0.1182, 0.0702,\n",
      "         0.0104],\n",
      "        [0.0651, 0.0382, 0.0437, 0.1585, 0.2111, 0.0583, 0.1766, 0.1501, 0.0863,\n",
      "         0.0120],\n",
      "        [0.0643, 0.0377, 0.0432, 0.1562, 0.2077, 0.0580, 0.1776, 0.1543, 0.0884,\n",
      "         0.0124],\n",
      "        [0.0651, 0.0388, 0.0447, 0.1547, 0.2047, 0.0594, 0.1782, 0.1523, 0.0883,\n",
      "         0.0139],\n",
      "        [0.0662, 0.0404, 0.0467, 0.1519, 0.1994, 0.0613, 0.1756, 0.1517, 0.0904,\n",
      "         0.0164],\n",
      "        [0.0667, 0.0414, 0.0477, 0.1484, 0.1941, 0.0627, 0.1738, 0.1532, 0.0939,\n",
      "         0.0182]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很 舒服 但 夏天 却 <UNK> <EOS> <PAD> <PAD>\n",
      "Reference: it was cozy in winter but extremely hot in\n",
      "Model: <SOS> life in the deep oceans <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0489, 0.0308, 0.1150, 0.0469, 0.1499, 0.4961, 0.0582, 0.0318, 0.0155,\n",
      "         0.0069],\n",
      "        [0.0352, 0.0166, 0.0538, 0.0232, 0.0795, 0.7353, 0.0281, 0.0153, 0.0084,\n",
      "         0.0047],\n",
      "        [0.0329, 0.0134, 0.0397, 0.0177, 0.0601, 0.7930, 0.0209, 0.0114, 0.0067,\n",
      "         0.0042],\n",
      "        [0.0352, 0.0148, 0.0404, 0.0191, 0.0608, 0.7801, 0.0223, 0.0130, 0.0083,\n",
      "         0.0059],\n",
      "        [0.0378, 0.0164, 0.0430, 0.0211, 0.0640, 0.7605, 0.0244, 0.0150, 0.0101,\n",
      "         0.0077],\n",
      "        [0.0399, 0.0172, 0.0448, 0.0221, 0.0674, 0.7477, 0.0248, 0.0159, 0.0112,\n",
      "         0.0091],\n",
      "        [0.0478, 0.0220, 0.0546, 0.0282, 0.0809, 0.6871, 0.0300, 0.0206, 0.0154,\n",
      "         0.0136],\n",
      "        [0.0504, 0.0238, 0.0572, 0.0303, 0.0841, 0.6679, 0.0319, 0.0223, 0.0169,\n",
      "         0.0152],\n",
      "        [0.0511, 0.0245, 0.0588, 0.0314, 0.0862, 0.6585, 0.0327, 0.0231, 0.0176,\n",
      "         0.0160]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 160.00, Train Loss: 1.24, Val Loss: 12.71, Train BLEU: 60.81, Val BLEU: 0.44\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克 泰坦尼克号 坦尼 尼克 号 是 拿 了 不少\n",
      "Reference: the truth of the matter is that the titanic\n",
      "Model: <SOS> the truth of the matter the the the the\n",
      "Attention Weights: tensor([[0.0240, 0.0086, 0.0076, 0.0352, 0.1925, 0.1643, 0.1656, 0.1448, 0.1107,\n",
      "         0.1466],\n",
      "        [0.0436, 0.0321, 0.0303, 0.1073, 0.2026, 0.1454, 0.1312, 0.1109, 0.0835,\n",
      "         0.1131],\n",
      "        [0.0649, 0.0848, 0.0869, 0.2405, 0.1574, 0.0947, 0.0780, 0.0658, 0.0513,\n",
      "         0.0756],\n",
      "        [0.0676, 0.1029, 0.1043, 0.2528, 0.1397, 0.0832, 0.0686, 0.0593, 0.0479,\n",
      "         0.0739],\n",
      "        [0.0700, 0.1177, 0.1158, 0.2517, 0.1259, 0.0762, 0.0638, 0.0564, 0.0471,\n",
      "         0.0753],\n",
      "        [0.0693, 0.1359, 0.1359, 0.2639, 0.1091, 0.0654, 0.0543, 0.0492, 0.0429,\n",
      "         0.0741],\n",
      "        [0.0730, 0.1476, 0.1487, 0.2619, 0.0963, 0.0582, 0.0489, 0.0461, 0.0423,\n",
      "         0.0771],\n",
      "        [0.0765, 0.1507, 0.1508, 0.2514, 0.0937, 0.0578, 0.0491, 0.0467, 0.0437,\n",
      "         0.0797],\n",
      "        [0.0781, 0.1517, 0.1506, 0.2453, 0.0933, 0.0582, 0.0495, 0.0473, 0.0447,\n",
      "         0.0813]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 很 幸运 幸运地 成长 在 一个 珍视 教育 也\n",
      "Reference: i was very lucky to grow up in a\n",
      "Model: <SOS> we biodiversity have the partnered and and the are\n",
      "Attention Weights: tensor([[3.6291e-01, 2.2745e-01, 1.7355e-01, 2.2415e-01, 1.1940e-02, 8.1512e-10,\n",
      "         8.1512e-10, 8.1512e-10, 8.1512e-10, 8.1512e-10],\n",
      "        [3.8490e-01, 2.1933e-01, 1.6360e-01, 2.1480e-01, 1.7371e-02, 3.0546e-09,\n",
      "         3.0546e-09, 3.0546e-09, 3.0546e-09, 3.0546e-09],\n",
      "        [4.0489e-01, 2.0718e-01, 1.5065e-01, 2.0528e-01, 3.1995e-02, 9.7520e-09,\n",
      "         9.7520e-09, 9.7520e-09, 9.7520e-09, 9.7520e-09],\n",
      "        [3.5931e-01, 1.8700e-01, 1.4900e-01, 2.2818e-01, 7.6497e-02, 5.0748e-08,\n",
      "         5.0748e-08, 5.0748e-08, 5.0748e-08, 5.0748e-08],\n",
      "        [3.0959e-01, 1.7667e-01, 1.5197e-01, 2.4539e-01, 1.1637e-01, 9.8301e-08,\n",
      "         9.8301e-08, 9.8301e-08, 9.8301e-08, 9.8301e-08],\n",
      "        [2.5745e-01, 1.6899e-01, 1.6271e-01, 2.5743e-01, 1.5341e-01, 1.1151e-07,\n",
      "         1.1151e-07, 1.1151e-07, 1.1151e-07, 1.1151e-07],\n",
      "        [2.4319e-01, 1.6676e-01, 1.6488e-01, 2.5592e-01, 1.6925e-01, 1.3823e-07,\n",
      "         1.3823e-07, 1.3823e-07, 1.3823e-07, 1.3823e-07],\n",
      "        [2.4165e-01, 1.6633e-01, 1.6504e-01, 2.5574e-01, 1.7124e-01, 1.5277e-07,\n",
      "         1.5277e-07, 1.5277e-07, 1.5277e-07, 1.5277e-07],\n",
      "        [2.4101e-01, 1.6601e-01, 1.6490e-01, 2.5561e-01, 1.7248e-01, 1.6007e-07,\n",
      "         1.6007e-07, 1.6007e-07, 1.6007e-07, 1.6007e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 161.00, Train Loss: 1.22, Val Loss: 12.75, Train BLEU: 59.86, Val BLEU: 0.44\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本 基本上 都 没有 被 开发 发过 但是 像\n",
      "Reference: it &apos;s mostly unexplored , and yet there are\n",
      "Model: <SOS> people &apos;s mostly unexplored , and there are are\n",
      "Attention Weights: tensor([[0.0440, 0.0476, 0.2530, 0.0728, 0.0939, 0.0694, 0.1403, 0.0977, 0.1705,\n",
      "         0.0107],\n",
      "        [0.0589, 0.0511, 0.2429, 0.0705, 0.0923, 0.0673, 0.1359, 0.0973, 0.1701,\n",
      "         0.0137],\n",
      "        [0.0818, 0.0589, 0.2316, 0.0693, 0.0883, 0.0659, 0.1260, 0.0937, 0.1644,\n",
      "         0.0202],\n",
      "        [0.0893, 0.0627, 0.2126, 0.0703, 0.0889, 0.0678, 0.1231, 0.0948, 0.1619,\n",
      "         0.0287],\n",
      "        [0.0912, 0.0647, 0.2035, 0.0707, 0.0895, 0.0689, 0.1215, 0.0954, 0.1601,\n",
      "         0.0345],\n",
      "        [0.0926, 0.0654, 0.1955, 0.0708, 0.0898, 0.0696, 0.1209, 0.0964, 0.1605,\n",
      "         0.0384],\n",
      "        [0.0916, 0.0655, 0.1927, 0.0707, 0.0903, 0.0701, 0.1209, 0.0971, 0.1605,\n",
      "         0.0407],\n",
      "        [0.0914, 0.0663, 0.1886, 0.0711, 0.0905, 0.0706, 0.1200, 0.0974, 0.1598,\n",
      "         0.0443],\n",
      "        [0.0909, 0.0665, 0.1875, 0.0713, 0.0907, 0.0710, 0.1198, 0.0976, 0.1593,\n",
      "         0.0454]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 很 幸运 幸运地 成长 在 一个 珍视 教育 也\n",
      "Reference: i was very lucky to grow up in a\n",
      "Model: <SOS> we &apos;s have have have and and the are\n",
      "Attention Weights: tensor([[3.6330e-01, 2.2247e-01, 1.7038e-01, 2.3085e-01, 1.2992e-02, 8.6081e-10,\n",
      "         8.6081e-10, 8.6081e-10, 8.6081e-10, 8.6081e-10],\n",
      "        [3.8449e-01, 2.1461e-01, 1.6068e-01, 2.2129e-01, 1.8931e-02, 3.2203e-09,\n",
      "         3.2203e-09, 3.2203e-09, 3.2203e-09, 3.2203e-09],\n",
      "        [4.0313e-01, 2.0250e-01, 1.4808e-01, 2.1132e-01, 3.4968e-02, 1.0333e-08,\n",
      "         1.0333e-08, 1.0333e-08, 1.0333e-08, 1.0333e-08],\n",
      "        [3.5312e-01, 1.8224e-01, 1.4685e-01, 2.3417e-01, 8.3614e-02, 5.3511e-08,\n",
      "         5.3511e-08, 5.3511e-08, 5.3511e-08, 5.3511e-08],\n",
      "        [3.0297e-01, 1.7233e-01, 1.4990e-01, 2.4941e-01, 1.2539e-01, 1.0270e-07,\n",
      "         1.0270e-07, 1.0270e-07, 1.0270e-07, 1.0270e-07],\n",
      "        [2.5101e-01, 1.6530e-01, 1.6104e-01, 2.5962e-01, 1.6304e-01, 1.1521e-07,\n",
      "         1.1521e-07, 1.1521e-07, 1.1521e-07, 1.1521e-07],\n",
      "        [2.3852e-01, 1.6354e-01, 1.6306e-01, 2.5762e-01, 1.7727e-01, 1.4457e-07,\n",
      "         1.4457e-07, 1.4457e-07, 1.4457e-07, 1.4457e-07],\n",
      "        [2.3733e-01, 1.6321e-01, 1.6319e-01, 2.5740e-01, 1.7888e-01, 1.5832e-07,\n",
      "         1.5832e-07, 1.5832e-07, 1.5832e-07, 1.5832e-07],\n",
      "        [2.3673e-01, 1.6292e-01, 1.6305e-01, 2.5721e-01, 1.8009e-01, 1.6605e-07,\n",
      "         1.6605e-07, 1.6605e-07, 1.6605e-07, 1.6605e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 162.00, Train Loss: 1.20, Val Loss: 12.78, Train BLEU: 61.41, Val BLEU: 0.43\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一种 种群 栖 动物 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: it &apos;s a colonial animal . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a jelly animal <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[3.5172e-01, 2.4429e-01, 1.7041e-01, 1.3035e-01, 4.9859e-02, 5.0379e-02,\n",
      "         2.9978e-03, 2.3768e-10, 2.3768e-10, 2.3768e-10],\n",
      "        [3.7790e-01, 2.3985e-01, 1.6302e-01, 1.2020e-01, 4.6920e-02, 4.8025e-02,\n",
      "         4.0824e-03, 7.9247e-10, 7.9247e-10, 7.9247e-10],\n",
      "        [4.1059e-01, 2.2705e-01, 1.4782e-01, 1.0866e-01, 4.5650e-02, 5.1464e-02,\n",
      "         8.7610e-03, 2.6887e-09, 2.6887e-09, 2.6887e-09],\n",
      "        [3.8200e-01, 2.0979e-01, 1.4543e-01, 1.1497e-01, 5.3411e-02, 6.9637e-02,\n",
      "         2.4769e-02, 1.5370e-08, 1.5370e-08, 1.5370e-08],\n",
      "        [3.3075e-01, 1.9348e-01, 1.4770e-01, 1.2682e-01, 6.4930e-02, 9.0475e-02,\n",
      "         4.5838e-02, 3.5439e-08, 3.5439e-08, 3.5439e-08],\n",
      "        [2.6171e-01, 1.6930e-01, 1.4697e-01, 1.3993e-01, 8.4772e-02, 1.2163e-01,\n",
      "         7.5692e-02, 5.0976e-08, 5.0976e-08, 5.0976e-08],\n",
      "        [2.3241e-01, 1.5854e-01, 1.4434e-01, 1.4229e-01, 9.4023e-02, 1.3393e-01,\n",
      "         9.4457e-02, 7.2437e-08, 7.2437e-08, 7.2437e-08],\n",
      "        [2.2992e-01, 1.5755e-01, 1.4422e-01, 1.4259e-01, 9.4676e-02, 1.3485e-01,\n",
      "         9.6208e-02, 7.8707e-08, 7.8707e-08, 7.8707e-08],\n",
      "        [2.2916e-01, 1.5720e-01, 1.4413e-01, 1.4265e-01, 9.4890e-02, 1.3517e-01,\n",
      "         9.6801e-02, 8.3138e-08, 8.3138e-08, 8.3138e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 那 就是 她 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: there she is . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> here &apos;s a kind stuff . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[2.2429e-01, 2.1994e-01, 2.0877e-01, 1.6696e-01, 1.0776e-01, 5.1451e-02,\n",
      "         1.4569e-02, 5.8043e-03, 4.4698e-04, 5.6051e-11],\n",
      "        [2.4300e-01, 2.1710e-01, 2.0508e-01, 1.6309e-01, 1.0297e-01, 4.8513e-02,\n",
      "         1.3927e-02, 5.6884e-03, 6.2281e-04, 1.6771e-10],\n",
      "        [2.8530e-01, 2.1357e-01, 1.8949e-01, 1.4916e-01, 9.3767e-02, 4.5845e-02,\n",
      "         1.4501e-02, 6.8090e-03, 1.5559e-03, 7.4333e-10],\n",
      "        [2.8757e-01, 1.9884e-01, 1.7740e-01, 1.4478e-01, 9.8576e-02, 5.5354e-02,\n",
      "         2.0670e-02, 1.1479e-02, 5.3412e-03, 6.0636e-09],\n",
      "        [2.7916e-01, 1.8797e-01, 1.7134e-01, 1.4348e-01, 1.0329e-01, 6.3785e-02,\n",
      "         2.6097e-02, 1.5584e-02, 9.3010e-03, 1.1944e-08],\n",
      "        [2.5965e-01, 1.7432e-01, 1.6245e-01, 1.4102e-01, 1.0936e-01, 7.6679e-02,\n",
      "         3.6121e-02, 2.3686e-02, 1.6716e-02, 2.5986e-08],\n",
      "        [2.3189e-01, 1.5929e-01, 1.5234e-01, 1.3749e-01, 1.1431e-01, 9.0160e-02,\n",
      "         4.9527e-02, 3.5822e-02, 2.9167e-02, 3.8011e-08],\n",
      "        [2.1326e-01, 1.5047e-01, 1.4640e-01, 1.3491e-01, 1.1624e-01, 9.7230e-02,\n",
      "         5.8106e-02, 4.4521e-02, 3.8867e-02, 4.9411e-08],\n",
      "        [2.1027e-01, 1.4921e-01, 1.4584e-01, 1.3475e-01, 1.1657e-01, 9.8301e-02,\n",
      "         5.9167e-02, 4.5672e-02, 4.0220e-02, 4.7519e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 163.00, Train Loss: 1.18, Val Loss: 12.78, Train BLEU: 63.67, Val BLEU: 0.39\n",
      "Sampling from training predictions...\n",
      "Source: 我 真 喜欢 这些 东西 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: i love that kind of stuff . <EOS> <PAD>\n",
      "Model: <SOS> i &apos;s a kind different stuff . <EOS> <EOS>\n",
      "Attention Weights: tensor([[3.7906e-01, 2.4119e-01, 1.6946e-01, 1.3427e-01, 7.2202e-02, 3.8273e-03,\n",
      "         5.2306e-10, 5.2306e-10, 5.2306e-10, 5.2306e-10],\n",
      "        [4.0357e-01, 2.3358e-01, 1.6186e-01, 1.2535e-01, 7.0004e-02, 5.6393e-03,\n",
      "         1.8140e-09, 1.8140e-09, 1.8140e-09, 1.8140e-09],\n",
      "        [4.2393e-01, 2.2245e-01, 1.5101e-01, 1.1783e-01, 7.3320e-02, 1.1469e-02,\n",
      "         6.0422e-09, 6.0422e-09, 6.0422e-09, 6.0422e-09],\n",
      "        [3.9811e-01, 2.0802e-01, 1.5001e-01, 1.2477e-01, 8.9933e-02, 2.9156e-02,\n",
      "         2.8745e-08, 2.8745e-08, 2.8745e-08, 2.8745e-08],\n",
      "        [3.6128e-01, 2.0054e-01, 1.5347e-01, 1.3411e-01, 1.0464e-01, 4.5954e-02,\n",
      "         5.6036e-08, 5.6036e-08, 5.6036e-08, 5.6036e-08],\n",
      "        [3.2708e-01, 1.9244e-01, 1.5763e-01, 1.4368e-01, 1.1792e-01, 6.1254e-02,\n",
      "         1.0915e-07, 1.0915e-07, 1.0915e-07, 1.0915e-07],\n",
      "        [2.9218e-01, 1.8444e-01, 1.6088e-01, 1.5305e-01, 1.3214e-01, 7.7305e-02,\n",
      "         1.0304e-07, 1.0304e-07, 1.0304e-07, 1.0304e-07],\n",
      "        [2.5854e-01, 1.7546e-01, 1.6199e-01, 1.6039e-01, 1.4633e-01, 9.7291e-02,\n",
      "         1.0014e-07, 1.0014e-07, 1.0014e-07, 1.0014e-07],\n",
      "        [2.5289e-01, 1.7375e-01, 1.6182e-01, 1.6125e-01, 1.4854e-01, 1.0174e-01,\n",
      "         1.1489e-07, 1.1489e-07, 1.1489e-07, 1.1489e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 对 他 来说 孩子 不 接受 受教 教育 <UNK> 是\n",
      "Reference: to him , there was greater risk in not\n",
      "Model: <SOS> we use the submarine alvin and use use cameras\n",
      "Attention Weights: tensor([[3.5533e-01, 2.4977e-01, 1.7309e-01, 1.2374e-01, 4.9242e-02, 4.6084e-02,\n",
      "         2.7492e-03, 2.2601e-10, 2.2601e-10, 2.2601e-10],\n",
      "        [3.8104e-01, 2.4532e-01, 1.6574e-01, 1.1432e-01, 4.6203e-02, 4.3731e-02,\n",
      "         3.6514e-03, 7.3858e-10, 7.3858e-10, 7.3858e-10],\n",
      "        [4.1364e-01, 2.3207e-01, 1.5058e-01, 1.0366e-01, 4.5057e-02, 4.7135e-02,\n",
      "         7.8536e-03, 2.4641e-09, 2.4641e-09, 2.4641e-09],\n",
      "        [3.8916e-01, 2.1595e-01, 1.4822e-01, 1.0940e-01, 5.2221e-02, 6.3269e-02,\n",
      "         2.1781e-02, 1.3760e-08, 1.3760e-08, 1.3760e-08],\n",
      "        [3.3955e-01, 2.0036e-01, 1.5115e-01, 1.2169e-01, 6.3660e-02, 8.2772e-02,\n",
      "         4.0820e-02, 3.1593e-08, 3.1593e-08, 3.1593e-08],\n",
      "        [2.7118e-01, 1.7610e-01, 1.5111e-01, 1.3635e-01, 8.3760e-02, 1.1344e-01,\n",
      "         6.8049e-02, 4.5638e-08, 4.5638e-08, 4.5638e-08],\n",
      "        [2.3753e-01, 1.6339e-01, 1.4808e-01, 1.3998e-01, 9.4469e-02, 1.2807e-01,\n",
      "         8.8479e-02, 6.5568e-08, 6.5568e-08, 6.5568e-08],\n",
      "        [2.3450e-01, 1.6222e-01, 1.4799e-01, 1.4044e-01, 9.5292e-02, 1.2925e-01,\n",
      "         9.0304e-02, 7.1159e-08, 7.1159e-08, 7.1159e-08],\n",
      "        [2.3375e-01, 1.6186e-01, 1.4792e-01, 1.4054e-01, 9.5494e-02, 1.2957e-01,\n",
      "         9.0871e-02, 7.5106e-08, 7.5106e-08, 7.5106e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 164.00, Train Loss: 1.16, Val Loss: 12.79, Train BLEU: 63.82, Val BLEU: 0.43\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一只 水母 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: here &apos;s a jelly . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> here &apos;s a jelly . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[3.5133e-01, 2.2231e-01, 1.7598e-01, 2.3624e-01, 1.4138e-02, 9.4372e-10,\n",
      "         9.4372e-10, 9.4372e-10, 9.4372e-10, 9.4372e-10],\n",
      "        [3.7040e-01, 2.1484e-01, 1.6656e-01, 2.2807e-01, 2.0122e-02, 3.4480e-09,\n",
      "         3.4480e-09, 3.4480e-09, 3.4480e-09, 3.4480e-09],\n",
      "        [3.8816e-01, 2.0228e-01, 1.5329e-01, 2.1884e-01, 3.7442e-02, 1.0898e-08,\n",
      "         1.0898e-08, 1.0898e-08, 1.0898e-08, 1.0898e-08],\n",
      "        [3.4199e-01, 1.8143e-01, 1.5018e-01, 2.3872e-01, 8.7687e-02, 5.5556e-08,\n",
      "         5.5556e-08, 5.5556e-08, 5.5556e-08, 5.5556e-08],\n",
      "        [2.9545e-01, 1.7189e-01, 1.5210e-01, 2.5104e-01, 1.2951e-01, 1.0131e-07,\n",
      "         1.0131e-07, 1.0131e-07, 1.0131e-07, 1.0131e-07],\n",
      "        [2.4626e-01, 1.6561e-01, 1.6289e-01, 2.5959e-01, 1.6565e-01, 1.0916e-07,\n",
      "         1.0916e-07, 1.0916e-07, 1.0916e-07, 1.0916e-07],\n",
      "        [2.3430e-01, 1.6398e-01, 1.6471e-01, 2.5705e-01, 1.7996e-01, 1.3472e-07,\n",
      "         1.3472e-07, 1.3472e-07, 1.3472e-07, 1.3472e-07],\n",
      "        [2.3326e-01, 1.6370e-01, 1.6487e-01, 2.5693e-01, 1.8124e-01, 1.4650e-07,\n",
      "         1.4650e-07, 1.4650e-07, 1.4650e-07, 1.4650e-07],\n",
      "        [2.3270e-01, 1.6350e-01, 1.6477e-01, 2.5659e-01, 1.8244e-01, 1.5404e-07,\n",
      "         1.5404e-07, 1.5404e-07, 1.5404e-07, 1.5404e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 她 两年 年前 退休 了 结果 却 把 我家 变成\n",
      "Reference: she retired two years ago , only to turn\n",
      "Model: <SOS> most of the the and and the the the\n",
      "Attention Weights: tensor([[3.7523e-01, 2.3756e-01, 1.7116e-01, 1.3716e-01, 7.4561e-02, 4.3309e-03,\n",
      "         6.1390e-10, 6.1390e-10, 6.1390e-10, 6.1390e-10],\n",
      "        [3.9972e-01, 2.2996e-01, 1.6343e-01, 1.2815e-01, 7.2373e-02, 6.3606e-03,\n",
      "         2.1052e-09, 2.1052e-09, 2.1052e-09, 2.1052e-09],\n",
      "        [4.2011e-01, 2.1859e-01, 1.5223e-01, 1.2024e-01, 7.5769e-02, 1.3058e-02,\n",
      "         7.0348e-09, 7.0348e-09, 7.0348e-09, 7.0348e-09],\n",
      "        [3.9327e-01, 2.0370e-01, 1.5049e-01, 1.2671e-01, 9.2778e-02, 3.3047e-02,\n",
      "         3.3449e-08, 3.3449e-08, 3.3449e-08, 3.3449e-08],\n",
      "        [3.5605e-01, 1.9638e-01, 1.5348e-01, 1.3546e-01, 1.0720e-01, 5.1432e-02,\n",
      "         6.4348e-08, 6.4348e-08, 6.4348e-08, 6.4348e-08],\n",
      "        [3.2107e-01, 1.8853e-01, 1.5740e-01, 1.4470e-01, 1.2045e-01, 6.7861e-02,\n",
      "         1.2437e-07, 1.2437e-07, 1.2437e-07, 1.2437e-07],\n",
      "        [2.8518e-01, 1.8054e-01, 1.6040e-01, 1.5391e-01, 1.3486e-01, 8.5103e-02,\n",
      "         1.1241e-07, 1.1241e-07, 1.1241e-07, 1.1241e-07],\n",
      "        [2.5324e-01, 1.7226e-01, 1.6123e-01, 1.6050e-01, 1.4802e-01, 1.0476e-01,\n",
      "         1.0949e-07, 1.0949e-07, 1.0949e-07, 1.0949e-07],\n",
      "        [2.4832e-01, 1.7084e-01, 1.6108e-01, 1.6121e-01, 1.4995e-01, 1.0860e-01,\n",
      "         1.2394e-07, 1.2394e-07, 1.2394e-07, 1.2394e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 165.00, Train Loss: 1.14, Val Loss: 12.81, Train BLEU: 64.09, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 原来 它 是 海洋 洋中 最长 的 生物 <EOS> <PAD>\n",
      "Reference: this turns out to be the longest creature in\n",
      "Model: <SOS> this turns out to be the creature creature creature\n",
      "Attention Weights: tensor([[1.2495e-01, 1.3305e-01, 1.4122e-01, 5.6270e-01, 3.1531e-02, 4.0831e-03,\n",
      "         1.4853e-03, 8.8775e-04, 9.3418e-05, 8.3898e-12],\n",
      "        [1.3510e-01, 1.2615e-01, 1.2870e-01, 5.6824e-01, 3.6886e-02, 3.1031e-03,\n",
      "         1.1121e-03, 6.3196e-04, 7.5836e-05, 2.1953e-11],\n",
      "        [1.5432e-01, 1.1740e-01, 1.1599e-01, 5.2828e-01, 7.8908e-02, 3.0987e-03,\n",
      "         1.1426e-03, 6.9557e-04, 1.7337e-04, 7.8597e-11],\n",
      "        [1.4757e-01, 1.0146e-01, 1.0049e-01, 4.8420e-01, 1.5952e-01, 3.7012e-03,\n",
      "         1.4798e-03, 1.0503e-03, 5.2411e-04, 5.3848e-10],\n",
      "        [1.2711e-01, 8.4072e-02, 8.5074e-02, 4.3815e-01, 2.5597e-01, 4.8847e-03,\n",
      "         2.0555e-03, 1.5826e-03, 1.1040e-03, 1.6276e-09],\n",
      "        [1.0644e-01, 6.9339e-02, 7.1665e-02, 3.8877e-01, 3.4912e-01, 6.9817e-03,\n",
      "         3.1429e-03, 2.5176e-03, 2.0181e-03, 3.9335e-09],\n",
      "        [8.7467e-02, 5.7748e-02, 6.1566e-02, 3.3619e-01, 4.3247e-01, 1.0294e-02,\n",
      "         5.3054e-03, 4.6595e-03, 4.3080e-03, 7.3959e-09],\n",
      "        [8.2724e-02, 5.6321e-02, 6.1620e-02, 3.2368e-01, 4.4212e-01, 1.3040e-02,\n",
      "         7.2196e-03, 6.6423e-03, 6.6342e-03, 1.0026e-08],\n",
      "        [8.2158e-02, 5.6437e-02, 6.2171e-02, 3.2380e-01, 4.3965e-01, 1.3696e-02,\n",
      "         7.6780e-03, 7.1474e-03, 7.2654e-03, 1.1254e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 很 幸运 幸运地 成长 在 一个 珍视 教育 也\n",
      "Reference: i was very lucky to grow up in a\n",
      "Model: <SOS> we &apos;s have have partnered and and the are\n",
      "Attention Weights: tensor([[3.3726e-01, 2.1501e-01, 1.7859e-01, 2.5327e-01, 1.5867e-02, 1.0806e-09,\n",
      "         1.0806e-09, 1.0806e-09, 1.0806e-09, 1.0806e-09],\n",
      "        [3.5481e-01, 2.0769e-01, 1.6931e-01, 2.4555e-01, 2.2638e-02, 3.9128e-09,\n",
      "         3.9128e-09, 3.9128e-09, 3.9128e-09, 3.9128e-09],\n",
      "        [3.7262e-01, 1.9515e-01, 1.5512e-01, 2.3471e-01, 4.2400e-02, 1.2380e-08,\n",
      "         1.2380e-08, 1.2380e-08, 1.2380e-08, 1.2380e-08],\n",
      "        [3.2540e-01, 1.7342e-01, 1.5017e-01, 2.5274e-01, 9.8268e-02, 6.2598e-08,\n",
      "         6.2598e-08, 6.2598e-08, 6.2598e-08, 6.2598e-08],\n",
      "        [2.8099e-01, 1.6408e-01, 1.5088e-01, 2.6223e-01, 1.4181e-01, 1.0968e-07,\n",
      "         1.0968e-07, 1.0968e-07, 1.0968e-07, 1.0968e-07],\n",
      "        [2.3589e-01, 1.5951e-01, 1.6118e-01, 2.6601e-01, 1.7740e-01, 1.1756e-07,\n",
      "         1.1756e-07, 1.1756e-07, 1.1756e-07, 1.1756e-07],\n",
      "        [2.2600e-01, 1.5863e-01, 1.6295e-01, 2.6273e-01, 1.8969e-01, 1.4318e-07,\n",
      "         1.4318e-07, 1.4318e-07, 1.4318e-07, 1.4318e-07],\n",
      "        [2.2510e-01, 1.5842e-01, 1.6307e-01, 2.6248e-01, 1.9094e-01, 1.5515e-07,\n",
      "         1.5515e-07, 1.5515e-07, 1.5515e-07, 1.5515e-07],\n",
      "        [2.2467e-01, 1.5826e-01, 1.6299e-01, 2.6219e-01, 1.9189e-01, 1.6223e-07,\n",
      "         1.6223e-07, 1.6223e-07, 1.6223e-07, 1.6223e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 166.00, Train Loss: 1.12, Val Loss: 12.81, Train BLEU: 66.87, Val BLEU: 0.39\n",
      "Sampling from training predictions...\n",
      "Source: 看到 这些 在 动 的 东西 了 吗 <EOS> <PAD>\n",
      "Reference: but see all those different working things ? <EOS>\n",
      "Model: <SOS> but see all those different working <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[2.2704e-01, 2.2809e-01, 2.1158e-01, 1.6198e-01, 1.0023e-01, 5.1557e-02,\n",
      "         1.3468e-02, 5.5889e-03, 4.6527e-04, 6.5217e-11],\n",
      "        [2.4571e-01, 2.2641e-01, 2.0934e-01, 1.5843e-01, 9.4709e-02, 4.7405e-02,\n",
      "         1.2285e-02, 5.1512e-03, 5.6959e-04, 1.7092e-10],\n",
      "        [2.8839e-01, 2.2212e-01, 1.9382e-01, 1.4519e-01, 8.5949e-02, 4.4400e-02,\n",
      "         1.2634e-02, 6.0622e-03, 1.4370e-03, 6.9463e-10],\n",
      "        [2.9396e-01, 2.0795e-01, 1.8183e-01, 1.4173e-01, 9.0259e-02, 5.1963e-02,\n",
      "         1.7546e-02, 9.9025e-03, 4.8507e-03, 5.3628e-09],\n",
      "        [2.8788e-01, 1.9644e-01, 1.7543e-01, 1.4095e-01, 9.5145e-02, 5.9962e-02,\n",
      "         2.2267e-02, 1.3440e-02, 8.4866e-03, 1.0570e-08],\n",
      "        [2.6914e-01, 1.8105e-01, 1.6582e-01, 1.3935e-01, 1.0285e-01, 7.3543e-02,\n",
      "         3.1861e-02, 2.0972e-02, 1.5418e-02, 2.3144e-08],\n",
      "        [2.3781e-01, 1.6310e-01, 1.5430e-01, 1.3654e-01, 1.1034e-01, 8.9732e-02,\n",
      "         4.6409e-02, 3.3686e-02, 2.8088e-02, 3.5080e-08],\n",
      "        [2.1546e-01, 1.5220e-01, 1.4699e-01, 1.3387e-01, 1.1346e-01, 9.8426e-02,\n",
      "         5.6545e-02, 4.3655e-02, 3.9384e-02, 4.8157e-08],\n",
      "        [2.1018e-01, 1.5031e-01, 1.4627e-01, 1.3384e-01, 1.1418e-01, 1.0018e-01,\n",
      "         5.8240e-02, 4.5434e-02, 4.1365e-02, 4.5310e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 出身 阿富汗 边远 <UNK> 地区 有着 与 他人 不同\n",
      "Reference: a total maverick from a remote province of afghanistan\n",
      "Model: <SOS> with vibrant the clips captured , , , the\n",
      "Attention Weights: tensor([[1.2089e-01, 1.3081e-01, 1.4128e-01, 5.7238e-01, 2.8723e-02, 3.6711e-03,\n",
      "         1.3416e-03, 8.1725e-04, 8.8240e-05, 7.7629e-12],\n",
      "        [1.3026e-01, 1.2396e-01, 1.2892e-01, 5.7995e-01, 3.2556e-02, 2.7410e-03,\n",
      "         9.8638e-04, 5.7142e-04, 6.9502e-05, 2.0014e-11],\n",
      "        [1.4951e-01, 1.1617e-01, 1.1709e-01, 5.4402e-01, 6.8711e-02, 2.7181e-03,\n",
      "         1.0040e-03, 6.2166e-04, 1.5511e-04, 6.9038e-11],\n",
      "        [1.4556e-01, 1.0222e-01, 1.0307e-01, 5.0339e-01, 1.3985e-01, 3.2358e-03,\n",
      "         1.2933e-03, 9.3298e-04, 4.6167e-04, 4.6641e-10],\n",
      "        [1.2761e-01, 8.5742e-02, 8.8012e-02, 4.5920e-01, 2.3098e-01, 4.2780e-03,\n",
      "         1.7922e-03, 1.4047e-03, 9.7428e-04, 1.4062e-09],\n",
      "        [1.0724e-01, 7.0527e-02, 7.3834e-02, 4.1005e-01, 3.2539e-01, 6.1737e-03,\n",
      "         2.7550e-03, 2.2382e-03, 1.7901e-03, 3.4550e-09],\n",
      "        [8.7757e-02, 5.8053e-02, 6.2582e-02, 3.5578e-01, 4.1390e-01, 9.2494e-03,\n",
      "         4.6958e-03, 4.1590e-03, 3.8194e-03, 6.6002e-09],\n",
      "        [8.2209e-02, 5.6026e-02, 6.2024e-02, 3.3993e-01, 4.2907e-01, 1.1978e-02,\n",
      "         6.5677e-03, 6.0979e-03, 6.0971e-03, 9.2127e-09],\n",
      "        [8.1535e-02, 5.6128e-02, 6.2639e-02, 3.4005e-01, 4.2654e-01, 1.2662e-02,\n",
      "         7.0469e-03, 6.6280e-03, 6.7680e-03, 1.0520e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 167.00, Train Loss: 1.10, Val Loss: 12.82, Train BLEU: 68.38, Val BLEU: 0.39\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想 海洋 占 了 地球 球面 面积 的 75\n",
      "Reference: when you think about it , the oceans are\n",
      "Model: <SOS> when you think about , , the oceans are\n",
      "Attention Weights: tensor([[0.0259, 0.0243, 0.2233, 0.0453, 0.0366, 0.2717, 0.2263, 0.1254, 0.0204,\n",
      "         0.0006],\n",
      "        [0.0344, 0.0267, 0.2178, 0.0440, 0.0359, 0.2751, 0.2190, 0.1220, 0.0217,\n",
      "         0.0035],\n",
      "        [0.0481, 0.0322, 0.2084, 0.0451, 0.0383, 0.2628, 0.1969, 0.1195, 0.0291,\n",
      "         0.0196],\n",
      "        [0.0551, 0.0366, 0.1949, 0.0472, 0.0413, 0.2464, 0.1788, 0.1185, 0.0374,\n",
      "         0.0438],\n",
      "        [0.0575, 0.0380, 0.1806, 0.0470, 0.0422, 0.2317, 0.1675, 0.1163, 0.0427,\n",
      "         0.0766],\n",
      "        [0.0569, 0.0375, 0.1649, 0.0452, 0.0416, 0.2159, 0.1549, 0.1120, 0.0467,\n",
      "         0.1243],\n",
      "        [0.0566, 0.0379, 0.1567, 0.0450, 0.0420, 0.2060, 0.1480, 0.1101, 0.0494,\n",
      "         0.1482],\n",
      "        [0.0551, 0.0375, 0.1527, 0.0446, 0.0418, 0.2012, 0.1446, 0.1098, 0.0512,\n",
      "         0.1614],\n",
      "        [0.0541, 0.0375, 0.1517, 0.0448, 0.0422, 0.1997, 0.1437, 0.1103, 0.0526,\n",
      "         0.1636]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正 的 学校 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: a real school . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> here &apos;s a kind different . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0259, 0.0243, 0.2233, 0.0453, 0.0366, 0.2717, 0.2263, 0.1254, 0.0204,\n",
      "         0.0006],\n",
      "        [0.0344, 0.0267, 0.2178, 0.0440, 0.0359, 0.2751, 0.2190, 0.1220, 0.0217,\n",
      "         0.0035],\n",
      "        [0.0481, 0.0322, 0.2084, 0.0451, 0.0383, 0.2628, 0.1969, 0.1195, 0.0291,\n",
      "         0.0196],\n",
      "        [0.0551, 0.0366, 0.1949, 0.0472, 0.0413, 0.2464, 0.1788, 0.1185, 0.0374,\n",
      "         0.0438],\n",
      "        [0.0575, 0.0380, 0.1806, 0.0470, 0.0422, 0.2317, 0.1675, 0.1163, 0.0427,\n",
      "         0.0766],\n",
      "        [0.0569, 0.0375, 0.1649, 0.0452, 0.0416, 0.2159, 0.1549, 0.1120, 0.0467,\n",
      "         0.1243],\n",
      "        [0.0566, 0.0379, 0.1567, 0.0450, 0.0420, 0.2060, 0.1480, 0.1101, 0.0494,\n",
      "         0.1482],\n",
      "        [0.0551, 0.0375, 0.1527, 0.0446, 0.0418, 0.2012, 0.1446, 0.1098, 0.0512,\n",
      "         0.1614],\n",
      "        [0.0541, 0.0375, 0.1517, 0.0448, 0.0422, 0.1997, 0.1437, 0.1103, 0.0526,\n",
      "         0.1636]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 168.00, Train Loss: 1.09, Val Loss: 12.83, Train BLEU: 69.39, Val BLEU: 0.43\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这 有 不少 精彩 的 泰坦 泰坦尼克 坦尼 尼克\n",
      "Reference: we &apos;ve got some of the most incredible video\n",
      "Model: <SOS> we &apos;ve got some of the most incredible the\n",
      "Attention Weights: tensor([[0.0501, 0.0436, 0.0576, 0.2864, 0.3797, 0.0634, 0.1130, 0.0034, 0.0017,\n",
      "         0.0009],\n",
      "        [0.0534, 0.0390, 0.0501, 0.2639, 0.3770, 0.0590, 0.1375, 0.0124, 0.0060,\n",
      "         0.0016],\n",
      "        [0.0582, 0.0360, 0.0450, 0.2272, 0.3412, 0.0608, 0.1659, 0.0418, 0.0207,\n",
      "         0.0032],\n",
      "        [0.0600, 0.0372, 0.0459, 0.2056, 0.2977, 0.0634, 0.1739, 0.0758, 0.0352,\n",
      "         0.0054],\n",
      "        [0.0570, 0.0348, 0.0430, 0.1874, 0.2731, 0.0614, 0.1792, 0.1079, 0.0491,\n",
      "         0.0072],\n",
      "        [0.0573, 0.0347, 0.0429, 0.1837, 0.2674, 0.0617, 0.1810, 0.1119, 0.0515,\n",
      "         0.0079],\n",
      "        [0.0594, 0.0364, 0.0451, 0.1804, 0.2594, 0.0640, 0.1808, 0.1118, 0.0533,\n",
      "         0.0095],\n",
      "        [0.0611, 0.0385, 0.0476, 0.1742, 0.2476, 0.0667, 0.1779, 0.1160, 0.0581,\n",
      "         0.0122],\n",
      "        [0.0616, 0.0397, 0.0489, 0.1692, 0.2383, 0.0681, 0.1769, 0.1208, 0.0626,\n",
      "         0.0140]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 但是 我 那 受过 教育 的 母亲 成为 为了 一名\n",
      "Reference: but my educated mother became a teacher . <EOS>\n",
      "Model: <SOS> and biodiversity the the and and the the the\n",
      "Attention Weights: tensor([[2.7188e-01, 2.2113e-01, 2.6776e-01, 3.2360e-02, 1.6807e-01, 2.5408e-02,\n",
      "         1.2302e-02, 1.0907e-03, 1.8289e-10, 1.8289e-10],\n",
      "        [2.9537e-01, 2.1664e-01, 2.7067e-01, 4.0099e-02, 1.4641e-01, 1.9736e-02,\n",
      "         9.9024e-03, 1.1689e-03, 5.7041e-10, 5.7041e-10],\n",
      "        [2.8789e-01, 1.8822e-01, 2.3611e-01, 7.0598e-02, 1.8317e-01, 2.0926e-02,\n",
      "         1.0655e-02, 2.4237e-03, 1.7081e-09, 1.7081e-09],\n",
      "        [2.6315e-01, 1.7031e-01, 2.1697e-01, 1.3139e-01, 1.7916e-01, 2.1544e-02,\n",
      "         1.2141e-02, 5.3285e-03, 6.5878e-09, 6.5878e-09],\n",
      "        [2.1505e-01, 1.4053e-01, 1.8432e-01, 1.8887e-01, 2.1941e-01, 2.6418e-02,\n",
      "         1.5705e-02, 9.6971e-03, 1.6260e-08, 1.6260e-08],\n",
      "        [1.7760e-01, 1.1692e-01, 1.5608e-01, 2.2817e-01, 2.5421e-01, 3.2675e-02,\n",
      "         2.0015e-02, 1.4332e-02, 2.7747e-08, 2.7747e-08],\n",
      "        [1.4559e-01, 1.0043e-01, 1.3680e-01, 2.6257e-01, 2.6907e-01, 3.9069e-02,\n",
      "         2.5504e-02, 2.0966e-02, 3.3957e-08, 3.3957e-08],\n",
      "        [1.3445e-01, 9.8921e-02, 1.3521e-01, 2.6730e-01, 2.5501e-01, 4.6485e-02,\n",
      "         3.2972e-02, 2.9655e-02, 4.6165e-08, 4.6165e-08],\n",
      "        [1.3432e-01, 1.0067e-01, 1.3762e-01, 2.6530e-01, 2.4803e-01, 4.7731e-02,\n",
      "         3.4594e-02, 3.1731e-02, 5.1430e-08, 5.1430e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 169.00, Train Loss: 1.07, Val Loss: 12.84, Train BLEU: 69.39, Val BLEU: 0.43\n",
      "Sampling from training predictions...\n",
      "Source: 看到 这些 在 动 的 东西 了 吗 <EOS> <PAD>\n",
      "Reference: but see all those different working things ? <EOS>\n",
      "Model: <SOS> but see all those different working <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[2.0567e-01, 2.1021e-01, 2.1172e-01, 1.6702e-01, 1.1561e-01, 7.0927e-02,\n",
      "         1.3049e-02, 5.3324e-03, 4.5861e-04, 8.1676e-11],\n",
      "        [2.2351e-01, 2.1114e-01, 2.1123e-01, 1.6454e-01, 1.0891e-01, 6.4012e-02,\n",
      "         1.1473e-02, 4.6808e-03, 5.0757e-04, 1.7814e-10],\n",
      "        [2.6422e-01, 2.0903e-01, 1.9788e-01, 1.5194e-01, 9.9154e-02, 5.9497e-02,\n",
      "         1.1586e-02, 5.4123e-03, 1.2872e-03, 6.6438e-10],\n",
      "        [2.7521e-01, 1.9693e-01, 1.8350e-01, 1.4585e-01, 1.0179e-01, 6.7095e-02,\n",
      "         1.6095e-02, 8.9560e-03, 4.5613e-03, 5.1285e-09],\n",
      "        [2.7275e-01, 1.8590e-01, 1.7493e-01, 1.4299e-01, 1.0557e-01, 7.6178e-02,\n",
      "         2.0818e-02, 1.2481e-02, 8.3906e-03, 1.0441e-08],\n",
      "        [2.5291e-01, 1.6896e-01, 1.6232e-01, 1.3922e-01, 1.1282e-01, 9.3393e-02,\n",
      "         3.2143e-02, 2.1352e-02, 1.6883e-02, 2.4973e-08],\n",
      "        [2.2134e-01, 1.5120e-01, 1.4899e-01, 1.3424e-01, 1.1795e-01, 1.0995e-01,\n",
      "         4.8141e-02, 3.5703e-02, 3.2490e-02, 3.8942e-08],\n",
      "        [2.0269e-01, 1.4261e-01, 1.4258e-01, 1.3142e-01, 1.1942e-01, 1.1638e-01,\n",
      "         5.7083e-02, 4.4701e-02, 4.3125e-02, 5.1305e-08],\n",
      "        [1.9863e-01, 1.4150e-01, 1.4228e-01, 1.3159e-01, 1.1995e-01, 1.1764e-01,\n",
      "         5.8191e-02, 4.5857e-02, 4.4364e-02, 4.8928e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 面带 <UNK> <UNK> 笑容 这 很少 少见 因为 大部\n",
      "Reference: there was a big smile on his face which\n",
      "Model: <SOS> with vibrant video clips captured submarines submarines the david\n",
      "Attention Weights: tensor([[0.0688, 0.0384, 0.1915, 0.1750, 0.1345, 0.0476, 0.1614, 0.1332, 0.0470,\n",
      "         0.0027],\n",
      "        [0.0845, 0.0448, 0.1940, 0.1714, 0.1440, 0.0548, 0.1447, 0.1166, 0.0423,\n",
      "         0.0029],\n",
      "        [0.1030, 0.0710, 0.1794, 0.1473, 0.1727, 0.0824, 0.1146, 0.0871, 0.0370,\n",
      "         0.0055],\n",
      "        [0.1066, 0.0859, 0.1631, 0.1346, 0.1856, 0.0926, 0.1025, 0.0792, 0.0401,\n",
      "         0.0098],\n",
      "        [0.1028, 0.1032, 0.1476, 0.1182, 0.1938, 0.1128, 0.0925, 0.0719, 0.0408,\n",
      "         0.0162],\n",
      "        [0.0891, 0.1534, 0.1119, 0.0850, 0.2030, 0.1673, 0.0660, 0.0513, 0.0371,\n",
      "         0.0359],\n",
      "        [0.0848, 0.1714, 0.0989, 0.0751, 0.1953, 0.1862, 0.0583, 0.0460, 0.0366,\n",
      "         0.0474],\n",
      "        [0.0825, 0.1784, 0.0930, 0.0713, 0.1923, 0.1920, 0.0552, 0.0443, 0.0370,\n",
      "         0.0538],\n",
      "        [0.0818, 0.1805, 0.0910, 0.0700, 0.1912, 0.1931, 0.0542, 0.0439, 0.0373,\n",
      "         0.0570]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 170.00, Train Loss: 1.06, Val Loss: 12.83, Train BLEU: 70.11, Val BLEU: 0.38\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里 生物 的 多样 多样性 和 密度 要 比\n",
      "Reference: the biodiversity and the <UNK> in the ocean is\n",
      "Model: <SOS> the biodiversity the the and the the the is\n",
      "Attention Weights: tensor([[0.0264, 0.0159, 0.0867, 0.0352, 0.1227, 0.6512, 0.0330, 0.0163, 0.0082,\n",
      "         0.0044],\n",
      "        [0.0174, 0.0081, 0.0379, 0.0158, 0.0588, 0.8327, 0.0152, 0.0075, 0.0040,\n",
      "         0.0026],\n",
      "        [0.0169, 0.0066, 0.0276, 0.0120, 0.0436, 0.8710, 0.0113, 0.0056, 0.0032,\n",
      "         0.0022],\n",
      "        [0.0191, 0.0077, 0.0286, 0.0132, 0.0440, 0.8601, 0.0129, 0.0069, 0.0043,\n",
      "         0.0033],\n",
      "        [0.0221, 0.0093, 0.0316, 0.0152, 0.0477, 0.8402, 0.0150, 0.0085, 0.0056,\n",
      "         0.0047],\n",
      "        [0.0256, 0.0107, 0.0348, 0.0171, 0.0527, 0.8200, 0.0163, 0.0096, 0.0069,\n",
      "         0.0063],\n",
      "        [0.0375, 0.0171, 0.0498, 0.0263, 0.0735, 0.7327, 0.0238, 0.0155, 0.0120,\n",
      "         0.0119],\n",
      "        [0.0412, 0.0194, 0.0537, 0.0291, 0.0783, 0.7066, 0.0264, 0.0176, 0.0138,\n",
      "         0.0139],\n",
      "        [0.0428, 0.0207, 0.0566, 0.0311, 0.0822, 0.6894, 0.0280, 0.0190, 0.0151,\n",
      "         0.0153]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 不知 知道 那 意味 意味着 什么 但是 我 能\n",
      "Reference: i didn &apos;t know what it meant , but\n",
      "Model: <SOS> it biodiversity have the the and and the the\n",
      "Attention Weights: tensor([[0.0470, 0.0416, 0.0572, 0.2956, 0.3798, 0.0635, 0.1096, 0.0033, 0.0016,\n",
      "         0.0008],\n",
      "        [0.0501, 0.0372, 0.0497, 0.2735, 0.3791, 0.0590, 0.1330, 0.0117, 0.0053,\n",
      "         0.0014],\n",
      "        [0.0549, 0.0344, 0.0447, 0.2368, 0.3459, 0.0613, 0.1616, 0.0393, 0.0185,\n",
      "         0.0026],\n",
      "        [0.0564, 0.0352, 0.0454, 0.2152, 0.3047, 0.0637, 0.1717, 0.0717, 0.0316,\n",
      "         0.0044],\n",
      "        [0.0540, 0.0332, 0.0427, 0.1960, 0.2794, 0.0621, 0.1782, 0.1037, 0.0448,\n",
      "         0.0060],\n",
      "        [0.0548, 0.0334, 0.0428, 0.1918, 0.2733, 0.0626, 0.1799, 0.1075, 0.0472,\n",
      "         0.0066],\n",
      "        [0.0569, 0.0350, 0.0449, 0.1879, 0.2646, 0.0649, 0.1799, 0.1085, 0.0493,\n",
      "         0.0080],\n",
      "        [0.0594, 0.0377, 0.0480, 0.1809, 0.2512, 0.0679, 0.1767, 0.1130, 0.0545,\n",
      "         0.0106],\n",
      "        [0.0602, 0.0391, 0.0495, 0.1752, 0.2404, 0.0694, 0.1755, 0.1189, 0.0594,\n",
      "         0.0125]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 171.00, Train Loss: 1.03, Val Loss: 12.84, Train BLEU: 71.30, Val BLEU: 0.38\n",
      "Sampling from training predictions...\n",
      "Source: 和 我们 合作 的 人们 帮 我们 找到 了 新\n",
      "Reference: people that have partnered with us have given us\n",
      "Model: <SOS> people &apos;s have partnered standing us us there there\n",
      "Attention Weights: tensor([[0.0358, 0.0368, 0.1271, 0.0740, 0.1291, 0.0732, 0.1213, 0.3527, 0.0421,\n",
      "         0.0079],\n",
      "        [0.0459, 0.0387, 0.1232, 0.0704, 0.1242, 0.0688, 0.1175, 0.3596, 0.0421,\n",
      "         0.0096],\n",
      "        [0.0674, 0.0458, 0.1245, 0.0701, 0.1170, 0.0676, 0.1116, 0.3319, 0.0488,\n",
      "         0.0150],\n",
      "        [0.0794, 0.0518, 0.1223, 0.0724, 0.1144, 0.0695, 0.1107, 0.3008, 0.0556,\n",
      "         0.0230],\n",
      "        [0.0848, 0.0561, 0.1207, 0.0749, 0.1131, 0.0721, 0.1104, 0.2773, 0.0606,\n",
      "         0.0299],\n",
      "        [0.0869, 0.0567, 0.1184, 0.0741, 0.1114, 0.0715, 0.1095, 0.2741, 0.0630,\n",
      "         0.0344],\n",
      "        [0.0884, 0.0592, 0.1173, 0.0756, 0.1108, 0.0732, 0.1100, 0.2573, 0.0670,\n",
      "         0.0413],\n",
      "        [0.0887, 0.0598, 0.1168, 0.0758, 0.1104, 0.0734, 0.1098, 0.2535, 0.0682,\n",
      "         0.0437],\n",
      "        [0.0880, 0.0602, 0.1163, 0.0760, 0.1103, 0.0739, 0.1101, 0.2487, 0.0697,\n",
      "         0.0467]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 父亲 那 就是 他 他 是 他家 家族\n",
      "Reference: and my father -- that &apos;s him -- he\n",
      "Model: <SOS> and when &apos;re &apos;re , , , , are\n",
      "Attention Weights: tensor([[0.0705, 0.0675, 0.0582, 0.0528, 0.0121, 0.1523, 0.4420, 0.1273, 0.0170,\n",
      "         0.0004],\n",
      "        [0.0757, 0.0678, 0.0601, 0.0585, 0.0189, 0.1474, 0.4437, 0.1117, 0.0155,\n",
      "         0.0006],\n",
      "        [0.0839, 0.0635, 0.0566, 0.0615, 0.0413, 0.1321, 0.4598, 0.0848, 0.0146,\n",
      "         0.0018],\n",
      "        [0.0806, 0.0559, 0.0522, 0.0634, 0.0889, 0.1198, 0.4444, 0.0715, 0.0175,\n",
      "         0.0058],\n",
      "        [0.0747, 0.0496, 0.0471, 0.0578, 0.1248, 0.1109, 0.4323, 0.0700, 0.0212,\n",
      "         0.0117],\n",
      "        [0.0643, 0.0407, 0.0398, 0.0517, 0.1768, 0.0991, 0.3994, 0.0698, 0.0278,\n",
      "         0.0306],\n",
      "        [0.0603, 0.0378, 0.0376, 0.0506, 0.2097, 0.0900, 0.3585, 0.0684, 0.0333,\n",
      "         0.0538],\n",
      "        [0.0608, 0.0394, 0.0398, 0.0535, 0.2116, 0.0876, 0.3292, 0.0713, 0.0390,\n",
      "         0.0678],\n",
      "        [0.0624, 0.0416, 0.0423, 0.0566, 0.2118, 0.0882, 0.3088, 0.0731, 0.0428,\n",
      "         0.0724]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 172.00, Train Loss: 1.02, Val Loss: 12.84, Train BLEU: 71.77, Val BLEU: 0.40\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数 多数 地震 和 火山 喷发 也 都 发生\n",
      "Reference: most of the earthquakes and volcanoes are in the\n",
      "Model: <SOS> most of the earthquakes and volcanoes the the the\n",
      "Attention Weights: tensor([[0.0045, 0.0146, 0.0442, 0.0497, 0.0366, 0.2899, 0.4520, 0.0409, 0.0183,\n",
      "         0.0494],\n",
      "        [0.0074, 0.0334, 0.0484, 0.0482, 0.0365, 0.2860, 0.4331, 0.0392, 0.0179,\n",
      "         0.0499],\n",
      "        [0.0200, 0.1301, 0.0627, 0.0508, 0.0363, 0.2505, 0.3395, 0.0357, 0.0187,\n",
      "         0.0556],\n",
      "        [0.0271, 0.1549, 0.0662, 0.0534, 0.0403, 0.2306, 0.2983, 0.0396, 0.0234,\n",
      "         0.0663],\n",
      "        [0.0305, 0.1632, 0.0685, 0.0548, 0.0426, 0.2187, 0.2779, 0.0424, 0.0265,\n",
      "         0.0749],\n",
      "        [0.0383, 0.1970, 0.0672, 0.0520, 0.0420, 0.1992, 0.2484, 0.0426, 0.0293,\n",
      "         0.0841],\n",
      "        [0.0452, 0.2128, 0.0669, 0.0520, 0.0425, 0.1867, 0.2256, 0.0434, 0.0322,\n",
      "         0.0928],\n",
      "        [0.0476, 0.2171, 0.0672, 0.0525, 0.0432, 0.1814, 0.2160, 0.0442, 0.0339,\n",
      "         0.0969],\n",
      "        [0.0502, 0.2201, 0.0680, 0.0538, 0.0449, 0.1750, 0.2053, 0.0460, 0.0364,\n",
      "         0.1004]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天 要 走 不同 的 路线 这样 才 没有\n",
      "Reference: each day , we took a different route so\n",
      "Model: <SOS> part of the going , , , are are\n",
      "Attention Weights: tensor([[0.0293, 0.0310, 0.2853, 0.0613, 0.1109, 0.0698, 0.2317, 0.0502, 0.0255,\n",
      "         0.1051],\n",
      "        [0.0342, 0.0312, 0.2785, 0.0574, 0.1082, 0.0655, 0.2314, 0.0467, 0.0245,\n",
      "         0.1224],\n",
      "        [0.0549, 0.0390, 0.2543, 0.0559, 0.0986, 0.0626, 0.1995, 0.0472, 0.0284,\n",
      "         0.1596],\n",
      "        [0.0666, 0.0459, 0.2194, 0.0594, 0.0972, 0.0658, 0.1796, 0.0524, 0.0357,\n",
      "         0.1780],\n",
      "        [0.0688, 0.0472, 0.2037, 0.0591, 0.0952, 0.0660, 0.1711, 0.0541, 0.0391,\n",
      "         0.1957],\n",
      "        [0.0713, 0.0491, 0.1851, 0.0591, 0.0923, 0.0664, 0.1596, 0.0562, 0.0440,\n",
      "         0.2169],\n",
      "        [0.0706, 0.0504, 0.1728, 0.0592, 0.0903, 0.0664, 0.1511, 0.0579, 0.0481,\n",
      "         0.2332],\n",
      "        [0.0702, 0.0508, 0.1714, 0.0596, 0.0905, 0.0668, 0.1503, 0.0583, 0.0490,\n",
      "         0.2331],\n",
      "        [0.0708, 0.0522, 0.1688, 0.0607, 0.0908, 0.0676, 0.1482, 0.0597, 0.0507,\n",
      "         0.2305]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 173.00, Train Loss: 1.00, Val Loss: 12.85, Train BLEU: 72.36, Val BLEU: 0.39\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地 地球 上 最长 的 山脉 都 在 海洋\n",
      "Reference: and in the oceans , there are the longest\n",
      "Model: <SOS> and of the animals , , are the are\n",
      "Attention Weights: tensor([[0.0279, 0.0296, 0.2875, 0.0620, 0.1134, 0.0708, 0.2345, 0.0508, 0.0244,\n",
      "         0.0990],\n",
      "        [0.0324, 0.0298, 0.2821, 0.0580, 0.1109, 0.0663, 0.2357, 0.0473, 0.0234,\n",
      "         0.1142],\n",
      "        [0.0519, 0.0372, 0.2584, 0.0566, 0.1010, 0.0637, 0.2050, 0.0480, 0.0273,\n",
      "         0.1509],\n",
      "        [0.0635, 0.0441, 0.2241, 0.0602, 0.0999, 0.0670, 0.1854, 0.0531, 0.0344,\n",
      "         0.1682],\n",
      "        [0.0664, 0.0461, 0.2076, 0.0606, 0.0984, 0.0678, 0.1764, 0.0554, 0.0381,\n",
      "         0.1832],\n",
      "        [0.0694, 0.0480, 0.1894, 0.0606, 0.0955, 0.0682, 0.1650, 0.0575, 0.0429,\n",
      "         0.2035],\n",
      "        [0.0689, 0.0493, 0.1748, 0.0602, 0.0925, 0.0678, 0.1547, 0.0590, 0.0474,\n",
      "         0.2254],\n",
      "        [0.0681, 0.0493, 0.1740, 0.0602, 0.0925, 0.0678, 0.1542, 0.0591, 0.0479,\n",
      "         0.2270],\n",
      "        [0.0689, 0.0510, 0.1704, 0.0615, 0.0926, 0.0688, 0.1511, 0.0606, 0.0501,\n",
      "         0.2250]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 她 两年 年前 退休 了 结果 却 把 我家 变成\n",
      "Reference: she retired two years ago , only to turn\n",
      "Model: <SOS> and of the the and and the are the\n",
      "Attention Weights: tensor([[3.3502e-01, 2.0083e-01, 1.6444e-01, 2.0407e-01, 9.0636e-02, 5.0114e-03,\n",
      "         1.2599e-09, 1.2599e-09, 1.2599e-09, 1.2599e-09],\n",
      "        [3.5867e-01, 1.9645e-01, 1.5807e-01, 1.9033e-01, 8.9008e-02, 7.4668e-03,\n",
      "         3.9053e-09, 3.9053e-09, 3.9053e-09, 3.9053e-09],\n",
      "        [3.7459e-01, 1.8703e-01, 1.4906e-01, 1.7966e-01, 9.3907e-02, 1.5760e-02,\n",
      "         1.1227e-08, 1.1227e-08, 1.1227e-08, 1.1227e-08],\n",
      "        [3.5275e-01, 1.7121e-01, 1.4324e-01, 1.8070e-01, 1.1286e-01, 3.9247e-02,\n",
      "         5.0448e-08, 5.0448e-08, 5.0448e-08, 5.0448e-08],\n",
      "        [3.2056e-01, 1.6469e-01, 1.4259e-01, 1.8295e-01, 1.2713e-01, 6.2083e-02,\n",
      "         8.7189e-08, 8.7189e-08, 8.7189e-08, 8.7189e-08],\n",
      "        [2.8799e-01, 1.5930e-01, 1.4502e-01, 1.8563e-01, 1.3891e-01, 8.3145e-02,\n",
      "         1.7215e-07, 1.7215e-07, 1.7215e-07, 1.7215e-07],\n",
      "        [2.5077e-01, 1.5360e-01, 1.4776e-01, 1.8916e-01, 1.5306e-01, 1.0564e-01,\n",
      "         1.5064e-07, 1.5064e-07, 1.5064e-07, 1.5064e-07],\n",
      "        [2.2302e-01, 1.4872e-01, 1.4907e-01, 1.8979e-01, 1.6333e-01, 1.2607e-01,\n",
      "         1.3653e-07, 1.3653e-07, 1.3653e-07, 1.3653e-07],\n",
      "        [2.1754e-01, 1.4786e-01, 1.4938e-01, 1.9036e-01, 1.6536e-01, 1.2950e-01,\n",
      "         1.5061e-07, 1.5061e-07, 1.5061e-07, 1.5061e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 174.00, Train Loss: 0.98, Val Loss: 12.88, Train BLEU: 72.90, Val BLEU: 0.38\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这 有 不少 精彩 的 泰坦 泰坦尼克 坦尼 尼克\n",
      "Reference: we &apos;ve got some of the most incredible video\n",
      "Model: <SOS> we &apos;ve got some of the most incredible incredible\n",
      "Attention Weights: tensor([[0.0404, 0.0339, 0.0493, 0.2915, 0.4034, 0.0627, 0.1128, 0.0039, 0.0017,\n",
      "         0.0006],\n",
      "        [0.0431, 0.0304, 0.0430, 0.2705, 0.3994, 0.0579, 0.1358, 0.0134, 0.0054,\n",
      "         0.0011],\n",
      "        [0.0474, 0.0283, 0.0389, 0.2353, 0.3612, 0.0602, 0.1641, 0.0439, 0.0187,\n",
      "         0.0020],\n",
      "        [0.0489, 0.0291, 0.0395, 0.2138, 0.3156, 0.0618, 0.1746, 0.0811, 0.0323,\n",
      "         0.0034],\n",
      "        [0.0476, 0.0281, 0.0380, 0.1941, 0.2853, 0.0609, 0.1811, 0.1152, 0.0449,\n",
      "         0.0048],\n",
      "        [0.0488, 0.0288, 0.0387, 0.1898, 0.2784, 0.0621, 0.1831, 0.1182, 0.0468,\n",
      "         0.0054],\n",
      "        [0.0512, 0.0308, 0.0414, 0.1867, 0.2690, 0.0651, 0.1835, 0.1170, 0.0484,\n",
      "         0.0068],\n",
      "        [0.0539, 0.0337, 0.0448, 0.1795, 0.2539, 0.0688, 0.1811, 0.1212, 0.0538,\n",
      "         0.0094],\n",
      "        [0.0548, 0.0353, 0.0466, 0.1739, 0.2419, 0.0707, 0.1804, 0.1267, 0.0585,\n",
      "         0.0112]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在 一个 房屋 房屋里 屋里 我们 100 多 人\n",
      "Reference: the school was in a house , more than\n",
      "Model: <SOS> we biodiversity the the the and the the the\n",
      "Attention Weights: tensor([[0.0040, 0.0146, 0.0410, 0.0476, 0.0355, 0.2990, 0.4552, 0.0398, 0.0170,\n",
      "         0.0462],\n",
      "        [0.0066, 0.0331, 0.0447, 0.0460, 0.0352, 0.2944, 0.4392, 0.0380, 0.0166,\n",
      "         0.0462],\n",
      "        [0.0179, 0.1285, 0.0584, 0.0487, 0.0349, 0.2588, 0.3481, 0.0350, 0.0174,\n",
      "         0.0522],\n",
      "        [0.0240, 0.1515, 0.0618, 0.0512, 0.0388, 0.2406, 0.3095, 0.0388, 0.0217,\n",
      "         0.0619],\n",
      "        [0.0271, 0.1566, 0.0644, 0.0533, 0.0416, 0.2293, 0.2904, 0.0423, 0.0250,\n",
      "         0.0701],\n",
      "        [0.0342, 0.1872, 0.0637, 0.0511, 0.0415, 0.2099, 0.2615, 0.0431, 0.0281,\n",
      "         0.0798],\n",
      "        [0.0419, 0.2039, 0.0639, 0.0514, 0.0423, 0.1953, 0.2353, 0.0444, 0.0316,\n",
      "         0.0900],\n",
      "        [0.0439, 0.2091, 0.0640, 0.0515, 0.0426, 0.1905, 0.2263, 0.0448, 0.0329,\n",
      "         0.0944],\n",
      "        [0.0471, 0.2148, 0.0650, 0.0528, 0.0443, 0.1824, 0.2136, 0.0465, 0.0354,\n",
      "         0.0979]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 175.00, Train Loss: 0.97, Val Loss: 12.90, Train BLEU: 72.88, Val BLEU: 0.40\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分 部分 的 动物 也 都 生活 在 海洋\n",
      "Reference: most of the animals are in the oceans .\n",
      "Model: <SOS> most of the animals are the the the the\n",
      "Attention Weights: tensor([[0.0213, 0.0419, 0.1055, 0.0495, 0.2747, 0.0499, 0.0365, 0.2991, 0.0331,\n",
      "         0.0884],\n",
      "        [0.0297, 0.0445, 0.1031, 0.0466, 0.2639, 0.0461, 0.0344, 0.2970, 0.0314,\n",
      "         0.1032],\n",
      "        [0.0533, 0.0570, 0.1046, 0.0477, 0.2322, 0.0460, 0.0357, 0.2637, 0.0351,\n",
      "         0.1246],\n",
      "        [0.0639, 0.0634, 0.1042, 0.0519, 0.2077, 0.0498, 0.0406, 0.2374, 0.0407,\n",
      "         0.1404],\n",
      "        [0.0686, 0.0645, 0.1006, 0.0520, 0.1910, 0.0501, 0.0420, 0.2248, 0.0440,\n",
      "         0.1624],\n",
      "        [0.0740, 0.0684, 0.0954, 0.0540, 0.1684, 0.0520, 0.0460, 0.2031, 0.0500,\n",
      "         0.1887],\n",
      "        [0.0756, 0.0709, 0.0947, 0.0562, 0.1614, 0.0543, 0.0490, 0.1940, 0.0533,\n",
      "         0.1904],\n",
      "        [0.0764, 0.0718, 0.0948, 0.0568, 0.1599, 0.0549, 0.0497, 0.1918, 0.0541,\n",
      "         0.1897],\n",
      "        [0.0758, 0.0718, 0.0949, 0.0570, 0.1597, 0.0551, 0.0500, 0.1915, 0.0544,\n",
      "         0.1899]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 在 塔利 塔利班 控制 阿富汗 的 那些 年 我 记得\n",
      "Reference: during taliban years , i remember there were times\n",
      "Model: <SOS> the of the the matter the the the the\n",
      "Attention Weights: tensor([[0.0469, 0.0501, 0.0613, 0.0781, 0.0898, 0.2766, 0.0999, 0.2088, 0.0879,\n",
      "         0.0006],\n",
      "        [0.0588, 0.0529, 0.0626, 0.0775, 0.0876, 0.2673, 0.0952, 0.2031, 0.0924,\n",
      "         0.0025],\n",
      "        [0.0799, 0.0585, 0.0646, 0.0761, 0.0838, 0.2273, 0.0906, 0.1892, 0.1160,\n",
      "         0.0140],\n",
      "        [0.0867, 0.0609, 0.0656, 0.0753, 0.0817, 0.1966, 0.0881, 0.1763, 0.1325,\n",
      "         0.0364],\n",
      "        [0.0875, 0.0606, 0.0651, 0.0737, 0.0795, 0.1808, 0.0862, 0.1693, 0.1409,\n",
      "         0.0564],\n",
      "        [0.0860, 0.0578, 0.0617, 0.0694, 0.0746, 0.1664, 0.0818, 0.1628, 0.1513,\n",
      "         0.0881],\n",
      "        [0.0822, 0.0564, 0.0598, 0.0661, 0.0706, 0.1453, 0.0777, 0.1495, 0.1571,\n",
      "         0.1354],\n",
      "        [0.0790, 0.0554, 0.0588, 0.0649, 0.0691, 0.1383, 0.0762, 0.1458, 0.1612,\n",
      "         0.1513],\n",
      "        [0.0777, 0.0552, 0.0587, 0.0646, 0.0687, 0.1360, 0.0756, 0.1443, 0.1629,\n",
      "         0.1562]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 176.00, Train Loss: 0.95, Val Loss: 12.91, Train BLEU: 76.22, Val BLEU: 0.40\n",
      "Sampling from training predictions...\n",
      "Source: 还有 这些 摇晃 着 旋转 转着 的 触角 <EOS> <PAD>\n",
      "Reference: it &apos;s got tentacles dangling , swirling around like\n",
      "Model: <SOS> it &apos;s got tentacles dangling , swirling around like\n",
      "Attention Weights: tensor([[1.1749e-01, 1.4068e-01, 2.9140e-01, 1.6410e-01, 2.6788e-01, 1.7483e-02,\n",
      "         6.6136e-04, 2.7438e-04, 3.2739e-05, 1.3628e-11],\n",
      "        [1.3628e-01, 1.4612e-01, 2.9045e-01, 1.6079e-01, 2.4630e-01, 1.9212e-02,\n",
      "         5.6240e-04, 2.4473e-04, 4.4059e-05, 3.9501e-11],\n",
      "        [1.6038e-01, 1.4562e-01, 2.6672e-01, 1.5124e-01, 2.3993e-01, 3.4907e-02,\n",
      "         7.2878e-04, 3.5267e-04, 1.2426e-04, 1.3844e-10],\n",
      "        [1.6693e-01, 1.3471e-01, 2.3214e-01, 1.3986e-01, 2.4603e-01, 7.7757e-02,\n",
      "         1.3431e-03, 7.5233e-04, 4.8448e-04, 9.5898e-10],\n",
      "        [1.5937e-01, 1.2100e-01, 2.0219e-01, 1.2875e-01, 2.4948e-01, 1.3428e-01,\n",
      "         2.3521e-03, 1.3665e-03, 1.2102e-03, 2.4693e-09],\n",
      "        [1.3698e-01, 9.8675e-02, 1.6081e-01, 1.0828e-01, 2.4129e-01, 2.4064e-01,\n",
      "         5.8423e-03, 3.6860e-03, 3.7963e-03, 7.6792e-09],\n",
      "        [1.1905e-01, 8.5679e-02, 1.3478e-01, 9.7161e-02, 2.2030e-01, 3.1529e-01,\n",
      "         1.1060e-02, 7.7495e-03, 8.9303e-03, 1.7296e-08],\n",
      "        [1.1343e-01, 8.3376e-02, 1.2906e-01, 9.5991e-02, 2.1669e-01, 3.2428e-01,\n",
      "         1.4204e-02, 1.0528e-02, 1.2446e-02, 2.3105e-08],\n",
      "        [1.1281e-01, 8.4409e-02, 1.3053e-01, 9.7869e-02, 2.1865e-01, 3.1555e-01,\n",
      "         1.5166e-02, 1.1420e-02, 1.3597e-02, 2.0029e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11 岁 那年 记得 得有 一天 早晨 醒来 听见\n",
      "Reference: when i was 11 , i remember waking up\n",
      "Model: <SOS> and of the the and and the are the\n",
      "Attention Weights: tensor([[5.3975e-01, 2.1355e-01, 8.2089e-02, 1.3104e-01, 3.3144e-02, 3.7164e-04,\n",
      "         4.6484e-05, 8.2594e-11, 8.2594e-11, 8.2594e-11],\n",
      "        [5.5892e-01, 2.0335e-01, 7.9920e-02, 1.2199e-01, 3.5140e-02, 5.9558e-04,\n",
      "         8.1789e-05, 3.7297e-10, 3.7297e-10, 3.7297e-10],\n",
      "        [5.6777e-01, 1.8302e-01, 7.6882e-02, 1.1697e-01, 4.9815e-02, 4.7095e-03,\n",
      "         8.3145e-04, 2.8424e-09, 2.8424e-09, 2.8424e-09],\n",
      "        [4.5012e-01, 1.7594e-01, 9.4563e-02, 1.4694e-01, 9.5646e-02, 3.0533e-02,\n",
      "         6.2667e-03, 2.4628e-08, 2.4628e-08, 2.4628e-08],\n",
      "        [3.6475e-01, 1.6220e-01, 1.0238e-01, 1.6161e-01, 1.2358e-01, 6.9269e-02,\n",
      "         1.6204e-02, 4.5530e-08, 4.5530e-08, 4.5530e-08],\n",
      "        [2.9348e-01, 1.4787e-01, 1.0681e-01, 1.6827e-01, 1.4297e-01, 1.1106e-01,\n",
      "         2.9547e-02, 6.3364e-08, 6.3364e-08, 6.3364e-08],\n",
      "        [2.5681e-01, 1.3891e-01, 1.0678e-01, 1.6785e-01, 1.5098e-01, 1.3983e-01,\n",
      "         3.8840e-02, 7.0831e-08, 7.0831e-08, 7.0831e-08],\n",
      "        [2.5458e-01, 1.3826e-01, 1.0655e-01, 1.6875e-01, 1.5203e-01, 1.4078e-01,\n",
      "         3.9063e-02, 6.6870e-08, 6.6870e-08, 6.6870e-08],\n",
      "        [2.5276e-01, 1.3730e-01, 1.0610e-01, 1.6857e-01, 1.5259e-01, 1.4293e-01,\n",
      "         3.9740e-02, 6.9623e-08, 6.9623e-08, 6.9623e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 177.00, Train Loss: 0.93, Val Loss: 12.89, Train BLEU: 77.95, Val BLEU: 0.41\n",
      "Sampling from training predictions...\n",
      "Source: <UNK> 塞尔 <UNK> <UNK> 斯特 说 过 真正 的 探索\n",
      "Reference: marcel proust said , &quot; the true voyage of\n",
      "Model: <SOS> marcel proust said , &quot; the true voyage voyage\n",
      "Attention Weights: tensor([[0.0001, 0.0000, 0.0001, 0.0008, 0.0375, 0.2168, 0.1277, 0.1679, 0.1205,\n",
      "         0.3286],\n",
      "        [0.0000, 0.0000, 0.0001, 0.0003, 0.0287, 0.2363, 0.1233, 0.1660, 0.1153,\n",
      "         0.3301],\n",
      "        [0.0002, 0.0002, 0.0005, 0.0027, 0.1018, 0.2963, 0.1161, 0.1335, 0.0927,\n",
      "         0.2560],\n",
      "        [0.0009, 0.0008, 0.0023, 0.0093, 0.1703, 0.2819, 0.1033, 0.1129, 0.0825,\n",
      "         0.2359],\n",
      "        [0.0051, 0.0046, 0.0108, 0.0327, 0.2656, 0.2283, 0.0819, 0.0879, 0.0697,\n",
      "         0.2133],\n",
      "        [0.0198, 0.0186, 0.0363, 0.0853, 0.3321, 0.1601, 0.0605, 0.0643, 0.0554,\n",
      "         0.1677],\n",
      "        [0.0283, 0.0265, 0.0483, 0.1038, 0.3222, 0.1398, 0.0565, 0.0607, 0.0542,\n",
      "         0.1597],\n",
      "        [0.0323, 0.0302, 0.0531, 0.1091, 0.3102, 0.1338, 0.0557, 0.0602, 0.0545,\n",
      "         0.1608],\n",
      "        [0.0336, 0.0315, 0.0547, 0.1105, 0.3060, 0.1312, 0.0557, 0.0605, 0.0550,\n",
      "         0.1615]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天 要 走 不同 的 路线 这样 才 没有\n",
      "Reference: each day , we took a different route so\n",
      "Model: <SOS> part when &apos;re &apos;re , , there , are\n",
      "Attention Weights: tensor([[0.0231, 0.0260, 0.2958, 0.0533, 0.1260, 0.0698, 0.2413, 0.0441, 0.0215,\n",
      "         0.0990],\n",
      "        [0.0265, 0.0261, 0.2909, 0.0502, 0.1224, 0.0655, 0.2446, 0.0414, 0.0206,\n",
      "         0.1119],\n",
      "        [0.0429, 0.0329, 0.2678, 0.0497, 0.1112, 0.0630, 0.2144, 0.0426, 0.0244,\n",
      "         0.1510],\n",
      "        [0.0539, 0.0395, 0.2342, 0.0540, 0.1095, 0.0665, 0.1966, 0.0478, 0.0307,\n",
      "         0.1673],\n",
      "        [0.0570, 0.0414, 0.2165, 0.0551, 0.1073, 0.0675, 0.1869, 0.0504, 0.0342,\n",
      "         0.1837],\n",
      "        [0.0598, 0.0432, 0.1967, 0.0552, 0.1027, 0.0676, 0.1741, 0.0526, 0.0387,\n",
      "         0.2095],\n",
      "        [0.0605, 0.0450, 0.1791, 0.0556, 0.0978, 0.0672, 0.1607, 0.0548, 0.0439,\n",
      "         0.2354],\n",
      "        [0.0600, 0.0452, 0.1779, 0.0558, 0.0977, 0.0672, 0.1599, 0.0550, 0.0446,\n",
      "         0.2367],\n",
      "        [0.0614, 0.0474, 0.1730, 0.0576, 0.0974, 0.0685, 0.1555, 0.0571, 0.0474,\n",
      "         0.2346]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 178.00, Train Loss: 0.92, Val Loss: 12.90, Train BLEU: 75.09, Val BLEU: 0.43\n",
      "Sampling from training predictions...\n",
      "Source: 我们 得用 非常 特殊 的 仪器 才能 能到 到达 那个\n",
      "Reference: we have to have a very special technology to\n",
      "Model: <SOS> we have to to a very special technology to\n",
      "Attention Weights: tensor([[0.0289, 0.2778, 0.1057, 0.1051, 0.0938, 0.1672, 0.1937, 0.0218, 0.0054,\n",
      "         0.0006],\n",
      "        [0.0363, 0.3318, 0.0784, 0.0741, 0.0671, 0.1216, 0.1773, 0.1018, 0.0100,\n",
      "         0.0015],\n",
      "        [0.0371, 0.3191, 0.0589, 0.0535, 0.0500, 0.0914, 0.1541, 0.2213, 0.0123,\n",
      "         0.0023],\n",
      "        [0.0384, 0.2886, 0.0551, 0.0505, 0.0481, 0.0854, 0.1447, 0.2705, 0.0153,\n",
      "         0.0035],\n",
      "        [0.0396, 0.2789, 0.0542, 0.0499, 0.0480, 0.0844, 0.1434, 0.2809, 0.0166,\n",
      "         0.0042],\n",
      "        [0.0413, 0.2752, 0.0523, 0.0486, 0.0471, 0.0836, 0.1451, 0.2847, 0.0175,\n",
      "         0.0048],\n",
      "        [0.0451, 0.2664, 0.0495, 0.0472, 0.0471, 0.0833, 0.1476, 0.2871, 0.0196,\n",
      "         0.0070],\n",
      "        [0.0492, 0.2554, 0.0503, 0.0484, 0.0488, 0.0853, 0.1513, 0.2803, 0.0220,\n",
      "         0.0089],\n",
      "        [0.0503, 0.2482, 0.0505, 0.0490, 0.0498, 0.0855, 0.1511, 0.2820, 0.0234,\n",
      "         0.0103]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 祖父 在 他 的 年代 是 位非 非凡\n",
      "Reference: my grandfather was an extraordinary man for his time\n",
      "Model: <SOS> we &apos;s have &apos;re going , and , ,\n",
      "Attention Weights: tensor([[0.0718, 0.0719, 0.0972, 0.1744, 0.1498, 0.2606, 0.1064, 0.0479, 0.0197,\n",
      "         0.0005],\n",
      "        [0.0827, 0.0732, 0.0970, 0.1729, 0.1462, 0.2612, 0.1028, 0.0449, 0.0183,\n",
      "         0.0008],\n",
      "        [0.1055, 0.0784, 0.0963, 0.1639, 0.1374, 0.2450, 0.0998, 0.0476, 0.0229,\n",
      "         0.0032],\n",
      "        [0.1195, 0.0816, 0.0960, 0.1537, 0.1296, 0.2245, 0.0984, 0.0534, 0.0315,\n",
      "         0.0117],\n",
      "        [0.1232, 0.0827, 0.0957, 0.1460, 0.1239, 0.2097, 0.0972, 0.0580, 0.0395,\n",
      "         0.0241],\n",
      "        [0.1205, 0.0800, 0.0910, 0.1337, 0.1148, 0.1923, 0.0959, 0.0638, 0.0530,\n",
      "         0.0551],\n",
      "        [0.1102, 0.0755, 0.0853, 0.1207, 0.1061, 0.1719, 0.0948, 0.0705, 0.0677,\n",
      "         0.0974],\n",
      "        [0.1055, 0.0737, 0.0837, 0.1172, 0.1038, 0.1663, 0.0947, 0.0729, 0.0727,\n",
      "         0.1096],\n",
      "        [0.1029, 0.0730, 0.0831, 0.1157, 0.1030, 0.1635, 0.0950, 0.0746, 0.0757,\n",
      "         0.1136]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 179.00, Train Loss: 0.90, Val Loss: 12.92, Train BLEU: 77.16, Val BLEU: 0.43\n",
      "Sampling from training predictions...\n",
      "Source: 看到 这些 在 动 的 东西 了 吗 <EOS> <PAD>\n",
      "Reference: but see all those different working things ? <EOS>\n",
      "Model: <SOS> but see all those different working things <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.8888e-01, 2.0760e-01, 2.2399e-01, 1.7885e-01, 1.2434e-01, 6.1558e-02,\n",
      "         1.0184e-02, 4.0920e-03, 5.1023e-04, 1.3155e-10],\n",
      "        [2.0698e-01, 2.0988e-01, 2.2431e-01, 1.7592e-01, 1.1695e-01, 5.3683e-02,\n",
      "         8.4400e-03, 3.3288e-03, 5.0263e-04, 2.0514e-10],\n",
      "        [2.4480e-01, 2.0879e-01, 2.1198e-01, 1.6350e-01, 1.0744e-01, 5.0114e-02,\n",
      "         8.4721e-03, 3.7395e-03, 1.1597e-03, 5.8055e-10],\n",
      "        [2.5855e-01, 2.0078e-01, 1.9910e-01, 1.5725e-01, 1.0820e-01, 5.5402e-02,\n",
      "         1.1205e-02, 5.8170e-03, 3.6946e-03, 4.0279e-09],\n",
      "        [2.6666e-01, 1.9066e-01, 1.8825e-01, 1.5211e-01, 1.1027e-01, 6.2628e-02,\n",
      "         1.4377e-02, 8.0632e-03, 6.9803e-03, 7.7816e-09],\n",
      "        [2.5348e-01, 1.7243e-01, 1.7235e-01, 1.4665e-01, 1.1690e-01, 8.0823e-02,\n",
      "         2.5037e-02, 1.5848e-02, 1.6482e-02, 2.2308e-08],\n",
      "        [2.1760e-01, 1.5221e-01, 1.5577e-01, 1.4043e-01, 1.2218e-01, 1.0076e-01,\n",
      "         4.2872e-02, 3.1149e-02, 3.7035e-02, 3.8846e-08],\n",
      "        [1.9481e-01, 1.4183e-01, 1.4705e-01, 1.3613e-01, 1.2338e-01, 1.0932e-01,\n",
      "         5.4183e-02, 4.2187e-02, 5.1104e-02, 5.5059e-08],\n",
      "        [1.8852e-01, 1.3999e-01, 1.4641e-01, 1.3649e-01, 1.2461e-01, 1.1154e-01,\n",
      "         5.6067e-02, 4.3922e-02, 5.2456e-02, 4.6254e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11 岁 那年 记得 得有 一天 早晨 醒来 听见\n",
      "Reference: when i was 11 , i remember waking up\n",
      "Model: <SOS> and of the the and and the are the\n",
      "Attention Weights: tensor([[5.5201e-01, 2.1497e-01, 7.8289e-02, 1.2208e-01, 3.2162e-02, 4.5162e-04,\n",
      "         5.0938e-05, 9.3699e-11, 9.3699e-11, 9.3699e-11],\n",
      "        [5.7238e-01, 2.0413e-01, 7.5777e-02, 1.1295e-01, 3.3975e-02, 6.9731e-04,\n",
      "         8.5512e-05, 3.9196e-10, 3.9196e-10, 3.9196e-10],\n",
      "        [5.7877e-01, 1.8345e-01, 7.3227e-02, 1.0946e-01, 4.8771e-02, 5.4554e-03,\n",
      "         8.6565e-04, 3.0668e-09, 3.0668e-09, 3.0668e-09],\n",
      "        [4.5873e-01, 1.7627e-01, 9.1182e-02, 1.3973e-01, 9.4216e-02, 3.3705e-02,\n",
      "         6.1565e-03, 2.5952e-08, 2.5952e-08, 2.5952e-08],\n",
      "        [3.7108e-01, 1.6250e-01, 9.9256e-02, 1.5501e-01, 1.2235e-01, 7.4244e-02,\n",
      "         1.5567e-02, 4.5694e-08, 4.5694e-08, 4.5694e-08],\n",
      "        [2.9276e-01, 1.4713e-01, 1.0453e-01, 1.6263e-01, 1.4359e-01, 1.2037e-01,\n",
      "         2.9000e-02, 6.3388e-08, 6.3388e-08, 6.3388e-08],\n",
      "        [2.5204e-01, 1.3708e-01, 1.0472e-01, 1.6246e-01, 1.5252e-01, 1.5223e-01,\n",
      "         3.8934e-02, 7.3513e-08, 7.3513e-08, 7.3513e-08],\n",
      "        [2.5008e-01, 1.3647e-01, 1.0449e-01, 1.6309e-01, 1.5335e-01, 1.5318e-01,\n",
      "         3.9337e-02, 7.1069e-08, 7.1069e-08, 7.1069e-08],\n",
      "        [2.4805e-01, 1.3540e-01, 1.0400e-01, 1.6290e-01, 1.5401e-01, 1.5558e-01,\n",
      "         4.0069e-02, 7.3064e-08, 7.3064e-08, 7.3064e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 180.00, Train Loss: 0.88, Val Loss: 12.93, Train BLEU: 77.93, Val BLEU: 0.41\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想 海洋 占 了 地球 球面 面积 的 75\n",
      "Reference: when you think about it , the oceans are\n",
      "Model: <SOS> when you think about it , the oceans are\n",
      "Attention Weights: tensor([[0.0124, 0.0120, 0.2242, 0.0291, 0.0237, 0.2673, 0.2477, 0.1652, 0.0176,\n",
      "         0.0008],\n",
      "        [0.0172, 0.0135, 0.2243, 0.0281, 0.0229, 0.2721, 0.2396, 0.1594, 0.0184,\n",
      "         0.0043],\n",
      "        [0.0267, 0.0178, 0.2184, 0.0299, 0.0256, 0.2648, 0.2170, 0.1528, 0.0247,\n",
      "         0.0222],\n",
      "        [0.0328, 0.0213, 0.2073, 0.0325, 0.0285, 0.2534, 0.1970, 0.1480, 0.0316,\n",
      "         0.0477],\n",
      "        [0.0357, 0.0228, 0.1902, 0.0329, 0.0293, 0.2373, 0.1812, 0.1424, 0.0367,\n",
      "         0.0914],\n",
      "        [0.0355, 0.0228, 0.1690, 0.0312, 0.0288, 0.2175, 0.1607, 0.1324, 0.0411,\n",
      "         0.1608],\n",
      "        [0.0361, 0.0238, 0.1606, 0.0317, 0.0297, 0.2082, 0.1531, 0.1292, 0.0440,\n",
      "         0.1835],\n",
      "        [0.0365, 0.0247, 0.1544, 0.0324, 0.0305, 0.1993, 0.1476, 0.1272, 0.0476,\n",
      "         0.1996],\n",
      "        [0.0363, 0.0250, 0.1531, 0.0328, 0.0311, 0.1968, 0.1462, 0.1271, 0.0492,\n",
      "         0.2023]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11 岁 那年 记得 得有 一天 早晨 醒来 听见\n",
      "Reference: when i was 11 , i remember waking up\n",
      "Model: <SOS> and of the the and and the are in\n",
      "Attention Weights: tensor([[5.4575e-01, 2.2077e-01, 7.7230e-02, 1.2449e-01, 3.1334e-02, 3.8219e-04,\n",
      "         4.2359e-05, 8.3633e-11, 8.3633e-11, 8.3633e-11],\n",
      "        [5.6866e-01, 2.0914e-01, 7.4289e-02, 1.1445e-01, 3.2812e-02, 5.7783e-04,\n",
      "         6.9387e-05, 3.3410e-10, 3.3410e-10, 3.3410e-10],\n",
      "        [5.7926e-01, 1.8783e-01, 7.1374e-02, 1.0980e-01, 4.6631e-02, 4.4274e-03,\n",
      "         6.8425e-04, 2.5466e-09, 2.5466e-09, 2.5466e-09],\n",
      "        [4.6869e-01, 1.8069e-01, 8.8884e-02, 1.3938e-01, 9.0182e-02, 2.7361e-02,\n",
      "         4.8095e-03, 2.1101e-08, 2.1101e-08, 2.1101e-08],\n",
      "        [3.8407e-01, 1.6759e-01, 9.7923e-02, 1.5640e-01, 1.1957e-01, 6.2013e-02,\n",
      "         1.2424e-02, 3.7040e-08, 3.7040e-08, 3.7040e-08],\n",
      "        [3.0623e-01, 1.5184e-01, 1.0386e-01, 1.6560e-01, 1.4303e-01, 1.0518e-01,\n",
      "         2.4252e-02, 5.3687e-08, 5.3687e-08, 5.3687e-08],\n",
      "        [2.5791e-01, 1.3982e-01, 1.0457e-01, 1.6603e-01, 1.5455e-01, 1.4207e-01,\n",
      "         3.5056e-02, 6.6231e-08, 6.6231e-08, 6.6231e-08],\n",
      "        [2.5514e-01, 1.3917e-01, 1.0445e-01, 1.6701e-01, 1.5568e-01, 1.4305e-01,\n",
      "         3.5508e-02, 6.3144e-08, 6.3144e-08, 6.3144e-08],\n",
      "        [2.5283e-01, 1.3801e-01, 1.0398e-01, 1.6692e-01, 1.5653e-01, 1.4551e-01,\n",
      "         3.6211e-02, 6.4290e-08, 6.4290e-08, 6.4290e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 181.00, Train Loss: 0.86, Val Loss: 12.93, Train BLEU: 77.51, Val BLEU: 0.57\n",
      "Sampling from training predictions...\n",
      "Source: 底下 这些 都 是 <UNK> 它们 上上 上上下下 上下 下下\n",
      "Reference: it &apos;s got these fishing <UNK> on the bottom\n",
      "Model: <SOS> it &apos;s got these fishing <UNK> on the bottom\n",
      "Attention Weights: tensor([[0.0453, 0.0443, 0.0381, 0.0339, 0.0148, 0.1166, 0.5849, 0.1091, 0.0123,\n",
      "         0.0008],\n",
      "        [0.0506, 0.0457, 0.0404, 0.0382, 0.0229, 0.1144, 0.5804, 0.0951, 0.0112,\n",
      "         0.0011],\n",
      "        [0.0558, 0.0425, 0.0376, 0.0394, 0.0460, 0.1009, 0.5929, 0.0714, 0.0106,\n",
      "         0.0029],\n",
      "        [0.0577, 0.0401, 0.0369, 0.0430, 0.0902, 0.0957, 0.5526, 0.0628, 0.0129,\n",
      "         0.0081],\n",
      "        [0.0556, 0.0366, 0.0341, 0.0404, 0.1244, 0.0896, 0.5253, 0.0624, 0.0158,\n",
      "         0.0159],\n",
      "        [0.0483, 0.0302, 0.0293, 0.0366, 0.1780, 0.0800, 0.4689, 0.0635, 0.0220,\n",
      "         0.0432],\n",
      "        [0.0437, 0.0270, 0.0269, 0.0352, 0.2229, 0.0703, 0.4094, 0.0603, 0.0264,\n",
      "         0.0779],\n",
      "        [0.0438, 0.0283, 0.0288, 0.0381, 0.2277, 0.0682, 0.3716, 0.0632, 0.0318,\n",
      "         0.0985],\n",
      "        [0.0462, 0.0310, 0.0319, 0.0421, 0.2279, 0.0702, 0.3482, 0.0654, 0.0356,\n",
      "         0.1015]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 在 被 跟踪 吗 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: were we being followed ? <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a kind different working <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0777, 0.0670, 0.0789, 0.0764, 0.4484, 0.2352, 0.0030, 0.0022, 0.0086,\n",
      "         0.0026],\n",
      "        [0.0889, 0.0619, 0.0694, 0.0673, 0.3873, 0.2739, 0.0185, 0.0131, 0.0149,\n",
      "         0.0048],\n",
      "        [0.0909, 0.0549, 0.0595, 0.0586, 0.3342, 0.2863, 0.0517, 0.0365, 0.0204,\n",
      "         0.0070],\n",
      "        [0.0854, 0.0530, 0.0575, 0.0580, 0.2903, 0.2739, 0.0935, 0.0556, 0.0235,\n",
      "         0.0093],\n",
      "        [0.0851, 0.0533, 0.0577, 0.0583, 0.2741, 0.2623, 0.1110, 0.0623, 0.0255,\n",
      "         0.0105],\n",
      "        [0.0796, 0.0489, 0.0534, 0.0543, 0.2576, 0.2578, 0.1369, 0.0748, 0.0261,\n",
      "         0.0107],\n",
      "        [0.0670, 0.0420, 0.0462, 0.0480, 0.2139, 0.2348, 0.1946, 0.1112, 0.0286,\n",
      "         0.0138],\n",
      "        [0.0636, 0.0400, 0.0439, 0.0459, 0.1951, 0.2236, 0.2114, 0.1304, 0.0306,\n",
      "         0.0155],\n",
      "        [0.0600, 0.0385, 0.0423, 0.0444, 0.1803, 0.2148, 0.2268, 0.1442, 0.0316,\n",
      "         0.0170]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 182.00, Train Loss: 0.85, Val Loss: 12.92, Train BLEU: 77.29, Val BLEU: 0.57\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 这位 是 比尔 <UNK> 我 是 大卫 <UNK>\n",
      "Reference: this is bill lange . i &apos;m dave gallo\n",
      "Model: <SOS> this is bill lange . i &apos;m dave gallo\n",
      "Attention Weights: tensor([[0.0598, 0.0669, 0.1615, 0.1429, 0.2558, 0.0766, 0.1097, 0.0917, 0.0307,\n",
      "         0.0045],\n",
      "        [0.0708, 0.0739, 0.1617, 0.1391, 0.2619, 0.0841, 0.0970, 0.0793, 0.0276,\n",
      "         0.0047],\n",
      "        [0.0829, 0.1002, 0.1454, 0.1180, 0.2766, 0.1088, 0.0774, 0.0592, 0.0242,\n",
      "         0.0073],\n",
      "        [0.0872, 0.1106, 0.1360, 0.1126, 0.2724, 0.1123, 0.0731, 0.0569, 0.0275,\n",
      "         0.0114],\n",
      "        [0.0836, 0.1248, 0.1242, 0.1002, 0.2666, 0.1301, 0.0700, 0.0544, 0.0290,\n",
      "         0.0171],\n",
      "        [0.0683, 0.1788, 0.0872, 0.0661, 0.2580, 0.1902, 0.0484, 0.0375, 0.0263,\n",
      "         0.0393],\n",
      "        [0.0627, 0.2004, 0.0732, 0.0550, 0.2430, 0.2146, 0.0410, 0.0320, 0.0253,\n",
      "         0.0529],\n",
      "        [0.0602, 0.2096, 0.0681, 0.0512, 0.2356, 0.2223, 0.0381, 0.0300, 0.0249,\n",
      "         0.0601],\n",
      "        [0.0596, 0.2115, 0.0666, 0.0503, 0.2320, 0.2229, 0.0374, 0.0297, 0.0254,\n",
      "         0.0644]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 所以 在 那 之后 5 年 我 <UNK> <UNK> 陪\n",
      "Reference: so for the next five years , i dressed\n",
      "Model: <SOS> we use the submarine alvin and use use cameras\n",
      "Attention Weights: tensor([[3.7594e-01, 1.3889e-01, 1.5817e-01, 2.9106e-01, 2.7680e-02, 7.2012e-03,\n",
      "         9.6072e-04, 9.4584e-05, 5.8385e-11, 5.8385e-11],\n",
      "        [4.2018e-01, 1.3849e-01, 1.4947e-01, 2.5273e-01, 2.6734e-02, 1.0919e-02,\n",
      "         1.2563e-03, 2.1431e-04, 3.0163e-10, 3.0163e-10],\n",
      "        [4.3867e-01, 1.3299e-01, 1.4051e-01, 2.3446e-01, 2.9807e-02, 2.1011e-02,\n",
      "         1.9861e-03, 5.7287e-04, 8.4724e-10, 8.4724e-10],\n",
      "        [4.3665e-01, 1.3060e-01, 1.3574e-01, 2.2023e-01, 3.4568e-02, 3.7285e-02,\n",
      "         3.3748e-03, 1.5487e-03, 4.4818e-09, 4.4818e-09],\n",
      "        [4.0623e-01, 1.2883e-01, 1.3552e-01, 2.2142e-01, 4.2400e-02, 5.7105e-02,\n",
      "         5.4173e-03, 3.0818e-03, 9.5605e-09, 9.5605e-09],\n",
      "        [3.6930e-01, 1.2453e-01, 1.3442e-01, 2.2089e-01, 5.1570e-02, 8.4661e-02,\n",
      "         8.8874e-03, 5.7362e-03, 2.0922e-08, 2.0922e-08],\n",
      "        [3.0912e-01, 1.1548e-01, 1.2926e-01, 2.1399e-01, 6.4753e-02, 1.3876e-01,\n",
      "         1.6554e-02, 1.2087e-02, 2.9338e-08, 2.9338e-08],\n",
      "        [2.4699e-01, 1.0657e-01, 1.2281e-01, 2.0046e-01, 7.8302e-02, 1.8933e-01,\n",
      "         3.0091e-02, 2.5456e-02, 5.0069e-08, 5.0069e-08],\n",
      "        [2.3785e-01, 1.0538e-01, 1.2334e-01, 2.0082e-01, 8.0031e-02, 1.9288e-01,\n",
      "         3.2170e-02, 2.7538e-02, 4.4260e-08, 4.4260e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 183.00, Train Loss: 0.83, Val Loss: 12.92, Train BLEU: 79.18, Val BLEU: 0.57\n",
      "Sampling from training predictions...\n",
      "Source: 我们 得用 非常 特殊 的 仪器 才能 能到 到达 那个\n",
      "Reference: we have to have a very special technology to\n",
      "Model: <SOS> we have to to a very special technology to\n",
      "Attention Weights: tensor([[0.0229, 0.2998, 0.0945, 0.0898, 0.0794, 0.1687, 0.2130, 0.0268, 0.0047,\n",
      "         0.0004],\n",
      "        [0.0297, 0.3444, 0.0715, 0.0645, 0.0577, 0.1212, 0.1884, 0.1126, 0.0088,\n",
      "         0.0012],\n",
      "        [0.0314, 0.3253, 0.0556, 0.0477, 0.0441, 0.0922, 0.1645, 0.2262, 0.0111,\n",
      "         0.0019],\n",
      "        [0.0343, 0.2917, 0.0543, 0.0474, 0.0448, 0.0879, 0.1538, 0.2680, 0.0147,\n",
      "         0.0031],\n",
      "        [0.0354, 0.2803, 0.0536, 0.0471, 0.0448, 0.0868, 0.1521, 0.2802, 0.0160,\n",
      "         0.0037],\n",
      "        [0.0368, 0.2736, 0.0513, 0.0454, 0.0436, 0.0847, 0.1518, 0.2914, 0.0170,\n",
      "         0.0044],\n",
      "        [0.0382, 0.2643, 0.0443, 0.0401, 0.0392, 0.0778, 0.1492, 0.3228, 0.0181,\n",
      "         0.0060],\n",
      "        [0.0415, 0.2556, 0.0437, 0.0399, 0.0396, 0.0784, 0.1527, 0.3213, 0.0199,\n",
      "         0.0075],\n",
      "        [0.0425, 0.2497, 0.0435, 0.0401, 0.0401, 0.0781, 0.1520, 0.3243, 0.0210,\n",
      "         0.0087]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 那 就是 她 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: there she is . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> here &apos;s a kind stuff . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.8600e-01, 2.0674e-01, 2.1467e-01, 1.7229e-01, 1.3416e-01, 7.1421e-02,\n",
      "         9.9866e-03, 4.0729e-03, 6.5695e-04, 1.6109e-10],\n",
      "        [2.0486e-01, 2.1011e-01, 2.1611e-01, 1.6962e-01, 1.2590e-01, 6.1497e-02,\n",
      "         8.0858e-03, 3.2146e-03, 6.0992e-04, 1.9825e-10],\n",
      "        [2.4002e-01, 2.0894e-01, 2.0458e-01, 1.5839e-01, 1.1663e-01, 5.8321e-02,\n",
      "         8.1988e-03, 3.6057e-03, 1.3264e-03, 4.8069e-10],\n",
      "        [2.5074e-01, 2.0351e-01, 1.9481e-01, 1.5433e-01, 1.1598e-01, 6.1559e-02,\n",
      "         1.0230e-02, 5.2276e-03, 3.6218e-03, 2.8156e-09],\n",
      "        [2.6298e-01, 1.9373e-01, 1.8410e-01, 1.4924e-01, 1.1633e-01, 6.7426e-02,\n",
      "         1.2654e-02, 6.9655e-03, 6.5694e-03, 5.0108e-09],\n",
      "        [2.5597e-01, 1.7392e-01, 1.6701e-01, 1.4259e-01, 1.2110e-01, 8.6426e-02,\n",
      "         2.2443e-02, 1.4063e-02, 1.6490e-02, 1.4678e-08],\n",
      "        [2.2308e-01, 1.5108e-01, 1.4902e-01, 1.3508e-01, 1.2416e-01, 1.0711e-01,\n",
      "         4.0090e-02, 2.9273e-02, 4.1118e-02, 3.2816e-08],\n",
      "        [1.9720e-01, 1.3959e-01, 1.4027e-01, 1.3063e-01, 1.2438e-01, 1.1541e-01,\n",
      "         5.2365e-02, 4.1344e-02, 5.8805e-02, 5.3220e-08],\n",
      "        [1.8899e-01, 1.3716e-01, 1.3944e-01, 1.3084e-01, 1.2570e-01, 1.1829e-01,\n",
      "         5.4782e-02, 4.3659e-02, 6.1143e-02, 4.4243e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 184.00, Train Loss: 0.82, Val Loss: 12.94, Train BLEU: 79.74, Val BLEU: 0.57\n",
      "Sampling from training predictions...\n",
      "Source: 它 可以 伸展 <UNK> 150 英尺 长 <EOS> <PAD> <PAD>\n",
      "Reference: it gets up to about 150 feet long .\n",
      "Model: <SOS> it gets up to about 150 feet long .\n",
      "Attention Weights: tensor([[2.2288e-01, 1.9858e-01, 2.3158e-01, 6.1065e-02, 2.6166e-01, 1.4970e-02,\n",
      "         7.7740e-03, 1.4905e-03, 2.6611e-10, 2.6611e-10],\n",
      "        [2.4700e-01, 1.9938e-01, 2.3968e-01, 7.3204e-02, 2.2170e-01, 1.1381e-02,\n",
      "         6.0886e-03, 1.5647e-03, 6.5662e-10, 6.5662e-10],\n",
      "        [2.3337e-01, 1.6686e-01, 2.0951e-01, 1.1975e-01, 2.4896e-01, 1.2062e-02,\n",
      "         6.5748e-03, 2.9177e-03, 1.6048e-09, 1.6048e-09],\n",
      "        [2.2558e-01, 1.5923e-01, 1.9773e-01, 1.7616e-01, 2.1655e-01, 1.2201e-02,\n",
      "         7.2290e-03, 5.3176e-03, 4.5054e-09, 4.5054e-09],\n",
      "        [1.9012e-01, 1.3120e-01, 1.6260e-01, 2.2431e-01, 2.5675e-01, 1.5987e-02,\n",
      "         9.7355e-03, 9.2946e-03, 1.0678e-08, 1.0678e-08],\n",
      "        [1.4814e-01, 1.0028e-01, 1.2593e-01, 2.6873e-01, 3.0753e-01, 2.1585e-02,\n",
      "         1.3395e-02, 1.4400e-02, 1.9211e-08, 1.9211e-08],\n",
      "        [1.1224e-01, 7.7717e-02, 1.0084e-01, 3.1654e-01, 3.2630e-01, 2.6731e-02,\n",
      "         1.7655e-02, 2.1969e-02, 2.3536e-08, 2.3536e-08],\n",
      "        [1.0273e-01, 7.6004e-02, 1.0017e-01, 3.2104e-01, 3.0703e-01, 3.4414e-02,\n",
      "         2.5220e-02, 3.3385e-02, 3.6694e-08, 3.6694e-08],\n",
      "        [1.0442e-01, 8.0215e-02, 1.0651e-01, 3.1510e-01, 2.8772e-01, 3.7807e-02,\n",
      "         2.9196e-02, 3.9030e-02, 4.4001e-08, 4.4001e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 想 过 要 放弃 但 我 的 父亲 这时\n",
      "Reference: i would want to quit , but my father\n",
      "Model: <SOS> and when &apos;re &apos;re standing , us , ,\n",
      "Attention Weights: tensor([[0.0299, 0.0375, 0.0478, 0.1605, 0.0693, 0.2020, 0.4284, 0.0192, 0.0052,\n",
      "         0.0002],\n",
      "        [0.0320, 0.0373, 0.0473, 0.1581, 0.0670, 0.1995, 0.4347, 0.0185, 0.0054,\n",
      "         0.0002],\n",
      "        [0.0381, 0.0392, 0.0483, 0.1573, 0.0668, 0.1968, 0.4270, 0.0180, 0.0081,\n",
      "         0.0005],\n",
      "        [0.0497, 0.0439, 0.0508, 0.1518, 0.0679, 0.1866, 0.4081, 0.0223, 0.0172,\n",
      "         0.0018],\n",
      "        [0.0612, 0.0488, 0.0545, 0.1449, 0.0700, 0.1744, 0.3716, 0.0296, 0.0388,\n",
      "         0.0062],\n",
      "        [0.0689, 0.0522, 0.0566, 0.1348, 0.0698, 0.1603, 0.3347, 0.0373, 0.0700,\n",
      "         0.0153],\n",
      "        [0.0637, 0.0444, 0.0474, 0.1050, 0.0573, 0.1261, 0.2912, 0.0459, 0.1680,\n",
      "         0.0511],\n",
      "        [0.0552, 0.0376, 0.0401, 0.0844, 0.0479, 0.1019, 0.2418, 0.0487, 0.2456,\n",
      "         0.0967],\n",
      "        [0.0514, 0.0352, 0.0378, 0.0789, 0.0449, 0.0954, 0.2273, 0.0491, 0.2662,\n",
      "         0.1138]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 185.00, Train Loss: 0.81, Val Loss: 12.98, Train BLEU: 78.92, Val BLEU: 0.57\n",
      "Sampling from training predictions...\n",
      "Source: 还有 前面 的 这个 是 推进 引擎 它 一会 一会儿\n",
      "Reference: and it &apos;s got these jet thrusters up in\n",
      "Model: <SOS> and it &apos;s got these jet thrusters up in\n",
      "Attention Weights: tensor([[0.0267, 0.0331, 0.0430, 0.1604, 0.0646, 0.2065, 0.4409, 0.0186, 0.0060,\n",
      "         0.0002],\n",
      "        [0.0287, 0.0330, 0.0427, 0.1579, 0.0626, 0.2039, 0.4468, 0.0180, 0.0062,\n",
      "         0.0002],\n",
      "        [0.0346, 0.0351, 0.0440, 0.1575, 0.0627, 0.2014, 0.4371, 0.0176, 0.0095,\n",
      "         0.0005],\n",
      "        [0.0459, 0.0399, 0.0467, 0.1518, 0.0643, 0.1907, 0.4161, 0.0223, 0.0201,\n",
      "         0.0021],\n",
      "        [0.0575, 0.0451, 0.0508, 0.1443, 0.0668, 0.1771, 0.3760, 0.0299, 0.0450,\n",
      "         0.0075],\n",
      "        [0.0648, 0.0483, 0.0527, 0.1325, 0.0664, 0.1606, 0.3363, 0.0378, 0.0819,\n",
      "         0.0186],\n",
      "        [0.0582, 0.0400, 0.0429, 0.0990, 0.0529, 0.1215, 0.2824, 0.0459, 0.1942,\n",
      "         0.0631],\n",
      "        [0.0497, 0.0337, 0.0361, 0.0792, 0.0439, 0.0977, 0.2333, 0.0473, 0.2685,\n",
      "         0.1105],\n",
      "        [0.0464, 0.0317, 0.0342, 0.0744, 0.0413, 0.0920, 0.2203, 0.0475, 0.2858,\n",
      "         0.1263]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 所以 在 那 之后 5 年 我 <UNK> <UNK> 陪\n",
      "Reference: so for the next five years , i dressed\n",
      "Model: <SOS> we use the submarine alvin and use use cameras\n",
      "Attention Weights: tensor([[3.3668e-01, 1.4007e-01, 1.7452e-01, 3.1389e-01, 2.6302e-02, 7.5050e-03,\n",
      "         9.2183e-04, 9.9221e-05, 5.9526e-11, 5.9526e-11],\n",
      "        [3.7797e-01, 1.4187e-01, 1.6741e-01, 2.7485e-01, 2.5697e-02, 1.0801e-02,\n",
      "         1.1855e-03, 2.1574e-04, 2.8043e-10, 2.8043e-10],\n",
      "        [3.9416e-01, 1.3728e-01, 1.5939e-01, 2.5790e-01, 2.8918e-02, 1.9969e-02,\n",
      "         1.8326e-03, 5.4942e-04, 7.3235e-10, 7.3235e-10],\n",
      "        [3.9875e-01, 1.3690e-01, 1.5413e-01, 2.3868e-01, 3.3655e-02, 3.3404e-02,\n",
      "         3.0716e-03, 1.4214e-03, 3.5950e-09, 3.5950e-09],\n",
      "        [3.8031e-01, 1.3478e-01, 1.5075e-01, 2.3438e-01, 4.1262e-02, 5.0661e-02,\n",
      "         5.0093e-03, 2.8432e-03, 7.4381e-09, 7.4381e-09],\n",
      "        [3.4932e-01, 1.2914e-01, 1.4712e-01, 2.3228e-01, 5.0924e-02, 7.7192e-02,\n",
      "         8.5196e-03, 5.5010e-03, 1.6353e-08, 1.6353e-08],\n",
      "        [2.9538e-01, 1.1789e-01, 1.3807e-01, 2.2222e-01, 6.4127e-02, 1.3390e-01,\n",
      "         1.6358e-02, 1.2061e-02, 2.3482e-08, 2.3482e-08],\n",
      "        [2.3556e-01, 1.0651e-01, 1.2729e-01, 2.0462e-01, 7.7421e-02, 1.9104e-01,\n",
      "         3.0745e-02, 2.6818e-02, 4.3174e-08, 4.3174e-08],\n",
      "        [2.2685e-01, 1.0527e-01, 1.2790e-01, 2.0542e-01, 7.9114e-02, 1.9400e-01,\n",
      "         3.2666e-02, 2.8773e-02, 3.7561e-08, 3.7561e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 186.00, Train Loss: 0.79, Val Loss: 13.00, Train BLEU: 82.17, Val BLEU: 0.57\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一只 水母 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: here &apos;s a jelly . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> here &apos;s a jelly . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[2.0828e-01, 1.4326e-01, 1.6814e-01, 4.3330e-01, 4.7022e-02, 2.8352e-09,\n",
      "         2.8352e-09, 2.8352e-09, 2.8352e-09, 2.8352e-09],\n",
      "        [2.1894e-01, 1.3819e-01, 1.6025e-01, 4.1596e-01, 6.6659e-02, 6.9970e-09,\n",
      "         6.9970e-09, 6.9970e-09, 6.9970e-09, 6.9970e-09],\n",
      "        [2.2619e-01, 1.3014e-01, 1.4737e-01, 3.8820e-01, 1.0811e-01, 1.5390e-08,\n",
      "         1.5390e-08, 1.5390e-08, 1.5390e-08, 1.5390e-08],\n",
      "        [1.9648e-01, 1.1114e-01, 1.3570e-01, 3.6812e-01, 1.8855e-01, 5.6605e-08,\n",
      "         5.6605e-08, 5.6605e-08, 5.6605e-08, 5.6605e-08],\n",
      "        [1.7764e-01, 1.0303e-01, 1.2824e-01, 3.4475e-01, 2.4634e-01, 7.0766e-08,\n",
      "         7.0766e-08, 7.0766e-08, 7.0766e-08, 7.0766e-08],\n",
      "        [1.5561e-01, 1.0741e-01, 1.3581e-01, 3.0640e-01, 2.9477e-01, 7.9310e-08,\n",
      "         7.9310e-08, 7.9310e-08, 7.9310e-08, 7.9310e-08],\n",
      "        [1.5278e-01, 1.1037e-01, 1.3918e-01, 2.9908e-01, 2.9860e-01, 9.3874e-08,\n",
      "         9.3874e-08, 9.3874e-08, 9.3874e-08, 9.3874e-08],\n",
      "        [1.5215e-01, 1.1032e-01, 1.3932e-01, 2.9884e-01, 2.9937e-01, 9.8500e-08,\n",
      "         9.8500e-08, 9.8500e-08, 9.8500e-08, 9.8500e-08],\n",
      "        [1.5203e-01, 1.1040e-01, 1.3936e-01, 2.9800e-01, 3.0021e-01, 1.0434e-07,\n",
      "         1.0434e-07, 1.0434e-07, 1.0434e-07, 1.0434e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把 书 放在 食品 杂货 袋中 这样 别人 就\n",
      "Reference: we would cover our books in grocery bags so\n",
      "Model: <SOS> it &apos;s have &apos;re standing , us , in\n",
      "Attention Weights: tensor([[0.0111, 0.0350, 0.0909, 0.0486, 0.3115, 0.0401, 0.0270, 0.3184, 0.0286,\n",
      "         0.0889],\n",
      "        [0.0170, 0.0395, 0.0929, 0.0483, 0.2998, 0.0396, 0.0272, 0.3092, 0.0284,\n",
      "         0.0981],\n",
      "        [0.0325, 0.0518, 0.0969, 0.0495, 0.2649, 0.0405, 0.0292, 0.2781, 0.0322,\n",
      "         0.1243],\n",
      "        [0.0435, 0.0608, 0.1006, 0.0558, 0.2362, 0.0472, 0.0358, 0.2479, 0.0392,\n",
      "         0.1330],\n",
      "        [0.0492, 0.0621, 0.0963, 0.0554, 0.2141, 0.0478, 0.0374, 0.2360, 0.0430,\n",
      "         0.1586],\n",
      "        [0.0574, 0.0634, 0.0869, 0.0514, 0.1839, 0.0448, 0.0375, 0.2206, 0.0449,\n",
      "         0.2092],\n",
      "        [0.0607, 0.0663, 0.0865, 0.0534, 0.1737, 0.0472, 0.0408, 0.2095, 0.0482,\n",
      "         0.2135],\n",
      "        [0.0621, 0.0677, 0.0868, 0.0545, 0.1710, 0.0485, 0.0422, 0.2056, 0.0495,\n",
      "         0.2121],\n",
      "        [0.0613, 0.0679, 0.0869, 0.0549, 0.1704, 0.0490, 0.0428, 0.2041, 0.0502,\n",
      "         0.2125]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 187.00, Train Loss: 0.78, Val Loss: 13.00, Train BLEU: 84.94, Val BLEU: 0.54\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克 泰坦尼克号 坦尼 尼克 号 是 拿 了 不少\n",
      "Reference: the truth of the matter is that the titanic\n",
      "Model: <SOS> the truth of the matter is the the titanic\n",
      "Attention Weights: tensor([[0.0201, 0.0221, 0.0162, 0.0892, 0.1924, 0.0952, 0.1079, 0.1234, 0.1054,\n",
      "         0.2280],\n",
      "        [0.0300, 0.0438, 0.0345, 0.1602, 0.1996, 0.0924, 0.0943, 0.1002, 0.0820,\n",
      "         0.1629],\n",
      "        [0.0457, 0.1015, 0.0849, 0.3006, 0.1431, 0.0594, 0.0545, 0.0566, 0.0484,\n",
      "         0.1051],\n",
      "        [0.0471, 0.1154, 0.0956, 0.2956, 0.1353, 0.0582, 0.0524, 0.0540, 0.0470,\n",
      "         0.0995],\n",
      "        [0.0490, 0.1328, 0.1098, 0.3004, 0.1243, 0.0540, 0.0479, 0.0493, 0.0436,\n",
      "         0.0887],\n",
      "        [0.0479, 0.1722, 0.1494, 0.3358, 0.0918, 0.0386, 0.0326, 0.0331, 0.0302,\n",
      "         0.0684],\n",
      "        [0.0525, 0.2079, 0.1935, 0.3476, 0.0582, 0.0248, 0.0207, 0.0215, 0.0210,\n",
      "         0.0523],\n",
      "        [0.0585, 0.2155, 0.2002, 0.3259, 0.0546, 0.0248, 0.0212, 0.0222, 0.0223,\n",
      "         0.0547],\n",
      "        [0.0615, 0.2156, 0.1977, 0.3120, 0.0563, 0.0266, 0.0229, 0.0241, 0.0245,\n",
      "         0.0589]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在 可以 去 个 真正 的 学校 念书 了\n",
      "Reference: &quot; you can go to a real school now\n",
      "Model: <SOS> people &apos;s mostly partnered standing , , , there\n",
      "Attention Weights: tensor([[0.0201, 0.0221, 0.0162, 0.0892, 0.1924, 0.0952, 0.1079, 0.1234, 0.1054,\n",
      "         0.2280],\n",
      "        [0.0300, 0.0438, 0.0345, 0.1602, 0.1996, 0.0924, 0.0943, 0.1002, 0.0820,\n",
      "         0.1629],\n",
      "        [0.0457, 0.1015, 0.0849, 0.3006, 0.1431, 0.0594, 0.0545, 0.0566, 0.0484,\n",
      "         0.1051],\n",
      "        [0.0471, 0.1154, 0.0956, 0.2956, 0.1353, 0.0582, 0.0524, 0.0540, 0.0470,\n",
      "         0.0995],\n",
      "        [0.0490, 0.1328, 0.1098, 0.3004, 0.1243, 0.0540, 0.0479, 0.0493, 0.0436,\n",
      "         0.0887],\n",
      "        [0.0479, 0.1722, 0.1494, 0.3358, 0.0918, 0.0386, 0.0326, 0.0331, 0.0302,\n",
      "         0.0684],\n",
      "        [0.0525, 0.2079, 0.1935, 0.3476, 0.0582, 0.0248, 0.0207, 0.0215, 0.0210,\n",
      "         0.0523],\n",
      "        [0.0585, 0.2155, 0.2002, 0.3259, 0.0546, 0.0248, 0.0212, 0.0222, 0.0223,\n",
      "         0.0547],\n",
      "        [0.0615, 0.2156, 0.1977, 0.3120, 0.0563, 0.0266, 0.0229, 0.0241, 0.0245,\n",
      "         0.0589]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 188.00, Train Loss: 0.76, Val Loss: 13.00, Train BLEU: 85.58, Val BLEU: 0.57\n",
      "Sampling from training predictions...\n",
      "Source: 我们 将 用 一些 影片 来讲 讲述 一些 深海 海里\n",
      "Reference: and we &apos;re going to tell you some stories\n",
      "Model: <SOS> and we &apos;re going to tell , there stories\n",
      "Attention Weights: tensor([[0.0081, 0.0075, 0.0108, 0.1226, 0.2431, 0.0434, 0.0396, 0.2149, 0.2518,\n",
      "         0.0583],\n",
      "        [0.0109, 0.0085, 0.0116, 0.1188, 0.2428, 0.0443, 0.0393, 0.2099, 0.2500,\n",
      "         0.0639],\n",
      "        [0.0189, 0.0123, 0.0153, 0.1169, 0.2209, 0.0484, 0.0428, 0.1975, 0.2432,\n",
      "         0.0838],\n",
      "        [0.0286, 0.0179, 0.0212, 0.1144, 0.2005, 0.0558, 0.0503, 0.1850, 0.2250,\n",
      "         0.1012],\n",
      "        [0.0324, 0.0202, 0.0235, 0.1141, 0.1931, 0.0587, 0.0529, 0.1796, 0.2175,\n",
      "         0.1081],\n",
      "        [0.0346, 0.0210, 0.0243, 0.1136, 0.1859, 0.0579, 0.0529, 0.1752, 0.2150,\n",
      "         0.1195],\n",
      "        [0.0355, 0.0211, 0.0242, 0.1103, 0.1810, 0.0568, 0.0515, 0.1701, 0.2169,\n",
      "         0.1326],\n",
      "        [0.0358, 0.0211, 0.0242, 0.1091, 0.1729, 0.0546, 0.0502, 0.1648, 0.2167,\n",
      "         0.1505],\n",
      "        [0.0364, 0.0218, 0.0249, 0.1092, 0.1695, 0.0547, 0.0507, 0.1625, 0.2147,\n",
      "         0.1557]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在 一个 房屋 房屋里 屋里 我们 100 多 人\n",
      "Reference: the school was in a house , more than\n",
      "Model: <SOS> we biodiversity have the the and the the the\n",
      "Attention Weights: tensor([[0.0023, 0.0298, 0.0277, 0.0325, 0.0271, 0.2919, 0.5002, 0.0290, 0.0118,\n",
      "         0.0477],\n",
      "        [0.0043, 0.0597, 0.0330, 0.0346, 0.0291, 0.2803, 0.4699, 0.0298, 0.0125,\n",
      "         0.0469],\n",
      "        [0.0116, 0.1849, 0.0444, 0.0380, 0.0293, 0.2381, 0.3568, 0.0287, 0.0141,\n",
      "         0.0542],\n",
      "        [0.0175, 0.2002, 0.0526, 0.0449, 0.0358, 0.2194, 0.3137, 0.0349, 0.0192,\n",
      "         0.0617],\n",
      "        [0.0205, 0.2012, 0.0564, 0.0474, 0.0385, 0.2100, 0.2946, 0.0389, 0.0225,\n",
      "         0.0700],\n",
      "        [0.0249, 0.2528, 0.0541, 0.0430, 0.0355, 0.1887, 0.2599, 0.0369, 0.0236,\n",
      "         0.0806],\n",
      "        [0.0294, 0.2994, 0.0522, 0.0397, 0.0323, 0.1721, 0.2280, 0.0338, 0.0236,\n",
      "         0.0894],\n",
      "        [0.0317, 0.3119, 0.0521, 0.0394, 0.0321, 0.1659, 0.2158, 0.0338, 0.0246,\n",
      "         0.0927],\n",
      "        [0.0353, 0.3196, 0.0538, 0.0410, 0.0338, 0.1577, 0.2008, 0.0357, 0.0271,\n",
      "         0.0953]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 189.00, Train Loss: 0.75, Val Loss: 12.99, Train BLEU: 86.73, Val BLEU: 0.56\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本 基本上 都 没有 被 开发 发过 但是 像\n",
      "Reference: it &apos;s mostly unexplored , and yet there are\n",
      "Model: <SOS> it &apos;s mostly unexplored , and yet there are\n",
      "Attention Weights: tensor([[0.0135, 0.0186, 0.2829, 0.0495, 0.0847, 0.0469, 0.1590, 0.1154, 0.2235,\n",
      "         0.0061],\n",
      "        [0.0219, 0.0229, 0.2848, 0.0486, 0.0806, 0.0451, 0.1484, 0.1148, 0.2254,\n",
      "         0.0076],\n",
      "        [0.0331, 0.0294, 0.2811, 0.0503, 0.0803, 0.0466, 0.1392, 0.1128, 0.2159,\n",
      "         0.0112],\n",
      "        [0.0458, 0.0374, 0.2532, 0.0557, 0.0834, 0.0523, 0.1344, 0.1147, 0.2056,\n",
      "         0.0175],\n",
      "        [0.0545, 0.0428, 0.2355, 0.0588, 0.0850, 0.0562, 0.1310, 0.1148, 0.1970,\n",
      "         0.0244],\n",
      "        [0.0577, 0.0436, 0.2279, 0.0580, 0.0838, 0.0567, 0.1287, 0.1141, 0.1992,\n",
      "         0.0303],\n",
      "        [0.0595, 0.0450, 0.2287, 0.0573, 0.0829, 0.0568, 0.1272, 0.1127, 0.1968,\n",
      "         0.0332],\n",
      "        [0.0606, 0.0457, 0.2305, 0.0557, 0.0816, 0.0560, 0.1259, 0.1111, 0.1960,\n",
      "         0.0367],\n",
      "        [0.0616, 0.0473, 0.2265, 0.0569, 0.0825, 0.0575, 0.1252, 0.1108, 0.1922,\n",
      "         0.0394]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 总是 担心 会 被 塔利 塔利班 发现 <EOS> <PAD>\n",
      "Reference: we always wondered what they knew about us .\n",
      "Model: <SOS> it &apos;s got to about about working . <EOS>\n",
      "Attention Weights: tensor([[0.0220, 0.3438, 0.1011, 0.0953, 0.0811, 0.1414, 0.1771, 0.0329, 0.0049,\n",
      "         0.0005],\n",
      "        [0.0293, 0.3691, 0.0824, 0.0740, 0.0633, 0.1068, 0.1543, 0.1103, 0.0092,\n",
      "         0.0013],\n",
      "        [0.0326, 0.3396, 0.0668, 0.0579, 0.0516, 0.0860, 0.1371, 0.2134, 0.0126,\n",
      "         0.0023],\n",
      "        [0.0372, 0.2997, 0.0662, 0.0582, 0.0532, 0.0835, 0.1297, 0.2507, 0.0175,\n",
      "         0.0040],\n",
      "        [0.0381, 0.2880, 0.0642, 0.0565, 0.0522, 0.0816, 0.1282, 0.2671, 0.0191,\n",
      "         0.0049],\n",
      "        [0.0385, 0.2815, 0.0588, 0.0518, 0.0484, 0.0770, 0.1267, 0.2915, 0.0201,\n",
      "         0.0057],\n",
      "        [0.0370, 0.2697, 0.0453, 0.0405, 0.0387, 0.0652, 0.1205, 0.3564, 0.0194,\n",
      "         0.0072],\n",
      "        [0.0383, 0.2610, 0.0421, 0.0379, 0.0368, 0.0633, 0.1225, 0.3697, 0.0200,\n",
      "         0.0083],\n",
      "        [0.0393, 0.2563, 0.0416, 0.0378, 0.0370, 0.0633, 0.1224, 0.3723, 0.0207,\n",
      "         0.0094]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 190.00, Train Loss: 0.73, Val Loss: 12.99, Train BLEU: 88.38, Val BLEU: 0.50\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里 生物 的 多样 多样性 和 密度 要 比\n",
      "Reference: the biodiversity and the <UNK> in the ocean is\n",
      "Model: <SOS> the biodiversity and the <UNK> in the is is\n",
      "Attention Weights: tensor([[0.0044, 0.0022, 0.0201, 0.0096, 0.0333, 0.9150, 0.0083, 0.0044, 0.0019,\n",
      "         0.0008],\n",
      "        [0.0035, 0.0015, 0.0098, 0.0051, 0.0171, 0.9540, 0.0049, 0.0025, 0.0012,\n",
      "         0.0006],\n",
      "        [0.0040, 0.0016, 0.0090, 0.0048, 0.0157, 0.9560, 0.0046, 0.0024, 0.0012,\n",
      "         0.0007],\n",
      "        [0.0057, 0.0024, 0.0113, 0.0065, 0.0185, 0.9418, 0.0068, 0.0038, 0.0020,\n",
      "         0.0013],\n",
      "        [0.0076, 0.0033, 0.0140, 0.0083, 0.0221, 0.9258, 0.0089, 0.0051, 0.0029,\n",
      "         0.0020],\n",
      "        [0.0085, 0.0035, 0.0139, 0.0083, 0.0220, 0.9240, 0.0088, 0.0052, 0.0033,\n",
      "         0.0026],\n",
      "        [0.0121, 0.0050, 0.0182, 0.0110, 0.0294, 0.8977, 0.0106, 0.0067, 0.0048,\n",
      "         0.0046],\n",
      "        [0.0139, 0.0061, 0.0200, 0.0124, 0.0318, 0.8846, 0.0120, 0.0079, 0.0057,\n",
      "         0.0056],\n",
      "        [0.0156, 0.0070, 0.0227, 0.0142, 0.0357, 0.8689, 0.0134, 0.0090, 0.0068,\n",
      "         0.0067]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 总是 担心 会 被 塔利 塔利班 发现 <EOS> <PAD>\n",
      "Reference: we always wondered what they knew about us .\n",
      "Model: <SOS> it &apos;s got to to about working swirling <EOS>\n",
      "Attention Weights: tensor([[0.0209, 0.3128, 0.1090, 0.1051, 0.0899, 0.1642, 0.1727, 0.0206, 0.0043,\n",
      "         0.0004],\n",
      "        [0.0290, 0.3493, 0.0947, 0.0871, 0.0746, 0.1305, 0.1580, 0.0674, 0.0083,\n",
      "         0.0011],\n",
      "        [0.0348, 0.3345, 0.0819, 0.0730, 0.0651, 0.1103, 0.1487, 0.1372, 0.0124,\n",
      "         0.0021],\n",
      "        [0.0408, 0.2998, 0.0822, 0.0739, 0.0675, 0.1069, 0.1411, 0.1663, 0.0177,\n",
      "         0.0038],\n",
      "        [0.0419, 0.2913, 0.0801, 0.0720, 0.0663, 0.1041, 0.1395, 0.1808, 0.0194,\n",
      "         0.0045],\n",
      "        [0.0427, 0.2886, 0.0742, 0.0664, 0.0617, 0.0982, 0.1385, 0.2036, 0.0208,\n",
      "         0.0054],\n",
      "        [0.0405, 0.2860, 0.0567, 0.0511, 0.0485, 0.0823, 0.1333, 0.2748, 0.0200,\n",
      "         0.0067],\n",
      "        [0.0405, 0.2754, 0.0497, 0.0451, 0.0437, 0.0767, 0.1340, 0.3071, 0.0201,\n",
      "         0.0079],\n",
      "        [0.0414, 0.2714, 0.0481, 0.0440, 0.0430, 0.0759, 0.1343, 0.3127, 0.0204,\n",
      "         0.0087]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 191.00, Train Loss: 0.71, Val Loss: 13.00, Train BLEU: 88.27, Val BLEU: 0.53\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数 多数 地震 和 火山 喷发 也 都 发生\n",
      "Reference: most of the earthquakes and volcanoes are in the\n",
      "Model: <SOS> most of the earthquakes and volcanoes are in the\n",
      "Attention Weights: tensor([[0.0021, 0.0298, 0.0258, 0.0324, 0.0256, 0.3069, 0.4922, 0.0275, 0.0107,\n",
      "         0.0469],\n",
      "        [0.0038, 0.0558, 0.0306, 0.0344, 0.0280, 0.2944, 0.4668, 0.0288, 0.0116,\n",
      "         0.0457],\n",
      "        [0.0101, 0.1618, 0.0430, 0.0400, 0.0305, 0.2540, 0.3618, 0.0297, 0.0143,\n",
      "         0.0548],\n",
      "        [0.0159, 0.1744, 0.0529, 0.0489, 0.0384, 0.2332, 0.3185, 0.0369, 0.0196,\n",
      "         0.0613],\n",
      "        [0.0192, 0.1813, 0.0580, 0.0519, 0.0411, 0.2206, 0.2964, 0.0408, 0.0228,\n",
      "         0.0679],\n",
      "        [0.0232, 0.2333, 0.0559, 0.0468, 0.0375, 0.1985, 0.2639, 0.0384, 0.0238,\n",
      "         0.0787],\n",
      "        [0.0266, 0.2922, 0.0523, 0.0416, 0.0322, 0.1810, 0.2312, 0.0334, 0.0225,\n",
      "         0.0871],\n",
      "        [0.0281, 0.3073, 0.0514, 0.0408, 0.0318, 0.1750, 0.2181, 0.0329, 0.0232,\n",
      "         0.0913],\n",
      "        [0.0318, 0.3154, 0.0531, 0.0425, 0.0335, 0.1664, 0.2023, 0.0347, 0.0257,\n",
      "         0.0947]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在 一个 房屋 房屋里 屋里 我们 100 多 人\n",
      "Reference: the school was in a house , more than\n",
      "Model: <SOS> we biodiversity have the <UNK> and the in the\n",
      "Attention Weights: tensor([[0.0021, 0.0298, 0.0258, 0.0324, 0.0256, 0.3069, 0.4922, 0.0275, 0.0107,\n",
      "         0.0469],\n",
      "        [0.0038, 0.0558, 0.0306, 0.0344, 0.0280, 0.2944, 0.4668, 0.0288, 0.0116,\n",
      "         0.0457],\n",
      "        [0.0101, 0.1618, 0.0430, 0.0400, 0.0305, 0.2540, 0.3618, 0.0297, 0.0143,\n",
      "         0.0548],\n",
      "        [0.0159, 0.1744, 0.0529, 0.0489, 0.0384, 0.2332, 0.3185, 0.0369, 0.0196,\n",
      "         0.0613],\n",
      "        [0.0192, 0.1813, 0.0580, 0.0519, 0.0411, 0.2206, 0.2964, 0.0408, 0.0228,\n",
      "         0.0679],\n",
      "        [0.0232, 0.2333, 0.0559, 0.0468, 0.0375, 0.1985, 0.2639, 0.0384, 0.0238,\n",
      "         0.0787],\n",
      "        [0.0266, 0.2922, 0.0523, 0.0416, 0.0322, 0.1810, 0.2312, 0.0334, 0.0225,\n",
      "         0.0871],\n",
      "        [0.0281, 0.3073, 0.0514, 0.0408, 0.0318, 0.1750, 0.2181, 0.0329, 0.0232,\n",
      "         0.0913],\n",
      "        [0.0318, 0.3154, 0.0531, 0.0425, 0.0335, 0.1664, 0.2023, 0.0347, 0.0257,\n",
      "         0.0947]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 192.00, Train Loss: 0.70, Val Loss: 13.02, Train BLEU: 88.55, Val BLEU: 0.57\n",
      "Sampling from training predictions...\n",
      "Source: 看到 这些 在 动 的 东西 了 吗 <EOS> <PAD>\n",
      "Reference: but see all those different working things ? <EOS>\n",
      "Model: <SOS> but see all those different working things <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.7204e-01, 2.0022e-01, 2.1242e-01, 1.7154e-01, 1.5897e-01, 7.4103e-02,\n",
      "         7.1134e-03, 2.9514e-03, 6.4943e-04, 1.1882e-10],\n",
      "        [1.9182e-01, 2.0459e-01, 2.1348e-01, 1.6888e-01, 1.4907e-01, 6.3710e-02,\n",
      "         5.6184e-03, 2.2585e-03, 5.6873e-04, 1.3019e-10],\n",
      "        [2.1658e-01, 2.0457e-01, 2.0548e-01, 1.5962e-01, 1.4141e-01, 6.2455e-02,\n",
      "         6.1236e-03, 2.6948e-03, 1.0764e-03, 2.5070e-10],\n",
      "        [2.2161e-01, 2.0602e-01, 2.0034e-01, 1.5751e-01, 1.3787e-01, 6.3329e-02,\n",
      "         7.5013e-03, 3.7198e-03, 2.1034e-03, 1.1104e-09],\n",
      "        [2.4009e-01, 1.9903e-01, 1.8945e-01, 1.5133e-01, 1.3514e-01, 6.7422e-02,\n",
      "         9.1869e-03, 4.8617e-03, 3.4918e-03, 1.6824e-09],\n",
      "        [2.4034e-01, 1.7744e-01, 1.7028e-01, 1.4308e-01, 1.3844e-01, 8.9525e-02,\n",
      "         1.8566e-02, 1.1498e-02, 1.0832e-02, 5.4949e-09],\n",
      "        [2.1285e-01, 1.4861e-01, 1.4735e-01, 1.3213e-01, 1.3786e-01, 1.1593e-01,\n",
      "         3.8374e-02, 2.8744e-02, 3.8148e-02, 1.6807e-08],\n",
      "        [1.8788e-01, 1.3603e-01, 1.3767e-01, 1.2707e-01, 1.3533e-01, 1.2404e-01,\n",
      "         5.1122e-02, 4.1343e-02, 5.9511e-02, 3.0869e-08],\n",
      "        [1.7874e-01, 1.3358e-01, 1.3694e-01, 1.2741e-01, 1.3647e-01, 1.2669e-01,\n",
      "         5.3648e-02, 4.3876e-02, 6.2631e-02, 2.4378e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 想 过 要 放弃 但 我 的 父亲 这时\n",
      "Reference: i would want to quit , but my father\n",
      "Model: <SOS> and we &apos;re &apos;re standing , , , ,\n",
      "Attention Weights: tensor([[0.0292, 0.0357, 0.0458, 0.1584, 0.0744, 0.1825, 0.4506, 0.0166, 0.0066,\n",
      "         0.0002],\n",
      "        [0.0322, 0.0367, 0.0465, 0.1572, 0.0732, 0.1812, 0.4498, 0.0163, 0.0067,\n",
      "         0.0002],\n",
      "        [0.0395, 0.0404, 0.0496, 0.1595, 0.0750, 0.1812, 0.4296, 0.0160, 0.0088,\n",
      "         0.0005],\n",
      "        [0.0517, 0.0472, 0.0546, 0.1559, 0.0794, 0.1749, 0.3988, 0.0204, 0.0156,\n",
      "         0.0015],\n",
      "        [0.0651, 0.0549, 0.0610, 0.1500, 0.0842, 0.1657, 0.3560, 0.0277, 0.0307,\n",
      "         0.0048],\n",
      "        [0.0755, 0.0596, 0.0637, 0.1403, 0.0833, 0.1533, 0.3198, 0.0358, 0.0566,\n",
      "         0.0121],\n",
      "        [0.0671, 0.0485, 0.0517, 0.1062, 0.0656, 0.1167, 0.2742, 0.0466, 0.1687,\n",
      "         0.0548],\n",
      "        [0.0537, 0.0376, 0.0402, 0.0807, 0.0503, 0.0894, 0.2234, 0.0473, 0.2646,\n",
      "         0.1127],\n",
      "        [0.0482, 0.0338, 0.0363, 0.0732, 0.0453, 0.0811, 0.2088, 0.0462, 0.2936,\n",
      "         0.1334]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 193.00, Train Loss: 0.68, Val Loss: 13.02, Train BLEU: 89.74, Val BLEU: 0.53\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这 有 不少 精彩 的 泰坦 泰坦尼克 坦尼 尼克\n",
      "Reference: we &apos;ve got some of the most incredible video\n",
      "Model: <SOS> we &apos;ve got some of the most incredible video\n",
      "Attention Weights: tensor([[0.0262, 0.0189, 0.0301, 0.2562, 0.4454, 0.0487, 0.1617, 0.0097, 0.0029,\n",
      "         0.0004],\n",
      "        [0.0319, 0.0205, 0.0307, 0.2349, 0.4244, 0.0486, 0.1759, 0.0252, 0.0074,\n",
      "         0.0006],\n",
      "        [0.0358, 0.0211, 0.0311, 0.2088, 0.3720, 0.0528, 0.1969, 0.0613, 0.0192,\n",
      "         0.0011],\n",
      "        [0.0423, 0.0256, 0.0359, 0.1900, 0.3135, 0.0586, 0.1997, 0.0996, 0.0322,\n",
      "         0.0026],\n",
      "        [0.0379, 0.0225, 0.0313, 0.1565, 0.2625, 0.0545, 0.2044, 0.1712, 0.0553,\n",
      "         0.0038],\n",
      "        [0.0367, 0.0214, 0.0296, 0.1456, 0.2471, 0.0529, 0.2039, 0.1950, 0.0633,\n",
      "         0.0043],\n",
      "        [0.0341, 0.0194, 0.0272, 0.1385, 0.2392, 0.0515, 0.2108, 0.2070, 0.0675,\n",
      "         0.0049],\n",
      "        [0.0340, 0.0193, 0.0272, 0.1353, 0.2328, 0.0521, 0.2103, 0.2118, 0.0710,\n",
      "         0.0061],\n",
      "        [0.0344, 0.0200, 0.0283, 0.1350, 0.2292, 0.0532, 0.2091, 0.2113, 0.0724,\n",
      "         0.0072]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 但是 我 那 受过 教育 的 母亲 成为 为了 一名\n",
      "Reference: but my educated mother became a teacher . <EOS>\n",
      "Model: <SOS> and biodiversity the the and and and the in\n",
      "Attention Weights: tensor([[2.3394e-01, 2.0097e-01, 2.5988e-01, 6.9420e-02, 2.1683e-01, 1.0993e-02,\n",
      "         6.3912e-03, 1.5793e-03, 2.2711e-10, 2.2711e-10],\n",
      "        [2.5659e-01, 2.0274e-01, 2.6583e-01, 8.2893e-02, 1.7708e-01, 8.2840e-03,\n",
      "         4.9417e-03, 1.6365e-03, 6.3685e-10, 6.3685e-10],\n",
      "        [2.4687e-01, 1.7774e-01, 2.4200e-01, 1.2610e-01, 1.8939e-01, 9.2912e-03,\n",
      "         5.6843e-03, 2.9227e-03, 1.5068e-09, 1.5068e-09],\n",
      "        [2.5040e-01, 1.8439e-01, 2.3824e-01, 1.5134e-01, 1.5504e-01, 9.6832e-03,\n",
      "         6.3523e-03, 4.5536e-03, 3.5173e-09, 3.5173e-09],\n",
      "        [2.2736e-01, 1.6026e-01, 2.0236e-01, 1.8462e-01, 1.9437e-01, 1.3931e-02,\n",
      "         9.1627e-03, 7.9430e-03, 8.4016e-09, 8.4016e-09],\n",
      "        [1.7942e-01, 1.2269e-01, 1.5762e-01, 2.3143e-01, 2.5966e-01, 2.1409e-02,\n",
      "         1.4200e-02, 1.3568e-02, 1.6277e-08, 1.6277e-08],\n",
      "        [1.2506e-01, 8.5877e-02, 1.1432e-01, 3.0381e-01, 3.0134e-01, 2.7535e-02,\n",
      "         1.9374e-02, 2.2686e-02, 2.1401e-08, 2.1401e-08],\n",
      "        [1.0681e-01, 7.8879e-02, 1.0565e-01, 3.2011e-01, 2.9011e-01, 3.4991e-02,\n",
      "         2.7267e-02, 3.6182e-02, 3.3745e-08, 3.3745e-08],\n",
      "        [1.0668e-01, 8.2551e-02, 1.1142e-01, 3.1450e-01, 2.7014e-01, 3.8782e-02,\n",
      "         3.2041e-02, 4.3888e-02, 4.0940e-08, 4.0940e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 194.00, Train Loss: 0.67, Val Loss: 13.03, Train BLEU: 88.68, Val BLEU: 0.56\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想 海洋 占 了 地球 球面 面积 的 75\n",
      "Reference: when you think about it , the oceans are\n",
      "Model: <SOS> when you think about it , the oceans are\n",
      "Attention Weights: tensor([[0.0105, 0.0097, 0.2093, 0.0244, 0.0188, 0.3059, 0.2373, 0.1677, 0.0152,\n",
      "         0.0012],\n",
      "        [0.0162, 0.0128, 0.2098, 0.0272, 0.0211, 0.2996, 0.2295, 0.1624, 0.0170,\n",
      "         0.0044],\n",
      "        [0.0275, 0.0197, 0.2016, 0.0345, 0.0278, 0.2714, 0.2152, 0.1611, 0.0251,\n",
      "         0.0162],\n",
      "        [0.0356, 0.0247, 0.1930, 0.0385, 0.0318, 0.2569, 0.1970, 0.1557, 0.0330,\n",
      "         0.0338],\n",
      "        [0.0409, 0.0277, 0.1756, 0.0396, 0.0337, 0.2339, 0.1775, 0.1464, 0.0406,\n",
      "         0.0841],\n",
      "        [0.0380, 0.0251, 0.1433, 0.0334, 0.0299, 0.2007, 0.1402, 0.1224, 0.0433,\n",
      "         0.2238],\n",
      "        [0.0353, 0.0234, 0.1323, 0.0306, 0.0280, 0.1904, 0.1282, 0.1138, 0.0426,\n",
      "         0.2756],\n",
      "        [0.0326, 0.0218, 0.1232, 0.0282, 0.0259, 0.1815, 0.1187, 0.1076, 0.0424,\n",
      "         0.3180],\n",
      "        [0.0318, 0.0216, 0.1223, 0.0282, 0.0260, 0.1803, 0.1177, 0.1073, 0.0432,\n",
      "         0.3216]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 不知 知道 那 意味 意味着 什么 但是 我 能\n",
      "Reference: i didn &apos;t know what it meant , but\n",
      "Model: <SOS> it &apos;s and the partnered and and are in\n",
      "Attention Weights: tensor([[0.0278, 0.0194, 0.0299, 0.2536, 0.4438, 0.0471, 0.1627, 0.0118, 0.0035,\n",
      "         0.0004],\n",
      "        [0.0338, 0.0210, 0.0305, 0.2311, 0.4207, 0.0470, 0.1760, 0.0305, 0.0089,\n",
      "         0.0006],\n",
      "        [0.0373, 0.0212, 0.0304, 0.2030, 0.3652, 0.0505, 0.1956, 0.0729, 0.0227,\n",
      "         0.0012],\n",
      "        [0.0433, 0.0255, 0.0349, 0.1836, 0.3058, 0.0561, 0.1969, 0.1143, 0.0367,\n",
      "         0.0026],\n",
      "        [0.0382, 0.0221, 0.0302, 0.1494, 0.2529, 0.0518, 0.1991, 0.1909, 0.0616,\n",
      "         0.0038],\n",
      "        [0.0369, 0.0210, 0.0285, 0.1386, 0.2374, 0.0502, 0.1981, 0.2152, 0.0700,\n",
      "         0.0043],\n",
      "        [0.0343, 0.0191, 0.0263, 0.1323, 0.2302, 0.0491, 0.2053, 0.2248, 0.0736,\n",
      "         0.0049],\n",
      "        [0.0344, 0.0191, 0.0265, 0.1295, 0.2245, 0.0500, 0.2053, 0.2278, 0.0768,\n",
      "         0.0062],\n",
      "        [0.0350, 0.0199, 0.0277, 0.1292, 0.2209, 0.0513, 0.2039, 0.2267, 0.0781,\n",
      "         0.0073]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 195.00, Train Loss: 0.65, Val Loss: 13.04, Train BLEU: 89.39, Val BLEU: 0.53\n",
      "Sampling from training predictions...\n",
      "Source: 原因 在于 我们 一直 没 把 海洋 当回事 回事 回事儿\n",
      "Reference: and the problem , i think , is that\n",
      "Model: <SOS> and the problem , i think , is that\n",
      "Attention Weights: tensor([[0.0270, 0.0228, 0.0332, 0.3926, 0.0430, 0.0264, 0.4059, 0.0486, 0.0003,\n",
      "         0.0000],\n",
      "        [0.0354, 0.0262, 0.0363, 0.3923, 0.0437, 0.0276, 0.3892, 0.0484, 0.0008,\n",
      "         0.0002],\n",
      "        [0.0603, 0.0396, 0.0492, 0.3346, 0.0560, 0.0385, 0.3385, 0.0767, 0.0049,\n",
      "         0.0016],\n",
      "        [0.0751, 0.0481, 0.0570, 0.2986, 0.0640, 0.0460, 0.3082, 0.0908, 0.0088,\n",
      "         0.0034],\n",
      "        [0.0755, 0.0452, 0.0529, 0.2547, 0.0593, 0.0451, 0.3178, 0.1227, 0.0187,\n",
      "         0.0082],\n",
      "        [0.0679, 0.0390, 0.0455, 0.2170, 0.0505, 0.0405, 0.3278, 0.1610, 0.0350,\n",
      "         0.0159],\n",
      "        [0.0620, 0.0350, 0.0414, 0.2052, 0.0458, 0.0373, 0.3303, 0.1769, 0.0453,\n",
      "         0.0208],\n",
      "        [0.0568, 0.0324, 0.0387, 0.1943, 0.0427, 0.0353, 0.3275, 0.1894, 0.0567,\n",
      "         0.0264],\n",
      "        [0.0561, 0.0335, 0.0395, 0.1795, 0.0429, 0.0365, 0.3064, 0.1970, 0.0722,\n",
      "         0.0365]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 有时 学校 <UNK> 突然 <UNK> 一周 因为 被 塔利 塔利班\n",
      "Reference: from time to time , the school would suddenly\n",
      "Model: <SOS> it &apos;s got to <UNK> i the bottom bottom\n",
      "Attention Weights: tensor([[0.0665, 0.0570, 0.0815, 0.1868, 0.1172, 0.1846, 0.1403, 0.0794, 0.0540,\n",
      "         0.0327],\n",
      "        [0.0823, 0.0617, 0.0846, 0.1844, 0.1144, 0.1765, 0.1344, 0.0767, 0.0525,\n",
      "         0.0324],\n",
      "        [0.1071, 0.0678, 0.0863, 0.1705, 0.1081, 0.1600, 0.1255, 0.0766, 0.0564,\n",
      "         0.0417],\n",
      "        [0.1236, 0.0749, 0.0888, 0.1561, 0.1042, 0.1450, 0.1177, 0.0780, 0.0612,\n",
      "         0.0505],\n",
      "        [0.1278, 0.0794, 0.0905, 0.1452, 0.1026, 0.1357, 0.1138, 0.0803, 0.0660,\n",
      "         0.0588],\n",
      "        [0.1303, 0.0788, 0.0886, 0.1384, 0.0998, 0.1304, 0.1116, 0.0815, 0.0704,\n",
      "         0.0702],\n",
      "        [0.1262, 0.0752, 0.0840, 0.1306, 0.0962, 0.1254, 0.1106, 0.0839, 0.0777,\n",
      "         0.0901],\n",
      "        [0.1250, 0.0748, 0.0831, 0.1279, 0.0952, 0.1234, 0.1099, 0.0846, 0.0798,\n",
      "         0.0963],\n",
      "        [0.1247, 0.0732, 0.0818, 0.1266, 0.0939, 0.1223, 0.1094, 0.0846, 0.0811,\n",
      "         0.1025]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 196.00, Train Loss: 0.64, Val Loss: 13.07, Train BLEU: 89.39, Val BLEU: 0.54\n",
      "Sampling from training predictions...\n",
      "Source: 原来 它 是 海洋 洋中 最长 的 生物 <EOS> <PAD>\n",
      "Reference: this turns out to be the longest creature in\n",
      "Model: <SOS> this turns out to be the longest creature in\n",
      "Attention Weights: tensor([[5.1226e-02, 4.4088e-02, 6.1920e-02, 6.8185e-01, 1.5972e-01, 7.7013e-04,\n",
      "         2.0396e-04, 1.4762e-04, 7.6990e-05, 5.3193e-12],\n",
      "        [5.8243e-02, 4.3689e-02, 5.7964e-02, 6.5223e-01, 1.8687e-01, 6.5621e-04,\n",
      "         1.6865e-04, 1.1903e-04, 6.8433e-05, 1.0655e-11],\n",
      "        [7.0597e-02, 4.5684e-02, 5.9547e-02, 5.6972e-01, 2.5320e-01, 7.5105e-04,\n",
      "         2.0836e-04, 1.5548e-04, 1.4031e-04, 3.0464e-11],\n",
      "        [7.9480e-02, 5.2396e-02, 6.5290e-02, 5.0219e-01, 2.9915e-01, 7.9064e-04,\n",
      "         2.5233e-04, 2.1010e-04, 2.3953e-04, 1.3923e-10],\n",
      "        [6.9820e-02, 4.2196e-02, 5.0221e-02, 3.9352e-01, 4.4201e-01, 1.1054e-03,\n",
      "         3.6093e-04, 3.2410e-04, 4.3821e-04, 3.4049e-10],\n",
      "        [4.4371e-02, 2.5246e-02, 3.0143e-02, 2.7593e-01, 6.2037e-01, 1.8515e-03,\n",
      "         6.5222e-04, 5.8398e-04, 8.4817e-04, 9.5111e-10],\n",
      "        [2.5443e-02, 1.4576e-02, 1.7680e-02, 1.8083e-01, 7.5381e-01, 2.9131e-03,\n",
      "         1.2762e-03, 1.2750e-03, 2.1916e-03, 2.5802e-09],\n",
      "        [2.2350e-02, 1.3151e-02, 1.6431e-02, 1.6858e-01, 7.6829e-01, 3.6851e-03,\n",
      "         1.8391e-03, 1.9616e-03, 3.7100e-03, 3.7818e-09],\n",
      "        [2.3019e-02, 1.3852e-02, 1.7627e-02, 1.7563e-01, 7.5685e-01, 4.1342e-03,\n",
      "         2.1185e-03, 2.3267e-03, 4.4469e-03, 4.3502e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11 岁 那年 记得 得有 一天 早晨 醒来 听见\n",
      "Reference: when i was 11 , i remember waking up\n",
      "Model: <SOS> and of the the and and the are is\n",
      "Attention Weights: tensor([[6.0480e-01, 1.8796e-01, 6.0662e-02, 1.0555e-01, 4.0156e-02, 7.9696e-04,\n",
      "         6.6751e-05, 1.8519e-10, 1.8519e-10, 1.8519e-10],\n",
      "        [6.1839e-01, 1.7884e-01, 5.9617e-02, 9.8012e-02, 4.3799e-02, 1.2328e-03,\n",
      "         1.0882e-04, 6.3695e-10, 6.3695e-10, 6.3695e-10],\n",
      "        [6.0722e-01, 1.6760e-01, 6.0083e-02, 9.7703e-02, 5.9884e-02, 6.7330e-03,\n",
      "         7.8208e-04, 3.6692e-09, 3.6692e-09, 3.6692e-09],\n",
      "        [4.8000e-01, 1.7405e-01, 8.2017e-02, 1.2782e-01, 1.0434e-01, 2.7703e-02,\n",
      "         4.0744e-03, 2.1773e-08, 2.1773e-08, 2.1773e-08],\n",
      "        [3.9102e-01, 1.6316e-01, 9.3892e-02, 1.4525e-01, 1.3601e-01, 6.0251e-02,\n",
      "         1.0422e-02, 2.7865e-08, 2.7865e-08, 2.7865e-08],\n",
      "        [2.8510e-01, 1.4002e-01, 9.8347e-02, 1.5455e-01, 1.6679e-01, 1.2822e-01,\n",
      "         2.6976e-02, 4.3251e-08, 4.3251e-08, 4.3251e-08],\n",
      "        [2.2172e-01, 1.2170e-01, 9.4698e-02, 1.5104e-01, 1.7593e-01, 1.8956e-01,\n",
      "         4.5349e-02, 5.5601e-08, 5.5601e-08, 5.5601e-08],\n",
      "        [2.1866e-01, 1.1952e-01, 9.3460e-02, 1.5092e-01, 1.7675e-01, 1.9417e-01,\n",
      "         4.6519e-02, 5.3785e-08, 5.3785e-08, 5.3785e-08],\n",
      "        [2.1735e-01, 1.1893e-01, 9.3215e-02, 1.5062e-01, 1.7680e-01, 1.9579e-01,\n",
      "         4.7294e-02, 5.7936e-08, 5.7936e-08, 5.7936e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 197.00, Train Loss: 0.63, Val Loss: 13.10, Train BLEU: 90.89, Val BLEU: 0.54\n",
      "Sampling from training predictions...\n",
      "Source: 底下 这些 都 是 <UNK> 它们 上上 上上下下 上下 下下\n",
      "Reference: it &apos;s got these fishing <UNK> on the bottom\n",
      "Model: <SOS> it &apos;s got these fishing <UNK> on the bottom\n",
      "Attention Weights: tensor([[0.0326, 0.0291, 0.0243, 0.0208, 0.0144, 0.0989, 0.6702, 0.0977, 0.0108,\n",
      "         0.0013],\n",
      "        [0.0430, 0.0361, 0.0305, 0.0270, 0.0213, 0.1061, 0.6345, 0.0895, 0.0105,\n",
      "         0.0017],\n",
      "        [0.0525, 0.0397, 0.0337, 0.0317, 0.0366, 0.0985, 0.6177, 0.0753, 0.0110,\n",
      "         0.0033],\n",
      "        [0.0665, 0.0499, 0.0438, 0.0440, 0.0554, 0.1097, 0.5308, 0.0778, 0.0154,\n",
      "         0.0069],\n",
      "        [0.0698, 0.0482, 0.0428, 0.0443, 0.0773, 0.1092, 0.4978, 0.0781, 0.0193,\n",
      "         0.0133],\n",
      "        [0.0574, 0.0369, 0.0344, 0.0387, 0.1327, 0.0930, 0.4572, 0.0776, 0.0279,\n",
      "         0.0442],\n",
      "        [0.0449, 0.0272, 0.0264, 0.0328, 0.2095, 0.0686, 0.3851, 0.0651, 0.0314,\n",
      "         0.1090],\n",
      "        [0.0401, 0.0247, 0.0246, 0.0315, 0.2312, 0.0590, 0.3457, 0.0624, 0.0345,\n",
      "         0.1462],\n",
      "        [0.0420, 0.0266, 0.0269, 0.0343, 0.2329, 0.0604, 0.3312, 0.0636, 0.0371,\n",
      "         0.1451]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 出身 阿富汗 边远 <UNK> 地区 有着 与 他人 不同\n",
      "Reference: a total maverick from a remote province of afghanistan\n",
      "Model: <SOS> and vibrant the clips captured , , , the\n",
      "Attention Weights: tensor([[5.2280e-02, 4.6471e-02, 6.4319e-02, 6.8317e-01, 1.5261e-01, 7.5497e-04,\n",
      "         1.9287e-04, 1.3732e-04, 7.1090e-05, 4.6597e-12],\n",
      "        [5.9316e-02, 4.6111e-02, 6.0348e-02, 6.5399e-01, 1.7923e-01, 6.6061e-04,\n",
      "         1.6403e-04, 1.1383e-04, 6.4734e-05, 9.4741e-12],\n",
      "        [7.2869e-02, 4.9034e-02, 6.3064e-02, 5.7251e-01, 2.4124e-01, 7.8293e-04,\n",
      "         2.1147e-04, 1.5464e-04, 1.3573e-04, 2.7614e-11],\n",
      "        [8.3927e-02, 5.7918e-02, 7.1247e-02, 5.1200e-01, 2.7340e-01, 8.2252e-04,\n",
      "         2.5659e-04, 2.0799e-04, 2.2538e-04, 1.2386e-10],\n",
      "        [7.7196e-02, 4.8945e-02, 5.7409e-02, 4.1466e-01, 3.9959e-01, 1.1238e-03,\n",
      "         3.5856e-04, 3.1448e-04, 4.0194e-04, 2.9361e-10],\n",
      "        [5.1193e-02, 3.0209e-02, 3.5484e-02, 3.0121e-01, 5.7801e-01, 1.8945e-03,\n",
      "         6.4903e-04, 5.6778e-04, 7.8031e-04, 8.2687e-10],\n",
      "        [2.8690e-02, 1.6691e-02, 1.9949e-02, 1.9644e-01, 7.3076e-01, 2.9839e-03,\n",
      "         1.2558e-03, 1.2196e-03, 2.0121e-03, 2.2607e-09],\n",
      "        [2.3977e-02, 1.4201e-02, 1.7476e-02, 1.7723e-01, 7.5635e-01, 3.6894e-03,\n",
      "         1.7910e-03, 1.8675e-03, 3.4226e-03, 3.3553e-09],\n",
      "        [2.4008e-02, 1.4500e-02, 1.8238e-02, 1.8278e-01, 7.4788e-01, 4.1035e-03,\n",
      "         2.0679e-03, 2.2350e-03, 4.1897e-03, 4.0278e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 198.00, Train Loss: 0.62, Val Loss: 13.10, Train BLEU: 92.17, Val BLEU: 0.54\n",
      "Sampling from training predictions...\n",
      "Source: 还有 前面 的 这个 是 推进 引擎 它 一会 一会儿\n",
      "Reference: and it &apos;s got these jet thrusters up in\n",
      "Model: <SOS> and it &apos;s got these jet thrusters up in\n",
      "Attention Weights: tensor([[0.0317, 0.0358, 0.0450, 0.1404, 0.0636, 0.1572, 0.5022, 0.0145, 0.0093,\n",
      "         0.0003],\n",
      "        [0.0354, 0.0371, 0.0462, 0.1397, 0.0635, 0.1567, 0.4973, 0.0146, 0.0093,\n",
      "         0.0003],\n",
      "        [0.0437, 0.0421, 0.0507, 0.1440, 0.0667, 0.1591, 0.4675, 0.0145, 0.0111,\n",
      "         0.0006],\n",
      "        [0.0571, 0.0499, 0.0567, 0.1437, 0.0727, 0.1569, 0.4249, 0.0185, 0.0179,\n",
      "         0.0017],\n",
      "        [0.0709, 0.0588, 0.0644, 0.1417, 0.0793, 0.1527, 0.3724, 0.0251, 0.0304,\n",
      "         0.0043],\n",
      "        [0.0828, 0.0648, 0.0683, 0.1354, 0.0806, 0.1437, 0.3305, 0.0326, 0.0511,\n",
      "         0.0102],\n",
      "        [0.0749, 0.0534, 0.0559, 0.1050, 0.0652, 0.1108, 0.2800, 0.0441, 0.1595,\n",
      "         0.0511],\n",
      "        [0.0560, 0.0379, 0.0398, 0.0752, 0.0466, 0.0799, 0.2182, 0.0442, 0.2764,\n",
      "         0.1258],\n",
      "        [0.0483, 0.0323, 0.0342, 0.0660, 0.0403, 0.0703, 0.2016, 0.0420, 0.3125,\n",
      "         0.1526]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把 书 放在 食品 杂货 袋中 这样 别人 就\n",
      "Reference: we would cover our books in grocery bags so\n",
      "Model: <SOS> it &apos;s have &apos;re partnered , us yet there\n",
      "Attention Weights: tensor([[0.0107, 0.0321, 0.0796, 0.0349, 0.3153, 0.0298, 0.0219, 0.3690, 0.0185,\n",
      "         0.0882],\n",
      "        [0.0176, 0.0386, 0.0863, 0.0379, 0.3004, 0.0324, 0.0242, 0.3496, 0.0204,\n",
      "         0.0926],\n",
      "        [0.0334, 0.0523, 0.0957, 0.0436, 0.2664, 0.0373, 0.0287, 0.3046, 0.0261,\n",
      "         0.1118],\n",
      "        [0.0479, 0.0653, 0.1043, 0.0531, 0.2352, 0.0473, 0.0377, 0.2586, 0.0351,\n",
      "         0.1157],\n",
      "        [0.0567, 0.0688, 0.1016, 0.0542, 0.2097, 0.0494, 0.0402, 0.2399, 0.0403,\n",
      "         0.1392],\n",
      "        [0.0625, 0.0658, 0.0884, 0.0470, 0.1789, 0.0421, 0.0364, 0.2328, 0.0396,\n",
      "         0.2065],\n",
      "        [0.0651, 0.0675, 0.0869, 0.0485, 0.1688, 0.0439, 0.0388, 0.2220, 0.0427,\n",
      "         0.2158],\n",
      "        [0.0660, 0.0685, 0.0871, 0.0499, 0.1666, 0.0454, 0.0404, 0.2176, 0.0441,\n",
      "         0.2144],\n",
      "        [0.0654, 0.0691, 0.0873, 0.0506, 0.1651, 0.0464, 0.0415, 0.2145, 0.0454,\n",
      "         0.2147]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 199.00, Train Loss: 0.60, Val Loss: 13.09, Train BLEU: 91.32, Val BLEU: 0.54\n",
      "Sampling from training predictions...\n",
      "Source: 当 你 站 在 海滩 上 或是 当 你 看到\n",
      "Reference: part of the problem , i think , is\n",
      "Model: <SOS> part of the problem , i , , is\n",
      "Attention Weights: tensor([[0.0145, 0.0121, 0.0186, 0.0294, 0.4798, 0.0497, 0.2705, 0.0283, 0.0143,\n",
      "         0.0829],\n",
      "        [0.0174, 0.0134, 0.0202, 0.0311, 0.4804, 0.0510, 0.2669, 0.0286, 0.0143,\n",
      "         0.0769],\n",
      "        [0.0312, 0.0205, 0.0277, 0.0390, 0.4183, 0.0589, 0.2483, 0.0358, 0.0201,\n",
      "         0.1001],\n",
      "        [0.0513, 0.0338, 0.0414, 0.0530, 0.3378, 0.0740, 0.2210, 0.0495, 0.0310,\n",
      "         0.1071],\n",
      "        [0.0622, 0.0415, 0.0488, 0.0597, 0.2943, 0.0797, 0.2027, 0.0568, 0.0382,\n",
      "         0.1161],\n",
      "        [0.0639, 0.0402, 0.0465, 0.0565, 0.2760, 0.0731, 0.1903, 0.0549, 0.0405,\n",
      "         0.1579],\n",
      "        [0.0618, 0.0377, 0.0430, 0.0520, 0.2609, 0.0654, 0.1775, 0.0515, 0.0411,\n",
      "         0.2091],\n",
      "        [0.0584, 0.0357, 0.0412, 0.0500, 0.2613, 0.0624, 0.1758, 0.0496, 0.0404,\n",
      "         0.2252],\n",
      "        [0.0571, 0.0357, 0.0415, 0.0502, 0.2568, 0.0622, 0.1732, 0.0499, 0.0414,\n",
      "         0.2319]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11 岁 那年 记得 得有 一天 早晨 醒来 听见\n",
      "Reference: when i was 11 , i remember waking up\n",
      "Model: <SOS> and of the the and and are are is\n",
      "Attention Weights: tensor([[6.0612e-01, 1.7954e-01, 5.8222e-02, 1.1283e-01, 4.2479e-02, 7.3987e-04,\n",
      "         6.3914e-05, 1.7321e-10, 1.7321e-10, 1.7321e-10],\n",
      "        [6.1811e-01, 1.7168e-01, 5.7336e-02, 1.0516e-01, 4.6490e-02, 1.1232e-03,\n",
      "         1.0078e-04, 5.9365e-10, 5.9365e-10, 5.9365e-10],\n",
      "        [6.0699e-01, 1.6208e-01, 5.7843e-02, 1.0368e-01, 6.2736e-02, 5.9774e-03,\n",
      "         6.9783e-04, 3.3269e-09, 3.3269e-09, 3.3269e-09],\n",
      "        [4.7800e-01, 1.7161e-01, 8.0111e-02, 1.3461e-01, 1.0811e-01, 2.4001e-02,\n",
      "         3.5557e-03, 1.8472e-08, 1.8472e-08, 1.8472e-08],\n",
      "        [3.9033e-01, 1.6278e-01, 9.3047e-02, 1.5267e-01, 1.4037e-01, 5.1749e-02,\n",
      "         9.0450e-03, 2.2443e-08, 2.2443e-08, 2.2443e-08],\n",
      "        [2.7843e-01, 1.3819e-01, 9.7669e-02, 1.6329e-01, 1.7659e-01, 1.2044e-01,\n",
      "         2.5388e-02, 3.5815e-08, 3.5815e-08, 3.5815e-08],\n",
      "        [2.1356e-01, 1.1870e-01, 9.3267e-02, 1.5865e-01, 1.8747e-01, 1.8453e-01,\n",
      "         4.3815e-02, 4.6724e-08, 4.6724e-08, 4.6724e-08],\n",
      "        [2.1100e-01, 1.1669e-01, 9.2086e-02, 1.5862e-01, 1.8838e-01, 1.8839e-01,\n",
      "         4.4837e-02, 4.4975e-08, 4.4975e-08, 4.4975e-08],\n",
      "        [2.0981e-01, 1.1619e-01, 9.1884e-02, 1.5816e-01, 1.8825e-01, 1.8999e-01,\n",
      "         4.5719e-02, 4.9279e-08, 4.9279e-08, 4.9279e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Experiment completed in 11 minutes with 8.64 best validation loss and 1.04 best validation BLEU.\n"
     ]
    }
   ],
   "source": [
    "model, results = train_and_eval_attn(\n",
    "    model=model, loaders_full=loaders_full, loaders_minibatch=loaders_minibatch, loaders_minitrain=loaders_minitrain, \n",
    "    params=params, vocab=vocab, print_intermediate=True, save_checkpoint=True, save_to_log=True, \n",
    "    lazy_eval=False, inspect_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt_created</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>clip_grad_max_norm</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2018-12-05 00:36:58</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.638907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2018-12-04 23:22:47</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.612291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2018-12-04 22:33:11</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.682158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2018-12-04 21:59:40</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.846257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2018-12-04 16:52:40</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.736520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             dt_created  num_epochs  learning_rate  clip_grad_max_norm  \\\n",
       "72  2018-12-05 00:36:58         200         0.0005                 1.0   \n",
       "71  2018-12-04 23:22:47         200         0.0005                 1.0   \n",
       "70  2018-12-04 22:33:11         200         0.0005                 1.0   \n",
       "69  2018-12-04 21:59:40         200         0.0005                 1.0   \n",
       "68  2018-12-04 16:52:40         500         0.0005                 1.0   \n",
       "\n",
       "    val_loss  \n",
       "72  8.638907  \n",
       "71  8.612291  \n",
       "70  8.682158  \n",
       "69  8.846257  \n",
       "68  8.736520  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_results(load_experiment_log())[['dt_created', 'num_epochs', 'learning_rate', 'clip_grad_max_norm', 'val_loss']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_single_learning_curve(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch: 199.00, Train Loss: 0.32, Val Loss: 13.19, Train BLEU: 98.94, Val BLEU: 0.27\n",
    "plot_single_learning_curve(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with attention energies = v_broadcast.bmm(torch.tanh(self.attn(concat)).transpose(1, 2)) # switched order  \n",
    "# Epoch: 199.00, Train Loss: 0.63, Val Loss: 12.82, Train BLEU: 92.05, Val BLEU: 0.38\n",
    "plot_single_learning_curve(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, token in enumerate(vocab[SRC_LANG]['id2token']): \n",
    "    if i < 20: \n",
    "        print(\"{}: {}\".format(i, token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, token in enumerate(vocab[TARG_LANG]['id2token']): \n",
    "    if i < 20: \n",
    "        print(\"{}: {}\".format(i, token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.arange(0, 3*5*10).view(3, 5, 10)\n",
    "print(x)\n",
    "y = x[1:, :, :]\n",
    "print(y)\n",
    "z = y.view(-1, 10)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.arange(0, 2*5).view(5, 2)\n",
    "print(t)\n",
    "u = t.contiguous().view(-1)\n",
    "print(u)\n",
    "v = t.permute(1, 0)\n",
    "print(v)\n",
    "w = v.contiguous().view(-1)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(0, 2*1*300)\n",
    "print(a)\n",
    "b = a.view(-1, 1, 300)\n",
    "print(b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (src_idxs, targ_idxs, src_lens, targ_lens) in enumerate(full_loaders['train']):\n",
    "#     print(i)\n",
    "#     print(src_idxs.size())\n",
    "#     print(src_idxs)\n",
    "#     print(src_lens)\n",
    "#     print(targ_idxs.size())\n",
    "#     print(targ_idxs)\n",
    "#     print(targ_lens)\n",
    "    id2token = vocab[SRC_LANG]['id2token']\n",
    "    test_tensor = src_idxs\n",
    "    list_of_lists = test_tensor.numpy().astype(int).tolist()\n",
    "    to_token = lambda l: ' '.join([id2token[idx] for idx in l])\n",
    "    list_of_lists_tokens = [to_token(l) for l in list_of_lists] \n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
