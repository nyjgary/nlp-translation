{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from data_processing import generate_vocab, process_data, create_dataloaders\n",
    "from model import get_pretrained_emb, EncoderRNN, DecoderRNN, DecoderAttnRNN, EncoderDecoder, EncoderDecoderAttn\n",
    "from train_eval import train_and_eval, count_parameters, summarize_results, plot_single_learning_curve, load_experiment_log\n",
    "import pickle as pkl \n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model identification\n",
    "SRC_LANG = 'zh'\n",
    "TARG_LANG = 'en'\n",
    "\n",
    "# data processing params  \n",
    "SRC_MAX_SENTENCE_LEN = 10\n",
    "TARG_MAX_SENTENCE_LEN = 10\n",
    "SRC_VOCAB_SIZE = 30000 \n",
    "TARG_VOCAB_SIZE = 30000 \n",
    "\n",
    "# model architecture params \n",
    "NETWORK_TYPE = 'rnn'\n",
    "RNN_CELL_TYPE = 'gru'\n",
    "NUM_LAYERS = 2 \n",
    "ENC_HIDDEN_DIM = 512\n",
    "DEC_HIDDEN_DIM = 2 * ENC_HIDDEN_DIM \n",
    "TEACHER_FORCING_RATIO = 1\n",
    "CLIP_GRAD_MAX_NORM = 1\n",
    "ENC_DROPOUT = 0.2 \n",
    "DEC_DROPOUT = 0.2 \n",
    "ATTENTION_TYPE = 'additive'\n",
    "\n",
    "# training params  \n",
    "BATCH_SIZE = 64 #32\n",
    "NUM_EPOCHS = 20\n",
    "LR = 0.0003 # 0.0005\n",
    "OPTIMIZER = 'Adam'\n",
    "LAZY_TRAIN = True\n",
    "\n",
    "# name the model \n",
    "if NETWORK_TYPE == 'rnn': \n",
    "    MODEL_NAME = '{}-rnn-{}-attn'.format(SRC_LANG, ATTENTION_TYPE)\n",
    "elif NETWORK_TYPE == 'cnn': \n",
    "    MODEL_NAME = '{}-cnn'.format(SRC_LANG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store as dict to save to results later \n",
    "params = {'model_name': MODEL_NAME, 'src_lang': SRC_LANG, 'targ_lang': TARG_LANG, 'rnn_cell_type': RNN_CELL_TYPE, \n",
    "          'src_max_sentence_len': SRC_MAX_SENTENCE_LEN, 'targ_max_sentence_len': TARG_MAX_SENTENCE_LEN, \n",
    "          'src_vocab_size': SRC_VOCAB_SIZE, 'targ_vocab_size': TARG_VOCAB_SIZE, \n",
    "          'num_layers': NUM_LAYERS, 'enc_hidden_dim': ENC_HIDDEN_DIM, 'dec_hidden_dim': DEC_HIDDEN_DIM,\n",
    "          'teacher_forcing_ratio': TEACHER_FORCING_RATIO, 'clip_grad_max_norm': CLIP_GRAD_MAX_NORM,\n",
    "          'enc_dropout': ENC_DROPOUT, 'dec_dropout': DEC_DROPOUT, 'attention_type': ATTENTION_TYPE, \n",
    "          'batch_size': BATCH_SIZE, 'num_epochs': NUM_EPOCHS, 'learning_rate': LR, 'optimizer': OPTIMIZER, \n",
    "          'lazy_train': LAZY_TRAIN} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a long time to process, save to pickle for reimport in future \n",
    "# vocab = generate_vocab(SRC_LANG, TARG_LANG, SRC_VOCAB_SIZE, TARG_VOCAB_SIZE)\n",
    "# vocab_filename = \"{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n",
    "# pkl.dump(vocab, open(vocab_filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload from pickle \n",
    "vocab_filename = \"{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n",
    "vocab = pkl.load(open(vocab_filename, \"rb\"))\n",
    "data = process_data(SRC_LANG, TARG_LANG, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, vocab, filter_long=False)\n",
    "data_minibatch = process_data(SRC_LANG, TARG_LANG, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, vocab, sample_limit=BATCH_SIZE, filter_long=False) \n",
    "data_minitrain = process_data(SRC_LANG, TARG_LANG, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, vocab, sample_limit=1000, filter_long=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders \n",
    "loaders_full = create_dataloaders(data, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)\n",
    "loaders_minibatch = create_dataloaders(data_minibatch, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)\n",
    "loaders_minitrain = create_dataloaders(data_minitrain, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model \n",
    "\n",
    "encoder = EncoderRNN(rnn_cell_type=RNN_CELL_TYPE, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, \n",
    "                     src_max_sentence_len=SRC_MAX_SENTENCE_LEN, enc_dropout=ENC_DROPOUT, \n",
    "                     pretrained_word2vec=get_pretrained_emb(vocab[SRC_LANG]['word2vec'], vocab[SRC_LANG]['token2id']))\n",
    "\n",
    "if ATTENTION_TYPE == 'without': \n",
    "    # without attention \n",
    "    decoder = DecoderRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS,\n",
    "                         targ_vocab_size=TARG_VOCAB_SIZE, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "                         pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], \n",
    "                                                                vocab[TARG_LANG]['token2id']))\n",
    "    model = EncoderDecoder(encoder, decoder, vocab[TARG_LANG]['token2id']).to(device)\n",
    "    \n",
    "else: \n",
    "    # with attention \n",
    "    decoder = DecoderAttnRNN(rnn_cell_type=RNN_CELL_TYPE, dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, \n",
    "                             num_layers=NUM_LAYERS, targ_vocab_size=TARG_VOCAB_SIZE, \n",
    "                             src_max_sentence_len=SRC_MAX_SENTENCE_LEN, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "                             dec_dropout=DEC_DROPOUT, attention_type=ATTENTION_TYPE,\n",
    "                             pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], \n",
    "                                                                    vocab[TARG_LANG]['token2id']))\n",
    "    model = EncoderDecoderAttn(encoder, decoder, vocab[TARG_LANG]['token2id']).to(device) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.00, Train Loss: 9.98, Val Loss: 10.14, Train BLEU: 0.29, Val BLEU: 0.21, Minutes Elapsed: 0.16\n",
      "Sampling from training predictions...\n",
      "Source: 我们 将 用 一些 影片 来讲 讲述 一些 深海 海里\n",
      "Reference: and we &apos;re going to tell you some stories\n",
      "Model: <SOS> we the the the the the the the the\n",
      "Attention Weights: tensor([[0.1011, 0.1037, 0.1024, 0.1004, 0.1010, 0.1010, 0.1007, 0.0996, 0.0972,\n",
      "         0.0929],\n",
      "        [0.1014, 0.1039, 0.1025, 0.1005, 0.1010, 0.1010, 0.1007, 0.0994, 0.0970,\n",
      "         0.0926],\n",
      "        [0.1015, 0.1041, 0.1026, 0.1005, 0.1011, 0.1010, 0.1007, 0.0993, 0.0968,\n",
      "         0.0924],\n",
      "        [0.1015, 0.1042, 0.1027, 0.1005, 0.1011, 0.1010, 0.1006, 0.0993, 0.0968,\n",
      "         0.0924],\n",
      "        [0.1015, 0.1042, 0.1027, 0.1005, 0.1011, 0.1010, 0.1006, 0.0993, 0.0968,\n",
      "         0.0923],\n",
      "        [0.1015, 0.1042, 0.1027, 0.1006, 0.1011, 0.1010, 0.1007, 0.0993, 0.0967,\n",
      "         0.0923],\n",
      "        [0.1015, 0.1042, 0.1027, 0.1006, 0.1011, 0.1010, 0.1007, 0.0993, 0.0967,\n",
      "         0.0923],\n",
      "        [0.1015, 0.1042, 0.1027, 0.1006, 0.1011, 0.1010, 0.1007, 0.0993, 0.0968,\n",
      "         0.0923],\n",
      "        [0.1015, 0.1042, 0.1027, 0.1006, 0.1011, 0.1010, 0.1007, 0.0993, 0.0968,\n",
      "         0.0923]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 梦想 很大 但 他们 对 我 的 期待\n",
      "Reference: i dream big , but my family dreams even\n",
      "Model: <SOS> we the the the the the the the the\n",
      "Attention Weights: tensor([[0.1027, 0.1016, 0.0997, 0.0998, 0.1019, 0.1010, 0.1025, 0.1014, 0.0976,\n",
      "         0.0917],\n",
      "        [0.1030, 0.1018, 0.0999, 0.1000, 0.1020, 0.1011, 0.1024, 0.1012, 0.0973,\n",
      "         0.0913],\n",
      "        [0.1031, 0.1019, 0.1000, 0.1000, 0.1020, 0.1011, 0.1024, 0.1012, 0.0972,\n",
      "         0.0911],\n",
      "        [0.1032, 0.1020, 0.1000, 0.1000, 0.1021, 0.1011, 0.1024, 0.1011, 0.0971,\n",
      "         0.0910],\n",
      "        [0.1032, 0.1020, 0.1000, 0.1001, 0.1021, 0.1011, 0.1024, 0.1011, 0.0971,\n",
      "         0.0910],\n",
      "        [0.1032, 0.1020, 0.1000, 0.1001, 0.1021, 0.1011, 0.1024, 0.1011, 0.0971,\n",
      "         0.0910],\n",
      "        [0.1032, 0.1020, 0.1000, 0.1001, 0.1021, 0.1011, 0.1024, 0.1011, 0.0971,\n",
      "         0.0910],\n",
      "        [0.1032, 0.1020, 0.1000, 0.1001, 0.1021, 0.1011, 0.1024, 0.1011, 0.0971,\n",
      "         0.0910],\n",
      "        [0.1031, 0.1020, 0.1000, 0.1001, 0.1021, 0.1011, 0.1024, 0.1011, 0.0971,\n",
      "         0.0910]])\n",
      "\n",
      "Epoch: 1.00, Train Loss: 9.50, Val Loss: 9.88, Train BLEU: 0.29, Val BLEU: 0.22, Minutes Elapsed: 0.33\n",
      "Sampling from training predictions...\n",
      "Source: 你 一定 听说 过 巨型 章鱼 之类 的 东西 但\n",
      "Reference: you hear about giant squid and things like that\n",
      "Model: <SOS> we the the the the the the the the\n",
      "Attention Weights: tensor([[0.0611, 0.0820, 0.1005, 0.1183, 0.1183, 0.1200, 0.1191, 0.1177, 0.0935,\n",
      "         0.0695],\n",
      "        [0.0610, 0.0821, 0.1007, 0.1187, 0.1186, 0.1202, 0.1192, 0.1176, 0.0931,\n",
      "         0.0688],\n",
      "        [0.0611, 0.0822, 0.1008, 0.1188, 0.1187, 0.1202, 0.1192, 0.1175, 0.0929,\n",
      "         0.0686],\n",
      "        [0.0612, 0.0824, 0.1009, 0.1189, 0.1187, 0.1202, 0.1191, 0.1174, 0.0927,\n",
      "         0.0684],\n",
      "        [0.0613, 0.0824, 0.1010, 0.1190, 0.1187, 0.1202, 0.1191, 0.1173, 0.0926,\n",
      "         0.0684],\n",
      "        [0.0614, 0.0825, 0.1010, 0.1190, 0.1187, 0.1201, 0.1190, 0.1173, 0.0926,\n",
      "         0.0684],\n",
      "        [0.0614, 0.0825, 0.1011, 0.1190, 0.1187, 0.1201, 0.1190, 0.1173, 0.0926,\n",
      "         0.0684],\n",
      "        [0.0614, 0.0826, 0.1011, 0.1190, 0.1187, 0.1201, 0.1190, 0.1172, 0.0926,\n",
      "         0.0683],\n",
      "        [0.0614, 0.0826, 0.1011, 0.1190, 0.1187, 0.1201, 0.1190, 0.1172, 0.0926,\n",
      "         0.0683]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 但是 当 我 回到 阿富汗 看见 我 的 学生 以及\n",
      "Reference: but when i am back in afghanistan , when\n",
      "Model: <SOS> we the the the the the the the the\n",
      "Attention Weights: tensor([[0.0570, 0.0900, 0.1096, 0.1105, 0.1100, 0.1212, 0.1310, 0.1197, 0.0905,\n",
      "         0.0604],\n",
      "        [0.0569, 0.0902, 0.1099, 0.1107, 0.1101, 0.1215, 0.1312, 0.1196, 0.0900,\n",
      "         0.0598],\n",
      "        [0.0570, 0.0905, 0.1101, 0.1108, 0.1102, 0.1215, 0.1312, 0.1194, 0.0898,\n",
      "         0.0595],\n",
      "        [0.0571, 0.0906, 0.1103, 0.1108, 0.1102, 0.1215, 0.1312, 0.1193, 0.0896,\n",
      "         0.0594],\n",
      "        [0.0572, 0.0907, 0.1103, 0.1109, 0.1102, 0.1215, 0.1311, 0.1192, 0.0895,\n",
      "         0.0593],\n",
      "        [0.0572, 0.0908, 0.1104, 0.1109, 0.1102, 0.1214, 0.1311, 0.1192, 0.0895,\n",
      "         0.0593],\n",
      "        [0.0573, 0.0908, 0.1104, 0.1109, 0.1102, 0.1214, 0.1311, 0.1192, 0.0895,\n",
      "         0.0593],\n",
      "        [0.0573, 0.0908, 0.1104, 0.1109, 0.1102, 0.1214, 0.1310, 0.1192, 0.0895,\n",
      "         0.0593],\n",
      "        [0.0573, 0.0909, 0.1104, 0.1109, 0.1102, 0.1214, 0.1310, 0.1192, 0.0895,\n",
      "         0.0593]])\n",
      "\n",
      "Epoch: 2.00, Train Loss: 8.82, Val Loss: 9.51, Train BLEU: 0.29, Val BLEU: 0.22, Minutes Elapsed: 0.49\n",
      "Sampling from training predictions...\n",
      "Source: 它们 还 没有 被 研究 透 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: they &apos;re very little understood . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> we the the the the the the the the\n",
      "Attention Weights: tensor([[0.0608, 0.1715, 0.2356, 0.2707, 0.1744, 0.0811, 0.0060, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0595, 0.1716, 0.2372, 0.2729, 0.1738, 0.0794, 0.0056, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0594, 0.1719, 0.2376, 0.2733, 0.1734, 0.0789, 0.0056, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0595, 0.1721, 0.2377, 0.2733, 0.1732, 0.0787, 0.0056, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0596, 0.1722, 0.2377, 0.2731, 0.1731, 0.0787, 0.0056, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0597, 0.1723, 0.2376, 0.2730, 0.1731, 0.0787, 0.0056, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0598, 0.1724, 0.2376, 0.2728, 0.1730, 0.0788, 0.0056, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0599, 0.1724, 0.2376, 0.2727, 0.1730, 0.0788, 0.0056, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0599, 0.1724, 0.2375, 0.2727, 0.1730, 0.0788, 0.0056, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 想 过 要 放弃 但 我 的 父亲 这时\n",
      "Reference: i would want to quit , but my father\n",
      "Model: <SOS> we the the the the the the the the\n",
      "Attention Weights: tensor([[0.0254, 0.0673, 0.1100, 0.1404, 0.1439, 0.1612, 0.1510, 0.1158, 0.0614,\n",
      "         0.0236],\n",
      "        [0.0246, 0.0667, 0.1101, 0.1413, 0.1448, 0.1625, 0.1518, 0.1155, 0.0602,\n",
      "         0.0226],\n",
      "        [0.0245, 0.0667, 0.1103, 0.1416, 0.1450, 0.1627, 0.1518, 0.1152, 0.0597,\n",
      "         0.0223],\n",
      "        [0.0246, 0.0669, 0.1105, 0.1417, 0.1451, 0.1627, 0.1517, 0.1150, 0.0596,\n",
      "         0.0222],\n",
      "        [0.0247, 0.0671, 0.1106, 0.1418, 0.1451, 0.1626, 0.1515, 0.1148, 0.0595,\n",
      "         0.0222],\n",
      "        [0.0248, 0.0672, 0.1107, 0.1418, 0.1450, 0.1625, 0.1514, 0.1148, 0.0595,\n",
      "         0.0223],\n",
      "        [0.0249, 0.0673, 0.1108, 0.1417, 0.1450, 0.1625, 0.1513, 0.1147, 0.0595,\n",
      "         0.0223],\n",
      "        [0.0249, 0.0673, 0.1108, 0.1417, 0.1450, 0.1624, 0.1513, 0.1147, 0.0596,\n",
      "         0.0223],\n",
      "        [0.0250, 0.0674, 0.1108, 0.1417, 0.1450, 0.1624, 0.1513, 0.1147, 0.0596,\n",
      "         0.0223]])\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d9727ebceea0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders_full\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloaders_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders_minibatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloaders_minibatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders_minitrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloaders_minitrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_intermediate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_to_log\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     lazy_eval=False, print_attn=True, inspect_samples=1)\n\u001b[0m",
      "\u001b[0;32m~/Documents/data-science-coursework/nyu-nlp/project/train_eval.py\u001b[0m in \u001b[0;36mtrain_and_eval\u001b[0;34m(model, loaders_full, loaders_minibatch, loaders_minitrain, params, vocab, lazy_eval, print_intermediate, save_checkpoint, save_to_log, inspect_samples, print_attn)\u001b[0m\n\u001b[1;32m    243\u001b[0m                         \u001b[0mcheckpoint_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'model_checkpoints/{}.pth.tar'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                         \u001b[0mcheck_dir_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/nlpclass/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \"\"\"\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/nlpclass/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/nlpclass/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \"\"\"\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/nlpclass/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mserialized_storage_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mserialized_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_should_read_directly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, results = train_and_eval(\n",
    "    model=model, loaders_full=loaders_full, loaders_minibatch=loaders_minibatch, loaders_minitrain=loaders_minitrain, \n",
    "    params=params, vocab=vocab, print_intermediate=100, save_checkpoint=True, save_to_log=True, \n",
    "    lazy_eval=False, print_attn=True, inspect_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_learning_curve(load_experiment_log(experiment_name=MODEL_NAME)[0]['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_results(load_experiment_log(experiment_name=MODEL_NAME))[[\n",
    "    'model_name', 'best_val_loss', 'best_val_bleu', 'runtime', 'dt_created', \n",
    "    'num_layers', 'enc_hidden_dim', 'dec_hidden_dim']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload model and test \n",
    "encoder = EncoderRNN(rnn_cell_type=RNN_CELL_TYPE, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, \n",
    "                     src_max_sentence_len=SRC_MAX_SENTENCE_LEN, enc_dropout=ENC_DROPOUT, \n",
    "                     pretrained_word2vec=get_pretrained_emb(vocab[SRC_LANG]['word2vec'], vocab[SRC_LANG]['token2id']))\n",
    "\n",
    "# # without attention \n",
    "# decoder = DecoderRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS,\n",
    "#                      targ_vocab_size=TARG_VOCAB_SIZE, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "#                      pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "# model = EncoderDecoder(encoder, decoder, vocab[TARG_LANG]['token2id']).to(device)\n",
    "\n",
    "# with additive attention \n",
    "decoder = DecoderAttnRNN(rnn_cell_type=RNN_CELL_TYPE, dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, \n",
    "                         num_layers=NUM_LAYERS, targ_vocab_size=TARG_VOCAB_SIZE, src_max_sentence_len=SRC_MAX_SENTENCE_LEN, \n",
    "                         targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, dec_dropout=DEC_DROPOUT, attention_type=ATTENTION_TYPE,\n",
    "                         pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "model = EncoderDecoderAttn(encoder, decoder, vocab[TARG_LANG]['token2id'])\n",
    "\n",
    "# # with multiplicative attention \n",
    "# decoder = DecoderAttnRNN(rnn_cell_type=RNN_CELL_TYPE, dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, \n",
    "#                          num_layers=NUM_LAYERS, targ_vocab_size=TARG_VOCAB_SIZE, src_max_sentence_len=SRC_MAX_SENTENCE_LEN, \n",
    "#                          targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, dec_dropout=DEC_DROPOUT, attention_type=ATTENTION_TYPE,\n",
    "#                          pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "# model = EncoderDecoderAttn(encoder, decoder, vocab[TARG_LANG]['token2id']).to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('model_checkpoints/{}.pth.tar'.format(MODEL_NAME), map_location=device)\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
