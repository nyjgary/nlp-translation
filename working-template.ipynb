{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from data_processing import generate_vocab, process_data, create_dataloaders \n",
    "from model import get_pretrained_emb, EncoderDecoder, EncoderRNN, DecoderRNN, DecoderSimpleRNN, EncoderSimpleRNN, \\\n",
    "    Attention, DecoderAttnRNN, DecoderRNNV2, EncoderDecoderAttention\n",
    "from train_eval import count_parameters, summarize_results, \\\n",
    "    plot_single_learning_curve, load_experiment_log\n",
    "from train_eval import train_and_eval, train_and_eval_attn \n",
    "import importlib\n",
    "import pickle as pkl \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model identification\n",
    "MODEL_NAME = 'zh-seq2seq-rnn-attention'\n",
    "SRC_LANG = 'zh'\n",
    "TARG_LANG = 'en'\n",
    "\n",
    "# data processing params  \n",
    "SRC_MAX_SENTENCE_LEN = 10\n",
    "TARG_MAX_SENTENCE_LEN = 10\n",
    "SRC_VOCAB_SIZE = 30000 #30000\n",
    "TARG_VOCAB_SIZE = 30000 #30000\n",
    "\n",
    "# model architecture params \n",
    "NUM_LAYERS = 2 #2 \n",
    "ENC_HIDDEN_DIM = 300 \n",
    "DEC_HIDDEN_DIM = ENC_HIDDEN_DIM #2 * ENC_HIDDEN_DIM \n",
    "TEACHER_FORCING_RATIO = 1\n",
    "CLIP_GRAD_MAX_NORM = 1\n",
    "ENC_DROPOUT = 0 # to actually implement\n",
    "DEC_DROPOUT = 0 # to actually implement\n",
    "\n",
    "# training params  \n",
    "BATCH_SIZE = 32 #32\n",
    "NUM_EPOCHS = 200\n",
    "LR = 0.0005 # 0.0005\n",
    "OPTIMIZER = 'Adam'\n",
    "LAZY_TRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store as dict to save to results later \n",
    "params = {'model_name': MODEL_NAME, 'src_lang': SRC_LANG, 'targ_lang': TARG_LANG, \n",
    "          'src_max_sentence_len': SRC_MAX_SENTENCE_LEN, 'targ_max_sentence_len': TARG_MAX_SENTENCE_LEN, \n",
    "          'src_vocab_size': SRC_VOCAB_SIZE, 'targ_vocab_size': TARG_VOCAB_SIZE, \n",
    "          'num_layers': NUM_LAYERS, 'enc_hidden_dim': ENC_HIDDEN_DIM, 'dec_hidden_dim': DEC_HIDDEN_DIM,\n",
    "          'teacher_forcing_ratio': TEACHER_FORCING_RATIO, 'clip_grad_max_norm': CLIP_GRAD_MAX_NORM,\n",
    "          'enc_dropout': ENC_DROPOUT, 'dec_dropout': DEC_DROPOUT, \n",
    "          'batch_size': BATCH_SIZE, 'num_epochs': NUM_EPOCHS, 'learning_rate': LR, 'optimizer': OPTIMIZER, \n",
    "          'lazy_train': LAZY_TRAIN} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab_test = generate_vocab(SRC_LANG, TARG_LANG, SRC_VOCAB_SIZE, TARG_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab['zh']['id2token'][987]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab['zh']['token2id']['森林']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab['en']['token2id']['activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab['en']['id2token'][987]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # takes a long time to process, save to pickle for reimport in future \n",
    "# vocab = generate_vocab(SRC_LANG, TARG_LANG, SRC_VOCAB_SIZE, TARG_VOCAB_SIZE)\n",
    "# vocab_filename = \"{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n",
    "# pkl.dump(vocab, open(vocab_filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload from pickle \n",
    "vocab_filename = \"{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n",
    "vocab = pkl.load(open(vocab_filename, \"rb\"))\n",
    "data = process_data(SRC_LANG, TARG_LANG, vocab)\n",
    "data_minibatch = process_data(SRC_LANG, TARG_LANG, vocab, sample_limit=BATCH_SIZE) \n",
    "data_minitrain = process_data(SRC_LANG, TARG_LANG, vocab, sample_limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # takes a long time to process, save to pickle for reimport in future \n",
    "# vocab = generate_vocab(SRC_LANG, TARG_LANG, SRC_VOCAB_SIZE, TARG_VOCAB_SIZE)\n",
    "# vocab_filename = \"{}-{}-vocab-fake.p\".format(SRC_LANG, TARG_LANG)\n",
    "# pkl.dump(vocab, open(vocab_filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_filename = \"{}-{}-vocab-fake.p\".format(SRC_LANG, TARG_LANG)\n",
    "# vocab = pkl.load(open(vocab_filename, \"rb\"))\n",
    "# data = process_data(SRC_LANG, TARG_LANG, vocab)\n",
    "# limited_data = process_data(SRC_LANG, TARG_LANG, vocab, sample_limit=BATCH_SIZE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders \n",
    "loaders_full = create_dataloaders(data, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)\n",
    "loaders_minibatch = create_dataloaders(data_minibatch, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)\n",
    "loaders_minitrain = create_dataloaders(data_minitrain, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model \n",
    "\n",
    "# encoder = EncoderRNN(enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, src_max_sentence_len=SRC_MAX_SENTENCE_LEN,\n",
    "#                      pretrained_word2vec=get_pretrained_emb(vocab[SRC_LANG]['word2vec'], vocab[SRC_LANG]['token2id']))\n",
    "encoder = EncoderSimpleRNN(enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, src_max_sentence_len=SRC_MAX_SENTENCE_LEN,\n",
    "                           pretrained_word2vec=get_pretrained_emb(vocab[SRC_LANG]['word2vec'], vocab[SRC_LANG]['token2id']))\n",
    "\n",
    "# decoder = DecoderRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS,\n",
    "#                       targ_vocab_size=TARG_VOCAB_SIZE, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "#                       pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "\n",
    "# decoder = DecoderRNNV2(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, \n",
    "#                        targ_vocab_size=TARG_VOCAB_SIZE, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "#                        pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "# decoder = DecoderSimpleRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, \n",
    "#                            targ_vocab_size=TARG_VOCAB_SIZE, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "#                            pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "decoder = DecoderAttnRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, \n",
    "                         targ_vocab_size=TARG_VOCAB_SIZE, src_max_sentence_len=SRC_MAX_SENTENCE_LEN, \n",
    "                         targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "                         pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "\n",
    "model = EncoderDecoderAttention(encoder, decoder, vocab[TARG_LANG]['token2id']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.00, Train Loss: 10.13, Val Loss: 10.23, Train BLEU: 0.32, Val BLEU: 0.18\n",
      "Sampling from training predictions...\n",
      "Source: 但 我 想 告诉 你 的 是 当 你 站\n",
      "Reference: but when you &apos;re standing at the beach ,\n",
      "Model: <SOS> numbered the the the the the the the the\n",
      "Attention Weights: tensor([[0.0859, 0.0922, 0.0969, 0.0986, 0.1013, 0.1034, 0.1047, 0.1058, 0.1066,\n",
      "         0.1046],\n",
      "        [0.0855, 0.0921, 0.0969, 0.0986, 0.1014, 0.1035, 0.1048, 0.1059, 0.1067,\n",
      "         0.1045],\n",
      "        [0.0855, 0.0921, 0.0969, 0.0987, 0.1014, 0.1036, 0.1048, 0.1059, 0.1067,\n",
      "         0.1045],\n",
      "        [0.0854, 0.0920, 0.0969, 0.0987, 0.1014, 0.1036, 0.1048, 0.1059, 0.1068,\n",
      "         0.1046],\n",
      "        [0.0853, 0.0920, 0.0969, 0.0986, 0.1014, 0.1036, 0.1048, 0.1059, 0.1068,\n",
      "         0.1046],\n",
      "        [0.0853, 0.0920, 0.0969, 0.0986, 0.1014, 0.1036, 0.1049, 0.1060, 0.1068,\n",
      "         0.1046],\n",
      "        [0.0853, 0.0920, 0.0969, 0.0986, 0.1014, 0.1036, 0.1049, 0.1060, 0.1068,\n",
      "         0.1046],\n",
      "        [0.0853, 0.0920, 0.0969, 0.0986, 0.1014, 0.1036, 0.1049, 0.1060, 0.1068,\n",
      "         0.1046],\n",
      "        [0.0853, 0.0920, 0.0969, 0.0986, 0.1014, 0.1036, 0.1049, 0.1060, 0.1068,\n",
      "         0.1046]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 永远 不会 忘记 那个 早晨 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: a morning that i will never forget . <EOS>\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0901, 0.0963, 0.1014, 0.1055, 0.1069, 0.1083, 0.1068, 0.1021, 0.0911,\n",
      "         0.0915],\n",
      "        [0.0901, 0.0963, 0.1014, 0.1055, 0.1069, 0.1084, 0.1068, 0.1021, 0.0911,\n",
      "         0.0915],\n",
      "        [0.0901, 0.0963, 0.1013, 0.1055, 0.1069, 0.1083, 0.1068, 0.1021, 0.0911,\n",
      "         0.0915],\n",
      "        [0.0901, 0.0963, 0.1013, 0.1055, 0.1069, 0.1083, 0.1068, 0.1021, 0.0912,\n",
      "         0.0915],\n",
      "        [0.0901, 0.0963, 0.1013, 0.1055, 0.1069, 0.1083, 0.1068, 0.1022, 0.0912,\n",
      "         0.0915],\n",
      "        [0.0900, 0.0963, 0.1013, 0.1055, 0.1069, 0.1083, 0.1069, 0.1022, 0.0912,\n",
      "         0.0915],\n",
      "        [0.0901, 0.0963, 0.1013, 0.1055, 0.1068, 0.1083, 0.1068, 0.1021, 0.0912,\n",
      "         0.0916],\n",
      "        [0.0901, 0.0963, 0.1013, 0.1054, 0.1068, 0.1083, 0.1068, 0.1021, 0.0912,\n",
      "         0.0916],\n",
      "        [0.0901, 0.0963, 0.1013, 0.1055, 0.1068, 0.1083, 0.1068, 0.1021, 0.0912,\n",
      "         0.0916]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 1.00, Train Loss: 9.92, Val Loss: 10.13, Train BLEU: 0.30, Val BLEU: 0.21\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的 平均 深度 是 两英里 英里 <EOS> <PAD> <PAD>\n",
      "Reference: the average depth is about two miles . <EOS>\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.1153, 0.1239, 0.1260, 0.1252, 0.1229, 0.1164, 0.1166, 0.1046, 0.0246,\n",
      "         0.0246],\n",
      "        [0.1151, 0.1239, 0.1261, 0.1254, 0.1231, 0.1165, 0.1165, 0.1042, 0.0246,\n",
      "         0.0246],\n",
      "        [0.1150, 0.1239, 0.1262, 0.1255, 0.1232, 0.1167, 0.1165, 0.1042, 0.0244,\n",
      "         0.0244],\n",
      "        [0.1151, 0.1240, 0.1264, 0.1257, 0.1234, 0.1169, 0.1167, 0.1043, 0.0238,\n",
      "         0.0238],\n",
      "        [0.1151, 0.1241, 0.1265, 0.1259, 0.1236, 0.1171, 0.1168, 0.1044, 0.0233,\n",
      "         0.0233],\n",
      "        [0.1152, 0.1242, 0.1266, 0.1260, 0.1237, 0.1172, 0.1169, 0.1044, 0.0228,\n",
      "         0.0228],\n",
      "        [0.1152, 0.1243, 0.1267, 0.1261, 0.1238, 0.1173, 0.1170, 0.1045, 0.0225,\n",
      "         0.0225],\n",
      "        [0.1153, 0.1243, 0.1268, 0.1262, 0.1239, 0.1173, 0.1170, 0.1044, 0.0224,\n",
      "         0.0224],\n",
      "        [0.1153, 0.1243, 0.1268, 0.1262, 0.1239, 0.1174, 0.1170, 0.1044, 0.0223,\n",
      "         0.0223]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班 走 了 父亲 大声 叫 着 <EOS> <PAD>\n",
      "Reference: &quot; the taliban are gone ! &quot; my father\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0888, 0.0950, 0.0992, 0.1016, 0.1040, 0.1028, 0.1039, 0.1036, 0.1035,\n",
      "         0.0974],\n",
      "        [0.0886, 0.0950, 0.0993, 0.1018, 0.1042, 0.1029, 0.1040, 0.1037, 0.1035,\n",
      "         0.0970],\n",
      "        [0.0885, 0.0950, 0.0993, 0.1017, 0.1042, 0.1030, 0.1040, 0.1037, 0.1036,\n",
      "         0.0970],\n",
      "        [0.0884, 0.0949, 0.0992, 0.1017, 0.1042, 0.1030, 0.1041, 0.1038, 0.1036,\n",
      "         0.0970],\n",
      "        [0.0884, 0.0949, 0.0992, 0.1017, 0.1042, 0.1031, 0.1041, 0.1038, 0.1036,\n",
      "         0.0970],\n",
      "        [0.0884, 0.0949, 0.0992, 0.1017, 0.1042, 0.1031, 0.1041, 0.1038, 0.1036,\n",
      "         0.0970],\n",
      "        [0.0883, 0.0949, 0.0993, 0.1018, 0.1043, 0.1031, 0.1042, 0.1038, 0.1036,\n",
      "         0.0969],\n",
      "        [0.0883, 0.0948, 0.0993, 0.1018, 0.1043, 0.1031, 0.1042, 0.1038, 0.1036,\n",
      "         0.0969],\n",
      "        [0.0883, 0.0948, 0.0992, 0.1018, 0.1043, 0.1031, 0.1042, 0.1038, 0.1036,\n",
      "         0.0969]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 2.00, Train Loss: 9.65, Val Loss: 10.00, Train BLEU: 1.53, Val BLEU: 0.20\n",
      "Sampling from training predictions...\n",
      "Source: 和 我们 合作 的 人们 帮 我们 找到 了 新\n",
      "Reference: people that have partnered with us have given us\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0928, 0.0956, 0.0981, 0.0993, 0.1000, 0.1005, 0.1010, 0.1040, 0.1062,\n",
      "         0.1025],\n",
      "        [0.0926, 0.0956, 0.0982, 0.0995, 0.1002, 0.1006, 0.1010, 0.1040, 0.1062,\n",
      "         0.1021],\n",
      "        [0.0924, 0.0955, 0.0982, 0.0996, 0.1002, 0.1005, 0.1011, 0.1040, 0.1063,\n",
      "         0.1022],\n",
      "        [0.0923, 0.0955, 0.0982, 0.0996, 0.1002, 0.1005, 0.1011, 0.1041, 0.1063,\n",
      "         0.1022],\n",
      "        [0.0923, 0.0955, 0.0982, 0.0996, 0.1002, 0.1005, 0.1011, 0.1041, 0.1064,\n",
      "         0.1022],\n",
      "        [0.0923, 0.0955, 0.0982, 0.0996, 0.1002, 0.1005, 0.1011, 0.1041, 0.1064,\n",
      "         0.1022],\n",
      "        [0.0923, 0.0954, 0.0981, 0.0995, 0.1001, 0.1004, 0.1011, 0.1042, 0.1065,\n",
      "         0.1024],\n",
      "        [0.0923, 0.0954, 0.0981, 0.0995, 0.1001, 0.1004, 0.1011, 0.1042, 0.1065,\n",
      "         0.1024],\n",
      "        [0.0922, 0.0954, 0.0981, 0.0995, 0.1002, 0.1004, 0.1011, 0.1042, 0.1065,\n",
      "         0.1023]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在 可以 去 个 真正 的 学校 念书 了\n",
      "Reference: &quot; you can go to a real school now\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0925, 0.0924, 0.0897, 0.0971, 0.1041, 0.1045, 0.1048, 0.1060, 0.1064,\n",
      "         0.1025],\n",
      "        [0.0920, 0.0920, 0.0893, 0.0975, 0.1047, 0.1048, 0.1050, 0.1061, 0.1063,\n",
      "         0.1023],\n",
      "        [0.0918, 0.0918, 0.0892, 0.0976, 0.1048, 0.1049, 0.1051, 0.1062, 0.1064,\n",
      "         0.1023],\n",
      "        [0.0918, 0.0917, 0.0891, 0.0976, 0.1047, 0.1050, 0.1051, 0.1062, 0.1065,\n",
      "         0.1024],\n",
      "        [0.0917, 0.0917, 0.0891, 0.0975, 0.1047, 0.1050, 0.1052, 0.1063, 0.1065,\n",
      "         0.1024],\n",
      "        [0.0917, 0.0917, 0.0891, 0.0974, 0.1047, 0.1050, 0.1052, 0.1063, 0.1066,\n",
      "         0.1024],\n",
      "        [0.0917, 0.0917, 0.0891, 0.0974, 0.1047, 0.1050, 0.1052, 0.1063, 0.1066,\n",
      "         0.1024],\n",
      "        [0.0917, 0.0917, 0.0891, 0.0974, 0.1046, 0.1050, 0.1052, 0.1063, 0.1066,\n",
      "         0.1024],\n",
      "        [0.0917, 0.0917, 0.0891, 0.0974, 0.1046, 0.1050, 0.1052, 0.1063, 0.1066,\n",
      "         0.1024]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 3.00, Train Loss: 9.35, Val Loss: 9.87, Train BLEU: 0.85, Val BLEU: 0.21\n",
      "Sampling from training predictions...\n",
      "Source: 是 我 最 喜欢 的 因为 它 哪 都 能动\n",
      "Reference: it &apos;s one of my favorites , because it\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0880, 0.0979, 0.1019, 0.1030, 0.1049, 0.1052, 0.1074, 0.1066, 0.0997,\n",
      "         0.0853],\n",
      "        [0.0876, 0.0983, 0.1027, 0.1039, 0.1059, 0.1059, 0.1079, 0.1064, 0.0984,\n",
      "         0.0829],\n",
      "        [0.0874, 0.0984, 0.1031, 0.1043, 0.1063, 0.1062, 0.1080, 0.1062, 0.0979,\n",
      "         0.0820],\n",
      "        [0.0872, 0.0984, 0.1032, 0.1046, 0.1065, 0.1064, 0.1081, 0.1062, 0.0977,\n",
      "         0.0816],\n",
      "        [0.0872, 0.0984, 0.1033, 0.1047, 0.1066, 0.1065, 0.1081, 0.1062, 0.0976,\n",
      "         0.0814],\n",
      "        [0.0871, 0.0984, 0.1033, 0.1047, 0.1066, 0.1065, 0.1082, 0.1062, 0.0976,\n",
      "         0.0813],\n",
      "        [0.0870, 0.0983, 0.1033, 0.1047, 0.1067, 0.1066, 0.1082, 0.1063, 0.0977,\n",
      "         0.0813],\n",
      "        [0.0869, 0.0982, 0.1032, 0.1047, 0.1067, 0.1066, 0.1083, 0.1063, 0.0977,\n",
      "         0.0813],\n",
      "        [0.0869, 0.0982, 0.1032, 0.1047, 0.1066, 0.1066, 0.1082, 0.1064, 0.0978,\n",
      "         0.0814]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 很 幸运 幸运地 成长 在 一个 珍视 教育 也\n",
      "Reference: i was very lucky to grow up in a\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0528, 0.0556, 0.0533, 0.0478, 0.0399, 0.1501, 0.1501, 0.1501, 0.1501,\n",
      "         0.1501],\n",
      "        [0.0448, 0.0474, 0.0453, 0.0404, 0.0336, 0.1577, 0.1577, 0.1577, 0.1577,\n",
      "         0.1577],\n",
      "        [0.0434, 0.0459, 0.0439, 0.0392, 0.0326, 0.1590, 0.1590, 0.1590, 0.1590,\n",
      "         0.1590],\n",
      "        [0.0446, 0.0472, 0.0452, 0.0405, 0.0337, 0.1578, 0.1578, 0.1578, 0.1578,\n",
      "         0.1578],\n",
      "        [0.0468, 0.0496, 0.0475, 0.0426, 0.0357, 0.1555, 0.1555, 0.1555, 0.1555,\n",
      "         0.1555],\n",
      "        [0.0475, 0.0503, 0.0482, 0.0433, 0.0362, 0.1549, 0.1549, 0.1549, 0.1549,\n",
      "         0.1549],\n",
      "        [0.0488, 0.0516, 0.0495, 0.0445, 0.0373, 0.1537, 0.1537, 0.1537, 0.1537,\n",
      "         0.1537],\n",
      "        [0.0487, 0.0515, 0.0494, 0.0444, 0.0372, 0.1538, 0.1538, 0.1538, 0.1538,\n",
      "         0.1538],\n",
      "        [0.0493, 0.0520, 0.0499, 0.0448, 0.0377, 0.1533, 0.1533, 0.1533, 0.1533,\n",
      "         0.1533]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4.00, Train Loss: 9.01, Val Loss: 9.72, Train BLEU: 0.32, Val BLEU: 0.21\n",
      "Sampling from training predictions...\n",
      "Source: 但 我 想 告诉 你 的 是 当 你 站\n",
      "Reference: but when you &apos;re standing at the beach ,\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0775, 0.0951, 0.1034, 0.1060, 0.1099, 0.1101, 0.1096, 0.1076, 0.1000,\n",
      "         0.0807],\n",
      "        [0.0749, 0.0944, 0.1040, 0.1071, 0.1116, 0.1117, 0.1110, 0.1082, 0.0994,\n",
      "         0.0777],\n",
      "        [0.0738, 0.0943, 0.1044, 0.1077, 0.1124, 0.1125, 0.1115, 0.1083, 0.0988,\n",
      "         0.0764],\n",
      "        [0.0731, 0.0941, 0.1046, 0.1080, 0.1128, 0.1129, 0.1118, 0.1083, 0.0986,\n",
      "         0.0759],\n",
      "        [0.0728, 0.0939, 0.1046, 0.1081, 0.1130, 0.1131, 0.1119, 0.1084, 0.0985,\n",
      "         0.0756],\n",
      "        [0.0726, 0.0938, 0.1046, 0.1082, 0.1131, 0.1132, 0.1120, 0.1084, 0.0985,\n",
      "         0.0756],\n",
      "        [0.0726, 0.0938, 0.1046, 0.1082, 0.1131, 0.1132, 0.1120, 0.1084, 0.0985,\n",
      "         0.0755],\n",
      "        [0.0726, 0.0937, 0.1046, 0.1082, 0.1131, 0.1132, 0.1120, 0.1084, 0.0985,\n",
      "         0.0756],\n",
      "        [0.0725, 0.0937, 0.1046, 0.1082, 0.1131, 0.1132, 0.1120, 0.1085, 0.0986,\n",
      "         0.0757]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 在 被 跟踪 吗 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: were we being followed ? <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> the the the the . . . . .\n",
      "Attention Weights: tensor([[0.0899, 0.1118, 0.1205, 0.1197, 0.1107, 0.0968, 0.0783, 0.0847, 0.1003,\n",
      "         0.0874],\n",
      "        [0.0891, 0.1137, 0.1236, 0.1226, 0.1120, 0.0957, 0.0753, 0.0829, 0.1000,\n",
      "         0.0851],\n",
      "        [0.0887, 0.1144, 0.1249, 0.1237, 0.1124, 0.0952, 0.0744, 0.0824, 0.0998,\n",
      "         0.0842],\n",
      "        [0.0883, 0.1146, 0.1255, 0.1244, 0.1127, 0.0951, 0.0740, 0.0821, 0.0996,\n",
      "         0.0837],\n",
      "        [0.0880, 0.1146, 0.1258, 0.1247, 0.1129, 0.0952, 0.0738, 0.0821, 0.0995,\n",
      "         0.0834],\n",
      "        [0.0878, 0.1145, 0.1258, 0.1248, 0.1131, 0.0953, 0.0738, 0.0821, 0.0994,\n",
      "         0.0833],\n",
      "        [0.0878, 0.1145, 0.1258, 0.1248, 0.1132, 0.0954, 0.0738, 0.0821, 0.0994,\n",
      "         0.0833],\n",
      "        [0.0877, 0.1144, 0.1258, 0.1248, 0.1132, 0.0955, 0.0739, 0.0821, 0.0994,\n",
      "         0.0833],\n",
      "        [0.0876, 0.1144, 0.1257, 0.1249, 0.1132, 0.0955, 0.0739, 0.0821, 0.0994,\n",
      "         0.0832]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 5.00, Train Loss: 8.66, Val Loss: 9.57, Train BLEU: 0.30, Val BLEU: 0.21\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地 地球 上 最长 的 山脉 都 在 海洋\n",
      "Reference: and in the oceans , there are the longest\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0712, 0.0925, 0.1036, 0.1110, 0.1118, 0.1143, 0.1130, 0.1113, 0.0987,\n",
      "         0.0726],\n",
      "        [0.0668, 0.0909, 0.1045, 0.1133, 0.1143, 0.1172, 0.1151, 0.1128, 0.0974,\n",
      "         0.0676],\n",
      "        [0.0653, 0.0904, 0.1050, 0.1145, 0.1155, 0.1185, 0.1158, 0.1131, 0.0964,\n",
      "         0.0656],\n",
      "        [0.0644, 0.0900, 0.1052, 0.1151, 0.1161, 0.1191, 0.1162, 0.1133, 0.0960,\n",
      "         0.0646],\n",
      "        [0.0639, 0.0898, 0.1053, 0.1154, 0.1164, 0.1195, 0.1164, 0.1134, 0.0958,\n",
      "         0.0642],\n",
      "        [0.0637, 0.0897, 0.1053, 0.1155, 0.1165, 0.1196, 0.1165, 0.1134, 0.0957,\n",
      "         0.0640],\n",
      "        [0.0637, 0.0896, 0.1053, 0.1156, 0.1166, 0.1196, 0.1165, 0.1134, 0.0957,\n",
      "         0.0639],\n",
      "        [0.0636, 0.0896, 0.1053, 0.1156, 0.1166, 0.1197, 0.1165, 0.1134, 0.0958,\n",
      "         0.0639],\n",
      "        [0.0636, 0.0896, 0.1053, 0.1156, 0.1166, 0.1196, 0.1165, 0.1134, 0.0958,\n",
      "         0.0640]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 在 被 跟踪 吗 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: were we being followed ? <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> the the the the the the . . .\n",
      "Attention Weights: tensor([[0.0859, 0.1125, 0.1229, 0.1225, 0.1129, 0.0981, 0.0771, 0.0841, 0.1007,\n",
      "         0.0834],\n",
      "        [0.0836, 0.1146, 0.1275, 0.1271, 0.1155, 0.0973, 0.0732, 0.0815, 0.1001,\n",
      "         0.0797],\n",
      "        [0.0827, 0.1155, 0.1294, 0.1289, 0.1163, 0.0968, 0.0718, 0.0807, 0.0998,\n",
      "         0.0781],\n",
      "        [0.0820, 0.1158, 0.1304, 0.1299, 0.1167, 0.0967, 0.0712, 0.0804, 0.0996,\n",
      "         0.0773],\n",
      "        [0.0816, 0.1158, 0.1308, 0.1304, 0.1171, 0.0968, 0.0710, 0.0803, 0.0994,\n",
      "         0.0768],\n",
      "        [0.0814, 0.1158, 0.1309, 0.1306, 0.1172, 0.0969, 0.0709, 0.0803, 0.0993,\n",
      "         0.0767],\n",
      "        [0.0813, 0.1158, 0.1309, 0.1307, 0.1173, 0.0970, 0.0709, 0.0803, 0.0992,\n",
      "         0.0766],\n",
      "        [0.0812, 0.1157, 0.1309, 0.1307, 0.1174, 0.0970, 0.0710, 0.0803, 0.0992,\n",
      "         0.0766],\n",
      "        [0.0811, 0.1156, 0.1309, 0.1308, 0.1174, 0.0971, 0.0710, 0.0803, 0.0992,\n",
      "         0.0765]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 6.00, Train Loss: 8.28, Val Loss: 9.41, Train BLEU: 0.32, Val BLEU: 0.21\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一只 水母 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: here &apos;s a jelly . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> the the the the . . . . .\n",
      "Attention Weights: tensor([[0.1536, 0.1832, 0.1740, 0.1377, 0.0774, 0.0548, 0.0548, 0.0548, 0.0548,\n",
      "         0.0548],\n",
      "        [0.0879, 0.1089, 0.1025, 0.0776, 0.0403, 0.1166, 0.1166, 0.1166, 0.1166,\n",
      "         0.1166],\n",
      "        [0.0628, 0.0787, 0.0737, 0.0551, 0.0281, 0.1403, 0.1403, 0.1403, 0.1403,\n",
      "         0.1403],\n",
      "        [0.0532, 0.0669, 0.0626, 0.0466, 0.0237, 0.1494, 0.1494, 0.1494, 0.1494,\n",
      "         0.1494],\n",
      "        [0.0507, 0.0638, 0.0597, 0.0445, 0.0226, 0.1517, 0.1517, 0.1517, 0.1517,\n",
      "         0.1517],\n",
      "        [0.0495, 0.0623, 0.0584, 0.0436, 0.0221, 0.1528, 0.1528, 0.1528, 0.1528,\n",
      "         0.1528],\n",
      "        [0.0499, 0.0628, 0.0590, 0.0441, 0.0224, 0.1524, 0.1524, 0.1524, 0.1524,\n",
      "         0.1524],\n",
      "        [0.0498, 0.0628, 0.0589, 0.0441, 0.0224, 0.1524, 0.1524, 0.1524, 0.1524,\n",
      "         0.1524],\n",
      "        [0.0502, 0.0632, 0.0593, 0.0444, 0.0227, 0.1520, 0.1520, 0.1520, 0.1520,\n",
      "         0.1520]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天 要 走 不同 的 路线 这样 才 没有\n",
      "Reference: each day , we took a different route so\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0738, 0.0950, 0.1045, 0.1096, 0.1099, 0.1118, 0.1112, 0.1102, 0.0997,\n",
      "         0.0743],\n",
      "        [0.0681, 0.0932, 0.1057, 0.1126, 0.1132, 0.1153, 0.1139, 0.1120, 0.0981,\n",
      "         0.0680],\n",
      "        [0.0664, 0.0926, 0.1063, 0.1139, 0.1145, 0.1167, 0.1147, 0.1123, 0.0970,\n",
      "         0.0656],\n",
      "        [0.0654, 0.0922, 0.1066, 0.1146, 0.1152, 0.1175, 0.1152, 0.1125, 0.0964,\n",
      "         0.0643],\n",
      "        [0.0648, 0.0920, 0.1068, 0.1150, 0.1156, 0.1179, 0.1155, 0.1126, 0.0961,\n",
      "         0.0637],\n",
      "        [0.0646, 0.0919, 0.1069, 0.1152, 0.1158, 0.1180, 0.1156, 0.1126, 0.0960,\n",
      "         0.0635],\n",
      "        [0.0645, 0.0919, 0.1069, 0.1152, 0.1159, 0.1181, 0.1156, 0.1126, 0.0960,\n",
      "         0.0634],\n",
      "        [0.0644, 0.0919, 0.1069, 0.1153, 0.1159, 0.1181, 0.1156, 0.1127, 0.0960,\n",
      "         0.0633],\n",
      "        [0.0643, 0.0919, 0.1070, 0.1153, 0.1159, 0.1181, 0.1156, 0.1126, 0.0960,\n",
      "         0.0633]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 7.00, Train Loss: 7.90, Val Loss: 9.26, Train BLEU: 0.32, Val BLEU: 0.22\n",
      "Sampling from training predictions...\n",
      "Source: 底下 这些 都 是 <UNK> 它们 上上 上上下下 上下 下下\n",
      "Reference: it &apos;s got these fishing <UNK> on the bottom\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0910, 0.1135, 0.1215, 0.1160, 0.0998, 0.1068, 0.0985, 0.1034, 0.0918,\n",
      "         0.0577],\n",
      "        [0.0884, 0.1164, 0.1278, 0.1207, 0.1006, 0.1089, 0.0970, 0.1022, 0.0876,\n",
      "         0.0503],\n",
      "        [0.0870, 0.1169, 0.1296, 0.1223, 0.1012, 0.1101, 0.0972, 0.1017, 0.0859,\n",
      "         0.0481],\n",
      "        [0.0859, 0.1168, 0.1304, 0.1234, 0.1019, 0.1110, 0.0975, 0.1014, 0.0849,\n",
      "         0.0468],\n",
      "        [0.0854, 0.1168, 0.1308, 0.1238, 0.1023, 0.1114, 0.0977, 0.1011, 0.0843,\n",
      "         0.0462],\n",
      "        [0.0851, 0.1167, 0.1310, 0.1241, 0.1026, 0.1117, 0.0979, 0.1010, 0.0840,\n",
      "         0.0458],\n",
      "        [0.0849, 0.1167, 0.1311, 0.1243, 0.1028, 0.1119, 0.0980, 0.1009, 0.0838,\n",
      "         0.0456],\n",
      "        [0.0848, 0.1167, 0.1311, 0.1244, 0.1029, 0.1120, 0.0981, 0.1009, 0.0837,\n",
      "         0.0455],\n",
      "        [0.0848, 0.1167, 0.1311, 0.1244, 0.1029, 0.1120, 0.0981, 0.1008, 0.0837,\n",
      "         0.0454]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把 书 放在 食品 杂货 袋中 这样 别人 就\n",
      "Reference: we would cover our books in grocery bags so\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0767, 0.0949, 0.1048, 0.1083, 0.1085, 0.1098, 0.1096, 0.1068, 0.1013,\n",
      "         0.0791],\n",
      "        [0.0702, 0.0924, 0.1060, 0.1115, 0.1123, 0.1141, 0.1132, 0.1084, 0.0999,\n",
      "         0.0720],\n",
      "        [0.0682, 0.0915, 0.1064, 0.1128, 0.1138, 0.1157, 0.1145, 0.1087, 0.0989,\n",
      "         0.0695],\n",
      "        [0.0669, 0.0909, 0.1066, 0.1135, 0.1147, 0.1167, 0.1153, 0.1090, 0.0983,\n",
      "         0.0682],\n",
      "        [0.0663, 0.0906, 0.1067, 0.1139, 0.1151, 0.1172, 0.1157, 0.1091, 0.0980,\n",
      "         0.0674],\n",
      "        [0.0660, 0.0906, 0.1068, 0.1141, 0.1154, 0.1174, 0.1158, 0.1090, 0.0978,\n",
      "         0.0671],\n",
      "        [0.0659, 0.0906, 0.1069, 0.1142, 0.1155, 0.1175, 0.1158, 0.1090, 0.0977,\n",
      "         0.0669],\n",
      "        [0.0658, 0.0905, 0.1070, 0.1142, 0.1155, 0.1176, 0.1159, 0.1090, 0.0976,\n",
      "         0.0669],\n",
      "        [0.0658, 0.0905, 0.1070, 0.1143, 0.1155, 0.1176, 0.1159, 0.1090, 0.0976,\n",
      "         0.0668]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8.00, Train Loss: 7.51, Val Loss: 9.11, Train BLEU: 0.32, Val BLEU: 0.22\n",
      "Sampling from training predictions...\n",
      "Source: 原来 它 是 海洋 洋中 最长 的 生物 <EOS> <PAD>\n",
      "Reference: this turns out to be the longest creature in\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0934, 0.1151, 0.1204, 0.1191, 0.1164, 0.1175, 0.1135, 0.0903, 0.0511,\n",
      "         0.0632],\n",
      "        [0.0629, 0.0836, 0.0900, 0.0891, 0.0867, 0.0883, 0.0832, 0.0612, 0.0308,\n",
      "         0.3242],\n",
      "        [0.0459, 0.0627, 0.0682, 0.0676, 0.0656, 0.0670, 0.0625, 0.0448, 0.0219,\n",
      "         0.4936],\n",
      "        [0.0371, 0.0514, 0.0563, 0.0559, 0.0542, 0.0553, 0.0512, 0.0361, 0.0174,\n",
      "         0.5852],\n",
      "        [0.0332, 0.0464, 0.0509, 0.0505, 0.0490, 0.0500, 0.0461, 0.0323, 0.0155,\n",
      "         0.6259],\n",
      "        [0.0318, 0.0445, 0.0488, 0.0484, 0.0470, 0.0479, 0.0441, 0.0309, 0.0148,\n",
      "         0.6418],\n",
      "        [0.0313, 0.0438, 0.0480, 0.0476, 0.0463, 0.0472, 0.0434, 0.0304, 0.0145,\n",
      "         0.6475],\n",
      "        [0.0312, 0.0436, 0.0479, 0.0475, 0.0462, 0.0470, 0.0432, 0.0304, 0.0145,\n",
      "         0.6484],\n",
      "        [0.0314, 0.0439, 0.0481, 0.0477, 0.0465, 0.0473, 0.0435, 0.0306, 0.0147,\n",
      "         0.6463]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 她 两年 年前 退休 了 结果 却 把 我家 变成\n",
      "Reference: she retired two years ago , only to turn\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.1157, 0.1373, 0.1399, 0.1333, 0.1095, 0.0614, 0.0757, 0.0757, 0.0757,\n",
      "         0.0757],\n",
      "        [0.0386, 0.0488, 0.0505, 0.0472, 0.0364, 0.0182, 0.1901, 0.1901, 0.1901,\n",
      "         0.1901],\n",
      "        [0.0212, 0.0274, 0.0284, 0.0263, 0.0199, 0.0097, 0.2168, 0.2168, 0.2168,\n",
      "         0.2168],\n",
      "        [0.0158, 0.0206, 0.0214, 0.0197, 0.0148, 0.0071, 0.2252, 0.2252, 0.2252,\n",
      "         0.2252],\n",
      "        [0.0142, 0.0185, 0.0193, 0.0178, 0.0133, 0.0064, 0.2276, 0.2276, 0.2276,\n",
      "         0.2276],\n",
      "        [0.0137, 0.0179, 0.0186, 0.0172, 0.0128, 0.0061, 0.2284, 0.2284, 0.2284,\n",
      "         0.2284],\n",
      "        [0.0136, 0.0177, 0.0185, 0.0170, 0.0127, 0.0061, 0.2286, 0.2286, 0.2286,\n",
      "         0.2286],\n",
      "        [0.0135, 0.0177, 0.0185, 0.0170, 0.0127, 0.0061, 0.2286, 0.2286, 0.2286,\n",
      "         0.2286],\n",
      "        [0.0137, 0.0179, 0.0187, 0.0172, 0.0129, 0.0062, 0.2283, 0.2283, 0.2283,\n",
      "         0.2283]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 9.00, Train Loss: 7.11, Val Loss: 8.97, Train BLEU: 0.32, Val BLEU: 0.21\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想 海洋 占 了 地球 球面 面积 的 75\n",
      "Reference: when you think about it , the oceans are\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0855, 0.1065, 0.1126, 0.1129, 0.1120, 0.1095, 0.1084, 0.1054, 0.0929,\n",
      "         0.0542],\n",
      "        [0.0773, 0.1057, 0.1160, 0.1182, 0.1179, 0.1148, 0.1125, 0.1065, 0.0875,\n",
      "         0.0437],\n",
      "        [0.0744, 0.1048, 0.1169, 0.1200, 0.1201, 0.1169, 0.1142, 0.1067, 0.0854,\n",
      "         0.0407],\n",
      "        [0.0727, 0.1043, 0.1173, 0.1210, 0.1213, 0.1181, 0.1151, 0.1069, 0.0842,\n",
      "         0.0391],\n",
      "        [0.0719, 0.1040, 0.1176, 0.1216, 0.1219, 0.1188, 0.1156, 0.1068, 0.0835,\n",
      "         0.0383],\n",
      "        [0.0715, 0.1039, 0.1177, 0.1219, 0.1223, 0.1191, 0.1158, 0.1068, 0.0832,\n",
      "         0.0379],\n",
      "        [0.0712, 0.1039, 0.1179, 0.1221, 0.1225, 0.1193, 0.1159, 0.1067, 0.0829,\n",
      "         0.0376],\n",
      "        [0.0711, 0.1039, 0.1180, 0.1222, 0.1226, 0.1194, 0.1160, 0.1066, 0.0827,\n",
      "         0.0375],\n",
      "        [0.0709, 0.1039, 0.1180, 0.1224, 0.1227, 0.1195, 0.1160, 0.1066, 0.0826,\n",
      "         0.0374]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 对 他 来说 孩子 不 接受 受教 教育 <UNK> 是\n",
      "Reference: to him , there was greater risk in not\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.1151, 0.1388, 0.1426, 0.1412, 0.1354, 0.1089, 0.0593, 0.0529, 0.0529,\n",
      "         0.0529],\n",
      "        [0.0538, 0.0706, 0.0746, 0.0745, 0.0698, 0.0516, 0.0243, 0.1936, 0.1936,\n",
      "         0.1936],\n",
      "        [0.0323, 0.0436, 0.0467, 0.0467, 0.0434, 0.0312, 0.0141, 0.2473, 0.2473,\n",
      "         0.2473],\n",
      "        [0.0235, 0.0322, 0.0347, 0.0348, 0.0321, 0.0226, 0.0100, 0.2700, 0.2700,\n",
      "         0.2700],\n",
      "        [0.0198, 0.0273, 0.0295, 0.0295, 0.0271, 0.0191, 0.0084, 0.2797, 0.2797,\n",
      "         0.2797],\n",
      "        [0.0183, 0.0252, 0.0273, 0.0273, 0.0250, 0.0175, 0.0077, 0.2839, 0.2839,\n",
      "         0.2839],\n",
      "        [0.0177, 0.0244, 0.0263, 0.0263, 0.0242, 0.0169, 0.0075, 0.2856, 0.2856,\n",
      "         0.2856],\n",
      "        [0.0174, 0.0240, 0.0260, 0.0260, 0.0238, 0.0167, 0.0074, 0.2862, 0.2862,\n",
      "         0.2862],\n",
      "        [0.0172, 0.0237, 0.0256, 0.0256, 0.0235, 0.0165, 0.0073, 0.2869, 0.2869,\n",
      "         0.2869]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 10.00, Train Loss: 6.72, Val Loss: 8.84, Train BLEU: 0.29, Val BLEU: 0.21\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分 部分 的 动物 也 都 生活 在 海洋\n",
      "Reference: most of the animals are in the oceans .\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0785, 0.0999, 0.1073, 0.1081, 0.1071, 0.1071, 0.1066, 0.1050, 0.1018,\n",
      "         0.0786],\n",
      "        [0.0686, 0.0972, 0.1093, 0.1121, 0.1119, 0.1119, 0.1107, 0.1079, 0.1011,\n",
      "         0.0693],\n",
      "        [0.0653, 0.0958, 0.1096, 0.1134, 0.1136, 0.1137, 0.1124, 0.1091, 0.1008,\n",
      "         0.0664],\n",
      "        [0.0635, 0.0948, 0.1097, 0.1141, 0.1146, 0.1148, 0.1134, 0.1098, 0.1006,\n",
      "         0.0648],\n",
      "        [0.0626, 0.0943, 0.1098, 0.1145, 0.1152, 0.1154, 0.1139, 0.1101, 0.1003,\n",
      "         0.0640],\n",
      "        [0.0621, 0.0941, 0.1099, 0.1148, 0.1155, 0.1158, 0.1142, 0.1102, 0.1000,\n",
      "         0.0635],\n",
      "        [0.0618, 0.0940, 0.1100, 0.1150, 0.1158, 0.1160, 0.1143, 0.1102, 0.0998,\n",
      "         0.0631],\n",
      "        [0.0616, 0.0939, 0.1101, 0.1151, 0.1160, 0.1162, 0.1145, 0.1102, 0.0996,\n",
      "         0.0628],\n",
      "        [0.0614, 0.0939, 0.1102, 0.1153, 0.1162, 0.1163, 0.1145, 0.1102, 0.0994,\n",
      "         0.0625]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11 岁 那年 记得 得有 一天 早晨 醒来 听见\n",
      "Reference: when i was 11 , i remember waking up\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.1275, 0.1591, 0.1652, 0.1569, 0.1377, 0.0893, 0.0574, 0.0356, 0.0356,\n",
      "         0.0356],\n",
      "        [0.0740, 0.1029, 0.1108, 0.1041, 0.0860, 0.0487, 0.0280, 0.1485, 0.1485,\n",
      "         0.1485],\n",
      "        [0.0487, 0.0702, 0.0769, 0.0722, 0.0583, 0.0316, 0.0177, 0.2081, 0.2081,\n",
      "         0.2081],\n",
      "        [0.0358, 0.0527, 0.0582, 0.0545, 0.0435, 0.0231, 0.0127, 0.2398, 0.2398,\n",
      "         0.2398],\n",
      "        [0.0294, 0.0436, 0.0483, 0.0453, 0.0359, 0.0189, 0.0103, 0.2561, 0.2561,\n",
      "         0.2561],\n",
      "        [0.0261, 0.0388, 0.0430, 0.0403, 0.0319, 0.0168, 0.0091, 0.2647, 0.2647,\n",
      "         0.2647],\n",
      "        [0.0243, 0.0361, 0.0401, 0.0375, 0.0296, 0.0156, 0.0085, 0.2694, 0.2694,\n",
      "         0.2694],\n",
      "        [0.0232, 0.0345, 0.0382, 0.0358, 0.0283, 0.0149, 0.0081, 0.2723, 0.2723,\n",
      "         0.2723],\n",
      "        [0.0225, 0.0334, 0.0370, 0.0346, 0.0274, 0.0145, 0.0079, 0.2743, 0.2743,\n",
      "         0.2743]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 11.00, Train Loss: 6.33, Val Loss: 8.73, Train BLEU: 0.29, Val BLEU: 0.21\n",
      "Sampling from training predictions...\n",
      "Source: 但 我 想 告诉 你 的 是 当 你 站\n",
      "Reference: but when you &apos;re standing at the beach ,\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0839, 0.1025, 0.1054, 0.1048, 0.1045, 0.1042, 0.1040, 0.1038, 0.1024,\n",
      "         0.0847],\n",
      "        [0.0746, 0.1015, 0.1078, 0.1083, 0.1082, 0.1078, 0.1071, 0.1061, 0.1022,\n",
      "         0.0763],\n",
      "        [0.0713, 0.1007, 0.1084, 0.1096, 0.1095, 0.1092, 0.1084, 0.1071, 0.1022,\n",
      "         0.0736],\n",
      "        [0.0693, 0.1000, 0.1087, 0.1103, 0.1104, 0.1101, 0.1092, 0.1077, 0.1021,\n",
      "         0.0720],\n",
      "        [0.0684, 0.0996, 0.1089, 0.1107, 0.1109, 0.1106, 0.1097, 0.1080, 0.1019,\n",
      "         0.0712],\n",
      "        [0.0678, 0.0993, 0.1090, 0.1110, 0.1113, 0.1110, 0.1099, 0.1082, 0.1018,\n",
      "         0.0707],\n",
      "        [0.0674, 0.0992, 0.1091, 0.1112, 0.1115, 0.1112, 0.1101, 0.1083, 0.1016,\n",
      "         0.0702],\n",
      "        [0.0671, 0.0991, 0.1092, 0.1114, 0.1118, 0.1114, 0.1103, 0.1083, 0.1015,\n",
      "         0.0699],\n",
      "        [0.0669, 0.0990, 0.1093, 0.1116, 0.1119, 0.1116, 0.1104, 0.1084, 0.1013,\n",
      "         0.0696]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 她 两年 年前 退休 了 结果 却 把 我家 变成\n",
      "Reference: she retired two years ago , only to turn\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.1424, 0.1718, 0.1723, 0.1640, 0.1382, 0.0711, 0.0350, 0.0350, 0.0350,\n",
      "         0.0350],\n",
      "        [0.0736, 0.0985, 0.1015, 0.0953, 0.0742, 0.0311, 0.1314, 0.1314, 0.1314,\n",
      "         0.1314],\n",
      "        [0.0460, 0.0640, 0.0668, 0.0625, 0.0473, 0.0186, 0.1737, 0.1737, 0.1737,\n",
      "         0.1737],\n",
      "        [0.0325, 0.0461, 0.0486, 0.0453, 0.0336, 0.0128, 0.1953, 0.1953, 0.1953,\n",
      "         0.1953],\n",
      "        [0.0259, 0.0371, 0.0392, 0.0365, 0.0268, 0.0100, 0.2061, 0.2061, 0.2061,\n",
      "         0.2061],\n",
      "        [0.0224, 0.0322, 0.0341, 0.0317, 0.0232, 0.0086, 0.2119, 0.2119, 0.2119,\n",
      "         0.2119],\n",
      "        [0.0203, 0.0293, 0.0311, 0.0288, 0.0210, 0.0078, 0.2154, 0.2154, 0.2154,\n",
      "         0.2154],\n",
      "        [0.0190, 0.0274, 0.0291, 0.0270, 0.0197, 0.0073, 0.2176, 0.2176, 0.2176,\n",
      "         0.2176],\n",
      "        [0.0181, 0.0261, 0.0277, 0.0257, 0.0187, 0.0070, 0.2192, 0.2192, 0.2192,\n",
      "         0.2192]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12.00, Train Loss: 5.97, Val Loss: 8.65, Train BLEU: 0.29, Val BLEU: 0.21\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一只 水母 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: here &apos;s a jelly . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> the the the the the the the the .\n",
      "Attention Weights: tensor([[0.1487, 0.1719, 0.1648, 0.1429, 0.0767, 0.0590, 0.0590, 0.0590, 0.0590,\n",
      "         0.0590],\n",
      "        [0.0445, 0.0568, 0.0551, 0.0448, 0.0197, 0.1558, 0.1558, 0.1558, 0.1558,\n",
      "         0.1558],\n",
      "        [0.0223, 0.0295, 0.0288, 0.0228, 0.0094, 0.1774, 0.1774, 0.1774, 0.1774,\n",
      "         0.1774],\n",
      "        [0.0146, 0.0197, 0.0193, 0.0150, 0.0060, 0.1851, 0.1851, 0.1851, 0.1851,\n",
      "         0.1851],\n",
      "        [0.0113, 0.0153, 0.0150, 0.0116, 0.0046, 0.1884, 0.1884, 0.1884, 0.1884,\n",
      "         0.1884],\n",
      "        [0.0096, 0.0132, 0.0130, 0.0099, 0.0039, 0.1901, 0.1901, 0.1901, 0.1901,\n",
      "         0.1901],\n",
      "        [0.0088, 0.0120, 0.0118, 0.0090, 0.0036, 0.1910, 0.1910, 0.1910, 0.1910,\n",
      "         0.1910],\n",
      "        [0.0082, 0.0112, 0.0111, 0.0084, 0.0033, 0.1916, 0.1916, 0.1916, 0.1916,\n",
      "         0.1916],\n",
      "        [0.0078, 0.0107, 0.0105, 0.0080, 0.0032, 0.1920, 0.1920, 0.1920, 0.1920,\n",
      "         0.1920]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正 的 学校 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: a real school . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> the the the the the the the the .\n",
      "Attention Weights: tensor([[0.0916, 0.1109, 0.1118, 0.1098, 0.1081, 0.1060, 0.1048, 0.1027, 0.0962,\n",
      "         0.0580],\n",
      "        [0.0818, 0.1106, 0.1158, 0.1150, 0.1137, 0.1112, 0.1093, 0.1050, 0.0920,\n",
      "         0.0457],\n",
      "        [0.0780, 0.1098, 0.1169, 0.1168, 0.1157, 0.1133, 0.1112, 0.1060, 0.0903,\n",
      "         0.0420],\n",
      "        [0.0758, 0.1091, 0.1174, 0.1177, 0.1169, 0.1145, 0.1124, 0.1067, 0.0894,\n",
      "         0.0402],\n",
      "        [0.0747, 0.1086, 0.1175, 0.1182, 0.1175, 0.1152, 0.1130, 0.1071, 0.0889,\n",
      "         0.0393],\n",
      "        [0.0740, 0.1083, 0.1176, 0.1185, 0.1179, 0.1157, 0.1134, 0.1073, 0.0886,\n",
      "         0.0387],\n",
      "        [0.0735, 0.1082, 0.1178, 0.1187, 0.1182, 0.1160, 0.1136, 0.1074, 0.0883,\n",
      "         0.0384],\n",
      "        [0.0732, 0.1080, 0.1179, 0.1190, 0.1184, 0.1162, 0.1138, 0.1074, 0.0880,\n",
      "         0.0381],\n",
      "        [0.0729, 0.1080, 0.1180, 0.1191, 0.1186, 0.1164, 0.1140, 0.1074, 0.0878,\n",
      "         0.0378]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 13.00, Train Loss: 5.64, Val Loss: 8.61, Train BLEU: 0.29, Val BLEU: 0.21\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数 多数 地震 和 火山 喷发 也 都 发生\n",
      "Reference: most of the earthquakes and volcanoes are in the\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0884, 0.1036, 0.1092, 0.1058, 0.1034, 0.1019, 0.1010, 0.1009, 0.1003,\n",
      "         0.0857],\n",
      "        [0.0777, 0.0997, 0.1112, 0.1098, 0.1078, 0.1065, 0.1051, 0.1040, 0.1008,\n",
      "         0.0775],\n",
      "        [0.0740, 0.0980, 0.1116, 0.1112, 0.1095, 0.1082, 0.1068, 0.1053, 0.1009,\n",
      "         0.0744],\n",
      "        [0.0718, 0.0967, 0.1116, 0.1119, 0.1105, 0.1094, 0.1079, 0.1062, 0.1011,\n",
      "         0.0728],\n",
      "        [0.0706, 0.0961, 0.1115, 0.1123, 0.1111, 0.1100, 0.1086, 0.1067, 0.1012,\n",
      "         0.0720],\n",
      "        [0.0699, 0.0957, 0.1115, 0.1125, 0.1114, 0.1104, 0.1090, 0.1070, 0.1012,\n",
      "         0.0715],\n",
      "        [0.0694, 0.0954, 0.1115, 0.1127, 0.1116, 0.1107, 0.1092, 0.1072, 0.1011,\n",
      "         0.0711],\n",
      "        [0.0691, 0.0953, 0.1115, 0.1128, 0.1118, 0.1109, 0.1094, 0.1074, 0.1011,\n",
      "         0.0708],\n",
      "        [0.0688, 0.0952, 0.1115, 0.1129, 0.1120, 0.1111, 0.1096, 0.1075, 0.1011,\n",
      "         0.0705]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 她 两年 年前 退休 了 结果 却 把 我家 变成\n",
      "Reference: she retired two years ago , only to turn\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.1185, 0.1330, 0.1281, 0.1223, 0.1108, 0.0637, 0.0809, 0.0809, 0.0809,\n",
      "         0.0809],\n",
      "        [0.0306, 0.0380, 0.0376, 0.0356, 0.0302, 0.0144, 0.2034, 0.2034, 0.2034,\n",
      "         0.2034],\n",
      "        [0.0146, 0.0188, 0.0188, 0.0177, 0.0146, 0.0065, 0.2272, 0.2272, 0.2272,\n",
      "         0.2272],\n",
      "        [0.0094, 0.0123, 0.0124, 0.0117, 0.0095, 0.0041, 0.2351, 0.2351, 0.2351,\n",
      "         0.2351],\n",
      "        [0.0073, 0.0096, 0.0098, 0.0092, 0.0073, 0.0031, 0.2384, 0.2384, 0.2384,\n",
      "         0.2384],\n",
      "        [0.0062, 0.0083, 0.0084, 0.0079, 0.0063, 0.0026, 0.2400, 0.2400, 0.2400,\n",
      "         0.2400],\n",
      "        [0.0056, 0.0075, 0.0077, 0.0072, 0.0057, 0.0024, 0.2410, 0.2410, 0.2410,\n",
      "         0.2410],\n",
      "        [0.0052, 0.0070, 0.0072, 0.0068, 0.0053, 0.0022, 0.2416, 0.2416, 0.2416,\n",
      "         0.2416],\n",
      "        [0.0050, 0.0067, 0.0069, 0.0064, 0.0051, 0.0021, 0.2420, 0.2420, 0.2420,\n",
      "         0.2420]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 14.00, Train Loss: 5.35, Val Loss: 8.61, Train BLEU: 0.30, Val BLEU: 0.21\n",
      "Sampling from training predictions...\n",
      "Source: 我们 用 的 是 深海 潜水 潜水艇 <UNK> 号 和\n",
      "Reference: we use the submarine alvin and we use cameras\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0958, 0.1068, 0.1030, 0.1005, 0.0995, 0.0980, 0.0998, 0.1014, 0.1013,\n",
      "         0.0938],\n",
      "        [0.0861, 0.1063, 0.1055, 0.1039, 0.1031, 0.1011, 0.1018, 0.1042, 0.1019,\n",
      "         0.0861],\n",
      "        [0.0826, 0.1062, 0.1068, 0.1054, 0.1046, 0.1025, 0.1023, 0.1047, 0.1021,\n",
      "         0.0829],\n",
      "        [0.0802, 0.1056, 0.1072, 0.1062, 0.1055, 0.1034, 0.1030, 0.1055, 0.1024,\n",
      "         0.0812],\n",
      "        [0.0788, 0.1052, 0.1074, 0.1066, 0.1060, 0.1039, 0.1035, 0.1059, 0.1025,\n",
      "         0.0802],\n",
      "        [0.0779, 0.1048, 0.1075, 0.1069, 0.1064, 0.1043, 0.1038, 0.1063, 0.1025,\n",
      "         0.0796],\n",
      "        [0.0774, 0.1046, 0.1075, 0.1071, 0.1066, 0.1046, 0.1041, 0.1065, 0.1025,\n",
      "         0.0792],\n",
      "        [0.0769, 0.1044, 0.1076, 0.1072, 0.1068, 0.1048, 0.1043, 0.1067, 0.1025,\n",
      "         0.0788],\n",
      "        [0.0766, 0.1043, 0.1076, 0.1074, 0.1069, 0.1049, 0.1045, 0.1068, 0.1025,\n",
      "         0.0785]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 对 他 来说 孩子 不 接受 受教 教育 <UNK> 是\n",
      "Reference: to him , there was greater risk in not\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.1059, 0.1160, 0.1114, 0.1080, 0.1044, 0.0963, 0.0585, 0.0998, 0.0998,\n",
      "         0.0998],\n",
      "        [0.0296, 0.0358, 0.0355, 0.0346, 0.0330, 0.0284, 0.0144, 0.2629, 0.2629,\n",
      "         0.2629],\n",
      "        [0.0141, 0.0176, 0.0176, 0.0172, 0.0163, 0.0136, 0.0065, 0.2990, 0.2990,\n",
      "         0.2990],\n",
      "        [0.0090, 0.0115, 0.0116, 0.0113, 0.0107, 0.0087, 0.0040, 0.3110, 0.3110,\n",
      "         0.3110],\n",
      "        [0.0068, 0.0088, 0.0089, 0.0088, 0.0082, 0.0066, 0.0030, 0.3163, 0.3163,\n",
      "         0.3163],\n",
      "        [0.0057, 0.0075, 0.0076, 0.0075, 0.0070, 0.0056, 0.0025, 0.3189, 0.3189,\n",
      "         0.3189],\n",
      "        [0.0051, 0.0067, 0.0069, 0.0068, 0.0063, 0.0051, 0.0022, 0.3203, 0.3203,\n",
      "         0.3203],\n",
      "        [0.0047, 0.0063, 0.0064, 0.0063, 0.0059, 0.0047, 0.0021, 0.3212, 0.3212,\n",
      "         0.3212],\n",
      "        [0.0045, 0.0060, 0.0061, 0.0060, 0.0057, 0.0045, 0.0020, 0.3217, 0.3217,\n",
      "         0.3217]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 15.00, Train Loss: 5.10, Val Loss: 8.63, Train BLEU: 0.32, Val BLEU: 0.21\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克 泰坦尼克号 坦尼 尼克 号 是 拿 了 不少\n",
      "Reference: the truth of the matter is that the titanic\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0922, 0.0997, 0.1019, 0.1045, 0.1064, 0.1028, 0.1009, 0.1002, 0.0998,\n",
      "         0.0916],\n",
      "        [0.0811, 0.0962, 0.1018, 0.1070, 0.1109, 0.1075, 0.1056, 0.1041, 0.1017,\n",
      "         0.0841],\n",
      "        [0.0776, 0.0951, 0.1017, 0.1077, 0.1125, 0.1094, 0.1074, 0.1056, 0.1021,\n",
      "         0.0808],\n",
      "        [0.0755, 0.0944, 0.1016, 0.1079, 0.1133, 0.1105, 0.1086, 0.1066, 0.1025,\n",
      "         0.0791],\n",
      "        [0.0741, 0.0939, 0.1016, 0.1081, 0.1138, 0.1112, 0.1093, 0.1072, 0.1027,\n",
      "         0.0781],\n",
      "        [0.0733, 0.0935, 0.1016, 0.1083, 0.1141, 0.1116, 0.1098, 0.1076, 0.1028,\n",
      "         0.0775],\n",
      "        [0.0727, 0.0933, 0.1016, 0.1084, 0.1143, 0.1119, 0.1101, 0.1079, 0.1029,\n",
      "         0.0770],\n",
      "        [0.0722, 0.0931, 0.1016, 0.1084, 0.1145, 0.1121, 0.1103, 0.1082, 0.1029,\n",
      "         0.0767],\n",
      "        [0.0718, 0.0929, 0.1016, 0.1085, 0.1146, 0.1123, 0.1105, 0.1083, 0.1030,\n",
      "         0.0764]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 父亲 在 用 他 的 灰色 小 收音\n",
      "Reference: my father was listening to bbc news on his\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0959, 0.1068, 0.1038, 0.1006, 0.1035, 0.1012, 0.0995, 0.0990, 0.0989,\n",
      "         0.0907],\n",
      "        [0.0846, 0.1045, 0.1062, 0.1042, 0.1079, 0.1050, 0.1031, 0.1020, 0.0997,\n",
      "         0.0826],\n",
      "        [0.0808, 0.1036, 0.1075, 0.1060, 0.1095, 0.1063, 0.1044, 0.1030, 0.0997,\n",
      "         0.0791],\n",
      "        [0.0785, 0.1027, 0.1079, 0.1069, 0.1105, 0.1072, 0.1053, 0.1037, 0.0998,\n",
      "         0.0774],\n",
      "        [0.0770, 0.1021, 0.1082, 0.1074, 0.1111, 0.1078, 0.1058, 0.1042, 0.0999,\n",
      "         0.0763],\n",
      "        [0.0761, 0.1018, 0.1083, 0.1078, 0.1116, 0.1082, 0.1062, 0.1045, 0.0999,\n",
      "         0.0757],\n",
      "        [0.0754, 0.1015, 0.1084, 0.1080, 0.1119, 0.1085, 0.1065, 0.1047, 0.0999,\n",
      "         0.0752],\n",
      "        [0.0750, 0.1014, 0.1085, 0.1082, 0.1121, 0.1087, 0.1067, 0.1049, 0.0999,\n",
      "         0.0748],\n",
      "        [0.0746, 0.1013, 0.1086, 0.1084, 0.1123, 0.1088, 0.1068, 0.1050, 0.0998,\n",
      "         0.0745]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16.00, Train Loss: 4.89, Val Loss: 8.68, Train BLEU: 0.36, Val BLEU: 0.24\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这 有 不少 精彩 的 泰坦 泰坦尼克 坦尼 尼克\n",
      "Reference: we &apos;ve got some of the most incredible video\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.1029, 0.1100, 0.1047, 0.1032, 0.1024, 0.1009, 0.0975, 0.0912, 0.0932,\n",
      "         0.0940],\n",
      "        [0.0934, 0.1101, 0.1078, 0.1072, 0.1067, 0.1050, 0.1008, 0.0915, 0.0918,\n",
      "         0.0855],\n",
      "        [0.0906, 0.1109, 0.1096, 0.1090, 0.1084, 0.1066, 0.1018, 0.0911, 0.0904,\n",
      "         0.0818],\n",
      "        [0.0886, 0.1107, 0.1102, 0.1098, 0.1094, 0.1075, 0.1026, 0.0915, 0.0900,\n",
      "         0.0797],\n",
      "        [0.0871, 0.1104, 0.1105, 0.1103, 0.1100, 0.1082, 0.1033, 0.0919, 0.0899,\n",
      "         0.0785],\n",
      "        [0.0860, 0.1102, 0.1107, 0.1107, 0.1104, 0.1086, 0.1038, 0.0922, 0.0898,\n",
      "         0.0776],\n",
      "        [0.0852, 0.1100, 0.1109, 0.1110, 0.1107, 0.1090, 0.1041, 0.0924, 0.0897,\n",
      "         0.0770],\n",
      "        [0.0845, 0.1098, 0.1111, 0.1113, 0.1110, 0.1092, 0.1044, 0.0926, 0.0896,\n",
      "         0.0765],\n",
      "        [0.0841, 0.1097, 0.1112, 0.1114, 0.1112, 0.1095, 0.1046, 0.0927, 0.0895,\n",
      "         0.0761]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 想 过 要 放弃 但 我 的 父亲 这时\n",
      "Reference: i would want to quit , but my father\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.1026, 0.1116, 0.1062, 0.1043, 0.1037, 0.1032, 0.1024, 0.1007, 0.0917,\n",
      "         0.0737],\n",
      "        [0.0935, 0.1123, 0.1101, 0.1092, 0.1087, 0.1083, 0.1072, 0.1034, 0.0852,\n",
      "         0.0621],\n",
      "        [0.0908, 0.1130, 0.1120, 0.1112, 0.1107, 0.1101, 0.1087, 0.1037, 0.0819,\n",
      "         0.0578],\n",
      "        [0.0888, 0.1130, 0.1128, 0.1123, 0.1118, 0.1112, 0.1097, 0.1042, 0.0805,\n",
      "         0.0557],\n",
      "        [0.0873, 0.1127, 0.1133, 0.1130, 0.1126, 0.1120, 0.1104, 0.1046, 0.0798,\n",
      "         0.0543],\n",
      "        [0.0862, 0.1125, 0.1136, 0.1135, 0.1131, 0.1125, 0.1109, 0.1048, 0.0792,\n",
      "         0.0535],\n",
      "        [0.0855, 0.1123, 0.1138, 0.1138, 0.1135, 0.1129, 0.1113, 0.1050, 0.0789,\n",
      "         0.0529],\n",
      "        [0.0849, 0.1122, 0.1140, 0.1141, 0.1138, 0.1132, 0.1115, 0.1052, 0.0787,\n",
      "         0.0524],\n",
      "        [0.0844, 0.1121, 0.1141, 0.1143, 0.1140, 0.1135, 0.1118, 0.1053, 0.0785,\n",
      "         0.0521]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 17.00, Train Loss: 4.72, Val Loss: 8.74, Train BLEU: 0.36, Val BLEU: 0.24\n",
      "Sampling from training predictions...\n",
      "Source: 和 我们 合作 的 人们 帮 我们 找到 了 新\n",
      "Reference: people that have partnered with us have given us\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.1002, 0.1041, 0.1006, 0.0997, 0.0996, 0.0994, 0.0993, 0.0997, 0.1001,\n",
      "         0.0973],\n",
      "        [0.0904, 0.1032, 0.1025, 0.1023, 0.1025, 0.1024, 0.1024, 0.1025, 0.1017,\n",
      "         0.0900],\n",
      "        [0.0879, 0.1036, 0.1035, 0.1034, 0.1035, 0.1035, 0.1032, 0.1031, 0.1016,\n",
      "         0.0867],\n",
      "        [0.0862, 0.1034, 0.1039, 0.1041, 0.1042, 0.1042, 0.1039, 0.1036, 0.1016,\n",
      "         0.0847],\n",
      "        [0.0848, 0.1032, 0.1042, 0.1045, 0.1048, 0.1048, 0.1045, 0.1041, 0.1017,\n",
      "         0.0834],\n",
      "        [0.0838, 0.1031, 0.1045, 0.1049, 0.1052, 0.1052, 0.1049, 0.1044, 0.1017,\n",
      "         0.0825],\n",
      "        [0.0831, 0.1029, 0.1046, 0.1052, 0.1055, 0.1055, 0.1051, 0.1046, 0.1017,\n",
      "         0.0818],\n",
      "        [0.0825, 0.1028, 0.1048, 0.1054, 0.1057, 0.1057, 0.1054, 0.1048, 0.1016,\n",
      "         0.0813],\n",
      "        [0.0819, 0.1027, 0.1049, 0.1056, 0.1059, 0.1059, 0.1056, 0.1049, 0.1016,\n",
      "         0.0808]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 祖父 在 他 的 年代 是 位非 非凡\n",
      "Reference: my grandfather was an extraordinary man for his time\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.1029, 0.1068, 0.1030, 0.1021, 0.1021, 0.1020, 0.1020, 0.1022, 0.1020,\n",
      "         0.0749],\n",
      "        [0.0934, 0.1068, 0.1059, 0.1060, 0.1062, 0.1063, 0.1062, 0.1058, 0.1012,\n",
      "         0.0623],\n",
      "        [0.0911, 0.1076, 0.1075, 0.1076, 0.1078, 0.1077, 0.1075, 0.1065, 0.0995,\n",
      "         0.0573],\n",
      "        [0.0895, 0.1077, 0.1083, 0.1085, 0.1087, 0.1086, 0.1083, 0.1070, 0.0986,\n",
      "         0.0548],\n",
      "        [0.0882, 0.1076, 0.1087, 0.1091, 0.1094, 0.1093, 0.1089, 0.1074, 0.0982,\n",
      "         0.0532],\n",
      "        [0.0872, 0.1075, 0.1090, 0.1096, 0.1098, 0.1098, 0.1094, 0.1077, 0.0979,\n",
      "         0.0521],\n",
      "        [0.0864, 0.1074, 0.1093, 0.1099, 0.1102, 0.1101, 0.1097, 0.1079, 0.0976,\n",
      "         0.0514],\n",
      "        [0.0858, 0.1074, 0.1095, 0.1102, 0.1105, 0.1104, 0.1099, 0.1080, 0.0974,\n",
      "         0.0508],\n",
      "        [0.0854, 0.1073, 0.1096, 0.1104, 0.1107, 0.1106, 0.1101, 0.1081, 0.0973,\n",
      "         0.0504]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 18.00, Train Loss: 4.58, Val Loss: 8.83, Train BLEU: 0.36, Val BLEU: 0.24\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 通过 潜水 潜水艇 拍下 的 影片 把 我们\n",
      "Reference: with vibrant video clips captured by submarines , david\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.1005, 0.1069, 0.1011, 0.0992, 0.1020, 0.0995, 0.0985, 0.0986, 0.0987,\n",
      "         0.0950],\n",
      "        [0.0890, 0.1051, 0.1030, 0.1023, 0.1058, 0.1029, 0.1021, 0.1022, 0.1007,\n",
      "         0.0869],\n",
      "        [0.0859, 0.1049, 0.1044, 0.1037, 0.1069, 0.1040, 0.1032, 0.1030, 0.1008,\n",
      "         0.0833],\n",
      "        [0.0838, 0.1043, 0.1050, 0.1046, 0.1077, 0.1048, 0.1040, 0.1037, 0.1009,\n",
      "         0.0812],\n",
      "        [0.0822, 0.1039, 0.1054, 0.1052, 0.1083, 0.1054, 0.1046, 0.1042, 0.1010,\n",
      "         0.0798],\n",
      "        [0.0811, 0.1035, 0.1057, 0.1056, 0.1087, 0.1059, 0.1051, 0.1045, 0.1011,\n",
      "         0.0787],\n",
      "        [0.0802, 0.1033, 0.1060, 0.1060, 0.1091, 0.1062, 0.1054, 0.1048, 0.1011,\n",
      "         0.0780],\n",
      "        [0.0796, 0.1032, 0.1061, 0.1062, 0.1093, 0.1065, 0.1056, 0.1050, 0.1011,\n",
      "         0.0774],\n",
      "        [0.0790, 0.1030, 0.1063, 0.1064, 0.1095, 0.1067, 0.1058, 0.1051, 0.1011,\n",
      "         0.0770]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在 一个 房屋 房屋里 屋里 我们 100 多 人\n",
      "Reference: the school was in a house , more than\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0998, 0.1076, 0.1030, 0.1005, 0.0994, 0.0990, 0.0986, 0.0986, 0.0988,\n",
      "         0.0947],\n",
      "        [0.0888, 0.1045, 0.1044, 0.1034, 0.1029, 0.1029, 0.1026, 0.1025, 0.1013,\n",
      "         0.0868],\n",
      "        [0.0859, 0.1040, 0.1055, 0.1047, 0.1043, 0.1041, 0.1037, 0.1035, 0.1014,\n",
      "         0.0831],\n",
      "        [0.0839, 0.1034, 0.1059, 0.1054, 0.1051, 0.1050, 0.1045, 0.1042, 0.1015,\n",
      "         0.0809],\n",
      "        [0.0824, 0.1029, 0.1062, 0.1060, 0.1058, 0.1057, 0.1052, 0.1048, 0.1016,\n",
      "         0.0794],\n",
      "        [0.0813, 0.1026, 0.1064, 0.1064, 0.1063, 0.1062, 0.1057, 0.1052, 0.1017,\n",
      "         0.0784],\n",
      "        [0.0805, 0.1023, 0.1065, 0.1067, 0.1066, 0.1065, 0.1060, 0.1055, 0.1017,\n",
      "         0.0777],\n",
      "        [0.0798, 0.1021, 0.1066, 0.1069, 0.1069, 0.1068, 0.1063, 0.1057, 0.1017,\n",
      "         0.0771],\n",
      "        [0.0793, 0.1019, 0.1067, 0.1071, 0.1071, 0.1070, 0.1065, 0.1059, 0.1018,\n",
      "         0.0767]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 19.00, Train Loss: 4.46, Val Loss: 8.93, Train BLEU: 2.05, Val BLEU: 0.22\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里 生物 的 多样 多样性 和 密度 要 比\n",
      "Reference: the biodiversity and the <UNK> in the ocean is\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.1025, 0.1029, 0.0987, 0.0983, 0.0984, 0.1010, 0.0993, 0.0991, 0.0998,\n",
      "         0.1000],\n",
      "        [0.0916, 0.1016, 0.1005, 0.1010, 0.1015, 0.1038, 0.1025, 0.1025, 0.1022,\n",
      "         0.0928],\n",
      "        [0.0888, 0.1021, 0.1017, 0.1022, 0.1026, 0.1042, 0.1035, 0.1033, 0.1023,\n",
      "         0.0893],\n",
      "        [0.0866, 0.1022, 0.1023, 0.1030, 0.1034, 0.1047, 0.1043, 0.1039, 0.1025,\n",
      "         0.0869],\n",
      "        [0.0849, 0.1021, 0.1028, 0.1036, 0.1040, 0.1052, 0.1049, 0.1044, 0.1026,\n",
      "         0.0854],\n",
      "        [0.0837, 0.1020, 0.1031, 0.1040, 0.1045, 0.1056, 0.1053, 0.1048, 0.1027,\n",
      "         0.0844],\n",
      "        [0.0829, 0.1019, 0.1033, 0.1044, 0.1048, 0.1058, 0.1056, 0.1050, 0.1027,\n",
      "         0.0836],\n",
      "        [0.0823, 0.1019, 0.1035, 0.1046, 0.1050, 0.1060, 0.1058, 0.1051, 0.1027,\n",
      "         0.0831],\n",
      "        [0.0818, 0.1019, 0.1037, 0.1048, 0.1052, 0.1061, 0.1060, 0.1053, 0.1027,\n",
      "         0.0827]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 出身 阿富汗 边远 <UNK> 地区 有着 与 他人 不同\n",
      "Reference: a total maverick from a remote province of afghanistan\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0947, 0.0956, 0.0915, 0.0909, 0.0929, 0.0910, 0.0891, 0.0847, 0.0567,\n",
      "         0.2129],\n",
      "        [0.0516, 0.0579, 0.0573, 0.0576, 0.0593, 0.0579, 0.0565, 0.0511, 0.0279,\n",
      "         0.5230],\n",
      "        [0.0292, 0.0340, 0.0339, 0.0340, 0.0350, 0.0341, 0.0331, 0.0290, 0.0147,\n",
      "         0.7230],\n",
      "        [0.0169, 0.0206, 0.0207, 0.0208, 0.0213, 0.0208, 0.0202, 0.0172, 0.0082,\n",
      "         0.8333],\n",
      "        [0.0116, 0.0145, 0.0147, 0.0148, 0.0152, 0.0148, 0.0144, 0.0120, 0.0055,\n",
      "         0.8824],\n",
      "        [0.0092, 0.0117, 0.0119, 0.0120, 0.0123, 0.0120, 0.0116, 0.0097, 0.0043,\n",
      "         0.9052],\n",
      "        [0.0079, 0.0101, 0.0104, 0.0104, 0.0107, 0.0105, 0.0101, 0.0083, 0.0037,\n",
      "         0.9180],\n",
      "        [0.0071, 0.0091, 0.0093, 0.0094, 0.0096, 0.0094, 0.0091, 0.0075, 0.0033,\n",
      "         0.9262],\n",
      "        [0.0065, 0.0084, 0.0086, 0.0087, 0.0089, 0.0087, 0.0084, 0.0069, 0.0030,\n",
      "         0.9319]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20.00, Train Loss: 4.35, Val Loss: 9.04, Train BLEU: 3.89, Val BLEU: 0.22\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数 多数 地震 和 火山 喷发 也 都 发生\n",
      "Reference: most of the earthquakes and volcanoes are in the\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.1016, 0.1059, 0.1010, 0.0996, 0.0990, 0.0989, 0.0987, 0.0988, 0.0992,\n",
      "         0.0974],\n",
      "        [0.0898, 0.1024, 0.1022, 0.1025, 0.1026, 0.1030, 0.1029, 0.1030, 0.1022,\n",
      "         0.0894],\n",
      "        [0.0866, 0.1018, 0.1032, 0.1038, 0.1041, 0.1044, 0.1042, 0.1042, 0.1025,\n",
      "         0.0852],\n",
      "        [0.0842, 0.1012, 0.1037, 0.1046, 0.1052, 0.1054, 0.1052, 0.1052, 0.1028,\n",
      "         0.0824],\n",
      "        [0.0824, 0.1007, 0.1041, 0.1052, 0.1059, 0.1062, 0.1060, 0.1059, 0.1030,\n",
      "         0.0807],\n",
      "        [0.0813, 0.1004, 0.1043, 0.1056, 0.1063, 0.1066, 0.1064, 0.1062, 0.1031,\n",
      "         0.0797],\n",
      "        [0.0806, 0.1002, 0.1045, 0.1059, 0.1066, 0.1069, 0.1067, 0.1065, 0.1031,\n",
      "         0.0790],\n",
      "        [0.0800, 0.1001, 0.1046, 0.1061, 0.1069, 0.1071, 0.1069, 0.1066, 0.1031,\n",
      "         0.0784],\n",
      "        [0.0796, 0.1000, 0.1047, 0.1063, 0.1070, 0.1073, 0.1071, 0.1068, 0.1031,\n",
      "         0.0780]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 在 塔利 塔利班 控制 阿富汗 的 那些 年 我 记得\n",
      "Reference: during taliban years , i remember there were times\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.1056, 0.1059, 0.1015, 0.1014, 0.1014, 0.1014, 0.1013, 0.1004, 0.1006,\n",
      "         0.0806],\n",
      "        [0.0948, 0.1057, 0.1049, 0.1058, 0.1064, 0.1066, 0.1066, 0.1049, 0.0995,\n",
      "         0.0647],\n",
      "        [0.0921, 0.1065, 0.1067, 0.1078, 0.1084, 0.1085, 0.1084, 0.1059, 0.0971,\n",
      "         0.0585],\n",
      "        [0.0899, 0.1068, 0.1078, 0.1091, 0.1097, 0.1098, 0.1096, 0.1066, 0.0958,\n",
      "         0.0550],\n",
      "        [0.0883, 0.1068, 0.1085, 0.1099, 0.1105, 0.1106, 0.1103, 0.1071, 0.0950,\n",
      "         0.0530],\n",
      "        [0.0872, 0.1069, 0.1089, 0.1104, 0.1110, 0.1111, 0.1108, 0.1074, 0.0946,\n",
      "         0.0517],\n",
      "        [0.0866, 0.1069, 0.1092, 0.1107, 0.1114, 0.1114, 0.1111, 0.1076, 0.0942,\n",
      "         0.0509],\n",
      "        [0.0861, 0.1070, 0.1094, 0.1110, 0.1116, 0.1117, 0.1113, 0.1077, 0.0940,\n",
      "         0.0503],\n",
      "        [0.0858, 0.1070, 0.1096, 0.1112, 0.1118, 0.1119, 0.1114, 0.1078, 0.0938,\n",
      "         0.0498]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 21.00, Train Loss: 4.26, Val Loss: 9.17, Train BLEU: 4.87, Val BLEU: 0.22\n",
      "Sampling from training predictions...\n",
      "Source: 是 我 最 喜欢 的 因为 它 哪 都 能动\n",
      "Reference: it &apos;s one of my favorites , because it\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.1045, 0.1031, 0.1010, 0.1012, 0.1015, 0.1019, 0.1021, 0.1026, 0.1030,\n",
      "         0.0792],\n",
      "        [0.0930, 0.1024, 0.1036, 0.1050, 0.1058, 0.1066, 0.1069, 0.1073, 0.1042,\n",
      "         0.0653],\n",
      "        [0.0904, 0.1030, 0.1051, 0.1067, 0.1076, 0.1083, 0.1086, 0.1085, 0.1029,\n",
      "         0.0590],\n",
      "        [0.0881, 0.1033, 0.1061, 0.1078, 0.1088, 0.1095, 0.1098, 0.1094, 0.1020,\n",
      "         0.0551],\n",
      "        [0.0866, 0.1034, 0.1066, 0.1085, 0.1096, 0.1103, 0.1105, 0.1100, 0.1016,\n",
      "         0.0528],\n",
      "        [0.0858, 0.1035, 0.1070, 0.1089, 0.1100, 0.1107, 0.1109, 0.1103, 0.1014,\n",
      "         0.0516],\n",
      "        [0.0852, 0.1035, 0.1072, 0.1092, 0.1103, 0.1110, 0.1112, 0.1105, 0.1012,\n",
      "         0.0508],\n",
      "        [0.0848, 0.1036, 0.1074, 0.1094, 0.1105, 0.1112, 0.1114, 0.1106, 0.1010,\n",
      "         0.0502],\n",
      "        [0.0845, 0.1036, 0.1075, 0.1095, 0.1106, 0.1113, 0.1115, 0.1107, 0.1009,\n",
      "         0.0498]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 对 他 来说 孩子 不 接受 受教 教育 <UNK> 是\n",
      "Reference: to him , there was greater risk in not\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0788, 0.0776, 0.0761, 0.0757, 0.0746, 0.0711, 0.0483, 0.1659, 0.1659,\n",
      "         0.1659],\n",
      "        [0.0347, 0.0381, 0.0386, 0.0387, 0.0382, 0.0349, 0.0191, 0.2526, 0.2526,\n",
      "         0.2526],\n",
      "        [0.0143, 0.0164, 0.0167, 0.0168, 0.0165, 0.0145, 0.0072, 0.2992, 0.2992,\n",
      "         0.2992],\n",
      "        [0.0063, 0.0075, 0.0077, 0.0078, 0.0076, 0.0065, 0.0030, 0.3178, 0.3178,\n",
      "         0.3178],\n",
      "        [0.0040, 0.0049, 0.0050, 0.0051, 0.0050, 0.0042, 0.0018, 0.3234, 0.3234,\n",
      "         0.3234],\n",
      "        [0.0031, 0.0039, 0.0040, 0.0040, 0.0039, 0.0033, 0.0014, 0.3254, 0.3254,\n",
      "         0.3254],\n",
      "        [0.0027, 0.0033, 0.0035, 0.0035, 0.0034, 0.0029, 0.0012, 0.3265, 0.3265,\n",
      "         0.3265],\n",
      "        [0.0024, 0.0030, 0.0031, 0.0032, 0.0031, 0.0026, 0.0011, 0.3272, 0.3272,\n",
      "         0.3272],\n",
      "        [0.0022, 0.0028, 0.0029, 0.0029, 0.0029, 0.0024, 0.0010, 0.3276, 0.3276,\n",
      "         0.3276]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 22.00, Train Loss: 4.19, Val Loss: 9.31, Train BLEU: 4.90, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一只 水母 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: here &apos;s a jelly . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the . . . . . .\n",
      "Attention Weights: tensor([[0.0793, 0.0782, 0.0758, 0.0724, 0.0486, 0.1291, 0.1291, 0.1291, 0.1291,\n",
      "         0.1291],\n",
      "        [0.0351, 0.0389, 0.0388, 0.0359, 0.0193, 0.1664, 0.1664, 0.1664, 0.1664,\n",
      "         0.1664],\n",
      "        [0.0129, 0.0149, 0.0149, 0.0133, 0.0064, 0.1875, 0.1875, 0.1875, 0.1875,\n",
      "         0.1875],\n",
      "        [0.0050, 0.0061, 0.0061, 0.0053, 0.0023, 0.1950, 0.1950, 0.1950, 0.1950,\n",
      "         0.1950],\n",
      "        [0.0030, 0.0038, 0.0038, 0.0033, 0.0014, 0.1969, 0.1969, 0.1969, 0.1969,\n",
      "         0.1969],\n",
      "        [0.0024, 0.0030, 0.0030, 0.0026, 0.0011, 0.1976, 0.1976, 0.1976, 0.1976,\n",
      "         0.1976],\n",
      "        [0.0020, 0.0025, 0.0026, 0.0022, 0.0009, 0.1980, 0.1980, 0.1980, 0.1980,\n",
      "         0.1980],\n",
      "        [0.0018, 0.0023, 0.0023, 0.0020, 0.0008, 0.1982, 0.1982, 0.1982, 0.1982,\n",
      "         0.1982],\n",
      "        [0.0017, 0.0021, 0.0021, 0.0018, 0.0007, 0.1983, 0.1983, 0.1983, 0.1983,\n",
      "         0.1983]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在 一个 房屋 房屋里 屋里 我们 100 多 人\n",
      "Reference: the school was in a house , more than\n",
      "Model: <SOS> it the the the , , , , ,\n",
      "Attention Weights: tensor([[0.0997, 0.1048, 0.1007, 0.1000, 0.0995, 0.0996, 0.0995, 0.0995, 0.0996,\n",
      "         0.0971],\n",
      "        [0.0868, 0.1004, 0.1017, 0.1030, 0.1034, 0.1040, 0.1040, 0.1041, 0.1030,\n",
      "         0.0897],\n",
      "        [0.0836, 0.0998, 0.1025, 0.1041, 0.1048, 0.1053, 0.1053, 0.1053, 0.1034,\n",
      "         0.0858],\n",
      "        [0.0809, 0.0991, 0.1029, 0.1049, 0.1058, 0.1064, 0.1064, 0.1065, 0.1040,\n",
      "         0.0830],\n",
      "        [0.0791, 0.0986, 0.1033, 0.1055, 0.1065, 0.1071, 0.1072, 0.1072, 0.1043,\n",
      "         0.0813],\n",
      "        [0.0781, 0.0984, 0.1035, 0.1058, 0.1069, 0.1075, 0.1076, 0.1076, 0.1044,\n",
      "         0.0802],\n",
      "        [0.0775, 0.0982, 0.1036, 0.1060, 0.1072, 0.1078, 0.1079, 0.1078, 0.1045,\n",
      "         0.0796],\n",
      "        [0.0770, 0.0982, 0.1038, 0.1062, 0.1073, 0.1080, 0.1080, 0.1080, 0.1045,\n",
      "         0.0790],\n",
      "        [0.0767, 0.0981, 0.1039, 0.1063, 0.1075, 0.1081, 0.1082, 0.1081, 0.1045,\n",
      "         0.0786]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 23.00, Train Loss: 4.13, Val Loss: 9.43, Train BLEU: 4.90, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 通过 潜水 潜水艇 拍下 的 影片 把 我们\n",
      "Reference: with vibrant video clips captured by submarines , david\n",
      "Model: <SOS> it the the the , , , , ,\n",
      "Attention Weights: tensor([[0.1011, 0.1044, 0.0995, 0.0990, 0.1023, 0.0993, 0.0986, 0.0989, 0.0989,\n",
      "         0.0980],\n",
      "        [0.0877, 0.1016, 0.1012, 0.1021, 0.1055, 0.1031, 0.1029, 0.1033, 0.1021,\n",
      "         0.0907],\n",
      "        [0.0840, 0.1009, 0.1023, 0.1035, 0.1066, 0.1045, 0.1043, 0.1045, 0.1026,\n",
      "         0.0869],\n",
      "        [0.0810, 0.1002, 0.1029, 0.1043, 0.1072, 0.1055, 0.1056, 0.1056, 0.1033,\n",
      "         0.0843],\n",
      "        [0.0792, 0.0998, 0.1034, 0.1049, 0.1077, 0.1061, 0.1063, 0.1063, 0.1037,\n",
      "         0.0827],\n",
      "        [0.0781, 0.0996, 0.1036, 0.1052, 0.1080, 0.1065, 0.1067, 0.1066, 0.1039,\n",
      "         0.0817],\n",
      "        [0.0775, 0.0995, 0.1038, 0.1054, 0.1081, 0.1068, 0.1069, 0.1069, 0.1039,\n",
      "         0.0811],\n",
      "        [0.0771, 0.0995, 0.1040, 0.1056, 0.1082, 0.1070, 0.1071, 0.1070, 0.1040,\n",
      "         0.0806],\n",
      "        [0.0767, 0.0994, 0.1041, 0.1058, 0.1083, 0.1071, 0.1073, 0.1071, 0.1040,\n",
      "         0.0801]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 但是 我 那 受过 教育 的 母亲 成为 为了 一名\n",
      "Reference: but my educated mother became a teacher . <EOS>\n",
      "Model: <SOS> it the the the , , , , ,\n",
      "Attention Weights: tensor([[0.0798, 0.0785, 0.0777, 0.0790, 0.0790, 0.0771, 0.0749, 0.0501, 0.2020,\n",
      "         0.2020],\n",
      "        [0.0483, 0.0534, 0.0545, 0.0558, 0.0560, 0.0549, 0.0519, 0.0276, 0.2988,\n",
      "         0.2988],\n",
      "        [0.0252, 0.0289, 0.0297, 0.0304, 0.0306, 0.0300, 0.0277, 0.0131, 0.3922,\n",
      "         0.3922],\n",
      "        [0.0110, 0.0132, 0.0137, 0.0140, 0.0141, 0.0139, 0.0126, 0.0054, 0.4511,\n",
      "         0.4511],\n",
      "        [0.0061, 0.0075, 0.0078, 0.0080, 0.0081, 0.0080, 0.0072, 0.0029, 0.4723,\n",
      "         0.4723],\n",
      "        [0.0045, 0.0056, 0.0059, 0.0060, 0.0061, 0.0060, 0.0053, 0.0021, 0.4793,\n",
      "         0.4793],\n",
      "        [0.0038, 0.0047, 0.0050, 0.0051, 0.0051, 0.0051, 0.0045, 0.0017, 0.4825,\n",
      "         0.4825],\n",
      "        [0.0034, 0.0043, 0.0045, 0.0046, 0.0046, 0.0046, 0.0041, 0.0016, 0.4843,\n",
      "         0.4843],\n",
      "        [0.0031, 0.0040, 0.0042, 0.0043, 0.0043, 0.0042, 0.0038, 0.0014, 0.4854,\n",
      "         0.4854]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24.00, Train Loss: 4.07, Val Loss: 9.56, Train BLEU: 3.97, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 这位 是 比尔 <UNK> 我 是 大卫 <UNK>\n",
      "Reference: this is bill lange . i &apos;m dave gallo\n",
      "Model: <SOS> it the the the the , , , ,\n",
      "Attention Weights: tensor([[0.1033, 0.1068, 0.1014, 0.1004, 0.1010, 0.1041, 0.1009, 0.1004, 0.0998,\n",
      "         0.0819],\n",
      "        [0.0898, 0.1046, 0.1041, 0.1046, 0.1051, 0.1085, 0.1063, 0.1057, 0.1017,\n",
      "         0.0697],\n",
      "        [0.0864, 0.1043, 0.1056, 0.1063, 0.1062, 0.1101, 0.1086, 0.1074, 0.1010,\n",
      "         0.0640],\n",
      "        [0.0834, 0.1037, 0.1066, 0.1076, 0.1070, 0.1112, 0.1103, 0.1089, 0.1010,\n",
      "         0.0601],\n",
      "        [0.0816, 0.1035, 0.1071, 0.1083, 0.1075, 0.1117, 0.1112, 0.1098, 0.1011,\n",
      "         0.0581],\n",
      "        [0.0807, 0.1034, 0.1074, 0.1087, 0.1078, 0.1120, 0.1117, 0.1102, 0.1011,\n",
      "         0.0570],\n",
      "        [0.0801, 0.1033, 0.1077, 0.1090, 0.1080, 0.1122, 0.1120, 0.1104, 0.1011,\n",
      "         0.0563],\n",
      "        [0.0796, 0.1033, 0.1078, 0.1092, 0.1081, 0.1123, 0.1122, 0.1106, 0.1010,\n",
      "         0.0558],\n",
      "        [0.0793, 0.1033, 0.1080, 0.1094, 0.1083, 0.1124, 0.1124, 0.1108, 0.1009,\n",
      "         0.0554]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 因此 毫无 毫无疑问 无疑 疑问 他 的 孩子 应当 受到\n",
      "Reference: there was no question that his children would receive\n",
      "Model: <SOS> it the the the the , , , ,\n",
      "Attention Weights: tensor([[0.0866, 0.0860, 0.0841, 0.0838, 0.0837, 0.0843, 0.0825, 0.0792, 0.0544,\n",
      "         0.2754],\n",
      "        [0.0629, 0.0709, 0.0721, 0.0727, 0.0731, 0.0735, 0.0723, 0.0673, 0.0372,\n",
      "         0.3980],\n",
      "        [0.0424, 0.0496, 0.0508, 0.0514, 0.0517, 0.0519, 0.0509, 0.0462, 0.0229,\n",
      "         0.5823],\n",
      "        [0.0240, 0.0294, 0.0304, 0.0309, 0.0310, 0.0311, 0.0306, 0.0271, 0.0122,\n",
      "         0.7534],\n",
      "        [0.0135, 0.0171, 0.0178, 0.0182, 0.0183, 0.0182, 0.0181, 0.0158, 0.0067,\n",
      "         0.8563],\n",
      "        [0.0089, 0.0116, 0.0122, 0.0124, 0.0125, 0.0124, 0.0124, 0.0107, 0.0044,\n",
      "         0.9026],\n",
      "        [0.0071, 0.0093, 0.0098, 0.0100, 0.0100, 0.0100, 0.0099, 0.0086, 0.0035,\n",
      "         0.9218],\n",
      "        [0.0062, 0.0082, 0.0086, 0.0088, 0.0088, 0.0088, 0.0087, 0.0075, 0.0030,\n",
      "         0.9314],\n",
      "        [0.0057, 0.0075, 0.0079, 0.0081, 0.0081, 0.0081, 0.0080, 0.0069, 0.0027,\n",
      "         0.9369]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 25.00, Train Loss: 4.03, Val Loss: 9.70, Train BLEU: 4.88, Val BLEU: 0.32\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想 海洋 占 了 地球 球面 面积 的 75\n",
      "Reference: when you think about it , the oceans are\n",
      "Model: <SOS> it the the the the the the , ,\n",
      "Attention Weights: tensor([[0.1038, 0.1042, 0.1021, 0.1015, 0.1017, 0.1020, 0.1021, 0.1012, 0.1023,\n",
      "         0.0791],\n",
      "        [0.0903, 0.1031, 0.1049, 0.1056, 0.1065, 0.1071, 0.1075, 0.1067, 0.1046,\n",
      "         0.0638],\n",
      "        [0.0877, 0.1035, 0.1063, 0.1073, 0.1083, 0.1089, 0.1094, 0.1080, 0.1036,\n",
      "         0.0569],\n",
      "        [0.0848, 0.1034, 0.1072, 0.1085, 0.1097, 0.1104, 0.1110, 0.1095, 0.1035,\n",
      "         0.0519],\n",
      "        [0.0829, 0.1033, 0.1076, 0.1092, 0.1105, 0.1113, 0.1119, 0.1104, 0.1035,\n",
      "         0.0493],\n",
      "        [0.0819, 0.1033, 0.1079, 0.1097, 0.1110, 0.1117, 0.1124, 0.1109, 0.1034,\n",
      "         0.0478],\n",
      "        [0.0812, 0.1033, 0.1081, 0.1100, 0.1113, 0.1121, 0.1127, 0.1112, 0.1032,\n",
      "         0.0469],\n",
      "        [0.0807, 0.1033, 0.1083, 0.1102, 0.1116, 0.1123, 0.1130, 0.1114, 0.1031,\n",
      "         0.0462],\n",
      "        [0.0803, 0.1033, 0.1085, 0.1104, 0.1118, 0.1125, 0.1132, 0.1115, 0.1029,\n",
      "         0.0457]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 因此 毫无 毫无疑问 无疑 疑问 他 的 孩子 应当 受到\n",
      "Reference: there was no question that his children would receive\n",
      "Model: <SOS> it the the the the the the , ,\n",
      "Attention Weights: tensor([[0.0921, 0.0926, 0.0909, 0.0905, 0.0904, 0.0912, 0.0888, 0.0849, 0.0577,\n",
      "         0.2208],\n",
      "        [0.0746, 0.0853, 0.0869, 0.0876, 0.0881, 0.0887, 0.0868, 0.0811, 0.0448,\n",
      "         0.2761],\n",
      "        [0.0581, 0.0686, 0.0704, 0.0712, 0.0716, 0.0720, 0.0704, 0.0642, 0.0319,\n",
      "         0.4216],\n",
      "        [0.0402, 0.0493, 0.0511, 0.0518, 0.0521, 0.0524, 0.0513, 0.0459, 0.0207,\n",
      "         0.5851],\n",
      "        [0.0266, 0.0337, 0.0351, 0.0357, 0.0359, 0.0360, 0.0354, 0.0313, 0.0132,\n",
      "         0.7172],\n",
      "        [0.0170, 0.0221, 0.0232, 0.0237, 0.0238, 0.0238, 0.0236, 0.0206, 0.0083,\n",
      "         0.8139],\n",
      "        [0.0120, 0.0158, 0.0167, 0.0170, 0.0171, 0.0171, 0.0170, 0.0148, 0.0058,\n",
      "         0.8667],\n",
      "        [0.0097, 0.0129, 0.0136, 0.0139, 0.0140, 0.0140, 0.0139, 0.0120, 0.0046,\n",
      "         0.8914],\n",
      "        [0.0085, 0.0114, 0.0121, 0.0123, 0.0124, 0.0124, 0.0123, 0.0107, 0.0041,\n",
      "         0.9038]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 26.00, Train Loss: 4.00, Val Loss: 9.81, Train BLEU: 3.84, Val BLEU: 0.22\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中 的 生命 大卫 <UNK> <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: life in the deep oceans <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0418, 0.0409, 0.0398, 0.0394, 0.0384, 0.0326, 0.0262, 0.2469, 0.2469,\n",
      "         0.2469],\n",
      "        [0.0319, 0.0355, 0.0359, 0.0360, 0.0351, 0.0273, 0.0187, 0.2599, 0.2599,\n",
      "         0.2599],\n",
      "        [0.0156, 0.0180, 0.0184, 0.0184, 0.0177, 0.0129, 0.0082, 0.2970, 0.2970,\n",
      "         0.2970],\n",
      "        [0.0058, 0.0071, 0.0074, 0.0074, 0.0071, 0.0049, 0.0029, 0.3192, 0.3192,\n",
      "         0.3192],\n",
      "        [0.0030, 0.0038, 0.0039, 0.0040, 0.0038, 0.0025, 0.0014, 0.3259, 0.3259,\n",
      "         0.3259],\n",
      "        [0.0021, 0.0027, 0.0028, 0.0028, 0.0027, 0.0018, 0.0010, 0.3280, 0.3280,\n",
      "         0.3280],\n",
      "        [0.0017, 0.0023, 0.0024, 0.0024, 0.0023, 0.0015, 0.0008, 0.3289, 0.3289,\n",
      "         0.3289],\n",
      "        [0.0016, 0.0021, 0.0022, 0.0022, 0.0021, 0.0013, 0.0007, 0.3293, 0.3293,\n",
      "         0.3293],\n",
      "        [0.0015, 0.0019, 0.0020, 0.0021, 0.0020, 0.0013, 0.0007, 0.3295, 0.3295,\n",
      "         0.3295]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 她 两年 年前 退休 了 结果 却 把 我家 变成\n",
      "Reference: she retired two years ago , only to turn\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0349, 0.0336, 0.0332, 0.0329, 0.0320, 0.0226, 0.2027, 0.2027, 0.2027,\n",
      "         0.2027],\n",
      "        [0.0262, 0.0285, 0.0291, 0.0290, 0.0277, 0.0159, 0.2109, 0.2109, 0.2109,\n",
      "         0.2109],\n",
      "        [0.0116, 0.0132, 0.0135, 0.0135, 0.0126, 0.0063, 0.2323, 0.2323, 0.2323,\n",
      "         0.2323],\n",
      "        [0.0042, 0.0050, 0.0052, 0.0052, 0.0048, 0.0021, 0.2433, 0.2433, 0.2433,\n",
      "         0.2433],\n",
      "        [0.0022, 0.0027, 0.0028, 0.0028, 0.0026, 0.0011, 0.2464, 0.2464, 0.2464,\n",
      "         0.2464],\n",
      "        [0.0016, 0.0020, 0.0021, 0.0021, 0.0019, 0.0008, 0.2474, 0.2474, 0.2474,\n",
      "         0.2474],\n",
      "        [0.0013, 0.0017, 0.0018, 0.0018, 0.0016, 0.0006, 0.2478, 0.2478, 0.2478,\n",
      "         0.2478],\n",
      "        [0.0012, 0.0015, 0.0016, 0.0016, 0.0014, 0.0006, 0.2480, 0.2480, 0.2480,\n",
      "         0.2480],\n",
      "        [0.0011, 0.0014, 0.0015, 0.0015, 0.0014, 0.0005, 0.2481, 0.2481, 0.2481,\n",
      "         0.2481]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 27.00, Train Loss: 3.97, Val Loss: 9.95, Train BLEU: 2.91, Val BLEU: 0.22\n",
      "Sampling from training predictions...\n",
      "Source: 我们 得用 非常 特殊 的 仪器 才能 能到 到达 那个\n",
      "Reference: we have to have a very special technology to\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.1013, 0.1040, 0.1007, 0.0998, 0.0993, 0.0995, 0.0993, 0.0982, 0.0987,\n",
      "         0.0991],\n",
      "        [0.0886, 0.1008, 0.1017, 0.1024, 0.1026, 0.1031, 0.1033, 0.1018, 0.1020,\n",
      "         0.0937],\n",
      "        [0.0861, 0.1007, 0.1023, 0.1033, 0.1036, 0.1041, 0.1043, 0.1023, 0.1024,\n",
      "         0.0908],\n",
      "        [0.0836, 0.1001, 0.1025, 0.1039, 0.1044, 0.1049, 0.1052, 0.1031, 0.1032,\n",
      "         0.0891],\n",
      "        [0.0814, 0.0996, 0.1027, 0.1044, 0.1050, 0.1056, 0.1060, 0.1038, 0.1039,\n",
      "         0.0876],\n",
      "        [0.0801, 0.0994, 0.1029, 0.1047, 0.1055, 0.1061, 0.1065, 0.1042, 0.1042,\n",
      "         0.0865],\n",
      "        [0.0792, 0.0993, 0.1030, 0.1050, 0.1058, 0.1064, 0.1068, 0.1044, 0.1043,\n",
      "         0.0857],\n",
      "        [0.0786, 0.0992, 0.1032, 0.1052, 0.1061, 0.1067, 0.1071, 0.1045, 0.1044,\n",
      "         0.0850],\n",
      "        [0.0781, 0.0992, 0.1033, 0.1054, 0.1063, 0.1069, 0.1073, 0.1046, 0.1045,\n",
      "         0.0845]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天 要 走 不同 的 路线 这样 才 没有\n",
      "Reference: each day , we took a different route so\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.1016, 0.1010, 0.0997, 0.0995, 0.0998, 0.0996, 0.0998, 0.0992, 0.0994,\n",
      "         0.1004],\n",
      "        [0.0885, 0.0993, 0.1011, 0.1020, 0.1028, 0.1029, 0.1034, 0.1028, 0.1025,\n",
      "         0.0947],\n",
      "        [0.0862, 0.0992, 0.1016, 0.1028, 0.1037, 0.1039, 0.1044, 0.1036, 0.1028,\n",
      "         0.0918],\n",
      "        [0.0838, 0.0988, 0.1019, 0.1033, 0.1044, 0.1046, 0.1052, 0.1045, 0.1036,\n",
      "         0.0900],\n",
      "        [0.0816, 0.0985, 0.1021, 0.1038, 0.1049, 0.1053, 0.1059, 0.1053, 0.1043,\n",
      "         0.0883],\n",
      "        [0.0803, 0.0983, 0.1024, 0.1041, 0.1053, 0.1057, 0.1063, 0.1058, 0.1046,\n",
      "         0.0872],\n",
      "        [0.0794, 0.0983, 0.1025, 0.1044, 0.1056, 0.1061, 0.1066, 0.1060, 0.1047,\n",
      "         0.0863],\n",
      "        [0.0787, 0.0983, 0.1027, 0.1046, 0.1058, 0.1063, 0.1069, 0.1063, 0.1048,\n",
      "         0.0856],\n",
      "        [0.0782, 0.0983, 0.1028, 0.1048, 0.1060, 0.1065, 0.1070, 0.1064, 0.1049,\n",
      "         0.0850]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28.00, Train Loss: 3.94, Val Loss: 10.08, Train BLEU: 2.91, Val BLEU: 0.22\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的 平均 深度 是 两英里 英里 <EOS> <PAD> <PAD>\n",
      "Reference: the average depth is about two miles . <EOS>\n",
      "Model: <SOS> it the the the <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0830, 0.0824, 0.0815, 0.0815, 0.0800, 0.0793, 0.0759, 0.0520, 0.1922,\n",
      "         0.1922],\n",
      "        [0.0715, 0.0809, 0.0827, 0.0836, 0.0828, 0.0825, 0.0773, 0.0441, 0.1973,\n",
      "         0.1973],\n",
      "        [0.0534, 0.0617, 0.0634, 0.0642, 0.0634, 0.0627, 0.0580, 0.0299, 0.2717,\n",
      "         0.2717],\n",
      "        [0.0330, 0.0396, 0.0410, 0.0416, 0.0412, 0.0405, 0.0371, 0.0171, 0.3544,\n",
      "         0.3544],\n",
      "        [0.0171, 0.0214, 0.0224, 0.0228, 0.0227, 0.0222, 0.0202, 0.0085, 0.4213,\n",
      "         0.4213],\n",
      "        [0.0090, 0.0117, 0.0123, 0.0126, 0.0125, 0.0123, 0.0111, 0.0044, 0.4571,\n",
      "         0.4571],\n",
      "        [0.0060, 0.0080, 0.0084, 0.0086, 0.0086, 0.0084, 0.0075, 0.0029, 0.4708,\n",
      "         0.4708],\n",
      "        [0.0049, 0.0065, 0.0069, 0.0070, 0.0070, 0.0068, 0.0061, 0.0023, 0.4763,\n",
      "         0.4763],\n",
      "        [0.0044, 0.0058, 0.0062, 0.0063, 0.0063, 0.0061, 0.0055, 0.0020, 0.4787,\n",
      "         0.4787]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 出身 阿富汗 边远 <UNK> 地区 有着 与 他人 不同\n",
      "Reference: a total maverick from a remote province of afghanistan\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0924, 0.0919, 0.0909, 0.0916, 0.0951, 0.0915, 0.0890, 0.0854, 0.0591,\n",
      "         0.2130],\n",
      "        [0.0801, 0.0905, 0.0924, 0.0943, 0.0982, 0.0944, 0.0924, 0.0875, 0.0506,\n",
      "         0.2194],\n",
      "        [0.0672, 0.0776, 0.0797, 0.0814, 0.0850, 0.0815, 0.0795, 0.0739, 0.0389,\n",
      "         0.3351],\n",
      "        [0.0518, 0.0618, 0.0639, 0.0655, 0.0686, 0.0657, 0.0642, 0.0588, 0.0281,\n",
      "         0.4715],\n",
      "        [0.0372, 0.0457, 0.0476, 0.0489, 0.0512, 0.0491, 0.0480, 0.0436, 0.0192,\n",
      "         0.6094],\n",
      "        [0.0241, 0.0306, 0.0321, 0.0330, 0.0344, 0.0331, 0.0325, 0.0292, 0.0122,\n",
      "         0.7388],\n",
      "        [0.0154, 0.0201, 0.0211, 0.0217, 0.0227, 0.0219, 0.0215, 0.0192, 0.0077,\n",
      "         0.8288],\n",
      "        [0.0110, 0.0145, 0.0153, 0.0157, 0.0164, 0.0158, 0.0156, 0.0139, 0.0054,\n",
      "         0.8767],\n",
      "        [0.0090, 0.0119, 0.0126, 0.0130, 0.0135, 0.0131, 0.0129, 0.0114, 0.0044,\n",
      "         0.8982]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 29.00, Train Loss: 3.93, Val Loss: 10.16, Train BLEU: 2.91, Val BLEU: 0.22\n",
      "Sampling from training predictions...\n",
      "Source: 我们 得用 非常 特殊 的 仪器 才能 能到 到达 那个\n",
      "Reference: we have to have a very special technology to\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.1032, 0.1042, 0.1000, 0.0991, 0.0986, 0.0988, 0.0990, 0.0984, 0.0979,\n",
      "         0.1009],\n",
      "        [0.0903, 0.1013, 0.1011, 0.1017, 0.1017, 0.1022, 0.1027, 0.1016, 0.1012,\n",
      "         0.0961],\n",
      "        [0.0878, 0.1012, 0.1017, 0.1026, 0.1027, 0.1032, 0.1036, 0.1022, 0.1017,\n",
      "         0.0933],\n",
      "        [0.0853, 0.1007, 0.1020, 0.1031, 0.1034, 0.1040, 0.1045, 0.1029, 0.1024,\n",
      "         0.0917],\n",
      "        [0.0830, 0.1003, 0.1023, 0.1037, 0.1041, 0.1047, 0.1052, 0.1036, 0.1031,\n",
      "         0.0900],\n",
      "        [0.0816, 0.1001, 0.1026, 0.1041, 0.1046, 0.1052, 0.1057, 0.1040, 0.1034,\n",
      "         0.0888],\n",
      "        [0.0808, 0.1001, 0.1028, 0.1044, 0.1049, 0.1055, 0.1060, 0.1041, 0.1035,\n",
      "         0.0878],\n",
      "        [0.0801, 0.1001, 0.1030, 0.1046, 0.1052, 0.1057, 0.1062, 0.1043, 0.1036,\n",
      "         0.0871],\n",
      "        [0.0797, 0.1001, 0.1031, 0.1048, 0.1054, 0.1059, 0.1064, 0.1044, 0.1036,\n",
      "         0.0866]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 想 过 要 放弃 但 我 的 父亲 这时\n",
      "Reference: i would want to quit , but my father\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.1056, 0.1017, 0.0999, 0.1002, 0.0998, 0.1001, 0.0998, 0.0983, 0.0985,\n",
      "         0.0960],\n",
      "        [0.0922, 0.1007, 0.1023, 0.1037, 0.1039, 0.1046, 0.1049, 0.1041, 0.0986,\n",
      "         0.0849],\n",
      "        [0.0904, 0.1014, 0.1036, 0.1052, 0.1055, 0.1062, 0.1065, 0.1054, 0.0960,\n",
      "         0.0797],\n",
      "        [0.0883, 0.1016, 0.1045, 0.1064, 0.1067, 0.1076, 0.1080, 0.1069, 0.0945,\n",
      "         0.0755],\n",
      "        [0.0860, 0.1016, 0.1052, 0.1073, 0.1078, 0.1087, 0.1092, 0.1083, 0.0937,\n",
      "         0.0720],\n",
      "        [0.0846, 0.1017, 0.1057, 0.1079, 0.1084, 0.1094, 0.1099, 0.1090, 0.0933,\n",
      "         0.0700],\n",
      "        [0.0837, 0.1018, 0.1061, 0.1083, 0.1089, 0.1098, 0.1104, 0.1095, 0.0929,\n",
      "         0.0686],\n",
      "        [0.0831, 0.1019, 0.1064, 0.1086, 0.1092, 0.1101, 0.1107, 0.1098, 0.0926,\n",
      "         0.0676],\n",
      "        [0.0827, 0.1020, 0.1066, 0.1089, 0.1094, 0.1104, 0.1109, 0.1100, 0.0924,\n",
      "         0.0669]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 30.00, Train Loss: 3.90, Val Loss: 10.25, Train BLEU: 2.91, Val BLEU: 0.22\n",
      "Sampling from training predictions...\n",
      "Source: 我们 将 用 一些 影片 来讲 讲述 一些 深海 海里\n",
      "Reference: and we &apos;re going to tell you some stories\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.1037, 0.0992, 0.0986, 0.0997, 0.0998, 0.0994, 0.0990, 0.0989, 0.0989,\n",
      "         0.1028],\n",
      "        [0.0907, 0.0982, 0.1003, 0.1021, 0.1026, 0.1024, 0.1022, 0.1022, 0.1020,\n",
      "         0.0974],\n",
      "        [0.0885, 0.0981, 0.1008, 0.1028, 0.1034, 0.1032, 0.1030, 0.1029, 0.1024,\n",
      "         0.0948],\n",
      "        [0.0863, 0.0979, 0.1011, 0.1033, 0.1040, 0.1039, 0.1038, 0.1036, 0.1031,\n",
      "         0.0931],\n",
      "        [0.0839, 0.0977, 0.1015, 0.1038, 0.1046, 0.1046, 0.1045, 0.1044, 0.1037,\n",
      "         0.0912],\n",
      "        [0.0825, 0.0978, 0.1018, 0.1042, 0.1050, 0.1051, 0.1050, 0.1048, 0.1040,\n",
      "         0.0897],\n",
      "        [0.0817, 0.0978, 0.1021, 0.1045, 0.1053, 0.1054, 0.1053, 0.1051, 0.1041,\n",
      "         0.0887],\n",
      "        [0.0810, 0.0979, 0.1023, 0.1047, 0.1056, 0.1056, 0.1055, 0.1052, 0.1041,\n",
      "         0.0879],\n",
      "        [0.0806, 0.0979, 0.1025, 0.1049, 0.1057, 0.1058, 0.1057, 0.1054, 0.1042,\n",
      "         0.0874]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 都 知道 自己 正 冒 着 生命 的 危险\n",
      "Reference: we all knew we were risking our lives --\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.1038, 0.1003, 0.1001, 0.0991, 0.0994, 0.0989, 0.0989, 0.0983, 0.0987,\n",
      "         0.1025],\n",
      "        [0.0908, 0.0989, 0.1014, 0.1014, 0.1022, 0.1019, 0.1021, 0.1016, 0.1016,\n",
      "         0.0981],\n",
      "        [0.0884, 0.0986, 0.1018, 0.1021, 0.1030, 0.1027, 0.1029, 0.1023, 0.1020,\n",
      "         0.0961],\n",
      "        [0.0861, 0.0983, 0.1020, 0.1025, 0.1036, 0.1034, 0.1036, 0.1030, 0.1026,\n",
      "         0.0949],\n",
      "        [0.0838, 0.0980, 0.1023, 0.1030, 0.1042, 0.1040, 0.1043, 0.1037, 0.1032,\n",
      "         0.0935],\n",
      "        [0.0823, 0.0979, 0.1026, 0.1035, 0.1046, 0.1045, 0.1047, 0.1041, 0.1034,\n",
      "         0.0923],\n",
      "        [0.0814, 0.0979, 0.1028, 0.1038, 0.1049, 0.1048, 0.1050, 0.1043, 0.1035,\n",
      "         0.0915],\n",
      "        [0.0808, 0.0980, 0.1030, 0.1040, 0.1051, 0.1051, 0.1052, 0.1045, 0.1036,\n",
      "         0.0908],\n",
      "        [0.0803, 0.0980, 0.1031, 0.1042, 0.1053, 0.1052, 0.1054, 0.1046, 0.1036,\n",
      "         0.0903]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 31.00, Train Loss: 3.87, Val Loss: 10.35, Train BLEU: 2.91, Val BLEU: 0.23\n",
      "Sampling from training predictions...\n",
      "Source: 它 可以 伸展 <UNK> 150 英尺 长 <EOS> <PAD> <PAD>\n",
      "Reference: it gets up to about 150 feet long .\n",
      "Model: <SOS> it the the the <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0920, 0.0894, 0.0900, 0.0932, 0.0926, 0.0879, 0.0859, 0.0616, 0.1537,\n",
      "         0.1537],\n",
      "        [0.0771, 0.0847, 0.0878, 0.0924, 0.0902, 0.0860, 0.0833, 0.0503, 0.1741,\n",
      "         0.1741],\n",
      "        [0.0536, 0.0599, 0.0625, 0.0660, 0.0642, 0.0612, 0.0588, 0.0320, 0.2709,\n",
      "         0.2709],\n",
      "        [0.0301, 0.0348, 0.0366, 0.0387, 0.0377, 0.0360, 0.0345, 0.0165, 0.3676,\n",
      "         0.3676],\n",
      "        [0.0136, 0.0165, 0.0174, 0.0185, 0.0180, 0.0172, 0.0164, 0.0071, 0.4377,\n",
      "         0.4377],\n",
      "        [0.0068, 0.0085, 0.0090, 0.0096, 0.0093, 0.0089, 0.0085, 0.0034, 0.4680,\n",
      "         0.4680],\n",
      "        [0.0046, 0.0058, 0.0062, 0.0066, 0.0064, 0.0061, 0.0058, 0.0023, 0.4781,\n",
      "         0.4781],\n",
      "        [0.0038, 0.0049, 0.0052, 0.0056, 0.0053, 0.0051, 0.0048, 0.0018, 0.4817,\n",
      "         0.4817],\n",
      "        [0.0035, 0.0044, 0.0047, 0.0051, 0.0049, 0.0047, 0.0044, 0.0017, 0.4834,\n",
      "         0.4834]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 总是 担心 会 被 塔利 塔利班 发现 <EOS> <PAD>\n",
      "Reference: we always wondered what they knew about us .\n",
      "Model: <SOS> it the the the the . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.1011, 0.1037, 0.1001, 0.0994, 0.0988, 0.0993, 0.0996, 0.0994, 0.0979,\n",
      "         0.1008],\n",
      "        [0.0895, 0.1012, 0.1013, 0.1019, 0.1018, 0.1025, 0.1030, 0.1024, 0.1007,\n",
      "         0.0956],\n",
      "        [0.0873, 0.1010, 0.1017, 0.1025, 0.1026, 0.1033, 0.1038, 0.1029, 0.1013,\n",
      "         0.0937],\n",
      "        [0.0851, 0.1007, 0.1020, 0.1030, 0.1032, 0.1039, 0.1045, 0.1034, 0.1019,\n",
      "         0.0923],\n",
      "        [0.0827, 0.1004, 0.1024, 0.1037, 0.1040, 0.1047, 0.1053, 0.1040, 0.1025,\n",
      "         0.0904],\n",
      "        [0.0812, 0.1002, 0.1028, 0.1042, 0.1045, 0.1052, 0.1058, 0.1043, 0.1029,\n",
      "         0.0889],\n",
      "        [0.0802, 0.1002, 0.1030, 0.1045, 0.1049, 0.1056, 0.1061, 0.1045, 0.1030,\n",
      "         0.0879],\n",
      "        [0.0796, 0.1002, 0.1033, 0.1048, 0.1052, 0.1058, 0.1064, 0.1046, 0.1031,\n",
      "         0.0871],\n",
      "        [0.0791, 0.1002, 0.1034, 0.1050, 0.1054, 0.1060, 0.1065, 0.1047, 0.1031,\n",
      "         0.0866]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32.00, Train Loss: 3.84, Val Loss: 10.42, Train BLEU: 4.82, Val BLEU: 0.23\n",
      "Sampling from training predictions...\n",
      "Source: 和 我们 合作 的 人们 帮 我们 找到 了 新\n",
      "Reference: people that have partnered with us have given us\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.1024, 0.0992, 0.0999, 0.0996, 0.1002, 0.0995, 0.0995, 0.0993, 0.0981,\n",
      "         0.1022],\n",
      "        [0.0910, 0.0986, 0.1015, 0.1019, 0.1028, 0.1022, 0.1024, 0.1020, 0.1004,\n",
      "         0.0973],\n",
      "        [0.0891, 0.0983, 0.1018, 0.1024, 0.1033, 0.1028, 0.1030, 0.1025, 0.1009,\n",
      "         0.0960],\n",
      "        [0.0873, 0.0982, 0.1020, 0.1027, 0.1038, 0.1033, 0.1035, 0.1029, 0.1013,\n",
      "         0.0950],\n",
      "        [0.0851, 0.0982, 0.1024, 0.1033, 0.1044, 0.1040, 0.1041, 0.1035, 0.1018,\n",
      "         0.0932],\n",
      "        [0.0836, 0.0982, 0.1028, 0.1038, 0.1048, 0.1045, 0.1046, 0.1039, 0.1020,\n",
      "         0.0918],\n",
      "        [0.0827, 0.0983, 0.1030, 0.1041, 0.1051, 0.1049, 0.1049, 0.1041, 0.1021,\n",
      "         0.0908],\n",
      "        [0.0821, 0.0983, 0.1032, 0.1043, 0.1053, 0.1051, 0.1051, 0.1043, 0.1022,\n",
      "         0.0901],\n",
      "        [0.0816, 0.0984, 0.1033, 0.1045, 0.1055, 0.1053, 0.1052, 0.1044, 0.1022,\n",
      "         0.0896]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正 的 学校 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: a real school . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.1062, 0.1019, 0.1009, 0.1004, 0.1006, 0.1011, 0.1009, 0.1002, 0.1036,\n",
      "         0.0843],\n",
      "        [0.0936, 0.1018, 0.1039, 0.1041, 0.1048, 0.1055, 0.1058, 0.1054, 0.1063,\n",
      "         0.0688],\n",
      "        [0.0919, 0.1023, 0.1050, 0.1055, 0.1062, 0.1069, 0.1072, 0.1066, 0.1063,\n",
      "         0.0622],\n",
      "        [0.0892, 0.1027, 0.1061, 0.1069, 0.1077, 0.1083, 0.1087, 0.1080, 0.1064,\n",
      "         0.0559],\n",
      "        [0.0867, 0.1029, 0.1070, 0.1079, 0.1088, 0.1094, 0.1098, 0.1091, 0.1064,\n",
      "         0.0519],\n",
      "        [0.0851, 0.1032, 0.1076, 0.1087, 0.1096, 0.1101, 0.1105, 0.1097, 0.1061,\n",
      "         0.0495],\n",
      "        [0.0842, 0.1033, 0.1080, 0.1092, 0.1101, 0.1105, 0.1109, 0.1100, 0.1058,\n",
      "         0.0480],\n",
      "        [0.0836, 0.1035, 0.1083, 0.1095, 0.1104, 0.1108, 0.1111, 0.1102, 0.1055,\n",
      "         0.0472],\n",
      "        [0.0832, 0.1035, 0.1085, 0.1097, 0.1106, 0.1110, 0.1113, 0.1103, 0.1053,\n",
      "         0.0466]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 33.00, Train Loss: 3.82, Val Loss: 10.46, Train BLEU: 6.89, Val BLEU: 0.23\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地 地球 上 最长 的 山脉 都 在 海洋\n",
      "Reference: and in the oceans , there are the longest\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.1039, 0.0995, 0.0992, 0.0991, 0.0999, 0.0991, 0.0993, 0.0978, 0.0978,\n",
      "         0.1043],\n",
      "        [0.0914, 0.0987, 0.1009, 0.1016, 0.1027, 0.1021, 0.1025, 0.1008, 0.1005,\n",
      "         0.0987],\n",
      "        [0.0896, 0.0986, 0.1013, 0.1021, 0.1034, 0.1028, 0.1031, 0.1013, 0.1009,\n",
      "         0.0968],\n",
      "        [0.0878, 0.0986, 0.1017, 0.1027, 0.1039, 0.1034, 0.1037, 0.1019, 0.1013,\n",
      "         0.0949],\n",
      "        [0.0852, 0.0987, 0.1023, 0.1035, 0.1047, 0.1043, 0.1045, 0.1027, 0.1018,\n",
      "         0.0923],\n",
      "        [0.0835, 0.0988, 0.1028, 0.1041, 0.1053, 0.1049, 0.1050, 0.1032, 0.1020,\n",
      "         0.0904],\n",
      "        [0.0825, 0.0988, 0.1030, 0.1044, 0.1056, 0.1053, 0.1054, 0.1036, 0.1021,\n",
      "         0.0892],\n",
      "        [0.0818, 0.0988, 0.1032, 0.1047, 0.1059, 0.1055, 0.1056, 0.1038, 0.1022,\n",
      "         0.0885],\n",
      "        [0.0813, 0.0989, 0.1034, 0.1048, 0.1060, 0.1057, 0.1058, 0.1039, 0.1023,\n",
      "         0.0880]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6 岁 那年 塔利 塔利班 占领 阿富汗 并 规定\n",
      "Reference: you see , i was six when the taliban\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0899, 0.0848, 0.0850, 0.0861, 0.0854, 0.0838, 0.0826, 0.0833, 0.0631,\n",
      "         0.2560],\n",
      "        [0.0734, 0.0790, 0.0815, 0.0832, 0.0827, 0.0814, 0.0805, 0.0796, 0.0504,\n",
      "         0.3083],\n",
      "        [0.0517, 0.0569, 0.0589, 0.0601, 0.0598, 0.0589, 0.0581, 0.0569, 0.0331,\n",
      "         0.5056],\n",
      "        [0.0293, 0.0336, 0.0350, 0.0357, 0.0356, 0.0351, 0.0346, 0.0335, 0.0173,\n",
      "         0.7104],\n",
      "        [0.0133, 0.0160, 0.0168, 0.0172, 0.0171, 0.0169, 0.0167, 0.0160, 0.0075,\n",
      "         0.8625],\n",
      "        [0.0067, 0.0084, 0.0088, 0.0090, 0.0090, 0.0089, 0.0088, 0.0083, 0.0037,\n",
      "         0.9282],\n",
      "        [0.0047, 0.0059, 0.0062, 0.0064, 0.0064, 0.0063, 0.0062, 0.0058, 0.0025,\n",
      "         0.9495],\n",
      "        [0.0040, 0.0051, 0.0053, 0.0055, 0.0055, 0.0054, 0.0053, 0.0050, 0.0021,\n",
      "         0.9569],\n",
      "        [0.0037, 0.0047, 0.0050, 0.0051, 0.0051, 0.0050, 0.0050, 0.0046, 0.0019,\n",
      "         0.9600]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 34.00, Train Loss: 3.79, Val Loss: 10.51, Train BLEU: 8.50, Val BLEU: 1.05\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中 的 生命 大卫 <UNK> <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: life in the deep oceans <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the . <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0545, 0.0512, 0.0503, 0.0505, 0.0511, 0.0453, 0.0380, 0.2197, 0.2197,\n",
      "         0.2197],\n",
      "        [0.0422, 0.0451, 0.0456, 0.0463, 0.0469, 0.0372, 0.0274, 0.2365, 0.2365,\n",
      "         0.2365],\n",
      "        [0.0200, 0.0221, 0.0224, 0.0228, 0.0229, 0.0172, 0.0120, 0.2869, 0.2869,\n",
      "         0.2869],\n",
      "        [0.0060, 0.0071, 0.0073, 0.0074, 0.0074, 0.0051, 0.0033, 0.3188, 0.3188,\n",
      "         0.3188],\n",
      "        [0.0024, 0.0029, 0.0031, 0.0031, 0.0031, 0.0020, 0.0013, 0.3274, 0.3274,\n",
      "         0.3274],\n",
      "        [0.0015, 0.0019, 0.0020, 0.0020, 0.0020, 0.0013, 0.0008, 0.3295, 0.3295,\n",
      "         0.3295],\n",
      "        [0.0013, 0.0016, 0.0016, 0.0017, 0.0017, 0.0011, 0.0006, 0.3302, 0.3302,\n",
      "         0.3302],\n",
      "        [0.0011, 0.0014, 0.0015, 0.0015, 0.0015, 0.0010, 0.0006, 0.3305, 0.3305,\n",
      "         0.3305],\n",
      "        [0.0011, 0.0014, 0.0014, 0.0014, 0.0014, 0.0009, 0.0005, 0.3306, 0.3306,\n",
      "         0.3306]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11 岁 那年 记得 得有 一天 早晨 醒来 听见\n",
      "Reference: when i was 11 , i remember waking up\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[0.0545, 0.0512, 0.0503, 0.0505, 0.0511, 0.0453, 0.0380, 0.2197, 0.2197,\n",
      "         0.2197],\n",
      "        [0.0422, 0.0451, 0.0456, 0.0463, 0.0469, 0.0372, 0.0274, 0.2365, 0.2365,\n",
      "         0.2365],\n",
      "        [0.0200, 0.0221, 0.0224, 0.0228, 0.0229, 0.0172, 0.0120, 0.2869, 0.2869,\n",
      "         0.2869],\n",
      "        [0.0060, 0.0071, 0.0073, 0.0074, 0.0074, 0.0051, 0.0033, 0.3188, 0.3188,\n",
      "         0.3188],\n",
      "        [0.0024, 0.0029, 0.0031, 0.0031, 0.0031, 0.0020, 0.0013, 0.3274, 0.3274,\n",
      "         0.3274],\n",
      "        [0.0015, 0.0019, 0.0020, 0.0020, 0.0020, 0.0013, 0.0008, 0.3295, 0.3295,\n",
      "         0.3295],\n",
      "        [0.0013, 0.0016, 0.0016, 0.0017, 0.0017, 0.0011, 0.0006, 0.3302, 0.3302,\n",
      "         0.3302],\n",
      "        [0.0011, 0.0014, 0.0015, 0.0015, 0.0015, 0.0010, 0.0006, 0.3305, 0.3305,\n",
      "         0.3305],\n",
      "        [0.0011, 0.0014, 0.0014, 0.0014, 0.0014, 0.0009, 0.0005, 0.3306, 0.3306,\n",
      "         0.3306]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 35.00, Train Loss: 3.76, Val Loss: 10.56, Train BLEU: 8.48, Val BLEU: 1.08\n",
      "Sampling from training predictions...\n",
      "Source: 和 我们 合作 的 人们 帮 我们 找到 了 新\n",
      "Reference: people that have partnered with us have given us\n",
      "Model: <SOS> it &apos;s the the the the the the ,\n",
      "Attention Weights: tensor([[0.1027, 0.0982, 0.0998, 0.0997, 0.1006, 0.0997, 0.0999, 0.0994, 0.0977,\n",
      "         0.1022],\n",
      "        [0.0915, 0.0979, 0.1016, 0.1020, 0.1031, 0.1023, 0.1025, 0.1018, 0.0998,\n",
      "         0.0976],\n",
      "        [0.0901, 0.0980, 0.1019, 0.1025, 0.1036, 0.1028, 0.1029, 0.1021, 0.0998,\n",
      "         0.0963],\n",
      "        [0.0888, 0.0982, 0.1023, 0.1029, 0.1040, 0.1033, 0.1033, 0.1024, 0.0999,\n",
      "         0.0949],\n",
      "        [0.0867, 0.0983, 0.1028, 0.1036, 0.1047, 0.1040, 0.1040, 0.1029, 0.1002,\n",
      "         0.0927],\n",
      "        [0.0849, 0.0985, 0.1033, 0.1042, 0.1053, 0.1046, 0.1045, 0.1034, 0.1003,\n",
      "         0.0910],\n",
      "        [0.0839, 0.0986, 0.1035, 0.1045, 0.1056, 0.1050, 0.1048, 0.1036, 0.1004,\n",
      "         0.0900],\n",
      "        [0.0831, 0.0986, 0.1037, 0.1048, 0.1058, 0.1052, 0.1051, 0.1038, 0.1005,\n",
      "         0.0893],\n",
      "        [0.0826, 0.0986, 0.1038, 0.1049, 0.1060, 0.1054, 0.1052, 0.1039, 0.1006,\n",
      "         0.0889]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在 一个 房屋 房屋里 屋里 我们 100 多 人\n",
      "Reference: the school was in a house , more than\n",
      "Model: <SOS> it &apos;s the the the the the the ,\n",
      "Attention Weights: tensor([[0.1029, 0.1029, 0.0993, 0.0996, 0.0991, 0.0998, 0.0991, 0.0976, 0.0969,\n",
      "         0.1027],\n",
      "        [0.0908, 0.1011, 0.1010, 0.1023, 0.1020, 0.1029, 0.1022, 0.1006, 0.0995,\n",
      "         0.0976],\n",
      "        [0.0892, 0.1011, 0.1014, 0.1029, 0.1027, 0.1036, 0.1027, 0.1009, 0.0997,\n",
      "         0.0958],\n",
      "        [0.0875, 0.1011, 0.1020, 0.1035, 0.1033, 0.1041, 0.1032, 0.1014, 0.0999,\n",
      "         0.0940],\n",
      "        [0.0847, 0.1006, 0.1027, 0.1044, 0.1043, 0.1051, 0.1042, 0.1023, 0.1005,\n",
      "         0.0913],\n",
      "        [0.0828, 0.1003, 0.1033, 0.1050, 0.1050, 0.1057, 0.1048, 0.1030, 0.1008,\n",
      "         0.0893],\n",
      "        [0.0816, 0.1000, 0.1037, 0.1054, 0.1054, 0.1061, 0.1052, 0.1033, 0.1009,\n",
      "         0.0882],\n",
      "        [0.0808, 0.0999, 0.1039, 0.1056, 0.1057, 0.1064, 0.1055, 0.1036, 0.1011,\n",
      "         0.0876],\n",
      "        [0.0802, 0.0998, 0.1041, 0.1058, 0.1059, 0.1066, 0.1057, 0.1038, 0.1012,\n",
      "         0.0871]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36.00, Train Loss: 3.74, Val Loss: 10.62, Train BLEU: 7.99, Val BLEU: 1.06\n",
      "Sampling from training predictions...\n",
      "Source: 当 你 站 在 海滩 上 或是 当 你 看到\n",
      "Reference: part of the problem , i think , is\n",
      "Model: <SOS> it &apos;s the the the the the , ,\n",
      "Attention Weights: tensor([[0.1014, 0.0973, 0.0985, 0.1000, 0.1012, 0.1003, 0.1009, 0.0990, 0.0981,\n",
      "         0.1033],\n",
      "        [0.0910, 0.0974, 0.1002, 0.1022, 0.1036, 0.1027, 0.1034, 0.1014, 0.1001,\n",
      "         0.0980],\n",
      "        [0.0897, 0.0975, 0.1006, 0.1027, 0.1041, 0.1033, 0.1038, 0.1016, 0.1001,\n",
      "         0.0965],\n",
      "        [0.0888, 0.0977, 0.1010, 0.1031, 0.1046, 0.1037, 0.1042, 0.1019, 0.1002,\n",
      "         0.0949],\n",
      "        [0.0869, 0.0981, 0.1017, 0.1038, 0.1053, 0.1044, 0.1048, 0.1025, 0.1004,\n",
      "         0.0921],\n",
      "        [0.0853, 0.0984, 0.1023, 0.1045, 0.1059, 0.1050, 0.1054, 0.1030, 0.1006,\n",
      "         0.0898],\n",
      "        [0.0842, 0.0985, 0.1027, 0.1049, 0.1063, 0.1054, 0.1057, 0.1033, 0.1006,\n",
      "         0.0884],\n",
      "        [0.0834, 0.0986, 0.1029, 0.1051, 0.1065, 0.1057, 0.1059, 0.1035, 0.1007,\n",
      "         0.0876],\n",
      "        [0.0828, 0.0987, 0.1031, 0.1053, 0.1067, 0.1059, 0.1061, 0.1036, 0.1008,\n",
      "         0.0871]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 都 知道 自己 正 冒 着 生命 的 危险\n",
      "Reference: we all knew we were risking our lives --\n",
      "Model: <SOS> it &apos;s the the the the the , ,\n",
      "Attention Weights: tensor([[0.1017, 0.0986, 0.1005, 0.0995, 0.1006, 0.0998, 0.1001, 0.0993, 0.0988,\n",
      "         0.1011],\n",
      "        [0.0907, 0.0981, 0.1021, 0.1016, 0.1030, 0.1023, 0.1027, 0.1017, 0.1008,\n",
      "         0.0970],\n",
      "        [0.0893, 0.0982, 0.1025, 0.1021, 0.1035, 0.1028, 0.1031, 0.1020, 0.1008,\n",
      "         0.0958],\n",
      "        [0.0881, 0.0984, 0.1028, 0.1025, 0.1039, 0.1032, 0.1035, 0.1022, 0.1008,\n",
      "         0.0945],\n",
      "        [0.0859, 0.0985, 0.1034, 0.1032, 0.1046, 0.1040, 0.1041, 0.1028, 0.1009,\n",
      "         0.0925],\n",
      "        [0.0839, 0.0987, 0.1039, 0.1039, 0.1053, 0.1046, 0.1047, 0.1033, 0.1011,\n",
      "         0.0907],\n",
      "        [0.0827, 0.0988, 0.1042, 0.1043, 0.1057, 0.1050, 0.1050, 0.1035, 0.1011,\n",
      "         0.0896],\n",
      "        [0.0818, 0.0988, 0.1044, 0.1046, 0.1059, 0.1053, 0.1052, 0.1037, 0.1012,\n",
      "         0.0890],\n",
      "        [0.0811, 0.0988, 0.1045, 0.1048, 0.1061, 0.1055, 0.1054, 0.1039, 0.1013,\n",
      "         0.0886]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 37.00, Train Loss: 3.71, Val Loss: 10.66, Train BLEU: 8.42, Val BLEU: 1.06\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一只 水母 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: here &apos;s a jelly . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the . . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0429, 0.0407, 0.0411, 0.0414, 0.0321, 0.1604, 0.1604, 0.1604, 0.1604,\n",
      "         0.1604],\n",
      "        [0.0412, 0.0439, 0.0452, 0.0450, 0.0291, 0.1591, 0.1591, 0.1591, 0.1591,\n",
      "         0.1591],\n",
      "        [0.0221, 0.0241, 0.0248, 0.0247, 0.0143, 0.1780, 0.1780, 0.1780, 0.1780,\n",
      "         0.1780],\n",
      "        [0.0075, 0.0086, 0.0089, 0.0088, 0.0044, 0.1924, 0.1924, 0.1924, 0.1924,\n",
      "         0.1924],\n",
      "        [0.0029, 0.0035, 0.0036, 0.0035, 0.0016, 0.1970, 0.1970, 0.1970, 0.1970,\n",
      "         0.1970],\n",
      "        [0.0018, 0.0022, 0.0023, 0.0022, 0.0009, 0.1981, 0.1981, 0.1981, 0.1981,\n",
      "         0.1981],\n",
      "        [0.0014, 0.0018, 0.0018, 0.0018, 0.0007, 0.1985, 0.1985, 0.1985, 0.1985,\n",
      "         0.1985],\n",
      "        [0.0013, 0.0016, 0.0016, 0.0016, 0.0006, 0.1987, 0.1987, 0.1987, 0.1987,\n",
      "         0.1987],\n",
      "        [0.0012, 0.0015, 0.0016, 0.0015, 0.0006, 0.1987, 0.1987, 0.1987, 0.1987,\n",
      "         0.1987]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 祖父 在 他 的 年代 是 位非 非凡\n",
      "Reference: my grandfather was an extraordinary man for his time\n",
      "Model: <SOS> it &apos;s the the the the the , ,\n",
      "Attention Weights: tensor([[0.1043, 0.0987, 0.1001, 0.1019, 0.1016, 0.1021, 0.1004, 0.0992, 0.1008,\n",
      "         0.0909],\n",
      "        [0.0932, 0.0995, 0.1030, 0.1053, 0.1052, 0.1059, 0.1043, 0.1033, 0.1038,\n",
      "         0.0764],\n",
      "        [0.0923, 0.1001, 0.1039, 0.1064, 0.1063, 0.1069, 0.1051, 0.1038, 0.1042,\n",
      "         0.0711],\n",
      "        [0.0913, 0.1008, 0.1049, 0.1074, 0.1073, 0.1079, 0.1059, 0.1045, 0.1043,\n",
      "         0.0657],\n",
      "        [0.0896, 0.1016, 0.1060, 0.1086, 0.1085, 0.1091, 0.1070, 0.1054, 0.1043,\n",
      "         0.0597],\n",
      "        [0.0879, 0.1023, 0.1070, 0.1096, 0.1095, 0.1100, 0.1079, 0.1061, 0.1041,\n",
      "         0.0556],\n",
      "        [0.0867, 0.1026, 0.1076, 0.1102, 0.1102, 0.1106, 0.1085, 0.1065, 0.1039,\n",
      "         0.0532],\n",
      "        [0.0859, 0.1029, 0.1080, 0.1106, 0.1105, 0.1109, 0.1089, 0.1068, 0.1037,\n",
      "         0.0518],\n",
      "        [0.0853, 0.1030, 0.1082, 0.1108, 0.1108, 0.1112, 0.1091, 0.1070, 0.1037,\n",
      "         0.0510]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 38.00, Train Loss: 3.69, Val Loss: 10.70, Train BLEU: 8.49, Val BLEU: 1.07\n",
      "Sampling from training predictions...\n",
      "Source: 还有 前面 的 这个 是 推进 引擎 它 一会 一会儿\n",
      "Reference: and it &apos;s got these jet thrusters up in\n",
      "Model: <SOS> it &apos;s the the the , , , ,\n",
      "Attention Weights: tensor([[0.1037, 0.0988, 0.0991, 0.1006, 0.1001, 0.1006, 0.0998, 0.0973, 0.0985,\n",
      "         0.1015],\n",
      "        [0.0923, 0.0994, 0.1022, 0.1044, 0.1041, 0.1049, 0.1045, 0.1031, 0.0976,\n",
      "         0.0877],\n",
      "        [0.0912, 0.0998, 0.1028, 0.1051, 0.1048, 0.1055, 0.1051, 0.1039, 0.0965,\n",
      "         0.0852],\n",
      "        [0.0905, 0.1006, 0.1038, 0.1061, 0.1057, 0.1064, 0.1059, 0.1047, 0.0948,\n",
      "         0.0813],\n",
      "        [0.0884, 0.1017, 0.1054, 0.1077, 0.1074, 0.1080, 0.1074, 0.1061, 0.0929,\n",
      "         0.0751],\n",
      "        [0.0865, 0.1023, 0.1065, 0.1089, 0.1086, 0.1091, 0.1084, 0.1069, 0.0917,\n",
      "         0.0712],\n",
      "        [0.0851, 0.1027, 0.1072, 0.1096, 0.1093, 0.1098, 0.1091, 0.1075, 0.0910,\n",
      "         0.0686],\n",
      "        [0.0841, 0.1030, 0.1077, 0.1101, 0.1098, 0.1103, 0.1095, 0.1078, 0.0906,\n",
      "         0.0671],\n",
      "        [0.0835, 0.1031, 0.1080, 0.1104, 0.1101, 0.1106, 0.1098, 0.1081, 0.0903,\n",
      "         0.0661]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 在 塔利 塔利班 控制 阿富汗 的 那些 年 我 记得\n",
      "Reference: during taliban years , i remember there were times\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.1031, 0.0989, 0.0990, 0.1000, 0.1002, 0.1006, 0.0992, 0.0985, 0.1008,\n",
      "         0.0997],\n",
      "        [0.0921, 0.0998, 0.1024, 0.1039, 0.1045, 0.1052, 0.1039, 0.1036, 0.1042,\n",
      "         0.0804],\n",
      "        [0.0915, 0.1007, 0.1036, 0.1052, 0.1058, 0.1063, 0.1048, 0.1043, 0.1042,\n",
      "         0.0735],\n",
      "        [0.0900, 0.1018, 0.1053, 0.1069, 0.1075, 0.1079, 0.1062, 0.1054, 0.1035,\n",
      "         0.0654],\n",
      "        [0.0882, 0.1028, 0.1067, 0.1085, 0.1090, 0.1093, 0.1076, 0.1062, 0.1024,\n",
      "         0.0593],\n",
      "        [0.0869, 0.1034, 0.1077, 0.1095, 0.1099, 0.1102, 0.1084, 0.1067, 0.1015,\n",
      "         0.0558],\n",
      "        [0.0859, 0.1038, 0.1083, 0.1101, 0.1105, 0.1108, 0.1089, 0.1070, 0.1009,\n",
      "         0.0538],\n",
      "        [0.0852, 0.1040, 0.1087, 0.1105, 0.1109, 0.1111, 0.1092, 0.1072, 0.1006,\n",
      "         0.0526],\n",
      "        [0.0846, 0.1041, 0.1090, 0.1108, 0.1112, 0.1114, 0.1095, 0.1074, 0.1004,\n",
      "         0.0517]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 39.00, Train Loss: 3.66, Val Loss: 10.74, Train BLEU: 6.88, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一种 种群 栖 动物 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: it &apos;s a colonial animal . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the . . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0439, 0.0423, 0.0433, 0.0432, 0.0422, 0.0423, 0.0332, 0.2365, 0.2365,\n",
      "         0.2365],\n",
      "        [0.0439, 0.0474, 0.0493, 0.0494, 0.0486, 0.0483, 0.0317, 0.2271, 0.2271,\n",
      "         0.2271],\n",
      "        [0.0289, 0.0319, 0.0332, 0.0333, 0.0326, 0.0324, 0.0192, 0.2628, 0.2628,\n",
      "         0.2628],\n",
      "        [0.0118, 0.0137, 0.0143, 0.0144, 0.0141, 0.0138, 0.0070, 0.3036, 0.3036,\n",
      "         0.3036],\n",
      "        [0.0047, 0.0057, 0.0060, 0.0060, 0.0059, 0.0057, 0.0026, 0.3211, 0.3211,\n",
      "         0.3211],\n",
      "        [0.0028, 0.0035, 0.0037, 0.0037, 0.0036, 0.0035, 0.0015, 0.3259, 0.3259,\n",
      "         0.3259],\n",
      "        [0.0022, 0.0028, 0.0030, 0.0030, 0.0029, 0.0027, 0.0011, 0.3274, 0.3274,\n",
      "         0.3274],\n",
      "        [0.0020, 0.0025, 0.0026, 0.0026, 0.0026, 0.0024, 0.0010, 0.3281, 0.3281,\n",
      "         0.3281],\n",
      "        [0.0019, 0.0023, 0.0025, 0.0025, 0.0024, 0.0023, 0.0009, 0.3284, 0.3284,\n",
      "         0.3284]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 有时 学校 <UNK> 突然 <UNK> 一周 因为 被 塔利 塔利班\n",
      "Reference: from time to time , the school would suddenly\n",
      "Model: <SOS> it &apos;s the the the , , , ,\n",
      "Attention Weights: tensor([[0.0997, 0.0974, 0.0997, 0.1018, 0.1013, 0.1015, 0.1008, 0.0997, 0.0980,\n",
      "         0.1003],\n",
      "        [0.0899, 0.0972, 0.1010, 0.1034, 0.1031, 0.1035, 0.1028, 0.1018, 0.1000,\n",
      "         0.0973],\n",
      "        [0.0890, 0.0974, 0.1015, 0.1040, 0.1036, 0.1040, 0.1031, 0.1018, 0.0995,\n",
      "         0.0961],\n",
      "        [0.0880, 0.0978, 0.1020, 0.1045, 0.1041, 0.1044, 0.1034, 0.1019, 0.0993,\n",
      "         0.0946],\n",
      "        [0.0859, 0.0982, 0.1028, 0.1053, 0.1050, 0.1052, 0.1041, 0.1024, 0.0993,\n",
      "         0.0918],\n",
      "        [0.0843, 0.0986, 0.1034, 0.1059, 0.1057, 0.1058, 0.1046, 0.1027, 0.0993,\n",
      "         0.0897],\n",
      "        [0.0832, 0.0988, 0.1038, 0.1063, 0.1061, 0.1061, 0.1049, 0.1029, 0.0992,\n",
      "         0.0885],\n",
      "        [0.0824, 0.0989, 0.1041, 0.1066, 0.1063, 0.1064, 0.1052, 0.1031, 0.0992,\n",
      "         0.0878],\n",
      "        [0.0817, 0.0990, 0.1043, 0.1067, 0.1065, 0.1065, 0.1053, 0.1032, 0.0993,\n",
      "         0.0874]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40.00, Train Loss: 3.64, Val Loss: 10.79, Train BLEU: 6.91, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 但 我 想 告诉 你 的 是 当 你 站\n",
      "Reference: but when you &apos;re standing at the beach ,\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0985, 0.0974, 0.0999, 0.1021, 0.1015, 0.1018, 0.1011, 0.1000, 0.0981,\n",
      "         0.0995],\n",
      "        [0.0894, 0.0971, 0.1010, 0.1035, 0.1031, 0.1036, 0.1030, 0.1020, 0.1001,\n",
      "         0.0971],\n",
      "        [0.0883, 0.0973, 0.1015, 0.1041, 0.1037, 0.1041, 0.1033, 0.1020, 0.0997,\n",
      "         0.0960],\n",
      "        [0.0876, 0.0977, 0.1019, 0.1045, 0.1041, 0.1045, 0.1036, 0.1020, 0.0994,\n",
      "         0.0946],\n",
      "        [0.0858, 0.0981, 0.1027, 0.1053, 0.1050, 0.1052, 0.1042, 0.1025, 0.0993,\n",
      "         0.0919],\n",
      "        [0.0842, 0.0985, 0.1034, 0.1060, 0.1057, 0.1058, 0.1047, 0.1028, 0.0992,\n",
      "         0.0897],\n",
      "        [0.0831, 0.0988, 0.1038, 0.1064, 0.1061, 0.1062, 0.1050, 0.1030, 0.0992,\n",
      "         0.0884],\n",
      "        [0.0822, 0.0989, 0.1041, 0.1067, 0.1064, 0.1065, 0.1053, 0.1032, 0.0992,\n",
      "         0.0876],\n",
      "        [0.0815, 0.0990, 0.1043, 0.1069, 0.1066, 0.1067, 0.1054, 0.1033, 0.0992,\n",
      "         0.0871]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 因此 毫无 毫无疑问 无疑 疑问 他 的 孩子 应当 受到\n",
      "Reference: there was no question that his children would receive\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0819, 0.0805, 0.0819, 0.0818, 0.0832, 0.0871, 0.0796, 0.0782, 0.0605,\n",
      "         0.2852],\n",
      "        [0.0757, 0.0831, 0.0862, 0.0867, 0.0884, 0.0920, 0.0852, 0.0834, 0.0547,\n",
      "         0.2646],\n",
      "        [0.0662, 0.0739, 0.0768, 0.0773, 0.0788, 0.0821, 0.0755, 0.0740, 0.0455,\n",
      "         0.3499],\n",
      "        [0.0517, 0.0594, 0.0619, 0.0622, 0.0635, 0.0660, 0.0605, 0.0592, 0.0327,\n",
      "         0.4830],\n",
      "        [0.0344, 0.0411, 0.0431, 0.0434, 0.0441, 0.0457, 0.0421, 0.0408, 0.0203,\n",
      "         0.6451],\n",
      "        [0.0209, 0.0261, 0.0274, 0.0276, 0.0280, 0.0289, 0.0267, 0.0256, 0.0117,\n",
      "         0.7770],\n",
      "        [0.0128, 0.0166, 0.0176, 0.0177, 0.0179, 0.0184, 0.0171, 0.0162, 0.0068,\n",
      "         0.8589],\n",
      "        [0.0094, 0.0124, 0.0131, 0.0132, 0.0134, 0.0137, 0.0127, 0.0119, 0.0049,\n",
      "         0.8952],\n",
      "        [0.0080, 0.0106, 0.0112, 0.0113, 0.0114, 0.0117, 0.0109, 0.0102, 0.0041,\n",
      "         0.9105]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 41.00, Train Loss: 3.61, Val Loss: 10.82, Train BLEU: 6.94, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 是 我 最 喜欢 的 因为 它 哪 都 能动\n",
      "Reference: it &apos;s one of my favorites , because it\n",
      "Model: <SOS> it &apos;s the the the , , , ,\n",
      "Attention Weights: tensor([[0.1023, 0.0989, 0.1009, 0.1029, 0.1026, 0.1031, 0.1011, 0.0993, 0.0993,\n",
      "         0.0896],\n",
      "        [0.0917, 0.0994, 0.1034, 0.1060, 0.1059, 0.1067, 0.1050, 0.1037, 0.1035,\n",
      "         0.0746],\n",
      "        [0.0912, 0.1000, 0.1043, 0.1070, 0.1069, 0.1076, 0.1055, 0.1038, 0.1037,\n",
      "         0.0701],\n",
      "        [0.0905, 0.1008, 0.1053, 0.1081, 0.1079, 0.1085, 0.1062, 0.1043, 0.1038,\n",
      "         0.0647],\n",
      "        [0.0891, 0.1018, 0.1066, 0.1094, 0.1092, 0.1097, 0.1073, 0.1051, 0.1037,\n",
      "         0.0582],\n",
      "        [0.0876, 0.1026, 0.1077, 0.1105, 0.1104, 0.1107, 0.1083, 0.1057, 0.1031,\n",
      "         0.0533],\n",
      "        [0.0863, 0.1032, 0.1085, 0.1113, 0.1112, 0.1115, 0.1090, 0.1062, 0.1026,\n",
      "         0.0502],\n",
      "        [0.0853, 0.1035, 0.1091, 0.1118, 0.1117, 0.1119, 0.1094, 0.1065, 0.1024,\n",
      "         0.0484],\n",
      "        [0.0847, 0.1037, 0.1094, 0.1121, 0.1120, 0.1122, 0.1097, 0.1067, 0.1022,\n",
      "         0.0474]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 很 幸运 幸运地 成长 在 一个 珍视 教育 也\n",
      "Reference: i was very lucky to grow up in a\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0443, 0.0431, 0.0434, 0.0431, 0.0337, 0.1585, 0.1585, 0.1585, 0.1585,\n",
      "         0.1585],\n",
      "        [0.0406, 0.0439, 0.0453, 0.0449, 0.0297, 0.1591, 0.1591, 0.1591, 0.1591,\n",
      "         0.1591],\n",
      "        [0.0248, 0.0274, 0.0282, 0.0280, 0.0166, 0.1750, 0.1750, 0.1750, 0.1750,\n",
      "         0.1750],\n",
      "        [0.0093, 0.0108, 0.0112, 0.0110, 0.0055, 0.1904, 0.1904, 0.1904, 0.1904,\n",
      "         0.1904],\n",
      "        [0.0038, 0.0046, 0.0048, 0.0047, 0.0021, 0.1960, 0.1960, 0.1960, 0.1960,\n",
      "         0.1960],\n",
      "        [0.0023, 0.0029, 0.0030, 0.0029, 0.0012, 0.1975, 0.1975, 0.1975, 0.1975,\n",
      "         0.1975],\n",
      "        [0.0019, 0.0023, 0.0024, 0.0023, 0.0010, 0.1980, 0.1980, 0.1980, 0.1980,\n",
      "         0.1980],\n",
      "        [0.0017, 0.0021, 0.0022, 0.0021, 0.0008, 0.1982, 0.1982, 0.1982, 0.1982,\n",
      "         0.1982],\n",
      "        [0.0016, 0.0020, 0.0021, 0.0019, 0.0008, 0.1983, 0.1983, 0.1983, 0.1983,\n",
      "         0.1983]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 42.00, Train Loss: 3.59, Val Loss: 10.84, Train BLEU: 6.91, Val BLEU: 0.23\n",
      "Sampling from training predictions...\n",
      "Source: 底下 这些 都 是 <UNK> 它们 上上 上上下下 上下 下下\n",
      "Reference: it &apos;s got these fishing <UNK> on the bottom\n",
      "Model: <SOS> it &apos;s the the the the the , ,\n",
      "Attention Weights: tensor([[0.1008, 0.0975, 0.0987, 0.1026, 0.1078, 0.0993, 0.1005, 0.0975, 0.0962,\n",
      "         0.0989],\n",
      "        [0.0905, 0.0987, 0.1029, 0.1092, 0.1041, 0.1047, 0.1062, 0.1032, 0.1010,\n",
      "         0.0795],\n",
      "        [0.0899, 0.0991, 0.1032, 0.1101, 0.1036, 0.1060, 0.1076, 0.1039, 0.1015,\n",
      "         0.0749],\n",
      "        [0.0897, 0.1000, 0.1041, 0.1110, 0.1032, 0.1073, 0.1089, 0.1048, 0.1016,\n",
      "         0.0695],\n",
      "        [0.0882, 0.1012, 0.1057, 0.1123, 0.1024, 0.1092, 0.1104, 0.1061, 0.1018,\n",
      "         0.0625],\n",
      "        [0.0867, 0.1025, 0.1073, 0.1132, 0.1015, 0.1107, 0.1116, 0.1073, 0.1016,\n",
      "         0.0576],\n",
      "        [0.0855, 0.1033, 0.1084, 0.1139, 0.1011, 0.1117, 0.1124, 0.1081, 0.1014,\n",
      "         0.0543],\n",
      "        [0.0845, 0.1038, 0.1091, 0.1143, 0.1010, 0.1124, 0.1128, 0.1086, 0.1011,\n",
      "         0.0522],\n",
      "        [0.0838, 0.1041, 0.1096, 0.1147, 0.1011, 0.1128, 0.1131, 0.1089, 0.1010,\n",
      "         0.0510]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 因此 毫无 毫无疑问 无疑 疑问 他 的 孩子 应当 受到\n",
      "Reference: there was no question that his children would receive\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0778, 0.0765, 0.0778, 0.0779, 0.0792, 0.0834, 0.0756, 0.0741, 0.0581,\n",
      "         0.3197],\n",
      "        [0.0686, 0.0754, 0.0783, 0.0788, 0.0805, 0.0842, 0.0774, 0.0758, 0.0501,\n",
      "         0.3308],\n",
      "        [0.0586, 0.0655, 0.0681, 0.0685, 0.0700, 0.0734, 0.0668, 0.0655, 0.0408,\n",
      "         0.4229],\n",
      "        [0.0423, 0.0490, 0.0512, 0.0515, 0.0525, 0.0550, 0.0499, 0.0488, 0.0269,\n",
      "         0.5730],\n",
      "        [0.0252, 0.0307, 0.0322, 0.0324, 0.0329, 0.0344, 0.0313, 0.0302, 0.0149,\n",
      "         0.7359],\n",
      "        [0.0141, 0.0181, 0.0191, 0.0192, 0.0195, 0.0202, 0.0184, 0.0175, 0.0079,\n",
      "         0.8460],\n",
      "        [0.0090, 0.0119, 0.0126, 0.0127, 0.0128, 0.0132, 0.0121, 0.0113, 0.0048,\n",
      "         0.8996],\n",
      "        [0.0071, 0.0094, 0.0100, 0.0100, 0.0101, 0.0104, 0.0096, 0.0089, 0.0037,\n",
      "         0.9208],\n",
      "        [0.0063, 0.0084, 0.0089, 0.0090, 0.0091, 0.0093, 0.0086, 0.0079, 0.0033,\n",
      "         0.9293]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 43.00, Train Loss: 3.57, Val Loss: 10.87, Train BLEU: 7.48, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 地球 的 大部 大部分 部分 都 是 海水 <EOS> <PAD>\n",
      "Reference: most of the planet is ocean water . <EOS>\n",
      "Model: <SOS> it &apos;s the the the . . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0832, 0.0816, 0.0839, 0.0858, 0.0847, 0.0827, 0.0809, 0.0798, 0.0628,\n",
      "         0.2745],\n",
      "        [0.0719, 0.0786, 0.0827, 0.0849, 0.0841, 0.0824, 0.0812, 0.0798, 0.0534,\n",
      "         0.3010],\n",
      "        [0.0624, 0.0693, 0.0730, 0.0749, 0.0740, 0.0722, 0.0710, 0.0701, 0.0443,\n",
      "         0.3886],\n",
      "        [0.0476, 0.0545, 0.0577, 0.0592, 0.0584, 0.0569, 0.0558, 0.0549, 0.0312,\n",
      "         0.5239],\n",
      "        [0.0307, 0.0367, 0.0390, 0.0400, 0.0395, 0.0384, 0.0376, 0.0366, 0.0187,\n",
      "         0.6829],\n",
      "        [0.0184, 0.0231, 0.0246, 0.0252, 0.0249, 0.0242, 0.0236, 0.0226, 0.0105,\n",
      "         0.8030],\n",
      "        [0.0116, 0.0152, 0.0162, 0.0166, 0.0164, 0.0160, 0.0155, 0.0146, 0.0063,\n",
      "         0.8716],\n",
      "        [0.0087, 0.0115, 0.0124, 0.0127, 0.0125, 0.0122, 0.0118, 0.0110, 0.0046,\n",
      "         0.9025],\n",
      "        [0.0075, 0.0100, 0.0107, 0.0110, 0.0109, 0.0106, 0.0103, 0.0095, 0.0040,\n",
      "         0.9155]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 所以 在 那 之后 5 年 我 <UNK> <UNK> 陪\n",
      "Reference: so for the next five years , i dressed\n",
      "Model: <SOS> we the the the the the the the the\n",
      "Attention Weights: tensor([[0.0697, 0.0683, 0.0700, 0.0705, 0.0694, 0.0718, 0.0662, 0.0518, 0.2312,\n",
      "         0.2312],\n",
      "        [0.0587, 0.0641, 0.0671, 0.0680, 0.0674, 0.0700, 0.0643, 0.0429, 0.2488,\n",
      "         0.2488],\n",
      "        [0.0460, 0.0513, 0.0538, 0.0544, 0.0538, 0.0561, 0.0511, 0.0316, 0.3009,\n",
      "         0.3009],\n",
      "        [0.0271, 0.0315, 0.0332, 0.0335, 0.0331, 0.0344, 0.0312, 0.0169, 0.3796,\n",
      "         0.3796],\n",
      "        [0.0133, 0.0165, 0.0175, 0.0176, 0.0174, 0.0179, 0.0161, 0.0076, 0.4380,\n",
      "         0.4380],\n",
      "        [0.0072, 0.0093, 0.0099, 0.0100, 0.0099, 0.0100, 0.0089, 0.0039, 0.4654,\n",
      "         0.4654],\n",
      "        [0.0050, 0.0066, 0.0071, 0.0071, 0.0070, 0.0071, 0.0063, 0.0026, 0.4755,\n",
      "         0.4755],\n",
      "        [0.0042, 0.0056, 0.0060, 0.0061, 0.0060, 0.0060, 0.0053, 0.0022, 0.4793,\n",
      "         0.4793],\n",
      "        [0.0039, 0.0052, 0.0055, 0.0056, 0.0055, 0.0055, 0.0049, 0.0020, 0.4809,\n",
      "         0.4809]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44.00, Train Loss: 3.55, Val Loss: 10.90, Train BLEU: 7.42, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里 生物 的 多样 多样性 和 密度 要 比\n",
      "Reference: the biodiversity and the <UNK> in the ocean is\n",
      "Model: <SOS> we the the the the the the the the\n",
      "Attention Weights: tensor([[0.0970, 0.0968, 0.1001, 0.1006, 0.1025, 0.1100, 0.1000, 0.0993, 0.0962,\n",
      "         0.0975],\n",
      "        [0.0877, 0.0960, 0.1011, 0.1021, 0.1044, 0.1108, 0.1018, 0.1016, 0.0987,\n",
      "         0.0957],\n",
      "        [0.0867, 0.0963, 0.1016, 0.1026, 0.1050, 0.1119, 0.1020, 0.1014, 0.0979,\n",
      "         0.0946],\n",
      "        [0.0863, 0.0965, 0.1019, 0.1028, 0.1053, 0.1125, 0.1021, 0.1014, 0.0976,\n",
      "         0.0936],\n",
      "        [0.0847, 0.0969, 0.1025, 0.1034, 0.1059, 0.1131, 0.1028, 0.1018, 0.0975,\n",
      "         0.0915],\n",
      "        [0.0824, 0.0974, 0.1032, 0.1043, 0.1066, 0.1134, 0.1036, 0.1023, 0.0976,\n",
      "         0.0891],\n",
      "        [0.0806, 0.0977, 0.1038, 0.1050, 0.1072, 0.1137, 0.1042, 0.1027, 0.0976,\n",
      "         0.0876],\n",
      "        [0.0795, 0.0978, 0.1042, 0.1054, 0.1075, 0.1139, 0.1045, 0.1029, 0.0977,\n",
      "         0.0866],\n",
      "        [0.0786, 0.0979, 0.1044, 0.1057, 0.1078, 0.1140, 0.1048, 0.1031, 0.0977,\n",
      "         0.0860]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 出身 阿富汗 边远 <UNK> 地区 有着 与 他人 不同\n",
      "Reference: a total maverick from a remote province of afghanistan\n",
      "Model: <SOS> we the the the the the the the the\n",
      "Attention Weights: tensor([[0.0876, 0.0865, 0.0882, 0.0908, 0.0968, 0.0893, 0.0860, 0.0841, 0.0666,\n",
      "         0.2241],\n",
      "        [0.0754, 0.0826, 0.0861, 0.0892, 0.0948, 0.0880, 0.0857, 0.0835, 0.0567,\n",
      "         0.2581],\n",
      "        [0.0669, 0.0744, 0.0777, 0.0807, 0.0860, 0.0792, 0.0768, 0.0750, 0.0484,\n",
      "         0.3350],\n",
      "        [0.0548, 0.0625, 0.0655, 0.0681, 0.0727, 0.0666, 0.0645, 0.0628, 0.0370,\n",
      "         0.4454],\n",
      "        [0.0390, 0.0463, 0.0487, 0.0506, 0.0539, 0.0495, 0.0478, 0.0462, 0.0245,\n",
      "         0.5933],\n",
      "        [0.0252, 0.0314, 0.0331, 0.0343, 0.0364, 0.0336, 0.0324, 0.0308, 0.0148,\n",
      "         0.7280],\n",
      "        [0.0165, 0.0214, 0.0227, 0.0235, 0.0248, 0.0230, 0.0221, 0.0208, 0.0092,\n",
      "         0.8158],\n",
      "        [0.0121, 0.0161, 0.0171, 0.0177, 0.0186, 0.0173, 0.0166, 0.0154, 0.0065,\n",
      "         0.8627],\n",
      "        [0.0099, 0.0133, 0.0142, 0.0147, 0.0154, 0.0144, 0.0138, 0.0127, 0.0052,\n",
      "         0.8866]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 45.00, Train Loss: 3.52, Val Loss: 10.91, Train BLEU: 7.48, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 是 我 最 喜欢 的 因为 它 哪 都 能动\n",
      "Reference: it &apos;s one of my favorites , because it\n",
      "Model: <SOS> it &apos;s the the the , , , ,\n",
      "Attention Weights: tensor([[0.1019, 0.0990, 0.1010, 0.1030, 0.1026, 0.1029, 0.1007, 0.0987, 0.0989,\n",
      "         0.0910],\n",
      "        [0.0913, 0.0996, 0.1037, 0.1063, 0.1063, 0.1069, 0.1050, 0.1035, 0.1031,\n",
      "         0.0743],\n",
      "        [0.0911, 0.1002, 0.1046, 0.1073, 0.1071, 0.1077, 0.1053, 0.1034, 0.1030,\n",
      "         0.0704],\n",
      "        [0.0909, 0.1008, 0.1054, 0.1082, 0.1079, 0.1084, 0.1059, 0.1037, 0.1029,\n",
      "         0.0659],\n",
      "        [0.0895, 0.1019, 0.1067, 0.1096, 0.1093, 0.1097, 0.1071, 0.1046, 0.1027,\n",
      "         0.0588],\n",
      "        [0.0878, 0.1028, 0.1079, 0.1108, 0.1106, 0.1109, 0.1082, 0.1053, 0.1021,\n",
      "         0.0536],\n",
      "        [0.0863, 0.1034, 0.1089, 0.1117, 0.1116, 0.1118, 0.1091, 0.1059, 0.1015,\n",
      "         0.0498],\n",
      "        [0.0852, 0.1039, 0.1096, 0.1124, 0.1123, 0.1124, 0.1097, 0.1063, 0.1010,\n",
      "         0.0473],\n",
      "        [0.0843, 0.1041, 0.1100, 0.1129, 0.1127, 0.1128, 0.1101, 0.1065, 0.1007,\n",
      "         0.0458]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 她 两年 年前 退休 了 结果 却 把 我家 变成\n",
      "Reference: she retired two years ago , only to turn\n",
      "Model: <SOS> we the the the the the the the the\n",
      "Attention Weights: tensor([[0.0508, 0.0499, 0.0509, 0.0503, 0.0492, 0.0397, 0.1773, 0.1773, 0.1773,\n",
      "         0.1773],\n",
      "        [0.0374, 0.0409, 0.0425, 0.0424, 0.0412, 0.0285, 0.1918, 0.1918, 0.1918,\n",
      "         0.1918],\n",
      "        [0.0256, 0.0285, 0.0297, 0.0295, 0.0287, 0.0183, 0.2099, 0.2099, 0.2099,\n",
      "         0.2099],\n",
      "        [0.0110, 0.0130, 0.0136, 0.0135, 0.0130, 0.0071, 0.2322, 0.2322, 0.2322,\n",
      "         0.2322],\n",
      "        [0.0049, 0.0061, 0.0064, 0.0064, 0.0060, 0.0028, 0.2418, 0.2418, 0.2418,\n",
      "         0.2418],\n",
      "        [0.0030, 0.0038, 0.0040, 0.0040, 0.0037, 0.0016, 0.2450, 0.2450, 0.2450,\n",
      "         0.2450],\n",
      "        [0.0023, 0.0030, 0.0032, 0.0031, 0.0029, 0.0012, 0.2460, 0.2460, 0.2460,\n",
      "         0.2460],\n",
      "        [0.0021, 0.0027, 0.0029, 0.0028, 0.0026, 0.0011, 0.2464, 0.2464, 0.2464,\n",
      "         0.2464],\n",
      "        [0.0020, 0.0026, 0.0027, 0.0027, 0.0025, 0.0011, 0.2466, 0.2466, 0.2466,\n",
      "         0.2466]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 46.00, Train Loss: 3.49, Val Loss: 10.93, Train BLEU: 7.49, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: <UNK> 塞尔 <UNK> <UNK> 斯特 说 过 真正 的 探索\n",
      "Reference: marcel proust said , &quot; the true voyage of\n",
      "Model: <SOS> marcel of the the , , , , ,\n",
      "Attention Weights: tensor([[0.1065, 0.1119, 0.1128, 0.1151, 0.1120, 0.0918, 0.0869, 0.0871, 0.0853,\n",
      "         0.0905],\n",
      "        [0.0721, 0.0800, 0.0827, 0.0949, 0.1176, 0.1112, 0.1099, 0.1112, 0.1091,\n",
      "         0.1112],\n",
      "        [0.0578, 0.0652, 0.0682, 0.0820, 0.1179, 0.1230, 0.1224, 0.1236, 0.1205,\n",
      "         0.1194],\n",
      "        [0.0443, 0.0510, 0.0544, 0.0693, 0.1142, 0.1342, 0.1364, 0.1377, 0.1334,\n",
      "         0.1250],\n",
      "        [0.0360, 0.0420, 0.0458, 0.0609, 0.1092, 0.1422, 0.1467, 0.1478, 0.1424,\n",
      "         0.1270],\n",
      "        [0.0323, 0.0380, 0.0419, 0.0569, 0.1059, 0.1461, 0.1520, 0.1530, 0.1467,\n",
      "         0.1272],\n",
      "        [0.0304, 0.0360, 0.0399, 0.0547, 0.1038, 0.1480, 0.1550, 0.1559, 0.1491,\n",
      "         0.1272],\n",
      "        [0.0295, 0.0350, 0.0389, 0.0536, 0.1025, 0.1490, 0.1565, 0.1574, 0.1504,\n",
      "         0.1271],\n",
      "        [0.0289, 0.0342, 0.0382, 0.0528, 0.1015, 0.1497, 0.1577, 0.1586, 0.1514,\n",
      "         0.1271]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6 岁 那年 塔利 塔利班 占领 阿富汗 并 规定\n",
      "Reference: you see , i was six when the taliban\n",
      "Model: <SOS> we the the the the the the the the\n",
      "Attention Weights: tensor([[0.0839, 0.0828, 0.0851, 0.0870, 0.0857, 0.0834, 0.0815, 0.0801, 0.0642,\n",
      "         0.2662],\n",
      "        [0.0699, 0.0766, 0.0806, 0.0826, 0.0817, 0.0799, 0.0786, 0.0768, 0.0533,\n",
      "         0.3200],\n",
      "        [0.0609, 0.0679, 0.0716, 0.0734, 0.0725, 0.0706, 0.0692, 0.0679, 0.0447,\n",
      "         0.4012],\n",
      "        [0.0468, 0.0540, 0.0572, 0.0586, 0.0578, 0.0562, 0.0550, 0.0537, 0.0318,\n",
      "         0.5289],\n",
      "        [0.0310, 0.0375, 0.0398, 0.0408, 0.0403, 0.0391, 0.0382, 0.0369, 0.0196,\n",
      "         0.6769],\n",
      "        [0.0194, 0.0246, 0.0263, 0.0270, 0.0266, 0.0259, 0.0252, 0.0239, 0.0114,\n",
      "         0.7897],\n",
      "        [0.0127, 0.0168, 0.0180, 0.0185, 0.0183, 0.0177, 0.0172, 0.0160, 0.0071,\n",
      "         0.8577],\n",
      "        [0.0096, 0.0129, 0.0139, 0.0143, 0.0141, 0.0137, 0.0132, 0.0122, 0.0053,\n",
      "         0.8907],\n",
      "        [0.0083, 0.0112, 0.0121, 0.0125, 0.0123, 0.0120, 0.0115, 0.0106, 0.0045,\n",
      "         0.9050]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 47.00, Train Loss: 3.47, Val Loss: 10.97, Train BLEU: 7.57, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 我们 用 的 是 深海 潜水 潜水艇 <UNK> 号 和\n",
      "Reference: we use the submarine alvin and we use cameras\n",
      "Model: <SOS> we the the the the the the the the\n",
      "Attention Weights: tensor([[0.0941, 0.0948, 0.0970, 0.0982, 0.1008, 0.1045, 0.1188, 0.1061, 0.0925,\n",
      "         0.0931],\n",
      "        [0.0864, 0.0953, 0.0994, 0.1014, 0.1055, 0.1095, 0.1129, 0.1011, 0.0959,\n",
      "         0.0926],\n",
      "        [0.0859, 0.0956, 0.0997, 0.1018, 0.1064, 0.1112, 0.1130, 0.0988, 0.0956,\n",
      "         0.0919],\n",
      "        [0.0865, 0.0967, 0.1009, 0.1028, 0.1075, 0.1122, 0.1094, 0.0948, 0.0967,\n",
      "         0.0924],\n",
      "        [0.0854, 0.0980, 0.1024, 0.1044, 0.1090, 0.1131, 0.1066, 0.0921, 0.0978,\n",
      "         0.0911],\n",
      "        [0.0836, 0.0991, 0.1040, 0.1060, 0.1104, 0.1136, 0.1046, 0.0905, 0.0986,\n",
      "         0.0897],\n",
      "        [0.0821, 0.0999, 0.1051, 0.1072, 0.1113, 0.1138, 0.1033, 0.0898, 0.0990,\n",
      "         0.0886],\n",
      "        [0.0811, 0.1004, 0.1058, 0.1079, 0.1119, 0.1139, 0.1026, 0.0894, 0.0992,\n",
      "         0.0879],\n",
      "        [0.0803, 0.1006, 0.1063, 0.1084, 0.1124, 0.1141, 0.1021, 0.0891, 0.0994,\n",
      "         0.0874]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 那 就是 她 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: there she is . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a . <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0891, 0.0894, 0.0900, 0.0905, 0.0906, 0.0901, 0.0872, 0.0840, 0.0687,\n",
      "         0.2203],\n",
      "        [0.0760, 0.0841, 0.0865, 0.0874, 0.0878, 0.0876, 0.0853, 0.0821, 0.0589,\n",
      "         0.2643],\n",
      "        [0.0683, 0.0768, 0.0790, 0.0798, 0.0801, 0.0798, 0.0774, 0.0746, 0.0510,\n",
      "         0.3332],\n",
      "        [0.0564, 0.0651, 0.0672, 0.0678, 0.0680, 0.0676, 0.0654, 0.0630, 0.0391,\n",
      "         0.4405],\n",
      "        [0.0413, 0.0497, 0.0515, 0.0520, 0.0521, 0.0518, 0.0500, 0.0480, 0.0269,\n",
      "         0.5767],\n",
      "        [0.0280, 0.0353, 0.0367, 0.0371, 0.0372, 0.0369, 0.0356, 0.0337, 0.0170,\n",
      "         0.7026],\n",
      "        [0.0192, 0.0253, 0.0265, 0.0267, 0.0268, 0.0266, 0.0255, 0.0240, 0.0110,\n",
      "         0.7885],\n",
      "        [0.0143, 0.0194, 0.0204, 0.0206, 0.0206, 0.0205, 0.0196, 0.0182, 0.0080,\n",
      "         0.8385],\n",
      "        [0.0118, 0.0161, 0.0170, 0.0172, 0.0173, 0.0171, 0.0164, 0.0151, 0.0064,\n",
      "         0.8655]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48.00, Train Loss: 3.44, Val Loss: 10.97, Train BLEU: 8.03, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想 海洋 占 了 地球 球面 面积 的 75\n",
      "Reference: when you think about it , the oceans are\n",
      "Model: <SOS> it &apos;s the the the , , , ,\n",
      "Attention Weights: tensor([[0.1025, 0.1011, 0.1027, 0.1024, 0.1028, 0.1035, 0.1023, 0.0995, 0.1018,\n",
      "         0.0814],\n",
      "        [0.0927, 0.1021, 0.1062, 0.1061, 0.1069, 0.1080, 0.1069, 0.1047, 0.1039,\n",
      "         0.0625],\n",
      "        [0.0929, 0.1032, 0.1076, 0.1073, 0.1080, 0.1090, 0.1076, 0.1050, 0.1036,\n",
      "         0.0558],\n",
      "        [0.0914, 0.1043, 0.1092, 0.1090, 0.1097, 0.1105, 0.1090, 0.1060, 0.1030,\n",
      "         0.0477],\n",
      "        [0.0891, 0.1054, 0.1107, 0.1108, 0.1114, 0.1120, 0.1104, 0.1070, 0.1017,\n",
      "         0.0415],\n",
      "        [0.0867, 0.1064, 0.1120, 0.1124, 0.1129, 0.1134, 0.1115, 0.1077, 0.1001,\n",
      "         0.0370],\n",
      "        [0.0848, 0.1070, 0.1130, 0.1135, 0.1139, 0.1143, 0.1124, 0.1082, 0.0988,\n",
      "         0.0342],\n",
      "        [0.0834, 0.1074, 0.1136, 0.1141, 0.1146, 0.1149, 0.1129, 0.1085, 0.0979,\n",
      "         0.0327],\n",
      "        [0.0826, 0.1076, 0.1140, 0.1145, 0.1149, 0.1153, 0.1132, 0.1086, 0.0974,\n",
      "         0.0319]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 不知 知道 那 意味 意味着 什么 但是 我 能\n",
      "Reference: i didn &apos;t know what it meant , but\n",
      "Model: <SOS> we the the the the the the the ,\n",
      "Attention Weights: tensor([[0.0962, 0.0964, 0.0987, 0.1012, 0.1016, 0.1007, 0.1011, 0.1036, 0.1028,\n",
      "         0.0977],\n",
      "        [0.0875, 0.0964, 0.1005, 0.1034, 0.1039, 0.1033, 0.1046, 0.1038, 0.1022,\n",
      "         0.0945],\n",
      "        [0.0869, 0.0964, 0.1007, 0.1037, 0.1042, 0.1034, 0.1048, 0.1048, 0.1020,\n",
      "         0.0933],\n",
      "        [0.0866, 0.0966, 0.1010, 0.1041, 0.1045, 0.1035, 0.1048, 0.1048, 0.1016,\n",
      "         0.0924],\n",
      "        [0.0848, 0.0972, 0.1019, 0.1051, 0.1055, 0.1045, 0.1055, 0.1051, 0.1009,\n",
      "         0.0897],\n",
      "        [0.0826, 0.0979, 0.1029, 0.1061, 0.1065, 0.1054, 0.1061, 0.1051, 0.1002,\n",
      "         0.0871],\n",
      "        [0.0808, 0.0984, 0.1037, 0.1069, 0.1073, 0.1062, 0.1065, 0.1050, 0.0998,\n",
      "         0.0854],\n",
      "        [0.0795, 0.0986, 0.1042, 0.1074, 0.1079, 0.1067, 0.1069, 0.1050, 0.0996,\n",
      "         0.0842],\n",
      "        [0.0785, 0.0988, 0.1045, 0.1077, 0.1082, 0.1070, 0.1071, 0.1050, 0.0996,\n",
      "         0.0835]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 49.00, Train Loss: 3.42, Val Loss: 11.00, Train BLEU: 7.61, Val BLEU: 0.32\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一种 种群 栖 动物 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: it &apos;s a colonial animal . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a . . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0587, 0.0589, 0.0604, 0.0601, 0.0580, 0.0568, 0.0461, 0.2003, 0.2003,\n",
      "         0.2003],\n",
      "        [0.0458, 0.0505, 0.0526, 0.0526, 0.0512, 0.0500, 0.0359, 0.2204, 0.2204,\n",
      "         0.2204],\n",
      "        [0.0362, 0.0406, 0.0424, 0.0423, 0.0410, 0.0402, 0.0270, 0.2434, 0.2434,\n",
      "         0.2434],\n",
      "        [0.0197, 0.0231, 0.0243, 0.0242, 0.0235, 0.0228, 0.0132, 0.2831, 0.2831,\n",
      "         0.2831],\n",
      "        [0.0094, 0.0118, 0.0125, 0.0125, 0.0120, 0.0114, 0.0057, 0.3082, 0.3082,\n",
      "         0.3082],\n",
      "        [0.0054, 0.0070, 0.0075, 0.0075, 0.0072, 0.0067, 0.0030, 0.3186, 0.3186,\n",
      "         0.3186],\n",
      "        [0.0042, 0.0055, 0.0059, 0.0058, 0.0056, 0.0052, 0.0022, 0.3219, 0.3219,\n",
      "         0.3219],\n",
      "        [0.0038, 0.0050, 0.0053, 0.0053, 0.0051, 0.0047, 0.0020, 0.3230, 0.3230,\n",
      "         0.3230],\n",
      "        [0.0036, 0.0047, 0.0051, 0.0050, 0.0048, 0.0044, 0.0019, 0.3235, 0.3235,\n",
      "         0.3235]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11 岁 那年 记得 得有 一天 早晨 醒来 听见\n",
      "Reference: when i was 11 , i remember waking up\n",
      "Model: <SOS> we the the the the the the the ,\n",
      "Attention Weights: tensor([[0.0598, 0.0600, 0.0596, 0.0599, 0.0627, 0.0483, 0.0419, 0.2026, 0.2026,\n",
      "         0.2026],\n",
      "        [0.0464, 0.0517, 0.0527, 0.0537, 0.0541, 0.0352, 0.0313, 0.2250, 0.2250,\n",
      "         0.2250],\n",
      "        [0.0364, 0.0415, 0.0423, 0.0432, 0.0437, 0.0246, 0.0226, 0.2486, 0.2486,\n",
      "         0.2486],\n",
      "        [0.0186, 0.0225, 0.0231, 0.0235, 0.0231, 0.0110, 0.0101, 0.2893, 0.2893,\n",
      "         0.2893],\n",
      "        [0.0091, 0.0118, 0.0122, 0.0124, 0.0118, 0.0050, 0.0044, 0.3111, 0.3111,\n",
      "         0.3111],\n",
      "        [0.0054, 0.0073, 0.0076, 0.0076, 0.0071, 0.0028, 0.0024, 0.3199, 0.3199,\n",
      "         0.3199],\n",
      "        [0.0042, 0.0058, 0.0060, 0.0060, 0.0055, 0.0022, 0.0018, 0.3228, 0.3228,\n",
      "         0.3228],\n",
      "        [0.0038, 0.0052, 0.0054, 0.0054, 0.0049, 0.0019, 0.0016, 0.3239, 0.3239,\n",
      "         0.3239],\n",
      "        [0.0036, 0.0050, 0.0052, 0.0052, 0.0047, 0.0018, 0.0015, 0.3243, 0.3243,\n",
      "         0.3243]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 50.00, Train Loss: 3.40, Val Loss: 11.04, Train BLEU: 7.02, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一只 水母 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: here &apos;s a jelly . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a . <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0558, 0.0557, 0.0557, 0.0542, 0.0439, 0.1469, 0.1469, 0.1469, 0.1469,\n",
      "         0.1469],\n",
      "        [0.0421, 0.0461, 0.0471, 0.0459, 0.0332, 0.1571, 0.1571, 0.1571, 0.1571,\n",
      "         0.1571],\n",
      "        [0.0316, 0.0351, 0.0360, 0.0352, 0.0238, 0.1677, 0.1677, 0.1677, 0.1677,\n",
      "         0.1677],\n",
      "        [0.0155, 0.0182, 0.0187, 0.0181, 0.0105, 0.1838, 0.1838, 0.1838, 0.1838,\n",
      "         0.1838],\n",
      "        [0.0071, 0.0089, 0.0092, 0.0087, 0.0043, 0.1924, 0.1924, 0.1924, 0.1924,\n",
      "         0.1924],\n",
      "        [0.0042, 0.0054, 0.0056, 0.0053, 0.0023, 0.1954, 0.1954, 0.1954, 0.1954,\n",
      "         0.1954],\n",
      "        [0.0033, 0.0044, 0.0045, 0.0042, 0.0018, 0.1963, 0.1963, 0.1963, 0.1963,\n",
      "         0.1963],\n",
      "        [0.0030, 0.0040, 0.0041, 0.0038, 0.0016, 0.1967, 0.1967, 0.1967, 0.1967,\n",
      "         0.1967],\n",
      "        [0.0029, 0.0038, 0.0040, 0.0037, 0.0015, 0.1968, 0.1968, 0.1968, 0.1968,\n",
      "         0.1968]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 这 是 我们 俩 人 唯一 的 受教 教育 方式\n",
      "Reference: it was the only way we both could be\n",
      "Model: <SOS> we the the the the the the the ,\n",
      "Attention Weights: tensor([[0.0956, 0.0977, 0.1003, 0.1019, 0.1032, 0.1022, 0.1025, 0.0999, 0.0974,\n",
      "         0.0992],\n",
      "        [0.0881, 0.0974, 0.1012, 0.1030, 0.1044, 0.1034, 0.1038, 0.1014, 0.0994,\n",
      "         0.0978],\n",
      "        [0.0879, 0.0977, 0.1016, 0.1034, 0.1050, 0.1036, 0.1040, 0.1011, 0.0986,\n",
      "         0.0970],\n",
      "        [0.0878, 0.0979, 0.1018, 0.1037, 0.1054, 0.1038, 0.1042, 0.1010, 0.0983,\n",
      "         0.0961],\n",
      "        [0.0864, 0.0983, 0.1024, 0.1045, 0.1062, 0.1045, 0.1048, 0.1014, 0.0982,\n",
      "         0.0933],\n",
      "        [0.0844, 0.0987, 0.1032, 0.1053, 0.1069, 0.1053, 0.1054, 0.1019, 0.0982,\n",
      "         0.0906],\n",
      "        [0.0828, 0.0990, 0.1038, 0.1059, 0.1074, 0.1059, 0.1059, 0.1023, 0.0983,\n",
      "         0.0887],\n",
      "        [0.0813, 0.0992, 0.1043, 0.1063, 0.1079, 0.1064, 0.1063, 0.1026, 0.0983,\n",
      "         0.0874],\n",
      "        [0.0803, 0.0993, 0.1046, 0.1066, 0.1082, 0.1067, 0.1066, 0.1028, 0.0984,\n",
      "         0.0865]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 51.00, Train Loss: 3.37, Val Loss: 11.04, Train BLEU: 7.55, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数 多数 地震 和 火山 喷发 也 都 发生\n",
      "Reference: most of the earthquakes and volcanoes are in the\n",
      "Model: <SOS> and the the the the the the the the\n",
      "Attention Weights: tensor([[0.0975, 0.1046, 0.1011, 0.1017, 0.1010, 0.1019, 0.1008, 0.0984, 0.0958,\n",
      "         0.0973],\n",
      "        [0.0887, 0.1024, 0.1016, 0.1030, 0.1025, 0.1038, 0.1026, 0.1002, 0.0982,\n",
      "         0.0970],\n",
      "        [0.0880, 0.1031, 0.1022, 0.1037, 0.1029, 0.1043, 0.1028, 0.0998, 0.0973,\n",
      "         0.0960],\n",
      "        [0.0874, 0.1038, 0.1027, 0.1041, 0.1032, 0.1046, 0.1030, 0.0997, 0.0970,\n",
      "         0.0947],\n",
      "        [0.0849, 0.1038, 0.1037, 0.1052, 0.1043, 0.1054, 0.1038, 0.1004, 0.0971,\n",
      "         0.0915],\n",
      "        [0.0823, 0.1034, 0.1047, 0.1062, 0.1053, 0.1063, 0.1045, 0.1011, 0.0973,\n",
      "         0.0889],\n",
      "        [0.0802, 0.1030, 0.1055, 0.1069, 0.1061, 0.1069, 0.1051, 0.1016, 0.0975,\n",
      "         0.0872],\n",
      "        [0.0786, 0.1028, 0.1060, 0.1075, 0.1066, 0.1073, 0.1056, 0.1020, 0.0976,\n",
      "         0.0860],\n",
      "        [0.0776, 0.1027, 0.1063, 0.1078, 0.1069, 0.1076, 0.1058, 0.1022, 0.0977,\n",
      "         0.0853]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把 书 放在 食品 杂货 袋中 这样 别人 就\n",
      "Reference: we would cover our books in grocery bags so\n",
      "Model: <SOS> we the the the the the the the the\n",
      "Attention Weights: tensor([[0.0971, 0.1005, 0.1013, 0.1013, 0.1023, 0.1013, 0.1005, 0.1002, 0.0968,\n",
      "         0.0987],\n",
      "        [0.0886, 0.0995, 0.1020, 0.1024, 0.1036, 0.1026, 0.1020, 0.1019, 0.0989,\n",
      "         0.0984],\n",
      "        [0.0882, 0.1001, 0.1027, 0.1029, 0.1042, 0.1027, 0.1019, 0.1017, 0.0981,\n",
      "         0.0974],\n",
      "        [0.0880, 0.1006, 0.1031, 0.1032, 0.1045, 0.1029, 0.1020, 0.1017, 0.0978,\n",
      "         0.0962],\n",
      "        [0.0859, 0.1011, 0.1040, 0.1042, 0.1054, 0.1038, 0.1027, 0.1021, 0.0978,\n",
      "         0.0929],\n",
      "        [0.0834, 0.1014, 0.1049, 0.1052, 0.1062, 0.1048, 0.1035, 0.1026, 0.0980,\n",
      "         0.0900],\n",
      "        [0.0813, 0.1016, 0.1055, 0.1059, 0.1068, 0.1055, 0.1042, 0.1031, 0.0981,\n",
      "         0.0881],\n",
      "        [0.0797, 0.1017, 0.1059, 0.1064, 0.1073, 0.1059, 0.1046, 0.1034, 0.0982,\n",
      "         0.0868],\n",
      "        [0.0786, 0.1018, 0.1062, 0.1067, 0.1076, 0.1063, 0.1049, 0.1036, 0.0983,\n",
      "         0.0860]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52.00, Train Loss: 3.34, Val Loss: 11.06, Train BLEU: 7.54, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 其实 它们 都 是 由 单独 的 动物 结合 合在\n",
      "Reference: these are all individual animals banding together to make\n",
      "Model: <SOS> these the the , , , , , ,\n",
      "Attention Weights: tensor([[0.1013, 0.1020, 0.1027, 0.1039, 0.1041, 0.1042, 0.1017, 0.0990, 0.0993,\n",
      "         0.0817],\n",
      "        [0.0936, 0.1029, 0.1052, 0.1068, 0.1072, 0.1079, 0.1055, 0.1047, 0.1049,\n",
      "         0.0612],\n",
      "        [0.0936, 0.1038, 0.1061, 0.1077, 0.1080, 0.1086, 0.1059, 0.1051, 0.1053,\n",
      "         0.0559],\n",
      "        [0.0923, 0.1053, 0.1082, 0.1098, 0.1101, 0.1105, 0.1077, 0.1061, 0.1038,\n",
      "         0.0463],\n",
      "        [0.0905, 0.1066, 0.1100, 0.1116, 0.1118, 0.1120, 0.1092, 0.1067, 0.1014,\n",
      "         0.0401],\n",
      "        [0.0887, 0.1075, 0.1113, 0.1129, 0.1132, 0.1132, 0.1103, 0.1071, 0.0996,\n",
      "         0.0363],\n",
      "        [0.0871, 0.1080, 0.1122, 0.1138, 0.1140, 0.1140, 0.1110, 0.1074, 0.0984,\n",
      "         0.0339],\n",
      "        [0.0859, 0.1083, 0.1128, 0.1144, 0.1147, 0.1145, 0.1116, 0.1077, 0.0976,\n",
      "         0.0325],\n",
      "        [0.0851, 0.1085, 0.1132, 0.1149, 0.1151, 0.1149, 0.1119, 0.1079, 0.0971,\n",
      "         0.0315]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 对 他 来说 孩子 不 接受 受教 教育 <UNK> 是\n",
      "Reference: to him , there was greater risk in not\n",
      "Model: <SOS> we the the the the the the the the\n",
      "Attention Weights: tensor([[0.0583, 0.0589, 0.0605, 0.0601, 0.0579, 0.0561, 0.0452, 0.2010, 0.2010,\n",
      "         0.2010],\n",
      "        [0.0473, 0.0520, 0.0541, 0.0541, 0.0526, 0.0514, 0.0372, 0.2171, 0.2171,\n",
      "         0.2171],\n",
      "        [0.0370, 0.0416, 0.0434, 0.0433, 0.0419, 0.0411, 0.0279, 0.2413, 0.2413,\n",
      "         0.2413],\n",
      "        [0.0199, 0.0234, 0.0245, 0.0244, 0.0236, 0.0230, 0.0134, 0.2826, 0.2826,\n",
      "         0.2826],\n",
      "        [0.0094, 0.0119, 0.0126, 0.0125, 0.0121, 0.0115, 0.0057, 0.3081, 0.3081,\n",
      "         0.3081],\n",
      "        [0.0054, 0.0070, 0.0075, 0.0075, 0.0072, 0.0067, 0.0030, 0.3186, 0.3186,\n",
      "         0.3186],\n",
      "        [0.0042, 0.0056, 0.0059, 0.0059, 0.0057, 0.0053, 0.0023, 0.3217, 0.3217,\n",
      "         0.3217],\n",
      "        [0.0038, 0.0051, 0.0054, 0.0054, 0.0052, 0.0048, 0.0021, 0.3227, 0.3227,\n",
      "         0.3227],\n",
      "        [0.0036, 0.0049, 0.0052, 0.0052, 0.0050, 0.0046, 0.0019, 0.3232, 0.3232,\n",
      "         0.3232]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 53.00, Train Loss: 3.32, Val Loss: 11.08, Train BLEU: 6.87, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一种 种群 栖 动物 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: it &apos;s a colonial animal . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s &apos;s about . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0682, 0.0693, 0.0713, 0.0709, 0.0681, 0.0656, 0.0522, 0.1781, 0.1781,\n",
      "         0.1781],\n",
      "        [0.0567, 0.0624, 0.0649, 0.0648, 0.0630, 0.0614, 0.0446, 0.1941, 0.1941,\n",
      "         0.1941],\n",
      "        [0.0455, 0.0511, 0.0534, 0.0532, 0.0515, 0.0505, 0.0343, 0.2201, 0.2201,\n",
      "         0.2201],\n",
      "        [0.0271, 0.0315, 0.0331, 0.0329, 0.0318, 0.0310, 0.0184, 0.2647, 0.2647,\n",
      "         0.2647],\n",
      "        [0.0137, 0.0171, 0.0180, 0.0180, 0.0173, 0.0167, 0.0084, 0.2969, 0.2969,\n",
      "         0.2969],\n",
      "        [0.0076, 0.0100, 0.0106, 0.0106, 0.0102, 0.0096, 0.0043, 0.3124, 0.3124,\n",
      "         0.3124],\n",
      "        [0.0056, 0.0075, 0.0080, 0.0079, 0.0076, 0.0071, 0.0030, 0.3178, 0.3178,\n",
      "         0.3178],\n",
      "        [0.0050, 0.0067, 0.0072, 0.0071, 0.0068, 0.0063, 0.0027, 0.3194, 0.3194,\n",
      "         0.3194],\n",
      "        [0.0047, 0.0064, 0.0068, 0.0068, 0.0065, 0.0060, 0.0025, 0.3201, 0.3201,\n",
      "         0.3201]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11 岁 那年 记得 得有 一天 早晨 醒来 听见\n",
      "Reference: when i was 11 , i remember waking up\n",
      "Model: <SOS> we the the the the the the the the\n",
      "Attention Weights: tensor([[0.0695, 0.0708, 0.0702, 0.0704, 0.0730, 0.0520, 0.0470, 0.1824, 0.1824,\n",
      "         0.1824],\n",
      "        [0.0578, 0.0644, 0.0654, 0.0666, 0.0669, 0.0408, 0.0389, 0.1997, 0.1997,\n",
      "         0.1997],\n",
      "        [0.0466, 0.0533, 0.0542, 0.0556, 0.0559, 0.0288, 0.0287, 0.2256, 0.2256,\n",
      "         0.2256],\n",
      "        [0.0261, 0.0313, 0.0319, 0.0326, 0.0321, 0.0136, 0.0140, 0.2728, 0.2728,\n",
      "         0.2728],\n",
      "        [0.0134, 0.0172, 0.0177, 0.0179, 0.0171, 0.0062, 0.0063, 0.3014, 0.3014,\n",
      "         0.3014],\n",
      "        [0.0077, 0.0104, 0.0108, 0.0108, 0.0100, 0.0034, 0.0033, 0.3146, 0.3146,\n",
      "         0.3146],\n",
      "        [0.0057, 0.0079, 0.0082, 0.0081, 0.0074, 0.0025, 0.0024, 0.3193, 0.3193,\n",
      "         0.3193],\n",
      "        [0.0051, 0.0071, 0.0073, 0.0073, 0.0065, 0.0022, 0.0021, 0.3208, 0.3208,\n",
      "         0.3208],\n",
      "        [0.0048, 0.0068, 0.0070, 0.0069, 0.0062, 0.0021, 0.0020, 0.3214, 0.3214,\n",
      "         0.3214]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 54.00, Train Loss: 3.29, Val Loss: 11.07, Train BLEU: 7.64, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 地球 的 大部 大部分 部分 都 是 海水 <EOS> <PAD>\n",
      "Reference: most of the planet is ocean water . <EOS>\n",
      "Model: <SOS> it &apos;s &apos;s to is . . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0825, 0.0827, 0.0855, 0.0874, 0.0858, 0.0830, 0.0805, 0.0774, 0.0611,\n",
      "         0.2741],\n",
      "        [0.0734, 0.0802, 0.0841, 0.0859, 0.0846, 0.0823, 0.0807, 0.0787, 0.0564,\n",
      "         0.2938],\n",
      "        [0.0651, 0.0722, 0.0760, 0.0776, 0.0760, 0.0737, 0.0721, 0.0710, 0.0489,\n",
      "         0.3675],\n",
      "        [0.0499, 0.0572, 0.0604, 0.0618, 0.0604, 0.0584, 0.0571, 0.0561, 0.0344,\n",
      "         0.5043],\n",
      "        [0.0335, 0.0403, 0.0427, 0.0437, 0.0428, 0.0413, 0.0403, 0.0391, 0.0212,\n",
      "         0.6551],\n",
      "        [0.0214, 0.0273, 0.0291, 0.0297, 0.0292, 0.0282, 0.0274, 0.0261, 0.0126,\n",
      "         0.7690],\n",
      "        [0.0141, 0.0189, 0.0203, 0.0207, 0.0204, 0.0197, 0.0191, 0.0179, 0.0079,\n",
      "         0.8410],\n",
      "        [0.0107, 0.0148, 0.0158, 0.0162, 0.0160, 0.0154, 0.0149, 0.0138, 0.0058,\n",
      "         0.8765],\n",
      "        [0.0093, 0.0129, 0.0139, 0.0142, 0.0140, 0.0135, 0.0130, 0.0119, 0.0050,\n",
      "         0.8922]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很 舒服 但 夏天 却 <UNK> <EOS> <PAD> <PAD>\n",
      "Reference: it was cozy in winter but extremely hot in\n",
      "Model: <SOS> it &apos;s the the . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0962, 0.0968, 0.1007, 0.1011, 0.1029, 0.1108, 0.1005, 0.0997, 0.0958,\n",
      "         0.0955],\n",
      "        [0.0888, 0.0966, 0.1016, 0.1022, 0.1048, 0.1101, 0.1014, 0.1010, 0.0977,\n",
      "         0.0959],\n",
      "        [0.0884, 0.0970, 0.1022, 0.1026, 0.1055, 0.1114, 0.1013, 0.1006, 0.0966,\n",
      "         0.0944],\n",
      "        [0.0880, 0.0972, 0.1025, 0.1028, 0.1057, 0.1127, 0.1014, 0.1005, 0.0961,\n",
      "         0.0931],\n",
      "        [0.0861, 0.0976, 0.1031, 0.1034, 0.1063, 0.1138, 0.1021, 0.1008, 0.0960,\n",
      "         0.0909],\n",
      "        [0.0835, 0.0980, 0.1038, 0.1043, 0.1069, 0.1143, 0.1029, 0.1013, 0.0962,\n",
      "         0.0889],\n",
      "        [0.0812, 0.0983, 0.1043, 0.1050, 0.1074, 0.1147, 0.1036, 0.1017, 0.0965,\n",
      "         0.0875],\n",
      "        [0.0795, 0.0984, 0.1047, 0.1054, 0.1078, 0.1150, 0.1040, 0.1020, 0.0966,\n",
      "         0.0865],\n",
      "        [0.0783, 0.0985, 0.1050, 0.1058, 0.1080, 0.1152, 0.1043, 0.1023, 0.0967,\n",
      "         0.0859]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 55.00, Train Loss: 3.26, Val Loss: 11.08, Train BLEU: 8.06, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本 基本上 都 没有 被 开发 发过 但是 像\n",
      "Reference: it &apos;s mostly unexplored , and yet there are\n",
      "Model: <SOS> we the the the the the the the the\n",
      "Attention Weights: tensor([[0.0967, 0.0993, 0.1028, 0.1014, 0.1026, 0.1016, 0.1020, 0.0999, 0.0977,\n",
      "         0.0959],\n",
      "        [0.0897, 0.0989, 0.1033, 0.1022, 0.1036, 0.1025, 0.1031, 0.1012, 0.0993,\n",
      "         0.0961],\n",
      "        [0.0893, 0.0995, 0.1041, 0.1026, 0.1041, 0.1028, 0.1034, 0.1010, 0.0986,\n",
      "         0.0946],\n",
      "        [0.0890, 0.0999, 0.1048, 0.1029, 0.1045, 0.1030, 0.1035, 0.1009, 0.0982,\n",
      "         0.0933],\n",
      "        [0.0871, 0.1003, 0.1055, 0.1036, 0.1052, 0.1036, 0.1040, 0.1012, 0.0981,\n",
      "         0.0913],\n",
      "        [0.0847, 0.1006, 0.1061, 0.1045, 0.1059, 0.1044, 0.1046, 0.1017, 0.0982,\n",
      "         0.0894],\n",
      "        [0.0826, 0.1008, 0.1066, 0.1051, 0.1065, 0.1050, 0.1050, 0.1021, 0.0983,\n",
      "         0.0881],\n",
      "        [0.0808, 0.1009, 0.1070, 0.1057, 0.1069, 0.1054, 0.1054, 0.1024, 0.0985,\n",
      "         0.0871],\n",
      "        [0.0795, 0.1010, 0.1073, 0.1060, 0.1072, 0.1058, 0.1057, 0.1026, 0.0986,\n",
      "         0.0864]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很 舒服 但 夏天 却 <UNK> <EOS> <PAD> <PAD>\n",
      "Reference: it was cozy in winter but extremely hot in\n",
      "Model: <SOS> it &apos;s the the . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0965, 0.0968, 0.1007, 0.1010, 0.1029, 0.1111, 0.1004, 0.0996, 0.0957,\n",
      "         0.0953],\n",
      "        [0.0892, 0.0966, 0.1016, 0.1021, 0.1048, 0.1104, 0.1012, 0.1008, 0.0974,\n",
      "         0.0958],\n",
      "        [0.0887, 0.0970, 0.1022, 0.1025, 0.1055, 0.1118, 0.1012, 0.1004, 0.0964,\n",
      "         0.0942],\n",
      "        [0.0883, 0.0972, 0.1025, 0.1027, 0.1058, 0.1132, 0.1013, 0.1003, 0.0958,\n",
      "         0.0928],\n",
      "        [0.0864, 0.0975, 0.1031, 0.1033, 0.1064, 0.1144, 0.1019, 0.1005, 0.0957,\n",
      "         0.0907],\n",
      "        [0.0837, 0.0979, 0.1038, 0.1041, 0.1070, 0.1150, 0.1027, 0.1011, 0.0960,\n",
      "         0.0887],\n",
      "        [0.0814, 0.0982, 0.1043, 0.1049, 0.1075, 0.1153, 0.1034, 0.1015, 0.0962,\n",
      "         0.0873],\n",
      "        [0.0797, 0.0984, 0.1047, 0.1053, 0.1079, 0.1156, 0.1038, 0.1018, 0.0963,\n",
      "         0.0863],\n",
      "        [0.0785, 0.0985, 0.1050, 0.1057, 0.1081, 0.1159, 0.1041, 0.1021, 0.0964,\n",
      "         0.0857]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56.00, Train Loss: 3.24, Val Loss: 11.10, Train BLEU: 8.39, Val BLEU: 0.26\n",
      "Sampling from training predictions...\n",
      "Source: 我们 得用 非常 特殊 的 仪器 才能 能到 到达 那个\n",
      "Reference: we have to have a very special technology to\n",
      "Model: <SOS> we the the the the the the the the\n",
      "Attention Weights: tensor([[0.0930, 0.1021, 0.1013, 0.1016, 0.1010, 0.1024, 0.1025, 0.1062, 0.0959,\n",
      "         0.0940],\n",
      "        [0.0871, 0.0995, 0.1013, 0.1024, 0.1022, 0.1040, 0.1048, 0.1065, 0.0977,\n",
      "         0.0944],\n",
      "        [0.0859, 0.1008, 0.1017, 0.1027, 0.1023, 0.1042, 0.1051, 0.1073, 0.0969,\n",
      "         0.0931],\n",
      "        [0.0850, 0.1020, 0.1025, 0.1030, 0.1024, 0.1043, 0.1052, 0.1080, 0.0962,\n",
      "         0.0914],\n",
      "        [0.0830, 0.1029, 0.1034, 0.1038, 0.1031, 0.1049, 0.1058, 0.1085, 0.0960,\n",
      "         0.0886],\n",
      "        [0.0806, 0.1034, 0.1044, 0.1048, 0.1041, 0.1057, 0.1064, 0.1084, 0.0962,\n",
      "         0.0861],\n",
      "        [0.0786, 0.1037, 0.1050, 0.1056, 0.1049, 0.1063, 0.1068, 0.1083, 0.0964,\n",
      "         0.0844],\n",
      "        [0.0771, 0.1039, 0.1055, 0.1061, 0.1054, 0.1067, 0.1071, 0.1083, 0.0966,\n",
      "         0.0834],\n",
      "        [0.0762, 0.1040, 0.1058, 0.1064, 0.1057, 0.1070, 0.1073, 0.1083, 0.0967,\n",
      "         0.0827]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 对 他 来说 孩子 不 接受 受教 教育 <UNK> 是\n",
      "Reference: to him , there was greater risk in not\n",
      "Model: <SOS> we the the the the the the the the\n",
      "Attention Weights: tensor([[0.0661, 0.0672, 0.0692, 0.0687, 0.0659, 0.0632, 0.0494, 0.1834, 0.1834,\n",
      "         0.1834],\n",
      "        [0.0579, 0.0633, 0.0657, 0.0656, 0.0636, 0.0620, 0.0451, 0.1923, 0.1923,\n",
      "         0.1923],\n",
      "        [0.0471, 0.0526, 0.0549, 0.0546, 0.0528, 0.0519, 0.0354, 0.2168, 0.2168,\n",
      "         0.2168],\n",
      "        [0.0285, 0.0329, 0.0344, 0.0342, 0.0329, 0.0322, 0.0193, 0.2619, 0.2619,\n",
      "         0.2619],\n",
      "        [0.0143, 0.0177, 0.0187, 0.0186, 0.0179, 0.0172, 0.0087, 0.2957, 0.2957,\n",
      "         0.2957],\n",
      "        [0.0077, 0.0100, 0.0107, 0.0106, 0.0102, 0.0096, 0.0042, 0.3123, 0.3123,\n",
      "         0.3123],\n",
      "        [0.0055, 0.0074, 0.0079, 0.0079, 0.0075, 0.0070, 0.0030, 0.3179, 0.3179,\n",
      "         0.3179],\n",
      "        [0.0049, 0.0066, 0.0071, 0.0070, 0.0067, 0.0062, 0.0026, 0.3196, 0.3196,\n",
      "         0.3196],\n",
      "        [0.0046, 0.0063, 0.0067, 0.0067, 0.0064, 0.0058, 0.0024, 0.3204, 0.3204,\n",
      "         0.3204]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 57.00, Train Loss: 3.21, Val Loss: 11.09, Train BLEU: 8.30, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中 的 生命 大卫 <UNK> <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: life in the deep oceans <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the about <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0576, 0.0581, 0.0572, 0.0576, 0.0595, 0.0398, 0.0372, 0.2110, 0.2110,\n",
      "         0.2110],\n",
      "        [0.0514, 0.0564, 0.0569, 0.0581, 0.0588, 0.0335, 0.0336, 0.2171, 0.2171,\n",
      "         0.2171],\n",
      "        [0.0407, 0.0460, 0.0463, 0.0476, 0.0479, 0.0228, 0.0244, 0.2415, 0.2415,\n",
      "         0.2415],\n",
      "        [0.0208, 0.0249, 0.0252, 0.0256, 0.0249, 0.0095, 0.0107, 0.2861, 0.2861,\n",
      "         0.2861],\n",
      "        [0.0096, 0.0125, 0.0128, 0.0128, 0.0119, 0.0039, 0.0043, 0.3107, 0.3107,\n",
      "         0.3107],\n",
      "        [0.0055, 0.0074, 0.0076, 0.0075, 0.0068, 0.0021, 0.0022, 0.3203, 0.3203,\n",
      "         0.3203],\n",
      "        [0.0043, 0.0059, 0.0061, 0.0059, 0.0053, 0.0017, 0.0017, 0.3231, 0.3231,\n",
      "         0.3231],\n",
      "        [0.0039, 0.0054, 0.0055, 0.0054, 0.0048, 0.0015, 0.0016, 0.3240, 0.3240,\n",
      "         0.3240],\n",
      "        [0.0038, 0.0052, 0.0054, 0.0052, 0.0046, 0.0015, 0.0015, 0.3243, 0.3243,\n",
      "         0.3243]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正 的 学校 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: a real school . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a . <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.1030, 0.1035, 0.1063, 0.1051, 0.1055, 0.1066, 0.1043, 0.1004, 0.1009,\n",
      "         0.0644],\n",
      "        [0.0956, 0.1045, 0.1090, 0.1076, 0.1082, 0.1099, 0.1078, 0.1048, 0.1041,\n",
      "         0.0485],\n",
      "        [0.0958, 0.1058, 0.1104, 0.1086, 0.1092, 0.1109, 0.1084, 0.1051, 0.1037,\n",
      "         0.0421],\n",
      "        [0.0946, 0.1071, 0.1120, 0.1103, 0.1108, 0.1124, 0.1096, 0.1059, 0.1025,\n",
      "         0.0349],\n",
      "        [0.0918, 0.1082, 0.1134, 0.1122, 0.1126, 0.1138, 0.1110, 0.1069, 0.1002,\n",
      "         0.0298],\n",
      "        [0.0889, 0.1093, 0.1148, 0.1139, 0.1142, 0.1151, 0.1124, 0.1078, 0.0977,\n",
      "         0.0261],\n",
      "        [0.0865, 0.1100, 0.1159, 0.1151, 0.1153, 0.1161, 0.1133, 0.1083, 0.0957,\n",
      "         0.0238],\n",
      "        [0.0848, 0.1104, 0.1165, 0.1158, 0.1161, 0.1168, 0.1139, 0.1086, 0.0944,\n",
      "         0.0227],\n",
      "        [0.0838, 0.1106, 0.1169, 0.1163, 0.1165, 0.1172, 0.1142, 0.1088, 0.0936,\n",
      "         0.0221]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 58.00, Train Loss: 3.18, Val Loss: 11.10, Train BLEU: 9.08, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 看到 这些 在 动 的 东西 了 吗 <EOS> <PAD>\n",
      "Reference: but see all those different working things ? <EOS>\n",
      "Model: <SOS> it &apos;s &apos;s to is . . . <EOS>\n",
      "Attention Weights: tensor([[0.0853, 0.0863, 0.0868, 0.0869, 0.0868, 0.0860, 0.0827, 0.0781, 0.0606,\n",
      "         0.2604],\n",
      "        [0.0777, 0.0845, 0.0860, 0.0864, 0.0865, 0.0860, 0.0832, 0.0800, 0.0572,\n",
      "         0.2725],\n",
      "        [0.0695, 0.0767, 0.0780, 0.0782, 0.0783, 0.0779, 0.0751, 0.0725, 0.0505,\n",
      "         0.3434],\n",
      "        [0.0542, 0.0617, 0.0628, 0.0630, 0.0630, 0.0625, 0.0601, 0.0579, 0.0365,\n",
      "         0.4784],\n",
      "        [0.0367, 0.0439, 0.0448, 0.0449, 0.0449, 0.0445, 0.0427, 0.0409, 0.0224,\n",
      "         0.6342],\n",
      "        [0.0233, 0.0296, 0.0305, 0.0306, 0.0305, 0.0302, 0.0290, 0.0273, 0.0131,\n",
      "         0.7559],\n",
      "        [0.0150, 0.0202, 0.0209, 0.0210, 0.0210, 0.0207, 0.0198, 0.0185, 0.0080,\n",
      "         0.8348],\n",
      "        [0.0108, 0.0150, 0.0156, 0.0157, 0.0157, 0.0155, 0.0148, 0.0136, 0.0056,\n",
      "         0.8778],\n",
      "        [0.0091, 0.0128, 0.0134, 0.0135, 0.0134, 0.0133, 0.0126, 0.0115, 0.0047,\n",
      "         0.8956]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 面带 <UNK> <UNK> 笑容 这 很少 少见 因为 大部\n",
      "Reference: there was a big smile on his face which\n",
      "Model: <SOS> most of the the the the the the the\n",
      "Attention Weights: tensor([[0.1085, 0.0984, 0.1093, 0.1107, 0.1127, 0.0997, 0.1004, 0.0986, 0.1015,\n",
      "         0.0601],\n",
      "        [0.1025, 0.0951, 0.1128, 0.1156, 0.1171, 0.0995, 0.1043, 0.1032, 0.1033,\n",
      "         0.0467],\n",
      "        [0.1020, 0.0900, 0.1162, 0.1191, 0.1196, 0.0961, 0.1069, 0.1053, 0.1050,\n",
      "         0.0399],\n",
      "        [0.1000, 0.0834, 0.1227, 0.1248, 0.1200, 0.0911, 0.1128, 0.1097, 0.1038,\n",
      "         0.0317],\n",
      "        [0.0966, 0.0802, 0.1278, 0.1287, 0.1203, 0.0890, 0.1180, 0.1129, 0.1000,\n",
      "         0.0263],\n",
      "        [0.0937, 0.0783, 0.1311, 0.1312, 0.1203, 0.0880, 0.1216, 0.1151, 0.0973,\n",
      "         0.0235],\n",
      "        [0.0918, 0.0775, 0.1326, 0.1324, 0.1204, 0.0878, 0.1234, 0.1161, 0.0957,\n",
      "         0.0221],\n",
      "        [0.0905, 0.0772, 0.1334, 0.1330, 0.1207, 0.0879, 0.1244, 0.1167, 0.0948,\n",
      "         0.0214],\n",
      "        [0.0896, 0.0770, 0.1339, 0.1334, 0.1210, 0.0879, 0.1250, 0.1171, 0.0942,\n",
      "         0.0210]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 59.00, Train Loss: 3.16, Val Loss: 11.12, Train BLEU: 8.64, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一种 种群 栖 动物 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: it &apos;s a colonial animal . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a a . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0678, 0.0688, 0.0710, 0.0704, 0.0674, 0.0643, 0.0490, 0.1804, 0.1804,\n",
      "         0.1804],\n",
      "        [0.0596, 0.0645, 0.0670, 0.0668, 0.0646, 0.0630, 0.0452, 0.1898, 0.1898,\n",
      "         0.1898],\n",
      "        [0.0483, 0.0533, 0.0556, 0.0553, 0.0533, 0.0525, 0.0356, 0.2154, 0.2154,\n",
      "         0.2154],\n",
      "        [0.0292, 0.0334, 0.0349, 0.0346, 0.0332, 0.0325, 0.0195, 0.2609, 0.2609,\n",
      "         0.2609],\n",
      "        [0.0144, 0.0178, 0.0187, 0.0186, 0.0178, 0.0171, 0.0085, 0.2957, 0.2957,\n",
      "         0.2957],\n",
      "        [0.0075, 0.0098, 0.0104, 0.0103, 0.0098, 0.0092, 0.0040, 0.3130, 0.3130,\n",
      "         0.3130],\n",
      "        [0.0054, 0.0072, 0.0077, 0.0076, 0.0072, 0.0067, 0.0028, 0.3185, 0.3185,\n",
      "         0.3185],\n",
      "        [0.0048, 0.0064, 0.0069, 0.0068, 0.0065, 0.0059, 0.0025, 0.3201, 0.3201,\n",
      "         0.3201],\n",
      "        [0.0045, 0.0061, 0.0065, 0.0064, 0.0061, 0.0056, 0.0023, 0.3208, 0.3208,\n",
      "         0.3208]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 永远 不会 忘记 那个 早晨 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: a morning that i will never forget . <EOS>\n",
      "Model: <SOS> it &apos;s a a . . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.1021, 0.1021, 0.1040, 0.1058, 0.1034, 0.1028, 0.1025, 0.0992, 0.0918,\n",
      "         0.0863],\n",
      "        [0.0960, 0.1047, 0.1079, 0.1100, 0.1074, 0.1071, 0.1089, 0.1074, 0.0870,\n",
      "         0.0636],\n",
      "        [0.0951, 0.1052, 0.1083, 0.1104, 0.1074, 0.1070, 0.1088, 0.1079, 0.0882,\n",
      "         0.0616],\n",
      "        [0.0941, 0.1073, 0.1107, 0.1128, 0.1097, 0.1092, 0.1106, 0.1090, 0.0833,\n",
      "         0.0534],\n",
      "        [0.0916, 0.1094, 0.1135, 0.1156, 0.1127, 0.1121, 0.1128, 0.1098, 0.0772,\n",
      "         0.0455],\n",
      "        [0.0897, 0.1106, 0.1151, 0.1171, 0.1144, 0.1137, 0.1139, 0.1098, 0.0738,\n",
      "         0.0419],\n",
      "        [0.0882, 0.1114, 0.1161, 0.1182, 0.1156, 0.1148, 0.1146, 0.1098, 0.0716,\n",
      "         0.0397],\n",
      "        [0.0872, 0.1118, 0.1168, 0.1189, 0.1162, 0.1154, 0.1150, 0.1098, 0.0703,\n",
      "         0.0384],\n",
      "        [0.0865, 0.1121, 0.1172, 0.1193, 0.1166, 0.1158, 0.1153, 0.1099, 0.0696,\n",
      "         0.0377]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60.00, Train Loss: 3.13, Val Loss: 11.11, Train BLEU: 8.55, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中 的 生命 大卫 <UNK> <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: life in the deep oceans <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a . <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0585, 0.0589, 0.0577, 0.0587, 0.0594, 0.0373, 0.0360, 0.2112, 0.2112,\n",
      "         0.2112],\n",
      "        [0.0523, 0.0569, 0.0572, 0.0590, 0.0592, 0.0320, 0.0332, 0.2167, 0.2167,\n",
      "         0.2167],\n",
      "        [0.0413, 0.0461, 0.0463, 0.0482, 0.0478, 0.0211, 0.0240, 0.2417, 0.2417,\n",
      "         0.2417],\n",
      "        [0.0211, 0.0250, 0.0251, 0.0258, 0.0245, 0.0086, 0.0103, 0.2866, 0.2866,\n",
      "         0.2866],\n",
      "        [0.0096, 0.0123, 0.0125, 0.0126, 0.0114, 0.0033, 0.0039, 0.3114, 0.3114,\n",
      "         0.3114],\n",
      "        [0.0054, 0.0073, 0.0075, 0.0074, 0.0065, 0.0018, 0.0021, 0.3207, 0.3207,\n",
      "         0.3207],\n",
      "        [0.0042, 0.0058, 0.0059, 0.0058, 0.0050, 0.0014, 0.0016, 0.3234, 0.3234,\n",
      "         0.3234],\n",
      "        [0.0038, 0.0052, 0.0054, 0.0052, 0.0045, 0.0013, 0.0015, 0.3243, 0.3243,\n",
      "         0.3243],\n",
      "        [0.0037, 0.0050, 0.0052, 0.0050, 0.0043, 0.0013, 0.0014, 0.3247, 0.3247,\n",
      "         0.3247]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 面带 <UNK> <UNK> 笑容 这 很少 少见 因为 大部\n",
      "Reference: there was a big smile on his face which\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.1097, 0.0973, 0.1111, 0.1131, 0.1118, 0.0979, 0.1008, 0.0989, 0.1008,\n",
      "         0.0585],\n",
      "        [0.1043, 0.0940, 0.1138, 0.1173, 0.1170, 0.0979, 0.1041, 0.1029, 0.1031,\n",
      "         0.0457],\n",
      "        [0.1039, 0.0878, 0.1181, 0.1217, 0.1194, 0.0932, 0.1073, 0.1054, 0.1049,\n",
      "         0.0383],\n",
      "        [0.1016, 0.0807, 0.1253, 0.1279, 0.1191, 0.0875, 0.1138, 0.1102, 0.1036,\n",
      "         0.0303],\n",
      "        [0.0980, 0.0771, 0.1309, 0.1324, 0.1189, 0.0850, 0.1195, 0.1137, 0.0995,\n",
      "         0.0250],\n",
      "        [0.0952, 0.0750, 0.1344, 0.1350, 0.1186, 0.0837, 0.1233, 0.1159, 0.0966,\n",
      "         0.0223],\n",
      "        [0.0933, 0.0741, 0.1360, 0.1362, 0.1187, 0.0835, 0.1253, 0.1170, 0.0949,\n",
      "         0.0210],\n",
      "        [0.0920, 0.0737, 0.1368, 0.1369, 0.1190, 0.0835, 0.1263, 0.1177, 0.0938,\n",
      "         0.0203],\n",
      "        [0.0911, 0.0735, 0.1373, 0.1373, 0.1192, 0.0835, 0.1270, 0.1180, 0.0932,\n",
      "         0.0200]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 61.00, Train Loss: 3.10, Val Loss: 11.14, Train BLEU: 8.56, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想 海洋 占 了 地球 球面 面积 的 75\n",
      "Reference: when you think about it , the oceans are\n",
      "Model: <SOS> it &apos;s the the , , , , ,\n",
      "Attention Weights: tensor([[0.1036, 0.1047, 0.1078, 0.1059, 0.1063, 0.1080, 0.1053, 0.1008, 0.0990,\n",
      "         0.0586],\n",
      "        [0.0976, 0.1054, 0.1099, 0.1076, 0.1082, 0.1104, 0.1079, 0.1049, 0.1036,\n",
      "         0.0444],\n",
      "        [0.0975, 0.1067, 0.1115, 0.1088, 0.1093, 0.1117, 0.1087, 0.1053, 0.1031,\n",
      "         0.0373],\n",
      "        [0.0965, 0.1083, 0.1134, 0.1106, 0.1110, 0.1133, 0.1099, 0.1059, 0.1015,\n",
      "         0.0298],\n",
      "        [0.0938, 0.1096, 0.1149, 0.1125, 0.1128, 0.1147, 0.1113, 0.1068, 0.0987,\n",
      "         0.0248],\n",
      "        [0.0909, 0.1109, 0.1164, 0.1143, 0.1145, 0.1160, 0.1125, 0.1074, 0.0956,\n",
      "         0.0214],\n",
      "        [0.0886, 0.1118, 0.1175, 0.1156, 0.1157, 0.1170, 0.1134, 0.1078, 0.0932,\n",
      "         0.0194],\n",
      "        [0.0871, 0.1123, 0.1183, 0.1164, 0.1164, 0.1177, 0.1140, 0.1079, 0.0916,\n",
      "         0.0184],\n",
      "        [0.0861, 0.1126, 0.1187, 0.1168, 0.1168, 0.1181, 0.1143, 0.1080, 0.0907,\n",
      "         0.0179]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 有时 学校 <UNK> 突然 <UNK> 一周 因为 被 塔利 塔利班\n",
      "Reference: from time to time , the school would suddenly\n",
      "Model: <SOS> it &apos;s got , , , , , ,\n",
      "Attention Weights: tensor([[0.0969, 0.0984, 0.1011, 0.1038, 0.1026, 0.1029, 0.1018, 0.1000, 0.0973,\n",
      "         0.0953],\n",
      "        [0.0919, 0.0985, 0.1015, 0.1042, 0.1029, 0.1032, 0.1022, 0.1005, 0.0983,\n",
      "         0.0968],\n",
      "        [0.0915, 0.0990, 0.1020, 0.1050, 0.1033, 0.1036, 0.1023, 0.1003, 0.0976,\n",
      "         0.0954],\n",
      "        [0.0910, 0.0994, 0.1026, 0.1056, 0.1037, 0.1040, 0.1024, 0.1001, 0.0971,\n",
      "         0.0941],\n",
      "        [0.0894, 0.0998, 0.1032, 0.1063, 0.1044, 0.1046, 0.1029, 0.1003, 0.0969,\n",
      "         0.0921],\n",
      "        [0.0871, 0.1002, 0.1040, 0.1070, 0.1052, 0.1053, 0.1035, 0.1008, 0.0970,\n",
      "         0.0899],\n",
      "        [0.0852, 0.1006, 0.1046, 0.1076, 0.1059, 0.1058, 0.1040, 0.1011, 0.0970,\n",
      "         0.0882],\n",
      "        [0.0836, 0.1008, 0.1051, 0.1081, 0.1063, 0.1063, 0.1043, 0.1014, 0.0970,\n",
      "         0.0870],\n",
      "        [0.0824, 0.1010, 0.1054, 0.1084, 0.1067, 0.1066, 0.1046, 0.1016, 0.0971,\n",
      "         0.0862]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 62.00, Train Loss: 3.07, Val Loss: 11.16, Train BLEU: 9.49, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 但 我 想 告诉 你 的 是 当 你 站\n",
      "Reference: but when you &apos;re standing at the beach ,\n",
      "Model: <SOS> we the the the the the the the the\n",
      "Attention Weights: tensor([[0.0969, 0.0985, 0.1011, 0.1038, 0.1026, 0.1029, 0.1018, 0.1000, 0.0974,\n",
      "         0.0952],\n",
      "        [0.0923, 0.0985, 0.1015, 0.1042, 0.1028, 0.1031, 0.1021, 0.1004, 0.0983,\n",
      "         0.0968],\n",
      "        [0.0918, 0.0990, 0.1020, 0.1050, 0.1032, 0.1036, 0.1022, 0.1002, 0.0976,\n",
      "         0.0954],\n",
      "        [0.0913, 0.0995, 0.1025, 0.1057, 0.1037, 0.1039, 0.1024, 0.1000, 0.0970,\n",
      "         0.0941],\n",
      "        [0.0898, 0.0998, 0.1031, 0.1064, 0.1043, 0.1046, 0.1028, 0.1002, 0.0968,\n",
      "         0.0921],\n",
      "        [0.0875, 0.1003, 0.1039, 0.1072, 0.1051, 0.1052, 0.1034, 0.1006, 0.0968,\n",
      "         0.0899],\n",
      "        [0.0856, 0.1007, 0.1046, 0.1078, 0.1058, 0.1058, 0.1039, 0.1010, 0.0968,\n",
      "         0.0882],\n",
      "        [0.0840, 0.1009, 0.1051, 0.1082, 0.1063, 0.1062, 0.1042, 0.1012, 0.0969,\n",
      "         0.0870],\n",
      "        [0.0828, 0.1011, 0.1054, 0.1086, 0.1067, 0.1065, 0.1045, 0.1014, 0.0969,\n",
      "         0.0861]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 因此 毫无 毫无疑问 无疑 疑问 他 的 孩子 应当 受到\n",
      "Reference: there was no question that his children would receive\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0868, 0.0882, 0.0899, 0.0892, 0.0918, 0.1027, 0.0843, 0.0787, 0.0585,\n",
      "         0.2299],\n",
      "        [0.0806, 0.0866, 0.0889, 0.0886, 0.0917, 0.1008, 0.0850, 0.0817, 0.0573,\n",
      "         0.2387],\n",
      "        [0.0728, 0.0796, 0.0817, 0.0811, 0.0846, 0.0943, 0.0776, 0.0753, 0.0509,\n",
      "         0.3021],\n",
      "        [0.0591, 0.0663, 0.0683, 0.0676, 0.0706, 0.0797, 0.0642, 0.0623, 0.0383,\n",
      "         0.4237],\n",
      "        [0.0426, 0.0502, 0.0518, 0.0513, 0.0534, 0.0604, 0.0485, 0.0466, 0.0249,\n",
      "         0.5702],\n",
      "        [0.0279, 0.0349, 0.0361, 0.0358, 0.0371, 0.0417, 0.0337, 0.0318, 0.0146,\n",
      "         0.7064],\n",
      "        [0.0177, 0.0236, 0.0246, 0.0244, 0.0252, 0.0281, 0.0229, 0.0212, 0.0086,\n",
      "         0.8036],\n",
      "        [0.0123, 0.0170, 0.0179, 0.0178, 0.0183, 0.0204, 0.0166, 0.0151, 0.0058,\n",
      "         0.8589],\n",
      "        [0.0100, 0.0141, 0.0148, 0.0147, 0.0151, 0.0169, 0.0137, 0.0124, 0.0047,\n",
      "         0.8835]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 63.00, Train Loss: 3.05, Val Loss: 11.17, Train BLEU: 8.77, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想 海洋 占 了 地球 球面 面积 的 75\n",
      "Reference: when you think about it , the oceans are\n",
      "Model: <SOS> it &apos;s the the , , , , ,\n",
      "Attention Weights: tensor([[0.1045, 0.1051, 0.1081, 0.1059, 0.1062, 0.1080, 0.1051, 0.1005, 0.0981,\n",
      "         0.0585],\n",
      "        [0.0986, 0.1057, 0.1103, 0.1075, 0.1079, 0.1105, 0.1077, 0.1045, 0.1031,\n",
      "         0.0440],\n",
      "        [0.0981, 0.1071, 0.1122, 0.1088, 0.1092, 0.1122, 0.1087, 0.1050, 0.1025,\n",
      "         0.0362],\n",
      "        [0.0969, 0.1088, 0.1141, 0.1107, 0.1110, 0.1138, 0.1100, 0.1057, 0.1006,\n",
      "         0.0283],\n",
      "        [0.0942, 0.1103, 0.1157, 0.1128, 0.1129, 0.1152, 0.1114, 0.1066, 0.0976,\n",
      "         0.0235],\n",
      "        [0.0913, 0.1115, 0.1172, 0.1146, 0.1146, 0.1165, 0.1126, 0.1071, 0.0943,\n",
      "         0.0203],\n",
      "        [0.0890, 0.1124, 0.1183, 0.1158, 0.1158, 0.1174, 0.1135, 0.1074, 0.0918,\n",
      "         0.0186],\n",
      "        [0.0874, 0.1130, 0.1189, 0.1166, 0.1165, 0.1180, 0.1140, 0.1076, 0.0902,\n",
      "         0.0178],\n",
      "        [0.0865, 0.1133, 0.1194, 0.1170, 0.1169, 0.1184, 0.1142, 0.1076, 0.0893,\n",
      "         0.0174]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在 一个 房屋 房屋里 屋里 我们 100 多 人\n",
      "Reference: the school was in a house , more than\n",
      "Model: <SOS> we the the the the the the the the\n",
      "Attention Weights: tensor([[0.1004, 0.1096, 0.1019, 0.1025, 0.1004, 0.1025, 0.1004, 0.0966, 0.0938,\n",
      "         0.0920],\n",
      "        [0.0948, 0.1088, 0.1013, 0.1025, 0.1006, 0.1032, 0.1009, 0.0969, 0.0950,\n",
      "         0.0959],\n",
      "        [0.0942, 0.1108, 0.1017, 0.1031, 0.1006, 0.1037, 0.1011, 0.0963, 0.0939,\n",
      "         0.0947],\n",
      "        [0.0928, 0.1122, 0.1027, 0.1039, 0.1010, 0.1042, 0.1013, 0.0960, 0.0932,\n",
      "         0.0925],\n",
      "        [0.0898, 0.1128, 0.1039, 0.1051, 0.1022, 0.1051, 0.1021, 0.0967, 0.0933,\n",
      "         0.0889],\n",
      "        [0.0867, 0.1129, 0.1052, 0.1062, 0.1034, 0.1059, 0.1028, 0.0975, 0.0936,\n",
      "         0.0858],\n",
      "        [0.0842, 0.1131, 0.1061, 0.1071, 0.1043, 0.1064, 0.1034, 0.0980, 0.0938,\n",
      "         0.0837],\n",
      "        [0.0826, 0.1133, 0.1067, 0.1076, 0.1048, 0.1068, 0.1037, 0.0983, 0.0938,\n",
      "         0.0823],\n",
      "        [0.0816, 0.1134, 0.1070, 0.1080, 0.1051, 0.1070, 0.1039, 0.0985, 0.0939,\n",
      "         0.0815]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64.00, Train Loss: 3.02, Val Loss: 11.19, Train BLEU: 9.53, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克 泰坦尼克号 坦尼 尼克 号 是 拿 了 不少\n",
      "Reference: the truth of the matter is that the titanic\n",
      "Model: <SOS> we the the the the the the the the\n",
      "Attention Weights: tensor([[0.0975, 0.1107, 0.1134, 0.1159, 0.1015, 0.0953, 0.0944, 0.0926, 0.0901,\n",
      "         0.0886],\n",
      "        [0.0944, 0.1080, 0.1128, 0.1141, 0.1011, 0.0961, 0.0953, 0.0936, 0.0919,\n",
      "         0.0927],\n",
      "        [0.0940, 0.1113, 0.1150, 0.1146, 0.1006, 0.0954, 0.0945, 0.0925, 0.0906,\n",
      "         0.0915],\n",
      "        [0.0927, 0.1120, 0.1159, 0.1162, 0.1018, 0.0957, 0.0945, 0.0922, 0.0898,\n",
      "         0.0893],\n",
      "        [0.0895, 0.1120, 0.1169, 0.1180, 0.1033, 0.0968, 0.0954, 0.0927, 0.0897,\n",
      "         0.0857],\n",
      "        [0.0859, 0.1121, 0.1181, 0.1199, 0.1044, 0.0979, 0.0963, 0.0933, 0.0898,\n",
      "         0.0822],\n",
      "        [0.0832, 0.1121, 0.1192, 0.1214, 0.1051, 0.0986, 0.0968, 0.0937, 0.0899,\n",
      "         0.0800],\n",
      "        [0.0817, 0.1121, 0.1197, 0.1222, 0.1055, 0.0990, 0.0972, 0.0939, 0.0899,\n",
      "         0.0787],\n",
      "        [0.0807, 0.1119, 0.1199, 0.1225, 0.1058, 0.0993, 0.0975, 0.0942, 0.0900,\n",
      "         0.0781]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 在 塔利 塔利班 控制 阿富汗 的 那些 年 我 记得\n",
      "Reference: during taliban years , i remember there were times\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.1050, 0.1069, 0.1067, 0.1079, 0.1076, 0.1083, 0.1042, 0.1007, 0.0952,\n",
      "         0.0575],\n",
      "        [0.1000, 0.1072, 0.1078, 0.1092, 0.1092, 0.1109, 0.1066, 0.1067, 0.1032,\n",
      "         0.0392],\n",
      "        [0.0994, 0.1080, 0.1085, 0.1100, 0.1100, 0.1116, 0.1068, 0.1069, 0.1039,\n",
      "         0.0349],\n",
      "        [0.0983, 0.1098, 0.1106, 0.1120, 0.1119, 0.1133, 0.1081, 0.1072, 0.1013,\n",
      "         0.0276],\n",
      "        [0.0965, 0.1113, 0.1124, 0.1138, 0.1136, 0.1146, 0.1094, 0.1072, 0.0979,\n",
      "         0.0234],\n",
      "        [0.0947, 0.1124, 0.1139, 0.1152, 0.1149, 0.1156, 0.1105, 0.1071, 0.0951,\n",
      "         0.0206],\n",
      "        [0.0932, 0.1132, 0.1150, 0.1163, 0.1159, 0.1164, 0.1112, 0.1070, 0.0930,\n",
      "         0.0188],\n",
      "        [0.0920, 0.1137, 0.1157, 0.1170, 0.1166, 0.1170, 0.1117, 0.1070, 0.0916,\n",
      "         0.0176],\n",
      "        [0.0911, 0.1141, 0.1162, 0.1175, 0.1171, 0.1174, 0.1121, 0.1070, 0.0906,\n",
      "         0.0169]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 65.00, Train Loss: 2.99, Val Loss: 11.22, Train BLEU: 9.45, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 和 我们 合作 的 人们 帮 我们 找到 了 新\n",
      "Reference: people that have partnered with us have given us\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0960, 0.0995, 0.1038, 0.1023, 0.1039, 0.1012, 0.1022, 0.1012, 0.0965,\n",
      "         0.0935],\n",
      "        [0.0924, 0.0994, 0.1040, 0.1024, 0.1042, 0.1012, 0.1025, 0.1014, 0.0971,\n",
      "         0.0953],\n",
      "        [0.0916, 0.1000, 0.1050, 0.1028, 0.1050, 0.1013, 0.1029, 0.1015, 0.0962,\n",
      "         0.0937],\n",
      "        [0.0908, 0.1005, 0.1059, 0.1034, 0.1056, 0.1014, 0.1032, 0.1016, 0.0956,\n",
      "         0.0921],\n",
      "        [0.0892, 0.1009, 0.1066, 0.1041, 0.1063, 0.1020, 0.1037, 0.1019, 0.0953,\n",
      "         0.0900],\n",
      "        [0.0871, 0.1013, 0.1073, 0.1049, 0.1069, 0.1027, 0.1042, 0.1022, 0.0953,\n",
      "         0.0880],\n",
      "        [0.0851, 0.1017, 0.1079, 0.1056, 0.1075, 0.1034, 0.1046, 0.1025, 0.0954,\n",
      "         0.0864],\n",
      "        [0.0833, 0.1020, 0.1084, 0.1061, 0.1080, 0.1039, 0.1050, 0.1027, 0.0955,\n",
      "         0.0852],\n",
      "        [0.0820, 0.1022, 0.1087, 0.1065, 0.1083, 0.1043, 0.1052, 0.1029, 0.0955,\n",
      "         0.0843]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 在 被 跟踪 吗 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: were we being followed ? <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a a . . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0971, 0.0980, 0.1011, 0.1030, 0.1086, 0.1142, 0.0964, 0.0901, 0.0976,\n",
      "         0.0938],\n",
      "        [0.0925, 0.0972, 0.1011, 0.1044, 0.1122, 0.1190, 0.0943, 0.0885, 0.0970,\n",
      "         0.0938],\n",
      "        [0.0920, 0.0973, 0.1014, 0.1055, 0.1163, 0.1245, 0.0917, 0.0831, 0.0960,\n",
      "         0.0922],\n",
      "        [0.0932, 0.0997, 0.1038, 0.1077, 0.1190, 0.1264, 0.0832, 0.0759, 0.0983,\n",
      "         0.0929],\n",
      "        [0.0929, 0.1020, 0.1064, 0.1103, 0.1220, 0.1288, 0.0758, 0.0688, 0.1003,\n",
      "         0.0927],\n",
      "        [0.0916, 0.1041, 0.1088, 0.1127, 0.1239, 0.1295, 0.0715, 0.0645, 0.1015,\n",
      "         0.0921],\n",
      "        [0.0901, 0.1056, 0.1106, 0.1144, 0.1245, 0.1291, 0.0695, 0.0624, 0.1022,\n",
      "         0.0916],\n",
      "        [0.0888, 0.1067, 0.1120, 0.1157, 0.1249, 0.1287, 0.0683, 0.0610, 0.1027,\n",
      "         0.0911],\n",
      "        [0.0878, 0.1074, 0.1130, 0.1167, 0.1252, 0.1285, 0.0676, 0.0600, 0.1030,\n",
      "         0.0907]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 66.00, Train Loss: 2.96, Val Loss: 11.22, Train BLEU: 9.68, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 还有 这些 摇晃 着 旋转 转着 的 触角 <EOS> <PAD>\n",
      "Reference: it &apos;s got tentacles dangling , swirling around like\n",
      "Model: <SOS> it &apos;s &apos;s to is . . . <EOS>\n",
      "Attention Weights: tensor([[0.0859, 0.0873, 0.0889, 0.0878, 0.0905, 0.1043, 0.0825, 0.0767, 0.0560,\n",
      "         0.2402],\n",
      "        [0.0801, 0.0852, 0.0873, 0.0865, 0.0899, 0.1019, 0.0825, 0.0790, 0.0557,\n",
      "         0.2520],\n",
      "        [0.0720, 0.0779, 0.0798, 0.0788, 0.0827, 0.0954, 0.0748, 0.0724, 0.0492,\n",
      "         0.3171],\n",
      "        [0.0562, 0.0629, 0.0647, 0.0637, 0.0671, 0.0786, 0.0600, 0.0580, 0.0349,\n",
      "         0.4538],\n",
      "        [0.0393, 0.0464, 0.0479, 0.0471, 0.0495, 0.0583, 0.0442, 0.0422, 0.0218,\n",
      "         0.6031],\n",
      "        [0.0241, 0.0304, 0.0316, 0.0312, 0.0325, 0.0380, 0.0290, 0.0271, 0.0118,\n",
      "         0.7443],\n",
      "        [0.0144, 0.0194, 0.0203, 0.0201, 0.0208, 0.0243, 0.0186, 0.0170, 0.0066,\n",
      "         0.8384],\n",
      "        [0.0098, 0.0136, 0.0143, 0.0142, 0.0146, 0.0171, 0.0131, 0.0118, 0.0045,\n",
      "         0.8872],\n",
      "        [0.0082, 0.0116, 0.0122, 0.0121, 0.0124, 0.0146, 0.0111, 0.0100, 0.0038,\n",
      "         0.9041]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 但是 我 那 受过 教育 的 母亲 成为 为了 一名\n",
      "Reference: but my educated mother became a teacher . <EOS>\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0737, 0.0800, 0.0863, 0.0645, 0.0930, 0.0756, 0.0677, 0.0499, 0.2047,\n",
      "         0.2047],\n",
      "        [0.0672, 0.0770, 0.0851, 0.0650, 0.0867, 0.0723, 0.0672, 0.0494, 0.2150,\n",
      "         0.2150],\n",
      "        [0.0585, 0.0696, 0.0769, 0.0523, 0.0756, 0.0632, 0.0591, 0.0418, 0.2515,\n",
      "         0.2515],\n",
      "        [0.0391, 0.0484, 0.0535, 0.0307, 0.0529, 0.0440, 0.0408, 0.0246, 0.3330,\n",
      "         0.3330],\n",
      "        [0.0227, 0.0293, 0.0323, 0.0162, 0.0324, 0.0273, 0.0250, 0.0126, 0.4012,\n",
      "         0.4012],\n",
      "        [0.0125, 0.0170, 0.0186, 0.0085, 0.0188, 0.0160, 0.0144, 0.0062, 0.4440,\n",
      "         0.4440],\n",
      "        [0.0073, 0.0102, 0.0112, 0.0051, 0.0115, 0.0098, 0.0087, 0.0034, 0.4664,\n",
      "         0.4664],\n",
      "        [0.0057, 0.0081, 0.0089, 0.0041, 0.0091, 0.0077, 0.0068, 0.0027, 0.4735,\n",
      "         0.4735],\n",
      "        [0.0054, 0.0076, 0.0084, 0.0039, 0.0087, 0.0073, 0.0064, 0.0025, 0.4749,\n",
      "         0.4749]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 67.00, Train Loss: 2.93, Val Loss: 11.22, Train BLEU: 9.69, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 是 我 最 喜欢 的 因为 它 哪 都 能动\n",
      "Reference: it &apos;s one of my favorites , because it\n",
      "Model: <SOS> it &apos;s &apos;s got , , , , ,\n",
      "Attention Weights: tensor([[0.1025, 0.1038, 0.1065, 0.1093, 0.1081, 0.1084, 0.1050, 0.1017, 0.0977,\n",
      "         0.0571],\n",
      "        [0.0983, 0.1040, 0.1072, 0.1106, 0.1091, 0.1100, 0.1064, 0.1040, 0.1022,\n",
      "         0.0481],\n",
      "        [0.0972, 0.1049, 0.1083, 0.1121, 0.1103, 0.1115, 0.1073, 0.1044, 0.1021,\n",
      "         0.0420],\n",
      "        [0.0970, 0.1059, 0.1095, 0.1135, 0.1115, 0.1126, 0.1079, 0.1046, 0.1016,\n",
      "         0.0360],\n",
      "        [0.0961, 0.1068, 0.1108, 0.1149, 0.1128, 0.1138, 0.1088, 0.1050, 0.1008,\n",
      "         0.0301],\n",
      "        [0.0938, 0.1078, 0.1121, 0.1161, 0.1141, 0.1149, 0.1099, 0.1057, 0.0993,\n",
      "         0.0263],\n",
      "        [0.0915, 0.1085, 0.1132, 0.1171, 0.1152, 0.1158, 0.1108, 0.1061, 0.0979,\n",
      "         0.0237],\n",
      "        [0.0897, 0.1091, 0.1141, 0.1179, 0.1161, 0.1165, 0.1114, 0.1064, 0.0968,\n",
      "         0.0218],\n",
      "        [0.0884, 0.1095, 0.1147, 0.1185, 0.1167, 0.1170, 0.1118, 0.1066, 0.0960,\n",
      "         0.0206]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 很 幸运 幸运地 成长 在 一个 珍视 教育 也\n",
      "Reference: i was very lucky to grow up in a\n",
      "Model: <SOS> we the the the the the the the the\n",
      "Attention Weights: tensor([[0.0461, 0.0465, 0.0464, 0.0439, 0.0322, 0.1570, 0.1570, 0.1570, 0.1570,\n",
      "         0.1570],\n",
      "        [0.0386, 0.0410, 0.0417, 0.0407, 0.0289, 0.1618, 0.1618, 0.1618, 0.1618,\n",
      "         0.1618],\n",
      "        [0.0303, 0.0329, 0.0334, 0.0329, 0.0220, 0.1697, 0.1697, 0.1697, 0.1697,\n",
      "         0.1697],\n",
      "        [0.0145, 0.0166, 0.0169, 0.0164, 0.0093, 0.1853, 0.1853, 0.1853, 0.1853,\n",
      "         0.1853],\n",
      "        [0.0065, 0.0079, 0.0081, 0.0078, 0.0036, 0.1932, 0.1932, 0.1932, 0.1932,\n",
      "         0.1932],\n",
      "        [0.0038, 0.0048, 0.0049, 0.0046, 0.0020, 0.1960, 0.1960, 0.1960, 0.1960,\n",
      "         0.1960],\n",
      "        [0.0030, 0.0038, 0.0039, 0.0036, 0.0015, 0.1969, 0.1969, 0.1969, 0.1969,\n",
      "         0.1969],\n",
      "        [0.0026, 0.0033, 0.0034, 0.0031, 0.0013, 0.1973, 0.1973, 0.1973, 0.1973,\n",
      "         0.1973],\n",
      "        [0.0025, 0.0032, 0.0033, 0.0030, 0.0013, 0.1974, 0.1974, 0.1974, 0.1974,\n",
      "         0.1974]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68.00, Train Loss: 2.91, Val Loss: 11.26, Train BLEU: 10.24, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 我们 将 用 一些 影片 来讲 讲述 一些 深海 海里\n",
      "Reference: and we &apos;re going to tell you some stories\n",
      "Model: <SOS> and of the the the the the the the\n",
      "Attention Weights: tensor([[0.0963, 0.0973, 0.1000, 0.1047, 0.1043, 0.1033, 0.1023, 0.1015, 0.0975,\n",
      "         0.0927],\n",
      "        [0.0923, 0.0965, 0.0995, 0.1048, 0.1040, 0.1031, 0.1022, 0.1017, 0.0992,\n",
      "         0.0967],\n",
      "        [0.0912, 0.0963, 0.0993, 0.1058, 0.1048, 0.1037, 0.1027, 0.1020, 0.0988,\n",
      "         0.0956],\n",
      "        [0.0899, 0.0964, 0.0997, 0.1068, 0.1056, 0.1043, 0.1031, 0.1023, 0.0984,\n",
      "         0.0935],\n",
      "        [0.0879, 0.0967, 0.1004, 0.1078, 0.1067, 0.1053, 0.1040, 0.1028, 0.0982,\n",
      "         0.0904],\n",
      "        [0.0856, 0.0973, 0.1013, 0.1086, 0.1076, 0.1061, 0.1047, 0.1032, 0.0981,\n",
      "         0.0876],\n",
      "        [0.0835, 0.0978, 0.1021, 0.1092, 0.1083, 0.1068, 0.1053, 0.1036, 0.0980,\n",
      "         0.0854],\n",
      "        [0.0816, 0.0982, 0.1028, 0.1098, 0.1090, 0.1074, 0.1058, 0.1039, 0.0979,\n",
      "         0.0837],\n",
      "        [0.0804, 0.0984, 0.1032, 0.1102, 0.1094, 0.1077, 0.1061, 0.1042, 0.0979,\n",
      "         0.0826]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 祖父 在 他 的 年代 是 位非 非凡\n",
      "Reference: my grandfather was an extraordinary man for his time\n",
      "Model: <SOS> we of the the the the the the ,\n",
      "Attention Weights: tensor([[0.1023, 0.1042, 0.1068, 0.1098, 0.1084, 0.1089, 0.1052, 0.1016, 0.0970,\n",
      "         0.0558],\n",
      "        [0.0985, 0.1042, 0.1074, 0.1109, 0.1093, 0.1103, 0.1065, 0.1039, 0.1016,\n",
      "         0.0474],\n",
      "        [0.0973, 0.1049, 0.1084, 0.1125, 0.1105, 0.1118, 0.1073, 0.1043, 0.1016,\n",
      "         0.0414],\n",
      "        [0.0971, 0.1059, 0.1096, 0.1140, 0.1117, 0.1130, 0.1079, 0.1045, 0.1011,\n",
      "         0.0350],\n",
      "        [0.0965, 0.1068, 0.1108, 0.1155, 0.1130, 0.1143, 0.1087, 0.1048, 0.1004,\n",
      "         0.0292],\n",
      "        [0.0944, 0.1077, 0.1122, 0.1167, 0.1143, 0.1154, 0.1098, 0.1054, 0.0990,\n",
      "         0.0251],\n",
      "        [0.0921, 0.1085, 0.1133, 0.1177, 0.1155, 0.1163, 0.1107, 0.1059, 0.0976,\n",
      "         0.0225],\n",
      "        [0.0902, 0.1090, 0.1142, 0.1185, 0.1163, 0.1170, 0.1114, 0.1062, 0.0965,\n",
      "         0.0206],\n",
      "        [0.0889, 0.1094, 0.1148, 0.1191, 0.1170, 0.1175, 0.1118, 0.1063, 0.0956,\n",
      "         0.0194]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 69.00, Train Loss: 2.87, Val Loss: 11.26, Train BLEU: 10.07, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 其实 它们 都 是 由 单独 的 动物 结合 合在\n",
      "Reference: these are all individual animals banding together to make\n",
      "Model: <SOS> these these these are are are are are are\n",
      "Attention Weights: tensor([[0.1057, 0.1083, 0.1074, 0.1084, 0.1080, 0.1089, 0.1037, 0.0999, 0.0941,\n",
      "         0.0556],\n",
      "        [0.1008, 0.1088, 0.1087, 0.1100, 0.1099, 0.1122, 0.1063, 0.1065, 0.1012,\n",
      "         0.0357],\n",
      "        [0.1003, 0.1095, 0.1094, 0.1107, 0.1105, 0.1129, 0.1065, 0.1067, 0.1018,\n",
      "         0.0318],\n",
      "        [0.0995, 0.1114, 0.1113, 0.1126, 0.1123, 0.1145, 0.1076, 0.1066, 0.0991,\n",
      "         0.0250],\n",
      "        [0.0977, 0.1130, 0.1133, 0.1145, 0.1142, 0.1160, 0.1090, 0.1065, 0.0956,\n",
      "         0.0202],\n",
      "        [0.0958, 0.1143, 0.1148, 0.1160, 0.1156, 0.1171, 0.1101, 0.1063, 0.0924,\n",
      "         0.0175],\n",
      "        [0.0942, 0.1152, 0.1160, 0.1172, 0.1167, 0.1179, 0.1109, 0.1061, 0.0901,\n",
      "         0.0157],\n",
      "        [0.0930, 0.1158, 0.1168, 0.1180, 0.1175, 0.1185, 0.1115, 0.1060, 0.0883,\n",
      "         0.0146],\n",
      "        [0.0920, 0.1162, 0.1174, 0.1186, 0.1181, 0.1190, 0.1119, 0.1059, 0.0871,\n",
      "         0.0139]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天 要 走 不同 的 路线 这样 才 没有\n",
      "Reference: each day , we took a different route so\n",
      "Model: <SOS> and of the the the the the the the\n",
      "Attention Weights: tensor([[0.0973, 0.1013, 0.1044, 0.1019, 0.1043, 0.1019, 0.1027, 0.0984, 0.0955,\n",
      "         0.0923],\n",
      "        [0.0933, 0.1006, 0.1041, 0.1012, 0.1041, 0.1014, 0.1030, 0.0981, 0.0964,\n",
      "         0.0975],\n",
      "        [0.0925, 0.1013, 0.1052, 0.1012, 0.1049, 0.1014, 0.1035, 0.0973, 0.0953,\n",
      "         0.0974],\n",
      "        [0.0912, 0.1019, 0.1063, 0.1018, 0.1058, 0.1019, 0.1040, 0.0971, 0.0946,\n",
      "         0.0954],\n",
      "        [0.0888, 0.1026, 0.1073, 0.1029, 0.1068, 0.1029, 0.1048, 0.0977, 0.0944,\n",
      "         0.0917],\n",
      "        [0.0861, 0.1032, 0.1082, 0.1040, 0.1078, 0.1039, 0.1056, 0.0984, 0.0945,\n",
      "         0.0884],\n",
      "        [0.0838, 0.1036, 0.1089, 0.1049, 0.1085, 0.1047, 0.1061, 0.0989, 0.0946,\n",
      "         0.0859],\n",
      "        [0.0819, 0.1040, 0.1095, 0.1056, 0.1091, 0.1053, 0.1066, 0.0993, 0.0946,\n",
      "         0.0841],\n",
      "        [0.0808, 0.1042, 0.1099, 0.1060, 0.1094, 0.1056, 0.1068, 0.0996, 0.0946,\n",
      "         0.0831]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 70.00, Train Loss: 2.86, Val Loss: 11.26, Train BLEU: 9.92, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想 海洋 占 了 地球 球面 面积 的 75\n",
      "Reference: when you think about it , the oceans are\n",
      "Model: <SOS> it you you the , , , , ,\n",
      "Attention Weights: tensor([[0.1048, 0.1065, 0.1103, 0.1066, 0.1065, 0.1094, 0.1054, 0.0996, 0.0944,\n",
      "         0.0565],\n",
      "        [0.0996, 0.1067, 0.1125, 0.1074, 0.1075, 0.1124, 0.1080, 0.1036, 0.1000,\n",
      "         0.0423],\n",
      "        [0.0986, 0.1082, 0.1150, 0.1089, 0.1090, 0.1147, 0.1094, 0.1042, 0.0990,\n",
      "         0.0331],\n",
      "        [0.0970, 0.1100, 0.1172, 0.1110, 0.1110, 0.1165, 0.1107, 0.1047, 0.0965,\n",
      "         0.0252],\n",
      "        [0.0943, 0.1115, 0.1187, 0.1131, 0.1131, 0.1178, 0.1122, 0.1054, 0.0931,\n",
      "         0.0207],\n",
      "        [0.0914, 0.1128, 0.1202, 0.1150, 0.1148, 0.1190, 0.1133, 0.1058, 0.0898,\n",
      "         0.0179],\n",
      "        [0.0892, 0.1137, 0.1212, 0.1163, 0.1160, 0.1199, 0.1141, 0.1059, 0.0873,\n",
      "         0.0165],\n",
      "        [0.0879, 0.1142, 0.1219, 0.1170, 0.1166, 0.1204, 0.1145, 0.1059, 0.0857,\n",
      "         0.0160],\n",
      "        [0.0871, 0.1145, 0.1222, 0.1174, 0.1170, 0.1206, 0.1147, 0.1059, 0.0848,\n",
      "         0.0157]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 有时 学校 <UNK> 突然 <UNK> 一周 因为 被 塔利 塔利班\n",
      "Reference: from time to time , the school would suddenly\n",
      "Model: <SOS> it &apos;s got , , , , , ,\n",
      "Attention Weights: tensor([[0.0960, 0.0992, 0.1016, 0.1046, 0.1030, 0.1033, 0.1020, 0.1000, 0.0972,\n",
      "         0.0932],\n",
      "        [0.0930, 0.0992, 0.1018, 0.1048, 0.1028, 0.1032, 0.1019, 0.1001, 0.0979,\n",
      "         0.0954],\n",
      "        [0.0923, 0.0997, 0.1023, 0.1059, 0.1032, 0.1037, 0.1020, 0.0998, 0.0971,\n",
      "         0.0940],\n",
      "        [0.0911, 0.0999, 0.1029, 0.1068, 0.1038, 0.1043, 0.1025, 0.0999, 0.0967,\n",
      "         0.0923],\n",
      "        [0.0892, 0.1000, 0.1034, 0.1076, 0.1046, 0.1051, 0.1031, 0.1002, 0.0965,\n",
      "         0.0903],\n",
      "        [0.0866, 0.1004, 0.1042, 0.1084, 0.1055, 0.1058, 0.1037, 0.1007, 0.0965,\n",
      "         0.0881],\n",
      "        [0.0844, 0.1006, 0.1049, 0.1090, 0.1062, 0.1065, 0.1042, 0.1011, 0.0965,\n",
      "         0.0865],\n",
      "        [0.0827, 0.1009, 0.1054, 0.1096, 0.1068, 0.1069, 0.1046, 0.1014, 0.0965,\n",
      "         0.0852],\n",
      "        [0.0815, 0.1010, 0.1058, 0.1099, 0.1072, 0.1073, 0.1049, 0.1016, 0.0965,\n",
      "         0.0843]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 71.00, Train Loss: 2.83, Val Loss: 11.28, Train BLEU: 12.48, Val BLEU: 0.26\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 这位 是 比尔 <UNK> 我 是 大卫 <UNK>\n",
      "Reference: this is bill lange . i &apos;m dave gallo\n",
      "Model: <SOS> this bill bill lange is gallo gallo gallo gallo\n",
      "Attention Weights: tensor([[0.1111, 0.0856, 0.1224, 0.1202, 0.1065, 0.0866, 0.1104, 0.1056, 0.0994,\n",
      "         0.0522],\n",
      "        [0.1096, 0.0823, 0.1236, 0.1234, 0.1127, 0.0857, 0.1109, 0.1076, 0.1022,\n",
      "         0.0421],\n",
      "        [0.1097, 0.0736, 0.1294, 0.1307, 0.1118, 0.0782, 0.1148, 0.1124, 0.1053,\n",
      "         0.0341],\n",
      "        [0.1065, 0.0651, 0.1382, 0.1395, 0.1079, 0.0706, 0.1227, 0.1187, 0.1041,\n",
      "         0.0267],\n",
      "        [0.1017, 0.0605, 0.1440, 0.1461, 0.1054, 0.0673, 0.1302, 0.1232, 0.0994,\n",
      "         0.0222],\n",
      "        [0.0986, 0.0585, 0.1466, 0.1496, 0.1043, 0.0662, 0.1345, 0.1253, 0.0963,\n",
      "         0.0202],\n",
      "        [0.0969, 0.0574, 0.1478, 0.1515, 0.1042, 0.0656, 0.1364, 0.1263, 0.0947,\n",
      "         0.0192],\n",
      "        [0.0958, 0.0568, 0.1483, 0.1526, 0.1044, 0.0654, 0.1373, 0.1269, 0.0938,\n",
      "         0.0186],\n",
      "        [0.0951, 0.0565, 0.1486, 0.1533, 0.1046, 0.0653, 0.1378, 0.1272, 0.0933,\n",
      "         0.0183]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 她 两年 年前 退休 了 结果 却 把 我家 变成\n",
      "Reference: she retired two years ago , only to turn\n",
      "Model: <SOS> most of the the the the the the the\n",
      "Attention Weights: tensor([[0.0503, 0.0515, 0.0526, 0.0512, 0.0479, 0.0344, 0.1780, 0.1780, 0.1780,\n",
      "         0.1780],\n",
      "        [0.0419, 0.0450, 0.0463, 0.0455, 0.0439, 0.0309, 0.1866, 0.1866, 0.1866,\n",
      "         0.1866],\n",
      "        [0.0344, 0.0376, 0.0388, 0.0381, 0.0371, 0.0251, 0.1972, 0.1972, 0.1972,\n",
      "         0.1972],\n",
      "        [0.0175, 0.0201, 0.0208, 0.0204, 0.0196, 0.0113, 0.2226, 0.2226, 0.2226,\n",
      "         0.2226],\n",
      "        [0.0080, 0.0098, 0.0103, 0.0100, 0.0094, 0.0045, 0.2370, 0.2370, 0.2370,\n",
      "         0.2370],\n",
      "        [0.0043, 0.0056, 0.0058, 0.0057, 0.0052, 0.0023, 0.2428, 0.2428, 0.2428,\n",
      "         0.2428],\n",
      "        [0.0032, 0.0041, 0.0043, 0.0042, 0.0038, 0.0016, 0.2447, 0.2447, 0.2447,\n",
      "         0.2447],\n",
      "        [0.0028, 0.0036, 0.0038, 0.0037, 0.0033, 0.0014, 0.2453, 0.2453, 0.2453,\n",
      "         0.2453],\n",
      "        [0.0026, 0.0034, 0.0036, 0.0035, 0.0031, 0.0013, 0.2456, 0.2456, 0.2456,\n",
      "         0.2456]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72.00, Train Loss: 2.81, Val Loss: 11.32, Train BLEU: 10.85, Val BLEU: 0.26\n",
      "Sampling from training predictions...\n",
      "Source: 原来 它 是 海洋 洋中 最长 的 生物 <EOS> <PAD>\n",
      "Reference: this turns out to be the longest creature in\n",
      "Model: <SOS> it &apos;s got to is is about . .\n",
      "Attention Weights: tensor([[0.0905, 0.0914, 0.0930, 0.0993, 0.1124, 0.0950, 0.0883, 0.0830, 0.0585,\n",
      "         0.1884],\n",
      "        [0.0837, 0.0875, 0.0901, 0.0984, 0.1121, 0.0921, 0.0869, 0.0843, 0.0587,\n",
      "         0.2061],\n",
      "        [0.0761, 0.0800, 0.0828, 0.0930, 0.1086, 0.0843, 0.0793, 0.0784, 0.0531,\n",
      "         0.2644],\n",
      "        [0.0631, 0.0677, 0.0706, 0.0807, 0.0969, 0.0720, 0.0670, 0.0663, 0.0408,\n",
      "         0.3749],\n",
      "        [0.0466, 0.0524, 0.0549, 0.0626, 0.0763, 0.0561, 0.0519, 0.0508, 0.0267,\n",
      "         0.5217],\n",
      "        [0.0311, 0.0374, 0.0394, 0.0444, 0.0543, 0.0402, 0.0369, 0.0353, 0.0158,\n",
      "         0.6653],\n",
      "        [0.0195, 0.0250, 0.0265, 0.0296, 0.0364, 0.0270, 0.0246, 0.0230, 0.0090,\n",
      "         0.7793],\n",
      "        [0.0130, 0.0174, 0.0185, 0.0205, 0.0253, 0.0189, 0.0172, 0.0158, 0.0058,\n",
      "         0.8477],\n",
      "        [0.0097, 0.0133, 0.0142, 0.0156, 0.0193, 0.0145, 0.0131, 0.0119, 0.0044,\n",
      "         0.8842]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 父亲 那 就是 他 他 是 他家 家族\n",
      "Reference: and my father -- that &apos;s him -- he\n",
      "Model: <SOS> and of the the the the the the the\n",
      "Attention Weights: tensor([[0.1025, 0.1038, 0.1038, 0.1165, 0.0888, 0.1088, 0.1165, 0.0995, 0.0917,\n",
      "         0.0682],\n",
      "        [0.0977, 0.1043, 0.1056, 0.1183, 0.0865, 0.1097, 0.1212, 0.1024, 0.0970,\n",
      "         0.0574],\n",
      "        [0.0957, 0.1049, 0.1070, 0.1242, 0.0845, 0.1094, 0.1238, 0.1020, 0.0965,\n",
      "         0.0520],\n",
      "        [0.0962, 0.1066, 0.1082, 0.1256, 0.0770, 0.1123, 0.1294, 0.1037, 0.0974,\n",
      "         0.0437],\n",
      "        [0.0956, 0.1086, 0.1095, 0.1263, 0.0697, 0.1160, 0.1349, 0.1061, 0.0977,\n",
      "         0.0355],\n",
      "        [0.0940, 0.1108, 0.1113, 0.1271, 0.0650, 0.1186, 0.1375, 0.1083, 0.0972,\n",
      "         0.0302],\n",
      "        [0.0924, 0.1127, 0.1132, 0.1277, 0.0619, 0.1206, 0.1389, 0.1101, 0.0965,\n",
      "         0.0262],\n",
      "        [0.0909, 0.1139, 0.1143, 0.1278, 0.0599, 0.1223, 0.1401, 0.1117, 0.0959,\n",
      "         0.0233],\n",
      "        [0.0900, 0.1148, 0.1150, 0.1278, 0.0586, 0.1234, 0.1408, 0.1126, 0.0954,\n",
      "         0.0216]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 73.00, Train Loss: 2.78, Val Loss: 11.33, Train BLEU: 10.81, Val BLEU: 0.26\n",
      "Sampling from training predictions...\n",
      "Source: 是 我 最 喜欢 的 因为 它 哪 都 能动\n",
      "Reference: it &apos;s one of my favorites , because it\n",
      "Model: <SOS> it &apos;s &apos;s got , , , , ,\n",
      "Attention Weights: tensor([[0.1019, 0.1050, 0.1071, 0.1098, 0.1084, 0.1086, 0.1051, 0.1014, 0.0963,\n",
      "         0.0563],\n",
      "        [0.0996, 0.1048, 0.1076, 0.1111, 0.1092, 0.1101, 0.1061, 0.1034, 0.1011,\n",
      "         0.0472],\n",
      "        [0.0982, 0.1052, 0.1085, 0.1128, 0.1105, 0.1118, 0.1070, 0.1039, 0.1013,\n",
      "         0.0409],\n",
      "        [0.0979, 0.1060, 0.1097, 0.1144, 0.1118, 0.1132, 0.1078, 0.1042, 0.1012,\n",
      "         0.0340],\n",
      "        [0.0973, 0.1067, 0.1108, 0.1159, 0.1131, 0.1145, 0.1085, 0.1044, 0.1006,\n",
      "         0.0282],\n",
      "        [0.0951, 0.1076, 0.1122, 0.1173, 0.1146, 0.1157, 0.1097, 0.1050, 0.0991,\n",
      "         0.0236],\n",
      "        [0.0928, 0.1083, 0.1134, 0.1183, 0.1158, 0.1167, 0.1106, 0.1055, 0.0977,\n",
      "         0.0210],\n",
      "        [0.0909, 0.1088, 0.1143, 0.1191, 0.1167, 0.1174, 0.1113, 0.1058, 0.0965,\n",
      "         0.0192],\n",
      "        [0.0896, 0.1092, 0.1149, 0.1197, 0.1173, 0.1180, 0.1117, 0.1059, 0.0956,\n",
      "         0.0180]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 不知 知道 那 意味 意味着 什么 但是 我 能\n",
      "Reference: i didn &apos;t know what it meant , but\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0933, 0.0956, 0.0980, 0.1022, 0.1018, 0.0998, 0.1035, 0.1078, 0.1082,\n",
      "         0.0899],\n",
      "        [0.0901, 0.0944, 0.0974, 0.1023, 0.1017, 0.1004, 0.1077, 0.1070, 0.1086,\n",
      "         0.0906],\n",
      "        [0.0877, 0.0924, 0.0956, 0.1022, 0.1014, 0.0997, 0.1103, 0.1124, 0.1108,\n",
      "         0.0877],\n",
      "        [0.0860, 0.0914, 0.0951, 0.1026, 0.1018, 0.0999, 0.1124, 0.1137, 0.1113,\n",
      "         0.0857],\n",
      "        [0.0842, 0.0911, 0.0952, 0.1031, 0.1023, 0.1004, 0.1136, 0.1151, 0.1115,\n",
      "         0.0834],\n",
      "        [0.0820, 0.0913, 0.0958, 0.1038, 0.1032, 0.1013, 0.1145, 0.1158, 0.1115,\n",
      "         0.0809],\n",
      "        [0.0799, 0.0919, 0.0967, 0.1044, 0.1040, 0.1022, 0.1148, 0.1157, 0.1113,\n",
      "         0.0790],\n",
      "        [0.0779, 0.0924, 0.0977, 0.1052, 0.1049, 0.1031, 0.1149, 0.1153, 0.1112,\n",
      "         0.0773],\n",
      "        [0.0766, 0.0929, 0.0983, 0.1058, 0.1056, 0.1038, 0.1149, 0.1149, 0.1112,\n",
      "         0.0760]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 74.00, Train Loss: 2.75, Val Loss: 11.32, Train BLEU: 12.68, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 还有 前面 的 这个 是 推进 引擎 它 一会 一会儿\n",
      "Reference: and it &apos;s got these jet thrusters up in\n",
      "Model: <SOS> it &apos;s &apos;s got got got , , ,\n",
      "Attention Weights: tensor([[0.1036, 0.1067, 0.1068, 0.1086, 0.1068, 0.1075, 0.1048, 0.0987, 0.0808,\n",
      "         0.0757],\n",
      "        [0.1004, 0.1065, 0.1072, 0.1098, 0.1076, 0.1096, 0.1073, 0.1033, 0.0804,\n",
      "         0.0679],\n",
      "        [0.0985, 0.1059, 0.1068, 0.1099, 0.1074, 0.1099, 0.1075, 0.1041, 0.0822,\n",
      "         0.0678],\n",
      "        [0.0987, 0.1066, 0.1075, 0.1110, 0.1081, 0.1111, 0.1083, 0.1048, 0.0799,\n",
      "         0.0639],\n",
      "        [0.0985, 0.1072, 0.1083, 0.1121, 0.1089, 0.1121, 0.1092, 0.1058, 0.0776,\n",
      "         0.0604],\n",
      "        [0.0972, 0.1087, 0.1102, 0.1142, 0.1110, 0.1141, 0.1110, 0.1071, 0.0731,\n",
      "         0.0535],\n",
      "        [0.0952, 0.1103, 0.1124, 0.1163, 0.1133, 0.1160, 0.1127, 0.1083, 0.0686,\n",
      "         0.0469],\n",
      "        [0.0936, 0.1115, 0.1139, 0.1178, 0.1148, 0.1172, 0.1139, 0.1090, 0.0656,\n",
      "         0.0427],\n",
      "        [0.0922, 0.1124, 0.1151, 0.1190, 0.1160, 0.1182, 0.1148, 0.1095, 0.0632,\n",
      "         0.0397]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 在 被 跟踪 吗 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: were we being followed ? <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a kind . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0974, 0.1000, 0.1023, 0.1037, 0.1096, 0.1124, 0.0879, 0.0851, 0.1031,\n",
      "         0.0985],\n",
      "        [0.0935, 0.0978, 0.1015, 0.1059, 0.1147, 0.1188, 0.0872, 0.0841, 0.0996,\n",
      "         0.0970],\n",
      "        [0.0927, 0.0970, 0.1016, 0.1077, 0.1209, 0.1270, 0.0842, 0.0776, 0.0969,\n",
      "         0.0943],\n",
      "        [0.0936, 0.0990, 0.1043, 0.1106, 0.1249, 0.1294, 0.0748, 0.0693, 0.0990,\n",
      "         0.0951],\n",
      "        [0.0934, 0.1013, 0.1071, 0.1136, 0.1284, 0.1307, 0.0672, 0.0621, 0.1008,\n",
      "         0.0953],\n",
      "        [0.0921, 0.1033, 0.1097, 0.1161, 0.1304, 0.1307, 0.0629, 0.0578, 0.1019,\n",
      "         0.0950],\n",
      "        [0.0906, 0.1048, 0.1114, 0.1176, 0.1310, 0.1301, 0.0612, 0.0558, 0.1027,\n",
      "         0.0948],\n",
      "        [0.0894, 0.1060, 0.1129, 0.1188, 0.1311, 0.1297, 0.0600, 0.0543, 0.1033,\n",
      "         0.0945],\n",
      "        [0.0886, 0.1070, 0.1141, 0.1198, 0.1312, 0.1295, 0.0592, 0.0530, 0.1036,\n",
      "         0.0940]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 75.00, Train Loss: 2.72, Val Loss: 11.34, Train BLEU: 12.89, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中 的 生命 大卫 <UNK> <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: life in the deep oceans <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> life in the deep <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0603, 0.0618, 0.0587, 0.0602, 0.0537, 0.0280, 0.0308, 0.2155, 0.2155,\n",
      "         0.2155],\n",
      "        [0.0570, 0.0613, 0.0601, 0.0639, 0.0588, 0.0296, 0.0329, 0.2121, 0.2121,\n",
      "         0.2121],\n",
      "        [0.0485, 0.0533, 0.0522, 0.0565, 0.0509, 0.0210, 0.0262, 0.2305, 0.2305,\n",
      "         0.2305],\n",
      "        [0.0258, 0.0302, 0.0295, 0.0311, 0.0261, 0.0077, 0.0105, 0.2797, 0.2797,\n",
      "         0.2797],\n",
      "        [0.0112, 0.0143, 0.0141, 0.0144, 0.0113, 0.0027, 0.0036, 0.3094, 0.3094,\n",
      "         0.3094],\n",
      "        [0.0059, 0.0078, 0.0077, 0.0078, 0.0059, 0.0014, 0.0018, 0.3206, 0.3206,\n",
      "         0.3206],\n",
      "        [0.0045, 0.0060, 0.0058, 0.0059, 0.0044, 0.0011, 0.0014, 0.3237, 0.3237,\n",
      "         0.3237],\n",
      "        [0.0040, 0.0054, 0.0053, 0.0053, 0.0039, 0.0010, 0.0012, 0.3246, 0.3246,\n",
      "         0.3246],\n",
      "        [0.0038, 0.0051, 0.0050, 0.0050, 0.0037, 0.0010, 0.0012, 0.3250, 0.3250,\n",
      "         0.3250]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 在 被 跟踪 吗 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: were we being followed ? <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a kind . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0971, 0.1003, 0.1026, 0.1040, 0.1096, 0.1118, 0.0873, 0.0847, 0.1035,\n",
      "         0.0990],\n",
      "        [0.0934, 0.0979, 0.1015, 0.1060, 0.1149, 0.1186, 0.0867, 0.0839, 0.0997,\n",
      "         0.0974],\n",
      "        [0.0927, 0.0971, 0.1015, 0.1078, 0.1212, 0.1271, 0.0838, 0.0776, 0.0968,\n",
      "         0.0945],\n",
      "        [0.0936, 0.0989, 0.1040, 0.1106, 0.1253, 0.1295, 0.0745, 0.0694, 0.0990,\n",
      "         0.0952],\n",
      "        [0.0935, 0.1011, 0.1067, 0.1135, 0.1288, 0.1308, 0.0671, 0.0622, 0.1008,\n",
      "         0.0954],\n",
      "        [0.0924, 0.1031, 0.1091, 0.1159, 0.1309, 0.1309, 0.0628, 0.0579, 0.1019,\n",
      "         0.0950],\n",
      "        [0.0910, 0.1045, 0.1108, 0.1174, 0.1315, 0.1303, 0.0610, 0.0559, 0.1027,\n",
      "         0.0949],\n",
      "        [0.0899, 0.1056, 0.1122, 0.1185, 0.1317, 0.1299, 0.0599, 0.0544, 0.1033,\n",
      "         0.0946],\n",
      "        [0.0890, 0.1067, 0.1134, 0.1194, 0.1318, 0.1297, 0.0590, 0.0532, 0.1036,\n",
      "         0.0941]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76.00, Train Loss: 2.70, Val Loss: 11.37, Train BLEU: 12.52, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 我们 用 的 是 深海 潜水 潜水艇 <UNK> 号 和\n",
      "Reference: we use the submarine alvin and we use cameras\n",
      "Model: <SOS> we the the the the the the the the\n",
      "Attention Weights: tensor([[0.0976, 0.1008, 0.1033, 0.1045, 0.1098, 0.1109, 0.0860, 0.0839, 0.1038,\n",
      "         0.0994],\n",
      "        [0.0939, 0.0981, 0.1017, 0.1063, 0.1148, 0.1176, 0.0862, 0.0837, 0.0998,\n",
      "         0.0979],\n",
      "        [0.0931, 0.0971, 0.1016, 0.1081, 0.1213, 0.1264, 0.0836, 0.0778, 0.0965,\n",
      "         0.0946],\n",
      "        [0.0941, 0.0989, 0.1039, 0.1108, 0.1254, 0.1292, 0.0745, 0.0697, 0.0987,\n",
      "         0.0950],\n",
      "        [0.0941, 0.1010, 0.1065, 0.1136, 0.1291, 0.1307, 0.0670, 0.0623, 0.1007,\n",
      "         0.0952],\n",
      "        [0.0933, 0.1029, 0.1088, 0.1159, 0.1315, 0.1309, 0.0624, 0.0577, 0.1018,\n",
      "         0.0948],\n",
      "        [0.0922, 0.1043, 0.1104, 0.1173, 0.1323, 0.1304, 0.0603, 0.0554, 0.1027,\n",
      "         0.0947],\n",
      "        [0.0911, 0.1054, 0.1117, 0.1183, 0.1327, 0.1301, 0.0590, 0.0539, 0.1033,\n",
      "         0.0945],\n",
      "        [0.0902, 0.1065, 0.1129, 0.1193, 0.1330, 0.1299, 0.0580, 0.0525, 0.1037,\n",
      "         0.0940]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 父亲 那 就是 他 他 是 他家 家族\n",
      "Reference: and my father -- that &apos;s him -- he\n",
      "Model: <SOS> and of the the the the the the the\n",
      "Attention Weights: tensor([[0.1008, 0.1035, 0.1039, 0.1146, 0.0885, 0.1093, 0.1186, 0.1005, 0.0928,\n",
      "         0.0675],\n",
      "        [0.0969, 0.1034, 0.1055, 0.1173, 0.0869, 0.1091, 0.1227, 0.1023, 0.0979,\n",
      "         0.0580],\n",
      "        [0.0952, 0.1038, 0.1068, 0.1241, 0.0854, 0.1082, 0.1251, 0.1014, 0.0969,\n",
      "         0.0530],\n",
      "        [0.0956, 0.1052, 0.1075, 0.1255, 0.0781, 0.1114, 0.1314, 0.1030, 0.0977,\n",
      "         0.0446],\n",
      "        [0.0950, 0.1068, 0.1084, 0.1260, 0.0708, 0.1154, 0.1380, 0.1053, 0.0981,\n",
      "         0.0362],\n",
      "        [0.0936, 0.1088, 0.1099, 0.1265, 0.0660, 0.1181, 0.1411, 0.1075, 0.0978,\n",
      "         0.0308],\n",
      "        [0.0922, 0.1107, 0.1116, 0.1268, 0.0626, 0.1203, 0.1428, 0.1094, 0.0971,\n",
      "         0.0264],\n",
      "        [0.0908, 0.1120, 0.1127, 0.1267, 0.0603, 0.1222, 0.1441, 0.1112, 0.0966,\n",
      "         0.0233],\n",
      "        [0.0898, 0.1128, 0.1134, 0.1267, 0.0589, 0.1234, 0.1450, 0.1123, 0.0961,\n",
      "         0.0215]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 77.00, Train Loss: 2.67, Val Loss: 11.37, Train BLEU: 13.08, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 但 我 想 告诉 你 的 是 当 你 站\n",
      "Reference: but when you &apos;re standing at the beach ,\n",
      "Model: <SOS> we of the the the the the , ,\n",
      "Attention Weights: tensor([[0.0943, 0.0987, 0.1013, 0.1044, 0.1030, 0.1035, 0.1024, 0.1007, 0.0981,\n",
      "         0.0936],\n",
      "        [0.0936, 0.0991, 0.1015, 0.1044, 0.1025, 0.1029, 0.1017, 0.1000, 0.0978,\n",
      "         0.0964],\n",
      "        [0.0932, 0.0995, 0.1019, 0.1058, 0.1029, 0.1034, 0.1019, 0.0997, 0.0968,\n",
      "         0.0950],\n",
      "        [0.0924, 0.0997, 0.1024, 0.1067, 0.1034, 0.1040, 0.1022, 0.0996, 0.0962,\n",
      "         0.0933],\n",
      "        [0.0907, 0.0997, 0.1028, 0.1075, 0.1041, 0.1048, 0.1028, 0.0999, 0.0960,\n",
      "         0.0915],\n",
      "        [0.0885, 0.1000, 0.1035, 0.1084, 0.1050, 0.1056, 0.1035, 0.1004, 0.0958,\n",
      "         0.0894],\n",
      "        [0.0865, 0.1003, 0.1041, 0.1090, 0.1058, 0.1063, 0.1041, 0.1007, 0.0957,\n",
      "         0.0876],\n",
      "        [0.0849, 0.1005, 0.1046, 0.1096, 0.1064, 0.1068, 0.1045, 0.1009, 0.0956,\n",
      "         0.0863],\n",
      "        [0.0837, 0.1008, 0.1050, 0.1100, 0.1068, 0.1072, 0.1048, 0.1011, 0.0955,\n",
      "         0.0852]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 但是 我 那 受过 教育 的 母亲 成为 为了 一名\n",
      "Reference: but my educated mother became a teacher . <EOS>\n",
      "Model: <SOS> and of the the the the the the the\n",
      "Attention Weights: tensor([[0.0706, 0.0774, 0.0800, 0.0564, 0.0885, 0.0777, 0.0686, 0.0478, 0.2165,\n",
      "         0.2165],\n",
      "        [0.0683, 0.0789, 0.0856, 0.0629, 0.0880, 0.0748, 0.0687, 0.0505, 0.2112,\n",
      "         0.2112],\n",
      "        [0.0634, 0.0762, 0.0847, 0.0548, 0.0812, 0.0681, 0.0629, 0.0467, 0.2310,\n",
      "         0.2310],\n",
      "        [0.0466, 0.0579, 0.0639, 0.0332, 0.0628, 0.0519, 0.0471, 0.0307, 0.3029,\n",
      "         0.3029],\n",
      "        [0.0281, 0.0366, 0.0400, 0.0175, 0.0400, 0.0336, 0.0300, 0.0164, 0.3789,\n",
      "         0.3789],\n",
      "        [0.0149, 0.0205, 0.0223, 0.0087, 0.0225, 0.0193, 0.0170, 0.0078, 0.4335,\n",
      "         0.4335],\n",
      "        [0.0076, 0.0108, 0.0117, 0.0044, 0.0119, 0.0103, 0.0089, 0.0036, 0.4654,\n",
      "         0.4654],\n",
      "        [0.0055, 0.0078, 0.0085, 0.0033, 0.0088, 0.0075, 0.0064, 0.0025, 0.4749,\n",
      "         0.4749],\n",
      "        [0.0053, 0.0075, 0.0081, 0.0031, 0.0085, 0.0072, 0.0061, 0.0024, 0.4759,\n",
      "         0.4759]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 78.00, Train Loss: 2.65, Val Loss: 11.36, Train BLEU: 12.84, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一只 水母 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: here &apos;s a jelly . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a jelly . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0428, 0.0444, 0.0446, 0.0426, 0.0296, 0.1592, 0.1592, 0.1592, 0.1592,\n",
      "         0.1592],\n",
      "        [0.0366, 0.0392, 0.0398, 0.0391, 0.0274, 0.1636, 0.1636, 0.1636, 0.1636,\n",
      "         0.1636],\n",
      "        [0.0317, 0.0344, 0.0350, 0.0348, 0.0238, 0.1681, 0.1681, 0.1681, 0.1681,\n",
      "         0.1681],\n",
      "        [0.0157, 0.0179, 0.0182, 0.0179, 0.0105, 0.1840, 0.1840, 0.1840, 0.1840,\n",
      "         0.1840],\n",
      "        [0.0065, 0.0079, 0.0081, 0.0078, 0.0038, 0.1932, 0.1932, 0.1932, 0.1932,\n",
      "         0.1932],\n",
      "        [0.0036, 0.0045, 0.0046, 0.0044, 0.0020, 0.1962, 0.1962, 0.1962, 0.1962,\n",
      "         0.1962],\n",
      "        [0.0027, 0.0035, 0.0035, 0.0033, 0.0014, 0.1971, 0.1971, 0.1971, 0.1971,\n",
      "         0.1971],\n",
      "        [0.0024, 0.0030, 0.0031, 0.0028, 0.0012, 0.1975, 0.1975, 0.1975, 0.1975,\n",
      "         0.1975],\n",
      "        [0.0022, 0.0028, 0.0029, 0.0027, 0.0012, 0.1976, 0.1976, 0.1976, 0.1976,\n",
      "         0.1976]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 在 被 跟踪 吗 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: were we being followed ? <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a kind . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0965, 0.1007, 0.1034, 0.1051, 0.1108, 0.1111, 0.0858, 0.0839, 0.1031,\n",
      "         0.0996],\n",
      "        [0.0933, 0.0981, 0.1016, 0.1065, 0.1160, 0.1184, 0.0857, 0.0833, 0.0993,\n",
      "         0.0979],\n",
      "        [0.0926, 0.0970, 0.1013, 0.1081, 0.1228, 0.1275, 0.0830, 0.0773, 0.0959,\n",
      "         0.0944],\n",
      "        [0.0938, 0.0989, 0.1036, 0.1105, 0.1266, 0.1300, 0.0740, 0.0693, 0.0985,\n",
      "         0.0948],\n",
      "        [0.0938, 0.1013, 0.1065, 0.1134, 0.1303, 0.1312, 0.0665, 0.0617, 0.1005,\n",
      "         0.0949],\n",
      "        [0.0928, 0.1033, 0.1088, 0.1155, 0.1321, 0.1308, 0.0628, 0.0578, 0.1017,\n",
      "         0.0945],\n",
      "        [0.0915, 0.1047, 0.1104, 0.1168, 0.1328, 0.1302, 0.0611, 0.0559, 0.1024,\n",
      "         0.0943],\n",
      "        [0.0904, 0.1059, 0.1117, 0.1179, 0.1331, 0.1299, 0.0600, 0.0545, 0.1029,\n",
      "         0.0938],\n",
      "        [0.0896, 0.1069, 0.1129, 0.1187, 0.1333, 0.1299, 0.0591, 0.0532, 0.1031,\n",
      "         0.0932]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 79.00, Train Loss: 2.61, Val Loss: 11.37, Train BLEU: 14.11, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: <UNK> 塞尔 <UNK> <UNK> 斯特 说 过 真正 的 探索\n",
      "Reference: marcel proust said , &quot; the true voyage of\n",
      "Model: <SOS> marcel proust said said &quot; &quot; true voyage voyage\n",
      "Attention Weights: tensor([[0.0884, 0.0947, 0.0932, 0.0994, 0.1130, 0.1069, 0.1040, 0.1053, 0.0989,\n",
      "         0.0964],\n",
      "        [0.0699, 0.0767, 0.0763, 0.0867, 0.1231, 0.1169, 0.1143, 0.1160, 0.1097,\n",
      "         0.1105],\n",
      "        [0.0576, 0.0627, 0.0613, 0.0699, 0.1218, 0.1281, 0.1263, 0.1285, 0.1210,\n",
      "         0.1228],\n",
      "        [0.0428, 0.0470, 0.0463, 0.0527, 0.1150, 0.1436, 0.1425, 0.1448, 0.1351,\n",
      "         0.1304],\n",
      "        [0.0298, 0.0330, 0.0329, 0.0387, 0.1039, 0.1581, 0.1592, 0.1614, 0.1489,\n",
      "         0.1341],\n",
      "        [0.0257, 0.0284, 0.0285, 0.0342, 0.0995, 0.1630, 0.1656, 0.1677, 0.1537,\n",
      "         0.1336],\n",
      "        [0.0240, 0.0267, 0.0268, 0.0325, 0.0973, 0.1648, 0.1685, 0.1706, 0.1559,\n",
      "         0.1330],\n",
      "        [0.0234, 0.0260, 0.0262, 0.0320, 0.0961, 0.1653, 0.1697, 0.1718, 0.1569,\n",
      "         0.1326],\n",
      "        [0.0229, 0.0256, 0.0257, 0.0315, 0.0951, 0.1657, 0.1706, 0.1728, 0.1577,\n",
      "         0.1324]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 很 害怕 但是 我们 仍然 渴望 望去 学校 <EOS>\n",
      "Reference: we were scared , but still , school was\n",
      "Model: <SOS> it &apos;s the the the the the is is\n",
      "Attention Weights: tensor([[0.0930, 0.0994, 0.1047, 0.1026, 0.1043, 0.1017, 0.1028, 0.1021, 0.0970,\n",
      "         0.0924],\n",
      "        [0.0926, 0.0997, 0.1052, 0.1023, 0.1043, 0.1010, 0.1025, 0.1015, 0.0964,\n",
      "         0.0944],\n",
      "        [0.0920, 0.1002, 0.1067, 0.1023, 0.1056, 0.1006, 0.1032, 0.1018, 0.0948,\n",
      "         0.0929],\n",
      "        [0.0911, 0.1006, 0.1079, 0.1029, 0.1063, 0.1007, 0.1036, 0.1020, 0.0940,\n",
      "         0.0909],\n",
      "        [0.0893, 0.1007, 0.1087, 0.1036, 0.1070, 0.1012, 0.1042, 0.1025, 0.0937,\n",
      "         0.0890],\n",
      "        [0.0870, 0.1011, 0.1095, 0.1044, 0.1079, 0.1020, 0.1048, 0.1030, 0.0935,\n",
      "         0.0868],\n",
      "        [0.0849, 0.1014, 0.1100, 0.1052, 0.1085, 0.1028, 0.1053, 0.1033, 0.0934,\n",
      "         0.0852],\n",
      "        [0.0832, 0.1018, 0.1105, 0.1059, 0.1090, 0.1034, 0.1057, 0.1035, 0.0932,\n",
      "         0.0838],\n",
      "        [0.0820, 0.1021, 0.1109, 0.1064, 0.1094, 0.1038, 0.1059, 0.1037, 0.0931,\n",
      "         0.0828]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80.00, Train Loss: 2.60, Val Loss: 11.40, Train BLEU: 13.66, Val BLEU: 0.26\n",
      "Sampling from training predictions...\n",
      "Source: <UNK> 塞尔 <UNK> <UNK> 斯特 说 过 真正 的 探索\n",
      "Reference: marcel proust said , &quot; the true voyage of\n",
      "Model: <SOS> marcel proust said said &quot; &quot; true voyage voyage\n",
      "Attention Weights: tensor([[0.0844, 0.0909, 0.0894, 0.0962, 0.1140, 0.1096, 0.1070, 0.1085, 0.1015,\n",
      "         0.0985],\n",
      "        [0.0669, 0.0738, 0.0734, 0.0842, 0.1237, 0.1189, 0.1167, 0.1186, 0.1117,\n",
      "         0.1121],\n",
      "        [0.0552, 0.0604, 0.0590, 0.0681, 0.1222, 0.1295, 0.1281, 0.1306, 0.1226,\n",
      "         0.1244],\n",
      "        [0.0407, 0.0449, 0.0442, 0.0510, 0.1155, 0.1445, 0.1438, 0.1466, 0.1363,\n",
      "         0.1324],\n",
      "        [0.0279, 0.0311, 0.0309, 0.0368, 0.1040, 0.1591, 0.1606, 0.1633, 0.1502,\n",
      "         0.1361],\n",
      "        [0.0236, 0.0262, 0.0262, 0.0320, 0.0988, 0.1645, 0.1675, 0.1702, 0.1554,\n",
      "         0.1356],\n",
      "        [0.0219, 0.0244, 0.0245, 0.0302, 0.0966, 0.1665, 0.1705, 0.1731, 0.1576,\n",
      "         0.1349],\n",
      "        [0.0212, 0.0238, 0.0239, 0.0296, 0.0953, 0.1671, 0.1718, 0.1744, 0.1586,\n",
      "         0.1344],\n",
      "        [0.0208, 0.0233, 0.0234, 0.0291, 0.0943, 0.1675, 0.1726, 0.1753, 0.1594,\n",
      "         0.1342]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 所以 在 那 之后 5 年 我 <UNK> <UNK> 陪\n",
      "Reference: so for the next five years , i dressed\n",
      "Model: <SOS> we the the the the the the the the\n",
      "Attention Weights: tensor([[0.0823, 0.0814, 0.0857, 0.0858, 0.0826, 0.0963, 0.0735, 0.0490, 0.1817,\n",
      "         0.1817],\n",
      "        [0.0770, 0.0780, 0.0824, 0.0829, 0.0802, 0.0961, 0.0737, 0.0513, 0.1892,\n",
      "         0.1892],\n",
      "        [0.0704, 0.0714, 0.0763, 0.0769, 0.0740, 0.0918, 0.0678, 0.0474, 0.2120,\n",
      "         0.2120],\n",
      "        [0.0554, 0.0574, 0.0621, 0.0626, 0.0595, 0.0765, 0.0533, 0.0328, 0.2702,\n",
      "         0.2702],\n",
      "        [0.0358, 0.0397, 0.0430, 0.0433, 0.0413, 0.0528, 0.0357, 0.0182, 0.3451,\n",
      "         0.3451],\n",
      "        [0.0201, 0.0242, 0.0263, 0.0265, 0.0253, 0.0321, 0.0212, 0.0088, 0.4076,\n",
      "         0.4076],\n",
      "        [0.0108, 0.0139, 0.0151, 0.0152, 0.0146, 0.0184, 0.0119, 0.0044, 0.4479,\n",
      "         0.4479],\n",
      "        [0.0068, 0.0090, 0.0098, 0.0099, 0.0095, 0.0121, 0.0076, 0.0028, 0.4663,\n",
      "         0.4663],\n",
      "        [0.0061, 0.0081, 0.0089, 0.0090, 0.0086, 0.0111, 0.0068, 0.0025, 0.4694,\n",
      "         0.4694]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 81.00, Train Loss: 2.57, Val Loss: 11.41, Train BLEU: 13.91, Val BLEU: 0.26\n",
      "Sampling from training predictions...\n",
      "Source: 是 我 最 喜欢 的 因为 它 哪 都 能动\n",
      "Reference: it &apos;s one of my favorites , because it\n",
      "Model: <SOS> it &apos;s &apos;s got , , , , ,\n",
      "Attention Weights: tensor([[0.0991, 0.1036, 0.1066, 0.1098, 0.1088, 0.1092, 0.1060, 0.1025, 0.0969,\n",
      "         0.0574],\n",
      "        [0.0990, 0.1042, 0.1073, 0.1111, 0.1094, 0.1105, 0.1068, 0.1037, 0.1009,\n",
      "         0.0470],\n",
      "        [0.0981, 0.1047, 0.1081, 0.1132, 0.1107, 0.1126, 0.1074, 0.1038, 0.1009,\n",
      "         0.0407],\n",
      "        [0.0981, 0.1058, 0.1094, 0.1148, 0.1120, 0.1140, 0.1081, 0.1039, 0.1005,\n",
      "         0.0335],\n",
      "        [0.0978, 0.1065, 0.1105, 0.1164, 0.1133, 0.1153, 0.1087, 0.1039, 0.0999,\n",
      "         0.0278],\n",
      "        [0.0958, 0.1075, 0.1121, 0.1181, 0.1150, 0.1168, 0.1098, 0.1043, 0.0981,\n",
      "         0.0225],\n",
      "        [0.0935, 0.1084, 0.1134, 0.1192, 0.1164, 0.1178, 0.1109, 0.1045, 0.0962,\n",
      "         0.0196],\n",
      "        [0.0914, 0.1091, 0.1144, 0.1202, 0.1175, 0.1187, 0.1117, 0.1047, 0.0946,\n",
      "         0.0178],\n",
      "        [0.0901, 0.1096, 0.1151, 0.1208, 0.1182, 0.1193, 0.1121, 0.1047, 0.0934,\n",
      "         0.0167]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11 岁 那年 记得 得有 一天 早晨 醒来 听见\n",
      "Reference: when i was 11 , i remember waking up\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0742, 0.0773, 0.0733, 0.0745, 0.0648, 0.0338, 0.0353, 0.1889, 0.1889,\n",
      "         0.1889],\n",
      "        [0.0678, 0.0720, 0.0701, 0.0754, 0.0687, 0.0366, 0.0383, 0.1903, 0.1903,\n",
      "         0.1903],\n",
      "        [0.0616, 0.0669, 0.0651, 0.0711, 0.0637, 0.0284, 0.0325, 0.2036, 0.2036,\n",
      "         0.2036],\n",
      "        [0.0376, 0.0430, 0.0415, 0.0443, 0.0372, 0.0114, 0.0146, 0.2568, 0.2568,\n",
      "         0.2568],\n",
      "        [0.0185, 0.0230, 0.0222, 0.0230, 0.0181, 0.0043, 0.0053, 0.2952, 0.2952,\n",
      "         0.2952],\n",
      "        [0.0092, 0.0121, 0.0117, 0.0120, 0.0089, 0.0020, 0.0023, 0.3140, 0.3140,\n",
      "         0.3140],\n",
      "        [0.0065, 0.0086, 0.0083, 0.0084, 0.0061, 0.0014, 0.0016, 0.3197, 0.3197,\n",
      "         0.3197],\n",
      "        [0.0058, 0.0077, 0.0074, 0.0074, 0.0054, 0.0013, 0.0015, 0.3212, 0.3212,\n",
      "         0.3212],\n",
      "        [0.0055, 0.0074, 0.0071, 0.0071, 0.0051, 0.0013, 0.0014, 0.3217, 0.3217,\n",
      "         0.3217]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 82.00, Train Loss: 2.54, Val Loss: 11.39, Train BLEU: 14.18, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 我们 得用 非常 特殊 的 仪器 才能 能到 到达 那个\n",
      "Reference: we have to have a very special technology to\n",
      "Model: <SOS> we have the the the the the the the\n",
      "Attention Weights: tensor([[0.0838, 0.0972, 0.1049, 0.1036, 0.1020, 0.1040, 0.1044, 0.1155, 0.0958,\n",
      "         0.0890],\n",
      "        [0.0853, 0.1014, 0.1024, 0.1011, 0.0995, 0.1032, 0.1058, 0.1177, 0.0938,\n",
      "         0.0897],\n",
      "        [0.0847, 0.1051, 0.1013, 0.0994, 0.0976, 0.1038, 0.1078, 0.1225, 0.0909,\n",
      "         0.0868],\n",
      "        [0.0829, 0.1072, 0.1027, 0.0995, 0.0968, 0.1036, 0.1081, 0.1265, 0.0893,\n",
      "         0.0834],\n",
      "        [0.0804, 0.1076, 0.1045, 0.1004, 0.0972, 0.1034, 0.1082, 0.1303, 0.0882,\n",
      "         0.0798],\n",
      "        [0.0762, 0.1056, 0.1069, 0.1026, 0.0990, 0.1046, 0.1093, 0.1319, 0.0879,\n",
      "         0.0760],\n",
      "        [0.0738, 0.1050, 0.1082, 0.1039, 0.1002, 0.1054, 0.1097, 0.1324, 0.0876,\n",
      "         0.0738],\n",
      "        [0.0723, 0.1042, 0.1089, 0.1046, 0.1010, 0.1060, 0.1101, 0.1326, 0.0875,\n",
      "         0.0727],\n",
      "        [0.0716, 0.1033, 0.1093, 0.1051, 0.1015, 0.1064, 0.1103, 0.1326, 0.0877,\n",
      "         0.0722]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 很 害怕 但是 我们 仍然 渴望 望去 学校 <EOS>\n",
      "Reference: we were scared , but still , school was\n",
      "Model: <SOS> it &apos;s got the the the the is is\n",
      "Attention Weights: tensor([[0.0923, 0.0995, 0.1048, 0.1028, 0.1042, 0.1020, 0.1028, 0.1022, 0.0973,\n",
      "         0.0922],\n",
      "        [0.0925, 0.0999, 0.1055, 0.1023, 0.1042, 0.1010, 0.1026, 0.1016, 0.0964,\n",
      "         0.0941],\n",
      "        [0.0917, 0.1003, 0.1074, 0.1021, 0.1057, 0.1002, 0.1035, 0.1021, 0.0945,\n",
      "         0.0924],\n",
      "        [0.0906, 0.1007, 0.1088, 0.1028, 0.1066, 0.1003, 0.1040, 0.1024, 0.0936,\n",
      "         0.0901],\n",
      "        [0.0888, 0.1009, 0.1097, 0.1035, 0.1074, 0.1009, 0.1046, 0.1028, 0.0933,\n",
      "         0.0881],\n",
      "        [0.0864, 0.1013, 0.1105, 0.1044, 0.1083, 0.1017, 0.1053, 0.1032, 0.0930,\n",
      "         0.0858],\n",
      "        [0.0843, 0.1016, 0.1111, 0.1053, 0.1090, 0.1025, 0.1058, 0.1035, 0.0928,\n",
      "         0.0841],\n",
      "        [0.0826, 0.1020, 0.1116, 0.1060, 0.1095, 0.1032, 0.1061, 0.1038, 0.0926,\n",
      "         0.0827],\n",
      "        [0.0814, 0.1023, 0.1119, 0.1064, 0.1100, 0.1036, 0.1064, 0.1040, 0.0925,\n",
      "         0.0816]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 83.00, Train Loss: 2.52, Val Loss: 11.40, Train BLEU: 14.36, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分 部分 的 动物 也 都 生活 在 海洋\n",
      "Reference: most of the animals are in the oceans .\n",
      "Model: <SOS> most of the the the the the the the\n",
      "Attention Weights: tensor([[0.0982, 0.1071, 0.1037, 0.1010, 0.1031, 0.1000, 0.0994, 0.1009, 0.0949,\n",
      "         0.0916],\n",
      "        [0.0975, 0.1071, 0.1034, 0.0999, 0.1034, 0.0984, 0.0979, 0.1013, 0.0939,\n",
      "         0.0970],\n",
      "        [0.0981, 0.1087, 0.1041, 0.0991, 0.1049, 0.0969, 0.0963, 0.1019, 0.0918,\n",
      "         0.0982],\n",
      "        [0.0972, 0.1105, 0.1055, 0.0998, 0.1059, 0.0971, 0.0961, 0.1020, 0.0905,\n",
      "         0.0954],\n",
      "        [0.0943, 0.1120, 0.1070, 0.1011, 0.1070, 0.0983, 0.0970, 0.1023, 0.0901,\n",
      "         0.0909],\n",
      "        [0.0910, 0.1128, 0.1082, 0.1025, 0.1080, 0.0997, 0.0981, 0.1025, 0.0901,\n",
      "         0.0871],\n",
      "        [0.0886, 0.1134, 0.1090, 0.1035, 0.1087, 0.1006, 0.0988, 0.1026, 0.0900,\n",
      "         0.0846],\n",
      "        [0.0872, 0.1140, 0.1095, 0.1041, 0.1092, 0.1011, 0.0992, 0.1027, 0.0899,\n",
      "         0.0831],\n",
      "        [0.0863, 0.1142, 0.1098, 0.1044, 0.1095, 0.1015, 0.0995, 0.1028, 0.0898,\n",
      "         0.0822]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 因此 毫无 毫无疑问 无疑 疑问 他 的 孩子 应当 受到\n",
      "Reference: there was no question that his children would receive\n",
      "Model: <SOS> most of the the the the the the the\n",
      "Attention Weights: tensor([[0.0797, 0.0837, 0.0858, 0.0849, 0.0879, 0.1086, 0.0804, 0.0752, 0.0517,\n",
      "         0.2622],\n",
      "        [0.0772, 0.0816, 0.0835, 0.0824, 0.0862, 0.1054, 0.0786, 0.0753, 0.0515,\n",
      "         0.2784],\n",
      "        [0.0723, 0.0763, 0.0784, 0.0767, 0.0821, 0.1049, 0.0728, 0.0705, 0.0481,\n",
      "         0.3179],\n",
      "        [0.0566, 0.0613, 0.0634, 0.0616, 0.0669, 0.0905, 0.0577, 0.0554, 0.0336,\n",
      "         0.4529],\n",
      "        [0.0388, 0.0447, 0.0464, 0.0451, 0.0486, 0.0686, 0.0419, 0.0394, 0.0204,\n",
      "         0.6062],\n",
      "        [0.0205, 0.0259, 0.0271, 0.0265, 0.0281, 0.0404, 0.0242, 0.0220, 0.0093,\n",
      "         0.7760],\n",
      "        [0.0099, 0.0134, 0.0142, 0.0140, 0.0146, 0.0214, 0.0127, 0.0112, 0.0042,\n",
      "         0.8844],\n",
      "        [0.0062, 0.0087, 0.0092, 0.0091, 0.0094, 0.0139, 0.0082, 0.0072, 0.0028,\n",
      "         0.9254],\n",
      "        [0.0059, 0.0082, 0.0087, 0.0086, 0.0089, 0.0132, 0.0078, 0.0068, 0.0026,\n",
      "         0.9294]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84.00, Train Loss: 2.49, Val Loss: 11.43, Train BLEU: 14.59, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: <UNK> 塞尔 <UNK> <UNK> 斯特 说 过 真正 的 探索\n",
      "Reference: marcel proust said , &quot; the true voyage of\n",
      "Model: <SOS> marcel proust said said &quot; true true voyage voyage\n",
      "Attention Weights: tensor([[0.0915, 0.0982, 0.0968, 0.1020, 0.1120, 0.1032, 0.1016, 0.1033, 0.0971,\n",
      "         0.0944],\n",
      "        [0.0740, 0.0813, 0.0808, 0.0906, 0.1215, 0.1123, 0.1112, 0.1133, 0.1073,\n",
      "         0.1077],\n",
      "        [0.0618, 0.0674, 0.0657, 0.0744, 0.1214, 0.1228, 0.1225, 0.1253, 0.1181,\n",
      "         0.1205],\n",
      "        [0.0455, 0.0499, 0.0489, 0.0555, 0.1150, 0.1390, 0.1399, 0.1429, 0.1335,\n",
      "         0.1298],\n",
      "        [0.0309, 0.0341, 0.0338, 0.0396, 0.1033, 0.1548, 0.1585, 0.1614, 0.1490,\n",
      "         0.1346],\n",
      "        [0.0263, 0.0290, 0.0289, 0.0347, 0.0983, 0.1602, 0.1656, 0.1683, 0.1544,\n",
      "         0.1343],\n",
      "        [0.0244, 0.0270, 0.0270, 0.0328, 0.0959, 0.1622, 0.1687, 0.1714, 0.1567,\n",
      "         0.1338],\n",
      "        [0.0238, 0.0264, 0.0264, 0.0322, 0.0946, 0.1628, 0.1700, 0.1726, 0.1578,\n",
      "         0.1334],\n",
      "        [0.0234, 0.0259, 0.0259, 0.0318, 0.0936, 0.1632, 0.1708, 0.1735, 0.1585,\n",
      "         0.1333]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 永远 不会 忘记 那个 早晨 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: a morning that i will never forget . <EOS>\n",
      "Model: <SOS> it &apos;s a a . . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0972, 0.1017, 0.1048, 0.1095, 0.1038, 0.1043, 0.1084, 0.1053, 0.0900,\n",
      "         0.0749],\n",
      "        [0.0963, 0.1039, 0.1075, 0.1126, 0.1058, 0.1062, 0.1131, 0.1119, 0.0848,\n",
      "         0.0578],\n",
      "        [0.0956, 0.1045, 0.1081, 0.1133, 0.1058, 0.1058, 0.1128, 0.1131, 0.0860,\n",
      "         0.0550],\n",
      "        [0.0956, 0.1071, 0.1107, 0.1158, 0.1083, 0.1080, 0.1140, 0.1135, 0.0806,\n",
      "         0.0463],\n",
      "        [0.0933, 0.1101, 0.1142, 0.1192, 0.1122, 0.1117, 0.1158, 0.1134, 0.0729,\n",
      "         0.0372],\n",
      "        [0.0913, 0.1115, 0.1159, 0.1207, 0.1143, 0.1136, 0.1163, 0.1129, 0.0693,\n",
      "         0.0342],\n",
      "        [0.0902, 0.1121, 0.1167, 0.1216, 0.1152, 0.1143, 0.1166, 0.1128, 0.0675,\n",
      "         0.0330],\n",
      "        [0.0895, 0.1125, 0.1172, 0.1221, 0.1156, 0.1147, 0.1168, 0.1128, 0.0663,\n",
      "         0.0324],\n",
      "        [0.0891, 0.1127, 0.1175, 0.1225, 0.1160, 0.1150, 0.1170, 0.1127, 0.0656,\n",
      "         0.0320]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 85.00, Train Loss: 2.46, Val Loss: 11.44, Train BLEU: 14.59, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 原来 它 是 海洋 洋中 最长 的 生物 <EOS> <PAD>\n",
      "Reference: this turns out to be the longest creature in\n",
      "Model: <SOS> it &apos;s got to is is longest . <EOS>\n",
      "Attention Weights: tensor([[0.0841, 0.0864, 0.0887, 0.0987, 0.1108, 0.0930, 0.0870, 0.0837, 0.0570,\n",
      "         0.2107],\n",
      "        [0.0799, 0.0823, 0.0848, 0.0966, 0.1113, 0.0893, 0.0841, 0.0835, 0.0571,\n",
      "         0.2311],\n",
      "        [0.0741, 0.0757, 0.0787, 0.0928, 0.1121, 0.0819, 0.0766, 0.0779, 0.0532,\n",
      "         0.2771],\n",
      "        [0.0613, 0.0637, 0.0667, 0.0809, 0.1033, 0.0698, 0.0643, 0.0655, 0.0401,\n",
      "         0.3845],\n",
      "        [0.0460, 0.0500, 0.0525, 0.0636, 0.0844, 0.0553, 0.0502, 0.0502, 0.0267,\n",
      "         0.5211],\n",
      "        [0.0288, 0.0340, 0.0359, 0.0432, 0.0583, 0.0379, 0.0340, 0.0329, 0.0144,\n",
      "         0.6806],\n",
      "        [0.0165, 0.0210, 0.0223, 0.0266, 0.0365, 0.0234, 0.0208, 0.0196, 0.0075,\n",
      "         0.8057],\n",
      "        [0.0102, 0.0135, 0.0145, 0.0169, 0.0234, 0.0151, 0.0134, 0.0123, 0.0045,\n",
      "         0.8761],\n",
      "        [0.0075, 0.0102, 0.0109, 0.0125, 0.0175, 0.0114, 0.0101, 0.0091, 0.0034,\n",
      "         0.9075]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在 可以 去 个 真正 的 学校 念书 了\n",
      "Reference: &quot; you can go to a real school now\n",
      "Model: <SOS> we of the the the the , , ,\n",
      "Attention Weights: tensor([[0.0977, 0.1081, 0.1124, 0.1170, 0.1036, 0.0956, 0.0946, 0.0930, 0.0902,\n",
      "         0.0876],\n",
      "        [0.0971, 0.1109, 0.1168, 0.1182, 0.1009, 0.0935, 0.0925, 0.0910, 0.0887,\n",
      "         0.0905],\n",
      "        [0.0970, 0.1176, 0.1231, 0.1208, 0.0991, 0.0904, 0.0892, 0.0875, 0.0851,\n",
      "         0.0902],\n",
      "        [0.0952, 0.1178, 0.1266, 0.1257, 0.1011, 0.0900, 0.0881, 0.0858, 0.0827,\n",
      "         0.0870],\n",
      "        [0.0919, 0.1173, 0.1296, 0.1318, 0.1033, 0.0902, 0.0878, 0.0849, 0.0811,\n",
      "         0.0821],\n",
      "        [0.0878, 0.1159, 0.1311, 0.1369, 0.1054, 0.0913, 0.0885, 0.0851, 0.0804,\n",
      "         0.0776],\n",
      "        [0.0841, 0.1157, 0.1322, 0.1402, 0.1066, 0.0920, 0.0890, 0.0853, 0.0801,\n",
      "         0.0748],\n",
      "        [0.0820, 0.1156, 0.1324, 0.1415, 0.1071, 0.0925, 0.0894, 0.0857, 0.0801,\n",
      "         0.0737],\n",
      "        [0.0807, 0.1153, 0.1322, 0.1419, 0.1076, 0.0930, 0.0899, 0.0860, 0.0803,\n",
      "         0.0731]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 86.00, Train Loss: 2.44, Val Loss: 11.44, Train BLEU: 14.74, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想 海洋 占 了 地球 球面 面积 的 75\n",
      "Reference: when you think about it , the oceans are\n",
      "Model: <SOS> when you you the , , , , ,\n",
      "Attention Weights: tensor([[0.1001, 0.1050, 0.1118, 0.1053, 0.1062, 0.1134, 0.1071, 0.1009, 0.0950,\n",
      "         0.0553],\n",
      "        [0.0986, 0.1053, 0.1145, 0.1050, 0.1060, 0.1164, 0.1088, 0.1021, 0.0993,\n",
      "         0.0440],\n",
      "        [0.0976, 0.1058, 0.1175, 0.1057, 0.1069, 0.1200, 0.1107, 0.1025, 0.0991,\n",
      "         0.0342],\n",
      "        [0.0961, 0.1074, 0.1202, 0.1074, 0.1087, 0.1231, 0.1122, 0.1028, 0.0967,\n",
      "         0.0254],\n",
      "        [0.0933, 0.1088, 0.1215, 0.1097, 0.1108, 0.1245, 0.1136, 0.1035, 0.0935,\n",
      "         0.0207],\n",
      "        [0.0906, 0.1100, 0.1227, 0.1117, 0.1126, 0.1256, 0.1147, 0.1037, 0.0902,\n",
      "         0.0181],\n",
      "        [0.0885, 0.1110, 0.1237, 0.1132, 0.1139, 0.1264, 0.1155, 0.1036, 0.0875,\n",
      "         0.0168],\n",
      "        [0.0872, 0.1115, 0.1243, 0.1140, 0.1146, 0.1268, 0.1159, 0.1035, 0.0858,\n",
      "         0.0164],\n",
      "        [0.0865, 0.1118, 0.1246, 0.1145, 0.1150, 0.1270, 0.1161, 0.1034, 0.0848,\n",
      "         0.0163]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 总是 担心 会 被 塔利 塔利班 发现 <EOS> <PAD>\n",
      "Reference: we always wondered what they knew about us .\n",
      "Model: <SOS> it &apos;s the to is about . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0840, 0.0968, 0.1043, 0.1030, 0.1013, 0.1044, 0.1054, 0.1160, 0.0955,\n",
      "         0.0893],\n",
      "        [0.0856, 0.1019, 0.1012, 0.1001, 0.0988, 0.1033, 0.1063, 0.1188, 0.0937,\n",
      "         0.0903],\n",
      "        [0.0852, 0.1064, 0.0998, 0.0980, 0.0966, 0.1038, 0.1080, 0.1240, 0.0907,\n",
      "         0.0874],\n",
      "        [0.0835, 0.1089, 0.1010, 0.0981, 0.0959, 0.1035, 0.1080, 0.1280, 0.0890,\n",
      "         0.0841],\n",
      "        [0.0809, 0.1093, 0.1026, 0.0989, 0.0960, 0.1033, 0.1084, 0.1323, 0.0879,\n",
      "         0.0804],\n",
      "        [0.0764, 0.1070, 0.1050, 0.1009, 0.0977, 0.1043, 0.1097, 0.1349, 0.0876,\n",
      "         0.0765],\n",
      "        [0.0735, 0.1054, 0.1065, 0.1024, 0.0991, 0.1052, 0.1104, 0.1356, 0.0876,\n",
      "         0.0744],\n",
      "        [0.0719, 0.1041, 0.1072, 0.1032, 0.1000, 0.1059, 0.1109, 0.1360, 0.0876,\n",
      "         0.0731],\n",
      "        [0.0710, 0.1029, 0.1076, 0.1038, 0.1005, 0.1064, 0.1113, 0.1360, 0.0877,\n",
      "         0.0727]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 87.00, Train Loss: 2.41, Val Loss: 11.45, Train BLEU: 14.76, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 其实 它们 都 是 由 单独 的 动物 结合 合在\n",
      "Reference: these are all individual animals banding together to make\n",
      "Model: <SOS> these these all animals animals are are are are\n",
      "Attention Weights: tensor([[0.1021, 0.1061, 0.1052, 0.1067, 0.1071, 0.1095, 0.1036, 0.1013, 0.0988,\n",
      "         0.0596],\n",
      "        [0.1005, 0.1075, 0.1067, 0.1085, 0.1092, 0.1140, 0.1063, 0.1075, 0.1048,\n",
      "         0.0350],\n",
      "        [0.1005, 0.1074, 0.1064, 0.1083, 0.1090, 0.1148, 0.1056, 0.1072, 0.1066,\n",
      "         0.0343],\n",
      "        [0.1002, 0.1092, 0.1084, 0.1102, 0.1108, 0.1165, 0.1066, 0.1075, 0.1048,\n",
      "         0.0258],\n",
      "        [0.0984, 0.1110, 0.1104, 0.1122, 0.1128, 0.1178, 0.1081, 0.1076, 0.1014,\n",
      "         0.0202],\n",
      "        [0.0964, 0.1127, 0.1123, 0.1140, 0.1145, 0.1189, 0.1095, 0.1074, 0.0977,\n",
      "         0.0165],\n",
      "        [0.0946, 0.1140, 0.1138, 0.1155, 0.1159, 0.1198, 0.1106, 0.1071, 0.0944,\n",
      "         0.0142],\n",
      "        [0.0931, 0.1148, 0.1148, 0.1166, 0.1170, 0.1206, 0.1114, 0.1069, 0.0920,\n",
      "         0.0129],\n",
      "        [0.0920, 0.1153, 0.1155, 0.1173, 0.1177, 0.1211, 0.1119, 0.1067, 0.0902,\n",
      "         0.0121]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 出身 阿富汗 边远 <UNK> 地区 有着 与 他人 不同\n",
      "Reference: a total maverick from a remote province of afghanistan\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0783, 0.0809, 0.0837, 0.0930, 0.1040, 0.0871, 0.0814, 0.0786, 0.0521,\n",
      "         0.2609],\n",
      "        [0.0765, 0.0790, 0.0819, 0.0936, 0.1077, 0.0854, 0.0804, 0.0803, 0.0543,\n",
      "         0.2610],\n",
      "        [0.0717, 0.0733, 0.0766, 0.0907, 0.1095, 0.0790, 0.0737, 0.0753, 0.0512,\n",
      "         0.2991],\n",
      "        [0.0587, 0.0612, 0.0645, 0.0787, 0.1007, 0.0669, 0.0612, 0.0628, 0.0381,\n",
      "         0.4071],\n",
      "        [0.0431, 0.0472, 0.0499, 0.0607, 0.0807, 0.0520, 0.0469, 0.0471, 0.0247,\n",
      "         0.5477],\n",
      "        [0.0259, 0.0309, 0.0329, 0.0400, 0.0540, 0.0343, 0.0306, 0.0297, 0.0128,\n",
      "         0.7089],\n",
      "        [0.0141, 0.0181, 0.0194, 0.0233, 0.0320, 0.0201, 0.0178, 0.0168, 0.0063,\n",
      "         0.8321],\n",
      "        [0.0084, 0.0113, 0.0121, 0.0143, 0.0198, 0.0126, 0.0111, 0.0102, 0.0037,\n",
      "         0.8966],\n",
      "        [0.0064, 0.0087, 0.0093, 0.0108, 0.0151, 0.0097, 0.0085, 0.0077, 0.0029,\n",
      "         0.9209]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 88.00, Train Loss: 2.40, Val Loss: 11.49, Train BLEU: 14.69, Val BLEU: 0.26\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这 有 不少 精彩 的 泰坦 泰坦尼克 坦尼 尼克\n",
      "Reference: we &apos;ve got some of the most incredible video\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0889, 0.0939, 0.0976, 0.1046, 0.1038, 0.1017, 0.1075, 0.1057, 0.1072,\n",
      "         0.0891],\n",
      "        [0.0874, 0.0923, 0.0958, 0.1031, 0.1023, 0.1007, 0.1099, 0.1081, 0.1095,\n",
      "         0.0908],\n",
      "        [0.0852, 0.0890, 0.0927, 0.1032, 0.1019, 0.0991, 0.1121, 0.1142, 0.1142,\n",
      "         0.0885],\n",
      "        [0.0838, 0.0879, 0.0919, 0.1039, 0.1024, 0.0989, 0.1145, 0.1148, 0.1159,\n",
      "         0.0862],\n",
      "        [0.0814, 0.0866, 0.0913, 0.1045, 0.1027, 0.0991, 0.1171, 0.1168, 0.1174,\n",
      "         0.0830],\n",
      "        [0.0791, 0.0861, 0.0912, 0.1046, 0.1029, 0.0994, 0.1184, 0.1187, 0.1191,\n",
      "         0.0806],\n",
      "        [0.0770, 0.0860, 0.0913, 0.1046, 0.1031, 0.0998, 0.1191, 0.1202, 0.1204,\n",
      "         0.0785],\n",
      "        [0.0749, 0.0864, 0.0919, 0.1051, 0.1038, 0.1004, 0.1193, 0.1205, 0.1211,\n",
      "         0.0765],\n",
      "        [0.0734, 0.0868, 0.0925, 0.1056, 0.1045, 0.1009, 0.1193, 0.1206, 0.1215,\n",
      "         0.0749]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6 岁 那年 塔利 塔利班 占领 阿富汗 并 规定\n",
      "Reference: you see , i was six when the taliban\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0884, 0.0901, 0.0981, 0.1011, 0.0932, 0.0878, 0.0852, 0.0831, 0.0555,\n",
      "         0.2174],\n",
      "        [0.0872, 0.0884, 0.0974, 0.1002, 0.0910, 0.0860, 0.0839, 0.0851, 0.0587,\n",
      "         0.2221],\n",
      "        [0.0822, 0.0825, 0.0937, 0.0977, 0.0862, 0.0796, 0.0778, 0.0810, 0.0556,\n",
      "         0.2639],\n",
      "        [0.0690, 0.0710, 0.0822, 0.0864, 0.0747, 0.0676, 0.0658, 0.0687, 0.0416,\n",
      "         0.3728],\n",
      "        [0.0514, 0.0558, 0.0649, 0.0689, 0.0594, 0.0532, 0.0514, 0.0519, 0.0270,\n",
      "         0.5161],\n",
      "        [0.0312, 0.0369, 0.0429, 0.0458, 0.0397, 0.0356, 0.0340, 0.0329, 0.0140,\n",
      "         0.6871],\n",
      "        [0.0167, 0.0214, 0.0249, 0.0267, 0.0233, 0.0210, 0.0198, 0.0186, 0.0068,\n",
      "         0.8208],\n",
      "        [0.0107, 0.0142, 0.0164, 0.0177, 0.0156, 0.0141, 0.0132, 0.0121, 0.0044,\n",
      "         0.8817],\n",
      "        [0.0082, 0.0110, 0.0126, 0.0137, 0.0122, 0.0110, 0.0104, 0.0094, 0.0035,\n",
      "         0.9081]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 89.00, Train Loss: 2.37, Val Loss: 11.50, Train BLEU: 15.81, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 通过 潜水 潜水艇 拍下 的 影片 把 我们\n",
      "Reference: with vibrant video clips captured by submarines , david\n",
      "Model: <SOS> with vibrant video , , , , , ,\n",
      "Attention Weights: tensor([[0.1022, 0.0899, 0.0987, 0.1048, 0.1234, 0.1060, 0.0977, 0.0978, 0.0916,\n",
      "         0.0879],\n",
      "        [0.1044, 0.0947, 0.0970, 0.1053, 0.1231, 0.1026, 0.0958, 0.0960, 0.0906,\n",
      "         0.0905],\n",
      "        [0.1060, 0.0893, 0.0973, 0.1088, 0.1286, 0.1021, 0.0942, 0.0952, 0.0880,\n",
      "         0.0905],\n",
      "        [0.0990, 0.0734, 0.1020, 0.1142, 0.1341, 0.1064, 0.0963, 0.0969, 0.0883,\n",
      "         0.0893],\n",
      "        [0.0884, 0.0588, 0.1086, 0.1221, 0.1367, 0.1116, 0.0997, 0.0994, 0.0891,\n",
      "         0.0855],\n",
      "        [0.0810, 0.0514, 0.1125, 0.1271, 0.1386, 0.1149, 0.1018, 0.1008, 0.0895,\n",
      "         0.0824],\n",
      "        [0.0778, 0.0486, 0.1139, 0.1291, 0.1400, 0.1164, 0.1026, 0.1013, 0.0896,\n",
      "         0.0808],\n",
      "        [0.0763, 0.0475, 0.1143, 0.1298, 0.1408, 0.1170, 0.1030, 0.1016, 0.0897,\n",
      "         0.0799],\n",
      "        [0.0756, 0.0473, 0.1142, 0.1300, 0.1414, 0.1172, 0.1032, 0.1018, 0.0898,\n",
      "         0.0794]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班 走 了 父亲 大声 叫 着 <EOS> <PAD>\n",
      "Reference: &quot; the taliban are gone ! &quot; my father\n",
      "Model: <SOS> it of the to is . . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0907, 0.0949, 0.0982, 0.1057, 0.1052, 0.1037, 0.1039, 0.1040, 0.1004,\n",
      "         0.0935],\n",
      "        [0.0908, 0.0943, 0.0974, 0.1054, 0.1045, 0.1030, 0.1031, 0.1033, 0.1005,\n",
      "         0.0977],\n",
      "        [0.0892, 0.0922, 0.0954, 0.1074, 0.1061, 0.1035, 0.1040, 0.1042, 0.1004,\n",
      "         0.0975],\n",
      "        [0.0878, 0.0918, 0.0956, 0.1091, 0.1074, 0.1042, 0.1046, 0.1046, 0.0999,\n",
      "         0.0949],\n",
      "        [0.0857, 0.0916, 0.0960, 0.1104, 0.1087, 0.1053, 0.1056, 0.1052, 0.0995,\n",
      "         0.0920],\n",
      "        [0.0834, 0.0917, 0.0964, 0.1114, 0.1098, 0.1063, 0.1066, 0.1058, 0.0993,\n",
      "         0.0893],\n",
      "        [0.0814, 0.0920, 0.0970, 0.1120, 0.1107, 0.1071, 0.1073, 0.1063, 0.0992,\n",
      "         0.0872],\n",
      "        [0.0795, 0.0923, 0.0974, 0.1124, 0.1114, 0.1078, 0.1079, 0.1068, 0.0991,\n",
      "         0.0854],\n",
      "        [0.0783, 0.0925, 0.0977, 0.1127, 0.1118, 0.1083, 0.1084, 0.1070, 0.0990,\n",
      "         0.0842]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-aaeb1af72133>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders_full\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloaders_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders_minibatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloaders_minibatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders_minitrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloaders_minitrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_intermediate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_to_log\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     lazy_eval=False, inspect_samples=1)\n\u001b[0m",
      "\u001b[0;32m~/Documents/data-science-coursework/nyu-nlp/project/train_eval.py\u001b[0m in \u001b[0;36mtrain_and_eval_attn\u001b[0;34m(model, loaders_full, loaders_minibatch, loaders_minitrain, params, vocab, lazy_eval, print_intermediate, save_checkpoint, save_to_log, inspect_samples)\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m             \u001b[0mfinal_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypotheses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m             \u001b[0mfinal_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarg_idxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/nlpclass/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/data-science-coursework/nyu-nlp/project/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src_idx, targ_idx, src_lens, targ_lens, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mdi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarg_max_sentence_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                         \u001b[0mdec_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m                         \u001b[0mdec_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                         \u001b[0mteacher_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarg_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/nlpclass/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/data-science-coursework/nyu-nlp/project/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, dec_input, dec_hidden, enc_outputs)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;31m#               print(\"after gru output has size {}\".format(output.size()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;31m#               print(\"after out FC layer output has size {}\".format(self.out(output[0]).size()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [batch_size * vocab_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;31m#               print(\"after softmax output has size {}\".format(output.size()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/nlpclass/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/nlpclass/lib/python3.6/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/envs/nlpclass/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel)\u001b[0m\n\u001b[1;32m    973\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log_softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, results = train_and_eval_attn(\n",
    "    model=model, loaders_full=loaders_full, loaders_minibatch=loaders_minibatch, loaders_minitrain=loaders_minitrain, \n",
    "    params=params, vocab=vocab, print_intermediate=True, save_checkpoint=True, save_to_log=True, \n",
    "    lazy_eval=False, inspect_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_results(load_experiment_log())[['dt_created', 'num_epochs', 'learning_rate', 'clip_grad_max_norm', 'val_loss']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_learning_curve(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch: 199.00, Train Loss: 0.32, Val Loss: 13.19, Train BLEU: 98.94, Val BLEU: 0.27\n",
    "plot_single_learning_curve(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with attention energies = v_broadcast.bmm(torch.tanh(self.attn(concat)).transpose(1, 2)) # switched order  \n",
    "# Epoch: 199.00, Train Loss: 0.63, Val Loss: 12.82, Train BLEU: 92.05, Val BLEU: 0.38\n",
    "plot_single_learning_curve(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, token in enumerate(vocab[SRC_LANG]['id2token']): \n",
    "    if i < 20: \n",
    "        print(\"{}: {}\".format(i, token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, token in enumerate(vocab[TARG_LANG]['id2token']): \n",
    "    if i < 20: \n",
    "        print(\"{}: {}\".format(i, token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.arange(0, 3*5*10).view(3, 5, 10)\n",
    "print(x)\n",
    "y = x[1:, :, :]\n",
    "print(y)\n",
    "z = y.view(-1, 10)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.arange(0, 2*5).view(5, 2)\n",
    "print(t)\n",
    "u = t.contiguous().view(-1)\n",
    "print(u)\n",
    "v = t.permute(1, 0)\n",
    "print(v)\n",
    "w = v.contiguous().view(-1)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(0, 2*1*300)\n",
    "print(a)\n",
    "b = a.view(-1, 1, 300)\n",
    "print(b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (src_idxs, targ_idxs, src_lens, targ_lens) in enumerate(full_loaders['train']):\n",
    "#     print(i)\n",
    "#     print(src_idxs.size())\n",
    "#     print(src_idxs)\n",
    "#     print(src_lens)\n",
    "#     print(targ_idxs.size())\n",
    "#     print(targ_idxs)\n",
    "#     print(targ_lens)\n",
    "    id2token = vocab[SRC_LANG]['id2token']\n",
    "    test_tensor = src_idxs\n",
    "    list_of_lists = test_tensor.numpy().astype(int).tolist()\n",
    "    to_token = lambda l: ' '.join([id2token[idx] for idx in l])\n",
    "    list_of_lists_tokens = [to_token(l) for l in list_of_lists] \n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
