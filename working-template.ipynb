{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from data_processing import generate_vocab, process_data, create_dataloaders \n",
    "from model import get_pretrained_emb, EncoderDecoder, EncoderRNN, DecoderRNN, Attention, DecoderAttnRNN\n",
    "from train_eval import train_and_eval, inspect_model, count_parameters, summarize_results, \\\n",
    "    plot_single_learning_curve, load_experiment_log\n",
    "import importlib\n",
    "import pickle as pkl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model identification\n",
    "MODEL_NAME = 'test_model'\n",
    "SRC_LANG = 'vi'\n",
    "TARG_LANG = 'en'\n",
    "\n",
    "# data processing params  \n",
    "SRC_MAX_SENTENCE_LEN = 10 \n",
    "TARG_MAX_SENTENCE_LEN = 10\n",
    "SRC_VOCAB_SIZE = 30000\n",
    "TARG_VOCAB_SIZE = 30000\n",
    "\n",
    "# model architecture params \n",
    "NUM_LAYERS = 2 \n",
    "ENC_HIDDEN_DIM = 300 \n",
    "DEC_HIDDEN_DIM = 2 * ENC_HIDDEN_DIM \n",
    "TEACHER_FORCING_RATIO = 0.5\n",
    "CLIP_GRAD_MAX_NORM = 10\n",
    "ENC_DROPOUT = 0 # to actually implement\n",
    "DEC_DROPOUT = 0 # to actually implement\n",
    "\n",
    "# training params  \n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 5\n",
    "LR = 0.0005\n",
    "OPTIMIZER = 'Adam'\n",
    "LAZY_TRAIN = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store as dict to save to results later \n",
    "params = {'model_name': MODEL_NAME, 'src_lang': SRC_LANG, 'targ_lang': TARG_LANG, \n",
    "          'src_max_sentence_len': SRC_MAX_SENTENCE_LEN, 'targ_max_sentence_len': TARG_MAX_SENTENCE_LEN, \n",
    "          'src_vocab_size': SRC_VOCAB_SIZE, 'targ_vocab_size': TARG_VOCAB_SIZE, \n",
    "          'num_layers': NUM_LAYERS, 'enc_hidden_dim': ENC_HIDDEN_DIM, 'dec_hidden_dim': DEC_HIDDEN_DIM,\n",
    "          'teacher_forcing_ratio': TEACHER_FORCING_RATIO, 'clip_grad_max_norm': CLIP_GRAD_MAX_NORM,\n",
    "          'enc_dropout': ENC_DROPOUT, 'dec_dropout': DEC_DROPOUT, \n",
    "          'batch_size': BATCH_SIZE, 'num_epochs': NUM_EPOCHS, 'learning_rate': LR, 'optimizer': OPTIMIZER, \n",
    "          'lazy_train': LAZY_TRAIN} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # takes a long time to process, save to pickle for reimport in future \n",
    "# vocab = generate_vocab(SRC_LANG, TARG_LANG, SRC_VOCAB_SIZE, TARG_VOCAB_SIZE)\n",
    "# vocab_filename = \"{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n",
    "# pkl.dump(vocab, open(vocab_filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload from pickle \n",
    "vocab_filename = \"{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n",
    "vocab = pkl.load(open(vocab_filename, \"rb\"))\n",
    "data = process_data(SRC_LANG, TARG_LANG, vocab)\n",
    "limited_data = process_data(SRC_LANG, TARG_LANG, vocab, sample_limit=BATCH_SIZE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders \n",
    "full_loaders = create_dataloaders(data, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)\n",
    "fast_loaders = create_dataloaders(limited_data, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model \n",
    "\n",
    "encoder = EncoderRNN(enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, src_max_sentence_len=SRC_MAX_SENTENCE_LEN,\n",
    "                     pretrained_word2vec=get_pretrained_emb(vocab[SRC_LANG]['word2vec'], vocab[SRC_LANG]['token2id']))\n",
    "decoder = DecoderRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, \n",
    "                     targ_vocab_size=TARG_VOCAB_SIZE, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "                     pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "# decoder = DecoderAttnRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, \n",
    "#                          targ_vocab_size=TARG_VOCAB_SIZE, src_max_sentence_len=SRC_MAX_SENTENCE_LEN, \n",
    "#                          targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "#                          pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "model = EncoderDecoder(encoder, decoder, vocab[TARG_LANG]['token2id']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.00, Train Loss: 0.00, Val Loss: 10.24, Train BLEU: 0.00, Val BLEU: 0.26\n",
      "Inspecting model on training data...\n",
      "REFERENCE TRANSLATION: rachel pike : the science behind a climate headline in 4 minutes , atmospheric chemist rachel pike provides i &apos;d like to talk to you today about headlines that look like this when they have to they are both two branches of the same field\n",
      "MODEL TRANSLATION: amplifications of of of of of of of of trumpet the the the it it it it it dizzy metallic of of of of of it it heirloom marriage the the of of it of of dizzy cowboy of of of of of of of\n",
      "Inspecting model on validation data...\n",
      "REFERENCE TRANSLATION: when i was little , i thought my country and i was very proud . in school , we spent a lot of time although i often wondered about the outside world , when i was seven years old , i saw\n",
      "MODEL TRANSLATION: neuro-bunk ensler separated lobe of of it it it euphore euphore euphore euphore euphore euphore euphore euphore euphore standardized and it it of it it of it arising the the of of of of of of dizzy dizzy of of of of of of of\n",
      "Epoch: 1.00, Train Loss: 0.00, Val Loss: 10.13, Train BLEU: 0.00, Val BLEU: 0.42\n",
      "Inspecting model on training data...\n",
      "REFERENCE TRANSLATION: rachel pike : the science behind a climate headline in 4 minutes , atmospheric chemist rachel pike provides i &apos;d like to talk to you today about headlines that look like this when they have to they are both two branches of the same field\n",
      "MODEL TRANSLATION: of of of is is is is is is the the the the the the the the the to the the the it it it it it the the the the the it it it it the the the it it it it it it\n",
      "Inspecting model on validation data...\n",
      "REFERENCE TRANSLATION: when i was little , i thought my country and i was very proud . in school , we spent a lot of time although i often wondered about the outside world , when i was seven years old , i saw\n",
      "MODEL TRANSLATION: to the the the it it it it it euphore euphore euphore euphore euphore euphore euphore euphore euphore the the the it it it it it it the the the the the the it it it to the the it it it it it it\n",
      "Epoch: 2.00, Train Loss: 0.00, Val Loss: 9.93, Train BLEU: 0.00, Val BLEU: 0.39\n",
      "Inspecting model on training data...\n",
      "REFERENCE TRANSLATION: rachel pike : the science behind a climate headline in 4 minutes , atmospheric chemist rachel pike provides i &apos;d like to talk to you today about headlines that look like this when they have to they are both two branches of the same field\n",
      "MODEL TRANSLATION: of of is is is is is is is the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Inspecting model on validation data...\n",
      "REFERENCE TRANSLATION: when i was little , i thought my country and i was very proud . in school , we spent a lot of time although i often wondered about the outside world , when i was seven years old , i saw\n",
      "MODEL TRANSLATION: the the the the the the the the the euphore is is is is is is is is the the the the the the the the the the the the the the the the the the to the the the the the the the the\n",
      "Epoch: 3.00, Train Loss: 0.00, Val Loss: 9.65, Train BLEU: 0.00, Val BLEU: 0.39\n",
      "Inspecting model on training data...\n",
      "REFERENCE TRANSLATION: rachel pike : the science behind a climate headline in 4 minutes , atmospheric chemist rachel pike provides i &apos;d like to talk to you today about headlines that look like this when they have to they are both two branches of the same field\n",
      "MODEL TRANSLATION: of of is is is is is is is the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Inspecting model on validation data...\n",
      "REFERENCE TRANSLATION: when i was little , i thought my country and i was very proud . in school , we spent a lot of time although i often wondered about the outside world , when i was seven years old , i saw\n",
      "MODEL TRANSLATION: the the the the the the the the the of of is is is is is is is the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Epoch: 4.00, Train Loss: 0.00, Val Loss: 9.34, Train BLEU: 0.00, Val BLEU: 0.39\n",
      "Inspecting model on training data...\n",
      "REFERENCE TRANSLATION: rachel pike : the science behind a climate headline in 4 minutes , atmospheric chemist rachel pike provides i &apos;d like to talk to you today about headlines that look like this when they have to they are both two branches of the same field\n",
      "MODEL TRANSLATION: of of of of of of of of of the the the the the the the the the the the of of the the the the the the the the of of the the the the the the the the the the the the the\n",
      "Inspecting model on validation data...\n",
      "REFERENCE TRANSLATION: when i was little , i thought my country and i was very proud . in school , we spent a lot of time although i often wondered about the outside world , when i was seven years old , i saw\n",
      "MODEL TRANSLATION: the the the the the the the the the of of of of of of of of of the the the the the the the the the the the of of the the the the the the the the the the the the the the\n",
      "Experiment completed in 0 minutes with 9.34 best validation loss and 0.42 best validation BLEU.\n"
     ]
    }
   ],
   "source": [
    "model, results = train_and_eval(\n",
    "    model=model, full_loaders=full_loaders, fast_loaders=fast_loaders, params=params, vocab=vocab, \n",
    "    print_intermediate=True, save_checkpoint=True, lazy_eval=True, inspect=True, save_to_log=True, print_summary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt_created</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>hyperparams</th>\n",
       "      <th>results</th>\n",
       "      <th>runtime</th>\n",
       "      <th>model_type</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>enc_hidden_dim</th>\n",
       "      <th>dec_hidden_dim</th>\n",
       "      <th>...</th>\n",
       "      <th>targ_lang</th>\n",
       "      <th>src_vocab_size</th>\n",
       "      <th>targ_vocab_size</th>\n",
       "      <th>src_max_sentence_len</th>\n",
       "      <th>targ_max_sentence_len</th>\n",
       "      <th>model_name</th>\n",
       "      <th>teacher_forcing_ratio</th>\n",
       "      <th>lazy_train</th>\n",
       "      <th>clip_grad_max_norm</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-26 23:17:44</td>\n",
       "      <td>test_run</td>\n",
       "      <td>{'model_type': 'attention_bahdanau', 'num_epoc...</td>\n",
       "      <td>[{'epoch': 0.0, 'val_loss': 8.783560848236084,...</td>\n",
       "      <td>53.518373</td>\n",
       "      <td>attention_bahdanau</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.433290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-27 00:43:43</td>\n",
       "      <td>test_run</td>\n",
       "      <td>{'model_type': 'attention_bahdanau', 'num_epoc...</td>\n",
       "      <td>[{'epoch': 0.0, 'val_loss': 8.989323210716247,...</td>\n",
       "      <td>52.872075</td>\n",
       "      <td>attention_bahdanau</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.436468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-27 02:28:19</td>\n",
       "      <td>test_run</td>\n",
       "      <td>{'model_type': 'without_attention', 'num_epoch...</td>\n",
       "      <td>[{'epoch': 0.0, 'val_loss': 8.887566566467285,...</td>\n",
       "      <td>1.302775</td>\n",
       "      <td>without_attention</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.335167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-27 02:30:44</td>\n",
       "      <td>test_run</td>\n",
       "      <td>{'model_type': 'without_attention', 'num_epoch...</td>\n",
       "      <td>[{'epoch': 0.0, 'val_loss': 8.855473518371582,...</td>\n",
       "      <td>1.179587</td>\n",
       "      <td>without_attention</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.390460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-11-27 05:10:18</td>\n",
       "      <td>test_run</td>\n",
       "      <td>{'model_type': 'attention_bahdanau', 'num_epoc...</td>\n",
       "      <td>[{'epoch': 0.0, 'val_loss': 8.919134140014648,...</td>\n",
       "      <td>155.873592</td>\n",
       "      <td>attention_bahdanau</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.484231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-11-28 00:43:37</td>\n",
       "      <td>test_run</td>\n",
       "      <td>{'model_type': 'attention_bahdanau', 'num_epoc...</td>\n",
       "      <td>[{'epoch': 0.0, 'val_loss': 10.040691375732422...</td>\n",
       "      <td>31.569452</td>\n",
       "      <td>attention_bahdanau</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.985807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-11-28 13:52:27</td>\n",
       "      <td>test_run</td>\n",
       "      <td>{'model_type': 'attention_bahdanau', 'num_epoc...</td>\n",
       "      <td>[{'epoch': 0.0, 'val_loss': 10.062241554260254...</td>\n",
       "      <td>673.474022</td>\n",
       "      <td>attention_bahdanau</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.088548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-11-28 17:55:24</td>\n",
       "      <td>test_run</td>\n",
       "      <td>{'model_type': 'attention_bahdanau', 'num_epoc...</td>\n",
       "      <td>[{'epoch': 0.0, 'val_loss': 10.21630573272705,...</td>\n",
       "      <td>6.029234</td>\n",
       "      <td>attention_bahdanau</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.507013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-12-01 02:29:11</td>\n",
       "      <td>test_model</td>\n",
       "      <td>{'model_name': 'test_model', 'num_epochs': 5, ...</td>\n",
       "      <td>[{'epoch': 0.0, 'val_loss': 10.221494674682617...</td>\n",
       "      <td>0.312100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>test_model</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.228798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-12-01 02:22:55</td>\n",
       "      <td>test_model</td>\n",
       "      <td>{'model_name': 'test_model', 'num_epochs': 5, ...</td>\n",
       "      <td>[{'epoch': 0.0, 'val_loss': 10.231721878051758...</td>\n",
       "      <td>0.381173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>test_model</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.330558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-12-01 02:38:47</td>\n",
       "      <td>test_model</td>\n",
       "      <td>{'model_name': 'test_model', 'src_lang': 'vi',...</td>\n",
       "      <td>[{'epoch': 0.0, 'val_loss': 10.238265037536621...</td>\n",
       "      <td>0.309454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>300</td>\n",
       "      <td>600</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>test_model</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.337175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             dt_created experiment_name  \\\n",
       "0   2018-11-26 23:17:44        test_run   \n",
       "1   2018-11-27 00:43:43        test_run   \n",
       "2   2018-11-27 02:28:19        test_run   \n",
       "3   2018-11-27 02:30:44        test_run   \n",
       "4   2018-11-27 05:10:18        test_run   \n",
       "5   2018-11-28 00:43:37        test_run   \n",
       "6   2018-11-28 13:52:27        test_run   \n",
       "7   2018-11-28 17:55:24        test_run   \n",
       "9   2018-12-01 02:29:11      test_model   \n",
       "8   2018-12-01 02:22:55      test_model   \n",
       "10  2018-12-01 02:38:47      test_model   \n",
       "\n",
       "                                          hyperparams  \\\n",
       "0   {'model_type': 'attention_bahdanau', 'num_epoc...   \n",
       "1   {'model_type': 'attention_bahdanau', 'num_epoc...   \n",
       "2   {'model_type': 'without_attention', 'num_epoch...   \n",
       "3   {'model_type': 'without_attention', 'num_epoch...   \n",
       "4   {'model_type': 'attention_bahdanau', 'num_epoc...   \n",
       "5   {'model_type': 'attention_bahdanau', 'num_epoc...   \n",
       "6   {'model_type': 'attention_bahdanau', 'num_epoc...   \n",
       "7   {'model_type': 'attention_bahdanau', 'num_epoc...   \n",
       "9   {'model_name': 'test_model', 'num_epochs': 5, ...   \n",
       "8   {'model_name': 'test_model', 'num_epochs': 5, ...   \n",
       "10  {'model_name': 'test_model', 'src_lang': 'vi',...   \n",
       "\n",
       "                                              results     runtime  \\\n",
       "0   [{'epoch': 0.0, 'val_loss': 8.783560848236084,...   53.518373   \n",
       "1   [{'epoch': 0.0, 'val_loss': 8.989323210716247,...   52.872075   \n",
       "2   [{'epoch': 0.0, 'val_loss': 8.887566566467285,...    1.302775   \n",
       "3   [{'epoch': 0.0, 'val_loss': 8.855473518371582,...    1.179587   \n",
       "4   [{'epoch': 0.0, 'val_loss': 8.919134140014648,...  155.873592   \n",
       "5   [{'epoch': 0.0, 'val_loss': 10.040691375732422...   31.569452   \n",
       "6   [{'epoch': 0.0, 'val_loss': 10.062241554260254...  673.474022   \n",
       "7   [{'epoch': 0.0, 'val_loss': 10.21630573272705,...    6.029234   \n",
       "9   [{'epoch': 0.0, 'val_loss': 10.221494674682617...    0.312100   \n",
       "8   [{'epoch': 0.0, 'val_loss': 10.231721878051758...    0.381173   \n",
       "10  [{'epoch': 0.0, 'val_loss': 10.238265037536621...    0.309454   \n",
       "\n",
       "            model_type  num_epochs  learning_rate  enc_hidden_dim  \\\n",
       "0   attention_bahdanau          10         0.0005             300   \n",
       "1   attention_bahdanau          10         0.0005             300   \n",
       "2    without_attention          10         0.0005             300   \n",
       "3    without_attention          10         0.0005             300   \n",
       "4   attention_bahdanau        1000         0.0005             300   \n",
       "5   attention_bahdanau         100         0.0005             300   \n",
       "6   attention_bahdanau        2000         0.0005             300   \n",
       "7   attention_bahdanau         100         0.0005             300   \n",
       "9                  NaN           5         0.0005             300   \n",
       "8                  NaN           5         0.0005             300   \n",
       "10                 NaN           5         0.0005             300   \n",
       "\n",
       "    dec_hidden_dim    ...     targ_lang src_vocab_size  targ_vocab_size  \\\n",
       "0              600    ...            en          10000            10000   \n",
       "1              600    ...            en          10000            10000   \n",
       "2              600    ...            en          10000            10000   \n",
       "3              600    ...            en          10000            10000   \n",
       "4              600    ...            en          10000            10000   \n",
       "5              600    ...            en          30000            30000   \n",
       "6              600    ...            en          30000            30000   \n",
       "7              600    ...            en          30000            30000   \n",
       "9              600    ...            en          30000            30000   \n",
       "8              600    ...            en          30000            30000   \n",
       "10             600    ...            en          30000            30000   \n",
       "\n",
       "    src_max_sentence_len  targ_max_sentence_len  model_name  \\\n",
       "0                     40                     40         NaN   \n",
       "1                     40                     40         NaN   \n",
       "2                     40                     40         NaN   \n",
       "3                     40                     40         NaN   \n",
       "4                     40                     40         NaN   \n",
       "5                     40                     40         NaN   \n",
       "6                     40                     40         NaN   \n",
       "7                     10                     10         NaN   \n",
       "9                     10                     10  test_model   \n",
       "8                     10                     10  test_model   \n",
       "10                    10                     10  test_model   \n",
       "\n",
       "   teacher_forcing_ratio  lazy_train  clip_grad_max_norm  val_loss  \n",
       "0                    NaN         NaN                 NaN  5.433290  \n",
       "1                    NaN         NaN                 NaN  5.436468  \n",
       "2                    NaN         NaN                 NaN  7.335167  \n",
       "3                    NaN         NaN                 NaN  7.390460  \n",
       "4                    NaN         NaN                 NaN  7.484231  \n",
       "5                    NaN         NaN                 NaN  7.985807  \n",
       "6                    NaN         NaN                 NaN  8.088548  \n",
       "7                    NaN         NaN                 NaN  8.507013  \n",
       "9                    0.5        True                10.0  9.228798  \n",
       "8                    0.5        True                 NaN  9.330558  \n",
       "10                   0.5        True                10.0  9.337175  \n",
       "\n",
       "[11 rows x 26 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_results(load_experiment_log())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_single_learning_curve(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
