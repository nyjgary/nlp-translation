{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from data_processing import generate_vocab, process_data, create_dataloaders \n",
    "from model import get_pretrained_emb, EncoderDecoder, EncoderRNN, DecoderRNN, DecoderSimpleRNN, EncoderSimpleRNN, \\\n",
    "    Attention, DecoderAttnRNN, DecoderRNNV2\n",
    "from train_eval import count_parameters, summarize_results, \\\n",
    "    plot_single_learning_curve, load_experiment_log\n",
    "from train_eval import train_and_eval \n",
    "import importlib\n",
    "import pickle as pkl \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model identification\n",
    "MODEL_NAME = 'zh-seq2seq-rnn-attention'\n",
    "SRC_LANG = 'zh'\n",
    "TARG_LANG = 'en'\n",
    "\n",
    "# data processing params  \n",
    "SRC_MAX_SENTENCE_LEN = 10\n",
    "TARG_MAX_SENTENCE_LEN = 10\n",
    "SRC_VOCAB_SIZE = 30000 #30000\n",
    "TARG_VOCAB_SIZE = 30000 #30000\n",
    "\n",
    "# model architecture params \n",
    "NUM_LAYERS = 2 #2 \n",
    "ENC_HIDDEN_DIM = 300 \n",
    "DEC_HIDDEN_DIM = ENC_HIDDEN_DIM #2 * ENC_HIDDEN_DIM \n",
    "TEACHER_FORCING_RATIO = 1\n",
    "CLIP_GRAD_MAX_NORM = 1\n",
    "ENC_DROPOUT = 0 # to actually implement\n",
    "DEC_DROPOUT = 0 # to actually implement\n",
    "\n",
    "# training params  \n",
    "BATCH_SIZE = 16 #32\n",
    "NUM_EPOCHS = 200\n",
    "LR = 0.0005 # 0.0005\n",
    "OPTIMIZER = 'Adam'\n",
    "LAZY_TRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store as dict to save to results later \n",
    "params = {'model_name': MODEL_NAME, 'src_lang': SRC_LANG, 'targ_lang': TARG_LANG, \n",
    "          'src_max_sentence_len': SRC_MAX_SENTENCE_LEN, 'targ_max_sentence_len': TARG_MAX_SENTENCE_LEN, \n",
    "          'src_vocab_size': SRC_VOCAB_SIZE, 'targ_vocab_size': TARG_VOCAB_SIZE, \n",
    "          'num_layers': NUM_LAYERS, 'enc_hidden_dim': ENC_HIDDEN_DIM, 'dec_hidden_dim': DEC_HIDDEN_DIM,\n",
    "          'teacher_forcing_ratio': TEACHER_FORCING_RATIO, 'clip_grad_max_norm': CLIP_GRAD_MAX_NORM,\n",
    "          'enc_dropout': ENC_DROPOUT, 'dec_dropout': DEC_DROPOUT, \n",
    "          'batch_size': BATCH_SIZE, 'num_epochs': NUM_EPOCHS, 'learning_rate': LR, 'optimizer': OPTIMIZER, \n",
    "          'lazy_train': LAZY_TRAIN} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab_test = generate_vocab(SRC_LANG, TARG_LANG, SRC_VOCAB_SIZE, TARG_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab['zh']['id2token'][987]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab['zh']['token2id']['森林']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab['en']['token2id']['activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab['en']['id2token'][987]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # takes a long time to process, save to pickle for reimport in future \n",
    "# vocab = generate_vocab(SRC_LANG, TARG_LANG, SRC_VOCAB_SIZE, TARG_VOCAB_SIZE)\n",
    "# vocab_filename = \"{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n",
    "# pkl.dump(vocab, open(vocab_filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload from pickle \n",
    "vocab_filename = \"{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n",
    "vocab = pkl.load(open(vocab_filename, \"rb\"))\n",
    "data = process_data(SRC_LANG, TARG_LANG, vocab)\n",
    "data_minibatch = process_data(SRC_LANG, TARG_LANG, vocab, sample_limit=BATCH_SIZE) \n",
    "data_minitrain = process_data(SRC_LANG, TARG_LANG, vocab, sample_limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # takes a long time to process, save to pickle for reimport in future \n",
    "# vocab = generate_vocab(SRC_LANG, TARG_LANG, SRC_VOCAB_SIZE, TARG_VOCAB_SIZE)\n",
    "# vocab_filename = \"{}-{}-vocab-fake.p\".format(SRC_LANG, TARG_LANG)\n",
    "# pkl.dump(vocab, open(vocab_filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_filename = \"{}-{}-vocab-fake.p\".format(SRC_LANG, TARG_LANG)\n",
    "# vocab = pkl.load(open(vocab_filename, \"rb\"))\n",
    "# data = process_data(SRC_LANG, TARG_LANG, vocab)\n",
    "# limited_data = process_data(SRC_LANG, TARG_LANG, vocab, sample_limit=BATCH_SIZE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders \n",
    "loaders_full = create_dataloaders(data, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)\n",
    "loaders_minibatch = create_dataloaders(data_minibatch, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)\n",
    "loaders_minitrain = create_dataloaders(data_minitrain, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model \n",
    "\n",
    "# encoder = EncoderRNN(enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, src_max_sentence_len=SRC_MAX_SENTENCE_LEN,\n",
    "#                      pretrained_word2vec=get_pretrained_emb(vocab[SRC_LANG]['word2vec'], vocab[SRC_LANG]['token2id']))\n",
    "encoder = EncoderSimpleRNN(enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, src_max_sentence_len=SRC_MAX_SENTENCE_LEN,\n",
    "                           pretrained_word2vec=get_pretrained_emb(vocab[SRC_LANG]['word2vec'], vocab[SRC_LANG]['token2id']))\n",
    "\n",
    "# decoder = DecoderRNNV2(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, \n",
    "#                        targ_vocab_size=TARG_VOCAB_SIZE, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "#                        pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "# decoder = DecoderSimpleRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, \n",
    "#                            targ_vocab_size=TARG_VOCAB_SIZE, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "#                            pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "decoder = DecoderAttnRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, \n",
    "                         targ_vocab_size=TARG_VOCAB_SIZE, src_max_sentence_len=SRC_MAX_SENTENCE_LEN, \n",
    "                         targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "                         pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "\n",
    "model = EncoderDecoder(encoder, decoder, vocab[TARG_LANG]['token2id']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.00, Train Loss: 10.04, Val Loss: 10.23, Train BLEU: 0.36, Val BLEU: 0.22\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分 部分 的 动物 也 都 生活 在 海洋\n",
      "Reference: most of the animals are in the oceans .\n",
      "Model: <SOS> the the the the the the the the the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 都 知道 自己 正 冒 着 生命 的 危险\n",
      "Reference: we all knew we were risking our lives --\n",
      "Model: <SOS> the the the the the the the the the\n",
      "\n",
      "Epoch: 1.00, Train Loss: 9.76, Val Loss: 10.18, Train BLEU: 0.41, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地 地球 上 最长 的 山脉 都 在 海洋\n",
      "Reference: and in the oceans , there are the longest\n",
      "Model: <SOS> the the the the the the the the the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 这 是 我们 俩 人 唯一 的 受教 教育 方式\n",
      "Reference: it was the only way we both could be\n",
      "Model: <SOS> the the the the the the the the the\n",
      "\n",
      "Epoch: 2.00, Train Loss: 9.44, Val Loss: 10.11, Train BLEU: 0.42, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 通过 潜水 潜水艇 拍下 的 影片 把 我们\n",
      "Reference: with vibrant video clips captured by submarines , david\n",
      "Model: <SOS> the the the the the the the the the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 都 知道 自己 正 冒 着 生命 的 危险\n",
      "Reference: we all knew we were risking our lives --\n",
      "Model: <SOS> the the the the the the the the the\n",
      "\n",
      "Epoch: 3.00, Train Loss: 9.09, Val Loss: 10.01, Train BLEU: 0.41, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中 的 生命 大卫 <UNK> <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: life in the deep oceans <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> the the the the <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天 要 走 不同 的 路线 这样 才 没有\n",
      "Reference: each day , we took a different route so\n",
      "Model: <SOS> the the the the the the the the the\n",
      "\n",
      "Epoch: 4.00, Train Loss: 8.71, Val Loss: 9.91, Train BLEU: 0.40, Val BLEU: 0.24\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地 地球 上 最长 的 山脉 都 在 海洋\n",
      "Reference: and in the oceans , there are the longest\n",
      "Model: <SOS> the the the the the the the the the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正 的 学校 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: a real school . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> the the the the the <EOS> <EOS> <EOS> <EOS>\n",
      "\n",
      "Epoch: 5.00, Train Loss: 8.31, Val Loss: 9.80, Train BLEU: 0.39, Val BLEU: 0.23\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 这位 是 比尔 <UNK> 我 是 大卫 <UNK>\n",
      "Reference: this is bill lange . i &apos;m dave gallo\n",
      "Model: <SOS> the the the the the the the the the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很 舒服 但 夏天 却 <UNK> <EOS> <PAD> <PAD>\n",
      "Reference: it was cozy in winter but extremely hot in\n",
      "Model: <SOS> the the the the the the the the <EOS>\n",
      "\n",
      "Epoch: 6.00, Train Loss: 7.91, Val Loss: 9.69, Train BLEU: 0.37, Val BLEU: 0.23\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 通过 潜水 潜水艇 拍下 的 影片 把 我们\n",
      "Reference: with vibrant video clips captured by submarines , david\n",
      "Model: <SOS> the the the the the the the the the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11 岁 那年 记得 得有 一天 早晨 醒来 听见\n",
      "Reference: when i was 11 , i remember waking up\n",
      "Model: <SOS> the the the the the the the the the\n",
      "\n",
      "Epoch: 7.00, Train Loss: 7.50, Val Loss: 9.60, Train BLEU: 0.37, Val BLEU: 0.22\n",
      "Sampling from training predictions...\n",
      "Source: 地球 的 大部 大部分 部分 都 是 海水 <EOS> <PAD>\n",
      "Reference: most of the planet is ocean water . <EOS>\n",
      "Model: <SOS> the the the the the the the the the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 都 知道 自己 正 冒 着 生命 的 危险\n",
      "Reference: we all knew we were risking our lives --\n",
      "Model: <SOS> the the the the the the the the the\n",
      "\n",
      "Epoch: 8.00, Train Loss: 7.11, Val Loss: 9.53, Train BLEU: 0.36, Val BLEU: 0.22\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地 地球 上 最长 的 山脉 都 在 海洋\n",
      "Reference: and in the oceans , there are the longest\n",
      "Model: <SOS> the the the the the the the the the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天 要 走 不同 的 路线 这样 才 没有\n",
      "Reference: each day , we took a different route so\n",
      "Model: <SOS> the the the the the the the the the\n",
      "\n",
      "Epoch: 9.00, Train Loss: 6.75, Val Loss: 9.50, Train BLEU: 0.36, Val BLEU: 0.22\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地 地球 上 最长 的 山脉 都 在 海洋\n",
      "Reference: and in the oceans , there are the longest\n",
      "Model: <SOS> the the the the the the the the the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 父亲 在 用 他 的 灰色 小 收音\n",
      "Reference: my father was listening to bbc news on his\n",
      "Model: <SOS> the the the the the the the the the\n",
      "\n",
      "Epoch: 10.00, Train Loss: 6.40, Val Loss: 9.49, Train BLEU: 0.36, Val BLEU: 0.22\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数 多数 地震 和 火山 喷发 也 都 发生\n",
      "Reference: most of the earthquakes and volcanoes are in the\n",
      "Model: <SOS> the the the the the the the the the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在 可以 去 个 真正 的 学校 念书 了\n",
      "Reference: &quot; you can go to a real school now\n",
      "Model: <SOS> the the the the the the the the the\n",
      "\n",
      "Epoch: 11.00, Train Loss: 6.06, Val Loss: 9.47, Train BLEU: 0.36, Val BLEU: 0.22\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地 地球 上 最长 的 山脉 都 在 海洋\n",
      "Reference: and in the oceans , there are the longest\n",
      "Model: <SOS> the the the the the the the the the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 所以 在 那 之后 5 年 我 <UNK> <UNK> 陪\n",
      "Reference: so for the next five years , i dressed\n",
      "Model: <SOS> the the the the the the the the the\n",
      "\n",
      "Epoch: 12.00, Train Loss: 5.72, Val Loss: 9.42, Train BLEU: 0.36, Val BLEU: 0.22\n",
      "Sampling from training predictions...\n",
      "Source: 当 你 站 在 海滩 上 或是 当 你 看到\n",
      "Reference: part of the problem , i think , is\n",
      "Model: <SOS> the the the the the the the the the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 面带 <UNK> <UNK> 笑容 这 很少 少见 因为 大部\n",
      "Reference: there was a big smile on his face which\n",
      "Model: <SOS> the the the the the the the the the\n",
      "\n",
      "Epoch: 13.00, Train Loss: 5.39, Val Loss: 9.36, Train BLEU: 0.36, Val BLEU: 0.22\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数 多数 地震 和 火山 喷发 也 都 发生\n",
      "Reference: most of the earthquakes and volcanoes are in the\n",
      "Model: <SOS> the the the the the the the the the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11 岁 那年 记得 得有 一天 早晨 醒来 听见\n",
      "Reference: when i was 11 , i remember waking up\n",
      "Model: <SOS> the the the the the the the the the\n",
      "\n",
      "Epoch: 14.00, Train Loss: 5.07, Val Loss: 9.30, Train BLEU: 0.36, Val BLEU: 0.22\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想 海洋 占 了 地球 球面 面积 的 75\n",
      "Reference: when you think about it , the oceans are\n",
      "Model: <SOS> the the the the the the the the the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在 一个 房屋 房屋里 屋里 我们 100 多 人\n",
      "Reference: the school was in a house , more than\n",
      "Model: <SOS> the the the the the the the the the\n",
      "\n",
      "Epoch: 15.00, Train Loss: 4.80, Val Loss: 9.26, Train BLEU: 0.36, Val BLEU: 0.22\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本 基本上 都 没有 被 开发 发过 但是 像\n",
      "Reference: it &apos;s mostly unexplored , and yet there are\n",
      "Model: <SOS> the the the the the the the the the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在 一个 房屋 房屋里 屋里 我们 100 多 人\n",
      "Reference: the school was in a house , more than\n",
      "Model: <SOS> the the the the the the the the the\n",
      "\n",
      "Epoch: 16.00, Train Loss: 4.55, Val Loss: 9.25, Train BLEU: 0.38, Val BLEU: 0.23\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克 泰坦尼克号 坦尼 尼克 号 是 拿 了 不少\n",
      "Reference: the truth of the matter is that the titanic\n",
      "Model: <SOS> most the the the the the the the the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 不知 知道 那 意味 意味着 什么 但是 我 能\n",
      "Reference: i didn &apos;t know what it meant , but\n",
      "Model: <SOS> most the the the the the the the the\n",
      "\n",
      "Epoch: 17.00, Train Loss: 4.33, Val Loss: 9.29, Train BLEU: 0.39, Val BLEU: 0.23\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这 有 不少 精彩 的 泰坦 泰坦尼克 坦尼 尼克\n",
      "Reference: we &apos;ve got some of the most incredible video\n",
      "Model: <SOS> most the the the the the the the the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 永远 不会 忘记 那个 早晨 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: a morning that i will never forget . <EOS>\n",
      "Model: <SOS> most the the the the the the <EOS> <EOS>\n",
      "\n",
      "Epoch: 18.00, Train Loss: 4.13, Val Loss: 9.37, Train BLEU: 0.48, Val BLEU: 0.23\n",
      "Sampling from training predictions...\n",
      "Source: 我们 将 用 一些 影片 来讲 讲述 一些 深海 海里\n",
      "Reference: and we &apos;re going to tell you some stories\n",
      "Model: <SOS> most the the the the the the the the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很 舒服 但 夏天 却 <UNK> <EOS> <PAD> <PAD>\n",
      "Reference: it was cozy in winter but extremely hot in\n",
      "Model: <SOS> most the the the the the the <EOS> <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19.00, Train Loss: 3.96, Val Loss: 9.47, Train BLEU: 1.40, Val BLEU: 0.24\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分 部分 的 动物 也 都 生活 在 海洋\n",
      "Reference: most of the animals are in the oceans .\n",
      "Model: <SOS> most of the the the the the the the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很 舒服 但 夏天 却 <UNK> <EOS> <PAD> <PAD>\n",
      "Reference: it was cozy in winter but extremely hot in\n",
      "Model: <SOS> most the the the the the <EOS> <EOS> <EOS>\n",
      "\n",
      "Epoch: 20.00, Train Loss: 3.80, Val Loss: 9.60, Train BLEU: 1.49, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克 泰坦尼克号 坦尼 尼克 号 是 拿 了 不少\n",
      "Reference: the truth of the matter is that the titanic\n",
      "Model: <SOS> most the the the the the the the the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天 要 走 不同 的 路线 这样 才 没有\n",
      "Reference: each day , we took a different route so\n",
      "Model: <SOS> most of the the the the the the the\n",
      "\n",
      "Epoch: 21.00, Train Loss: 3.68, Val Loss: 9.75, Train BLEU: 1.10, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 地球 的 大部 大部分 部分 都 是 海水 <EOS> <PAD>\n",
      "Reference: most of the planet is ocean water . <EOS>\n",
      "Model: <SOS> most the the the the the . <EOS> <EOS>\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 都 知道 自己 正 冒 着 生命 的 危险\n",
      "Reference: we all knew we were risking our lives --\n",
      "Model: <SOS> and of the the the the the the the\n",
      "\n",
      "Epoch: 22.00, Train Loss: 3.57, Val Loss: 9.90, Train BLEU: 0.61, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数 多数 地震 和 火山 喷发 也 都 发生\n",
      "Reference: most of the earthquakes and volcanoes are in the\n",
      "Model: <SOS> most the the the the the the the the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班 走 了 父亲 大声 叫 着 <EOS> <PAD>\n",
      "Reference: &quot; the taliban are gone ! &quot; my father\n",
      "Model: <SOS> most the the the the . . <EOS> <EOS>\n",
      "\n",
      "Epoch: 23.00, Train Loss: 3.48, Val Loss: 10.05, Train BLEU: 0.52, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克 泰坦尼克号 坦尼 尼克 号 是 拿 了 不少\n",
      "Reference: the truth of the matter is that the titanic\n",
      "Model: <SOS> most the the the the the the the the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6 岁 那年 塔利 塔利班 占领 阿富汗 并 规定\n",
      "Reference: you see , i was six when the taliban\n",
      "Model: <SOS> most the the the the the the the the\n",
      "\n",
      "Epoch: 24.00, Train Loss: 3.41, Val Loss: 10.22, Train BLEU: 0.56, Val BLEU: 0.24\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数 多数 地震 和 火山 喷发 也 都 发生\n",
      "Reference: most of the earthquakes and volcanoes are in the\n",
      "Model: <SOS> most the the the the the the the the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11 岁 那年 记得 得有 一天 早晨 醒来 听见\n",
      "Reference: when i was 11 , i remember waking up\n",
      "Model: <SOS> most the the the the the the the the\n",
      "\n",
      "Epoch: 25.00, Train Loss: 3.35, Val Loss: 10.38, Train BLEU: 0.60, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 原因 在于 我们 一直 没 把 海洋 当回事 回事 回事儿\n",
      "Reference: and the problem , i think , is that\n",
      "Model: <SOS> and the the the the , , , ,\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6 岁 那年 塔利 塔利班 占领 阿富汗 并 规定\n",
      "Reference: you see , i was six when the taliban\n",
      "Model: <SOS> most the the the the the the , ,\n",
      "\n",
      "Epoch: 26.00, Train Loss: 3.29, Val Loss: 10.54, Train BLEU: 0.60, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的 平均 深度 是 两英里 英里 <EOS> <PAD> <PAD>\n",
      "Reference: the average depth is about two miles . <EOS>\n",
      "Model: <SOS> the the the is <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把 书 放在 食品 杂货 袋中 这样 别人 就\n",
      "Reference: we would cover our books in grocery bags so\n",
      "Model: <SOS> most the the the the the , , ,\n",
      "\n",
      "Epoch: 27.00, Train Loss: 3.25, Val Loss: 10.70, Train BLEU: 0.60, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里 生物 的 多样 多样性 和 密度 要 比\n",
      "Reference: the biodiversity and the <UNK> in the ocean is\n",
      "Model: <SOS> most the the the the the , , ,\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 永远 不会 忘记 那个 早晨 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: a morning that i will never forget . <EOS>\n",
      "Model: <SOS> the the the <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "\n",
      "Epoch: 28.00, Train Loss: 3.21, Val Loss: 10.85, Train BLEU: 0.62, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 通过 潜水 潜水艇 拍下 的 影片 把 我们\n",
      "Reference: with vibrant video clips captured by submarines , david\n",
      "Model: <SOS> most the the the the the , , ,\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 永远 不会 忘记 那个 早晨 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: a morning that i will never forget . <EOS>\n",
      "Model: <SOS> the the the is <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "\n",
      "Epoch: 29.00, Train Loss: 3.17, Val Loss: 10.99, Train BLEU: 0.70, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地 地球 上 最长 的 山脉 都 在 海洋\n",
      "Reference: and in the oceans , there are the longest\n",
      "Model: <SOS> and the the the the the , , ,\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 父亲 在 用 他 的 灰色 小 收音\n",
      "Reference: my father was listening to bbc news on his\n",
      "Model: <SOS> and the the the the the , , ,\n",
      "\n",
      "Epoch: 30.00, Train Loss: 3.13, Val Loss: 11.12, Train BLEU: 0.71, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 这位 是 比尔 <UNK> 我 是 大卫 <UNK>\n",
      "Reference: this is bill lange . i &apos;m dave gallo\n",
      "Model: <SOS> this of the the , , , , ,\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把 书 放在 食品 杂货 袋中 这样 别人 就\n",
      "Reference: we would cover our books in grocery bags so\n",
      "Model: <SOS> and the the the the the , , ,\n",
      "\n",
      "Epoch: 31.00, Train Loss: 3.10, Val Loss: 11.24, Train BLEU: 0.82, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地 地球 上 最长 的 山脉 都 在 海洋\n",
      "Reference: and in the oceans , there are the longest\n",
      "Model: <SOS> and of the the the the , , ,\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 所以 在 那 之后 5 年 我 <UNK> <UNK> 陪\n",
      "Reference: so for the next five years , i dressed\n",
      "Model: <SOS> and of the the the the , , ,\n",
      "\n",
      "Epoch: 32.00, Train Loss: 3.06, Val Loss: 11.34, Train BLEU: 1.01, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 通过 潜水 潜水艇 拍下 的 影片 把 我们\n",
      "Reference: with vibrant video clips captured by submarines , david\n",
      "Model: <SOS> and of the the the the , , ,\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6 岁 那年 塔利 塔利班 占领 阿富汗 并 规定\n",
      "Reference: you see , i was six when the taliban\n",
      "Model: <SOS> and of the the the the , , ,\n",
      "\n",
      "Epoch: 33.00, Train Loss: 3.03, Val Loss: 11.44, Train BLEU: 1.04, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 这位 是 比尔 <UNK> 我 是 大卫 <UNK>\n",
      "Reference: this is bill lange . i &apos;m dave gallo\n",
      "Model: <SOS> this of the is , , , is is\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 所以 在 那 之后 5 年 我 <UNK> <UNK> 陪\n",
      "Reference: so for the next five years , i dressed\n",
      "Model: <SOS> and of the the the the , , ,\n",
      "\n",
      "Epoch: 34.00, Train Loss: 3.00, Val Loss: 11.53, Train BLEU: 1.42, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这 有 不少 精彩 的 泰坦 泰坦尼克 坦尼 尼克\n",
      "Reference: we &apos;ve got some of the most incredible video\n",
      "Model: <SOS> and of the the the the the , ,\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 永远 不会 忘记 那个 早晨 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: a morning that i will never forget . <EOS>\n",
      "Model: <SOS> the the the the <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "\n",
      "Epoch: 35.00, Train Loss: 2.96, Val Loss: 11.60, Train BLEU: 1.74, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 通过 潜水 潜水艇 拍下 的 影片 把 我们\n",
      "Reference: with vibrant video clips captured by submarines , david\n",
      "Model: <SOS> and of the the the the , , ,\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在 一个 房屋 房屋里 屋里 我们 100 多 人\n",
      "Reference: the school was in a house , more than\n",
      "Model: <SOS> and of the the the the the , ,\n",
      "\n",
      "Epoch: 36.00, Train Loss: 2.93, Val Loss: 11.68, Train BLEU: 1.88, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想 海洋 占 了 地球 球面 面积 的 75\n",
      "Reference: when you think about it , the oceans are\n",
      "Model: <SOS> when of the the , , , , ,\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在 可以 去 个 真正 的 学校 念书 了\n",
      "Reference: &quot; you can go to a real school now\n",
      "Model: <SOS> most of the the the the the , ,\n",
      "\n",
      "Epoch: 37.00, Train Loss: 2.90, Val Loss: 11.74, Train BLEU: 1.88, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的 平均 深度 是 两英里 英里 <EOS> <PAD> <PAD>\n",
      "Reference: the average depth is about two miles . <EOS>\n",
      "Model: <SOS> the the the the is <EOS> <EOS> <EOS> <EOS>\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11 岁 那年 记得 得有 一天 早晨 醒来 听见\n",
      "Reference: when i was 11 , i remember waking up\n",
      "Model: <SOS> most of the the the the the , ,\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38.00, Train Loss: 2.87, Val Loss: 11.79, Train BLEU: 1.97, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想 海洋 占 了 地球 球面 面积 的 75\n",
      "Reference: when you think about it , the oceans are\n",
      "Model: <SOS> when the the , , , , , ,\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把 书 放在 食品 杂货 袋中 这样 别人 就\n",
      "Reference: we would cover our books in grocery bags so\n",
      "Model: <SOS> most of the the the the the the are\n",
      "\n",
      "Epoch: 39.00, Train Loss: 2.84, Val Loss: 11.85, Train BLEU: 1.95, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 地球 的 大部 大部分 部分 都 是 海水 <EOS> <PAD>\n",
      "Reference: most of the planet is ocean water . <EOS>\n",
      "Model: <SOS> most the the the is . . . <EOS>\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正 的 学校 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: a real school . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> the the the deep <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "\n",
      "Epoch: 40.00, Train Loss: 2.81, Val Loss: 11.91, Train BLEU: 1.96, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克 泰坦尼克号 坦尼 尼克 号 是 拿 了 不少\n",
      "Reference: the truth of the matter is that the titanic\n",
      "Model: <SOS> most of the the the the the the are\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在 可以 去 个 真正 的 学校 念书 了\n",
      "Reference: &quot; you can go to a real school now\n",
      "Model: <SOS> most of the the the the the the are\n",
      "\n",
      "Epoch: 41.00, Train Loss: 2.78, Val Loss: 11.96, Train BLEU: 1.96, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本 基本上 都 没有 被 开发 发过 但是 像\n",
      "Reference: it &apos;s mostly unexplored , and yet there are\n",
      "Model: <SOS> most of the the the the the the are\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天 要 走 不同 的 路线 这样 才 没有\n",
      "Reference: each day , we took a different route so\n",
      "Model: <SOS> most of the the the the the the are\n",
      "\n",
      "Epoch: 42.00, Train Loss: 2.75, Val Loss: 12.01, Train BLEU: 2.47, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 原因 在于 我们 一直 没 把 海洋 当回事 回事 回事儿\n",
      "Reference: and the problem , i think , is that\n",
      "Model: <SOS> and the , , , , , , ,\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天 要 走 不同 的 路线 这样 才 没有\n",
      "Reference: each day , we took a different route so\n",
      "Model: <SOS> most of the the the the the the are\n",
      "\n",
      "Epoch: 43.00, Train Loss: 2.72, Val Loss: 12.06, Train BLEU: 2.45, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里 生物 的 多样 多样性 和 密度 要 比\n",
      "Reference: the biodiversity and the <UNK> in the ocean is\n",
      "Model: <SOS> most of the the the the the the are\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 永远 不会 忘记 那个 早晨 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: a morning that i will never forget . <EOS>\n",
      "Model: <SOS> the the the deep is <EOS> <EOS> <EOS> <EOS>\n",
      "\n",
      "Epoch: 44.00, Train Loss: 2.69, Val Loss: 12.11, Train BLEU: 2.45, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数 多数 地震 和 火山 喷发 也 都 发生\n",
      "Reference: most of the earthquakes and volcanoes are in the\n",
      "Model: <SOS> most of the the the the the the are\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 面带 <UNK> <UNK> 笑容 这 很少 少见 因为 大部\n",
      "Reference: there was a big smile on his face which\n",
      "Model: <SOS> and of the the the the are are are\n",
      "\n",
      "Epoch: 45.00, Train Loss: 2.66, Val Loss: 12.16, Train BLEU: 2.67, Val BLEU: 0.26\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想 海洋 占 了 地球 球面 面积 的 75\n",
      "Reference: when you think about it , the oceans are\n",
      "Model: <SOS> when the the , , , , , ,\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天 要 走 不同 的 路线 这样 才 没有\n",
      "Reference: each day , we took a different route so\n",
      "Model: <SOS> most of the the the the the the are\n",
      "\n",
      "Epoch: 46.00, Train Loss: 2.63, Val Loss: 12.21, Train BLEU: 2.69, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克 泰坦尼克号 坦尼 尼克 号 是 拿 了 不少\n",
      "Reference: the truth of the matter is that the titanic\n",
      "Model: <SOS> the of the the the the the the are\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6 岁 那年 塔利 塔利班 占领 阿富汗 并 规定\n",
      "Reference: you see , i was six when the taliban\n",
      "Model: <SOS> most of the the the the the are are\n",
      "\n",
      "Epoch: 47.00, Train Loss: 2.60, Val Loss: 12.24, Train BLEU: 2.78, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分 部分 的 动物 也 都 生活 在 海洋\n",
      "Reference: most of the animals are in the oceans .\n",
      "Model: <SOS> most of the the the the the are are\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 这 是 我们 俩 人 唯一 的 受教 教育 方式\n",
      "Reference: it was the only way we both could be\n",
      "Model: <SOS> most of the the the the the are are\n",
      "\n",
      "Epoch: 48.00, Train Loss: 2.57, Val Loss: 12.27, Train BLEU: 4.63, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 地球 的 大部 大部分 部分 都 是 海水 <EOS> <PAD>\n",
      "Reference: most of the planet is ocean water . <EOS>\n",
      "Model: <SOS> most of the the is . . . <EOS>\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 这 是 我们 俩 人 唯一 的 受教 教育 方式\n",
      "Reference: it was the only way we both could be\n",
      "Model: <SOS> most of the the the the the the are\n",
      "\n",
      "Epoch: 49.00, Train Loss: 2.54, Val Loss: 12.30, Train BLEU: 4.66, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 这位 是 比尔 <UNK> 我 是 大卫 <UNK>\n",
      "Reference: this is bill lange . i &apos;m dave gallo\n",
      "Model: <SOS> this is bill is is is is is i\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 都 知道 自己 正 冒 着 生命 的 危险\n",
      "Reference: we all knew we were risking our lives --\n",
      "Model: <SOS> most of the the the the the the are\n",
      "\n",
      "Epoch: 50.00, Train Loss: 2.50, Val Loss: 12.32, Train BLEU: 5.94, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中 的 生命 大卫 <UNK> <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: life in the deep oceans <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> life in in deep <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天 要 走 不同 的 路线 这样 才 没有\n",
      "Reference: each day , we took a different route so\n",
      "Model: <SOS> most of the the the the the are are\n",
      "\n",
      "Epoch: 51.00, Train Loss: 2.47, Val Loss: 12.34, Train BLEU: 8.09, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 通过 潜水 潜水艇 拍下 的 影片 把 我们\n",
      "Reference: with vibrant video clips captured by submarines , david\n",
      "Model: <SOS> with of the the , , , are are\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6 岁 那年 塔利 塔利班 占领 阿富汗 并 规定\n",
      "Reference: you see , i was six when the taliban\n",
      "Model: <SOS> most of the the the the the are are\n",
      "\n",
      "Epoch: 52.00, Train Loss: 2.44, Val Loss: 12.37, Train BLEU: 8.10, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 我们 将 用 一些 影片 来讲 讲述 一些 深海 海里\n",
      "Reference: and we &apos;re going to tell you some stories\n",
      "Model: <SOS> most of the the the the the the are\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班 走 了 父亲 大声 叫 着 <EOS> <PAD>\n",
      "Reference: &quot; the taliban are gone ! &quot; my father\n",
      "Model: <SOS> most of the the is is . . <EOS>\n",
      "\n",
      "Epoch: 53.00, Train Loss: 2.41, Val Loss: 12.40, Train BLEU: 8.07, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分 部分 的 动物 也 都 生活 在 海洋\n",
      "Reference: most of the animals are in the oceans .\n",
      "Model: <SOS> most of the the the the the the are\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正 的 学校 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: a real school . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> the average depth is is <EOS> <EOS> <EOS> <EOS>\n",
      "\n",
      "Epoch: 54.00, Train Loss: 2.38, Val Loss: 12.42, Train BLEU: 8.40, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 当 你 站 在 海滩 上 或是 当 你 看到\n",
      "Reference: part of the problem , i think , is\n",
      "Model: <SOS> most of the the the the the the the\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很 舒服 但 夏天 却 <UNK> <EOS> <PAD> <PAD>\n",
      "Reference: it was cozy in winter but extremely hot in\n",
      "Model: <SOS> the in the deep oceans <EOS> <EOS> <EOS> <EOS>\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2a79c913e327>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders_full\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloaders_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders_minibatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloaders_minibatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders_minitrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloaders_minitrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_intermediate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_to_log\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     lazy_eval=False, inspect_samples=1)\n\u001b[0m",
      "\u001b[0;32m~/Documents/data-science-coursework/nyu-nlp/project/train_eval.py\u001b[0m in \u001b[0;36mtrain_and_eval\u001b[0;34m(model, loaders_full, loaders_minibatch, loaders_minitrain, params, vocab, lazy_eval, print_intermediate, save_checkpoint, save_to_log, inspect_samples)\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0;31m# calculate metrics on train set (or proxy thereof) only if lazy_eval not set to True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlazy_eval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m                     \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_bleu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_hyp_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ref_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_source_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_hyp_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ref_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_source_tokens\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m                             \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader_proxy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_id2token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg_id2token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/data-science-coursework/nyu-nlp/project/train_eval.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, loader, src_id2token, targ_id2token, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc_idxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         outputs, hypotheses = model(src_idxs, targ_idxs, src_lens, targ_lens, \n\u001b[0;32m--> 105\u001b[0;31m                                     teacher_forcing_ratio=teacher_forcing_ratio)\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarg_idxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/nlpclass/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/data-science-coursework/nyu-nlp/project/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src_idx, targ_idx, src_lens, targ_lens, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0msrc_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc_lens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg_lens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0menc_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                 \u001b[0mdec_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdec_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarg_max_sentence_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarg_vocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/nlpclass/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/data-science-coursework/nyu-nlp/project/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, enc_input, enc_input_lens)\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_input_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitHidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                 \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \t\toutput, _ = torch.nn.utils.rnn.pad_packed_sequence(output, batch_first=True, \n\u001b[1;32m    133\u001b[0m                                                                                                                    \u001b[0mtotal_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_max_sentence_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/nlpclass/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/nlpclass/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/nlpclass/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/nlpclass/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/nlpclass/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/nlpclass/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mflat_hidden\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/nlpclass/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mGRUCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mgi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mgh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_hh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mi_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mh_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/nlpclass/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, results = train_and_eval(\n",
    "    model=model, loaders_full=loaders_full, loaders_minibatch=loaders_minibatch, loaders_minitrain=loaders_minitrain, \n",
    "    params=params, vocab=vocab, print_intermediate=True, save_checkpoint=True, save_to_log=True, \n",
    "    lazy_eval=False, inspect_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_results(load_experiment_log())[['dt_created', 'num_epochs', 'learning_rate', 'clip_grad_max_norm', 'val_loss']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_learning_curve(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, token in enumerate(vocab[SRC_LANG]['id2token']): \n",
    "    if i < 20: \n",
    "        print(\"{}: {}\".format(i, token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, token in enumerate(vocab[TARG_LANG]['id2token']): \n",
    "    if i < 20: \n",
    "        print(\"{}: {}\".format(i, token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.arange(0, 3*5*10).view(3, 5, 10)\n",
    "print(x)\n",
    "y = x[1:, :, :]\n",
    "print(y)\n",
    "z = y.view(-1, 10)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.arange(0, 2*5).view(5, 2)\n",
    "print(t)\n",
    "u = t.contiguous().view(-1)\n",
    "print(u)\n",
    "v = t.permute(1, 0)\n",
    "print(v)\n",
    "w = v.contiguous().view(-1)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(0, 2*1*300)\n",
    "print(a)\n",
    "b = a.view(-1, 1, 300)\n",
    "print(b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (src_idxs, targ_idxs, src_lens, targ_lens) in enumerate(full_loaders['train']):\n",
    "#     print(i)\n",
    "#     print(src_idxs.size())\n",
    "#     print(src_idxs)\n",
    "#     print(src_lens)\n",
    "#     print(targ_idxs.size())\n",
    "#     print(targ_idxs)\n",
    "#     print(targ_lens)\n",
    "    id2token = vocab[SRC_LANG]['id2token']\n",
    "    test_tensor = src_idxs\n",
    "    list_of_lists = test_tensor.numpy().astype(int).tolist()\n",
    "    to_token = lambda l: ' '.join([id2token[idx] for idx in l])\n",
    "    list_of_lists_tokens = [to_token(l) for l in list_of_lists] \n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
