{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from data_processing import generate_vocab, process_data, create_dataloaders \n",
    "from model import get_pretrained_emb, EncoderDecoder, EncoderRNN, DecoderRNN, DecoderSimpleRNN, EncoderSimpleRNN, \\\n",
    "    Attention, DecoderAttnRNN, DecoderRNNV2, EncoderDecoderAttention, EncoderSimpleRNN_Test, DecoderAttnRNN_Test\n",
    "from train_eval import count_parameters, summarize_results, \\\n",
    "    plot_single_learning_curve, load_experiment_log\n",
    "from train_eval import train_and_eval, train_and_eval_attn \n",
    "import importlib\n",
    "import pickle as pkl \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model identification\n",
    "MODEL_NAME = 'zh-seq2seq-rnn-attention'\n",
    "SRC_LANG = 'zh'\n",
    "TARG_LANG = 'en'\n",
    "\n",
    "# data processing params  \n",
    "SRC_MAX_SENTENCE_LEN = 10\n",
    "TARG_MAX_SENTENCE_LEN = 10\n",
    "SRC_VOCAB_SIZE = 30000 #30000\n",
    "TARG_VOCAB_SIZE = 30000 #30000\n",
    "\n",
    "# model architecture params \n",
    "RNN_CELL_TYPE = 'gru'\n",
    "NUM_LAYERS = 2 #2 \n",
    "ENC_HIDDEN_DIM = 256 #512\n",
    "DEC_HIDDEN_DIM = 2 * ENC_HIDDEN_DIM #2 * ENC_HIDDEN_DIM \n",
    "TEACHER_FORCING_RATIO = 1\n",
    "CLIP_GRAD_MAX_NORM = 1\n",
    "ENC_DROPOUT = 0.2 # to actually implement\n",
    "DEC_DROPOUT = 0.2 # to actually implement\n",
    "\n",
    "# training params  \n",
    "BATCH_SIZE = 32 #32\n",
    "NUM_EPOCHS = 200\n",
    "LR = 0.0005 # 0.0005\n",
    "OPTIMIZER = 'Adam'\n",
    "LAZY_TRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store as dict to save to results later \n",
    "params = {'model_name': MODEL_NAME, 'src_lang': SRC_LANG, 'targ_lang': TARG_LANG, 'rnn_cell_type': RNN_CELL_TYPE, \n",
    "          'src_max_sentence_len': SRC_MAX_SENTENCE_LEN, 'targ_max_sentence_len': TARG_MAX_SENTENCE_LEN, \n",
    "          'src_vocab_size': SRC_VOCAB_SIZE, 'targ_vocab_size': TARG_VOCAB_SIZE, \n",
    "          'num_layers': NUM_LAYERS, 'enc_hidden_dim': ENC_HIDDEN_DIM, 'dec_hidden_dim': DEC_HIDDEN_DIM,\n",
    "          'teacher_forcing_ratio': TEACHER_FORCING_RATIO, 'clip_grad_max_norm': CLIP_GRAD_MAX_NORM,\n",
    "          'enc_dropout': ENC_DROPOUT, 'dec_dropout': DEC_DROPOUT, \n",
    "          'batch_size': BATCH_SIZE, 'num_epochs': NUM_EPOCHS, 'learning_rate': LR, 'optimizer': OPTIMIZER, \n",
    "          'lazy_train': LAZY_TRAIN} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab_test = generate_vocab(SRC_LANG, TARG_LANG, SRC_VOCAB_SIZE, TARG_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab['zh']['id2token'][987]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab['zh']['token2id']['森林']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab['en']['token2id']['activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab['en']['id2token'][987]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # takes a long time to process, save to pickle for reimport in future \n",
    "# vocab = generate_vocab(SRC_LANG, TARG_LANG, SRC_VOCAB_SIZE, TARG_VOCAB_SIZE)\n",
    "# vocab_filename = \"{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n",
    "# pkl.dump(vocab, open(vocab_filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload from pickle \n",
    "vocab_filename = \"{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n",
    "vocab = pkl.load(open(vocab_filename, \"rb\"))\n",
    "data = process_data(SRC_LANG, TARG_LANG, vocab)\n",
    "data_minibatch = process_data(SRC_LANG, TARG_LANG, vocab, sample_limit=BATCH_SIZE) \n",
    "data_minitrain = process_data(SRC_LANG, TARG_LANG, vocab, sample_limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # takes a long time to process, save to pickle for reimport in future \n",
    "# vocab = generate_vocab(SRC_LANG, TARG_LANG, SRC_VOCAB_SIZE, TARG_VOCAB_SIZE)\n",
    "# vocab_filename = \"{}-{}-vocab-fake.p\".format(SRC_LANG, TARG_LANG)\n",
    "# pkl.dump(vocab, open(vocab_filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_filename = \"{}-{}-vocab-fake.p\".format(SRC_LANG, TARG_LANG)\n",
    "# vocab = pkl.load(open(vocab_filename, \"rb\"))\n",
    "# data = process_data(SRC_LANG, TARG_LANG, vocab)\n",
    "# limited_data = process_data(SRC_LANG, TARG_LANG, vocab, sample_limit=BATCH_SIZE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders \n",
    "loaders_full = create_dataloaders(data, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)\n",
    "loaders_minibatch = create_dataloaders(data_minibatch, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)\n",
    "loaders_minitrain = create_dataloaders(data_minitrain, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model \n",
    "\n",
    "# encoder = EncoderRNN(enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, src_max_sentence_len=SRC_MAX_SENTENCE_LEN,\n",
    "#                      pretrained_word2vec=get_pretrained_emb(vocab[SRC_LANG]['word2vec'], vocab[SRC_LANG]['token2id']))\n",
    "# encoder = EncoderSimpleRNN(enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, src_max_sentence_len=SRC_MAX_SENTENCE_LEN,\n",
    "#                            pretrained_word2vec=get_pretrained_emb(vocab[SRC_LANG]['word2vec'], vocab[SRC_LANG]['token2id']))\n",
    "# encoder = EncoderSimpleRNN(enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, src_max_sentence_len=SRC_MAX_SENTENCE_LEN,\n",
    "#                            pretrained_word2vec=get_pretrained_emb(vocab[SRC_LANG]['word2vec'], vocab[SRC_LANG]['token2id']))\n",
    "encoder = EncoderSimpleRNN_Test(rnn_cell_type=RNN_CELL_TYPE, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, src_max_sentence_len=SRC_MAX_SENTENCE_LEN,\n",
    "                                enc_dropout=ENC_DROPOUT, pretrained_word2vec=get_pretrained_emb(vocab[SRC_LANG]['word2vec'], vocab[SRC_LANG]['token2id']))\n",
    "\n",
    "# decoder = DecoderRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS,\n",
    "#                       targ_vocab_size=TARG_VOCAB_SIZE, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "#                       pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "\n",
    "# decoder = DecoderRNNV2(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, \n",
    "#                        targ_vocab_size=TARG_VOCAB_SIZE, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "#                        pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "# decoder = DecoderSimpleRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, \n",
    "#                            targ_vocab_size=TARG_VOCAB_SIZE, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "#                            pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "# decoder = DecoderAttnRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, \n",
    "#                          targ_vocab_size=TARG_VOCAB_SIZE, src_max_sentence_len=SRC_MAX_SENTENCE_LEN, \n",
    "#                          targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "#                          pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "decoder = DecoderAttnRNN_Test(rnn_cell_type=RNN_CELL_TYPE, dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, \n",
    "                         targ_vocab_size=TARG_VOCAB_SIZE, src_max_sentence_len=SRC_MAX_SENTENCE_LEN, \n",
    "                         targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, dec_dropout=DEC_DROPOUT, \n",
    "                         pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "\n",
    "\n",
    "model = EncoderDecoderAttention(encoder, decoder, vocab[TARG_LANG]['token2id']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.00, Train Loss: 10.03, Val Loss: 10.20, Train BLEU: 3.69, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 这位 是 比尔 <UNK> 我 是 大卫 <UNK>\n",
      "Reference: this is bill lange . i &apos;m dave gallo\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.1047, 0.1023, 0.1051, 0.1015, 0.0921, 0.0978, 0.1031, 0.1021, 0.0990,\n",
      "         0.0923],\n",
      "        [0.1047, 0.1023, 0.1051, 0.1015, 0.0921, 0.0978, 0.1031, 0.1021, 0.0990,\n",
      "         0.0922],\n",
      "        [0.1047, 0.1023, 0.1052, 0.1016, 0.0921, 0.0978, 0.1031, 0.1021, 0.0990,\n",
      "         0.0922],\n",
      "        [0.1047, 0.1023, 0.1052, 0.1016, 0.0921, 0.0978, 0.1031, 0.1021, 0.0990,\n",
      "         0.0922],\n",
      "        [0.1048, 0.1023, 0.1052, 0.1016, 0.0921, 0.0978, 0.1031, 0.1021, 0.0990,\n",
      "         0.0922],\n",
      "        [0.1048, 0.1023, 0.1052, 0.1016, 0.0921, 0.0978, 0.1031, 0.1021, 0.0990,\n",
      "         0.0922],\n",
      "        [0.1048, 0.1024, 0.1052, 0.1015, 0.0921, 0.0978, 0.1031, 0.1020, 0.0990,\n",
      "         0.0922],\n",
      "        [0.1048, 0.1024, 0.1052, 0.1016, 0.0921, 0.0977, 0.1030, 0.1020, 0.0990,\n",
      "         0.0922],\n",
      "        [0.1048, 0.1024, 0.1052, 0.1016, 0.0921, 0.0977, 0.1030, 0.1020, 0.0990,\n",
      "         0.0923]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 很 害怕 但是 我们 仍然 渴望 望去 学校 <EOS>\n",
      "Reference: we were scared , but still , school was\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0984, 0.0999, 0.1020, 0.1034, 0.1037, 0.1053, 0.1026, 0.1005, 0.0958,\n",
      "         0.0885],\n",
      "        [0.0984, 0.0999, 0.1020, 0.1034, 0.1037, 0.1053, 0.1026, 0.1005, 0.0957,\n",
      "         0.0883],\n",
      "        [0.0983, 0.0999, 0.1020, 0.1034, 0.1037, 0.1054, 0.1027, 0.1005, 0.0957,\n",
      "         0.0883],\n",
      "        [0.0983, 0.0999, 0.1020, 0.1034, 0.1038, 0.1054, 0.1027, 0.1005, 0.0957,\n",
      "         0.0883],\n",
      "        [0.0983, 0.0999, 0.1020, 0.1034, 0.1037, 0.1054, 0.1027, 0.1005, 0.0957,\n",
      "         0.0883],\n",
      "        [0.0983, 0.0999, 0.1020, 0.1034, 0.1037, 0.1054, 0.1027, 0.1005, 0.0957,\n",
      "         0.0883],\n",
      "        [0.0983, 0.0999, 0.1020, 0.1034, 0.1037, 0.1054, 0.1027, 0.1006, 0.0957,\n",
      "         0.0883],\n",
      "        [0.0983, 0.0999, 0.1020, 0.1034, 0.1037, 0.1054, 0.1027, 0.1006, 0.0957,\n",
      "         0.0883],\n",
      "        [0.0983, 0.0999, 0.1020, 0.1034, 0.1037, 0.1054, 0.1027, 0.1006, 0.0957,\n",
      "         0.0883]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 1.00, Train Loss: 9.71, Val Loss: 10.07, Train BLEU: 0.26, Val BLEU: 0.17\n",
      "Sampling from training predictions...\n",
      "Source: <UNK> 塞尔 <UNK> <UNK> 斯特 说 过 真正 的 探索\n",
      "Reference: marcel proust said , &quot; the true voyage of\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0654, 0.0754, 0.0754, 0.0823, 0.1003, 0.1283, 0.1349, 0.1275, 0.1167,\n",
      "         0.0937],\n",
      "        [0.0651, 0.0753, 0.0753, 0.0823, 0.1003, 0.1285, 0.1351, 0.1277, 0.1168,\n",
      "         0.0936],\n",
      "        [0.0651, 0.0753, 0.0753, 0.0823, 0.1004, 0.1285, 0.1351, 0.1276, 0.1167,\n",
      "         0.0935],\n",
      "        [0.0652, 0.0754, 0.0754, 0.0824, 0.1003, 0.1285, 0.1351, 0.1276, 0.1167,\n",
      "         0.0936],\n",
      "        [0.0652, 0.0754, 0.0754, 0.0824, 0.1003, 0.1284, 0.1350, 0.1275, 0.1167,\n",
      "         0.0936],\n",
      "        [0.0653, 0.0754, 0.0755, 0.0824, 0.1003, 0.1284, 0.1350, 0.1275, 0.1167,\n",
      "         0.0936],\n",
      "        [0.0653, 0.0755, 0.0755, 0.0825, 0.1003, 0.1283, 0.1349, 0.1275, 0.1166,\n",
      "         0.0936],\n",
      "        [0.0653, 0.0755, 0.0755, 0.0825, 0.1003, 0.1283, 0.1349, 0.1274, 0.1166,\n",
      "         0.0936],\n",
      "        [0.0653, 0.0755, 0.0755, 0.0825, 0.1003, 0.1283, 0.1349, 0.1274, 0.1166,\n",
      "         0.0936]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 在 被 跟踪 吗 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: were we being followed ? <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it the <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0966, 0.1155, 0.1215, 0.1205, 0.1111, 0.1013, 0.0880, 0.0805, 0.0892,\n",
      "         0.0759],\n",
      "        [0.0965, 0.1155, 0.1215, 0.1206, 0.1112, 0.1013, 0.0880, 0.0804, 0.0892,\n",
      "         0.0757],\n",
      "        [0.0964, 0.1155, 0.1215, 0.1206, 0.1112, 0.1013, 0.0881, 0.0804, 0.0892,\n",
      "         0.0757],\n",
      "        [0.0964, 0.1154, 0.1215, 0.1206, 0.1112, 0.1013, 0.0881, 0.0805, 0.0893,\n",
      "         0.0757],\n",
      "        [0.0964, 0.1154, 0.1214, 0.1205, 0.1112, 0.1014, 0.0882, 0.0805, 0.0893,\n",
      "         0.0758],\n",
      "        [0.0964, 0.1153, 0.1214, 0.1205, 0.1112, 0.1014, 0.0882, 0.0806, 0.0893,\n",
      "         0.0758],\n",
      "        [0.0964, 0.1153, 0.1214, 0.1205, 0.1112, 0.1014, 0.0882, 0.0806, 0.0893,\n",
      "         0.0758],\n",
      "        [0.0964, 0.1153, 0.1213, 0.1204, 0.1111, 0.1014, 0.0882, 0.0806, 0.0893,\n",
      "         0.0759],\n",
      "        [0.0964, 0.1153, 0.1213, 0.1204, 0.1111, 0.1014, 0.0882, 0.0806, 0.0893,\n",
      "         0.0759]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 2.00, Train Loss: 9.30, Val Loss: 9.91, Train BLEU: 0.29, Val BLEU: 0.18\n",
      "Sampling from training predictions...\n",
      "Source: 底下 这些 都 是 <UNK> 它们 上上 上上下下 上下 下下\n",
      "Reference: it &apos;s got these fishing <UNK> on the bottom\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.1024, 0.1387, 0.1632, 0.1458, 0.0926, 0.1019, 0.0743, 0.0749, 0.0670,\n",
      "         0.0394],\n",
      "        [0.1022, 0.1389, 0.1637, 0.1461, 0.0925, 0.1019, 0.0740, 0.0748, 0.0668,\n",
      "         0.0391],\n",
      "        [0.1021, 0.1388, 0.1637, 0.1461, 0.0925, 0.1019, 0.0740, 0.0748, 0.0669,\n",
      "         0.0391],\n",
      "        [0.1020, 0.1386, 0.1636, 0.1462, 0.0926, 0.1019, 0.0741, 0.0748, 0.0669,\n",
      "         0.0392],\n",
      "        [0.1020, 0.1386, 0.1636, 0.1462, 0.0927, 0.1020, 0.0741, 0.0748, 0.0669,\n",
      "         0.0392],\n",
      "        [0.1019, 0.1385, 0.1635, 0.1461, 0.0927, 0.1020, 0.0741, 0.0749, 0.0670,\n",
      "         0.0393],\n",
      "        [0.1019, 0.1384, 0.1634, 0.1461, 0.0928, 0.1020, 0.0742, 0.0749, 0.0670,\n",
      "         0.0393],\n",
      "        [0.1019, 0.1384, 0.1633, 0.1461, 0.0928, 0.1020, 0.0742, 0.0750, 0.0671,\n",
      "         0.0394],\n",
      "        [0.1019, 0.1384, 0.1633, 0.1460, 0.0928, 0.1020, 0.0742, 0.0750, 0.0671,\n",
      "         0.0393]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很 舒服 但 夏天 却 <UNK> <EOS> <PAD> <PAD>\n",
      "Reference: it was cozy in winter but extremely hot in\n",
      "Model: <SOS> the the <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0728, 0.1066, 0.1156, 0.1231, 0.1087, 0.0830, 0.1171, 0.1113, 0.0980,\n",
      "         0.0638],\n",
      "        [0.0725, 0.1066, 0.1157, 0.1233, 0.1088, 0.0829, 0.1172, 0.1115, 0.0980,\n",
      "         0.0635],\n",
      "        [0.0724, 0.1066, 0.1157, 0.1233, 0.1088, 0.0829, 0.1171, 0.1115, 0.0981,\n",
      "         0.0635],\n",
      "        [0.0724, 0.1066, 0.1156, 0.1232, 0.1088, 0.0830, 0.1170, 0.1115, 0.0982,\n",
      "         0.0637],\n",
      "        [0.0724, 0.1065, 0.1155, 0.1231, 0.1088, 0.0830, 0.1170, 0.1115, 0.0983,\n",
      "         0.0638],\n",
      "        [0.0724, 0.1065, 0.1154, 0.1231, 0.1088, 0.0831, 0.1170, 0.1115, 0.0983,\n",
      "         0.0639],\n",
      "        [0.0725, 0.1064, 0.1154, 0.1230, 0.1088, 0.0831, 0.1169, 0.1115, 0.0984,\n",
      "         0.0640],\n",
      "        [0.0724, 0.1064, 0.1154, 0.1230, 0.1088, 0.0831, 0.1170, 0.1115, 0.0984,\n",
      "         0.0640],\n",
      "        [0.0725, 0.1064, 0.1153, 0.1230, 0.1088, 0.0831, 0.1170, 0.1115, 0.0984,\n",
      "         0.0641]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 3.00, Train Loss: 8.81, Val Loss: 9.72, Train BLEU: 0.30, Val BLEU: 0.20\n",
      "Sampling from training predictions...\n",
      "Source: 还有 前面 的 这个 是 推进 引擎 它 一会 一会儿\n",
      "Reference: and it &apos;s got these jet thrusters up in\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0504, 0.0983, 0.1510, 0.1649, 0.1784, 0.1463, 0.1121, 0.0701, 0.0198,\n",
      "         0.0088],\n",
      "        [0.0499, 0.0980, 0.1512, 0.1652, 0.1788, 0.1466, 0.1122, 0.0700, 0.0195,\n",
      "         0.0086],\n",
      "        [0.0498, 0.0980, 0.1511, 0.1651, 0.1789, 0.1466, 0.1122, 0.0700, 0.0196,\n",
      "         0.0086],\n",
      "        [0.0498, 0.0979, 0.1509, 0.1649, 0.1788, 0.1467, 0.1124, 0.0702, 0.0197,\n",
      "         0.0087],\n",
      "        [0.0499, 0.0978, 0.1507, 0.1647, 0.1786, 0.1466, 0.1125, 0.0705, 0.0199,\n",
      "         0.0088],\n",
      "        [0.0499, 0.0978, 0.1507, 0.1646, 0.1784, 0.1466, 0.1126, 0.0706, 0.0200,\n",
      "         0.0088],\n",
      "        [0.0499, 0.0978, 0.1505, 0.1645, 0.1783, 0.1466, 0.1126, 0.0707, 0.0201,\n",
      "         0.0089],\n",
      "        [0.0500, 0.0979, 0.1505, 0.1644, 0.1782, 0.1465, 0.1127, 0.0708, 0.0201,\n",
      "         0.0089],\n",
      "        [0.0501, 0.0979, 0.1504, 0.1643, 0.1781, 0.1465, 0.1127, 0.0709, 0.0202,\n",
      "         0.0090]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11 岁 那年 记得 得有 一天 早晨 醒来 听见\n",
      "Reference: when i was 11 , i remember waking up\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[1.1538e-05, 1.9184e-05, 2.5042e-05, 1.9052e-05, 1.0955e-05, 3.6237e-06,\n",
      "         2.3403e-06, 3.3330e-01, 3.3330e-01, 3.3330e-01],\n",
      "        [1.4242e-05, 2.3757e-05, 3.1084e-05, 2.3644e-05, 1.3565e-05, 4.4597e-06,\n",
      "         2.8714e-06, 3.3330e-01, 3.3330e-01, 3.3330e-01],\n",
      "        [1.5307e-05, 2.5430e-05, 3.3232e-05, 2.5372e-05, 1.4645e-05, 4.8722e-06,\n",
      "         3.1503e-06, 3.3329e-01, 3.3329e-01, 3.3329e-01],\n",
      "        [1.5645e-05, 2.5852e-05, 3.3710e-05, 2.5844e-05, 1.5022e-05, 5.0637e-06,\n",
      "         3.2929e-06, 3.3329e-01, 3.3329e-01, 3.3329e-01],\n",
      "        [1.5743e-05, 2.5903e-05, 3.3711e-05, 2.5922e-05, 1.5148e-05, 5.1575e-06,\n",
      "         3.3684e-06, 3.3329e-01, 3.3329e-01, 3.3329e-01],\n",
      "        [1.5782e-05, 2.5889e-05, 3.3642e-05, 2.5916e-05, 1.5197e-05, 5.2085e-06,\n",
      "         3.4109e-06, 3.3329e-01, 3.3329e-01, 3.3329e-01],\n",
      "        [1.5820e-05, 2.5899e-05, 3.3620e-05, 2.5927e-05, 1.5237e-05, 5.2445e-06,\n",
      "         3.4404e-06, 3.3329e-01, 3.3329e-01, 3.3329e-01],\n",
      "        [1.5888e-05, 2.5977e-05, 3.3696e-05, 2.6002e-05, 1.5302e-05, 5.2809e-06,\n",
      "         3.4677e-06, 3.3329e-01, 3.3329e-01, 3.3329e-01],\n",
      "        [1.5879e-05, 2.5932e-05, 3.3613e-05, 2.5943e-05, 1.5279e-05, 5.2808e-06,\n",
      "         3.4690e-06, 3.3329e-01, 3.3329e-01, 3.3329e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4.00, Train Loss: 8.28, Val Loss: 9.52, Train BLEU: 0.31, Val BLEU: 0.22\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里 生物 的 多样 多样性 和 密度 要 比\n",
      "Reference: the biodiversity and the <UNK> in the ocean is\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0303, 0.0925, 0.1301, 0.1602, 0.1318, 0.0753, 0.1421, 0.1232, 0.0865,\n",
      "         0.0280],\n",
      "        [0.0295, 0.0922, 0.1301, 0.1609, 0.1322, 0.0751, 0.1426, 0.1236, 0.0863,\n",
      "         0.0274],\n",
      "        [0.0293, 0.0920, 0.1301, 0.1611, 0.1323, 0.0751, 0.1427, 0.1236, 0.0863,\n",
      "         0.0274],\n",
      "        [0.0293, 0.0919, 0.1300, 0.1611, 0.1323, 0.0752, 0.1426, 0.1236, 0.0865,\n",
      "         0.0275],\n",
      "        [0.0294, 0.0919, 0.1298, 0.1609, 0.1323, 0.0753, 0.1425, 0.1236, 0.0866,\n",
      "         0.0277],\n",
      "        [0.0295, 0.0920, 0.1298, 0.1607, 0.1322, 0.0754, 0.1424, 0.1236, 0.0867,\n",
      "         0.0278],\n",
      "        [0.0295, 0.0920, 0.1297, 0.1605, 0.1321, 0.0754, 0.1423, 0.1236, 0.0868,\n",
      "         0.0279],\n",
      "        [0.0296, 0.0920, 0.1297, 0.1604, 0.1320, 0.0755, 0.1423, 0.1236, 0.0869,\n",
      "         0.0280],\n",
      "        [0.0296, 0.0921, 0.1296, 0.1603, 0.1320, 0.0755, 0.1422, 0.1236, 0.0870,\n",
      "         0.0281]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 出身 阿富汗 边远 <UNK> 地区 有着 与 他人 不同\n",
      "Reference: a total maverick from a remote province of afghanistan\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[5.5580e-05, 1.6848e-04, 2.3013e-04, 1.8575e-04, 9.9203e-05, 1.5824e-04,\n",
      "         1.3137e-04, 5.0304e-05, 9.1650e-06, 9.9891e-01],\n",
      "        [6.6214e-05, 2.0329e-04, 2.7854e-04, 2.2419e-04, 1.1888e-04, 1.9053e-04,\n",
      "         1.5812e-04, 5.9907e-05, 1.0728e-05, 9.9869e-01],\n",
      "        [6.6718e-05, 2.0314e-04, 2.7776e-04, 2.2388e-04, 1.1927e-04, 1.9061e-04,\n",
      "         1.5867e-04, 6.0670e-05, 1.1071e-05, 9.9869e-01],\n",
      "        [6.6203e-05, 1.9908e-04, 2.7116e-04, 2.1908e-04, 1.1759e-04, 1.8720e-04,\n",
      "         1.5631e-04, 6.0495e-05, 1.1279e-05, 9.9871e-01],\n",
      "        [6.6179e-05, 1.9692e-04, 2.6729e-04, 2.1636e-04, 1.1685e-04, 1.8534e-04,\n",
      "         1.5507e-04, 6.0590e-05, 1.1482e-05, 9.9872e-01],\n",
      "        [6.6479e-05, 1.9634e-04, 2.6581e-04, 2.1540e-04, 1.1684e-04, 1.8483e-04,\n",
      "         1.5483e-04, 6.0880e-05, 1.1663e-05, 9.9873e-01],\n",
      "        [6.6935e-05, 1.9668e-04, 2.6578e-04, 2.1553e-04, 1.1725e-04, 1.8514e-04,\n",
      "         1.5520e-04, 6.1278e-05, 1.1822e-05, 9.9872e-01],\n",
      "        [6.7311e-05, 1.9710e-04, 2.6601e-04, 2.1582e-04, 1.1763e-04, 1.8551e-04,\n",
      "         1.5557e-04, 6.1589e-05, 1.1936e-05, 9.9872e-01],\n",
      "        [6.7869e-05, 1.9824e-04, 2.6729e-04, 2.1693e-04, 1.1841e-04, 1.8655e-04,\n",
      "         1.5649e-04, 6.2075e-05, 1.2068e-05, 9.9871e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 5.00, Train Loss: 7.77, Val Loss: 9.33, Train BLEU: 0.30, Val BLEU: 0.20\n",
      "Sampling from training predictions...\n",
      "Source: 地球 的 大部 大部分 部分 都 是 海水 <EOS> <PAD>\n",
      "Reference: most of the planet is ocean water . <EOS>\n",
      "Model: <SOS> the the the the the the the <EOS> <EOS>\n",
      "Attention Weights: tensor([[8.0217e-05, 3.4214e-04, 5.3263e-04, 6.1208e-04, 7.4115e-04, 7.5813e-04,\n",
      "         4.3887e-04, 1.1184e-04, 1.0321e-05, 9.9637e-01],\n",
      "        [8.2905e-05, 3.6476e-04, 5.7301e-04, 6.5922e-04, 8.0099e-04, 8.2130e-04,\n",
      "         4.7137e-04, 1.1691e-04, 1.0335e-05, 9.9610e-01],\n",
      "        [7.6401e-05, 3.3441e-04, 5.2500e-04, 6.0370e-04, 7.3361e-04, 7.5311e-04,\n",
      "         4.3329e-04, 1.0819e-04, 9.7623e-06, 9.9642e-01],\n",
      "        [7.4860e-05, 3.2272e-04, 5.0410e-04, 5.7872e-04, 7.0193e-04, 7.2052e-04,\n",
      "         4.1704e-04, 1.0581e-04, 9.8167e-06, 9.9656e-01],\n",
      "        [7.5531e-05, 3.2090e-04, 4.9864e-04, 5.7141e-04, 6.9165e-04, 7.0965e-04,\n",
      "         4.1294e-04, 1.0625e-04, 1.0081e-05, 9.9660e-01],\n",
      "        [7.7021e-05, 3.2351e-04, 5.0059e-04, 5.7281e-04, 6.9220e-04, 7.0988e-04,\n",
      "         4.1468e-04, 1.0779e-04, 1.0392e-05, 9.9659e-01],\n",
      "        [7.8761e-05, 3.2802e-04, 5.0597e-04, 5.7833e-04, 6.9799e-04, 7.1553e-04,\n",
      "         4.1913e-04, 1.0975e-04, 1.0698e-05, 9.9656e-01],\n",
      "        [7.9894e-05, 3.3093e-04, 5.0942e-04, 5.8187e-04, 7.0166e-04, 7.1910e-04,\n",
      "         4.2199e-04, 1.1102e-04, 1.0899e-05, 9.9653e-01],\n",
      "        [8.1311e-05, 3.3529e-04, 5.1528e-04, 5.8821e-04, 7.0882e-04, 7.2626e-04,\n",
      "         4.2685e-04, 1.1274e-04, 1.1129e-05, 9.9649e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 很 害怕 但是 我们 仍然 渴望 望去 学校 <EOS>\n",
      "Reference: we were scared , but still , school was\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0185, 0.0583, 0.1049, 0.1528, 0.1619, 0.1783, 0.1438, 0.1070, 0.0613,\n",
      "         0.0132],\n",
      "        [0.0175, 0.0572, 0.1045, 0.1538, 0.1631, 0.1800, 0.1444, 0.1067, 0.0603,\n",
      "         0.0125],\n",
      "        [0.0172, 0.0566, 0.1042, 0.1541, 0.1636, 0.1808, 0.1447, 0.1065, 0.0599,\n",
      "         0.0123],\n",
      "        [0.0171, 0.0565, 0.1041, 0.1541, 0.1636, 0.1809, 0.1448, 0.1066, 0.0599,\n",
      "         0.0123],\n",
      "        [0.0172, 0.0566, 0.1042, 0.1540, 0.1635, 0.1807, 0.1447, 0.1067, 0.0601,\n",
      "         0.0124],\n",
      "        [0.0173, 0.0567, 0.1043, 0.1539, 0.1633, 0.1805, 0.1446, 0.1067, 0.0602,\n",
      "         0.0125],\n",
      "        [0.0174, 0.0569, 0.1043, 0.1538, 0.1632, 0.1802, 0.1446, 0.1068, 0.0604,\n",
      "         0.0125],\n",
      "        [0.0174, 0.0570, 0.1044, 0.1537, 0.1631, 0.1801, 0.1445, 0.1068, 0.0605,\n",
      "         0.0126],\n",
      "        [0.0175, 0.0571, 0.1044, 0.1536, 0.1630, 0.1799, 0.1444, 0.1068, 0.0606,\n",
      "         0.0126]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 6.00, Train Loss: 7.28, Val Loss: 9.15, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一种 种群 栖 动物 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: it &apos;s a colonial animal . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[7.1511e-05, 3.0183e-04, 4.3642e-04, 4.3890e-04, 3.0031e-04, 6.3686e-05,\n",
      "         3.3671e-06, 3.3279e-01, 3.3279e-01, 3.3279e-01],\n",
      "        [5.5911e-05, 2.4968e-04, 3.6597e-04, 3.6777e-04, 2.4835e-04, 4.9701e-05,\n",
      "         2.4270e-06, 3.3289e-01, 3.3289e-01, 3.3289e-01],\n",
      "        [4.6178e-05, 2.0717e-04, 3.0427e-04, 3.0596e-04, 2.0642e-04, 4.1203e-05,\n",
      "         2.0456e-06, 3.3296e-01, 3.3296e-01, 3.3296e-01],\n",
      "        [4.5086e-05, 1.9919e-04, 2.9105e-04, 2.9262e-04, 1.9811e-04, 4.0174e-05,\n",
      "         2.0553e-06, 3.3298e-01, 3.3298e-01, 3.3298e-01],\n",
      "        [4.7042e-05, 2.0362e-04, 2.9556e-04, 2.9699e-04, 2.0198e-04, 4.1749e-05,\n",
      "         2.1995e-06, 3.3297e-01, 3.3297e-01, 3.3297e-01],\n",
      "        [4.8449e-05, 2.0705e-04, 2.9925e-04, 3.0056e-04, 2.0495e-04, 4.2857e-05,\n",
      "         2.2989e-06, 3.3296e-01, 3.3296e-01, 3.3296e-01],\n",
      "        [5.0188e-05, 2.1216e-04, 3.0556e-04, 3.0678e-04, 2.0968e-04, 4.4270e-05,\n",
      "         2.4091e-06, 3.3296e-01, 3.3296e-01, 3.3296e-01],\n",
      "        [5.1625e-05, 2.1646e-04, 3.1096e-04, 3.1213e-04, 2.1372e-04, 4.5454e-05,\n",
      "         2.4993e-06, 3.3295e-01, 3.3295e-01, 3.3295e-01],\n",
      "        [5.2313e-05, 2.1840e-04, 3.1329e-04, 3.1442e-04, 2.1549e-04, 4.6013e-05,\n",
      "         2.5446e-06, 3.3295e-01, 3.3295e-01, 3.3295e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11 岁 那年 记得 得有 一天 早晨 醒来 听见\n",
      "Reference: when i was 11 , i remember waking up\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[4.0319e-05, 1.7978e-04, 3.3621e-04, 2.2189e-04, 6.5065e-05, 3.8196e-06,\n",
      "         9.4198e-07, 3.3305e-01, 3.3305e-01, 3.3305e-01],\n",
      "        [2.8656e-05, 1.3505e-04, 2.5988e-04, 1.6917e-04, 4.7598e-05, 2.5990e-06,\n",
      "         6.2781e-07, 3.3312e-01, 3.3312e-01, 3.3312e-01],\n",
      "        [2.3103e-05, 1.0915e-04, 2.1093e-04, 1.3719e-04, 3.8576e-05, 2.1401e-06,\n",
      "         5.2571e-07, 3.3316e-01, 3.3316e-01, 3.3316e-01],\n",
      "        [2.2385e-05, 1.0418e-04, 1.9983e-04, 1.3041e-04, 3.7136e-05, 2.1208e-06,\n",
      "         5.2793e-07, 3.3317e-01, 3.3317e-01, 3.3317e-01],\n",
      "        [2.2863e-05, 1.0474e-04, 1.9925e-04, 1.3045e-04, 3.7598e-05, 2.2012e-06,\n",
      "         5.5308e-07, 3.3317e-01, 3.3317e-01, 3.3317e-01],\n",
      "        [2.3640e-05, 1.0693e-04, 2.0206e-04, 1.3264e-04, 3.8585e-05, 2.3009e-06,\n",
      "         5.8174e-07, 3.3316e-01, 3.3316e-01, 3.3316e-01],\n",
      "        [2.4426e-05, 1.0942e-04, 2.0573e-04, 1.3532e-04, 3.9641e-05, 2.3954e-06,\n",
      "         6.0814e-07, 3.3316e-01, 3.3316e-01, 3.3316e-01],\n",
      "        [2.5133e-05, 1.1181e-04, 2.0947e-04, 1.3799e-04, 4.0625e-05, 2.4780e-06,\n",
      "         6.3085e-07, 3.3316e-01, 3.3316e-01, 3.3316e-01],\n",
      "        [2.5825e-05, 1.1423e-04, 2.1333e-04, 1.4069e-04, 4.1585e-05, 2.5546e-06,\n",
      "         6.5152e-07, 3.3315e-01, 3.3315e-01, 3.3315e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7.00, Train Loss: 6.83, Val Loss: 8.99, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 还有 这些 摇晃 着 旋转 转着 的 触角 <EOS> <PAD>\n",
      "Reference: it &apos;s got tentacles dangling , swirling around like\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[1.6944e-04, 1.0960e-03, 2.2571e-03, 2.9221e-03, 2.1334e-03, 8.2567e-04,\n",
      "         1.1863e-03, 2.7416e-04, 9.2408e-06, 9.8913e-01],\n",
      "        [8.6609e-05, 6.2077e-04, 1.3401e-03, 1.7676e-03, 1.2643e-03, 4.6205e-04,\n",
      "         6.7492e-04, 1.4291e-04, 4.2833e-06, 9.9364e-01],\n",
      "        [6.3650e-05, 4.6150e-04, 1.0049e-03, 1.3304e-03, 9.4725e-04, 3.4294e-04,\n",
      "         5.0301e-04, 1.0542e-04, 3.2076e-06, 9.9524e-01],\n",
      "        [6.2673e-05, 4.4583e-04, 9.6111e-04, 1.2662e-03, 9.0338e-04, 3.3097e-04,\n",
      "         4.8395e-04, 1.0289e-04, 3.2284e-06, 9.9544e-01],\n",
      "        [6.7743e-05, 4.6894e-04, 9.9683e-04, 1.3049e-03, 9.3467e-04, 3.4796e-04,\n",
      "         5.0627e-04, 1.0977e-04, 3.5571e-06, 9.9526e-01],\n",
      "        [7.1859e-05, 4.8825e-04, 1.0281e-03, 1.3401e-03, 9.6245e-04, 3.6216e-04,\n",
      "         5.2516e-04, 1.1540e-04, 3.8224e-06, 9.9510e-01],\n",
      "        [7.5810e-05, 5.0756e-04, 1.0610e-03, 1.3786e-03, 9.9222e-04, 3.7647e-04,\n",
      "         5.4444e-04, 1.2089e-04, 4.0714e-06, 9.9494e-01],\n",
      "        [7.8930e-05, 5.2281e-04, 1.0872e-03, 1.4094e-03, 1.0161e-03, 3.8787e-04,\n",
      "         5.5980e-04, 1.2526e-04, 4.2696e-06, 9.9481e-01],\n",
      "        [8.0280e-05, 5.2897e-04, 1.0971e-03, 1.4206e-03, 1.0249e-03, 3.9249e-04,\n",
      "         5.6589e-04, 1.2711e-04, 4.3589e-06, 9.9476e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 但是 我 那 受过 教育 的 母亲 成为 为了 一名\n",
      "Reference: but my educated mother became a teacher . <EOS>\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[1.2440e-04, 4.3518e-04, 4.8145e-04, 1.3096e-04, 1.5046e-04, 3.6323e-04,\n",
      "         1.6534e-04, 4.6709e-06, 4.9907e-01, 4.9907e-01],\n",
      "        [6.1492e-05, 2.3224e-04, 2.5979e-04, 6.5575e-05, 7.5067e-05, 1.9004e-04,\n",
      "         8.2640e-05, 2.0476e-06, 4.9952e-01, 4.9952e-01],\n",
      "        [4.4295e-05, 1.6889e-04, 1.8939e-04, 4.7413e-05, 5.4235e-05, 1.3790e-04,\n",
      "         5.9687e-05, 1.5008e-06, 4.9965e-01, 4.9965e-01],\n",
      "        [4.3045e-05, 1.6191e-04, 1.8105e-04, 4.5871e-05, 5.2462e-05, 1.3227e-04,\n",
      "         5.7611e-05, 1.4960e-06, 4.9966e-01, 4.9966e-01],\n",
      "        [4.5401e-05, 1.6784e-04, 1.8703e-04, 4.8100e-05, 5.4971e-05, 1.3719e-04,\n",
      "         6.0229e-05, 1.6134e-06, 4.9965e-01, 4.9965e-01],\n",
      "        [4.7894e-05, 1.7471e-04, 1.9420e-04, 5.0523e-05, 5.7699e-05, 1.4287e-04,\n",
      "         6.3110e-05, 1.7296e-06, 4.9963e-01, 4.9963e-01],\n",
      "        [5.0000e-05, 1.8067e-04, 2.0047e-04, 5.2594e-05, 6.0027e-05, 1.4779e-04,\n",
      "         6.5573e-05, 1.8262e-06, 4.9962e-01, 4.9962e-01],\n",
      "        [5.1976e-05, 1.8640e-04, 2.0656e-04, 5.4553e-05, 6.2232e-05, 1.5254e-04,\n",
      "         6.7921e-05, 1.9152e-06, 4.9961e-01, 4.9961e-01],\n",
      "        [5.4490e-05, 1.9392e-04, 2.1466e-04, 5.7094e-05, 6.5103e-05, 1.5882e-04,\n",
      "         7.0998e-05, 2.0276e-06, 4.9959e-01, 4.9959e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 8.00, Train Loss: 6.40, Val Loss: 8.85, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 我们 将 用 一些 影片 来讲 讲述 一些 深海 海里\n",
      "Reference: and we &apos;re going to tell you some stories\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0092, 0.0758, 0.1417, 0.1578, 0.1633, 0.1606, 0.1421, 0.1028, 0.0428,\n",
      "         0.0040],\n",
      "        [0.0072, 0.0713, 0.1435, 0.1618, 0.1681, 0.1646, 0.1433, 0.0996, 0.0377,\n",
      "         0.0029],\n",
      "        [0.0067, 0.0698, 0.1436, 0.1628, 0.1695, 0.1659, 0.1438, 0.0988, 0.0364,\n",
      "         0.0027],\n",
      "        [0.0067, 0.0698, 0.1437, 0.1629, 0.1695, 0.1659, 0.1438, 0.0988, 0.0363,\n",
      "         0.0027],\n",
      "        [0.0068, 0.0701, 0.1438, 0.1628, 0.1693, 0.1657, 0.1437, 0.0989, 0.0365,\n",
      "         0.0027],\n",
      "        [0.0068, 0.0703, 0.1438, 0.1626, 0.1691, 0.1655, 0.1436, 0.0990, 0.0366,\n",
      "         0.0027],\n",
      "        [0.0069, 0.0705, 0.1438, 0.1625, 0.1689, 0.1654, 0.1435, 0.0990, 0.0367,\n",
      "         0.0028],\n",
      "        [0.0069, 0.0706, 0.1438, 0.1624, 0.1688, 0.1653, 0.1435, 0.0991, 0.0368,\n",
      "         0.0028],\n",
      "        [0.0069, 0.0707, 0.1438, 0.1624, 0.1687, 0.1652, 0.1435, 0.0991, 0.0369,\n",
      "         0.0028]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 总是 担心 会 被 塔利 塔利班 发现 <EOS> <PAD>\n",
      "Reference: we always wondered what they knew about us .\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0059, 0.0147, 0.0972, 0.1826, 0.2306, 0.2074, 0.1529, 0.0575, 0.0461,\n",
      "         0.0050],\n",
      "        [0.0044, 0.0116, 0.0919, 0.1860, 0.2425, 0.2156, 0.1529, 0.0515, 0.0401,\n",
      "         0.0037],\n",
      "        [0.0041, 0.0109, 0.0901, 0.1866, 0.2458, 0.2178, 0.1527, 0.0499, 0.0386,\n",
      "         0.0034],\n",
      "        [0.0041, 0.0109, 0.0901, 0.1867, 0.2461, 0.2179, 0.1526, 0.0497, 0.0385,\n",
      "         0.0034],\n",
      "        [0.0041, 0.0110, 0.0903, 0.1867, 0.2457, 0.2176, 0.1526, 0.0498, 0.0387,\n",
      "         0.0034],\n",
      "        [0.0042, 0.0110, 0.0906, 0.1867, 0.2453, 0.2173, 0.1526, 0.0500, 0.0388,\n",
      "         0.0035],\n",
      "        [0.0042, 0.0111, 0.0908, 0.1866, 0.2450, 0.2171, 0.1526, 0.0502, 0.0390,\n",
      "         0.0035],\n",
      "        [0.0042, 0.0112, 0.0909, 0.1866, 0.2448, 0.2169, 0.1525, 0.0503, 0.0391,\n",
      "         0.0035],\n",
      "        [0.0042, 0.0112, 0.0910, 0.1866, 0.2446, 0.2168, 0.1525, 0.0504, 0.0392,\n",
      "         0.0035]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 9.00, Train Loss: 6.00, Val Loss: 8.73, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 原来 它 是 海洋 洋中 最长 的 生物 <EOS> <PAD>\n",
      "Reference: this turns out to be the longest creature in\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[3.8794e-04, 3.4462e-03, 5.8120e-03, 5.5187e-03, 3.4195e-03, 5.0095e-03,\n",
      "         3.7523e-03, 8.1213e-04, 1.3217e-05, 9.7183e-01],\n",
      "        [7.2055e-05, 8.0449e-04, 1.4579e-03, 1.3743e-03, 7.9334e-04, 1.2169e-03,\n",
      "         8.7536e-04, 1.5795e-04, 2.0304e-06, 9.9325e-01],\n",
      "        [4.2703e-05, 4.8974e-04, 8.9812e-04, 8.4563e-04, 4.8262e-04, 7.4736e-04,\n",
      "         5.3427e-04, 9.4188e-05, 1.2252e-06, 9.9586e-01],\n",
      "        [4.2312e-05, 4.7143e-04, 8.5420e-04, 8.0308e-04, 4.6186e-04, 7.1185e-04,\n",
      "         5.1063e-04, 9.1823e-05, 1.2351e-06, 9.9605e-01],\n",
      "        [4.6806e-05, 5.0227e-04, 8.9725e-04, 8.4268e-04, 4.8941e-04, 7.4920e-04,\n",
      "         5.4008e-04, 9.9664e-05, 1.3903e-06, 9.9583e-01],\n",
      "        [5.1367e-05, 5.3484e-04, 9.4525e-04, 8.8725e-04, 5.1917e-04, 7.9056e-04,\n",
      "         5.7218e-04, 1.0779e-04, 1.5495e-06, 9.9559e-01],\n",
      "        [5.4810e-05, 5.5910e-04, 9.8121e-04, 9.2070e-04, 5.4146e-04, 8.2157e-04,\n",
      "         5.9626e-04, 1.1391e-04, 1.6727e-06, 9.9541e-01],\n",
      "        [5.7298e-05, 5.7632e-04, 1.0067e-03, 9.4447e-04, 5.5734e-04, 8.4362e-04,\n",
      "         6.1341e-04, 1.1832e-04, 1.7635e-06, 9.9528e-01],\n",
      "        [5.9462e-05, 5.9168e-04, 1.0299e-03, 9.6615e-04, 5.7166e-04, 8.6364e-04,\n",
      "         6.2886e-04, 1.2219e-04, 1.8415e-06, 9.9516e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 但是 我 那 受过 教育 的 母亲 成为 为了 一名\n",
      "Reference: but my educated mother became a teacher . <EOS>\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[2.6078e-04, 1.2608e-03, 1.5470e-03, 5.3327e-04, 6.2273e-04, 1.2031e-03,\n",
      "         4.6281e-04, 6.2141e-06, 4.9705e-01, 4.9705e-01],\n",
      "        [4.6154e-05, 2.6499e-04, 3.3518e-04, 1.0201e-04, 1.1930e-04, 2.4771e-04,\n",
      "         8.4985e-05, 8.8414e-07, 4.9940e-01, 4.9940e-01],\n",
      "        [2.6887e-05, 1.5738e-04, 2.0015e-04, 6.0023e-05, 7.0103e-05, 1.4675e-04,\n",
      "         4.9696e-05, 5.2488e-07, 4.9964e-01, 4.9964e-01],\n",
      "        [2.6296e-05, 1.5069e-04, 1.9051e-04, 5.7879e-05, 6.7518e-05, 1.4008e-04,\n",
      "         4.7921e-05, 5.2397e-07, 4.9966e-01, 4.9966e-01],\n",
      "        [2.8918e-05, 1.6119e-04, 2.0236e-04, 6.2561e-05, 7.2857e-05, 1.4949e-04,\n",
      "         5.1864e-05, 5.8852e-07, 4.9964e-01, 4.9964e-01],\n",
      "        [3.1498e-05, 1.7184e-04, 2.1465e-04, 6.7261e-05, 7.8218e-05, 1.5914e-04,\n",
      "         5.5834e-05, 6.5278e-07, 4.9961e-01, 4.9961e-01],\n",
      "        [3.3567e-05, 1.8039e-04, 2.2457e-04, 7.1046e-05, 8.2529e-05, 1.6692e-04,\n",
      "         5.9033e-05, 7.0541e-07, 4.9959e-01, 4.9959e-01],\n",
      "        [3.5403e-05, 1.8805e-04, 2.3352e-04, 7.4422e-05, 8.6379e-05, 1.7391e-04,\n",
      "         6.1888e-05, 7.5187e-07, 4.9957e-01, 4.9957e-01],\n",
      "        [3.7575e-05, 1.9727e-04, 2.4439e-04, 7.8476e-05, 9.1016e-05, 1.8239e-04,\n",
      "         6.5305e-05, 8.0647e-07, 4.9955e-01, 4.9955e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10.00, Train Loss: 5.63, Val Loss: 8.65, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: <UNK> 塞尔 <UNK> <UNK> 斯特 说 过 真正 的 探索\n",
      "Reference: marcel proust said , &quot; the true voyage of\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[1.2411e-05, 1.3072e-04, 5.2154e-04, 2.9466e-03, 3.0546e-02, 2.1471e-01,\n",
      "         3.0808e-01, 2.7389e-01, 1.5530e-01, 1.3860e-02],\n",
      "        [6.5165e-06, 6.0912e-05, 2.4477e-04, 1.5056e-03, 2.0291e-02, 2.1071e-01,\n",
      "         3.3230e-01, 2.8619e-01, 1.4068e-01, 8.0105e-03],\n",
      "        [7.1135e-06, 6.0205e-05, 2.3172e-04, 1.3865e-03, 1.8785e-02, 2.0872e-01,\n",
      "         3.3696e-01, 2.8859e-01, 1.3787e-01, 7.3790e-03],\n",
      "        [7.3811e-06, 6.1221e-05, 2.3318e-04, 1.3840e-03, 1.8677e-02, 2.0848e-01,\n",
      "         3.3735e-01, 2.8881e-01, 1.3763e-01, 7.3656e-03],\n",
      "        [7.4708e-06, 6.1810e-05, 2.3506e-04, 1.3927e-03, 1.8744e-02, 2.0855e-01,\n",
      "         3.3717e-01, 2.8871e-01, 1.3772e-01, 7.4108e-03],\n",
      "        [7.5047e-06, 6.2161e-05, 2.3649e-04, 1.4008e-03, 1.8820e-02, 2.0865e-01,\n",
      "         3.3696e-01, 2.8858e-01, 1.3783e-01, 7.4511e-03],\n",
      "        [7.5246e-06, 6.2447e-05, 2.3775e-04, 1.4084e-03, 1.8892e-02, 2.0873e-01,\n",
      "         3.3675e-01, 2.8848e-01, 1.3795e-01, 7.4855e-03],\n",
      "        [7.5103e-06, 6.2426e-05, 2.3783e-04, 1.4096e-03, 1.8911e-02, 2.0877e-01,\n",
      "         3.3669e-01, 2.8844e-01, 1.3798e-01, 7.4937e-03],\n",
      "        [7.5271e-06, 6.2612e-05, 2.3858e-04, 1.4138e-03, 1.8946e-02, 2.0879e-01,\n",
      "         3.3658e-01, 2.8840e-01, 1.3805e-01, 7.5138e-03]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 因此 毫无 毫无疑问 无疑 疑问 他 的 孩子 应当 受到\n",
      "Reference: there was no question that his children would receive\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[5.1800e-04, 4.3211e-03, 7.7088e-03, 9.0795e-03, 7.5708e-03, 3.9428e-03,\n",
      "         5.0528e-03, 1.2427e-03, 1.6703e-05, 9.6055e-01],\n",
      "        [5.1883e-05, 5.6783e-04, 1.1192e-03, 1.3595e-03, 1.0967e-03, 5.1143e-04,\n",
      "         6.7379e-04, 1.3338e-04, 1.3360e-06, 9.9448e-01],\n",
      "        [2.7384e-05, 3.0713e-04, 6.1404e-04, 7.4994e-04, 6.0202e-04, 2.7621e-04,\n",
      "         3.6603e-04, 7.0869e-05, 7.2456e-07, 9.9699e-01],\n",
      "        [2.6665e-05, 2.9040e-04, 5.7259e-04, 6.9543e-04, 5.5940e-04, 2.5978e-04,\n",
      "         3.4306e-04, 6.7752e-05, 7.1639e-07, 9.9718e-01],\n",
      "        [3.0271e-05, 3.1601e-04, 6.1189e-04, 7.3805e-04, 5.9570e-04, 2.8126e-04,\n",
      "         3.6946e-04, 7.5038e-05, 8.2607e-07, 9.9698e-01],\n",
      "        [3.3270e-05, 3.3721e-04, 6.4516e-04, 7.7476e-04, 6.2680e-04, 2.9930e-04,\n",
      "         3.9174e-04, 8.1139e-05, 9.2150e-07, 9.9681e-01],\n",
      "        [3.5969e-05, 3.5653e-04, 6.7626e-04, 8.0958e-04, 6.5617e-04, 3.1594e-04,\n",
      "         4.1237e-04, 8.6677e-05, 1.0084e-06, 9.9665e-01],\n",
      "        [3.7961e-05, 3.7057e-04, 6.9882e-04, 8.3486e-04, 6.7751e-04, 3.2805e-04,\n",
      "         4.2737e-04, 9.0733e-05, 1.0735e-06, 9.9653e-01],\n",
      "        [3.8579e-05, 3.7414e-04, 7.0382e-04, 8.4009e-04, 6.8211e-04, 3.3109e-04,\n",
      "         4.3100e-04, 9.1911e-05, 1.0963e-06, 9.9651e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 11.00, Train Loss: 5.30, Val Loss: 8.59, Train BLEU: 0.30, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里 生物 的 多样 多样性 和 密度 要 比\n",
      "Reference: the biodiversity and the <UNK> in the ocean is\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0104, 0.0865, 0.1323, 0.1519, 0.1446, 0.1152, 0.1452, 0.1271, 0.0783,\n",
      "         0.0086],\n",
      "        [0.0065, 0.0796, 0.1351, 0.1612, 0.1515, 0.1134, 0.1511, 0.1273, 0.0693,\n",
      "         0.0051],\n",
      "        [0.0060, 0.0781, 0.1353, 0.1628, 0.1527, 0.1129, 0.1522, 0.1273, 0.0680,\n",
      "         0.0047],\n",
      "        [0.0061, 0.0782, 0.1353, 0.1627, 0.1527, 0.1129, 0.1522, 0.1273, 0.0680,\n",
      "         0.0047],\n",
      "        [0.0061, 0.0784, 0.1353, 0.1626, 0.1525, 0.1130, 0.1521, 0.1273, 0.0680,\n",
      "         0.0048],\n",
      "        [0.0062, 0.0786, 0.1353, 0.1624, 0.1524, 0.1130, 0.1520, 0.1273, 0.0681,\n",
      "         0.0048],\n",
      "        [0.0062, 0.0787, 0.1353, 0.1623, 0.1523, 0.1130, 0.1519, 0.1273, 0.0682,\n",
      "         0.0048],\n",
      "        [0.0062, 0.0788, 0.1353, 0.1623, 0.1522, 0.1130, 0.1519, 0.1272, 0.0682,\n",
      "         0.0048],\n",
      "        [0.0062, 0.0788, 0.1353, 0.1622, 0.1522, 0.1130, 0.1519, 0.1272, 0.0683,\n",
      "         0.0049]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 总是 担心 会 被 塔利 塔利班 发现 <EOS> <PAD>\n",
      "Reference: we always wondered what they knew about us .\n",
      "Model: <SOS> the the the the the the the <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0078, 0.0292, 0.1206, 0.1726, 0.1923, 0.1794, 0.1500, 0.0804, 0.0621,\n",
      "         0.0055],\n",
      "        [0.0046, 0.0208, 0.1160, 0.1820, 0.2091, 0.1916, 0.1527, 0.0700, 0.0504,\n",
      "         0.0030],\n",
      "        [0.0043, 0.0197, 0.1146, 0.1830, 0.2119, 0.1937, 0.1531, 0.0683, 0.0488,\n",
      "         0.0028],\n",
      "        [0.0043, 0.0197, 0.1146, 0.1830, 0.2118, 0.1936, 0.1530, 0.0684, 0.0488,\n",
      "         0.0028],\n",
      "        [0.0043, 0.0199, 0.1148, 0.1829, 0.2115, 0.1933, 0.1529, 0.0685, 0.0489,\n",
      "         0.0028],\n",
      "        [0.0044, 0.0200, 0.1150, 0.1828, 0.2112, 0.1931, 0.1529, 0.0686, 0.0491,\n",
      "         0.0028],\n",
      "        [0.0044, 0.0201, 0.1151, 0.1827, 0.2111, 0.1930, 0.1528, 0.0687, 0.0491,\n",
      "         0.0029],\n",
      "        [0.0044, 0.0202, 0.1152, 0.1827, 0.2109, 0.1929, 0.1528, 0.0688, 0.0492,\n",
      "         0.0029],\n",
      "        [0.0044, 0.0202, 0.1153, 0.1827, 0.2108, 0.1928, 0.1528, 0.0688, 0.0493,\n",
      "         0.0029]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 12.00, Train Loss: 5.02, Val Loss: 8.57, Train BLEU: 0.31, Val BLEU: 0.21\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克 泰坦尼克号 坦尼 尼克 号 是 拿 了 不少\n",
      "Reference: the truth of the matter is that the titanic\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0045, 0.0053, 0.0139, 0.0448, 0.1595, 0.2185, 0.2241, 0.2000, 0.1184,\n",
      "         0.0110],\n",
      "        [0.0019, 0.0023, 0.0070, 0.0296, 0.1553, 0.2385, 0.2467, 0.2104, 0.1031,\n",
      "         0.0052],\n",
      "        [0.0017, 0.0021, 0.0064, 0.0277, 0.1534, 0.2409, 0.2501, 0.2119, 0.1010,\n",
      "         0.0048],\n",
      "        [0.0017, 0.0021, 0.0064, 0.0277, 0.1534, 0.2409, 0.2501, 0.2119, 0.1009,\n",
      "         0.0048],\n",
      "        [0.0017, 0.0021, 0.0065, 0.0279, 0.1536, 0.2407, 0.2498, 0.2118, 0.1010,\n",
      "         0.0048],\n",
      "        [0.0018, 0.0021, 0.0065, 0.0281, 0.1538, 0.2406, 0.2496, 0.2116, 0.1011,\n",
      "         0.0048],\n",
      "        [0.0018, 0.0021, 0.0066, 0.0282, 0.1539, 0.2405, 0.2495, 0.2115, 0.1012,\n",
      "         0.0049],\n",
      "        [0.0018, 0.0021, 0.0066, 0.0282, 0.1540, 0.2404, 0.2493, 0.2115, 0.1012,\n",
      "         0.0049],\n",
      "        [0.0018, 0.0021, 0.0066, 0.0283, 0.1540, 0.2403, 0.2492, 0.2114, 0.1013,\n",
      "         0.0049]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 有时 学校 <UNK> 突然 <UNK> 一周 因为 被 塔利 塔利班\n",
      "Reference: from time to time , the school would suddenly\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0177, 0.0908, 0.1263, 0.1362, 0.1435, 0.1418, 0.1363, 0.1203, 0.0771,\n",
      "         0.0100],\n",
      "        [0.0103, 0.0829, 0.1288, 0.1426, 0.1531, 0.1504, 0.1421, 0.1194, 0.0655,\n",
      "         0.0049],\n",
      "        [0.0095, 0.0811, 0.1288, 0.1434, 0.1547, 0.1519, 0.1431, 0.1192, 0.0638,\n",
      "         0.0045],\n",
      "        [0.0095, 0.0812, 0.1289, 0.1434, 0.1547, 0.1518, 0.1431, 0.1192, 0.0637,\n",
      "         0.0045],\n",
      "        [0.0096, 0.0814, 0.1289, 0.1434, 0.1545, 0.1517, 0.1430, 0.1192, 0.0638,\n",
      "         0.0045],\n",
      "        [0.0096, 0.0816, 0.1289, 0.1433, 0.1544, 0.1516, 0.1429, 0.1192, 0.0639,\n",
      "         0.0045],\n",
      "        [0.0097, 0.0816, 0.1289, 0.1433, 0.1544, 0.1516, 0.1429, 0.1192, 0.0640,\n",
      "         0.0046],\n",
      "        [0.0097, 0.0817, 0.1289, 0.1432, 0.1543, 0.1515, 0.1428, 0.1192, 0.0640,\n",
      "         0.0046],\n",
      "        [0.0097, 0.0818, 0.1289, 0.1432, 0.1543, 0.1515, 0.1428, 0.1192, 0.0641,\n",
      "         0.0046]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 13.00, Train Loss: 4.78, Val Loss: 8.58, Train BLEU: 0.31, Val BLEU: 0.22\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 通过 潜水 潜水艇 拍下 的 影片 把 我们\n",
      "Reference: with vibrant video clips captured by submarines , david\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0124, 0.0369, 0.1138, 0.1393, 0.1293, 0.1586, 0.1619, 0.1418, 0.0945,\n",
      "         0.0116],\n",
      "        [0.0052, 0.0222, 0.1085, 0.1456, 0.1302, 0.1754, 0.1803, 0.1475, 0.0806,\n",
      "         0.0045],\n",
      "        [0.0046, 0.0204, 0.1069, 0.1461, 0.1298, 0.1781, 0.1836, 0.1483, 0.0784,\n",
      "         0.0039],\n",
      "        [0.0046, 0.0203, 0.1068, 0.1461, 0.1298, 0.1781, 0.1837, 0.1484, 0.0783,\n",
      "         0.0039],\n",
      "        [0.0046, 0.0204, 0.1069, 0.1461, 0.1299, 0.1780, 0.1835, 0.1483, 0.0783,\n",
      "         0.0039],\n",
      "        [0.0046, 0.0205, 0.1070, 0.1461, 0.1299, 0.1779, 0.1834, 0.1482, 0.0784,\n",
      "         0.0040],\n",
      "        [0.0047, 0.0206, 0.1070, 0.1461, 0.1300, 0.1779, 0.1832, 0.1481, 0.0784,\n",
      "         0.0040],\n",
      "        [0.0047, 0.0206, 0.1071, 0.1460, 0.1300, 0.1778, 0.1832, 0.1481, 0.0785,\n",
      "         0.0040],\n",
      "        [0.0047, 0.0207, 0.1071, 0.1460, 0.1300, 0.1778, 0.1831, 0.1481, 0.0785,\n",
      "         0.0040]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 都 知道 自己 正 冒 着 生命 的 危险\n",
      "Reference: we all knew we were risking our lives --\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0166, 0.0874, 0.1215, 0.1409, 0.1428, 0.1439, 0.1356, 0.1188, 0.0790,\n",
      "         0.0134],\n",
      "        [0.0076, 0.0758, 0.1224, 0.1524, 0.1552, 0.1569, 0.1433, 0.1172, 0.0638,\n",
      "         0.0054],\n",
      "        [0.0067, 0.0733, 0.1218, 0.1542, 0.1574, 0.1593, 0.1446, 0.1167, 0.0614,\n",
      "         0.0047],\n",
      "        [0.0067, 0.0733, 0.1218, 0.1543, 0.1574, 0.1594, 0.1446, 0.1166, 0.0612,\n",
      "         0.0047],\n",
      "        [0.0067, 0.0735, 0.1219, 0.1542, 0.1573, 0.1593, 0.1445, 0.1166, 0.0613,\n",
      "         0.0047],\n",
      "        [0.0068, 0.0737, 0.1220, 0.1542, 0.1573, 0.1592, 0.1444, 0.1166, 0.0613,\n",
      "         0.0048],\n",
      "        [0.0068, 0.0738, 0.1220, 0.1541, 0.1572, 0.1591, 0.1444, 0.1165, 0.0614,\n",
      "         0.0048],\n",
      "        [0.0068, 0.0739, 0.1220, 0.1541, 0.1571, 0.1590, 0.1443, 0.1166, 0.0614,\n",
      "         0.0048],\n",
      "        [0.0068, 0.0739, 0.1220, 0.1540, 0.1571, 0.1590, 0.1443, 0.1166, 0.0615,\n",
      "         0.0048]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14.00, Train Loss: 4.59, Val Loss: 8.64, Train BLEU: 0.35, Val BLEU: 0.22\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想 海洋 占 了 地球 球面 面积 的 75\n",
      "Reference: when you think about it , the oceans are\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0239, 0.0999, 0.1325, 0.1466, 0.1482, 0.1431, 0.1347, 0.1123, 0.0573,\n",
      "         0.0015],\n",
      "        [0.0099, 0.0884, 0.1384, 0.1626, 0.1652, 0.1556, 0.1406, 0.1039, 0.0352,\n",
      "         0.0002],\n",
      "        [0.0083, 0.0853, 0.1388, 0.1657, 0.1687, 0.1580, 0.1414, 0.1019, 0.0319,\n",
      "         0.0002],\n",
      "        [0.0081, 0.0852, 0.1388, 0.1660, 0.1690, 0.1582, 0.1414, 0.1016, 0.0315,\n",
      "         0.0002],\n",
      "        [0.0082, 0.0853, 0.1389, 0.1660, 0.1689, 0.1581, 0.1414, 0.1015, 0.0315,\n",
      "         0.0002],\n",
      "        [0.0082, 0.0855, 0.1390, 0.1659, 0.1688, 0.1581, 0.1413, 0.1015, 0.0315,\n",
      "         0.0002],\n",
      "        [0.0083, 0.0856, 0.1390, 0.1659, 0.1688, 0.1580, 0.1413, 0.1015, 0.0316,\n",
      "         0.0002],\n",
      "        [0.0083, 0.0857, 0.1390, 0.1658, 0.1687, 0.1580, 0.1412, 0.1015, 0.0316,\n",
      "         0.0002],\n",
      "        [0.0083, 0.0857, 0.1390, 0.1658, 0.1687, 0.1579, 0.1412, 0.1016, 0.0316,\n",
      "         0.0002]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 这 是 我们 俩 人 唯一 的 受教 教育 方式\n",
      "Reference: it was the only way we both could be\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0308, 0.1014, 0.1257, 0.1328, 0.1329, 0.1337, 0.1278, 0.1179, 0.0833,\n",
      "         0.0137],\n",
      "        [0.0147, 0.0944, 0.1330, 0.1447, 0.1446, 0.1456, 0.1348, 0.1177, 0.0663,\n",
      "         0.0041],\n",
      "        [0.0126, 0.0922, 0.1339, 0.1469, 0.1468, 0.1480, 0.1359, 0.1172, 0.0631,\n",
      "         0.0033],\n",
      "        [0.0124, 0.0921, 0.1340, 0.1472, 0.1470, 0.1482, 0.1360, 0.1171, 0.0626,\n",
      "         0.0033],\n",
      "        [0.0125, 0.0923, 0.1341, 0.1472, 0.1470, 0.1482, 0.1359, 0.1171, 0.0626,\n",
      "         0.0033],\n",
      "        [0.0125, 0.0924, 0.1341, 0.1471, 0.1469, 0.1481, 0.1359, 0.1170, 0.0626,\n",
      "         0.0033],\n",
      "        [0.0126, 0.0925, 0.1341, 0.1471, 0.1469, 0.1480, 0.1358, 0.1170, 0.0627,\n",
      "         0.0033],\n",
      "        [0.0126, 0.0925, 0.1341, 0.1471, 0.1468, 0.1480, 0.1358, 0.1170, 0.0627,\n",
      "         0.0033],\n",
      "        [0.0126, 0.0926, 0.1341, 0.1470, 0.1468, 0.1480, 0.1358, 0.1170, 0.0627,\n",
      "         0.0033]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 15.00, Train Loss: 4.43, Val Loss: 8.74, Train BLEU: 0.35, Val BLEU: 0.22\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里 生物 的 多样 多样性 和 密度 要 比\n",
      "Reference: the biodiversity and the <UNK> in the ocean is\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0255, 0.1026, 0.1268, 0.1350, 0.1323, 0.1194, 0.1298, 0.1192, 0.0897,\n",
      "         0.0195],\n",
      "        [0.0114, 0.0968, 0.1350, 0.1490, 0.1438, 0.1215, 0.1390, 0.1206, 0.0757,\n",
      "         0.0072],\n",
      "        [0.0096, 0.0948, 0.1362, 0.1519, 0.1462, 0.1213, 0.1408, 0.1205, 0.0727,\n",
      "         0.0059],\n",
      "        [0.0094, 0.0947, 0.1364, 0.1524, 0.1465, 0.1212, 0.1410, 0.1205, 0.0722,\n",
      "         0.0058],\n",
      "        [0.0094, 0.0949, 0.1365, 0.1524, 0.1464, 0.1211, 0.1410, 0.1204, 0.0721,\n",
      "         0.0058],\n",
      "        [0.0095, 0.0950, 0.1365, 0.1523, 0.1463, 0.1211, 0.1409, 0.1204, 0.0722,\n",
      "         0.0058],\n",
      "        [0.0095, 0.0951, 0.1365, 0.1522, 0.1463, 0.1211, 0.1409, 0.1204, 0.0722,\n",
      "         0.0058],\n",
      "        [0.0095, 0.0951, 0.1365, 0.1522, 0.1462, 0.1211, 0.1409, 0.1204, 0.0722,\n",
      "         0.0058],\n",
      "        [0.0095, 0.0952, 0.1365, 0.1522, 0.1462, 0.1211, 0.1409, 0.1204, 0.0722,\n",
      "         0.0058]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正 的 学校 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: a real school . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it the the <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0262, 0.1033, 0.1327, 0.1447, 0.1457, 0.1408, 0.1329, 0.1120, 0.0598,\n",
      "         0.0017],\n",
      "        [0.0116, 0.0939, 0.1392, 0.1598, 0.1614, 0.1525, 0.1384, 0.1046, 0.0384,\n",
      "         0.0003],\n",
      "        [0.0097, 0.0910, 0.1398, 0.1628, 0.1648, 0.1549, 0.1393, 0.1027, 0.0348,\n",
      "         0.0002],\n",
      "        [0.0095, 0.0907, 0.1399, 0.1633, 0.1652, 0.1552, 0.1394, 0.1023, 0.0343,\n",
      "         0.0002],\n",
      "        [0.0095, 0.0909, 0.1400, 0.1633, 0.1652, 0.1551, 0.1393, 0.1023, 0.0343,\n",
      "         0.0002],\n",
      "        [0.0095, 0.0911, 0.1400, 0.1632, 0.1651, 0.1550, 0.1393, 0.1023, 0.0343,\n",
      "         0.0002],\n",
      "        [0.0096, 0.0912, 0.1400, 0.1632, 0.1650, 0.1550, 0.1392, 0.1023, 0.0343,\n",
      "         0.0002],\n",
      "        [0.0096, 0.0912, 0.1400, 0.1631, 0.1650, 0.1550, 0.1392, 0.1023, 0.0344,\n",
      "         0.0002],\n",
      "        [0.0096, 0.0913, 0.1400, 0.1631, 0.1649, 0.1549, 0.1392, 0.1023, 0.0344,\n",
      "         0.0002]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 16.00, Train Loss: 4.31, Val Loss: 8.87, Train BLEU: 2.90, Val BLEU: 0.21\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数 多数 地震 和 火山 喷发 也 都 发生\n",
      "Reference: most of the earthquakes and volcanoes are in the\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0226, 0.0733, 0.1256, 0.1382, 0.1424, 0.1388, 0.1332, 0.1225, 0.0882,\n",
      "         0.0154],\n",
      "        [0.0101, 0.0564, 0.1294, 0.1500, 0.1574, 0.1511, 0.1417, 0.1241, 0.0742,\n",
      "         0.0056],\n",
      "        [0.0083, 0.0523, 0.1293, 0.1524, 0.1609, 0.1540, 0.1435, 0.1241, 0.0708,\n",
      "         0.0045],\n",
      "        [0.0080, 0.0515, 0.1293, 0.1529, 0.1616, 0.1546, 0.1438, 0.1240, 0.0700,\n",
      "         0.0042],\n",
      "        [0.0080, 0.0515, 0.1295, 0.1530, 0.1617, 0.1546, 0.1438, 0.1240, 0.0699,\n",
      "         0.0042],\n",
      "        [0.0080, 0.0516, 0.1295, 0.1530, 0.1616, 0.1545, 0.1437, 0.1239, 0.0699,\n",
      "         0.0042],\n",
      "        [0.0081, 0.0517, 0.1296, 0.1530, 0.1615, 0.1544, 0.1437, 0.1239, 0.0699,\n",
      "         0.0042],\n",
      "        [0.0081, 0.0518, 0.1296, 0.1529, 0.1615, 0.1544, 0.1436, 0.1239, 0.0699,\n",
      "         0.0042],\n",
      "        [0.0081, 0.0518, 0.1296, 0.1529, 0.1615, 0.1544, 0.1436, 0.1239, 0.0700,\n",
      "         0.0043]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 在 被 跟踪 吗 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: were we being followed ? <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0314, 0.1144, 0.1392, 0.1449, 0.1401, 0.1314, 0.1052, 0.0850, 0.0887,\n",
      "         0.0197],\n",
      "        [0.0165, 0.1143, 0.1543, 0.1641, 0.1556, 0.1407, 0.0996, 0.0717, 0.0754,\n",
      "         0.0079],\n",
      "        [0.0140, 0.1132, 0.1575, 0.1687, 0.1593, 0.1427, 0.0977, 0.0683, 0.0721,\n",
      "         0.0065],\n",
      "        [0.0136, 0.1132, 0.1582, 0.1697, 0.1601, 0.1431, 0.0973, 0.0674, 0.0713,\n",
      "         0.0062],\n",
      "        [0.0136, 0.1134, 0.1583, 0.1698, 0.1601, 0.1431, 0.0973, 0.0673, 0.0711,\n",
      "         0.0061],\n",
      "        [0.0136, 0.1135, 0.1583, 0.1697, 0.1600, 0.1430, 0.0973, 0.0673, 0.0712,\n",
      "         0.0061],\n",
      "        [0.0137, 0.1136, 0.1583, 0.1696, 0.1599, 0.1430, 0.0973, 0.0673, 0.0712,\n",
      "         0.0062],\n",
      "        [0.0137, 0.1136, 0.1582, 0.1695, 0.1598, 0.1429, 0.0974, 0.0674, 0.0712,\n",
      "         0.0062],\n",
      "        [0.0137, 0.1137, 0.1582, 0.1695, 0.1598, 0.1429, 0.0974, 0.0674, 0.0712,\n",
      "         0.0062]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 17.00, Train Loss: 4.21, Val Loss: 9.01, Train BLEU: 3.77, Val BLEU: 0.23\n",
      "Sampling from training predictions...\n",
      "Source: 原来 它 是 海洋 洋中 最长 的 生物 <EOS> <PAD>\n",
      "Reference: this turns out to be the longest creature in\n",
      "Model: <SOS> it &apos;s the <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0227, 0.0825, 0.0975, 0.0964, 0.0862, 0.0921, 0.0810, 0.0420, 0.0015,\n",
      "         0.3982],\n",
      "        [0.0038, 0.0238, 0.0304, 0.0299, 0.0255, 0.0279, 0.0231, 0.0089, 0.0001,\n",
      "         0.8265],\n",
      "        [0.0018, 0.0129, 0.0168, 0.0165, 0.0139, 0.0154, 0.0125, 0.0045, 0.0000,\n",
      "         0.9057],\n",
      "        [0.0011, 0.0083, 0.0107, 0.0105, 0.0088, 0.0098, 0.0079, 0.0028, 0.0000,\n",
      "         0.9401],\n",
      "        [0.0009, 0.0065, 0.0083, 0.0081, 0.0068, 0.0076, 0.0062, 0.0022, 0.0000,\n",
      "         0.9532],\n",
      "        [0.0009, 0.0058, 0.0074, 0.0072, 0.0060, 0.0067, 0.0055, 0.0020, 0.0000,\n",
      "         0.9585],\n",
      "        [0.0008, 0.0055, 0.0069, 0.0068, 0.0057, 0.0063, 0.0052, 0.0019, 0.0000,\n",
      "         0.9608],\n",
      "        [0.0008, 0.0053, 0.0067, 0.0066, 0.0055, 0.0062, 0.0050, 0.0019, 0.0000,\n",
      "         0.9619],\n",
      "        [0.0008, 0.0052, 0.0066, 0.0065, 0.0054, 0.0061, 0.0050, 0.0019, 0.0000,\n",
      "         0.9625]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 她 两年 年前 退休 了 结果 却 把 我家 变成\n",
      "Reference: she retired two years ago , only to turn\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[1.4684e-02, 4.1363e-02, 4.5159e-02, 4.0086e-02, 2.1738e-02, 7.6326e-04,\n",
      "         2.0905e-01, 2.0905e-01, 2.0905e-01, 2.0905e-01],\n",
      "        [1.5525e-03, 6.7593e-03, 7.6588e-03, 6.4262e-03, 2.6557e-03, 3.0247e-05,\n",
      "         2.4373e-01, 2.4373e-01, 2.4373e-01, 2.4373e-01],\n",
      "        [6.7160e-04, 3.2178e-03, 3.6745e-03, 3.0453e-03, 1.1837e-03, 1.0581e-05,\n",
      "         2.4705e-01, 2.4705e-01, 2.4705e-01, 2.4705e-01],\n",
      "        [3.9473e-04, 1.8953e-03, 2.1586e-03, 1.7856e-03, 6.8740e-04, 5.8271e-06,\n",
      "         2.4827e-01, 2.4827e-01, 2.4827e-01, 2.4827e-01],\n",
      "        [3.2191e-04, 1.4911e-03, 1.6883e-03, 1.3997e-03, 5.4635e-04, 4.8812e-06,\n",
      "         2.4864e-01, 2.4864e-01, 2.4864e-01, 2.4864e-01],\n",
      "        [2.9692e-04, 1.3390e-03, 1.5103e-03, 1.2548e-03, 4.9600e-04, 4.6750e-06,\n",
      "         2.4877e-01, 2.4877e-01, 2.4877e-01, 2.4877e-01],\n",
      "        [2.8710e-04, 1.2742e-03, 1.4340e-03, 1.1930e-03, 4.7539e-04, 4.6416e-06,\n",
      "         2.4883e-01, 2.4883e-01, 2.4883e-01, 2.4883e-01],\n",
      "        [2.8204e-04, 1.2408e-03, 1.3946e-03, 1.1610e-03, 4.6478e-04, 4.6319e-06,\n",
      "         2.4886e-01, 2.4886e-01, 2.4886e-01, 2.4886e-01],\n",
      "        [2.8015e-04, 1.2251e-03, 1.3757e-03, 1.1459e-03, 4.6010e-04, 4.6484e-06,\n",
      "         2.4888e-01, 2.4888e-01, 2.4888e-01, 2.4888e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18.00, Train Loss: 4.13, Val Loss: 9.16, Train BLEU: 3.87, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想 海洋 占 了 地球 球面 面积 的 75\n",
      "Reference: when you think about it , the oceans are\n",
      "Model: <SOS> it the the the the the , , ,\n",
      "Attention Weights: tensor([[0.0317, 0.1112, 0.1334, 0.1417, 0.1412, 0.1365, 0.1287, 0.1102, 0.0634,\n",
      "         0.0021],\n",
      "        [0.0198, 0.1077, 0.1387, 0.1509, 0.1504, 0.1435, 0.1323, 0.1065, 0.0496,\n",
      "         0.0006],\n",
      "        [0.0169, 0.1059, 0.1399, 0.1536, 0.1532, 0.1456, 0.1333, 0.1052, 0.0459,\n",
      "         0.0004],\n",
      "        [0.0159, 0.1053, 0.1403, 0.1546, 0.1543, 0.1465, 0.1336, 0.1046, 0.0445,\n",
      "         0.0004],\n",
      "        [0.0157, 0.1053, 0.1405, 0.1548, 0.1545, 0.1466, 0.1337, 0.1045, 0.0441,\n",
      "         0.0004],\n",
      "        [0.0157, 0.1054, 0.1405, 0.1549, 0.1545, 0.1466, 0.1337, 0.1044, 0.0440,\n",
      "         0.0004],\n",
      "        [0.0158, 0.1055, 0.1405, 0.1548, 0.1545, 0.1466, 0.1336, 0.1044, 0.0440,\n",
      "         0.0004],\n",
      "        [0.0158, 0.1056, 0.1405, 0.1548, 0.1544, 0.1465, 0.1336, 0.1044, 0.0440,\n",
      "         0.0004],\n",
      "        [0.0158, 0.1056, 0.1405, 0.1548, 0.1544, 0.1465, 0.1336, 0.1044, 0.0440,\n",
      "         0.0004]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 很 幸运 幸运地 成长 在 一个 珍视 教育 也\n",
      "Reference: i was very lucky to grow up in a\n",
      "Model: <SOS> it the the the the the , , ,\n",
      "Attention Weights: tensor([[6.8787e-03, 1.8499e-02, 1.7716e-02, 9.8301e-03, 3.4219e-04, 1.8935e-01,\n",
      "         1.8935e-01, 1.8935e-01, 1.8935e-01, 1.8935e-01],\n",
      "        [1.2915e-03, 4.8938e-03, 4.6241e-03, 2.0802e-03, 2.8537e-05, 1.9742e-01,\n",
      "         1.9742e-01, 1.9742e-01, 1.9742e-01, 1.9742e-01],\n",
      "        [6.6043e-04, 2.7246e-03, 2.5637e-03, 1.0925e-03, 1.1732e-05, 1.9859e-01,\n",
      "         1.9859e-01, 1.9859e-01, 1.9859e-01, 1.9859e-01],\n",
      "        [4.0830e-04, 1.6982e-03, 1.5921e-03, 6.7019e-04, 6.6101e-06, 1.9912e-01,\n",
      "         1.9912e-01, 1.9912e-01, 1.9912e-01, 1.9912e-01],\n",
      "        [3.2514e-04, 1.3182e-03, 1.2325e-03, 5.2283e-04, 5.2800e-06, 1.9932e-01,\n",
      "         1.9932e-01, 1.9932e-01, 1.9932e-01, 1.9932e-01],\n",
      "        [2.9248e-04, 1.1648e-03, 1.0877e-03, 4.6480e-04, 4.8554e-06, 1.9940e-01,\n",
      "         1.9940e-01, 1.9940e-01, 1.9940e-01, 1.9940e-01],\n",
      "        [2.8065e-04, 1.1026e-03, 1.0290e-03, 4.4251e-04, 4.7641e-06, 1.9943e-01,\n",
      "         1.9943e-01, 1.9943e-01, 1.9943e-01, 1.9943e-01],\n",
      "        [2.7354e-04, 1.0669e-03, 9.9534e-04, 4.2961e-04, 4.7068e-06, 1.9945e-01,\n",
      "         1.9945e-01, 1.9945e-01, 1.9945e-01, 1.9945e-01],\n",
      "        [2.7092e-04, 1.0502e-03, 9.7938e-04, 4.2394e-04, 4.7109e-06, 1.9945e-01,\n",
      "         1.9945e-01, 1.9945e-01, 1.9945e-01, 1.9945e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 19.00, Train Loss: 4.07, Val Loss: 9.31, Train BLEU: 4.00, Val BLEU: 0.34\n",
      "Sampling from training predictions...\n",
      "Source: 它 可以 伸展 <UNK> 150 英尺 长 <EOS> <PAD> <PAD>\n",
      "Reference: it gets up to about 150 feet long .\n",
      "Model: <SOS> it &apos;s the . <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0114, 0.0301, 0.0318, 0.0217, 0.0266, 0.0300, 0.0184, 0.0006, 0.4147,\n",
      "         0.4147],\n",
      "        [0.0045, 0.0155, 0.0168, 0.0104, 0.0133, 0.0154, 0.0082, 0.0001, 0.4579,\n",
      "         0.4579],\n",
      "        [0.0029, 0.0111, 0.0120, 0.0073, 0.0094, 0.0110, 0.0056, 0.0001, 0.4703,\n",
      "         0.4703],\n",
      "        [0.0020, 0.0075, 0.0082, 0.0049, 0.0064, 0.0075, 0.0038, 0.0000, 0.4799,\n",
      "         0.4799],\n",
      "        [0.0016, 0.0059, 0.0064, 0.0039, 0.0050, 0.0058, 0.0029, 0.0000, 0.4843,\n",
      "         0.4843],\n",
      "        [0.0014, 0.0051, 0.0055, 0.0034, 0.0043, 0.0051, 0.0026, 0.0000, 0.4863,\n",
      "         0.4863],\n",
      "        [0.0013, 0.0048, 0.0051, 0.0031, 0.0040, 0.0047, 0.0024, 0.0000, 0.4873,\n",
      "         0.4873],\n",
      "        [0.0013, 0.0046, 0.0049, 0.0030, 0.0039, 0.0045, 0.0023, 0.0000, 0.4877,\n",
      "         0.4877],\n",
      "        [0.0012, 0.0045, 0.0048, 0.0030, 0.0038, 0.0044, 0.0023, 0.0000, 0.4880,\n",
      "         0.4880]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 对 他 来说 孩子 不 接受 受教 教育 <UNK> 是\n",
      "Reference: to him , there was greater risk in not\n",
      "Model: <SOS> it the the the the , , , ,\n",
      "Attention Weights: tensor([[0.0086, 0.0233, 0.0258, 0.0255, 0.0222, 0.0121, 0.0005, 0.2940, 0.2940,\n",
      "         0.2940],\n",
      "        [0.0033, 0.0120, 0.0137, 0.0135, 0.0114, 0.0052, 0.0001, 0.3136, 0.3136,\n",
      "         0.3136],\n",
      "        [0.0022, 0.0085, 0.0098, 0.0096, 0.0080, 0.0035, 0.0001, 0.3194, 0.3194,\n",
      "         0.3194],\n",
      "        [0.0015, 0.0057, 0.0066, 0.0065, 0.0054, 0.0023, 0.0000, 0.3240, 0.3240,\n",
      "         0.3240],\n",
      "        [0.0012, 0.0044, 0.0051, 0.0050, 0.0042, 0.0018, 0.0000, 0.3261, 0.3261,\n",
      "         0.3261],\n",
      "        [0.0010, 0.0038, 0.0044, 0.0044, 0.0036, 0.0016, 0.0000, 0.3271, 0.3271,\n",
      "         0.3271],\n",
      "        [0.0010, 0.0036, 0.0041, 0.0040, 0.0034, 0.0015, 0.0000, 0.3275, 0.3275,\n",
      "         0.3275],\n",
      "        [0.0009, 0.0034, 0.0039, 0.0039, 0.0032, 0.0014, 0.0000, 0.3277, 0.3277,\n",
      "         0.3277],\n",
      "        [0.0009, 0.0033, 0.0038, 0.0038, 0.0031, 0.0014, 0.0000, 0.3279, 0.3279,\n",
      "         0.3279]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 20.00, Train Loss: 4.01, Val Loss: 9.46, Train BLEU: 4.04, Val BLEU: 0.34\n",
      "Sampling from training predictions...\n",
      "Source: 还有 这些 摇晃 着 旋转 转着 的 触角 <EOS> <PAD>\n",
      "Reference: it &apos;s got tentacles dangling , swirling around like\n",
      "Model: <SOS> it &apos;s the . . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0122, 0.0399, 0.0460, 0.0472, 0.0441, 0.0358, 0.0379, 0.0211, 0.0008,\n",
      "         0.7150],\n",
      "        [0.0059, 0.0256, 0.0308, 0.0318, 0.0293, 0.0226, 0.0241, 0.0116, 0.0002,\n",
      "         0.8181],\n",
      "        [0.0046, 0.0217, 0.0264, 0.0273, 0.0251, 0.0191, 0.0204, 0.0094, 0.0002,\n",
      "         0.8458],\n",
      "        [0.0034, 0.0165, 0.0201, 0.0208, 0.0191, 0.0145, 0.0155, 0.0070, 0.0001,\n",
      "         0.8832],\n",
      "        [0.0028, 0.0132, 0.0160, 0.0166, 0.0153, 0.0116, 0.0125, 0.0057, 0.0001,\n",
      "         0.9062],\n",
      "        [0.0024, 0.0114, 0.0138, 0.0142, 0.0131, 0.0100, 0.0107, 0.0049, 0.0001,\n",
      "         0.9194],\n",
      "        [0.0022, 0.0105, 0.0126, 0.0131, 0.0120, 0.0092, 0.0099, 0.0045, 0.0001,\n",
      "         0.9260],\n",
      "        [0.0022, 0.0100, 0.0120, 0.0124, 0.0114, 0.0088, 0.0094, 0.0043, 0.0001,\n",
      "         0.9294],\n",
      "        [0.0021, 0.0097, 0.0117, 0.0121, 0.0111, 0.0085, 0.0091, 0.0042, 0.0001,\n",
      "         0.9313]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班 走 了 父亲 大声 叫 着 <EOS> <PAD>\n",
      "Reference: &quot; the taliban are gone ! &quot; my father\n",
      "Model: <SOS> it &apos;s the . <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0361, 0.1135, 0.1291, 0.1318, 0.1317, 0.1290, 0.1228, 0.1105, 0.0800,\n",
      "         0.0157],\n",
      "        [0.0269, 0.1129, 0.1337, 0.1374, 0.1373, 0.1338, 0.1257, 0.1099, 0.0727,\n",
      "         0.0096],\n",
      "        [0.0240, 0.1122, 0.1352, 0.1394, 0.1394, 0.1355, 0.1266, 0.1095, 0.0701,\n",
      "         0.0081],\n",
      "        [0.0224, 0.1118, 0.1359, 0.1404, 0.1404, 0.1364, 0.1272, 0.1093, 0.0688,\n",
      "         0.0074],\n",
      "        [0.0221, 0.1119, 0.1361, 0.1407, 0.1407, 0.1367, 0.1273, 0.1092, 0.0683,\n",
      "         0.0071],\n",
      "        [0.0220, 0.1119, 0.1361, 0.1407, 0.1407, 0.1367, 0.1273, 0.1092, 0.0682,\n",
      "         0.0070],\n",
      "        [0.0220, 0.1120, 0.1362, 0.1407, 0.1407, 0.1367, 0.1273, 0.1092, 0.0681,\n",
      "         0.0070],\n",
      "        [0.0220, 0.1121, 0.1362, 0.1407, 0.1407, 0.1367, 0.1273, 0.1092, 0.0681,\n",
      "         0.0070],\n",
      "        [0.0220, 0.1121, 0.1361, 0.1407, 0.1407, 0.1367, 0.1273, 0.1092, 0.0681,\n",
      "         0.0070]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 21.00, Train Loss: 3.97, Val Loss: 9.61, Train BLEU: 3.98, Val BLEU: 0.33\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中 的 生命 大卫 <UNK> <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: life in the deep oceans <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the . . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0102, 0.0301, 0.0338, 0.0310, 0.0225, 0.0039, 0.0004, 0.2894, 0.2894,\n",
      "         0.2894],\n",
      "        [0.0065, 0.0243, 0.0282, 0.0255, 0.0173, 0.0022, 0.0001, 0.2987, 0.2987,\n",
      "         0.2987],\n",
      "        [0.0055, 0.0222, 0.0260, 0.0234, 0.0156, 0.0018, 0.0001, 0.3018, 0.3018,\n",
      "         0.3018],\n",
      "        [0.0040, 0.0164, 0.0192, 0.0173, 0.0115, 0.0012, 0.0001, 0.3101, 0.3101,\n",
      "         0.3101],\n",
      "        [0.0030, 0.0124, 0.0145, 0.0130, 0.0086, 0.0009, 0.0000, 0.3158, 0.3158,\n",
      "         0.3158],\n",
      "        [0.0025, 0.0103, 0.0120, 0.0108, 0.0072, 0.0008, 0.0000, 0.3188, 0.3188,\n",
      "         0.3188],\n",
      "        [0.0023, 0.0092, 0.0107, 0.0097, 0.0064, 0.0007, 0.0000, 0.3203, 0.3203,\n",
      "         0.3203],\n",
      "        [0.0022, 0.0087, 0.0101, 0.0091, 0.0061, 0.0007, 0.0000, 0.3210, 0.3210,\n",
      "         0.3210],\n",
      "        [0.0021, 0.0084, 0.0098, 0.0088, 0.0059, 0.0006, 0.0000, 0.3215, 0.3215,\n",
      "         0.3215]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他们 知道 我们 的 住处 吗 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: do they know where we live ? <EOS> <PAD>\n",
      "Model: <SOS> it &apos;s the . . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[2.3130e-05, 8.9473e-04, 3.9570e-03, 2.0904e-02, 1.2038e-01, 2.2681e-01,\n",
      "         2.2718e-01, 2.0605e-01, 1.5836e-01, 3.5437e-02],\n",
      "        [7.8095e-06, 3.6313e-04, 1.9131e-03, 1.3138e-02, 1.0775e-01, 2.4059e-01,\n",
      "         2.4312e-01, 2.1552e-01, 1.5393e-01, 2.3673e-02],\n",
      "        [5.2589e-06, 2.6509e-04, 1.4974e-03, 1.1249e-02, 1.0360e-01, 2.4487e-01,\n",
      "         2.4817e-01, 2.1806e-01, 1.5169e-01, 2.0599e-02],\n",
      "        [4.1238e-06, 2.2086e-04, 1.3025e-03, 1.0352e-02, 1.0187e-01, 2.4688e-01,\n",
      "         2.5032e-01, 2.1910e-01, 1.5070e-01, 1.9245e-02],\n",
      "        [3.7318e-06, 2.0578e-04, 1.2354e-03, 1.0055e-02, 1.0157e-01, 2.4764e-01,\n",
      "         2.5091e-01, 2.1931e-01, 1.5028e-01, 1.8784e-02],\n",
      "        [3.5461e-06, 1.9893e-04, 1.2056e-03, 9.9338e-03, 1.0156e-01, 2.4798e-01,\n",
      "         2.5110e-01, 2.1935e-01, 1.5008e-01, 1.8583e-02],\n",
      "        [3.4305e-06, 1.9487e-04, 1.1885e-03, 9.8693e-03, 1.0158e-01, 2.4814e-01,\n",
      "         2.5116e-01, 2.1937e-01, 1.5001e-01, 1.8483e-02],\n",
      "        [3.3795e-06, 1.9331e-04, 1.1827e-03, 9.8559e-03, 1.0165e-01, 2.4818e-01,\n",
      "         2.5114e-01, 2.1934e-01, 1.5000e-01, 1.8459e-02],\n",
      "        [3.3363e-06, 1.9196e-04, 1.1776e-03, 9.8406e-03, 1.0168e-01, 2.4819e-01,\n",
      "         2.5113e-01, 2.1934e-01, 1.5001e-01, 1.8441e-02]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22.00, Train Loss: 3.94, Val Loss: 9.74, Train BLEU: 3.80, Val BLEU: 0.32\n",
      "Sampling from training predictions...\n",
      "Source: 还有 前面 的 这个 是 推进 引擎 它 一会 一会儿\n",
      "Reference: and it &apos;s got these jet thrusters up in\n",
      "Model: <SOS> it the the the the the , , ,\n",
      "Attention Weights: tensor([[0.0410, 0.1239, 0.1423, 0.1457, 0.1464, 0.1410, 0.1294, 0.1028, 0.0266,\n",
      "         0.0009],\n",
      "        [0.0317, 0.1231, 0.1472, 0.1518, 0.1527, 0.1457, 0.1308, 0.0980, 0.0187,\n",
      "         0.0004],\n",
      "        [0.0287, 0.1224, 0.1487, 0.1539, 0.1549, 0.1473, 0.1311, 0.0962, 0.0165,\n",
      "         0.0003],\n",
      "        [0.0269, 0.1220, 0.1496, 0.1552, 0.1562, 0.1483, 0.1314, 0.0950, 0.0151,\n",
      "         0.0002],\n",
      "        [0.0264, 0.1221, 0.1499, 0.1555, 0.1566, 0.1486, 0.1314, 0.0946, 0.0147,\n",
      "         0.0002],\n",
      "        [0.0263, 0.1222, 0.1500, 0.1556, 0.1567, 0.1486, 0.1314, 0.0944, 0.0145,\n",
      "         0.0002],\n",
      "        [0.0263, 0.1222, 0.1500, 0.1556, 0.1567, 0.1487, 0.1314, 0.0944, 0.0144,\n",
      "         0.0002],\n",
      "        [0.0263, 0.1223, 0.1500, 0.1556, 0.1567, 0.1487, 0.1314, 0.0944, 0.0144,\n",
      "         0.0002],\n",
      "        [0.0263, 0.1223, 0.1500, 0.1556, 0.1567, 0.1486, 0.1315, 0.0944, 0.0144,\n",
      "         0.0002]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很 舒服 但 夏天 却 <UNK> <EOS> <PAD> <PAD>\n",
      "Reference: it was cozy in winter but extremely hot in\n",
      "Model: <SOS> it &apos;s the . . . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0377, 0.1145, 0.1274, 0.1317, 0.1291, 0.1190, 0.1225, 0.1111, 0.0852,\n",
      "         0.0216],\n",
      "        [0.0292, 0.1147, 0.1320, 0.1377, 0.1343, 0.1215, 0.1256, 0.1109, 0.0795,\n",
      "         0.0147],\n",
      "        [0.0264, 0.1144, 0.1334, 0.1397, 0.1361, 0.1222, 0.1266, 0.1108, 0.0775,\n",
      "         0.0129],\n",
      "        [0.0248, 0.1142, 0.1341, 0.1408, 0.1370, 0.1226, 0.1273, 0.1109, 0.0765,\n",
      "         0.0119],\n",
      "        [0.0244, 0.1143, 0.1343, 0.1411, 0.1372, 0.1228, 0.1275, 0.1109, 0.0761,\n",
      "         0.0115],\n",
      "        [0.0243, 0.1144, 0.1343, 0.1412, 0.1373, 0.1228, 0.1276, 0.1109, 0.0759,\n",
      "         0.0114],\n",
      "        [0.0243, 0.1144, 0.1343, 0.1412, 0.1373, 0.1228, 0.1276, 0.1109, 0.0759,\n",
      "         0.0113],\n",
      "        [0.0243, 0.1145, 0.1343, 0.1412, 0.1373, 0.1228, 0.1276, 0.1109, 0.0759,\n",
      "         0.0113],\n",
      "        [0.0243, 0.1145, 0.1343, 0.1411, 0.1372, 0.1228, 0.1277, 0.1109, 0.0759,\n",
      "         0.0113]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 23.00, Train Loss: 3.91, Val Loss: 9.88, Train BLEU: 3.79, Val BLEU: 0.32\n",
      "Sampling from training predictions...\n",
      "Source: 是 我 最 喜欢 的 因为 它 哪 都 能动\n",
      "Reference: it &apos;s one of my favorites , because it\n",
      "Model: <SOS> it the the the the the , , ,\n",
      "Attention Weights: tensor([[0.0501, 0.1182, 0.1316, 0.1345, 0.1353, 0.1313, 0.1250, 0.1090, 0.0640,\n",
      "         0.0012],\n",
      "        [0.0398, 0.1182, 0.1364, 0.1403, 0.1412, 0.1359, 0.1274, 0.1066, 0.0538,\n",
      "         0.0005],\n",
      "        [0.0367, 0.1178, 0.1378, 0.1421, 0.1432, 0.1373, 0.1281, 0.1058, 0.0509,\n",
      "         0.0004],\n",
      "        [0.0348, 0.1176, 0.1385, 0.1431, 0.1443, 0.1383, 0.1286, 0.1054, 0.0491,\n",
      "         0.0003],\n",
      "        [0.0345, 0.1176, 0.1387, 0.1434, 0.1446, 0.1385, 0.1287, 0.1052, 0.0485,\n",
      "         0.0003],\n",
      "        [0.0344, 0.1177, 0.1387, 0.1435, 0.1447, 0.1386, 0.1288, 0.1051, 0.0482,\n",
      "         0.0003],\n",
      "        [0.0344, 0.1178, 0.1388, 0.1435, 0.1448, 0.1386, 0.1288, 0.1051, 0.0481,\n",
      "         0.0003],\n",
      "        [0.0344, 0.1178, 0.1388, 0.1435, 0.1448, 0.1386, 0.1288, 0.1051, 0.0481,\n",
      "         0.0003],\n",
      "        [0.0344, 0.1178, 0.1387, 0.1435, 0.1447, 0.1386, 0.1288, 0.1051, 0.0481,\n",
      "         0.0003]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 那 就是 她 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: there she is . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the . . . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0039, 0.0111, 0.0125, 0.0128, 0.0125, 0.0118, 0.0104, 0.0067, 0.0003,\n",
      "         0.9181],\n",
      "        [0.0009, 0.0034, 0.0039, 0.0041, 0.0040, 0.0037, 0.0032, 0.0018, 0.0000,\n",
      "         0.9750],\n",
      "        [0.0007, 0.0028, 0.0033, 0.0034, 0.0033, 0.0031, 0.0026, 0.0014, 0.0000,\n",
      "         0.9792],\n",
      "        [0.0005, 0.0021, 0.0024, 0.0025, 0.0025, 0.0023, 0.0019, 0.0011, 0.0000,\n",
      "         0.9847],\n",
      "        [0.0004, 0.0016, 0.0019, 0.0020, 0.0019, 0.0018, 0.0015, 0.0008, 0.0000,\n",
      "         0.9879],\n",
      "        [0.0004, 0.0014, 0.0017, 0.0017, 0.0017, 0.0016, 0.0013, 0.0007, 0.0000,\n",
      "         0.9895],\n",
      "        [0.0004, 0.0013, 0.0016, 0.0016, 0.0016, 0.0015, 0.0012, 0.0007, 0.0000,\n",
      "         0.9902],\n",
      "        [0.0003, 0.0013, 0.0015, 0.0016, 0.0015, 0.0014, 0.0012, 0.0007, 0.0000,\n",
      "         0.9905],\n",
      "        [0.0003, 0.0013, 0.0015, 0.0015, 0.0015, 0.0014, 0.0012, 0.0007, 0.0000,\n",
      "         0.9906]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 24.00, Train Loss: 3.87, Val Loss: 10.01, Train BLEU: 3.79, Val BLEU: 0.32\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的 平均 深度 是 两英里 英里 <EOS> <PAD> <PAD>\n",
      "Reference: the average depth is about two miles . <EOS>\n",
      "Model: <SOS> it &apos;s the . . . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.2827e-03, 3.4548e-03, 3.7555e-03, 3.7720e-03, 3.5338e-03, 2.5773e-03,\n",
      "         1.8102e-03, 7.5774e-05, 4.8987e-01, 4.8987e-01],\n",
      "        [1.8363e-04, 6.4373e-04, 7.2034e-04, 7.2437e-04, 6.6605e-04, 4.4768e-04,\n",
      "         2.8377e-04, 6.1598e-06, 4.9816e-01, 4.9816e-01],\n",
      "        [1.2829e-04, 4.8583e-04, 5.4766e-04, 5.5059e-04, 5.0356e-04, 3.3099e-04,\n",
      "         2.0402e-04, 3.5601e-06, 4.9862e-01, 4.9862e-01],\n",
      "        [9.2570e-05, 3.5815e-04, 4.0314e-04, 4.0507e-04, 3.6993e-04, 2.4093e-04,\n",
      "         1.4750e-04, 2.2495e-06, 4.9899e-01, 4.9899e-01],\n",
      "        [7.6206e-05, 2.9046e-04, 3.2568e-04, 3.2715e-04, 2.9898e-04, 1.9471e-04,\n",
      "         1.1955e-04, 1.7867e-06, 4.9918e-01, 4.9918e-01],\n",
      "        [6.8658e-05, 2.5630e-04, 2.8627e-04, 2.8744e-04, 2.6294e-04, 1.7184e-04,\n",
      "         1.0606e-04, 1.6346e-06, 4.9928e-01, 4.9928e-01],\n",
      "        [6.5887e-05, 2.4189e-04, 2.6940e-04, 2.7040e-04, 2.4751e-04, 1.6234e-04,\n",
      "         1.0068e-04, 1.6090e-06, 4.9932e-01, 4.9932e-01],\n",
      "        [6.5079e-05, 2.3637e-04, 2.6276e-04, 2.6364e-04, 2.4141e-04, 1.5872e-04,\n",
      "         9.8760e-05, 1.6168e-06, 4.9934e-01, 4.9934e-01],\n",
      "        [6.4904e-05, 2.3428e-04, 2.6016e-04, 2.6097e-04, 2.3902e-04, 1.5737e-04,\n",
      "         9.8116e-05, 1.6286e-06, 4.9934e-01, 4.9934e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 出身 阿富汗 边远 <UNK> 地区 有着 与 他人 不同\n",
      "Reference: a total maverick from a remote province of afghanistan\n",
      "Model: <SOS> it the the the the the the , ,\n",
      "Attention Weights: tensor([[2.5708e-03, 6.8231e-03, 7.4910e-03, 7.4359e-03, 6.9198e-03, 7.0715e-03,\n",
      "         6.2357e-03, 3.7459e-03, 1.7259e-04, 9.5153e-01],\n",
      "        [3.7868e-04, 1.3045e-03, 1.4792e-03, 1.4671e-03, 1.3373e-03, 1.3718e-03,\n",
      "         1.1667e-03, 6.0805e-04, 1.4657e-05, 9.9087e-01],\n",
      "        [2.6812e-04, 9.9617e-04, 1.1380e-03, 1.1270e-03, 1.0201e-03, 1.0512e-03,\n",
      "         8.8543e-04, 4.4392e-04, 8.6462e-06, 9.9306e-01],\n",
      "        [1.9449e-04, 7.3731e-04, 8.4077e-04, 8.3108e-04, 7.4949e-04, 7.7674e-04,\n",
      "         6.5306e-04, 3.2277e-04, 5.5152e-06, 9.9489e-01],\n",
      "        [1.5996e-04, 5.9728e-04, 6.7825e-04, 6.6998e-04, 6.0423e-04, 6.2754e-04,\n",
      "         5.2843e-04, 2.6139e-04, 4.3786e-06, 9.9587e-01],\n",
      "        [1.4385e-04, 5.2621e-04, 5.9502e-04, 5.8751e-04, 5.3056e-04, 5.5127e-04,\n",
      "         4.6507e-04, 2.3143e-04, 3.9957e-06, 9.9637e-01],\n",
      "        [1.3804e-04, 4.9660e-04, 5.5974e-04, 5.5249e-04, 4.9949e-04, 5.1900e-04,\n",
      "         4.3852e-04, 2.1956e-04, 3.9295e-06, 9.9657e-01],\n",
      "        [1.3609e-04, 4.8444e-04, 5.4493e-04, 5.3773e-04, 4.8647e-04, 5.0545e-04,\n",
      "         4.2749e-04, 2.1493e-04, 3.9402e-06, 9.9666e-01],\n",
      "        [1.3581e-04, 4.8038e-04, 5.3970e-04, 5.3248e-04, 4.8191e-04, 5.0068e-04,\n",
      "         4.2370e-04, 2.1356e-04, 3.9696e-06, 9.9669e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 25.00, Train Loss: 3.85, Val Loss: 10.14, Train BLEU: 3.50, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 是 我 最 喜欢 的 因为 它 哪 都 能动\n",
      "Reference: it &apos;s one of my favorites , because it\n",
      "Model: <SOS> it the the the the the , , ,\n",
      "Attention Weights: tensor([[0.0556, 0.1171, 0.1299, 0.1333, 0.1344, 0.1305, 0.1242, 0.1083, 0.0655,\n",
      "         0.0013],\n",
      "        [0.0440, 0.1170, 0.1351, 0.1399, 0.1412, 0.1358, 0.1268, 0.1055, 0.0541,\n",
      "         0.0005],\n",
      "        [0.0406, 0.1167, 0.1365, 0.1418, 0.1432, 0.1373, 0.1276, 0.1047, 0.0511,\n",
      "         0.0004],\n",
      "        [0.0387, 0.1164, 0.1373, 0.1429, 0.1445, 0.1383, 0.1282, 0.1043, 0.0492,\n",
      "         0.0003],\n",
      "        [0.0383, 0.1165, 0.1376, 0.1432, 0.1448, 0.1385, 0.1283, 0.1040, 0.0485,\n",
      "         0.0003],\n",
      "        [0.0382, 0.1166, 0.1377, 0.1433, 0.1450, 0.1386, 0.1283, 0.1039, 0.0481,\n",
      "         0.0003],\n",
      "        [0.0382, 0.1167, 0.1377, 0.1433, 0.1450, 0.1386, 0.1283, 0.1039, 0.0480,\n",
      "         0.0003],\n",
      "        [0.0383, 0.1168, 0.1377, 0.1433, 0.1450, 0.1386, 0.1283, 0.1038, 0.0480,\n",
      "         0.0003],\n",
      "        [0.0383, 0.1168, 0.1377, 0.1433, 0.1450, 0.1386, 0.1283, 0.1038, 0.0480,\n",
      "         0.0003]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6 岁 那年 塔利 塔利班 占领 阿富汗 并 规定\n",
      "Reference: you see , i was six when the taliban\n",
      "Model: <SOS> it the the the the the the , ,\n",
      "Attention Weights: tensor([[1.8915e-03, 4.7882e-03, 5.2128e-03, 5.3206e-03, 5.3371e-03, 5.1224e-03,\n",
      "         4.4566e-03, 2.7179e-03, 1.3502e-04, 9.6502e-01],\n",
      "        [1.8126e-04, 5.9936e-04, 6.7430e-04, 6.9304e-04, 6.9506e-04, 6.5791e-04,\n",
      "         5.4815e-04, 2.8830e-04, 7.3506e-06, 9.9566e-01],\n",
      "        [1.1622e-04, 4.1626e-04, 4.7225e-04, 4.8597e-04, 4.8710e-04, 4.5929e-04,\n",
      "         3.7841e-04, 1.9116e-04, 3.9349e-06, 9.9699e-01],\n",
      "        [8.2061e-05, 3.0270e-04, 3.4325e-04, 3.5326e-04, 3.5425e-04, 3.3384e-04,\n",
      "         2.7395e-04, 1.3579e-04, 2.4221e-06, 9.9782e-01],\n",
      "        [6.7829e-05, 2.4803e-04, 2.8034e-04, 2.8845e-04, 2.8945e-04, 2.7301e-04,\n",
      "         2.2414e-04, 1.1083e-04, 1.9070e-06, 9.9822e-01],\n",
      "        [6.1916e-05, 2.2152e-04, 2.4931e-04, 2.5638e-04, 2.5737e-04, 2.4300e-04,\n",
      "         1.9989e-04, 9.9379e-05, 1.7547e-06, 9.9841e-01],\n",
      "        [6.0296e-05, 2.1126e-04, 2.3688e-04, 2.4346e-04, 2.4443e-04, 2.3096e-04,\n",
      "         1.9039e-04, 9.5388e-05, 1.7579e-06, 9.9849e-01],\n",
      "        [5.9790e-05, 2.0667e-04, 2.3120e-04, 2.3753e-04, 2.3848e-04, 2.2543e-04,\n",
      "         1.8612e-04, 9.3775e-05, 1.7830e-06, 9.9852e-01],\n",
      "        [5.9956e-05, 2.0552e-04, 2.2960e-04, 2.3582e-04, 2.3675e-04, 2.2386e-04,\n",
      "         1.8499e-04, 9.3536e-05, 1.8118e-06, 9.9853e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26.00, Train Loss: 3.82, Val Loss: 10.25, Train BLEU: 3.80, Val BLEU: 0.34\n",
      "Sampling from training predictions...\n",
      "Source: 看到 这些 在 动 的 东西 了 吗 <EOS> <PAD>\n",
      "Reference: but see all those different working things ? <EOS>\n",
      "Model: <SOS> it &apos;s the the . . . <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.5734e-03, 3.7128e-03, 4.1322e-03, 4.2524e-03, 4.1891e-03, 3.9472e-03,\n",
      "         3.4992e-03, 2.3120e-03, 1.2193e-04, 9.7226e-01],\n",
      "        [1.0340e-04, 3.1791e-04, 3.6921e-04, 3.8391e-04, 3.7604e-04, 3.4749e-04,\n",
      "         2.9564e-04, 1.7040e-04, 4.4887e-06, 9.9763e-01],\n",
      "        [5.9713e-05, 1.9892e-04, 2.3344e-04, 2.4316e-04, 2.3775e-04, 2.1863e-04,\n",
      "         1.8403e-04, 1.0228e-04, 2.1710e-06, 9.9852e-01],\n",
      "        [4.0569e-05, 1.3986e-04, 1.6434e-04, 1.7121e-04, 1.6730e-04, 1.5357e-04,\n",
      "         1.2877e-04, 7.0232e-05, 1.2760e-06, 9.9896e-01],\n",
      "        [3.3658e-05, 1.1556e-04, 1.3547e-04, 1.4109e-04, 1.3788e-04, 1.2659e-04,\n",
      "         1.0618e-04, 5.7709e-05, 9.9983e-07, 9.9914e-01],\n",
      "        [3.0951e-05, 1.0416e-04, 1.2156e-04, 1.2651e-04, 1.2366e-04, 1.1365e-04,\n",
      "         9.5484e-05, 5.2101e-05, 9.2091e-07, 9.9923e-01],\n",
      "        [3.0500e-05, 1.0042e-04, 1.1667e-04, 1.2131e-04, 1.1860e-04, 1.0913e-04,\n",
      "         9.1885e-05, 5.0497e-05, 9.3533e-07, 9.9926e-01],\n",
      "        [3.0615e-05, 9.9234e-05, 1.1494e-04, 1.1943e-04, 1.1679e-04, 1.0755e-04,\n",
      "         9.0707e-05, 5.0141e-05, 9.6433e-07, 9.9927e-01],\n",
      "        [3.0867e-05, 9.9115e-05, 1.1459e-04, 1.1902e-04, 1.1640e-04, 1.0726e-04,\n",
      "         9.0549e-05, 5.0239e-05, 9.8848e-07, 9.9927e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 因此 毫无 毫无疑问 无疑 疑问 他 的 孩子 应当 受到\n",
      "Reference: there was no question that his children would receive\n",
      "Model: <SOS> we the the the the the the , ,\n",
      "Attention Weights: tensor([[1.5378e-03, 3.6758e-03, 4.0576e-03, 4.1660e-03, 3.9299e-03, 3.2129e-03,\n",
      "         3.4125e-03, 2.0919e-03, 1.0339e-04, 9.7381e-01],\n",
      "        [1.0146e-04, 3.1645e-04, 3.6355e-04, 3.7683e-04, 3.4934e-04, 2.7034e-04,\n",
      "         2.8844e-04, 1.5103e-04, 3.7376e-06, 9.9778e-01],\n",
      "        [5.8409e-05, 1.9753e-04, 2.2923e-04, 2.3791e-04, 2.1947e-04, 1.6729e-04,\n",
      "         1.7907e-04, 8.9836e-05, 1.7878e-06, 9.9862e-01],\n",
      "        [3.9527e-05, 1.3838e-04, 1.6068e-04, 1.6679e-04, 1.5337e-04, 1.1603e-04,\n",
      "         1.2477e-04, 6.1142e-05, 1.0391e-06, 9.9904e-01],\n",
      "        [3.3245e-05, 1.1549e-04, 1.3363e-04, 1.3866e-04, 1.2746e-04, 9.6400e-05,\n",
      "         1.0391e-04, 5.0742e-05, 8.2430e-07, 9.9920e-01],\n",
      "        [3.0386e-05, 1.0343e-04, 1.1915e-04, 1.2351e-04, 1.1361e-04, 8.6212e-05,\n",
      "         9.2914e-05, 4.5572e-05, 7.5751e-07, 9.9928e-01],\n",
      "        [2.9998e-05, 9.9908e-05, 1.1460e-04, 1.1868e-04, 1.0925e-04, 8.3260e-05,\n",
      "         8.9657e-05, 4.4341e-05, 7.7281e-07, 9.9931e-01],\n",
      "        [3.0143e-05, 9.8893e-05, 1.1312e-04, 1.1706e-04, 1.0784e-04, 8.2421e-05,\n",
      "         8.8695e-05, 4.4151e-05, 7.9771e-07, 9.9932e-01],\n",
      "        [3.0238e-05, 9.8364e-05, 1.1235e-04, 1.1621e-04, 1.0710e-04, 8.2002e-05,\n",
      "         8.8210e-05, 4.4086e-05, 8.1362e-07, 9.9932e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 27.00, Train Loss: 3.80, Val Loss: 10.36, Train BLEU: 3.85, Val BLEU: 0.34\n",
      "Sampling from training predictions...\n",
      "Source: 但 我 想 告诉 你 的 是 当 你 站\n",
      "Reference: but when you &apos;re standing at the beach ,\n",
      "Model: <SOS> we the the the the the the , ,\n",
      "Attention Weights: tensor([[0.0580, 0.1101, 0.1219, 0.1261, 0.1273, 0.1245, 0.1186, 0.1068, 0.0822,\n",
      "         0.0244],\n",
      "        [0.0467, 0.1102, 0.1272, 0.1333, 0.1348, 0.1306, 0.1221, 0.1059, 0.0741,\n",
      "         0.0150],\n",
      "        [0.0434, 0.1099, 0.1285, 0.1352, 0.1368, 0.1322, 0.1231, 0.1056, 0.0721,\n",
      "         0.0132],\n",
      "        [0.0416, 0.1096, 0.1291, 0.1362, 0.1380, 0.1332, 0.1237, 0.1056, 0.0709,\n",
      "         0.0121],\n",
      "        [0.0412, 0.1098, 0.1295, 0.1366, 0.1383, 0.1335, 0.1238, 0.1054, 0.0703,\n",
      "         0.0116],\n",
      "        [0.0411, 0.1100, 0.1296, 0.1367, 0.1385, 0.1336, 0.1238, 0.1053, 0.0700,\n",
      "         0.0114],\n",
      "        [0.0411, 0.1100, 0.1297, 0.1367, 0.1385, 0.1336, 0.1238, 0.1053, 0.0699,\n",
      "         0.0114],\n",
      "        [0.0411, 0.1101, 0.1297, 0.1367, 0.1385, 0.1336, 0.1238, 0.1052, 0.0699,\n",
      "         0.0113],\n",
      "        [0.0411, 0.1101, 0.1297, 0.1367, 0.1385, 0.1336, 0.1238, 0.1052, 0.0699,\n",
      "         0.0113]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很 舒服 但 夏天 却 <UNK> <EOS> <PAD> <PAD>\n",
      "Reference: it was cozy in winter but extremely hot in\n",
      "Model: <SOS> it &apos;s the . . . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0500, 0.1140, 0.1244, 0.1296, 0.1274, 0.1178, 0.1205, 0.1084, 0.0834,\n",
      "         0.0244],\n",
      "        [0.0385, 0.1147, 0.1303, 0.1377, 0.1346, 0.1213, 0.1245, 0.1078, 0.0755,\n",
      "         0.0150],\n",
      "        [0.0353, 0.1146, 0.1318, 0.1400, 0.1366, 0.1222, 0.1255, 0.1076, 0.0734,\n",
      "         0.0132],\n",
      "        [0.0335, 0.1145, 0.1325, 0.1412, 0.1376, 0.1224, 0.1263, 0.1076, 0.0723,\n",
      "         0.0121],\n",
      "        [0.0331, 0.1147, 0.1329, 0.1417, 0.1379, 0.1224, 0.1265, 0.1075, 0.0718,\n",
      "         0.0117],\n",
      "        [0.0330, 0.1149, 0.1331, 0.1418, 0.1380, 0.1223, 0.1265, 0.1074, 0.0715,\n",
      "         0.0115],\n",
      "        [0.0330, 0.1151, 0.1332, 0.1419, 0.1380, 0.1222, 0.1265, 0.1074, 0.0714,\n",
      "         0.0114],\n",
      "        [0.0330, 0.1151, 0.1332, 0.1419, 0.1380, 0.1222, 0.1266, 0.1074, 0.0714,\n",
      "         0.0113],\n",
      "        [0.0330, 0.1152, 0.1332, 0.1419, 0.1379, 0.1222, 0.1265, 0.1074, 0.0714,\n",
      "         0.0113]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 28.00, Train Loss: 3.77, Val Loss: 10.46, Train BLEU: 4.03, Val BLEU: 0.35\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分 部分 的 动物 也 都 生活 在 海洋\n",
      "Reference: most of the animals are in the oceans .\n",
      "Model: <SOS> we the the the the the , , ,\n",
      "Attention Weights: tensor([[0.0500, 0.1093, 0.1234, 0.1293, 0.1283, 0.1273, 0.1212, 0.1081, 0.0823,\n",
      "         0.0207],\n",
      "        [0.0380, 0.1080, 0.1286, 0.1372, 0.1360, 0.1341, 0.1252, 0.1071, 0.0737,\n",
      "         0.0121],\n",
      "        [0.0347, 0.1073, 0.1298, 0.1392, 0.1380, 0.1359, 0.1262, 0.1069, 0.0716,\n",
      "         0.0104],\n",
      "        [0.0330, 0.1067, 0.1304, 0.1403, 0.1390, 0.1370, 0.1269, 0.1068, 0.0704,\n",
      "         0.0095],\n",
      "        [0.0326, 0.1068, 0.1308, 0.1408, 0.1394, 0.1373, 0.1270, 0.1065, 0.0697,\n",
      "         0.0091],\n",
      "        [0.0325, 0.1070, 0.1309, 0.1410, 0.1395, 0.1374, 0.1271, 0.1064, 0.0694,\n",
      "         0.0089],\n",
      "        [0.0325, 0.1071, 0.1310, 0.1410, 0.1396, 0.1374, 0.1271, 0.1064, 0.0693,\n",
      "         0.0088],\n",
      "        [0.0325, 0.1071, 0.1310, 0.1410, 0.1396, 0.1374, 0.1270, 0.1063, 0.0692,\n",
      "         0.0088],\n",
      "        [0.0325, 0.1072, 0.1310, 0.1410, 0.1396, 0.1374, 0.1270, 0.1063, 0.0692,\n",
      "         0.0088]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 那 就是 她 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: there she is . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the . . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.1997e-03, 2.5603e-03, 2.8409e-03, 2.9238e-03, 2.8785e-03, 2.7072e-03,\n",
      "         2.3969e-03, 1.5968e-03, 9.0823e-05, 9.8081e-01],\n",
      "        [4.3245e-05, 1.1980e-04, 1.3913e-04, 1.4486e-04, 1.4170e-04, 1.3039e-04,\n",
      "         1.1027e-04, 6.3478e-05, 1.7610e-06, 9.9911e-01],\n",
      "        [1.9710e-05, 5.9355e-05, 6.9749e-05, 7.2786e-05, 7.1065e-05, 6.5014e-05,\n",
      "         5.4305e-05, 3.0013e-05, 6.6424e-07, 9.9956e-01],\n",
      "        [1.2353e-05, 3.8509e-05, 4.5327e-05, 4.7309e-05, 4.6157e-05, 4.2132e-05,\n",
      "         3.5028e-05, 1.8933e-05, 3.5417e-07, 9.9971e-01],\n",
      "        [1.0192e-05, 3.1669e-05, 3.7189e-05, 3.8796e-05, 3.7847e-05, 3.4546e-05,\n",
      "         2.8717e-05, 1.5435e-05, 2.7384e-07, 9.9977e-01],\n",
      "        [9.9177e-06, 3.0055e-05, 3.5098e-05, 3.6569e-05, 3.5677e-05, 3.2607e-05,\n",
      "         2.7171e-05, 1.4702e-05, 2.7100e-07, 9.9978e-01],\n",
      "        [1.0199e-05, 3.0137e-05, 3.5022e-05, 3.6446e-05, 3.5566e-05, 3.2555e-05,\n",
      "         2.7206e-05, 1.4870e-05, 2.9159e-07, 9.9978e-01],\n",
      "        [1.0428e-05, 3.0351e-05, 3.5173e-05, 3.6580e-05, 3.5703e-05, 3.2711e-05,\n",
      "         2.7387e-05, 1.5068e-05, 3.0725e-07, 9.9978e-01],\n",
      "        [1.0586e-05, 3.0577e-05, 3.5384e-05, 3.6789e-05, 3.5910e-05, 3.2918e-05,\n",
      "         2.7587e-05, 1.5230e-05, 3.1659e-07, 9.9977e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 29.00, Train Loss: 3.75, Val Loss: 10.56, Train BLEU: 4.06, Val BLEU: 0.33\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地 地球 上 最长 的 山脉 都 在 海洋\n",
      "Reference: and in the oceans , there are the longest\n",
      "Model: <SOS> and the the the the the the , ,\n",
      "Attention Weights: tensor([[0.0549, 0.1111, 0.1231, 0.1283, 0.1277, 0.1260, 0.1187, 0.1076, 0.0816,\n",
      "         0.0211],\n",
      "        [0.0424, 0.1106, 0.1287, 0.1363, 0.1355, 0.1327, 0.1223, 0.1066, 0.0727,\n",
      "         0.0122],\n",
      "        [0.0390, 0.1101, 0.1300, 0.1383, 0.1376, 0.1345, 0.1233, 0.1063, 0.0705,\n",
      "         0.0105],\n",
      "        [0.0373, 0.1099, 0.1306, 0.1394, 0.1386, 0.1354, 0.1238, 0.1062, 0.0693,\n",
      "         0.0096],\n",
      "        [0.0369, 0.1101, 0.1310, 0.1398, 0.1390, 0.1357, 0.1238, 0.1060, 0.0686,\n",
      "         0.0092],\n",
      "        [0.0368, 0.1103, 0.1312, 0.1400, 0.1391, 0.1358, 0.1238, 0.1058, 0.0683,\n",
      "         0.0090],\n",
      "        [0.0367, 0.1104, 0.1313, 0.1401, 0.1391, 0.1358, 0.1238, 0.1058, 0.0682,\n",
      "         0.0089],\n",
      "        [0.0367, 0.1105, 0.1313, 0.1401, 0.1391, 0.1358, 0.1237, 0.1058, 0.0682,\n",
      "         0.0089],\n",
      "        [0.0367, 0.1105, 0.1313, 0.1401, 0.1391, 0.1358, 0.1237, 0.1058, 0.0681,\n",
      "         0.0089]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 她 两年 年前 退休 了 结果 却 把 我家 变成\n",
      "Reference: she retired two years ago , only to turn\n",
      "Model: <SOS> and the the the the the the , ,\n",
      "Attention Weights: tensor([[3.0999e-04, 5.2500e-04, 5.4652e-04, 4.9597e-04, 3.2254e-04, 1.8258e-05,\n",
      "         2.4945e-01, 2.4945e-01, 2.4945e-01, 2.4945e-01],\n",
      "        [8.6633e-06, 1.7897e-05, 1.9007e-05, 1.6639e-05, 9.2512e-06, 2.5416e-07,\n",
      "         2.4998e-01, 2.4998e-01, 2.4998e-01, 2.4998e-01],\n",
      "        [3.5199e-06, 7.7744e-06, 8.3040e-06, 7.1952e-06, 3.8226e-06, 8.3461e-08,\n",
      "         2.4999e-01, 2.4999e-01, 2.4999e-01, 2.4999e-01],\n",
      "        [2.0786e-06, 4.7050e-06, 5.0233e-06, 4.3283e-06, 2.2378e-06, 4.1044e-08,\n",
      "         2.5000e-01, 2.5000e-01, 2.5000e-01, 2.5000e-01],\n",
      "        [1.7628e-06, 3.9647e-06, 4.2195e-06, 3.6299e-06, 1.8647e-06, 3.2587e-08,\n",
      "         2.5000e-01, 2.5000e-01, 2.5000e-01, 2.5000e-01],\n",
      "        [1.7897e-06, 3.9287e-06, 4.1629e-06, 3.5860e-06, 1.8596e-06, 3.4193e-08,\n",
      "         2.5000e-01, 2.5000e-01, 2.5000e-01, 2.5000e-01],\n",
      "        [1.8584e-06, 3.9964e-06, 4.2228e-06, 3.6455e-06, 1.9128e-06, 3.7492e-08,\n",
      "         2.5000e-01, 2.5000e-01, 2.5000e-01, 2.5000e-01],\n",
      "        [1.8931e-06, 4.0281e-06, 4.2511e-06, 3.6749e-06, 1.9410e-06, 3.9394e-08,\n",
      "         2.5000e-01, 2.5000e-01, 2.5000e-01, 2.5000e-01],\n",
      "        [1.9188e-06, 4.0622e-06, 4.2846e-06, 3.7062e-06, 1.9636e-06, 4.0475e-08,\n",
      "         2.5000e-01, 2.5000e-01, 2.5000e-01, 2.5000e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30.00, Train Loss: 3.73, Val Loss: 10.65, Train BLEU: 4.04, Val BLEU: 0.26\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分 部分 的 动物 也 都 生活 在 海洋\n",
      "Reference: most of the animals are in the oceans .\n",
      "Model: <SOS> and the the the the the the the the\n",
      "Attention Weights: tensor([[0.0547, 0.1098, 0.1234, 0.1290, 0.1278, 0.1264, 0.1198, 0.1065, 0.0812,\n",
      "         0.0214],\n",
      "        [0.0418, 0.1087, 0.1289, 0.1374, 0.1359, 0.1335, 0.1239, 0.1053, 0.0721,\n",
      "         0.0123],\n",
      "        [0.0384, 0.1080, 0.1303, 0.1396, 0.1380, 0.1354, 0.1250, 0.1050, 0.0699,\n",
      "         0.0106],\n",
      "        [0.0368, 0.1076, 0.1308, 0.1407, 0.1390, 0.1363, 0.1255, 0.1048, 0.0688,\n",
      "         0.0097],\n",
      "        [0.0364, 0.1078, 0.1313, 0.1412, 0.1394, 0.1366, 0.1256, 0.1045, 0.0680,\n",
      "         0.0093],\n",
      "        [0.0362, 0.1080, 0.1315, 0.1414, 0.1395, 0.1367, 0.1256, 0.1043, 0.0677,\n",
      "         0.0091],\n",
      "        [0.0362, 0.1081, 0.1316, 0.1415, 0.1396, 0.1367, 0.1256, 0.1043, 0.0675,\n",
      "         0.0090],\n",
      "        [0.0362, 0.1081, 0.1316, 0.1415, 0.1396, 0.1367, 0.1256, 0.1042, 0.0675,\n",
      "         0.0089],\n",
      "        [0.0362, 0.1082, 0.1316, 0.1415, 0.1396, 0.1367, 0.1256, 0.1042, 0.0675,\n",
      "         0.0089]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 面带 <UNK> <UNK> 笑容 这 很少 少见 因为 大部\n",
      "Reference: there was a big smile on his face which\n",
      "Model: <SOS> and the the the the the the the the\n",
      "Attention Weights: tensor([[0.0417, 0.0167, 0.1804, 0.1883, 0.0897, 0.0382, 0.1996, 0.1718, 0.0733,\n",
      "         0.0003],\n",
      "        [0.0274, 0.0092, 0.1933, 0.2067, 0.0788, 0.0266, 0.2218, 0.1796, 0.0565,\n",
      "         0.0001],\n",
      "        [0.0243, 0.0079, 0.1965, 0.2111, 0.0748, 0.0239, 0.2277, 0.1815, 0.0522,\n",
      "         0.0001],\n",
      "        [0.0229, 0.0072, 0.1982, 0.2134, 0.0724, 0.0223, 0.2309, 0.1826, 0.0499,\n",
      "         0.0001],\n",
      "        [0.0225, 0.0069, 0.1992, 0.2145, 0.0714, 0.0217, 0.2321, 0.1828, 0.0488,\n",
      "         0.0001],\n",
      "        [0.0223, 0.0068, 0.1997, 0.2149, 0.0710, 0.0215, 0.2325, 0.1828, 0.0483,\n",
      "         0.0001],\n",
      "        [0.0223, 0.0068, 0.1999, 0.2151, 0.0709, 0.0214, 0.2327, 0.1828, 0.0481,\n",
      "         0.0001],\n",
      "        [0.0223, 0.0068, 0.2000, 0.2152, 0.0708, 0.0214, 0.2328, 0.1828, 0.0480,\n",
      "         0.0001],\n",
      "        [0.0223, 0.0068, 0.2001, 0.2152, 0.0708, 0.0214, 0.2328, 0.1828, 0.0479,\n",
      "         0.0001]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 31.00, Train Loss: 3.71, Val Loss: 10.73, Train BLEU: 4.03, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分 部分 的 动物 也 都 生活 在 海洋\n",
      "Reference: most of the animals are in the oceans .\n",
      "Model: <SOS> and the the the the the the the the\n",
      "Attention Weights: tensor([[0.0568, 0.1101, 0.1234, 0.1289, 0.1276, 0.1259, 0.1192, 0.1057, 0.0806,\n",
      "         0.0217],\n",
      "        [0.0436, 0.1090, 0.1292, 0.1376, 0.1359, 0.1332, 0.1233, 0.1044, 0.0714,\n",
      "         0.0124],\n",
      "        [0.0400, 0.1084, 0.1306, 0.1398, 0.1381, 0.1350, 0.1243, 0.1040, 0.0691,\n",
      "         0.0107],\n",
      "        [0.0385, 0.1081, 0.1312, 0.1409, 0.1390, 0.1359, 0.1248, 0.1038, 0.0680,\n",
      "         0.0098],\n",
      "        [0.0381, 0.1083, 0.1316, 0.1414, 0.1394, 0.1362, 0.1249, 0.1035, 0.0672,\n",
      "         0.0094],\n",
      "        [0.0380, 0.1085, 0.1319, 0.1416, 0.1396, 0.1363, 0.1248, 0.1033, 0.0669,\n",
      "         0.0092],\n",
      "        [0.0379, 0.1086, 0.1320, 0.1417, 0.1396, 0.1364, 0.1248, 0.1032, 0.0667,\n",
      "         0.0091],\n",
      "        [0.0379, 0.1087, 0.1320, 0.1418, 0.1396, 0.1364, 0.1248, 0.1032, 0.0667,\n",
      "         0.0090],\n",
      "        [0.0379, 0.1087, 0.1320, 0.1418, 0.1396, 0.1363, 0.1248, 0.1032, 0.0666,\n",
      "         0.0090]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把 书 放在 食品 杂货 袋中 这样 别人 就\n",
      "Reference: we would cover our books in grocery bags so\n",
      "Model: <SOS> and the the the the the the the the\n",
      "Attention Weights: tensor([[0.0568, 0.1101, 0.1234, 0.1289, 0.1276, 0.1259, 0.1192, 0.1057, 0.0806,\n",
      "         0.0217],\n",
      "        [0.0436, 0.1090, 0.1292, 0.1376, 0.1359, 0.1332, 0.1233, 0.1044, 0.0714,\n",
      "         0.0124],\n",
      "        [0.0400, 0.1084, 0.1306, 0.1398, 0.1381, 0.1350, 0.1243, 0.1040, 0.0691,\n",
      "         0.0107],\n",
      "        [0.0385, 0.1081, 0.1312, 0.1409, 0.1390, 0.1359, 0.1248, 0.1038, 0.0680,\n",
      "         0.0098],\n",
      "        [0.0381, 0.1083, 0.1316, 0.1414, 0.1394, 0.1362, 0.1249, 0.1035, 0.0672,\n",
      "         0.0094],\n",
      "        [0.0380, 0.1085, 0.1319, 0.1416, 0.1396, 0.1363, 0.1248, 0.1033, 0.0669,\n",
      "         0.0092],\n",
      "        [0.0379, 0.1086, 0.1320, 0.1417, 0.1396, 0.1364, 0.1248, 0.1032, 0.0667,\n",
      "         0.0091],\n",
      "        [0.0379, 0.1087, 0.1320, 0.1418, 0.1396, 0.1364, 0.1248, 0.1032, 0.0667,\n",
      "         0.0090],\n",
      "        [0.0379, 0.1087, 0.1320, 0.1418, 0.1396, 0.1363, 0.1248, 0.1032, 0.0666,\n",
      "         0.0090]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 32.00, Train Loss: 3.69, Val Loss: 10.81, Train BLEU: 4.03, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里 生物 的 多样 多样性 和 密度 要 比\n",
      "Reference: the biodiversity and the <UNK> in the ocean is\n",
      "Model: <SOS> and the the the the the the the the\n",
      "Attention Weights: tensor([[0.0614, 0.1149, 0.1247, 0.1294, 0.1262, 0.1143, 0.1177, 0.1048, 0.0804,\n",
      "         0.0261],\n",
      "        [0.0480, 0.1163, 0.1319, 0.1392, 0.1347, 0.1177, 0.1218, 0.1035, 0.0713,\n",
      "         0.0156],\n",
      "        [0.0444, 0.1165, 0.1337, 0.1418, 0.1368, 0.1181, 0.1228, 0.1031, 0.0692,\n",
      "         0.0136],\n",
      "        [0.0430, 0.1167, 0.1346, 0.1430, 0.1377, 0.1180, 0.1233, 0.1029, 0.0681,\n",
      "         0.0127],\n",
      "        [0.0426, 0.1172, 0.1352, 0.1436, 0.1381, 0.1177, 0.1234, 0.1027, 0.0675,\n",
      "         0.0122],\n",
      "        [0.0425, 0.1175, 0.1355, 0.1439, 0.1382, 0.1176, 0.1233, 0.1025, 0.0671,\n",
      "         0.0119],\n",
      "        [0.0424, 0.1177, 0.1357, 0.1440, 0.1382, 0.1175, 0.1233, 0.1024, 0.0669,\n",
      "         0.0118],\n",
      "        [0.0424, 0.1178, 0.1357, 0.1441, 0.1382, 0.1174, 0.1233, 0.1024, 0.0669,\n",
      "         0.0118],\n",
      "        [0.0424, 0.1179, 0.1358, 0.1441, 0.1382, 0.1174, 0.1233, 0.1024, 0.0669,\n",
      "         0.0117]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 很 幸运 幸运地 成长 在 一个 珍视 教育 也\n",
      "Reference: i was very lucky to grow up in a\n",
      "Model: <SOS> and the the the the the the the the\n",
      "Attention Weights: tensor([[2.1478e-04, 3.3152e-04, 3.1489e-04, 2.0928e-04, 1.2889e-05, 1.9978e-01,\n",
      "         1.9978e-01, 1.9978e-01, 1.9978e-01, 1.9978e-01],\n",
      "        [3.0759e-06, 5.7066e-06, 5.3441e-06, 3.0224e-06, 8.9313e-08, 2.0000e-01,\n",
      "         2.0000e-01, 2.0000e-01, 2.0000e-01, 2.0000e-01],\n",
      "        [9.3297e-07, 1.8414e-06, 1.7159e-06, 9.2474e-07, 2.1753e-08, 2.0000e-01,\n",
      "         2.0000e-01, 2.0000e-01, 2.0000e-01, 2.0000e-01],\n",
      "        [4.9934e-07, 1.0076e-06, 9.3358e-07, 4.8905e-07, 9.7910e-09, 2.0000e-01,\n",
      "         2.0000e-01, 2.0000e-01, 2.0000e-01, 2.0000e-01],\n",
      "        [4.2404e-07, 8.5431e-07, 7.8767e-07, 4.0828e-07, 7.6770e-09, 2.0000e-01,\n",
      "         2.0000e-01, 2.0000e-01, 2.0000e-01, 2.0000e-01],\n",
      "        [4.3484e-07, 8.5944e-07, 7.9015e-07, 4.1196e-07, 7.9777e-09, 2.0000e-01,\n",
      "         2.0000e-01, 2.0000e-01, 2.0000e-01, 2.0000e-01],\n",
      "        [4.7135e-07, 9.1192e-07, 8.3810e-07, 4.4262e-07, 9.1541e-09, 2.0000e-01,\n",
      "         2.0000e-01, 2.0000e-01, 2.0000e-01, 2.0000e-01],\n",
      "        [4.8844e-07, 9.3410e-07, 8.5883e-07, 4.5728e-07, 9.8593e-09, 2.0000e-01,\n",
      "         2.0000e-01, 2.0000e-01, 2.0000e-01, 2.0000e-01],\n",
      "        [5.0510e-07, 9.6024e-07, 8.8314e-07, 4.7233e-07, 1.0407e-08, 2.0000e-01,\n",
      "         2.0000e-01, 2.0000e-01, 2.0000e-01, 2.0000e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 33.00, Train Loss: 3.67, Val Loss: 10.89, Train BLEU: 4.03, Val BLEU: 0.24\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想 海洋 占 了 地球 球面 面积 的 75\n",
      "Reference: when you think about it , the oceans are\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0648, 0.1165, 0.1276, 0.1335, 0.1326, 0.1281, 0.1200, 0.1043, 0.0690,\n",
      "         0.0036],\n",
      "        [0.0496, 0.1160, 0.1339, 0.1430, 0.1417, 0.1351, 0.1230, 0.1005, 0.0557,\n",
      "         0.0013],\n",
      "        [0.0456, 0.1156, 0.1354, 0.1455, 0.1441, 0.1369, 0.1237, 0.0996, 0.0526,\n",
      "         0.0010],\n",
      "        [0.0442, 0.1156, 0.1360, 0.1466, 0.1451, 0.1376, 0.1239, 0.0990, 0.0510,\n",
      "         0.0009],\n",
      "        [0.0438, 0.1160, 0.1365, 0.1472, 0.1455, 0.1378, 0.1238, 0.0985, 0.0501,\n",
      "         0.0009],\n",
      "        [0.0437, 0.1162, 0.1368, 0.1474, 0.1457, 0.1378, 0.1237, 0.0982, 0.0497,\n",
      "         0.0008],\n",
      "        [0.0436, 0.1164, 0.1369, 0.1475, 0.1457, 0.1378, 0.1237, 0.0981, 0.0494,\n",
      "         0.0008],\n",
      "        [0.0436, 0.1165, 0.1370, 0.1476, 0.1458, 0.1378, 0.1236, 0.0980, 0.0493,\n",
      "         0.0008],\n",
      "        [0.0436, 0.1165, 0.1370, 0.1476, 0.1458, 0.1378, 0.1236, 0.0980, 0.0493,\n",
      "         0.0008]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在 可以 去 个 真正 的 学校 念书 了\n",
      "Reference: &quot; you can go to a real school now\n",
      "Model: <SOS> and the the the the the the the the\n",
      "Attention Weights: tensor([[0.0391, 0.0370, 0.0631, 0.1135, 0.1636, 0.1614, 0.1527, 0.1366, 0.1036,\n",
      "         0.0293],\n",
      "        [0.0260, 0.0249, 0.0502, 0.1092, 0.1829, 0.1809, 0.1677, 0.1432, 0.0971,\n",
      "         0.0178],\n",
      "        [0.0231, 0.0221, 0.0462, 0.1071, 0.1878, 0.1862, 0.1716, 0.1449, 0.0954,\n",
      "         0.0156],\n",
      "        [0.0219, 0.0208, 0.0443, 0.1057, 0.1902, 0.1887, 0.1735, 0.1457, 0.0947,\n",
      "         0.0146],\n",
      "        [0.0215, 0.0202, 0.0434, 0.1054, 0.1914, 0.1898, 0.1742, 0.1459, 0.0941,\n",
      "         0.0140],\n",
      "        [0.0213, 0.0200, 0.0431, 0.1052, 0.1919, 0.1903, 0.1746, 0.1460, 0.0938,\n",
      "         0.0138],\n",
      "        [0.0213, 0.0199, 0.0429, 0.1051, 0.1921, 0.1905, 0.1747, 0.1461, 0.0937,\n",
      "         0.0136],\n",
      "        [0.0212, 0.0199, 0.0429, 0.1051, 0.1922, 0.1906, 0.1748, 0.1461, 0.0937,\n",
      "         0.0136],\n",
      "        [0.0212, 0.0198, 0.0429, 0.1050, 0.1922, 0.1906, 0.1748, 0.1461, 0.0937,\n",
      "         0.0136]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34.00, Train Loss: 3.65, Val Loss: 10.96, Train BLEU: 4.03, Val BLEU: 0.24\n",
      "Sampling from training predictions...\n",
      "Source: <UNK> 塞尔 <UNK> <UNK> 斯特 说 过 真正 的 探索\n",
      "Reference: marcel proust said , &quot; the true voyage of\n",
      "Model: <SOS> marcel the the , , , , , ,\n",
      "Attention Weights: tensor([[1.3275e-09, 3.7548e-09, 1.4468e-08, 4.1622e-07, 1.2279e-02, 2.4698e-01,\n",
      "         2.4501e-01, 2.3232e-01, 1.9166e-01, 7.1744e-02],\n",
      "        [1.7130e-09, 3.4024e-09, 8.6186e-09, 1.0374e-07, 2.8515e-03, 2.6091e-01,\n",
      "         2.7042e-01, 2.4939e-01, 1.8042e-01, 3.6015e-02],\n",
      "        [3.8837e-09, 6.9180e-09, 1.5222e-08, 1.3095e-07, 2.0443e-03, 2.6130e-01,\n",
      "         2.7667e-01, 2.5320e-01, 1.7694e-01, 2.9849e-02],\n",
      "        [5.4565e-09, 9.3809e-09, 1.9785e-08, 1.5053e-07, 1.8672e-03, 2.6153e-01,\n",
      "         2.7847e-01, 2.5408e-01, 1.7574e-01, 2.8314e-02],\n",
      "        [6.1261e-09, 1.0436e-08, 2.1814e-08, 1.6092e-07, 1.8418e-03, 2.6131e-01,\n",
      "         2.7907e-01, 2.5438e-01, 1.7543e-01, 2.7971e-02],\n",
      "        [6.5492e-09, 1.1114e-08, 2.3135e-08, 1.6854e-07, 1.8429e-03, 2.6129e-01,\n",
      "         2.7928e-01, 2.5447e-01, 1.7528e-01, 2.7846e-02],\n",
      "        [6.8681e-09, 1.1625e-08, 2.4119e-08, 1.7419e-07, 1.8448e-03, 2.6128e-01,\n",
      "         2.7939e-01, 2.5452e-01, 1.7520e-01, 2.7776e-02],\n",
      "        [7.2064e-09, 1.2169e-08, 2.5165e-08, 1.8032e-07, 1.8520e-03, 2.6124e-01,\n",
      "         2.7943e-01, 2.5454e-01, 1.7516e-01, 2.7770e-02],\n",
      "        [7.4502e-09, 1.2558e-08, 2.5901e-08, 1.8442e-07, 1.8549e-03, 2.6122e-01,\n",
      "         2.7948e-01, 2.5457e-01, 1.7513e-01, 2.7753e-02]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 在 塔利 塔利班 控制 阿富汗 的 那些 年 我 记得\n",
      "Reference: during taliban years , i remember there were times\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0680, 0.1173, 0.1300, 0.1342, 0.1333, 0.1280, 0.1201, 0.1022, 0.0641,\n",
      "         0.0027],\n",
      "        [0.0524, 0.1172, 0.1374, 0.1442, 0.1431, 0.1350, 0.1229, 0.0973, 0.0497,\n",
      "         0.0009],\n",
      "        [0.0482, 0.1168, 0.1392, 0.1469, 0.1456, 0.1367, 0.1236, 0.0960, 0.0463,\n",
      "         0.0007],\n",
      "        [0.0466, 0.1168, 0.1401, 0.1481, 0.1467, 0.1373, 0.1238, 0.0952, 0.0448,\n",
      "         0.0006],\n",
      "        [0.0463, 0.1171, 0.1406, 0.1486, 0.1470, 0.1375, 0.1237, 0.0947, 0.0439,\n",
      "         0.0006],\n",
      "        [0.0461, 0.1173, 0.1409, 0.1489, 0.1472, 0.1375, 0.1236, 0.0945, 0.0435,\n",
      "         0.0005],\n",
      "        [0.0461, 0.1175, 0.1411, 0.1490, 0.1472, 0.1375, 0.1235, 0.0943, 0.0433,\n",
      "         0.0005],\n",
      "        [0.0460, 0.1176, 0.1411, 0.1490, 0.1472, 0.1375, 0.1235, 0.0943, 0.0432,\n",
      "         0.0005],\n",
      "        [0.0460, 0.1176, 0.1411, 0.1490, 0.1472, 0.1375, 0.1235, 0.0943, 0.0432,\n",
      "         0.0005]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 35.00, Train Loss: 3.63, Val Loss: 11.02, Train BLEU: 5.02, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里 生物 的 多样 多样性 和 密度 要 比\n",
      "Reference: the biodiversity and the <UNK> in the ocean is\n",
      "Model: <SOS> and the the the the the the the the\n",
      "Attention Weights: tensor([[0.0656, 0.1146, 0.1248, 0.1291, 0.1260, 0.1143, 0.1158, 0.1029, 0.0792,\n",
      "         0.0276],\n",
      "        [0.0515, 0.1165, 0.1329, 0.1397, 0.1352, 0.1177, 0.1196, 0.1011, 0.0695,\n",
      "         0.0163],\n",
      "        [0.0477, 0.1168, 0.1350, 0.1426, 0.1375, 0.1179, 0.1205, 0.1006, 0.0672,\n",
      "         0.0142],\n",
      "        [0.0463, 0.1171, 0.1360, 0.1439, 0.1385, 0.1177, 0.1209, 0.1003, 0.0662,\n",
      "         0.0133],\n",
      "        [0.0460, 0.1176, 0.1365, 0.1444, 0.1388, 0.1175, 0.1208, 0.0999, 0.0655,\n",
      "         0.0128],\n",
      "        [0.0459, 0.1179, 0.1369, 0.1447, 0.1389, 0.1174, 0.1208, 0.0997, 0.0651,\n",
      "         0.0125],\n",
      "        [0.0459, 0.1181, 0.1370, 0.1448, 0.1390, 0.1173, 0.1207, 0.0996, 0.0650,\n",
      "         0.0124],\n",
      "        [0.0459, 0.1182, 0.1371, 0.1449, 0.1390, 0.1173, 0.1207, 0.0996, 0.0649,\n",
      "         0.0124],\n",
      "        [0.0459, 0.1183, 0.1371, 0.1449, 0.1390, 0.1172, 0.1207, 0.0996, 0.0649,\n",
      "         0.0124]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 不知 知道 那 意味 意味着 什么 但是 我 能\n",
      "Reference: i didn &apos;t know what it meant , but\n",
      "Model: <SOS> and the the the the the the the the\n",
      "Attention Weights: tensor([[0.0736, 0.1243, 0.1367, 0.1403, 0.1387, 0.1326, 0.1149, 0.0627, 0.0553,\n",
      "         0.0210],\n",
      "        [0.0593, 0.1278, 0.1477, 0.1536, 0.1513, 0.1417, 0.1155, 0.0503, 0.0416,\n",
      "         0.0113],\n",
      "        [0.0551, 0.1285, 0.1506, 0.1572, 0.1546, 0.1440, 0.1153, 0.0469, 0.0384,\n",
      "         0.0096],\n",
      "        [0.0536, 0.1289, 0.1519, 0.1587, 0.1560, 0.1450, 0.1152, 0.0453, 0.0367,\n",
      "         0.0088],\n",
      "        [0.0533, 0.1294, 0.1525, 0.1593, 0.1565, 0.1453, 0.1149, 0.0445, 0.0359,\n",
      "         0.0084],\n",
      "        [0.0532, 0.1298, 0.1530, 0.1597, 0.1567, 0.1454, 0.1147, 0.0439, 0.0354,\n",
      "         0.0082],\n",
      "        [0.0532, 0.1300, 0.1532, 0.1598, 0.1568, 0.1454, 0.1146, 0.0437, 0.0351,\n",
      "         0.0081],\n",
      "        [0.0532, 0.1302, 0.1533, 0.1599, 0.1568, 0.1454, 0.1146, 0.0435, 0.0350,\n",
      "         0.0081],\n",
      "        [0.0532, 0.1302, 0.1533, 0.1599, 0.1569, 0.1454, 0.1146, 0.0435, 0.0350,\n",
      "         0.0081]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 36.00, Train Loss: 3.61, Val Loss: 11.08, Train BLEU: 6.86, Val BLEU: 0.24\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一只 水母 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: here &apos;s a jelly . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the to . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[2.3575e-04, 3.4112e-04, 3.2730e-04, 2.2409e-04, 1.4956e-05, 1.9977e-01,\n",
      "         1.9977e-01, 1.9977e-01, 1.9977e-01, 1.9977e-01],\n",
      "        [1.9032e-06, 3.2935e-06, 3.1086e-06, 1.7953e-06, 5.5178e-08, 2.0000e-01,\n",
      "         2.0000e-01, 2.0000e-01, 2.0000e-01, 2.0000e-01],\n",
      "        [4.0370e-07, 7.4244e-07, 6.9748e-07, 3.8243e-07, 9.3014e-09, 2.0000e-01,\n",
      "         2.0000e-01, 2.0000e-01, 2.0000e-01, 2.0000e-01],\n",
      "        [1.8429e-07, 3.4638e-07, 3.2368e-07, 1.7219e-07, 3.5476e-09, 2.0000e-01,\n",
      "         2.0000e-01, 2.0000e-01, 2.0000e-01, 2.0000e-01],\n",
      "        [1.5307e-07, 2.8753e-07, 2.6741e-07, 1.4075e-07, 2.7409e-09, 2.0000e-01,\n",
      "         2.0000e-01, 2.0000e-01, 2.0000e-01, 2.0000e-01],\n",
      "        [1.6713e-07, 3.0696e-07, 2.8481e-07, 1.5144e-07, 3.0812e-09, 2.0000e-01,\n",
      "         2.0000e-01, 2.0000e-01, 2.0000e-01, 2.0000e-01],\n",
      "        [1.9135e-07, 3.4448e-07, 3.1966e-07, 1.7246e-07, 3.7526e-09, 2.0000e-01,\n",
      "         2.0000e-01, 2.0000e-01, 2.0000e-01, 2.0000e-01],\n",
      "        [2.0461e-07, 3.6504e-07, 3.3891e-07, 1.8426e-07, 4.1559e-09, 2.0000e-01,\n",
      "         2.0000e-01, 2.0000e-01, 2.0000e-01, 2.0000e-01],\n",
      "        [2.1453e-07, 3.8124e-07, 3.5403e-07, 1.9319e-07, 4.4307e-09, 2.0000e-01,\n",
      "         2.0000e-01, 2.0000e-01, 2.0000e-01, 2.0000e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 那 就是 她 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: there she is . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the to . . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.1934e-03, 2.0126e-03, 2.2064e-03, 2.2496e-03, 2.1981e-03, 2.0571e-03,\n",
      "         1.8026e-03, 1.2410e-03, 8.8209e-05, 9.8495e-01],\n",
      "        [1.0081e-05, 2.1832e-05, 2.5166e-05, 2.5934e-05, 2.5087e-05, 2.2784e-05,\n",
      "         1.8783e-05, 1.0899e-05, 3.5340e-07, 9.9984e-01],\n",
      "        [2.1542e-06, 5.0714e-06, 5.9308e-06, 6.1269e-06, 5.9052e-06, 5.3136e-06,\n",
      "         4.2993e-06, 2.3671e-06, 6.0308e-08, 9.9996e-01],\n",
      "        [9.6601e-07, 2.3486e-06, 2.7576e-06, 2.8498e-06, 2.7423e-06, 2.4582e-06,\n",
      "         1.9696e-06, 1.0530e-06, 2.2678e-08, 9.9998e-01],\n",
      "        [7.5080e-07, 1.8346e-06, 2.1522e-06, 2.2223e-06, 2.1372e-06, 1.9139e-06,\n",
      "         1.5297e-06, 8.1009e-07, 1.6476e-08, 9.9999e-01],\n",
      "        [8.2969e-07, 1.9807e-06, 2.3094e-06, 2.3806e-06, 2.2895e-06, 2.0533e-06,\n",
      "         1.6464e-06, 8.7932e-07, 1.8442e-08, 9.9999e-01],\n",
      "        [9.7371e-07, 2.2607e-06, 2.6202e-06, 2.6976e-06, 2.5964e-06, 2.3346e-06,\n",
      "         1.8819e-06, 1.0206e-06, 2.2942e-08, 9.9998e-01],\n",
      "        [1.0711e-06, 2.4478e-06, 2.8278e-06, 2.9096e-06, 2.8019e-06, 2.5236e-06,\n",
      "         2.0411e-06, 1.1177e-06, 2.6324e-08, 9.9998e-01],\n",
      "        [1.1290e-06, 2.5628e-06, 2.9563e-06, 3.0410e-06, 2.9292e-06, 2.6404e-06,\n",
      "         2.1387e-06, 1.1764e-06, 2.8300e-08, 9.9998e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, results = train_and_eval_attn(\n",
    "    model=model, loaders_full=loaders_full, loaders_minibatch=loaders_minibatch, loaders_minitrain=loaders_minitrain, \n",
    "    params=params, vocab=vocab, print_intermediate=True, save_checkpoint=True, save_to_log=True, \n",
    "    lazy_eval=False, inspect_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_results(load_experiment_log())[['dt_created', 'num_epochs', 'learning_rate', 'clip_grad_max_norm', 'val_loss']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_learning_curve(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch: 199.00, Train Loss: 0.32, Val Loss: 13.19, Train BLEU: 98.94, Val BLEU: 0.27\n",
    "plot_single_learning_curve(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with attention energies = v_broadcast.bmm(torch.tanh(self.attn(concat)).transpose(1, 2)) # switched order  \n",
    "# Epoch: 199.00, Train Loss: 0.63, Val Loss: 12.82, Train BLEU: 92.05, Val BLEU: 0.38\n",
    "plot_single_learning_curve(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, token in enumerate(vocab[SRC_LANG]['id2token']): \n",
    "    if i < 20: \n",
    "        print(\"{}: {}\".format(i, token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, token in enumerate(vocab[TARG_LANG]['id2token']): \n",
    "    if i < 20: \n",
    "        print(\"{}: {}\".format(i, token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.arange(0, 3*5*10).view(3, 5, 10)\n",
    "print(x)\n",
    "y = x[1:, :, :]\n",
    "print(y)\n",
    "z = y.view(-1, 10)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.arange(0, 2*5).view(5, 2)\n",
    "print(t)\n",
    "u = t.contiguous().view(-1)\n",
    "print(u)\n",
    "v = t.permute(1, 0)\n",
    "print(v)\n",
    "w = v.contiguous().view(-1)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(0, 2*1*300)\n",
    "print(a)\n",
    "b = a.view(-1, 1, 300)\n",
    "print(b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (src_idxs, targ_idxs, src_lens, targ_lens) in enumerate(full_loaders['train']):\n",
    "#     print(i)\n",
    "#     print(src_idxs.size())\n",
    "#     print(src_idxs)\n",
    "#     print(src_lens)\n",
    "#     print(targ_idxs.size())\n",
    "#     print(targ_idxs)\n",
    "#     print(targ_lens)\n",
    "    id2token = vocab[SRC_LANG]['id2token']\n",
    "    test_tensor = src_idxs\n",
    "    list_of_lists = test_tensor.numpy().astype(int).tolist()\n",
    "    to_token = lambda l: ' '.join([id2token[idx] for idx in l])\n",
    "    list_of_lists_tokens = [to_token(l) for l in list_of_lists] \n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
