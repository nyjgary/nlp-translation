{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from data_processing import generate_vocab, process_data, create_dataloaders \n",
    "from model import get_pretrained_emb, EncoderDecoder, EncoderRNN, DecoderRNN, DecoderSimpleRNN, EncoderSimpleRNN, \\\n",
    "    Attention, DecoderAttnRNN, DecoderRNNV2, EncoderDecoderAttention, EncoderSimpleRNN_Test, DecoderAttnRNN_Test, \\\n",
    "    DecoderRNN_Test\n",
    "from train_eval import count_parameters, summarize_results, \\\n",
    "    plot_single_learning_curve, load_experiment_log\n",
    "from train_eval import train_and_eval, train_and_eval_attn \n",
    "import importlib\n",
    "import pickle as pkl \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model identification\n",
    "MODEL_NAME = 'zh-seq2seq-rnn-attention'\n",
    "SRC_LANG = 'zh'\n",
    "TARG_LANG = 'en'\n",
    "\n",
    "# data processing params  \n",
    "SRC_MAX_SENTENCE_LEN = 10\n",
    "TARG_MAX_SENTENCE_LEN = 10\n",
    "SRC_VOCAB_SIZE = 30000 #30000\n",
    "TARG_VOCAB_SIZE = 30000 #30000\n",
    "\n",
    "# model architecture params \n",
    "RNN_CELL_TYPE = 'gru'\n",
    "NUM_LAYERS = 2 #2 \n",
    "ENC_HIDDEN_DIM = 256 #512\n",
    "DEC_HIDDEN_DIM = 2 * ENC_HIDDEN_DIM #2 * ENC_HIDDEN_DIM \n",
    "TEACHER_FORCING_RATIO = 1\n",
    "CLIP_GRAD_MAX_NORM = 1\n",
    "ENC_DROPOUT = 0.2 # to actually implement\n",
    "DEC_DROPOUT = 0.2 # to actually implement\n",
    "\n",
    "# training params  \n",
    "BATCH_SIZE = 32 #32\n",
    "NUM_EPOCHS = 200\n",
    "LR = 0.0005 # 0.0005\n",
    "OPTIMIZER = 'Adam'\n",
    "LAZY_TRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store as dict to save to results later \n",
    "params = {'model_name': MODEL_NAME, 'src_lang': SRC_LANG, 'targ_lang': TARG_LANG, 'rnn_cell_type': RNN_CELL_TYPE, \n",
    "          'src_max_sentence_len': SRC_MAX_SENTENCE_LEN, 'targ_max_sentence_len': TARG_MAX_SENTENCE_LEN, \n",
    "          'src_vocab_size': SRC_VOCAB_SIZE, 'targ_vocab_size': TARG_VOCAB_SIZE, \n",
    "          'num_layers': NUM_LAYERS, 'enc_hidden_dim': ENC_HIDDEN_DIM, 'dec_hidden_dim': DEC_HIDDEN_DIM,\n",
    "          'teacher_forcing_ratio': TEACHER_FORCING_RATIO, 'clip_grad_max_norm': CLIP_GRAD_MAX_NORM,\n",
    "          'enc_dropout': ENC_DROPOUT, 'dec_dropout': DEC_DROPOUT, \n",
    "          'batch_size': BATCH_SIZE, 'num_epochs': NUM_EPOCHS, 'learning_rate': LR, 'optimizer': OPTIMIZER, \n",
    "          'lazy_train': LAZY_TRAIN} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab_test = generate_vocab(SRC_LANG, TARG_LANG, SRC_VOCAB_SIZE, TARG_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab['zh']['id2token'][987]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab['zh']['token2id']['森林']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab['en']['token2id']['activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab['en']['id2token'][987]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # takes a long time to process, save to pickle for reimport in future \n",
    "# vocab = generate_vocab(SRC_LANG, TARG_LANG, SRC_VOCAB_SIZE, TARG_VOCAB_SIZE)\n",
    "# vocab_filename = \"{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n",
    "# pkl.dump(vocab, open(vocab_filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload from pickle \n",
    "vocab_filename = \"{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n",
    "vocab = pkl.load(open(vocab_filename, \"rb\"))\n",
    "data = process_data(SRC_LANG, TARG_LANG, vocab)\n",
    "data_minibatch = process_data(SRC_LANG, TARG_LANG, vocab, sample_limit=BATCH_SIZE) \n",
    "data_minitrain = process_data(SRC_LANG, TARG_LANG, vocab, sample_limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # takes a long time to process, save to pickle for reimport in future \n",
    "# vocab = generate_vocab(SRC_LANG, TARG_LANG, SRC_VOCAB_SIZE, TARG_VOCAB_SIZE)\n",
    "# vocab_filename = \"{}-{}-vocab-fake.p\".format(SRC_LANG, TARG_LANG)\n",
    "# pkl.dump(vocab, open(vocab_filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_filename = \"{}-{}-vocab-fake.p\".format(SRC_LANG, TARG_LANG)\n",
    "# vocab = pkl.load(open(vocab_filename, \"rb\"))\n",
    "# data = process_data(SRC_LANG, TARG_LANG, vocab)\n",
    "# limited_data = process_data(SRC_LANG, TARG_LANG, vocab, sample_limit=BATCH_SIZE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders \n",
    "loaders_full = create_dataloaders(data, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)\n",
    "loaders_minibatch = create_dataloaders(data_minibatch, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)\n",
    "loaders_minitrain = create_dataloaders(data_minitrain, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model \n",
    "\n",
    "# encoder = EncoderRNN(enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, src_max_sentence_len=SRC_MAX_SENTENCE_LEN,\n",
    "#                      pretrained_word2vec=get_pretrained_emb(vocab[SRC_LANG]['word2vec'], vocab[SRC_LANG]['token2id']))\n",
    "# encoder = EncoderSimpleRNN(enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, src_max_sentence_len=SRC_MAX_SENTENCE_LEN,\n",
    "#                            pretrained_word2vec=get_pretrained_emb(vocab[SRC_LANG]['word2vec'], vocab[SRC_LANG]['token2id']))\n",
    "# encoder = EncoderSimpleRNN(enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, src_max_sentence_len=SRC_MAX_SENTENCE_LEN,\n",
    "#                            pretrained_word2vec=get_pretrained_emb(vocab[SRC_LANG]['word2vec'], vocab[SRC_LANG]['token2id']))\n",
    "encoder = EncoderSimpleRNN_Test(rnn_cell_type=RNN_CELL_TYPE, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, src_max_sentence_len=SRC_MAX_SENTENCE_LEN,\n",
    "                                enc_dropout=ENC_DROPOUT, pretrained_word2vec=get_pretrained_emb(vocab[SRC_LANG]['word2vec'], vocab[SRC_LANG]['token2id']))\n",
    "\n",
    "# decoder = DecoderRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS,\n",
    "#                       targ_vocab_size=TARG_VOCAB_SIZE, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "#                       pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "# decoder = DecoderRNNV2(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, \n",
    "#                        targ_vocab_size=TARG_VOCAB_SIZE, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "#                        pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "# decoder = DecoderSimpleRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, \n",
    "#                            targ_vocab_size=TARG_VOCAB_SIZE, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "#                            pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "# decoder = DecoderAttnRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, \n",
    "#                          targ_vocab_size=TARG_VOCAB_SIZE, src_max_sentence_len=SRC_MAX_SENTENCE_LEN, \n",
    "#                          targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "#                          pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "# decoder = DecoderAttnRNN_Test(rnn_cell_type=RNN_CELL_TYPE, dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, \n",
    "#                          targ_vocab_size=TARG_VOCAB_SIZE, src_max_sentence_len=SRC_MAX_SENTENCE_LEN, \n",
    "#                          targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, dec_dropout=DEC_DROPOUT, \n",
    "#                          pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "decoder = DecoderRNN_Test(\n",
    "    rnn_cell_type=RNN_CELL_TYPE, attn=True, dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, \n",
    "    num_layers=NUM_LAYERS, targ_vocab_size=TARG_VOCAB_SIZE, src_max_sentence_len=SRC_MAX_SENTENCE_LEN, \n",
    "    targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, dec_dropout=DEC_DROPOUT, \n",
    "    pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "\n",
    "model = EncoderDecoderAttention(encoder, decoder, vocab[TARG_LANG]['token2id']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.00, Train Loss: 10.12, Val Loss: 10.24, Train BLEU: 0.31, Val BLEU: 0.20\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克 泰坦尼克号 坦尼 尼克 号 是 拿 了 不少\n",
      "Reference: the truth of the matter is that the titanic\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0976, 0.0948, 0.0933, 0.0972, 0.0977, 0.1007, 0.1033, 0.1045, 0.1055,\n",
      "         0.1054],\n",
      "        [0.0976, 0.0949, 0.0934, 0.0973, 0.0977, 0.1007, 0.1032, 0.1044, 0.1054,\n",
      "         0.1054],\n",
      "        [0.0977, 0.0949, 0.0934, 0.0973, 0.0977, 0.1007, 0.1032, 0.1044, 0.1054,\n",
      "         0.1053],\n",
      "        [0.0977, 0.0949, 0.0934, 0.0973, 0.0977, 0.1007, 0.1032, 0.1044, 0.1054,\n",
      "         0.1053],\n",
      "        [0.0976, 0.0949, 0.0934, 0.0973, 0.0977, 0.1007, 0.1032, 0.1044, 0.1054,\n",
      "         0.1053],\n",
      "        [0.0976, 0.0949, 0.0934, 0.0973, 0.0977, 0.1007, 0.1032, 0.1044, 0.1054,\n",
      "         0.1053],\n",
      "        [0.0976, 0.0949, 0.0934, 0.0973, 0.0977, 0.1007, 0.1032, 0.1044, 0.1054,\n",
      "         0.1053],\n",
      "        [0.0976, 0.0949, 0.0934, 0.0973, 0.0977, 0.1007, 0.1032, 0.1044, 0.1054,\n",
      "         0.1053],\n",
      "        [0.0976, 0.0949, 0.0934, 0.0973, 0.0977, 0.1007, 0.1032, 0.1044, 0.1054,\n",
      "         0.1053]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 这 是 我们 俩 人 唯一 的 受教 教育 方式\n",
      "Reference: it was the only way we both could be\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0946, 0.0980, 0.1005, 0.1010, 0.0999, 0.0988, 0.0991, 0.1007, 0.1036,\n",
      "         0.1037],\n",
      "        [0.0945, 0.0980, 0.1005, 0.1009, 0.0999, 0.0988, 0.0991, 0.1008, 0.1037,\n",
      "         0.1038],\n",
      "        [0.0946, 0.0980, 0.1006, 0.1009, 0.0999, 0.0988, 0.0991, 0.1008, 0.1036,\n",
      "         0.1037],\n",
      "        [0.0946, 0.0981, 0.1006, 0.1009, 0.0999, 0.0988, 0.0991, 0.1008, 0.1036,\n",
      "         0.1037],\n",
      "        [0.0946, 0.0981, 0.1006, 0.1009, 0.0999, 0.0988, 0.0991, 0.1008, 0.1036,\n",
      "         0.1037],\n",
      "        [0.0945, 0.0980, 0.1006, 0.1009, 0.0999, 0.0988, 0.0991, 0.1008, 0.1036,\n",
      "         0.1037],\n",
      "        [0.0945, 0.0980, 0.1006, 0.1009, 0.0999, 0.0988, 0.0991, 0.1008, 0.1036,\n",
      "         0.1037],\n",
      "        [0.0945, 0.0980, 0.1006, 0.1009, 0.0999, 0.0988, 0.0991, 0.1008, 0.1036,\n",
      "         0.1037],\n",
      "        [0.0945, 0.0980, 0.1006, 0.1009, 0.0999, 0.0988, 0.0991, 0.1008, 0.1036,\n",
      "         0.1037]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 1.00, Train Loss: 9.87, Val Loss: 10.15, Train BLEU: 0.29, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分 部分 的 动物 也 都 生活 在 海洋\n",
      "Reference: most of the animals are in the oceans .\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0933, 0.0942, 0.0969, 0.1005, 0.1023, 0.1031, 0.1046, 0.1028, 0.1032,\n",
      "         0.0991],\n",
      "        [0.0932, 0.0941, 0.0969, 0.1005, 0.1024, 0.1031, 0.1047, 0.1029, 0.1032,\n",
      "         0.0991],\n",
      "        [0.0932, 0.0941, 0.0969, 0.1005, 0.1024, 0.1032, 0.1047, 0.1029, 0.1032,\n",
      "         0.0990],\n",
      "        [0.0932, 0.0941, 0.0969, 0.1005, 0.1024, 0.1032, 0.1047, 0.1029, 0.1032,\n",
      "         0.0990],\n",
      "        [0.0932, 0.0941, 0.0968, 0.1005, 0.1024, 0.1032, 0.1047, 0.1029, 0.1032,\n",
      "         0.0990],\n",
      "        [0.0932, 0.0941, 0.0968, 0.1004, 0.1024, 0.1032, 0.1047, 0.1029, 0.1032,\n",
      "         0.0990],\n",
      "        [0.0932, 0.0941, 0.0968, 0.1004, 0.1024, 0.1032, 0.1047, 0.1029, 0.1032,\n",
      "         0.0990],\n",
      "        [0.0932, 0.0941, 0.0968, 0.1004, 0.1024, 0.1032, 0.1047, 0.1029, 0.1032,\n",
      "         0.0990],\n",
      "        [0.0932, 0.0941, 0.0968, 0.1004, 0.1024, 0.1031, 0.1047, 0.1029, 0.1032,\n",
      "         0.0990]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 父亲 在 用 他 的 灰色 小 收音\n",
      "Reference: my father was listening to bbc news on his\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0941, 0.0921, 0.0963, 0.0974, 0.0972, 0.1000, 0.1046, 0.1070, 0.1072,\n",
      "         0.1040],\n",
      "        [0.0941, 0.0920, 0.0963, 0.0974, 0.0972, 0.1001, 0.1047, 0.1070, 0.1072,\n",
      "         0.1040],\n",
      "        [0.0941, 0.0920, 0.0963, 0.0974, 0.0972, 0.1001, 0.1047, 0.1071, 0.1072,\n",
      "         0.1040],\n",
      "        [0.0940, 0.0920, 0.0963, 0.0974, 0.0972, 0.1001, 0.1047, 0.1071, 0.1072,\n",
      "         0.1040],\n",
      "        [0.0940, 0.0920, 0.0963, 0.0974, 0.0972, 0.1001, 0.1047, 0.1070, 0.1072,\n",
      "         0.1040],\n",
      "        [0.0941, 0.0920, 0.0963, 0.0974, 0.0972, 0.1001, 0.1047, 0.1070, 0.1072,\n",
      "         0.1040],\n",
      "        [0.0941, 0.0920, 0.0963, 0.0974, 0.0972, 0.1001, 0.1047, 0.1070, 0.1072,\n",
      "         0.1040],\n",
      "        [0.0941, 0.0920, 0.0963, 0.0974, 0.0973, 0.1001, 0.1047, 0.1070, 0.1072,\n",
      "         0.1040],\n",
      "        [0.0941, 0.0921, 0.0963, 0.0974, 0.0973, 0.1001, 0.1046, 0.1070, 0.1072,\n",
      "         0.1040]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 2.00, Train Loss: 9.49, Val Loss: 10.01, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想 海洋 占 了 地球 球面 面积 的 75\n",
      "Reference: when you think about it , the oceans are\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0898, 0.0997, 0.1055, 0.1096, 0.1118, 0.1081, 0.1053, 0.0989, 0.0934,\n",
      "         0.0777],\n",
      "        [0.0896, 0.0997, 0.1056, 0.1098, 0.1121, 0.1082, 0.1053, 0.0989, 0.0933,\n",
      "         0.0775],\n",
      "        [0.0896, 0.0997, 0.1057, 0.1099, 0.1121, 0.1082, 0.1053, 0.0988, 0.0932,\n",
      "         0.0773],\n",
      "        [0.0896, 0.0998, 0.1057, 0.1100, 0.1121, 0.1082, 0.1053, 0.0988, 0.0932,\n",
      "         0.0773],\n",
      "        [0.0897, 0.0998, 0.1057, 0.1100, 0.1121, 0.1082, 0.1053, 0.0989, 0.0932,\n",
      "         0.0772],\n",
      "        [0.0897, 0.0998, 0.1057, 0.1099, 0.1121, 0.1082, 0.1053, 0.0989, 0.0932,\n",
      "         0.0772],\n",
      "        [0.0897, 0.0998, 0.1057, 0.1099, 0.1121, 0.1082, 0.1053, 0.0989, 0.0932,\n",
      "         0.0772],\n",
      "        [0.0898, 0.0998, 0.1057, 0.1099, 0.1121, 0.1082, 0.1053, 0.0989, 0.0932,\n",
      "         0.0772],\n",
      "        [0.0898, 0.0998, 0.1057, 0.1099, 0.1120, 0.1081, 0.1053, 0.0988, 0.0932,\n",
      "         0.0772]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6 岁 那年 塔利 塔利班 占领 阿富汗 并 规定\n",
      "Reference: you see , i was six when the taliban\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[1.0156e-01, 1.1444e-01, 1.1861e-01, 1.1716e-01, 1.2036e-01, 1.2365e-01,\n",
      "         1.1881e-01, 1.0280e-01, 8.2606e-02, 5.5462e-06],\n",
      "        [1.0132e-01, 1.1439e-01, 1.1864e-01, 1.1725e-01, 1.2054e-01, 1.2387e-01,\n",
      "         1.1894e-01, 1.0273e-01, 8.2314e-02, 5.4978e-06],\n",
      "        [1.0129e-01, 1.1442e-01, 1.1866e-01, 1.1729e-01, 1.2063e-01, 1.2396e-01,\n",
      "         1.1895e-01, 1.0264e-01, 8.2164e-02, 5.7561e-06],\n",
      "        [1.0133e-01, 1.1445e-01, 1.1866e-01, 1.1727e-01, 1.2061e-01, 1.2397e-01,\n",
      "         1.1895e-01, 1.0261e-01, 8.2142e-02, 5.9357e-06],\n",
      "        [1.0139e-01, 1.1447e-01, 1.1865e-01, 1.1724e-01, 1.2058e-01, 1.2395e-01,\n",
      "         1.1894e-01, 1.0260e-01, 8.2171e-02, 6.0214e-06],\n",
      "        [1.0142e-01, 1.1448e-01, 1.1864e-01, 1.1721e-01, 1.2054e-01, 1.2392e-01,\n",
      "         1.1893e-01, 1.0262e-01, 8.2227e-02, 6.0376e-06],\n",
      "        [1.0142e-01, 1.1447e-01, 1.1862e-01, 1.1719e-01, 1.2052e-01, 1.2391e-01,\n",
      "         1.1894e-01, 1.0265e-01, 8.2282e-02, 6.0209e-06],\n",
      "        [1.0143e-01, 1.1448e-01, 1.1862e-01, 1.1718e-01, 1.2051e-01, 1.2390e-01,\n",
      "         1.1894e-01, 1.0265e-01, 8.2297e-02, 6.0272e-06],\n",
      "        [1.0144e-01, 1.1449e-01, 1.1862e-01, 1.1718e-01, 1.2050e-01, 1.2389e-01,\n",
      "         1.1893e-01, 1.0264e-01, 8.2304e-02, 6.0025e-06]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 3.00, Train Loss: 8.96, Val Loss: 9.80, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里 生物 的 多样 多样性 和 密度 要 比\n",
      "Reference: the biodiversity and the <UNK> in the ocean is\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0783, 0.1003, 0.1077, 0.1140, 0.1091, 0.1021, 0.1120, 0.1055, 0.0968,\n",
      "         0.0743],\n",
      "        [0.0774, 0.1000, 0.1078, 0.1144, 0.1096, 0.1025, 0.1125, 0.1056, 0.0966,\n",
      "         0.0735],\n",
      "        [0.0772, 0.1000, 0.1079, 0.1145, 0.1097, 0.1027, 0.1127, 0.1056, 0.0965,\n",
      "         0.0732],\n",
      "        [0.0772, 0.1000, 0.1079, 0.1146, 0.1097, 0.1028, 0.1128, 0.1056, 0.0964,\n",
      "         0.0731],\n",
      "        [0.0772, 0.1001, 0.1079, 0.1145, 0.1097, 0.1028, 0.1127, 0.1056, 0.0964,\n",
      "         0.0731],\n",
      "        [0.0773, 0.1001, 0.1080, 0.1145, 0.1096, 0.1028, 0.1127, 0.1055, 0.0964,\n",
      "         0.0731],\n",
      "        [0.0774, 0.1001, 0.1080, 0.1145, 0.1096, 0.1028, 0.1127, 0.1055, 0.0964,\n",
      "         0.0731],\n",
      "        [0.0775, 0.1002, 0.1079, 0.1144, 0.1095, 0.1027, 0.1126, 0.1055, 0.0964,\n",
      "         0.0733],\n",
      "        [0.0775, 0.1002, 0.1079, 0.1144, 0.1095, 0.1027, 0.1126, 0.1055, 0.0964,\n",
      "         0.0733]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 这 是 我们 俩 人 唯一 的 受教 教育 方式\n",
      "Reference: it was the only way we both could be\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0826, 0.1045, 0.1156, 0.1167, 0.1120, 0.1115, 0.1047, 0.1016, 0.0882,\n",
      "         0.0627],\n",
      "        [0.0818, 0.1044, 0.1158, 0.1171, 0.1124, 0.1120, 0.1050, 0.1017, 0.0879,\n",
      "         0.0618],\n",
      "        [0.0816, 0.1044, 0.1160, 0.1173, 0.1125, 0.1122, 0.1051, 0.1018, 0.0877,\n",
      "         0.0615],\n",
      "        [0.0816, 0.1045, 0.1160, 0.1173, 0.1125, 0.1122, 0.1050, 0.1018, 0.0876,\n",
      "         0.0614],\n",
      "        [0.0817, 0.1046, 0.1161, 0.1173, 0.1125, 0.1121, 0.1050, 0.1017, 0.0876,\n",
      "         0.0614],\n",
      "        [0.0818, 0.1046, 0.1161, 0.1173, 0.1124, 0.1121, 0.1049, 0.1017, 0.0876,\n",
      "         0.0614],\n",
      "        [0.0819, 0.1046, 0.1161, 0.1173, 0.1124, 0.1120, 0.1049, 0.1017, 0.0876,\n",
      "         0.0615],\n",
      "        [0.0820, 0.1047, 0.1161, 0.1172, 0.1124, 0.1120, 0.1049, 0.1016, 0.0876,\n",
      "         0.0615],\n",
      "        [0.0820, 0.1047, 0.1162, 0.1172, 0.1124, 0.1120, 0.1049, 0.1016, 0.0876,\n",
      "         0.0615]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4.00, Train Loss: 8.39, Val Loss: 9.58, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地 地球 上 最长 的 山脉 都 在 海洋\n",
      "Reference: and in the oceans , there are the longest\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0612, 0.0898, 0.1079, 0.1261, 0.1271, 0.1294, 0.1204, 0.1093, 0.0829,\n",
      "         0.0459],\n",
      "        [0.0595, 0.0889, 0.1079, 0.1270, 0.1282, 0.1307, 0.1214, 0.1097, 0.0822,\n",
      "         0.0445],\n",
      "        [0.0590, 0.0887, 0.1080, 0.1274, 0.1287, 0.1312, 0.1217, 0.1098, 0.0818,\n",
      "         0.0439],\n",
      "        [0.0588, 0.0887, 0.1080, 0.1275, 0.1288, 0.1313, 0.1217, 0.1097, 0.0817,\n",
      "         0.0437],\n",
      "        [0.0589, 0.0887, 0.1081, 0.1275, 0.1288, 0.1313, 0.1217, 0.1097, 0.0816,\n",
      "         0.0437],\n",
      "        [0.0590, 0.0888, 0.1081, 0.1275, 0.1288, 0.1312, 0.1216, 0.1096, 0.0816,\n",
      "         0.0438],\n",
      "        [0.0591, 0.0888, 0.1081, 0.1274, 0.1287, 0.1312, 0.1216, 0.1096, 0.0816,\n",
      "         0.0438],\n",
      "        [0.0591, 0.0889, 0.1081, 0.1274, 0.1287, 0.1311, 0.1215, 0.1095, 0.0816,\n",
      "         0.0438],\n",
      "        [0.0592, 0.0889, 0.1081, 0.1274, 0.1287, 0.1311, 0.1215, 0.1095, 0.0816,\n",
      "         0.0439]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 那 就是 她 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: there she is . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[7.4879e-02, 1.1148e-01, 1.4344e-01, 1.5750e-01, 1.5275e-01, 1.3739e-01,\n",
      "         1.1619e-01, 7.7412e-02, 2.8959e-02, 2.6499e-07],\n",
      "        [7.2976e-02, 1.1065e-01, 1.4402e-01, 1.5889e-01, 1.5422e-01, 1.3839e-01,\n",
      "         1.1651e-01, 7.6567e-02, 2.7767e-02, 2.9581e-07],\n",
      "        [7.2335e-02, 1.1048e-01, 1.4437e-01, 1.5949e-01, 1.5475e-01, 1.3867e-01,\n",
      "         1.1646e-01, 7.6094e-02, 2.7352e-02, 3.3654e-07],\n",
      "        [7.2136e-02, 1.1046e-01, 1.4451e-01, 1.5970e-01, 1.5492e-01, 1.3873e-01,\n",
      "         1.1640e-01, 7.5927e-02, 2.7233e-02, 3.5617e-07],\n",
      "        [7.2127e-02, 1.1049e-01, 1.4454e-01, 1.5972e-01, 1.5491e-01, 1.3869e-01,\n",
      "         1.1636e-01, 7.5912e-02, 2.7250e-02, 3.6822e-07],\n",
      "        [7.2185e-02, 1.1053e-01, 1.4454e-01, 1.5968e-01, 1.5485e-01, 1.3864e-01,\n",
      "         1.1633e-01, 7.5937e-02, 2.7298e-02, 3.7555e-07],\n",
      "        [7.2268e-02, 1.1059e-01, 1.4452e-01, 1.5963e-01, 1.5478e-01, 1.3859e-01,\n",
      "         1.1631e-01, 7.5964e-02, 2.7345e-02, 3.7864e-07],\n",
      "        [7.2341e-02, 1.1063e-01, 1.4451e-01, 1.5958e-01, 1.5473e-01, 1.3855e-01,\n",
      "         1.1629e-01, 7.5987e-02, 2.7380e-02, 3.7906e-07],\n",
      "        [7.2389e-02, 1.1066e-01, 1.4451e-01, 1.5956e-01, 1.5469e-01, 1.3852e-01,\n",
      "         1.1628e-01, 7.5993e-02, 2.7395e-02, 3.7894e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 5.00, Train Loss: 7.85, Val Loss: 9.37, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一只 水母 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: here &apos;s a jelly . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[2.2473e-01, 3.1504e-01, 2.6088e-01, 1.5313e-01, 4.6226e-02, 2.0385e-07,\n",
      "         2.0385e-07, 2.0385e-07, 2.0385e-07, 2.0385e-07],\n",
      "        [2.2179e-01, 3.1889e-01, 2.6357e-01, 1.5181e-01, 4.3935e-02, 2.8751e-07,\n",
      "         2.8751e-07, 2.8751e-07, 2.8751e-07, 2.8751e-07],\n",
      "        [2.2095e-01, 3.2014e-01, 2.6426e-01, 1.5127e-01, 4.3373e-02, 3.6054e-07,\n",
      "         3.6054e-07, 3.6054e-07, 3.6054e-07, 3.6054e-07],\n",
      "        [2.2058e-01, 3.2047e-01, 2.6449e-01, 1.5120e-01, 4.3265e-02, 3.9510e-07,\n",
      "         3.9510e-07, 3.9510e-07, 3.9510e-07, 3.9510e-07],\n",
      "        [2.2040e-01, 3.2048e-01, 2.6454e-01, 1.5126e-01, 4.3316e-02, 4.0882e-07,\n",
      "         4.0882e-07, 4.0882e-07, 4.0882e-07, 4.0882e-07],\n",
      "        [2.2044e-01, 3.2046e-01, 2.6448e-01, 1.5126e-01, 4.3366e-02, 4.2377e-07,\n",
      "         4.2377e-07, 4.2377e-07, 4.2377e-07, 4.2377e-07],\n",
      "        [2.2048e-01, 3.2039e-01, 2.6442e-01, 1.5128e-01, 4.3425e-02, 4.2848e-07,\n",
      "         4.2848e-07, 4.2848e-07, 4.2848e-07, 4.2848e-07],\n",
      "        [2.2061e-01, 3.2036e-01, 2.6432e-01, 1.5125e-01, 4.3460e-02, 4.3501e-07,\n",
      "         4.3501e-07, 4.3501e-07, 4.3501e-07, 4.3501e-07],\n",
      "        [2.2063e-01, 3.2030e-01, 2.6430e-01, 1.5129e-01, 4.3489e-02, 4.2745e-07,\n",
      "         4.2745e-07, 4.2745e-07, 4.2745e-07, 4.2745e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天 要 走 不同 的 路线 这样 才 没有\n",
      "Reference: each day , we took a different route so\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0490, 0.0859, 0.1112, 0.1339, 0.1354, 0.1376, 0.1261, 0.1112, 0.0765,\n",
      "         0.0331],\n",
      "        [0.0461, 0.0841, 0.1111, 0.1355, 0.1374, 0.1400, 0.1277, 0.1118, 0.0752,\n",
      "         0.0310],\n",
      "        [0.0454, 0.0838, 0.1113, 0.1361, 0.1381, 0.1407, 0.1281, 0.1117, 0.0745,\n",
      "         0.0304],\n",
      "        [0.0452, 0.0837, 0.1113, 0.1363, 0.1383, 0.1409, 0.1281, 0.1116, 0.0743,\n",
      "         0.0302],\n",
      "        [0.0452, 0.0837, 0.1114, 0.1363, 0.1383, 0.1409, 0.1281, 0.1116, 0.0742,\n",
      "         0.0302],\n",
      "        [0.0453, 0.0838, 0.1114, 0.1363, 0.1383, 0.1409, 0.1281, 0.1116, 0.0742,\n",
      "         0.0302],\n",
      "        [0.0453, 0.0838, 0.1114, 0.1363, 0.1382, 0.1408, 0.1280, 0.1115, 0.0742,\n",
      "         0.0303],\n",
      "        [0.0454, 0.0839, 0.1114, 0.1363, 0.1382, 0.1408, 0.1280, 0.1115, 0.0742,\n",
      "         0.0303],\n",
      "        [0.0455, 0.0839, 0.1114, 0.1363, 0.1382, 0.1407, 0.1280, 0.1115, 0.0742,\n",
      "         0.0303]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 6.00, Train Loss: 7.35, Val Loss: 9.19, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分 部分 的 动物 也 都 生活 在 海洋\n",
      "Reference: most of the animals are in the oceans .\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0372, 0.0717, 0.1106, 0.1386, 0.1447, 0.1495, 0.1383, 0.1085, 0.0743,\n",
      "         0.0265],\n",
      "        [0.0334, 0.0683, 0.1100, 0.1410, 0.1482, 0.1535, 0.1411, 0.1086, 0.0721,\n",
      "         0.0240],\n",
      "        [0.0326, 0.0676, 0.1099, 0.1417, 0.1491, 0.1545, 0.1417, 0.1084, 0.0712,\n",
      "         0.0233],\n",
      "        [0.0324, 0.0675, 0.1099, 0.1418, 0.1493, 0.1547, 0.1418, 0.1084, 0.0710,\n",
      "         0.0232],\n",
      "        [0.0324, 0.0674, 0.1099, 0.1418, 0.1494, 0.1547, 0.1418, 0.1083, 0.0710,\n",
      "         0.0232],\n",
      "        [0.0324, 0.0675, 0.1099, 0.1418, 0.1494, 0.1547, 0.1418, 0.1083, 0.0710,\n",
      "         0.0232],\n",
      "        [0.0324, 0.0675, 0.1099, 0.1418, 0.1494, 0.1547, 0.1417, 0.1083, 0.0710,\n",
      "         0.0232],\n",
      "        [0.0324, 0.0675, 0.1100, 0.1418, 0.1493, 0.1547, 0.1417, 0.1083, 0.0710,\n",
      "         0.0232],\n",
      "        [0.0325, 0.0676, 0.1100, 0.1418, 0.1493, 0.1546, 0.1417, 0.1083, 0.0710,\n",
      "         0.0232]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很 舒服 但 夏天 却 <UNK> <EOS> <PAD> <PAD>\n",
      "Reference: it was cozy in winter but extremely hot in\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0440, 0.0974, 0.1228, 0.1382, 0.1279, 0.1047, 0.1304, 0.1134, 0.0854,\n",
      "         0.0359],\n",
      "        [0.0400, 0.0955, 0.1238, 0.1410, 0.1302, 0.1050, 0.1330, 0.1143, 0.0841,\n",
      "         0.0332],\n",
      "        [0.0393, 0.0952, 0.1241, 0.1418, 0.1308, 0.1049, 0.1335, 0.1144, 0.0835,\n",
      "         0.0324],\n",
      "        [0.0392, 0.0951, 0.1243, 0.1420, 0.1309, 0.1048, 0.1336, 0.1144, 0.0834,\n",
      "         0.0323],\n",
      "        [0.0392, 0.0951, 0.1243, 0.1420, 0.1309, 0.1047, 0.1336, 0.1144, 0.0834,\n",
      "         0.0323],\n",
      "        [0.0392, 0.0952, 0.1243, 0.1420, 0.1308, 0.1046, 0.1336, 0.1145, 0.0834,\n",
      "         0.0324],\n",
      "        [0.0392, 0.0952, 0.1243, 0.1420, 0.1308, 0.1046, 0.1336, 0.1145, 0.0834,\n",
      "         0.0324],\n",
      "        [0.0393, 0.0952, 0.1243, 0.1420, 0.1307, 0.1045, 0.1336, 0.1145, 0.0835,\n",
      "         0.0324],\n",
      "        [0.0393, 0.0953, 0.1243, 0.1420, 0.1307, 0.1045, 0.1336, 0.1145, 0.0835,\n",
      "         0.0324]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 7.00, Train Loss: 6.88, Val Loss: 9.03, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 通过 潜水 潜水艇 拍下 的 影片 把 我们\n",
      "Reference: with vibrant video clips captured by submarines , david\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0256, 0.0257, 0.0889, 0.1197, 0.1002, 0.1608, 0.1791, 0.1549, 0.1099,\n",
      "         0.0352],\n",
      "        [0.0219, 0.0223, 0.0856, 0.1191, 0.0983, 0.1657, 0.1868, 0.1592, 0.1092,\n",
      "         0.0319],\n",
      "        [0.0213, 0.0218, 0.0851, 0.1190, 0.0979, 0.1667, 0.1883, 0.1598, 0.1088,\n",
      "         0.0313],\n",
      "        [0.0212, 0.0218, 0.0849, 0.1190, 0.0979, 0.1669, 0.1885, 0.1599, 0.1087,\n",
      "         0.0312],\n",
      "        [0.0212, 0.0218, 0.0849, 0.1190, 0.0979, 0.1669, 0.1885, 0.1599, 0.1087,\n",
      "         0.0312],\n",
      "        [0.0212, 0.0218, 0.0849, 0.1190, 0.0979, 0.1669, 0.1885, 0.1599, 0.1087,\n",
      "         0.0312],\n",
      "        [0.0212, 0.0218, 0.0850, 0.1190, 0.0979, 0.1669, 0.1885, 0.1599, 0.1087,\n",
      "         0.0312],\n",
      "        [0.0212, 0.0218, 0.0850, 0.1190, 0.0979, 0.1669, 0.1884, 0.1599, 0.1087,\n",
      "         0.0313],\n",
      "        [0.0212, 0.0218, 0.0850, 0.1190, 0.0979, 0.1669, 0.1884, 0.1598, 0.1087,\n",
      "         0.0313]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班 走 了 父亲 大声 叫 着 <EOS> <PAD>\n",
      "Reference: &quot; the taliban are gone ! &quot; my father\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0405, 0.1009, 0.1339, 0.1379, 0.1395, 0.1368, 0.1244, 0.1010, 0.0637,\n",
      "         0.0215],\n",
      "        [0.0357, 0.0982, 0.1356, 0.1410, 0.1431, 0.1402, 0.1264, 0.1004, 0.0605,\n",
      "         0.0188],\n",
      "        [0.0350, 0.0979, 0.1360, 0.1417, 0.1438, 0.1408, 0.1266, 0.1002, 0.0598,\n",
      "         0.0183],\n",
      "        [0.0349, 0.0977, 0.1360, 0.1418, 0.1439, 0.1409, 0.1267, 0.1002, 0.0597,\n",
      "         0.0182],\n",
      "        [0.0349, 0.0977, 0.1360, 0.1418, 0.1439, 0.1409, 0.1267, 0.1002, 0.0597,\n",
      "         0.0182],\n",
      "        [0.0348, 0.0977, 0.1360, 0.1418, 0.1439, 0.1410, 0.1267, 0.1002, 0.0597,\n",
      "         0.0182],\n",
      "        [0.0349, 0.0977, 0.1360, 0.1418, 0.1439, 0.1409, 0.1267, 0.1002, 0.0597,\n",
      "         0.0182],\n",
      "        [0.0349, 0.0977, 0.1360, 0.1418, 0.1439, 0.1409, 0.1267, 0.1002, 0.0597,\n",
      "         0.0182],\n",
      "        [0.0349, 0.0977, 0.1360, 0.1418, 0.1439, 0.1409, 0.1267, 0.1002, 0.0597,\n",
      "         0.0182]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8.00, Train Loss: 6.46, Val Loss: 8.90, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数 多数 地震 和 火山 喷发 也 都 发生\n",
      "Reference: most of the earthquakes and volcanoes are in the\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0243, 0.0450, 0.1048, 0.1369, 0.1536, 0.1503, 0.1453, 0.1303, 0.0855,\n",
      "         0.0241],\n",
      "        [0.0200, 0.0398, 0.1022, 0.1387, 0.1586, 0.1553, 0.1495, 0.1323, 0.0827,\n",
      "         0.0208],\n",
      "        [0.0196, 0.0393, 0.1019, 0.1390, 0.1593, 0.1560, 0.1500, 0.1323, 0.0821,\n",
      "         0.0204],\n",
      "        [0.0195, 0.0393, 0.1018, 0.1390, 0.1594, 0.1561, 0.1501, 0.1323, 0.0821,\n",
      "         0.0203],\n",
      "        [0.0195, 0.0392, 0.1017, 0.1390, 0.1595, 0.1562, 0.1501, 0.1323, 0.0821,\n",
      "         0.0203],\n",
      "        [0.0195, 0.0392, 0.1017, 0.1390, 0.1595, 0.1562, 0.1501, 0.1323, 0.0821,\n",
      "         0.0204],\n",
      "        [0.0195, 0.0393, 0.1017, 0.1390, 0.1594, 0.1562, 0.1501, 0.1323, 0.0821,\n",
      "         0.0204],\n",
      "        [0.0195, 0.0393, 0.1017, 0.1390, 0.1594, 0.1562, 0.1501, 0.1323, 0.0821,\n",
      "         0.0204],\n",
      "        [0.0195, 0.0393, 0.1017, 0.1390, 0.1594, 0.1562, 0.1501, 0.1323, 0.0821,\n",
      "         0.0204]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 所以 在 那 之后 5 年 我 <UNK> <UNK> 陪\n",
      "Reference: so for the next five years , i dressed\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[6.2609e-02, 1.6925e-01, 2.1622e-01, 2.2051e-01, 1.8777e-01, 8.4898e-02,\n",
      "         5.2139e-02, 6.6060e-03, 4.2828e-09, 4.2828e-09],\n",
      "        [5.5094e-02, 1.6720e-01, 2.2228e-01, 2.2899e-01, 1.9184e-01, 8.0974e-02,\n",
      "         4.8131e-02, 5.4950e-03, 1.1854e-08, 1.1854e-08],\n",
      "        [5.4323e-02, 1.6683e-01, 2.2290e-01, 2.3008e-01, 1.9235e-01, 8.0541e-02,\n",
      "         4.7591e-02, 5.3871e-03, 1.4899e-08, 1.4899e-08],\n",
      "        [5.4109e-02, 1.6664e-01, 2.2291e-01, 2.3029e-01, 1.9254e-01, 8.0585e-02,\n",
      "         4.7552e-02, 5.3740e-03, 1.5243e-08, 1.5243e-08],\n",
      "        [5.4018e-02, 1.6654e-01, 2.2289e-01, 2.3036e-01, 1.9262e-01, 8.0638e-02,\n",
      "         4.7555e-02, 5.3747e-03, 1.5278e-08, 1.5278e-08],\n",
      "        [5.3973e-02, 1.6649e-01, 2.2289e-01, 2.3040e-01, 1.9266e-01, 8.0663e-02,\n",
      "         4.7549e-02, 5.3745e-03, 1.5294e-08, 1.5294e-08],\n",
      "        [5.3948e-02, 1.6647e-01, 2.2289e-01, 2.3042e-01, 1.9268e-01, 8.0678e-02,\n",
      "         4.7543e-02, 5.3741e-03, 1.5300e-08, 1.5300e-08],\n",
      "        [5.3948e-02, 1.6646e-01, 2.2287e-01, 2.3041e-01, 1.9268e-01, 8.0698e-02,\n",
      "         4.7551e-02, 5.3769e-03, 1.5282e-08, 1.5282e-08],\n",
      "        [5.3946e-02, 1.6646e-01, 2.2287e-01, 2.3041e-01, 1.9268e-01, 8.0706e-02,\n",
      "         4.7550e-02, 5.3774e-03, 1.5277e-08, 1.5277e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 9.00, Train Loss: 6.06, Val Loss: 8.79, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的 平均 深度 是 两英里 英里 <EOS> <PAD> <PAD>\n",
      "Reference: the average depth is about two miles . <EOS>\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[5.7018e-02, 1.6456e-01, 2.1213e-01, 2.1875e-01, 1.9132e-01, 9.3642e-02,\n",
      "         5.6598e-02, 5.9767e-03, 2.1051e-09, 2.1051e-09],\n",
      "        [4.9290e-02, 1.6192e-01, 2.1816e-01, 2.2762e-01, 1.9612e-01, 8.9746e-02,\n",
      "         5.2203e-02, 4.9392e-03, 7.4501e-09, 7.4501e-09],\n",
      "        [4.8747e-02, 1.6155e-01, 2.1855e-01, 2.2845e-01, 1.9662e-01, 8.9463e-02,\n",
      "         5.1768e-02, 4.8579e-03, 9.1544e-09, 9.1544e-09],\n",
      "        [4.8610e-02, 1.6142e-01, 2.1852e-01, 2.2855e-01, 1.9676e-01, 8.9535e-02,\n",
      "         5.1763e-02, 4.8477e-03, 9.1707e-09, 9.1707e-09],\n",
      "        [4.8552e-02, 1.6134e-01, 2.1847e-01, 2.2857e-01, 1.9681e-01, 8.9613e-02,\n",
      "         5.1790e-02, 4.8502e-03, 9.0838e-09, 9.0838e-09],\n",
      "        [4.8521e-02, 1.6130e-01, 2.1845e-01, 2.2857e-01, 1.9684e-01, 8.9662e-02,\n",
      "         5.1807e-02, 4.8525e-03, 9.0161e-09, 9.0161e-09],\n",
      "        [4.8497e-02, 1.6127e-01, 2.1843e-01, 2.2858e-01, 1.9686e-01, 8.9693e-02,\n",
      "         5.1816e-02, 4.8539e-03, 8.9650e-09, 8.9650e-09],\n",
      "        [4.8489e-02, 1.6126e-01, 2.1842e-01, 2.2857e-01, 1.9686e-01, 8.9719e-02,\n",
      "         5.1830e-02, 4.8568e-03, 8.9273e-09, 8.9273e-09],\n",
      "        [4.8477e-02, 1.6124e-01, 2.1841e-01, 2.2858e-01, 1.9687e-01, 8.9728e-02,\n",
      "         5.1832e-02, 4.8574e-03, 8.9060e-09, 8.9060e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 很 害怕 但是 我们 仍然 渴望 望去 学校 <EOS>\n",
      "Reference: we were scared , but still , school was\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0366, 0.0880, 0.1171, 0.1323, 0.1354, 0.1374, 0.1289, 0.1145, 0.0836,\n",
      "         0.0263],\n",
      "        [0.0309, 0.0839, 0.1174, 0.1355, 0.1394, 0.1420, 0.1322, 0.1154, 0.0807,\n",
      "         0.0226],\n",
      "        [0.0305, 0.0835, 0.1173, 0.1357, 0.1398, 0.1425, 0.1326, 0.1154, 0.0803,\n",
      "         0.0223],\n",
      "        [0.0304, 0.0835, 0.1173, 0.1358, 0.1399, 0.1425, 0.1326, 0.1155, 0.0803,\n",
      "         0.0223],\n",
      "        [0.0304, 0.0835, 0.1173, 0.1358, 0.1398, 0.1425, 0.1326, 0.1155, 0.0803,\n",
      "         0.0224],\n",
      "        [0.0304, 0.0835, 0.1173, 0.1358, 0.1398, 0.1425, 0.1326, 0.1155, 0.0804,\n",
      "         0.0224],\n",
      "        [0.0304, 0.0835, 0.1173, 0.1358, 0.1398, 0.1424, 0.1326, 0.1155, 0.0804,\n",
      "         0.0224],\n",
      "        [0.0304, 0.0835, 0.1173, 0.1358, 0.1398, 0.1424, 0.1326, 0.1155, 0.0804,\n",
      "         0.0224],\n",
      "        [0.0304, 0.0835, 0.1173, 0.1358, 0.1398, 0.1424, 0.1326, 0.1155, 0.0804,\n",
      "         0.0224]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 10.00, Train Loss: 5.71, Val Loss: 8.71, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地 地球 上 最长 的 山脉 都 在 海洋\n",
      "Reference: and in the oceans , there are the longest\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0296, 0.0847, 0.1165, 0.1330, 0.1367, 0.1390, 0.1340, 0.1220, 0.0834,\n",
      "         0.0211],\n",
      "        [0.0244, 0.0803, 0.1166, 0.1362, 0.1409, 0.1436, 0.1374, 0.1232, 0.0798,\n",
      "         0.0177],\n",
      "        [0.0242, 0.0800, 0.1165, 0.1364, 0.1412, 0.1439, 0.1376, 0.1233, 0.0795,\n",
      "         0.0175],\n",
      "        [0.0241, 0.0800, 0.1165, 0.1364, 0.1412, 0.1438, 0.1376, 0.1233, 0.0796,\n",
      "         0.0176],\n",
      "        [0.0242, 0.0800, 0.1165, 0.1364, 0.1411, 0.1438, 0.1376, 0.1232, 0.0796,\n",
      "         0.0176],\n",
      "        [0.0242, 0.0800, 0.1165, 0.1363, 0.1411, 0.1438, 0.1375, 0.1232, 0.0797,\n",
      "         0.0176],\n",
      "        [0.0242, 0.0800, 0.1165, 0.1363, 0.1411, 0.1438, 0.1375, 0.1232, 0.0797,\n",
      "         0.0177],\n",
      "        [0.0241, 0.0800, 0.1165, 0.1363, 0.1411, 0.1438, 0.1375, 0.1232, 0.0797,\n",
      "         0.0177],\n",
      "        [0.0241, 0.0800, 0.1165, 0.1363, 0.1411, 0.1438, 0.1375, 0.1232, 0.0797,\n",
      "         0.0177]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 父亲 在 用 他 的 灰色 小 收音\n",
      "Reference: my father was listening to bbc news on his\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0216, 0.0293, 0.0997, 0.1296, 0.1150, 0.1563, 0.1647, 0.1485, 0.1071,\n",
      "         0.0282],\n",
      "        [0.0175, 0.0250, 0.0965, 0.1305, 0.1142, 0.1619, 0.1721, 0.1527, 0.1053,\n",
      "         0.0244],\n",
      "        [0.0172, 0.0247, 0.0962, 0.1304, 0.1142, 0.1624, 0.1726, 0.1529, 0.1052,\n",
      "         0.0242],\n",
      "        [0.0172, 0.0247, 0.0962, 0.1304, 0.1141, 0.1624, 0.1726, 0.1529, 0.1052,\n",
      "         0.0243],\n",
      "        [0.0172, 0.0247, 0.0962, 0.1303, 0.1141, 0.1623, 0.1726, 0.1529, 0.1053,\n",
      "         0.0243],\n",
      "        [0.0172, 0.0247, 0.0962, 0.1304, 0.1141, 0.1623, 0.1725, 0.1529, 0.1053,\n",
      "         0.0244],\n",
      "        [0.0172, 0.0247, 0.0962, 0.1304, 0.1141, 0.1623, 0.1725, 0.1529, 0.1053,\n",
      "         0.0244],\n",
      "        [0.0172, 0.0247, 0.0963, 0.1304, 0.1141, 0.1623, 0.1725, 0.1529, 0.1053,\n",
      "         0.0244],\n",
      "        [0.0172, 0.0247, 0.0962, 0.1304, 0.1141, 0.1623, 0.1725, 0.1529, 0.1053,\n",
      "         0.0244]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 11.00, Train Loss: 5.40, Val Loss: 8.65, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 底下 这些 都 是 <UNK> 它们 上上 上上下下 上下 下下\n",
      "Reference: it &apos;s got these fishing <UNK> on the bottom\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0392, 0.1169, 0.1589, 0.1598, 0.1091, 0.1488, 0.1111, 0.0991, 0.0524,\n",
      "         0.0048],\n",
      "        [0.0337, 0.1148, 0.1641, 0.1661, 0.1093, 0.1532, 0.1107, 0.0965, 0.0477,\n",
      "         0.0039],\n",
      "        [0.0335, 0.1145, 0.1642, 0.1662, 0.1092, 0.1536, 0.1108, 0.0965, 0.0476,\n",
      "         0.0039],\n",
      "        [0.0335, 0.1145, 0.1641, 0.1661, 0.1091, 0.1537, 0.1109, 0.0966, 0.0477,\n",
      "         0.0039],\n",
      "        [0.0335, 0.1144, 0.1639, 0.1660, 0.1091, 0.1537, 0.1110, 0.0967, 0.0478,\n",
      "         0.0039],\n",
      "        [0.0335, 0.1144, 0.1639, 0.1659, 0.1091, 0.1537, 0.1110, 0.0967, 0.0478,\n",
      "         0.0039],\n",
      "        [0.0335, 0.1144, 0.1639, 0.1659, 0.1091, 0.1537, 0.1110, 0.0967, 0.0478,\n",
      "         0.0039],\n",
      "        [0.0335, 0.1144, 0.1639, 0.1659, 0.1091, 0.1537, 0.1110, 0.0967, 0.0478,\n",
      "         0.0039],\n",
      "        [0.0335, 0.1144, 0.1639, 0.1659, 0.1092, 0.1537, 0.1110, 0.0967, 0.0479,\n",
      "         0.0039]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 很 幸运 幸运地 成长 在 一个 珍视 教育 也\n",
      "Reference: i was very lucky to grow up in a\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[1.4376e-01, 3.3617e-01, 3.3187e-01, 1.7262e-01, 1.5574e-02, 1.5216e-09,\n",
      "         1.5216e-09, 1.5216e-09, 1.5216e-09, 1.5216e-09],\n",
      "        [1.3077e-01, 3.4397e-01, 3.4337e-01, 1.6835e-01, 1.3548e-02, 9.4298e-09,\n",
      "         9.4298e-09, 9.4298e-09, 9.4298e-09, 9.4298e-09],\n",
      "        [1.3013e-01, 3.4415e-01, 3.4408e-01, 1.6821e-01, 1.3421e-02, 1.1331e-08,\n",
      "         1.1331e-08, 1.1331e-08, 1.1331e-08, 1.1331e-08],\n",
      "        [1.2999e-01, 3.4406e-01, 3.4416e-01, 1.6838e-01, 1.3417e-02, 1.1158e-08,\n",
      "         1.1158e-08, 1.1158e-08, 1.1158e-08, 1.1158e-08],\n",
      "        [1.2996e-01, 3.4394e-01, 3.4412e-01, 1.6853e-01, 1.3453e-02, 1.0980e-08,\n",
      "         1.0980e-08, 1.0980e-08, 1.0980e-08, 1.0980e-08],\n",
      "        [1.2990e-01, 3.4391e-01, 3.4412e-01, 1.6860e-01, 1.3461e-02, 1.0803e-08,\n",
      "         1.0803e-08, 1.0803e-08, 1.0803e-08, 1.0803e-08],\n",
      "        [1.2986e-01, 3.4389e-01, 3.4414e-01, 1.6865e-01, 1.3466e-02, 1.0679e-08,\n",
      "         1.0679e-08, 1.0679e-08, 1.0679e-08, 1.0679e-08],\n",
      "        [1.2980e-01, 3.4390e-01, 3.4417e-01, 1.6867e-01, 1.3463e-02, 1.0582e-08,\n",
      "         1.0582e-08, 1.0582e-08, 1.0582e-08, 1.0582e-08],\n",
      "        [1.2975e-01, 3.4390e-01, 3.4420e-01, 1.6869e-01, 1.3460e-02, 1.0495e-08,\n",
      "         1.0495e-08, 1.0495e-08, 1.0495e-08, 1.0495e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12.00, Train Loss: 5.13, Val Loss: 8.64, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 原来 它 是 海洋 洋中 最长 的 生物 <EOS> <PAD>\n",
      "Reference: this turns out to be the longest creature in\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[4.1061e-02, 1.2376e-01, 1.5786e-01, 1.6129e-01, 1.3720e-01, 1.5914e-01,\n",
      "         1.4181e-01, 7.1598e-02, 6.2811e-03, 3.5813e-10],\n",
      "        [3.4871e-02, 1.2066e-01, 1.6063e-01, 1.6532e-01, 1.3904e-01, 1.6356e-01,\n",
      "         1.4323e-01, 6.7415e-02, 5.2709e-03, 2.3881e-09],\n",
      "        [3.4640e-02, 1.2031e-01, 1.6051e-01, 1.6536e-01, 1.3926e-01, 1.6376e-01,\n",
      "         1.4350e-01, 6.7430e-02, 5.2320e-03, 2.7607e-09],\n",
      "        [3.4593e-02, 1.2022e-01, 1.6038e-01, 1.6527e-01, 1.3935e-01, 1.6379e-01,\n",
      "         1.4362e-01, 6.7544e-02, 5.2317e-03, 2.7052e-09],\n",
      "        [3.4605e-02, 1.2021e-01, 1.6032e-01, 1.6521e-01, 1.3937e-01, 1.6377e-01,\n",
      "         1.4365e-01, 6.7621e-02, 5.2455e-03, 2.6572e-09],\n",
      "        [3.4602e-02, 1.2021e-01, 1.6031e-01, 1.6520e-01, 1.3936e-01, 1.6376e-01,\n",
      "         1.4366e-01, 6.7653e-02, 5.2508e-03, 2.6211e-09],\n",
      "        [3.4589e-02, 1.2022e-01, 1.6031e-01, 1.6519e-01, 1.3935e-01, 1.6376e-01,\n",
      "         1.4366e-01, 6.7667e-02, 5.2517e-03, 2.5912e-09],\n",
      "        [3.4573e-02, 1.2022e-01, 1.6032e-01, 1.6520e-01, 1.3933e-01, 1.6377e-01,\n",
      "         1.4367e-01, 6.7670e-02, 5.2508e-03, 2.5672e-09],\n",
      "        [3.4559e-02, 1.2022e-01, 1.6033e-01, 1.6520e-01, 1.3932e-01, 1.6377e-01,\n",
      "         1.4367e-01, 6.7670e-02, 5.2496e-03, 2.5486e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6 岁 那年 塔利 塔利班 占领 阿富汗 并 规定\n",
      "Reference: you see , i was six when the taliban\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[3.7161e-02, 1.1349e-01, 1.4581e-01, 1.5741e-01, 1.6478e-01, 1.6334e-01,\n",
      "         1.4064e-01, 7.0940e-02, 6.4400e-03, 3.4156e-10],\n",
      "        [3.1237e-02, 1.0946e-01, 1.4707e-01, 1.6119e-01, 1.6985e-01, 1.6801e-01,\n",
      "         1.4143e-01, 6.6399e-02, 5.3682e-03, 2.2482e-09],\n",
      "        [3.1024e-02, 1.0910e-01, 1.4691e-01, 1.6124e-01, 1.7004e-01, 1.6828e-01,\n",
      "         1.4166e-01, 6.6419e-02, 5.3273e-03, 2.5937e-09],\n",
      "        [3.0993e-02, 1.0904e-01, 1.4681e-01, 1.6117e-01, 1.7001e-01, 1.6833e-01,\n",
      "         1.4178e-01, 6.6540e-02, 5.3279e-03, 2.5414e-09],\n",
      "        [3.1011e-02, 1.0906e-01, 1.4678e-01, 1.6112e-01, 1.6997e-01, 1.6830e-01,\n",
      "         1.4180e-01, 6.6620e-02, 5.3414e-03, 2.4952e-09],\n",
      "        [3.1013e-02, 1.0907e-01, 1.4677e-01, 1.6111e-01, 1.6995e-01, 1.6828e-01,\n",
      "         1.4180e-01, 6.6651e-02, 5.3465e-03, 2.4602e-09],\n",
      "        [3.1005e-02, 1.0908e-01, 1.4678e-01, 1.6111e-01, 1.6994e-01, 1.6827e-01,\n",
      "         1.4180e-01, 6.6663e-02, 5.3475e-03, 2.4323e-09],\n",
      "        [3.0989e-02, 1.0907e-01, 1.4678e-01, 1.6112e-01, 1.6995e-01, 1.6828e-01,\n",
      "         1.4180e-01, 6.6664e-02, 5.3459e-03, 2.4094e-09],\n",
      "        [3.0975e-02, 1.0907e-01, 1.4679e-01, 1.6112e-01, 1.6996e-01, 1.6828e-01,\n",
      "         1.4180e-01, 6.6662e-02, 5.3444e-03, 2.3923e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 13.00, Train Loss: 4.91, Val Loss: 8.66, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 通过 潜水 潜水艇 拍下 的 影片 把 我们\n",
      "Reference: with vibrant video clips captured by submarines , david\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0230, 0.0378, 0.1052, 0.1296, 0.1234, 0.1466, 0.1512, 0.1426, 0.1108,\n",
      "         0.0298],\n",
      "        [0.0188, 0.0334, 0.1035, 0.1312, 0.1241, 0.1518, 0.1571, 0.1460, 0.1086,\n",
      "         0.0256],\n",
      "        [0.0187, 0.0332, 0.1032, 0.1311, 0.1241, 0.1518, 0.1572, 0.1462, 0.1088,\n",
      "         0.0257],\n",
      "        [0.0186, 0.0332, 0.1031, 0.1310, 0.1240, 0.1518, 0.1572, 0.1463, 0.1090,\n",
      "         0.0258],\n",
      "        [0.0186, 0.0331, 0.1031, 0.1310, 0.1239, 0.1518, 0.1572, 0.1463, 0.1091,\n",
      "         0.0259],\n",
      "        [0.0186, 0.0331, 0.1031, 0.1309, 0.1239, 0.1518, 0.1572, 0.1463, 0.1092,\n",
      "         0.0260],\n",
      "        [0.0186, 0.0331, 0.1031, 0.1309, 0.1239, 0.1518, 0.1572, 0.1463, 0.1092,\n",
      "         0.0260],\n",
      "        [0.0186, 0.0331, 0.1031, 0.1309, 0.1238, 0.1518, 0.1572, 0.1463, 0.1092,\n",
      "         0.0260],\n",
      "        [0.0185, 0.0331, 0.1031, 0.1309, 0.1238, 0.1518, 0.1572, 0.1463, 0.1092,\n",
      "         0.0260]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 总是 担心 会 被 塔利 塔利班 发现 <EOS> <PAD>\n",
      "Reference: we always wondered what they knew about us .\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0281, 0.0562, 0.1098, 0.1334, 0.1451, 0.1472, 0.1429, 0.1176, 0.0943,\n",
      "         0.0255],\n",
      "        [0.0231, 0.0509, 0.1099, 0.1376, 0.1512, 0.1532, 0.1468, 0.1154, 0.0904,\n",
      "         0.0216],\n",
      "        [0.0229, 0.0506, 0.1097, 0.1376, 0.1513, 0.1534, 0.1469, 0.1154, 0.0905,\n",
      "         0.0217],\n",
      "        [0.0229, 0.0505, 0.1096, 0.1375, 0.1513, 0.1534, 0.1470, 0.1154, 0.0907,\n",
      "         0.0218],\n",
      "        [0.0229, 0.0505, 0.1095, 0.1374, 0.1513, 0.1534, 0.1470, 0.1154, 0.0907,\n",
      "         0.0219],\n",
      "        [0.0229, 0.0505, 0.1095, 0.1374, 0.1513, 0.1534, 0.1470, 0.1154, 0.0908,\n",
      "         0.0219],\n",
      "        [0.0228, 0.0504, 0.1095, 0.1374, 0.1513, 0.1534, 0.1470, 0.1154, 0.0908,\n",
      "         0.0219],\n",
      "        [0.0228, 0.0504, 0.1095, 0.1374, 0.1513, 0.1534, 0.1470, 0.1154, 0.0908,\n",
      "         0.0219],\n",
      "        [0.0228, 0.0504, 0.1095, 0.1374, 0.1513, 0.1534, 0.1470, 0.1154, 0.0908,\n",
      "         0.0219]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 14.00, Train Loss: 4.73, Val Loss: 8.73, Train BLEU: 0.28, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克 泰坦尼克号 坦尼 尼克 号 是 拿 了 不少\n",
      "Reference: the truth of the matter is that the titanic\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0243, 0.0458, 0.0717, 0.0905, 0.1400, 0.1574, 0.1612, 0.1551, 0.1213,\n",
      "         0.0328],\n",
      "        [0.0199, 0.0409, 0.0669, 0.0872, 0.1435, 0.1644, 0.1688, 0.1605, 0.1198,\n",
      "         0.0281],\n",
      "        [0.0199, 0.0410, 0.0670, 0.0870, 0.1432, 0.1642, 0.1687, 0.1606, 0.1201,\n",
      "         0.0284],\n",
      "        [0.0198, 0.0409, 0.0669, 0.0868, 0.1431, 0.1642, 0.1687, 0.1607, 0.1204,\n",
      "         0.0285],\n",
      "        [0.0198, 0.0409, 0.0668, 0.0867, 0.1430, 0.1641, 0.1687, 0.1608, 0.1205,\n",
      "         0.0286],\n",
      "        [0.0198, 0.0408, 0.0667, 0.0867, 0.1430, 0.1642, 0.1688, 0.1608, 0.1206,\n",
      "         0.0286],\n",
      "        [0.0197, 0.0408, 0.0667, 0.0867, 0.1430, 0.1642, 0.1688, 0.1608, 0.1206,\n",
      "         0.0287],\n",
      "        [0.0197, 0.0408, 0.0666, 0.0866, 0.1430, 0.1642, 0.1688, 0.1609, 0.1207,\n",
      "         0.0287],\n",
      "        [0.0197, 0.0407, 0.0666, 0.0866, 0.1431, 0.1642, 0.1688, 0.1609, 0.1207,\n",
      "         0.0287]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 有时 学校 <UNK> 突然 <UNK> 一周 因为 被 塔利 塔利班\n",
      "Reference: from time to time , the school would suddenly\n",
      "Model: <SOS> the the the the the the the the the\n",
      "Attention Weights: tensor([[0.0382, 0.0920, 0.1128, 0.1212, 0.1261, 0.1280, 0.1276, 0.1223, 0.0994,\n",
      "         0.0323],\n",
      "        [0.0321, 0.0892, 0.1140, 0.1240, 0.1299, 0.1319, 0.1310, 0.1239, 0.0965,\n",
      "         0.0274],\n",
      "        [0.0320, 0.0891, 0.1138, 0.1240, 0.1299, 0.1319, 0.1310, 0.1240, 0.0966,\n",
      "         0.0277],\n",
      "        [0.0318, 0.0889, 0.1137, 0.1239, 0.1299, 0.1320, 0.1311, 0.1241, 0.0969,\n",
      "         0.0278],\n",
      "        [0.0318, 0.0888, 0.1136, 0.1239, 0.1299, 0.1320, 0.1311, 0.1241, 0.0969,\n",
      "         0.0279],\n",
      "        [0.0318, 0.0888, 0.1136, 0.1238, 0.1299, 0.1319, 0.1311, 0.1241, 0.0970,\n",
      "         0.0279],\n",
      "        [0.0318, 0.0888, 0.1136, 0.1238, 0.1299, 0.1320, 0.1311, 0.1241, 0.0970,\n",
      "         0.0279],\n",
      "        [0.0318, 0.0888, 0.1136, 0.1238, 0.1299, 0.1320, 0.1311, 0.1241, 0.0970,\n",
      "         0.0279],\n",
      "        [0.0318, 0.0888, 0.1136, 0.1238, 0.1299, 0.1320, 0.1311, 0.1241, 0.0970,\n",
      "         0.0279]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 15.00, Train Loss: 4.59, Val Loss: 8.83, Train BLEU: 0.33, Val BLEU: 0.21\n",
      "Sampling from training predictions...\n",
      "Source: 当 你 站 在 海滩 上 或是 当 你 看到\n",
      "Reference: part of the problem , i think , is\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0401, 0.0930, 0.1131, 0.1214, 0.1252, 0.1280, 0.1277, 0.1235, 0.0996,\n",
      "         0.0285],\n",
      "        [0.0338, 0.0905, 0.1143, 0.1245, 0.1289, 0.1320, 0.1310, 0.1250, 0.0963,\n",
      "         0.0237],\n",
      "        [0.0338, 0.0904, 0.1142, 0.1244, 0.1288, 0.1319, 0.1310, 0.1250, 0.0965,\n",
      "         0.0240],\n",
      "        [0.0335, 0.0901, 0.1140, 0.1243, 0.1289, 0.1320, 0.1311, 0.1252, 0.0968,\n",
      "         0.0241],\n",
      "        [0.0334, 0.0900, 0.1139, 0.1243, 0.1289, 0.1320, 0.1311, 0.1253, 0.0969,\n",
      "         0.0242],\n",
      "        [0.0334, 0.0900, 0.1139, 0.1243, 0.1289, 0.1320, 0.1312, 0.1253, 0.0969,\n",
      "         0.0242],\n",
      "        [0.0334, 0.0900, 0.1139, 0.1243, 0.1289, 0.1321, 0.1312, 0.1253, 0.0969,\n",
      "         0.0242],\n",
      "        [0.0333, 0.0899, 0.1139, 0.1243, 0.1289, 0.1321, 0.1312, 0.1253, 0.0969,\n",
      "         0.0242],\n",
      "        [0.0333, 0.0899, 0.1139, 0.1243, 0.1289, 0.1321, 0.1312, 0.1253, 0.0969,\n",
      "         0.0242]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在 可以 去 个 真正 的 学校 念书 了\n",
      "Reference: &quot; you can go to a real school now\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0258, 0.0499, 0.0760, 0.0936, 0.1380, 0.1529, 0.1565, 0.1517, 0.1216,\n",
      "         0.0341],\n",
      "        [0.0211, 0.0448, 0.0713, 0.0907, 0.1419, 0.1599, 0.1639, 0.1570, 0.1202,\n",
      "         0.0292],\n",
      "        [0.0212, 0.0451, 0.0715, 0.0906, 0.1415, 0.1595, 0.1637, 0.1570, 0.1205,\n",
      "         0.0295],\n",
      "        [0.0210, 0.0449, 0.0713, 0.0903, 0.1414, 0.1595, 0.1638, 0.1572, 0.1209,\n",
      "         0.0296],\n",
      "        [0.0209, 0.0448, 0.0712, 0.0902, 0.1413, 0.1596, 0.1639, 0.1573, 0.1210,\n",
      "         0.0297],\n",
      "        [0.0209, 0.0447, 0.0711, 0.0901, 0.1413, 0.1596, 0.1640, 0.1574, 0.1211,\n",
      "         0.0297],\n",
      "        [0.0209, 0.0447, 0.0711, 0.0901, 0.1413, 0.1596, 0.1640, 0.1574, 0.1211,\n",
      "         0.0298],\n",
      "        [0.0209, 0.0446, 0.0710, 0.0900, 0.1414, 0.1597, 0.1640, 0.1575, 0.1212,\n",
      "         0.0298],\n",
      "        [0.0208, 0.0446, 0.0710, 0.0900, 0.1414, 0.1597, 0.1640, 0.1575, 0.1212,\n",
      "         0.0298]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16.00, Train Loss: 4.48, Val Loss: 8.96, Train BLEU: 0.36, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 我们 将 用 一些 影片 来讲 讲述 一些 深海 海里\n",
      "Reference: and we &apos;re going to tell you some stories\n",
      "Model: <SOS> it the the the the the , , ,\n",
      "Attention Weights: tensor([[0.0360, 0.0929, 0.1135, 0.1218, 0.1264, 0.1285, 0.1283, 0.1235, 0.0996,\n",
      "         0.0294],\n",
      "        [0.0299, 0.0902, 0.1150, 0.1250, 0.1304, 0.1326, 0.1318, 0.1250, 0.0959,\n",
      "         0.0244],\n",
      "        [0.0300, 0.0901, 0.1148, 0.1249, 0.1302, 0.1325, 0.1317, 0.1250, 0.0961,\n",
      "         0.0247],\n",
      "        [0.0297, 0.0898, 0.1147, 0.1249, 0.1303, 0.1326, 0.1318, 0.1252, 0.0963,\n",
      "         0.0248],\n",
      "        [0.0295, 0.0896, 0.1146, 0.1249, 0.1303, 0.1327, 0.1319, 0.1253, 0.0964,\n",
      "         0.0248],\n",
      "        [0.0295, 0.0896, 0.1146, 0.1249, 0.1303, 0.1327, 0.1319, 0.1253, 0.0965,\n",
      "         0.0248],\n",
      "        [0.0295, 0.0896, 0.1146, 0.1249, 0.1303, 0.1327, 0.1319, 0.1253, 0.0965,\n",
      "         0.0248],\n",
      "        [0.0294, 0.0895, 0.1146, 0.1249, 0.1303, 0.1327, 0.1319, 0.1253, 0.0965,\n",
      "         0.0248],\n",
      "        [0.0294, 0.0895, 0.1146, 0.1249, 0.1303, 0.1327, 0.1319, 0.1253, 0.0965,\n",
      "         0.0248]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 她 两年 年前 退休 了 结果 却 把 我家 变成\n",
      "Reference: she retired two years ago , only to turn\n",
      "Model: <SOS> it the the the the the , , ,\n",
      "Attention Weights: tensor([[9.6050e-02, 2.1650e-01, 2.5508e-01, 2.5084e-01, 1.6563e-01, 1.5907e-02,\n",
      "         1.6770e-10, 1.6770e-10, 1.6770e-10, 1.6770e-10],\n",
      "        [8.4789e-02, 2.1839e-01, 2.6485e-01, 2.5851e-01, 1.6013e-01, 1.3337e-02,\n",
      "         2.2057e-09, 2.2057e-09, 2.2057e-09, 2.2057e-09],\n",
      "        [8.4826e-02, 2.1791e-01, 2.6437e-01, 2.5844e-01, 1.6087e-01, 1.3571e-02,\n",
      "         2.6772e-09, 2.6772e-09, 2.6772e-09, 2.6772e-09],\n",
      "        [8.4107e-02, 2.1754e-01, 2.6454e-01, 2.5899e-01, 1.6136e-01, 1.3468e-02,\n",
      "         2.6524e-09, 2.6524e-09, 2.6524e-09, 2.6524e-09],\n",
      "        [8.3811e-02, 2.1738e-01, 2.6463e-01, 2.5922e-01, 1.6152e-01, 1.3437e-02,\n",
      "         2.6396e-09, 2.6396e-09, 2.6396e-09, 2.6396e-09],\n",
      "        [8.3679e-02, 2.1734e-01, 2.6469e-01, 2.5932e-01, 1.6156e-01, 1.3410e-02,\n",
      "         2.6195e-09, 2.6195e-09, 2.6195e-09, 2.6195e-09],\n",
      "        [8.3619e-02, 2.1736e-01, 2.6473e-01, 2.5936e-01, 1.6155e-01, 1.3390e-02,\n",
      "         2.5977e-09, 2.5977e-09, 2.5977e-09, 2.5977e-09],\n",
      "        [8.3584e-02, 2.1738e-01, 2.6477e-01, 2.5937e-01, 1.6152e-01, 1.3373e-02,\n",
      "         2.5772e-09, 2.5772e-09, 2.5772e-09, 2.5772e-09],\n",
      "        [8.3574e-02, 2.1740e-01, 2.6478e-01, 2.5937e-01, 1.6151e-01, 1.3368e-02,\n",
      "         2.5565e-09, 2.5565e-09, 2.5565e-09, 2.5565e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 17.00, Train Loss: 4.40, Val Loss: 9.10, Train BLEU: 0.36, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 当 你 站 在 海滩 上 或是 当 你 看到\n",
      "Reference: part of the problem , i think , is\n",
      "Model: <SOS> it the the the the the , , ,\n",
      "Attention Weights: tensor([[0.0434, 0.0934, 0.1114, 0.1192, 0.1230, 0.1256, 0.1259, 0.1228, 0.1031,\n",
      "         0.0323],\n",
      "        [0.0364, 0.0911, 0.1128, 0.1224, 0.1268, 0.1297, 0.1293, 0.1246, 0.1002,\n",
      "         0.0268],\n",
      "        [0.0365, 0.0910, 0.1127, 0.1223, 0.1267, 0.1296, 0.1293, 0.1246, 0.1003,\n",
      "         0.0271],\n",
      "        [0.0361, 0.0907, 0.1125, 0.1223, 0.1267, 0.1297, 0.1294, 0.1248, 0.1006,\n",
      "         0.0272],\n",
      "        [0.0359, 0.0905, 0.1125, 0.1223, 0.1268, 0.1298, 0.1295, 0.1249, 0.1007,\n",
      "         0.0272],\n",
      "        [0.0358, 0.0904, 0.1124, 0.1223, 0.1268, 0.1298, 0.1296, 0.1249, 0.1007,\n",
      "         0.0272],\n",
      "        [0.0358, 0.0904, 0.1124, 0.1223, 0.1268, 0.1299, 0.1296, 0.1249, 0.1007,\n",
      "         0.0272],\n",
      "        [0.0357, 0.0904, 0.1124, 0.1223, 0.1268, 0.1299, 0.1296, 0.1250, 0.1008,\n",
      "         0.0272],\n",
      "        [0.0357, 0.0904, 0.1124, 0.1223, 0.1268, 0.1299, 0.1296, 0.1250, 0.1008,\n",
      "         0.0272]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 总是 担心 会 被 塔利 塔利班 发现 <EOS> <PAD>\n",
      "Reference: we always wondered what they knew about us .\n",
      "Model: <SOS> it the the the the the , , ,\n",
      "Attention Weights: tensor([[0.0334, 0.0666, 0.1087, 0.1248, 0.1327, 0.1360, 0.1363, 0.1249, 0.1046,\n",
      "         0.0321],\n",
      "        [0.0273, 0.0613, 0.1095, 0.1288, 0.1383, 0.1416, 0.1405, 0.1243, 0.1015,\n",
      "         0.0269],\n",
      "        [0.0274, 0.0613, 0.1093, 0.1287, 0.1382, 0.1416, 0.1405, 0.1242, 0.1016,\n",
      "         0.0272],\n",
      "        [0.0271, 0.0609, 0.1091, 0.1287, 0.1383, 0.1418, 0.1407, 0.1244, 0.1018,\n",
      "         0.0273],\n",
      "        [0.0269, 0.0607, 0.1090, 0.1287, 0.1384, 0.1419, 0.1408, 0.1244, 0.1019,\n",
      "         0.0273],\n",
      "        [0.0268, 0.0606, 0.1089, 0.1287, 0.1385, 0.1419, 0.1409, 0.1245, 0.1020,\n",
      "         0.0274],\n",
      "        [0.0268, 0.0605, 0.1089, 0.1287, 0.1385, 0.1420, 0.1409, 0.1245, 0.1020,\n",
      "         0.0274],\n",
      "        [0.0267, 0.0604, 0.1089, 0.1287, 0.1385, 0.1420, 0.1410, 0.1245, 0.1020,\n",
      "         0.0274],\n",
      "        [0.0267, 0.0604, 0.1089, 0.1287, 0.1385, 0.1420, 0.1410, 0.1245, 0.1020,\n",
      "         0.0274]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 18.00, Train Loss: 4.33, Val Loss: 9.26, Train BLEU: 0.36, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 我们 得用 非常 特殊 的 仪器 才能 能到 到达 那个\n",
      "Reference: we have to have a very special technology to\n",
      "Model: <SOS> it the the the the the , , ,\n",
      "Attention Weights: tensor([[0.0351, 0.0688, 0.1087, 0.1235, 0.1308, 0.1340, 0.1345, 0.1249, 0.1059,\n",
      "         0.0338],\n",
      "        [0.0287, 0.0634, 0.1095, 0.1275, 0.1363, 0.1395, 0.1388, 0.1248, 0.1031,\n",
      "         0.0284],\n",
      "        [0.0287, 0.0634, 0.1094, 0.1274, 0.1363, 0.1396, 0.1388, 0.1246, 0.1031,\n",
      "         0.0286],\n",
      "        [0.0283, 0.0629, 0.1092, 0.1274, 0.1365, 0.1398, 0.1391, 0.1248, 0.1033,\n",
      "         0.0287],\n",
      "        [0.0281, 0.0626, 0.1090, 0.1274, 0.1366, 0.1400, 0.1392, 0.1249, 0.1035,\n",
      "         0.0287],\n",
      "        [0.0280, 0.0625, 0.1089, 0.1274, 0.1366, 0.1400, 0.1393, 0.1249, 0.1035,\n",
      "         0.0287],\n",
      "        [0.0280, 0.0624, 0.1089, 0.1274, 0.1366, 0.1401, 0.1393, 0.1249, 0.1035,\n",
      "         0.0287],\n",
      "        [0.0280, 0.0624, 0.1089, 0.1274, 0.1366, 0.1401, 0.1394, 0.1249, 0.1035,\n",
      "         0.0287],\n",
      "        [0.0279, 0.0623, 0.1089, 0.1275, 0.1367, 0.1401, 0.1394, 0.1249, 0.1035,\n",
      "         0.0287]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 都 知道 自己 正 冒 着 生命 的 危险\n",
      "Reference: we all knew we were risking our lives --\n",
      "Model: <SOS> it the the the the the , , ,\n",
      "Attention Weights: tensor([[0.0377, 0.0901, 0.1095, 0.1189, 0.1235, 0.1257, 0.1259, 0.1228, 0.1059,\n",
      "         0.0401],\n",
      "        [0.0310, 0.0869, 0.1103, 0.1221, 0.1275, 0.1302, 0.1297, 0.1248, 0.1034,\n",
      "         0.0341],\n",
      "        [0.0310, 0.0868, 0.1101, 0.1221, 0.1275, 0.1302, 0.1297, 0.1249, 0.1035,\n",
      "         0.0343],\n",
      "        [0.0306, 0.0864, 0.1100, 0.1221, 0.1276, 0.1304, 0.1299, 0.1251, 0.1037,\n",
      "         0.0344],\n",
      "        [0.0303, 0.0862, 0.1099, 0.1221, 0.1276, 0.1304, 0.1300, 0.1252, 0.1039,\n",
      "         0.0344],\n",
      "        [0.0302, 0.0861, 0.1098, 0.1221, 0.1276, 0.1305, 0.1300, 0.1252, 0.1039,\n",
      "         0.0345],\n",
      "        [0.0302, 0.0861, 0.1098, 0.1221, 0.1276, 0.1305, 0.1300, 0.1252, 0.1039,\n",
      "         0.0345],\n",
      "        [0.0302, 0.0861, 0.1098, 0.1221, 0.1276, 0.1305, 0.1301, 0.1253, 0.1040,\n",
      "         0.0345],\n",
      "        [0.0301, 0.0861, 0.1098, 0.1221, 0.1277, 0.1305, 0.1301, 0.1253, 0.1040,\n",
      "         0.0345]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 19.00, Train Loss: 4.28, Val Loss: 9.42, Train BLEU: 0.36, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一只 水母 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: here &apos;s a jelly . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it it the the the the , , ,\n",
      "Attention Weights: tensor([[1.4156e-01, 2.8520e-01, 3.1316e-01, 2.3372e-01, 2.6351e-02, 1.0318e-10,\n",
      "         1.0318e-10, 1.0318e-10, 1.0318e-10, 1.0318e-10],\n",
      "        [1.2697e-01, 2.9261e-01, 3.2677e-01, 2.3143e-01, 2.2220e-02, 1.9387e-09,\n",
      "         1.9387e-09, 1.9387e-09, 1.9387e-09, 1.9387e-09],\n",
      "        [1.2681e-01, 2.9223e-01, 3.2663e-01, 2.3184e-01, 2.2495e-02, 2.8001e-09,\n",
      "         2.8001e-09, 2.8001e-09, 2.8001e-09, 2.8001e-09],\n",
      "        [1.2556e-01, 2.9218e-01, 3.2747e-01, 2.3259e-01, 2.2200e-02, 2.9506e-09,\n",
      "         2.9506e-09, 2.9506e-09, 2.9506e-09, 2.9506e-09],\n",
      "        [1.2481e-01, 2.9215e-01, 3.2800e-01, 2.3299e-01, 2.2048e-02, 2.9513e-09,\n",
      "         2.9513e-09, 2.9513e-09, 2.9513e-09, 2.9513e-09],\n",
      "        [1.2447e-01, 2.9216e-01, 3.2823e-01, 2.3317e-01, 2.1970e-02, 2.8852e-09,\n",
      "         2.8852e-09, 2.8852e-09, 2.8852e-09, 2.8852e-09],\n",
      "        [1.2439e-01, 2.9216e-01, 3.2828e-01, 2.3322e-01, 2.1949e-02, 2.8187e-09,\n",
      "         2.8187e-09, 2.8187e-09, 2.8187e-09, 2.8187e-09],\n",
      "        [1.2432e-01, 2.9219e-01, 3.2833e-01, 2.3323e-01, 2.1923e-02, 2.7738e-09,\n",
      "         2.7738e-09, 2.7738e-09, 2.7738e-09, 2.7738e-09],\n",
      "        [1.2433e-01, 2.9221e-01, 3.2831e-01, 2.3322e-01, 2.1921e-02, 2.7391e-09,\n",
      "         2.7391e-09, 2.7391e-09, 2.7391e-09, 2.7391e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 祖父 在 他 的 年代 是 位非 非凡\n",
      "Reference: my grandfather was an extraordinary man for his time\n",
      "Model: <SOS> it it the the the the , , ,\n",
      "Attention Weights: tensor([[0.0469, 0.0973, 0.1146, 0.1226, 0.1270, 0.1291, 0.1295, 0.1250, 0.0952,\n",
      "         0.0128],\n",
      "        [0.0399, 0.0951, 0.1161, 0.1257, 0.1309, 0.1331, 0.1331, 0.1264, 0.0901,\n",
      "         0.0098],\n",
      "        [0.0398, 0.0950, 0.1160, 0.1256, 0.1309, 0.1331, 0.1331, 0.1264, 0.0902,\n",
      "         0.0099],\n",
      "        [0.0393, 0.0946, 0.1159, 0.1257, 0.1311, 0.1332, 0.1333, 0.1267, 0.0904,\n",
      "         0.0098],\n",
      "        [0.0390, 0.0944, 0.1158, 0.1257, 0.1311, 0.1333, 0.1335, 0.1268, 0.0905,\n",
      "         0.0098],\n",
      "        [0.0389, 0.0944, 0.1158, 0.1257, 0.1312, 0.1334, 0.1335, 0.1269, 0.0906,\n",
      "         0.0097],\n",
      "        [0.0389, 0.0943, 0.1158, 0.1257, 0.1312, 0.1334, 0.1335, 0.1269, 0.0906,\n",
      "         0.0097],\n",
      "        [0.0388, 0.0943, 0.1158, 0.1257, 0.1312, 0.1334, 0.1335, 0.1269, 0.0906,\n",
      "         0.0097],\n",
      "        [0.0388, 0.0943, 0.1158, 0.1257, 0.1312, 0.1334, 0.1335, 0.1269, 0.0906,\n",
      "         0.0097]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20.00, Train Loss: 4.24, Val Loss: 9.57, Train BLEU: 0.36, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一只 水母 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: here &apos;s a jelly . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it it the the the the the , ,\n",
      "Attention Weights: tensor([[1.4442e-01, 2.8202e-01, 3.0928e-01, 2.3631e-01, 2.7964e-02, 8.2845e-11,\n",
      "         8.2845e-11, 8.2845e-11, 8.2845e-11, 8.2845e-11],\n",
      "        [1.2958e-01, 2.8921e-01, 3.2282e-01, 2.3477e-01, 2.3620e-02, 1.6870e-09,\n",
      "         1.6870e-09, 1.6870e-09, 1.6870e-09, 1.6870e-09],\n",
      "        [1.2939e-01, 2.8895e-01, 3.2274e-01, 2.3503e-01, 2.3894e-02, 2.5539e-09,\n",
      "         2.5539e-09, 2.5539e-09, 2.5539e-09, 2.5539e-09],\n",
      "        [1.2794e-01, 2.8901e-01, 3.2375e-01, 2.3580e-01, 2.3497e-02, 2.7803e-09,\n",
      "         2.7803e-09, 2.7803e-09, 2.7803e-09, 2.7803e-09],\n",
      "        [1.2709e-01, 2.8906e-01, 3.2437e-01, 2.3621e-01, 2.3274e-02, 2.7796e-09,\n",
      "         2.7796e-09, 2.7796e-09, 2.7796e-09, 2.7796e-09],\n",
      "        [1.2674e-01, 2.8908e-01, 3.2461e-01, 2.3639e-01, 2.3176e-02, 2.6991e-09,\n",
      "         2.6991e-09, 2.6991e-09, 2.6991e-09, 2.6991e-09],\n",
      "        [1.2667e-01, 2.8909e-01, 3.2465e-01, 2.3644e-01, 2.3154e-02, 2.6259e-09,\n",
      "         2.6259e-09, 2.6259e-09, 2.6259e-09, 2.6259e-09],\n",
      "        [1.2662e-01, 2.8910e-01, 3.2469e-01, 2.3646e-01, 2.3137e-02, 2.5754e-09,\n",
      "         2.5754e-09, 2.5754e-09, 2.5754e-09, 2.5754e-09],\n",
      "        [1.2663e-01, 2.8911e-01, 3.2467e-01, 2.3645e-01, 2.3142e-02, 2.5410e-09,\n",
      "         2.5410e-09, 2.5410e-09, 2.5410e-09, 2.5410e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 出身 阿富汗 边远 <UNK> 地区 有着 与 他人 不同\n",
      "Reference: a total maverick from a remote province of afghanistan\n",
      "Model: <SOS> it it the the the the the , ,\n",
      "Attention Weights: tensor([[5.1649e-02, 1.1611e-01, 1.3695e-01, 1.4495e-01, 1.4123e-01, 1.4936e-01,\n",
      "         1.4364e-01, 1.0362e-01, 1.2501e-02, 3.4714e-11],\n",
      "        [4.3495e-02, 1.1385e-01, 1.3941e-01, 1.4881e-01, 1.4370e-01, 1.5418e-01,\n",
      "         1.4678e-01, 9.9590e-02, 1.0187e-02, 6.3140e-10],\n",
      "        [4.3410e-02, 1.1370e-01, 1.3934e-01, 1.4883e-01, 1.4359e-01, 1.5420e-01,\n",
      "         1.4690e-01, 9.9744e-02, 1.0291e-02, 9.4833e-10],\n",
      "        [4.2692e-02, 1.1327e-01, 1.3933e-01, 1.4903e-01, 1.4374e-01, 1.5459e-01,\n",
      "         1.4736e-01, 9.9895e-02, 1.0097e-02, 1.0283e-09],\n",
      "        [4.2250e-02, 1.1302e-01, 1.3933e-01, 1.4916e-01, 1.4385e-01, 1.5483e-01,\n",
      "         1.4762e-01, 9.9955e-02, 9.9816e-03, 1.0227e-09],\n",
      "        [4.2098e-02, 1.1293e-01, 1.3932e-01, 1.4920e-01, 1.4389e-01, 1.5490e-01,\n",
      "         1.4771e-01, 9.9997e-02, 9.9455e-03, 9.9294e-10],\n",
      "        [4.2046e-02, 1.1290e-01, 1.3932e-01, 1.4922e-01, 1.4390e-01, 1.5493e-01,\n",
      "         1.4773e-01, 1.0001e-01, 9.9335e-03, 9.6695e-10],\n",
      "        [4.2026e-02, 1.1290e-01, 1.3933e-01, 1.4924e-01, 1.4391e-01, 1.5494e-01,\n",
      "         1.4773e-01, 1.0001e-01, 9.9288e-03, 9.4880e-10],\n",
      "        [4.2020e-02, 1.1290e-01, 1.3933e-01, 1.4924e-01, 1.4391e-01, 1.5494e-01,\n",
      "         1.4773e-01, 1.0001e-01, 9.9280e-03, 9.3651e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 21.00, Train Loss: 4.21, Val Loss: 9.72, Train BLEU: 7.44, Val BLEU: 1.02\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的 平均 深度 是 两英里 英里 <EOS> <PAD> <PAD>\n",
      "Reference: the average depth is about two miles . <EOS>\n",
      "Model: <SOS> it &apos;s the the the the the the ,\n",
      "Attention Weights: tensor([[6.3164e-02, 1.3836e-01, 1.6244e-01, 1.7300e-01, 1.7478e-01, 1.5398e-01,\n",
      "         1.2050e-01, 1.3782e-02, 3.5154e-11, 3.5154e-11],\n",
      "        [5.3733e-02, 1.3698e-01, 1.6669e-01, 1.7963e-01, 1.8133e-01, 1.5407e-01,\n",
      "         1.1620e-01, 1.1372e-02, 7.0019e-10, 7.0019e-10],\n",
      "        [5.3620e-02, 1.3680e-01, 1.6661e-01, 1.7967e-01, 1.8143e-01, 1.5416e-01,\n",
      "         1.1621e-01, 1.1503e-02, 1.0933e-09, 1.0933e-09],\n",
      "        [5.2641e-02, 1.3637e-01, 1.6670e-01, 1.8013e-01, 1.8211e-01, 1.5443e-01,\n",
      "         1.1639e-01, 1.1235e-02, 1.2196e-09, 1.2196e-09],\n",
      "        [5.2060e-02, 1.3612e-01, 1.6679e-01, 1.8042e-01, 1.8250e-01, 1.5457e-01,\n",
      "         1.1647e-01, 1.1068e-02, 1.2069e-09, 1.2069e-09],\n",
      "        [5.1862e-02, 1.3603e-01, 1.6682e-01, 1.8053e-01, 1.8262e-01, 1.5464e-01,\n",
      "         1.1650e-01, 1.1011e-02, 1.1641e-09, 1.1641e-09],\n",
      "        [5.1794e-02, 1.3600e-01, 1.6683e-01, 1.8057e-01, 1.8267e-01, 1.5466e-01,\n",
      "         1.1649e-01, 1.0990e-02, 1.1290e-09, 1.1290e-09],\n",
      "        [5.1783e-02, 1.3600e-01, 1.6684e-01, 1.8059e-01, 1.8267e-01, 1.5465e-01,\n",
      "         1.1648e-01, 1.0987e-02, 1.1049e-09, 1.1049e-09],\n",
      "        [5.1782e-02, 1.3600e-01, 1.6685e-01, 1.8059e-01, 1.8267e-01, 1.5465e-01,\n",
      "         1.1647e-01, 1.0987e-02, 1.0887e-09, 1.0887e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他们 知道 我们 的 住处 吗 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: do they know where we live ? <EOS> <PAD>\n",
      "Model: <SOS> it &apos;s the the the the the the ,\n",
      "Attention Weights: tensor([[1.3275e-06, 9.9062e-06, 2.0300e-05, 3.5831e-04, 3.0107e-02, 1.8857e-01,\n",
      "         2.3347e-01, 2.4323e-01, 2.2039e-01, 8.3850e-02],\n",
      "        [3.1984e-06, 1.4965e-05, 2.6564e-05, 2.9758e-04, 2.1229e-02, 1.8373e-01,\n",
      "         2.4400e-01, 2.5614e-01, 2.2460e-01, 6.9964e-02],\n",
      "        [4.0442e-06, 1.7725e-05, 3.0958e-05, 3.2352e-04, 2.1146e-02, 1.8312e-01,\n",
      "         2.4437e-01, 2.5661e-01, 2.2466e-01, 6.9715e-02],\n",
      "        [3.9071e-06, 1.6906e-05, 2.9441e-05, 3.0728e-04, 2.0621e-02, 1.8268e-01,\n",
      "         2.4476e-01, 2.5722e-01, 2.2510e-01, 6.9275e-02],\n",
      "        [3.8084e-06, 1.6445e-05, 2.8601e-05, 2.9942e-04, 2.0461e-02, 1.8253e-01,\n",
      "         2.4480e-01, 2.5734e-01, 2.2525e-01, 6.9263e-02],\n",
      "        [3.7472e-06, 1.6189e-05, 2.8147e-05, 2.9567e-04, 2.0422e-02, 1.8252e-01,\n",
      "         2.4480e-01, 2.5736e-01, 2.2527e-01, 6.9287e-02],\n",
      "        [3.7115e-06, 1.6045e-05, 2.7895e-05, 2.9371e-04, 2.0410e-02, 1.8254e-01,\n",
      "         2.4480e-01, 2.5735e-01, 2.2526e-01, 6.9296e-02],\n",
      "        [3.6988e-06, 1.5997e-05, 2.7814e-05, 2.9315e-04, 2.0417e-02, 1.8256e-01,\n",
      "         2.4480e-01, 2.5735e-01, 2.2523e-01, 6.9301e-02],\n",
      "        [3.6953e-06, 1.5981e-05, 2.7783e-05, 2.9288e-04, 2.0419e-02, 1.8256e-01,\n",
      "         2.4480e-01, 2.5734e-01, 2.2523e-01, 6.9312e-02]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 22.00, Train Loss: 4.19, Val Loss: 9.86, Train BLEU: 7.29, Val BLEU: 0.96\n",
      "Sampling from training predictions...\n",
      "Source: <UNK> 塞尔 <UNK> <UNK> 斯特 说 过 真正 的 探索\n",
      "Reference: marcel proust said , &quot; the true voyage of\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[4.5329e-07, 2.7993e-06, 5.3609e-06, 1.1326e-04, 2.1249e-02, 1.8626e-01,\n",
      "         2.3481e-01, 2.4518e-01, 2.2387e-01, 8.8494e-02],\n",
      "        [1.3996e-06, 5.4443e-06, 8.9574e-06, 1.0512e-04, 1.3982e-02, 1.7906e-01,\n",
      "         2.4520e-01, 2.5884e-01, 2.2915e-01, 7.3645e-02],\n",
      "        [1.9356e-06, 7.0121e-06, 1.1319e-05, 1.2080e-04, 1.4002e-02, 1.7827e-01,\n",
      "         2.4564e-01, 2.5938e-01, 2.2922e-01, 7.3341e-02],\n",
      "        [1.8897e-06, 6.7452e-06, 1.0847e-05, 1.1460e-04, 1.3551e-02, 1.7762e-01,\n",
      "         2.4606e-01, 2.6007e-01, 2.2971e-01, 7.2856e-02],\n",
      "        [1.8362e-06, 6.5402e-06, 1.0503e-05, 1.1113e-04, 1.3423e-02, 1.7751e-01,\n",
      "         2.4610e-01, 2.6017e-01, 2.2983e-01, 7.2830e-02],\n",
      "        [1.8025e-06, 6.4205e-06, 1.0305e-05, 1.0935e-04, 1.3388e-02, 1.7754e-01,\n",
      "         2.4611e-01, 2.6018e-01, 2.2983e-01, 7.2825e-02],\n",
      "        [1.7844e-06, 6.3571e-06, 1.0200e-05, 1.0845e-04, 1.3375e-02, 1.7757e-01,\n",
      "         2.4612e-01, 2.6018e-01, 2.2982e-01, 7.2807e-02],\n",
      "        [1.7791e-06, 6.3383e-06, 1.0169e-05, 1.0819e-04, 1.3377e-02, 1.7760e-01,\n",
      "         2.4613e-01, 2.6018e-01, 2.2979e-01, 7.2790e-02],\n",
      "        [1.7790e-06, 6.3358e-06, 1.0163e-05, 1.0811e-04, 1.3376e-02, 1.7761e-01,\n",
      "         2.4613e-01, 2.6018e-01, 2.2979e-01, 7.2790e-02]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 总是 担心 会 被 塔利 塔利班 发现 <EOS> <PAD>\n",
      "Reference: we always wondered what they knew about us .\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[0.0412, 0.0740, 0.1090, 0.1209, 0.1269, 0.1293, 0.1293, 0.1222, 0.1079,\n",
      "         0.0393],\n",
      "        [0.0338, 0.0686, 0.1097, 0.1244, 0.1318, 0.1345, 0.1336, 0.1233, 0.1065,\n",
      "         0.0338],\n",
      "        [0.0338, 0.0686, 0.1096, 0.1244, 0.1319, 0.1346, 0.1337, 0.1232, 0.1063,\n",
      "         0.0338],\n",
      "        [0.0330, 0.0679, 0.1094, 0.1246, 0.1323, 0.1351, 0.1342, 0.1234, 0.1065,\n",
      "         0.0336],\n",
      "        [0.0326, 0.0674, 0.1093, 0.1247, 0.1325, 0.1354, 0.1344, 0.1235, 0.1066,\n",
      "         0.0335],\n",
      "        [0.0325, 0.0673, 0.1093, 0.1247, 0.1326, 0.1355, 0.1345, 0.1235, 0.1067,\n",
      "         0.0335],\n",
      "        [0.0324, 0.0672, 0.1093, 0.1247, 0.1326, 0.1355, 0.1346, 0.1235, 0.1067,\n",
      "         0.0335],\n",
      "        [0.0324, 0.0672, 0.1093, 0.1248, 0.1326, 0.1355, 0.1346, 0.1235, 0.1066,\n",
      "         0.0335],\n",
      "        [0.0324, 0.0672, 0.1093, 0.1248, 0.1326, 0.1355, 0.1346, 0.1234, 0.1066,\n",
      "         0.0335]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23.00, Train Loss: 4.16, Val Loss: 9.99, Train BLEU: 7.29, Val BLEU: 0.96\n",
      "Sampling from training predictions...\n",
      "Source: 原来 它 是 海洋 洋中 最长 的 生物 <EOS> <PAD>\n",
      "Reference: this turns out to be the longest creature in\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[5.6943e-02, 1.1686e-01, 1.3540e-01, 1.4259e-01, 1.3888e-01, 1.4666e-01,\n",
      "         1.4131e-01, 1.0691e-01, 1.4443e-02, 2.1127e-11],\n",
      "        [4.8269e-02, 1.1464e-01, 1.3754e-01, 1.4613e-01, 1.4110e-01, 1.5136e-01,\n",
      "         1.4485e-01, 1.0408e-01, 1.2043e-02, 4.7428e-10],\n",
      "        [4.8242e-02, 1.1461e-01, 1.3759e-01, 1.4619e-01, 1.4093e-01, 1.5135e-01,\n",
      "         1.4483e-01, 1.0403e-01, 1.2221e-02, 8.0587e-10],\n",
      "        [4.7219e-02, 1.1421e-01, 1.3770e-01, 1.4651e-01, 1.4112e-01, 1.5185e-01,\n",
      "         1.4535e-01, 1.0411e-01, 1.1914e-02, 9.4395e-10],\n",
      "        [4.6614e-02, 1.1394e-01, 1.3775e-01, 1.4671e-01, 1.4127e-01, 1.5219e-01,\n",
      "         1.4568e-01, 1.0416e-01, 1.1699e-02, 9.3244e-10],\n",
      "        [4.6419e-02, 1.1384e-01, 1.3776e-01, 1.4679e-01, 1.4133e-01, 1.5232e-01,\n",
      "         1.4579e-01, 1.0414e-01, 1.1608e-02, 8.8911e-10],\n",
      "        [4.6357e-02, 1.1382e-01, 1.3778e-01, 1.4685e-01, 1.4136e-01, 1.5238e-01,\n",
      "         1.4581e-01, 1.0409e-01, 1.1562e-02, 8.5490e-10],\n",
      "        [4.6342e-02, 1.1382e-01, 1.3780e-01, 1.4687e-01, 1.4137e-01, 1.5240e-01,\n",
      "         1.4581e-01, 1.0404e-01, 1.1539e-02, 8.3246e-10],\n",
      "        [4.6343e-02, 1.1383e-01, 1.3781e-01, 1.4689e-01, 1.4138e-01, 1.5240e-01,\n",
      "         1.4580e-01, 1.0402e-01, 1.1529e-02, 8.1836e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 不知 知道 那 意味 意味着 什么 但是 我 能\n",
      "Reference: i didn &apos;t know what it meant , but\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[0.0504, 0.1019, 0.1177, 0.1248, 0.1287, 0.1299, 0.1271, 0.1064, 0.0782,\n",
      "         0.0349],\n",
      "        [0.0426, 0.1004, 0.1203, 0.1292, 0.1340, 0.1354, 0.1310, 0.1048, 0.0726,\n",
      "         0.0297],\n",
      "        [0.0426, 0.1004, 0.1203, 0.1293, 0.1341, 0.1355, 0.1311, 0.1047, 0.0722,\n",
      "         0.0297],\n",
      "        [0.0417, 0.1000, 0.1205, 0.1297, 0.1346, 0.1361, 0.1316, 0.1046, 0.0719,\n",
      "         0.0294],\n",
      "        [0.0412, 0.0998, 0.1205, 0.1298, 0.1348, 0.1363, 0.1318, 0.1046, 0.0717,\n",
      "         0.0293],\n",
      "        [0.0411, 0.0997, 0.1205, 0.1299, 0.1349, 0.1364, 0.1319, 0.1046, 0.0717,\n",
      "         0.0293],\n",
      "        [0.0410, 0.0997, 0.1205, 0.1299, 0.1350, 0.1365, 0.1319, 0.1045, 0.0717,\n",
      "         0.0293],\n",
      "        [0.0410, 0.0997, 0.1205, 0.1299, 0.1350, 0.1365, 0.1319, 0.1045, 0.0717,\n",
      "         0.0293],\n",
      "        [0.0410, 0.0997, 0.1205, 0.1299, 0.1350, 0.1365, 0.1319, 0.1045, 0.0716,\n",
      "         0.0293]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 24.00, Train Loss: 4.14, Val Loss: 10.11, Train BLEU: 7.29, Val BLEU: 0.96\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 通过 潜水 潜水艇 拍下 的 影片 把 我们\n",
      "Reference: with vibrant video clips captured by submarines , david\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[0.0312, 0.0249, 0.1080, 0.1264, 0.1282, 0.1379, 0.1393, 0.1363, 0.1210,\n",
      "         0.0468],\n",
      "        [0.0254, 0.0208, 0.1061, 0.1278, 0.1289, 0.1426, 0.1447, 0.1407, 0.1217,\n",
      "         0.0414],\n",
      "        [0.0256, 0.0210, 0.1059, 0.1278, 0.1288, 0.1426, 0.1448, 0.1406, 0.1214,\n",
      "         0.0415],\n",
      "        [0.0248, 0.0204, 0.1056, 0.1280, 0.1288, 0.1431, 0.1453, 0.1411, 0.1217,\n",
      "         0.0412],\n",
      "        [0.0244, 0.0200, 0.1054, 0.1280, 0.1288, 0.1434, 0.1457, 0.1414, 0.1219,\n",
      "         0.0411],\n",
      "        [0.0242, 0.0198, 0.1053, 0.1281, 0.1289, 0.1435, 0.1458, 0.1415, 0.1219,\n",
      "         0.0410],\n",
      "        [0.0241, 0.0198, 0.1053, 0.1281, 0.1289, 0.1436, 0.1459, 0.1415, 0.1219,\n",
      "         0.0410],\n",
      "        [0.0241, 0.0197, 0.1053, 0.1281, 0.1289, 0.1436, 0.1459, 0.1415, 0.1219,\n",
      "         0.0410],\n",
      "        [0.0241, 0.0197, 0.1053, 0.1281, 0.1289, 0.1436, 0.1459, 0.1415, 0.1219,\n",
      "         0.0410]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 父亲 那 就是 他 他 是 他家 家族\n",
      "Reference: and my father -- that &apos;s him -- he\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[0.0539, 0.1091, 0.1261, 0.1268, 0.0834, 0.1358, 0.1282, 0.1298, 0.0966,\n",
      "         0.0103],\n",
      "        [0.0467, 0.1087, 0.1301, 0.1309, 0.0790, 0.1410, 0.1303, 0.1321, 0.0930,\n",
      "         0.0082],\n",
      "        [0.0468, 0.1088, 0.1302, 0.1309, 0.0788, 0.1410, 0.1302, 0.1319, 0.0929,\n",
      "         0.0084],\n",
      "        [0.0459, 0.1086, 0.1305, 0.1313, 0.0782, 0.1416, 0.1305, 0.1324, 0.0929,\n",
      "         0.0081],\n",
      "        [0.0454, 0.1084, 0.1306, 0.1313, 0.0778, 0.1420, 0.1307, 0.1327, 0.0931,\n",
      "         0.0080],\n",
      "        [0.0452, 0.1083, 0.1306, 0.1314, 0.0776, 0.1422, 0.1308, 0.1328, 0.0931,\n",
      "         0.0079],\n",
      "        [0.0452, 0.1083, 0.1307, 0.1314, 0.0775, 0.1423, 0.1308, 0.1328, 0.0930,\n",
      "         0.0079],\n",
      "        [0.0452, 0.1083, 0.1307, 0.1314, 0.0775, 0.1423, 0.1308, 0.1328, 0.0930,\n",
      "         0.0079],\n",
      "        [0.0452, 0.1083, 0.1307, 0.1314, 0.0775, 0.1424, 0.1309, 0.1328, 0.0930,\n",
      "         0.0079]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 25.00, Train Loss: 4.12, Val Loss: 10.22, Train BLEU: 7.29, Val BLEU: 0.96\n",
      "Sampling from training predictions...\n",
      "Source: 原因 在于 我们 一直 没 把 海洋 当回事 回事 回事儿\n",
      "Reference: and the problem , i think , is that\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[0.0532, 0.1063, 0.1243, 0.1332, 0.1372, 0.1387, 0.1355, 0.1163, 0.0475,\n",
      "         0.0077],\n",
      "        [0.0459, 0.1044, 0.1263, 0.1370, 0.1421, 0.1435, 0.1389, 0.1147, 0.0409,\n",
      "         0.0062],\n",
      "        [0.0459, 0.1043, 0.1262, 0.1370, 0.1421, 0.1435, 0.1388, 0.1146, 0.0411,\n",
      "         0.0064],\n",
      "        [0.0449, 0.1040, 0.1264, 0.1374, 0.1427, 0.1441, 0.1393, 0.1146, 0.0405,\n",
      "         0.0062],\n",
      "        [0.0444, 0.1037, 0.1264, 0.1376, 0.1430, 0.1445, 0.1396, 0.1147, 0.0401,\n",
      "         0.0061],\n",
      "        [0.0442, 0.1036, 0.1264, 0.1377, 0.1431, 0.1447, 0.1397, 0.1146, 0.0400,\n",
      "         0.0060],\n",
      "        [0.0441, 0.1036, 0.1264, 0.1378, 0.1432, 0.1447, 0.1397, 0.1146, 0.0399,\n",
      "         0.0060],\n",
      "        [0.0441, 0.1036, 0.1264, 0.1378, 0.1433, 0.1448, 0.1397, 0.1146, 0.0398,\n",
      "         0.0059],\n",
      "        [0.0441, 0.1036, 0.1265, 0.1378, 0.1433, 0.1448, 0.1397, 0.1145, 0.0398,\n",
      "         0.0059]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把 书 放在 食品 杂货 袋中 这样 别人 就\n",
      "Reference: we would cover our books in grocery bags so\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[0.0470, 0.0925, 0.1096, 0.1174, 0.1207, 0.1227, 0.1225, 0.1198, 0.1064,\n",
      "         0.0414],\n",
      "        [0.0392, 0.0892, 0.1101, 0.1199, 0.1241, 0.1266, 0.1263, 0.1224, 0.1059,\n",
      "         0.0363],\n",
      "        [0.0393, 0.0891, 0.1101, 0.1200, 0.1242, 0.1267, 0.1264, 0.1223, 0.1056,\n",
      "         0.0363],\n",
      "        [0.0384, 0.0887, 0.1101, 0.1203, 0.1245, 0.1271, 0.1267, 0.1225, 0.1056,\n",
      "         0.0360],\n",
      "        [0.0379, 0.0884, 0.1100, 0.1204, 0.1247, 0.1274, 0.1270, 0.1227, 0.1057,\n",
      "         0.0358],\n",
      "        [0.0377, 0.0883, 0.1100, 0.1204, 0.1248, 0.1275, 0.1271, 0.1228, 0.1057,\n",
      "         0.0357],\n",
      "        [0.0376, 0.0882, 0.1100, 0.1205, 0.1249, 0.1275, 0.1272, 0.1228, 0.1056,\n",
      "         0.0356],\n",
      "        [0.0376, 0.0882, 0.1100, 0.1205, 0.1249, 0.1276, 0.1272, 0.1229, 0.1056,\n",
      "         0.0356],\n",
      "        [0.0376, 0.0882, 0.1100, 0.1205, 0.1249, 0.1276, 0.1272, 0.1229, 0.1056,\n",
      "         0.0355]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 26.00, Train Loss: 4.10, Val Loss: 10.32, Train BLEU: 7.29, Val BLEU: 0.96\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本 基本上 都 没有 被 开发 发过 但是 像\n",
      "Reference: it &apos;s mostly unexplored , and yet there are\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[0.0494, 0.0941, 0.1084, 0.1161, 0.1195, 0.1213, 0.1207, 0.1178, 0.1052,\n",
      "         0.0474],\n",
      "        [0.0417, 0.0913, 0.1088, 0.1184, 0.1227, 0.1249, 0.1242, 0.1204, 0.1050,\n",
      "         0.0427],\n",
      "        [0.0418, 0.0913, 0.1088, 0.1186, 0.1228, 0.1250, 0.1242, 0.1202, 0.1046,\n",
      "         0.0426],\n",
      "        [0.0409, 0.0910, 0.1089, 0.1188, 0.1231, 0.1254, 0.1245, 0.1204, 0.1046,\n",
      "         0.0423],\n",
      "        [0.0404, 0.0908, 0.1088, 0.1189, 0.1233, 0.1256, 0.1247, 0.1206, 0.1047,\n",
      "         0.0422],\n",
      "        [0.0402, 0.0907, 0.1088, 0.1190, 0.1234, 0.1257, 0.1248, 0.1207, 0.1046,\n",
      "         0.0420],\n",
      "        [0.0401, 0.0906, 0.1088, 0.1191, 0.1235, 0.1258, 0.1249, 0.1207, 0.1046,\n",
      "         0.0419],\n",
      "        [0.0400, 0.0906, 0.1088, 0.1191, 0.1235, 0.1259, 0.1250, 0.1207, 0.1045,\n",
      "         0.0418],\n",
      "        [0.0400, 0.0906, 0.1088, 0.1191, 0.1236, 0.1259, 0.1250, 0.1207, 0.1045,\n",
      "         0.0418]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 父亲 在 用 他 的 灰色 小 收音\n",
      "Reference: my father was listening to bbc news on his\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[0.0297, 0.0149, 0.1080, 0.1278, 0.1283, 0.1401, 0.1416, 0.1382, 0.1228,\n",
      "         0.0487],\n",
      "        [0.0243, 0.0125, 0.1056, 0.1287, 0.1283, 0.1443, 0.1466, 0.1423, 0.1236,\n",
      "         0.0439],\n",
      "        [0.0246, 0.0128, 0.1054, 0.1286, 0.1280, 0.1443, 0.1466, 0.1422, 0.1234,\n",
      "         0.0441],\n",
      "        [0.0239, 0.0124, 0.1050, 0.1288, 0.1280, 0.1447, 0.1471, 0.1426, 0.1236,\n",
      "         0.0438],\n",
      "        [0.0234, 0.0121, 0.1048, 0.1289, 0.1280, 0.1450, 0.1475, 0.1429, 0.1237,\n",
      "         0.0436],\n",
      "        [0.0232, 0.0119, 0.1048, 0.1289, 0.1281, 0.1452, 0.1477, 0.1430, 0.1237,\n",
      "         0.0434],\n",
      "        [0.0231, 0.0118, 0.1048, 0.1290, 0.1281, 0.1454, 0.1478, 0.1431, 0.1237,\n",
      "         0.0433],\n",
      "        [0.0230, 0.0118, 0.1048, 0.1290, 0.1281, 0.1454, 0.1478, 0.1431, 0.1236,\n",
      "         0.0432],\n",
      "        [0.0230, 0.0118, 0.1048, 0.1290, 0.1281, 0.1454, 0.1479, 0.1432, 0.1236,\n",
      "         0.0432]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27.00, Train Loss: 4.08, Val Loss: 10.42, Train BLEU: 7.29, Val BLEU: 0.96\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本 基本上 都 没有 被 开发 发过 但是 像\n",
      "Reference: it &apos;s mostly unexplored , and yet there are\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[0.0508, 0.0947, 0.1085, 0.1161, 0.1194, 0.1211, 0.1204, 0.1172, 0.1044,\n",
      "         0.0475],\n",
      "        [0.0432, 0.0920, 0.1088, 0.1183, 0.1224, 0.1245, 0.1236, 0.1196, 0.1043,\n",
      "         0.0431],\n",
      "        [0.0433, 0.0921, 0.1089, 0.1185, 0.1225, 0.1246, 0.1236, 0.1195, 0.1040,\n",
      "         0.0432],\n",
      "        [0.0424, 0.0918, 0.1089, 0.1187, 0.1228, 0.1250, 0.1239, 0.1197, 0.1039,\n",
      "         0.0429],\n",
      "        [0.0419, 0.0916, 0.1089, 0.1188, 0.1229, 0.1252, 0.1241, 0.1198, 0.1040,\n",
      "         0.0428],\n",
      "        [0.0417, 0.0914, 0.1089, 0.1190, 0.1231, 0.1254, 0.1242, 0.1199, 0.1039,\n",
      "         0.0425],\n",
      "        [0.0415, 0.0914, 0.1089, 0.1190, 0.1232, 0.1255, 0.1243, 0.1199, 0.1038,\n",
      "         0.0423],\n",
      "        [0.0415, 0.0913, 0.1089, 0.1191, 0.1233, 0.1255, 0.1244, 0.1200, 0.1038,\n",
      "         0.0422],\n",
      "        [0.0415, 0.0913, 0.1089, 0.1191, 0.1233, 0.1256, 0.1244, 0.1200, 0.1038,\n",
      "         0.0422]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 父亲 在 用 他 的 灰色 小 收音\n",
      "Reference: my father was listening to bbc news on his\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[0.0286, 0.0109, 0.1079, 0.1286, 0.1280, 0.1413, 0.1428, 0.1391, 0.1234,\n",
      "         0.0494],\n",
      "        [0.0236, 0.0093, 0.1053, 0.1292, 0.1276, 0.1453, 0.1475, 0.1430, 0.1243,\n",
      "         0.0449],\n",
      "        [0.0240, 0.0097, 0.1051, 0.1291, 0.1273, 0.1452, 0.1475, 0.1429, 0.1241,\n",
      "         0.0452],\n",
      "        [0.0233, 0.0094, 0.1048, 0.1293, 0.1272, 0.1456, 0.1481, 0.1433, 0.1242,\n",
      "         0.0449],\n",
      "        [0.0228, 0.0091, 0.1046, 0.1294, 0.1272, 0.1459, 0.1484, 0.1436, 0.1244,\n",
      "         0.0447],\n",
      "        [0.0225, 0.0090, 0.1045, 0.1294, 0.1273, 0.1462, 0.1486, 0.1437, 0.1243,\n",
      "         0.0444],\n",
      "        [0.0224, 0.0089, 0.1045, 0.1295, 0.1273, 0.1463, 0.1488, 0.1438, 0.1243,\n",
      "         0.0443],\n",
      "        [0.0223, 0.0088, 0.1045, 0.1295, 0.1273, 0.1464, 0.1488, 0.1438, 0.1243,\n",
      "         0.0442],\n",
      "        [0.0223, 0.0088, 0.1045, 0.1296, 0.1273, 0.1464, 0.1489, 0.1438, 0.1242,\n",
      "         0.0442]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 28.00, Train Loss: 4.06, Val Loss: 10.52, Train BLEU: 7.29, Val BLEU: 0.96\n",
      "Sampling from training predictions...\n",
      "Source: 我们 将 用 一些 影片 来讲 讲述 一些 深海 海里\n",
      "Reference: and we &apos;re going to tell you some stories\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[0.0540, 0.0977, 0.1107, 0.1164, 0.1197, 0.1208, 0.1201, 0.1166, 0.1026,\n",
      "         0.0415],\n",
      "        [0.0466, 0.0957, 0.1115, 0.1184, 0.1224, 0.1239, 0.1231, 0.1188, 0.1022,\n",
      "         0.0374],\n",
      "        [0.0468, 0.0958, 0.1116, 0.1185, 0.1225, 0.1239, 0.1230, 0.1185, 0.1018,\n",
      "         0.0376],\n",
      "        [0.0460, 0.0957, 0.1118, 0.1187, 0.1227, 0.1241, 0.1232, 0.1187, 0.1017,\n",
      "         0.0373],\n",
      "        [0.0454, 0.0954, 0.1118, 0.1189, 0.1230, 0.1244, 0.1235, 0.1188, 0.1018,\n",
      "         0.0371],\n",
      "        [0.0451, 0.0953, 0.1118, 0.1190, 0.1231, 0.1246, 0.1236, 0.1189, 0.1017,\n",
      "         0.0368],\n",
      "        [0.0450, 0.0953, 0.1119, 0.1191, 0.1232, 0.1247, 0.1237, 0.1190, 0.1016,\n",
      "         0.0366],\n",
      "        [0.0449, 0.0952, 0.1119, 0.1191, 0.1233, 0.1247, 0.1238, 0.1190, 0.1016,\n",
      "         0.0365],\n",
      "        [0.0449, 0.0952, 0.1119, 0.1191, 0.1233, 0.1247, 0.1238, 0.1190, 0.1016,\n",
      "         0.0365]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 那 就是 她 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: there she is . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[6.3960e-02, 1.1648e-01, 1.3360e-01, 1.4049e-01, 1.4317e-01, 1.4175e-01,\n",
      "         1.3627e-01, 1.0935e-01, 1.4942e-02, 1.1216e-11],\n",
      "        [5.5431e-02, 1.1388e-01, 1.3461e-01, 1.4323e-01, 1.4661e-01, 1.4525e-01,\n",
      "         1.3911e-01, 1.0848e-01, 1.3411e-02, 3.2563e-10],\n",
      "        [5.5579e-02, 1.1387e-01, 1.3464e-01, 1.4328e-01, 1.4661e-01, 1.4514e-01,\n",
      "         1.3885e-01, 1.0816e-01, 1.3874e-02, 7.2031e-10],\n",
      "        [5.4478e-02, 1.1361e-01, 1.3488e-01, 1.4369e-01, 1.4707e-01, 1.4551e-01,\n",
      "         1.3911e-01, 1.0807e-01, 1.3577e-02, 8.7941e-10],\n",
      "        [5.3712e-02, 1.1332e-01, 1.3497e-01, 1.4397e-01, 1.4745e-01, 1.4587e-01,\n",
      "         1.3940e-01, 1.0807e-01, 1.3239e-02, 8.3773e-10],\n",
      "        [5.3363e-02, 1.1321e-01, 1.3508e-01, 1.4419e-01, 1.4772e-01, 1.4611e-01,\n",
      "         1.3952e-01, 1.0785e-01, 1.2958e-02, 7.8977e-10],\n",
      "        [5.3211e-02, 1.1316e-01, 1.3514e-01, 1.4432e-01, 1.4786e-01, 1.4624e-01,\n",
      "         1.3957e-01, 1.0770e-01, 1.2800e-02, 7.6776e-10],\n",
      "        [5.3155e-02, 1.1315e-01, 1.3517e-01, 1.4437e-01, 1.4793e-01, 1.4629e-01,\n",
      "         1.3959e-01, 1.0762e-01, 1.2731e-02, 7.5816e-10],\n",
      "        [5.3137e-02, 1.1314e-01, 1.3517e-01, 1.4439e-01, 1.4795e-01, 1.4631e-01,\n",
      "         1.3960e-01, 1.0760e-01, 1.2704e-02, 7.5377e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 29.00, Train Loss: 4.04, Val Loss: 10.60, Train BLEU: 7.29, Val BLEU: 0.96\n",
      "Sampling from training predictions...\n",
      "Source: 它 可以 伸展 <UNK> 150 英尺 长 <EOS> <PAD> <PAD>\n",
      "Reference: it gets up to about 150 feet long .\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[1.1088e-01, 1.7224e-01, 1.6003e-01, 2.7286e-02, 1.3801e-01, 2.0318e-01,\n",
      "         1.6892e-01, 1.9450e-02, 1.6746e-11, 1.6746e-11],\n",
      "        [1.0238e-01, 1.7372e-01, 1.6106e-01, 2.5709e-02, 1.3703e-01, 2.0975e-01,\n",
      "         1.7180e-01, 1.8554e-02, 5.4411e-10, 5.4411e-10],\n",
      "        [1.0304e-01, 1.7389e-01, 1.6110e-01, 2.6683e-02, 1.3662e-01, 2.0821e-01,\n",
      "         1.7094e-01, 1.9507e-02, 1.2597e-09, 1.2597e-09],\n",
      "        [1.0180e-01, 1.7427e-01, 1.6135e-01, 2.6196e-02, 1.3635e-01, 2.0928e-01,\n",
      "         1.7162e-01, 1.9138e-02, 1.5453e-09, 1.5453e-09],\n",
      "        [1.0084e-01, 1.7429e-01, 1.6130e-01, 2.5614e-02, 1.3645e-01, 2.1053e-01,\n",
      "         1.7232e-01, 1.8659e-02, 1.4560e-09, 1.4560e-09],\n",
      "        [1.0047e-01, 1.7439e-01, 1.6123e-01, 2.5191e-02, 1.3654e-01, 2.1139e-01,\n",
      "         1.7253e-01, 1.8264e-02, 1.3724e-09, 1.3724e-09],\n",
      "        [1.0032e-01, 1.7445e-01, 1.6120e-01, 2.4971e-02, 1.3658e-01, 2.1183e-01,\n",
      "         1.7259e-01, 1.8051e-02, 1.3437e-09, 1.3437e-09],\n",
      "        [1.0026e-01, 1.7445e-01, 1.6119e-01, 2.4892e-02, 1.3662e-01, 2.1201e-01,\n",
      "         1.7261e-01, 1.7971e-02, 1.3353e-09, 1.3353e-09],\n",
      "        [1.0025e-01, 1.7444e-01, 1.6118e-01, 2.4878e-02, 1.3664e-01, 2.1205e-01,\n",
      "         1.7261e-01, 1.7951e-02, 1.3327e-09, 1.3327e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 很 害怕 但是 我们 仍然 渴望 望去 学校 <EOS>\n",
      "Reference: we were scared , but still , school was\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[0.0592, 0.0964, 0.1090, 0.1154, 0.1180, 0.1193, 0.1182, 0.1148, 0.1026,\n",
      "         0.0471],\n",
      "        [0.0521, 0.0944, 0.1094, 0.1172, 0.1205, 0.1222, 0.1209, 0.1169, 0.1028,\n",
      "         0.0435],\n",
      "        [0.0524, 0.0946, 0.1095, 0.1173, 0.1204, 0.1222, 0.1208, 0.1166, 0.1024,\n",
      "         0.0438],\n",
      "        [0.0518, 0.0945, 0.1096, 0.1175, 0.1207, 0.1224, 0.1209, 0.1167, 0.1023,\n",
      "         0.0436],\n",
      "        [0.0511, 0.0942, 0.1096, 0.1176, 0.1209, 0.1227, 0.1212, 0.1169, 0.1024,\n",
      "         0.0434],\n",
      "        [0.0508, 0.0941, 0.1097, 0.1178, 0.1211, 0.1229, 0.1214, 0.1170, 0.1023,\n",
      "         0.0430],\n",
      "        [0.0507, 0.0940, 0.1097, 0.1179, 0.1212, 0.1230, 0.1214, 0.1170, 0.1022,\n",
      "         0.0428],\n",
      "        [0.0506, 0.0940, 0.1097, 0.1179, 0.1213, 0.1231, 0.1215, 0.1170, 0.1022,\n",
      "         0.0427],\n",
      "        [0.0505, 0.0940, 0.1097, 0.1180, 0.1213, 0.1231, 0.1215, 0.1171, 0.1022,\n",
      "         0.0426]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 30.00, Train Loss: 4.02, Val Loss: 10.68, Train BLEU: 5.94, Val BLEU: 0.19\n",
      "Sampling from training predictions...\n",
      "Source: 还有 这些 摇晃 着 旋转 转着 的 触角 <EOS> <PAD>\n",
      "Reference: it &apos;s got tentacles dangling , swirling around like\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[6.8648e-02, 1.2140e-01, 1.3693e-01, 1.4404e-01, 1.4389e-01, 1.3238e-01,\n",
      "         1.3633e-01, 1.0395e-01, 1.2426e-02, 9.5613e-12],\n",
      "        [6.0849e-02, 1.1961e-01, 1.3822e-01, 1.4686e-01, 1.4690e-01, 1.3360e-01,\n",
      "         1.3894e-01, 1.0327e-01, 1.1739e-02, 3.1367e-10],\n",
      "        [6.1336e-02, 1.1974e-01, 1.3821e-01, 1.4681e-01, 1.4676e-01, 1.3315e-01,\n",
      "         1.3843e-01, 1.0312e-01, 1.2439e-02, 7.5995e-10],\n",
      "        [6.0302e-02, 1.1963e-01, 1.3853e-01, 1.4732e-01, 1.4720e-01, 1.3315e-01,\n",
      "         1.3874e-01, 1.0296e-01, 1.2173e-02, 9.3086e-10],\n",
      "        [5.9501e-02, 1.1942e-01, 1.3871e-01, 1.4772e-01, 1.4761e-01, 1.3322e-01,\n",
      "         1.3908e-01, 1.0291e-01, 1.1832e-02, 8.7662e-10],\n",
      "        [5.9001e-02, 1.1933e-01, 1.3893e-01, 1.4810e-01, 1.4798e-01, 1.3326e-01,\n",
      "         1.3929e-01, 1.0262e-01, 1.1491e-02, 8.0932e-10],\n",
      "        [5.8794e-02, 1.1930e-01, 1.3903e-01, 1.4828e-01, 1.4816e-01, 1.3330e-01,\n",
      "         1.3938e-01, 1.0245e-01, 1.1324e-02, 7.8803e-10],\n",
      "        [5.8713e-02, 1.1927e-01, 1.3907e-01, 1.4834e-01, 1.4823e-01, 1.3332e-01,\n",
      "         1.3942e-01, 1.0238e-01, 1.1258e-02, 7.8365e-10],\n",
      "        [5.8674e-02, 1.1925e-01, 1.3908e-01, 1.4837e-01, 1.4826e-01, 1.3333e-01,\n",
      "         1.3944e-01, 1.0236e-01, 1.1228e-02, 7.8298e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 祖父 在 他 的 年代 是 位非 非凡\n",
      "Reference: my grandfather was an extraordinary man for his time\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0641, 0.1034, 0.1156, 0.1211, 0.1243, 0.1246, 0.1239, 0.1183, 0.0934,\n",
      "         0.0112],\n",
      "        [0.0573, 0.1019, 0.1164, 0.1230, 0.1268, 0.1272, 0.1264, 0.1199, 0.0916,\n",
      "         0.0095],\n",
      "        [0.0577, 0.1022, 0.1164, 0.1229, 0.1266, 0.1270, 0.1261, 0.1196, 0.0915,\n",
      "         0.0100],\n",
      "        [0.0570, 0.1021, 0.1166, 0.1231, 0.1269, 0.1272, 0.1263, 0.1196, 0.0914,\n",
      "         0.0099],\n",
      "        [0.0563, 0.1019, 0.1166, 0.1233, 0.1271, 0.1275, 0.1266, 0.1198, 0.0914,\n",
      "         0.0096],\n",
      "        [0.0559, 0.1017, 0.1167, 0.1235, 0.1274, 0.1277, 0.1268, 0.1199, 0.0911,\n",
      "         0.0093],\n",
      "        [0.0557, 0.1017, 0.1167, 0.1236, 0.1275, 0.1279, 0.1269, 0.1199, 0.0909,\n",
      "         0.0092],\n",
      "        [0.0556, 0.1016, 0.1167, 0.1236, 0.1276, 0.1279, 0.1270, 0.1200, 0.0908,\n",
      "         0.0091],\n",
      "        [0.0556, 0.1016, 0.1167, 0.1236, 0.1276, 0.1279, 0.1270, 0.1200, 0.0908,\n",
      "         0.0091]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31.00, Train Loss: 4.00, Val Loss: 10.76, Train BLEU: 5.94, Val BLEU: 0.22\n",
      "Sampling from training predictions...\n",
      "Source: 和 我们 合作 的 人们 帮 我们 找到 了 新\n",
      "Reference: people that have partnered with us have given us\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0619, 0.0977, 0.1094, 0.1155, 0.1177, 0.1190, 0.1173, 0.1135, 0.1011,\n",
      "         0.0469],\n",
      "        [0.0555, 0.0962, 0.1099, 0.1171, 0.1199, 0.1214, 0.1196, 0.1152, 0.1012,\n",
      "         0.0441],\n",
      "        [0.0562, 0.0964, 0.1099, 0.1170, 0.1197, 0.1211, 0.1193, 0.1148, 0.1009,\n",
      "         0.0447],\n",
      "        [0.0557, 0.0964, 0.1100, 0.1172, 0.1199, 0.1213, 0.1194, 0.1148, 0.1008,\n",
      "         0.0445],\n",
      "        [0.0549, 0.0962, 0.1101, 0.1174, 0.1201, 0.1216, 0.1196, 0.1150, 0.1008,\n",
      "         0.0442],\n",
      "        [0.0545, 0.0960, 0.1101, 0.1176, 0.1204, 0.1219, 0.1198, 0.1151, 0.1007,\n",
      "         0.0438],\n",
      "        [0.0543, 0.0959, 0.1102, 0.1177, 0.1205, 0.1220, 0.1199, 0.1151, 0.1006,\n",
      "         0.0436],\n",
      "        [0.0542, 0.0959, 0.1102, 0.1178, 0.1206, 0.1221, 0.1200, 0.1152, 0.1006,\n",
      "         0.0435],\n",
      "        [0.0542, 0.0959, 0.1102, 0.1178, 0.1206, 0.1221, 0.1200, 0.1152, 0.1006,\n",
      "         0.0434]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正 的 学校 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: a real school . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[0.0583, 0.1028, 0.1166, 0.1236, 0.1266, 0.1265, 0.1251, 0.1181, 0.0913,\n",
      "         0.0111],\n",
      "        [0.0522, 0.1013, 0.1173, 0.1254, 0.1289, 0.1289, 0.1271, 0.1190, 0.0896,\n",
      "         0.0103],\n",
      "        [0.0529, 0.1015, 0.1172, 0.1253, 0.1286, 0.1285, 0.1267, 0.1187, 0.0898,\n",
      "         0.0109],\n",
      "        [0.0522, 0.1014, 0.1174, 0.1256, 0.1289, 0.1287, 0.1268, 0.1187, 0.0896,\n",
      "         0.0107],\n",
      "        [0.0514, 0.1011, 0.1175, 0.1258, 0.1293, 0.1291, 0.1272, 0.1189, 0.0894,\n",
      "         0.0104],\n",
      "        [0.0510, 0.1009, 0.1175, 0.1260, 0.1295, 0.1293, 0.1274, 0.1189, 0.0891,\n",
      "         0.0102],\n",
      "        [0.0508, 0.1008, 0.1176, 0.1262, 0.1297, 0.1295, 0.1275, 0.1189, 0.0889,\n",
      "         0.0100],\n",
      "        [0.0507, 0.1008, 0.1176, 0.1262, 0.1298, 0.1295, 0.1276, 0.1189, 0.0889,\n",
      "         0.0100],\n",
      "        [0.0507, 0.1008, 0.1176, 0.1262, 0.1298, 0.1296, 0.1276, 0.1190, 0.0888,\n",
      "         0.0100]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 32.00, Train Loss: 3.98, Val Loss: 10.83, Train BLEU: 5.94, Val BLEU: 0.22\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数 多数 地震 和 火山 喷发 也 都 发生\n",
      "Reference: most of the earthquakes and volcanoes are in the\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0509, 0.0777, 0.1130, 0.1208, 0.1243, 0.1242, 0.1233, 0.1191, 0.1041,\n",
      "         0.0426],\n",
      "        [0.0450, 0.0744, 0.1131, 0.1225, 0.1267, 0.1267, 0.1257, 0.1211, 0.1044,\n",
      "         0.0404],\n",
      "        [0.0460, 0.0751, 0.1130, 0.1222, 0.1263, 0.1262, 0.1252, 0.1206, 0.1042,\n",
      "         0.0414],\n",
      "        [0.0454, 0.0748, 0.1131, 0.1224, 0.1266, 0.1265, 0.1254, 0.1207, 0.1041,\n",
      "         0.0411],\n",
      "        [0.0445, 0.0741, 0.1131, 0.1227, 0.1270, 0.1269, 0.1258, 0.1210, 0.1041,\n",
      "         0.0407],\n",
      "        [0.0441, 0.0737, 0.1132, 0.1229, 0.1273, 0.1272, 0.1260, 0.1211, 0.1040,\n",
      "         0.0403],\n",
      "        [0.0440, 0.0736, 0.1132, 0.1230, 0.1275, 0.1273, 0.1261, 0.1212, 0.1039,\n",
      "         0.0401],\n",
      "        [0.0439, 0.0735, 0.1132, 0.1231, 0.1275, 0.1274, 0.1262, 0.1212, 0.1039,\n",
      "         0.0400],\n",
      "        [0.0439, 0.0735, 0.1132, 0.1231, 0.1276, 0.1274, 0.1262, 0.1213, 0.1039,\n",
      "         0.0400]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 对 他 来说 孩子 不 接受 受教 教育 <UNK> 是\n",
      "Reference: to him , there was greater risk in not\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[1.1254e-01, 1.7225e-01, 1.8659e-01, 1.9037e-01, 1.8379e-01, 1.3900e-01,\n",
      "         1.5447e-02, 1.1143e-11, 1.1143e-11, 1.1143e-11],\n",
      "        [1.0365e-01, 1.7161e-01, 1.8909e-01, 1.9412e-01, 1.8729e-01, 1.3893e-01,\n",
      "         1.5313e-02, 4.3304e-10, 4.3304e-10, 4.3304e-10],\n",
      "        [1.0469e-01, 1.7161e-01, 1.8850e-01, 1.9325e-01, 1.8637e-01, 1.3892e-01,\n",
      "         1.6648e-02, 1.1288e-09, 1.1288e-09, 1.1288e-09],\n",
      "        [1.0358e-01, 1.7185e-01, 1.8904e-01, 1.9384e-01, 1.8677e-01, 1.3862e-01,\n",
      "         1.6305e-02, 1.4050e-09, 1.4050e-09, 1.4050e-09],\n",
      "        [1.0252e-01, 1.7186e-01, 1.8954e-01, 1.9453e-01, 1.8734e-01, 1.3846e-01,\n",
      "         1.5748e-02, 1.2967e-09, 1.2967e-09, 1.2967e-09],\n",
      "        [1.0189e-01, 1.7195e-01, 1.9000e-01, 1.9511e-01, 1.8773e-01, 1.3806e-01,\n",
      "         1.5260e-02, 1.1706e-09, 1.1706e-09, 1.1706e-09],\n",
      "        [1.0164e-01, 1.7198e-01, 1.9019e-01, 1.9536e-01, 1.8789e-01, 1.3787e-01,\n",
      "         1.5066e-02, 1.1407e-09, 1.1407e-09, 1.1407e-09],\n",
      "        [1.0152e-01, 1.7198e-01, 1.9027e-01, 1.9547e-01, 1.8797e-01, 1.3780e-01,\n",
      "         1.4988e-02, 1.1401e-09, 1.1401e-09, 1.1401e-09],\n",
      "        [1.0145e-01, 1.7197e-01, 1.9030e-01, 1.9552e-01, 1.8801e-01, 1.3778e-01,\n",
      "         1.4954e-02, 1.1447e-09, 1.1447e-09, 1.1447e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 33.00, Train Loss: 3.96, Val Loss: 10.90, Train BLEU: 5.80, Val BLEU: 0.22\n",
      "Sampling from training predictions...\n",
      "Source: <UNK> 塞尔 <UNK> <UNK> 斯特 说 过 真正 的 探索\n",
      "Reference: marcel proust said , &quot; the true voyage of\n",
      "Model: <SOS> marcel of the the , the the the the\n",
      "Attention Weights: tensor([[3.1398e-09, 2.8644e-09, 3.3391e-09, 2.6986e-08, 6.3138e-04, 1.6542e-01,\n",
      "         2.4758e-01, 2.5325e-01, 2.3075e-01, 1.0237e-01],\n",
      "        [3.6943e-08, 3.5926e-08, 4.0931e-08, 1.8662e-07, 4.3977e-04, 1.4966e-01,\n",
      "         2.5438e-01, 2.6580e-01, 2.3847e-01, 9.1255e-02],\n",
      "        [1.1189e-07, 1.0932e-07, 1.2322e-07, 4.8857e-07, 5.6835e-04, 1.4799e-01,\n",
      "         2.5453e-01, 2.6574e-01, 2.3848e-01, 9.2695e-02],\n",
      "        [1.4205e-07, 1.3897e-07, 1.5598e-07, 5.9032e-07, 5.7068e-04, 1.4613e-01,\n",
      "         2.5503e-01, 2.6669e-01, 2.3912e-01, 9.2461e-02],\n",
      "        [1.4263e-07, 1.3907e-07, 1.5558e-07, 5.8292e-07, 5.6251e-04, 1.4587e-01,\n",
      "         2.5509e-01, 2.6689e-01, 2.3920e-01, 9.2382e-02],\n",
      "        [1.4331e-07, 1.3955e-07, 1.5590e-07, 5.8316e-07, 5.6492e-04, 1.4588e-01,\n",
      "         2.5509e-01, 2.6692e-01, 2.3918e-01, 9.2362e-02],\n",
      "        [1.4524e-07, 1.4142e-07, 1.5789e-07, 5.9049e-07, 5.6965e-04, 1.4590e-01,\n",
      "         2.5506e-01, 2.6689e-01, 2.3916e-01, 9.2414e-02],\n",
      "        [1.4730e-07, 1.4346e-07, 1.6015e-07, 5.9904e-07, 5.7415e-04, 1.4596e-01,\n",
      "         2.5502e-01, 2.6683e-01, 2.3913e-01, 9.2495e-02],\n",
      "        [1.4882e-07, 1.4498e-07, 1.6182e-07, 6.0538e-07, 5.7722e-04, 1.4599e-01,\n",
      "         2.5499e-01, 2.6678e-01, 2.3911e-01, 9.2549e-02]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 所以 在 那 之后 5 年 我 <UNK> <UNK> 陪\n",
      "Reference: so for the next five years , i dressed\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[8.8990e-02, 1.5021e-01, 1.6489e-01, 1.7010e-01, 1.6737e-01, 1.3158e-01,\n",
      "         1.1579e-01, 1.1070e-02, 9.4388e-12, 9.4388e-12],\n",
      "        [8.1067e-02, 1.4932e-01, 1.6681e-01, 1.7311e-01, 1.7039e-01, 1.3226e-01,\n",
      "         1.1566e-01, 1.1389e-02, 3.8020e-10, 3.8020e-10],\n",
      "        [8.2311e-02, 1.4942e-01, 1.6635e-01, 1.7231e-01, 1.6943e-01, 1.3175e-01,\n",
      "         1.1579e-01, 1.2640e-02, 1.0200e-09, 1.0200e-09],\n",
      "        [8.1441e-02, 1.4975e-01, 1.6696e-01, 1.7293e-01, 1.6987e-01, 1.3112e-01,\n",
      "         1.1556e-01, 1.2373e-02, 1.2651e-09, 1.2651e-09],\n",
      "        [8.0318e-02, 1.4979e-01, 1.6754e-01, 1.7374e-01, 1.7060e-01, 1.3092e-01,\n",
      "         1.1527e-01, 1.1830e-02, 1.1527e-09, 1.1527e-09],\n",
      "        [7.9785e-02, 1.4980e-01, 1.6787e-01, 1.7423e-01, 1.7103e-01, 1.3085e-01,\n",
      "         1.1494e-01, 1.1495e-02, 1.0378e-09, 1.0378e-09],\n",
      "        [7.9498e-02, 1.4981e-01, 1.6806e-01, 1.7451e-01, 1.7127e-01, 1.3080e-01,\n",
      "         1.1473e-01, 1.1325e-02, 1.0058e-09, 1.0058e-09],\n",
      "        [7.9368e-02, 1.4980e-01, 1.6814e-01, 1.7462e-01, 1.7137e-01, 1.3080e-01,\n",
      "         1.1465e-01, 1.1258e-02, 1.0031e-09, 1.0031e-09],\n",
      "        [7.9302e-02, 1.4978e-01, 1.6816e-01, 1.7467e-01, 1.7142e-01, 1.3081e-01,\n",
      "         1.1462e-01, 1.1232e-02, 1.0059e-09, 1.0059e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 34.00, Train Loss: 3.95, Val Loss: 10.96, Train BLEU: 5.75, Val BLEU: 0.21\n",
      "Sampling from training predictions...\n",
      "Source: 但 我 想 告诉 你 的 是 当 你 站\n",
      "Reference: but when you &apos;re standing at the beach ,\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0661, 0.1003, 0.1101, 0.1142, 0.1173, 0.1176, 0.1161, 0.1119, 0.0992,\n",
      "         0.0470],\n",
      "        [0.0608, 0.0994, 0.1107, 0.1155, 0.1190, 0.1194, 0.1178, 0.1131, 0.0992,\n",
      "         0.0451],\n",
      "        [0.0619, 0.0997, 0.1106, 0.1152, 0.1185, 0.1188, 0.1172, 0.1126, 0.0991,\n",
      "         0.0464],\n",
      "        [0.0616, 0.0999, 0.1108, 0.1153, 0.1186, 0.1189, 0.1172, 0.1126, 0.0990,\n",
      "         0.0462],\n",
      "        [0.0609, 0.0997, 0.1109, 0.1156, 0.1189, 0.1192, 0.1175, 0.1128, 0.0989,\n",
      "         0.0457],\n",
      "        [0.0604, 0.0996, 0.1110, 0.1158, 0.1192, 0.1194, 0.1177, 0.1129, 0.0987,\n",
      "         0.0453],\n",
      "        [0.0602, 0.0995, 0.1111, 0.1159, 0.1193, 0.1196, 0.1178, 0.1129, 0.0987,\n",
      "         0.0451],\n",
      "        [0.0601, 0.0995, 0.1111, 0.1159, 0.1194, 0.1196, 0.1178, 0.1129, 0.0986,\n",
      "         0.0450],\n",
      "        [0.0601, 0.0995, 0.1111, 0.1159, 0.1194, 0.1197, 0.1179, 0.1129, 0.0986,\n",
      "         0.0449]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 因此 毫无 毫无疑问 无疑 疑问 他 的 孩子 应当 受到\n",
      "Reference: there was no question that his children would receive\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[7.5922e-02, 1.2638e-01, 1.3948e-01, 1.4564e-01, 1.4350e-01, 1.2424e-01,\n",
      "         1.3475e-01, 1.0028e-01, 9.8070e-03, 7.4671e-12],\n",
      "        [6.9472e-02, 1.2511e-01, 1.4042e-01, 1.4758e-01, 1.4552e-01, 1.2486e-01,\n",
      "         1.3654e-01, 1.0032e-01, 1.0193e-02, 3.1668e-10],\n",
      "        [7.0742e-02, 1.2524e-01, 1.4002e-01, 1.4693e-01, 1.4483e-01, 1.2441e-01,\n",
      "         1.3575e-01, 1.0068e-01, 1.1416e-02, 8.8453e-10],\n",
      "        [6.9990e-02, 1.2534e-01, 1.4039e-01, 1.4737e-01, 1.4513e-01, 1.2420e-01,\n",
      "         1.3600e-01, 1.0042e-01, 1.1166e-02, 1.1069e-09],\n",
      "        [6.9078e-02, 1.2526e-01, 1.4077e-01, 1.4795e-01, 1.4565e-01, 1.2409e-01,\n",
      "         1.3638e-01, 1.0013e-01, 1.0693e-02, 1.0076e-09],\n",
      "        [6.8513e-02, 1.2523e-01, 1.4107e-01, 1.4840e-01, 1.4606e-01, 1.2403e-01,\n",
      "         1.3656e-01, 9.9771e-02, 1.0354e-02, 8.9757e-10],\n",
      "        [6.8239e-02, 1.2521e-01, 1.4121e-01, 1.4861e-01, 1.4626e-01, 1.2403e-01,\n",
      "         1.3665e-01, 9.9582e-02, 1.0210e-02, 8.6682e-10],\n",
      "        [6.8095e-02, 1.2520e-01, 1.4127e-01, 1.4871e-01, 1.4635e-01, 1.2403e-01,\n",
      "         1.3670e-01, 9.9508e-02, 1.0148e-02, 8.6341e-10],\n",
      "        [6.8015e-02, 1.2518e-01, 1.4129e-01, 1.4875e-01, 1.4640e-01, 1.2403e-01,\n",
      "         1.3673e-01, 9.9483e-02, 1.0121e-02, 8.6505e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35.00, Train Loss: 3.93, Val Loss: 11.03, Train BLEU: 5.80, Val BLEU: 0.21\n",
      "Sampling from training predictions...\n",
      "Source: 还有 这些 摇晃 着 旋转 转着 的 触角 <EOS> <PAD>\n",
      "Reference: it &apos;s got tentacles dangling , swirling around like\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[7.7468e-02, 1.2749e-01, 1.4003e-01, 1.4590e-01, 1.4334e-01, 1.2220e-01,\n",
      "         1.3447e-01, 9.9775e-02, 9.3306e-03, 7.1641e-12],\n",
      "        [7.1214e-02, 1.2622e-01, 1.4084e-01, 1.4765e-01, 1.4519e-01, 1.2284e-01,\n",
      "         1.3616e-01, 9.9987e-02, 9.8934e-03, 3.2047e-10],\n",
      "        [7.2643e-02, 1.2630e-01, 1.4031e-01, 1.4684e-01, 1.4437e-01, 1.2247e-01,\n",
      "         1.3533e-01, 1.0050e-01, 1.1249e-02, 9.3389e-10],\n",
      "        [7.2007e-02, 1.2644e-01, 1.4067e-01, 1.4724e-01, 1.4462e-01, 1.2224e-01,\n",
      "         1.3555e-01, 1.0022e-01, 1.1017e-02, 1.1731e-09],\n",
      "        [7.1100e-02, 1.2640e-01, 1.4108e-01, 1.4782e-01, 1.4514e-01, 1.2212e-01,\n",
      "         1.3591e-01, 9.9901e-02, 1.0535e-02, 1.0623e-09],\n",
      "        [7.0517e-02, 1.2639e-01, 1.4140e-01, 1.4829e-01, 1.4556e-01, 1.2204e-01,\n",
      "         1.3609e-01, 9.9527e-02, 1.0189e-02, 9.4376e-10],\n",
      "        [7.0215e-02, 1.2639e-01, 1.4156e-01, 1.4852e-01, 1.4576e-01, 1.2203e-01,\n",
      "         1.3617e-01, 9.9324e-02, 1.0041e-02, 9.0842e-10],\n",
      "        [7.0058e-02, 1.2637e-01, 1.4162e-01, 1.4862e-01, 1.4586e-01, 1.2202e-01,\n",
      "         1.3622e-01, 9.9248e-02, 9.9788e-03, 9.0288e-10],\n",
      "        [6.9978e-02, 1.2635e-01, 1.4164e-01, 1.4866e-01, 1.4591e-01, 1.2203e-01,\n",
      "         1.3625e-01, 9.9227e-02, 9.9544e-03, 9.0310e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 都 知道 自己 正 冒 着 生命 的 危险\n",
      "Reference: we all knew we were risking our lives --\n",
      "Model: <SOS> it the the the the the the the the\n",
      "Attention Weights: tensor([[0.0607, 0.0997, 0.1095, 0.1167, 0.1183, 0.1195, 0.1168, 0.1124, 0.0989,\n",
      "         0.0475],\n",
      "        [0.0553, 0.0984, 0.1100, 0.1180, 0.1201, 0.1212, 0.1185, 0.1137, 0.0990,\n",
      "         0.0459],\n",
      "        [0.0567, 0.0987, 0.1098, 0.1175, 0.1194, 0.1205, 0.1178, 0.1132, 0.0990,\n",
      "         0.0474],\n",
      "        [0.0564, 0.0989, 0.1099, 0.1176, 0.1195, 0.1206, 0.1178, 0.1131, 0.0989,\n",
      "         0.0473],\n",
      "        [0.0558, 0.0987, 0.1100, 0.1179, 0.1198, 0.1209, 0.1180, 0.1133, 0.0988,\n",
      "         0.0468],\n",
      "        [0.0553, 0.0986, 0.1101, 0.1182, 0.1201, 0.1212, 0.1182, 0.1133, 0.0986,\n",
      "         0.0464],\n",
      "        [0.0551, 0.0985, 0.1102, 0.1183, 0.1202, 0.1213, 0.1183, 0.1134, 0.0985,\n",
      "         0.0461],\n",
      "        [0.0549, 0.0985, 0.1102, 0.1184, 0.1203, 0.1214, 0.1184, 0.1134, 0.0984,\n",
      "         0.0460],\n",
      "        [0.0549, 0.0985, 0.1102, 0.1184, 0.1204, 0.1215, 0.1184, 0.1134, 0.0984,\n",
      "         0.0459]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 36.00, Train Loss: 3.91, Val Loss: 11.08, Train BLEU: 7.06, Val BLEU: 0.99\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 这位 是 比尔 <UNK> 我 是 大卫 <UNK>\n",
      "Reference: this is bill lange . i &apos;m dave gallo\n",
      "Model: <SOS> it the the the the , , the the\n",
      "Attention Weights: tensor([[0.0262, 0.0003, 0.1876, 0.1972, 0.0226, 0.0017, 0.2646, 0.2440, 0.0558,\n",
      "         0.0000],\n",
      "        [0.0263, 0.0007, 0.1866, 0.1960, 0.0246, 0.0029, 0.2658, 0.2416, 0.0554,\n",
      "         0.0001],\n",
      "        [0.0287, 0.0010, 0.1857, 0.1951, 0.0270, 0.0037, 0.2613, 0.2386, 0.0588,\n",
      "         0.0001],\n",
      "        [0.0277, 0.0009, 0.1855, 0.1951, 0.0262, 0.0036, 0.2630, 0.2397, 0.0580,\n",
      "         0.0001],\n",
      "        [0.0269, 0.0009, 0.1852, 0.1950, 0.0255, 0.0034, 0.2646, 0.2408, 0.0576,\n",
      "         0.0001],\n",
      "        [0.0266, 0.0009, 0.1850, 0.1949, 0.0252, 0.0034, 0.2653, 0.2413, 0.0574,\n",
      "         0.0001],\n",
      "        [0.0265, 0.0009, 0.1849, 0.1948, 0.0251, 0.0033, 0.2655, 0.2416, 0.0573,\n",
      "         0.0001],\n",
      "        [0.0264, 0.0009, 0.1848, 0.1948, 0.0251, 0.0033, 0.2655, 0.2416, 0.0573,\n",
      "         0.0001],\n",
      "        [0.0265, 0.0009, 0.1847, 0.1948, 0.0251, 0.0033, 0.2655, 0.2417, 0.0574,\n",
      "         0.0001]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 因此 毫无 毫无疑问 无疑 疑问 他 的 孩子 应当 受到\n",
      "Reference: there was no question that his children would receive\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[7.8882e-02, 1.2843e-01, 1.4039e-01, 1.4596e-01, 1.4310e-01, 1.2038e-01,\n",
      "         1.3428e-01, 9.9640e-02, 8.9448e-03, 6.9142e-12],\n",
      "        [7.2778e-02, 1.2712e-01, 1.4106e-01, 1.4754e-01, 1.4480e-01, 1.2111e-01,\n",
      "         1.3592e-01, 1.0000e-01, 9.6695e-03, 3.2540e-10],\n",
      "        [7.4389e-02, 1.2713e-01, 1.4039e-01, 1.4655e-01, 1.4385e-01, 1.2082e-01,\n",
      "         1.3503e-01, 1.0066e-01, 1.1175e-02, 9.9255e-10],\n",
      "        [7.3895e-02, 1.2732e-01, 1.4072e-01, 1.4688e-01, 1.4403e-01, 1.2059e-01,\n",
      "         1.3521e-01, 1.0037e-01, 1.0980e-02, 1.2539e-09],\n",
      "        [7.3025e-02, 1.2729e-01, 1.4113e-01, 1.4745e-01, 1.4453e-01, 1.2046e-01,\n",
      "         1.3555e-01, 1.0006e-01, 1.0501e-02, 1.1284e-09],\n",
      "        [7.2404e-02, 1.2731e-01, 1.4148e-01, 1.4794e-01, 1.4495e-01, 1.2038e-01,\n",
      "         1.3573e-01, 9.9663e-02, 1.0137e-02, 1.0011e-09],\n",
      "        [7.2065e-02, 1.2733e-01, 1.4166e-01, 1.4819e-01, 1.4518e-01, 1.2035e-01,\n",
      "         1.3582e-01, 9.9435e-02, 9.9760e-03, 9.6039e-10],\n",
      "        [7.1902e-02, 1.2732e-01, 1.4173e-01, 1.4830e-01, 1.4528e-01, 1.2033e-01,\n",
      "         1.3587e-01, 9.9357e-02, 9.9120e-03, 9.5228e-10],\n",
      "        [7.1828e-02, 1.2730e-01, 1.4175e-01, 1.4833e-01, 1.4532e-01, 1.2034e-01,\n",
      "         1.3591e-01, 9.9344e-02, 9.8917e-03, 9.5120e-10]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 37.00, Train Loss: 3.89, Val Loss: 11.14, Train BLEU: 7.23, Val BLEU: 0.97\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 这位 是 比尔 <UNK> 我 是 大卫 <UNK>\n",
      "Reference: this is bill lange . i &apos;m dave gallo\n",
      "Model: <SOS> it the the the , , , , the\n",
      "Attention Weights: tensor([[0.0237, 0.0002, 0.1871, 0.1956, 0.0179, 0.0011, 0.2718, 0.2505, 0.0522,\n",
      "         0.0000],\n",
      "        [0.0244, 0.0005, 0.1860, 0.1944, 0.0204, 0.0021, 0.2724, 0.2474, 0.0524,\n",
      "         0.0001],\n",
      "        [0.0270, 0.0008, 0.1853, 0.1937, 0.0229, 0.0028, 0.2673, 0.2440, 0.0561,\n",
      "         0.0001],\n",
      "        [0.0261, 0.0007, 0.1851, 0.1937, 0.0222, 0.0027, 0.2689, 0.2449, 0.0555,\n",
      "         0.0001],\n",
      "        [0.0253, 0.0007, 0.1846, 0.1934, 0.0216, 0.0026, 0.2705, 0.2461, 0.0551,\n",
      "         0.0001],\n",
      "        [0.0250, 0.0007, 0.1844, 0.1933, 0.0213, 0.0026, 0.2712, 0.2466, 0.0549,\n",
      "         0.0001],\n",
      "        [0.0249, 0.0007, 0.1842, 0.1933, 0.0212, 0.0025, 0.2713, 0.2469, 0.0548,\n",
      "         0.0001],\n",
      "        [0.0249, 0.0007, 0.1841, 0.1932, 0.0213, 0.0026, 0.2713, 0.2469, 0.0549,\n",
      "         0.0001],\n",
      "        [0.0249, 0.0007, 0.1841, 0.1932, 0.0213, 0.0026, 0.2712, 0.2469, 0.0549,\n",
      "         0.0001]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11 岁 那年 记得 得有 一天 早晨 醒来 听见\n",
      "Reference: when i was 11 , i remember waking up\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[1.6768e-01, 2.6054e-01, 2.6880e-01, 2.2693e-01, 7.4848e-02, 6.8425e-05,\n",
      "         1.1358e-03, 1.4771e-11, 1.4771e-11, 1.4771e-11],\n",
      "        [1.5770e-01, 2.6016e-01, 2.7212e-01, 2.2996e-01, 7.7927e-02, 2.2421e-04,\n",
      "         1.9138e-03, 7.7876e-10, 7.7876e-10, 7.7876e-10],\n",
      "        [1.5923e-01, 2.5719e-01, 2.6851e-01, 2.2894e-01, 8.3061e-02, 3.8606e-04,\n",
      "         2.6742e-03, 2.4079e-09, 2.4079e-09, 2.4079e-09],\n",
      "        [1.5844e-01, 2.5793e-01, 2.6940e-01, 2.2887e-01, 8.2354e-02, 3.8673e-04,\n",
      "         2.6210e-03, 2.9150e-09, 2.9150e-09, 2.9150e-09],\n",
      "        [1.5721e-01, 2.5891e-01, 2.7085e-01, 2.2921e-01, 8.1031e-02, 3.5067e-04,\n",
      "         2.4365e-03, 2.5453e-09, 2.5453e-09, 2.5453e-09],\n",
      "        [1.5657e-01, 2.5949e-01, 2.7165e-01, 2.2932e-01, 8.0290e-02, 3.3197e-04,\n",
      "         2.3523e-03, 2.3248e-09, 2.3248e-09, 2.3248e-09],\n",
      "        [1.5619e-01, 2.5976e-01, 2.7207e-01, 2.2941e-01, 7.9920e-02, 3.2487e-04,\n",
      "         2.3194e-03, 2.2675e-09, 2.2675e-09, 2.2675e-09],\n",
      "        [1.5603e-01, 2.5982e-01, 2.7220e-01, 2.2949e-01, 7.9832e-02, 3.2332e-04,\n",
      "         2.3124e-03, 2.2577e-09, 2.2577e-09, 2.2577e-09],\n",
      "        [1.5598e-01, 2.5979e-01, 2.7221e-01, 2.2953e-01, 7.9854e-02, 3.2379e-04,\n",
      "         2.3151e-03, 2.2613e-09, 2.2613e-09, 2.2613e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 38.00, Train Loss: 3.87, Val Loss: 11.18, Train BLEU: 7.29, Val BLEU: 0.97\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中 的 生命 大卫 <UNK> <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: life in the deep oceans <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the the the the , , ,\n",
      "Attention Weights: tensor([[1.7155e-01, 2.6433e-01, 2.7069e-01, 2.2531e-01, 6.7206e-02, 4.1608e-05,\n",
      "         8.6433e-04, 1.4359e-11, 1.4359e-11, 1.4359e-11],\n",
      "        [1.6162e-01, 2.6375e-01, 2.7383e-01, 2.2820e-01, 7.0858e-02, 1.5905e-04,\n",
      "         1.5856e-03, 7.9320e-10, 7.9320e-10, 7.9320e-10],\n",
      "        [1.6328e-01, 2.6038e-01, 2.6991e-01, 2.2737e-01, 7.6460e-02, 2.9277e-04,\n",
      "         2.3097e-03, 2.5678e-09, 2.5678e-09, 2.5678e-09],\n",
      "        [1.6272e-01, 2.6103e-01, 2.7057e-01, 2.2713e-01, 7.5957e-02, 2.9888e-04,\n",
      "         2.2908e-03, 3.1400e-09, 3.1400e-09, 3.1400e-09],\n",
      "        [1.6160e-01, 2.6196e-01, 2.7190e-01, 2.2738e-01, 7.4748e-02, 2.7193e-04,\n",
      "         2.1356e-03, 2.7372e-09, 2.7372e-09, 2.7372e-09],\n",
      "        [1.6090e-01, 2.6261e-01, 2.7276e-01, 2.2746e-01, 7.3975e-02, 2.5607e-04,\n",
      "         2.0551e-03, 2.4922e-09, 2.4922e-09, 2.4922e-09],\n",
      "        [1.6049e-01, 2.6291e-01, 2.7320e-01, 2.2753e-01, 7.3592e-02, 2.5014e-04,\n",
      "         2.0244e-03, 2.4240e-09, 2.4240e-09, 2.4240e-09],\n",
      "        [1.6033e-01, 2.6296e-01, 2.7332e-01, 2.2760e-01, 7.3516e-02, 2.4904e-04,\n",
      "         2.0191e-03, 2.4102e-09, 2.4102e-09, 2.4102e-09],\n",
      "        [1.6029e-01, 2.6292e-01, 2.7331e-01, 2.2765e-01, 7.3554e-02, 2.4964e-04,\n",
      "         2.0229e-03, 2.4125e-09, 2.4125e-09, 2.4125e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天 要 走 不同 的 路线 这样 才 没有\n",
      "Reference: each day , we took a different route so\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[0.0640, 0.1020, 0.1110, 0.1164, 0.1174, 0.1182, 0.1161, 0.1123, 0.0997,\n",
      "         0.0430],\n",
      "        [0.0589, 0.1008, 0.1114, 0.1174, 0.1189, 0.1197, 0.1175, 0.1135, 0.0999,\n",
      "         0.0418],\n",
      "        [0.0608, 0.1010, 0.1110, 0.1166, 0.1179, 0.1188, 0.1167, 0.1130, 0.1000,\n",
      "         0.0441],\n",
      "        [0.0609, 0.1013, 0.1111, 0.1166, 0.1179, 0.1187, 0.1166, 0.1128, 0.0999,\n",
      "         0.0442],\n",
      "        [0.0604, 0.1013, 0.1112, 0.1168, 0.1181, 0.1189, 0.1168, 0.1130, 0.0998,\n",
      "         0.0438],\n",
      "        [0.0599, 0.1012, 0.1114, 0.1171, 0.1183, 0.1191, 0.1169, 0.1130, 0.0996,\n",
      "         0.0434],\n",
      "        [0.0596, 0.1012, 0.1115, 0.1173, 0.1185, 0.1193, 0.1171, 0.1130, 0.0995,\n",
      "         0.0431],\n",
      "        [0.0595, 0.1011, 0.1115, 0.1174, 0.1186, 0.1194, 0.1171, 0.1131, 0.0994,\n",
      "         0.0429],\n",
      "        [0.0594, 0.1011, 0.1115, 0.1174, 0.1186, 0.1194, 0.1171, 0.1131, 0.0994,\n",
      "         0.0429]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39.00, Train Loss: 3.86, Val Loss: 11.22, Train BLEU: 7.29, Val BLEU: 0.97\n",
      "Sampling from training predictions...\n",
      "Source: 我们 得用 非常 特殊 的 仪器 才能 能到 到达 那个\n",
      "Reference: we have to have a very special technology to\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[0.0588, 0.0701, 0.1155, 0.1232, 0.1268, 0.1266, 0.1234, 0.1065, 0.1036,\n",
      "         0.0455],\n",
      "        [0.0541, 0.0685, 0.1155, 0.1242, 0.1284, 0.1283, 0.1247, 0.1074, 0.1041,\n",
      "         0.0447],\n",
      "        [0.0564, 0.0706, 0.1147, 0.1228, 0.1267, 0.1267, 0.1234, 0.1073, 0.1041,\n",
      "         0.0472],\n",
      "        [0.0566, 0.0710, 0.1149, 0.1229, 0.1266, 0.1265, 0.1231, 0.1071, 0.1039,\n",
      "         0.0474],\n",
      "        [0.0562, 0.0707, 0.1150, 0.1231, 0.1269, 0.1267, 0.1233, 0.1071, 0.1039,\n",
      "         0.0471],\n",
      "        [0.0556, 0.0702, 0.1152, 0.1235, 0.1273, 0.1271, 0.1236, 0.1070, 0.1038,\n",
      "         0.0467],\n",
      "        [0.0553, 0.0698, 0.1154, 0.1238, 0.1276, 0.1274, 0.1238, 0.1069, 0.1037,\n",
      "         0.0464],\n",
      "        [0.0551, 0.0697, 0.1155, 0.1239, 0.1278, 0.1275, 0.1239, 0.1068, 0.1036,\n",
      "         0.0462],\n",
      "        [0.0551, 0.0696, 0.1155, 0.1239, 0.1278, 0.1276, 0.1239, 0.1068, 0.1036,\n",
      "         0.0462]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 面带 <UNK> <UNK> 笑容 这 很少 少见 因为 大部\n",
      "Reference: there was a big smile on his face which\n",
      "Model: <SOS> it of the the the the the the the\n",
      "Attention Weights: tensor([[1.9414e-02, 8.9930e-05, 1.8366e-01, 1.9079e-01, 1.1292e-02, 5.0329e-04,\n",
      "         2.8629e-01, 2.6215e-01, 4.5803e-02, 9.6615e-06],\n",
      "        [2.0890e-02, 2.9671e-04, 1.8239e-01, 1.8996e-01, 1.4099e-02, 1.1967e-03,\n",
      "         2.8620e-01, 2.5791e-01, 4.7019e-02, 4.8335e-05],\n",
      "        [2.3855e-02, 4.8456e-04, 1.8234e-01, 1.8998e-01, 1.6678e-02, 1.7406e-03,\n",
      "         2.7983e-01, 2.5366e-01, 5.1336e-02, 9.5203e-05],\n",
      "        [2.3297e-02, 4.8077e-04, 1.8210e-01, 1.8988e-01, 1.6361e-02, 1.7229e-03,\n",
      "         2.8080e-01, 2.5417e-01, 5.1100e-02, 9.6243e-05],\n",
      "        [2.2624e-02, 4.4725e-04, 1.8145e-01, 1.8956e-01, 1.5816e-02, 1.6270e-03,\n",
      "         2.8227e-01, 2.5541e-01, 5.0706e-02, 8.9774e-05],\n",
      "        [2.2321e-02, 4.3679e-04, 1.8111e-01, 1.8939e-01, 1.5579e-02, 1.5950e-03,\n",
      "         2.8295e-01, 2.5602e-01, 5.0503e-02, 8.7520e-05],\n",
      "        [2.2264e-02, 4.3662e-04, 1.8096e-01, 1.8936e-01, 1.5535e-02, 1.5934e-03,\n",
      "         2.8306e-01, 2.5622e-01, 5.0498e-02, 8.7572e-05],\n",
      "        [2.2284e-02, 4.3926e-04, 1.8088e-01, 1.8936e-01, 1.5558e-02, 1.6010e-03,\n",
      "         2.8298e-01, 2.5625e-01, 5.0562e-02, 8.8245e-05],\n",
      "        [2.2318e-02, 4.4216e-04, 1.8084e-01, 1.8936e-01, 1.5594e-02, 1.6097e-03,\n",
      "         2.8288e-01, 2.5624e-01, 5.0630e-02, 8.8967e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 40.00, Train Loss: 3.84, Val Loss: 11.26, Train BLEU: 7.29, Val BLEU: 0.97\n",
      "Sampling from training predictions...\n",
      "Source: 是 我 最 喜欢 的 因为 它 哪 都 能动\n",
      "Reference: it &apos;s one of my favorites , because it\n",
      "Model: <SOS> it &apos;s the the the , , , ,\n",
      "Attention Weights: tensor([[0.0748, 0.1085, 0.1165, 0.1202, 0.1222, 0.1216, 0.1206, 0.1151, 0.0922,\n",
      "         0.0082],\n",
      "        [0.0698, 0.1076, 0.1168, 0.1212, 0.1235, 0.1232, 0.1223, 0.1163, 0.0913,\n",
      "         0.0081],\n",
      "        [0.0717, 0.1077, 0.1163, 0.1203, 0.1225, 0.1222, 0.1214, 0.1158, 0.0923,\n",
      "         0.0098],\n",
      "        [0.0721, 0.1081, 0.1164, 0.1203, 0.1224, 0.1220, 0.1212, 0.1156, 0.0922,\n",
      "         0.0100],\n",
      "        [0.0718, 0.1080, 0.1165, 0.1204, 0.1225, 0.1221, 0.1213, 0.1157, 0.0921,\n",
      "         0.0098],\n",
      "        [0.0713, 0.1080, 0.1166, 0.1206, 0.1228, 0.1224, 0.1215, 0.1157, 0.0918,\n",
      "         0.0095],\n",
      "        [0.0709, 0.1079, 0.1168, 0.1208, 0.1230, 0.1226, 0.1216, 0.1157, 0.0915,\n",
      "         0.0092],\n",
      "        [0.0707, 0.1079, 0.1168, 0.1209, 0.1231, 0.1227, 0.1217, 0.1157, 0.0914,\n",
      "         0.0091],\n",
      "        [0.0707, 0.1079, 0.1168, 0.1209, 0.1231, 0.1227, 0.1217, 0.1157, 0.0914,\n",
      "         0.0091]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把 书 放在 食品 杂货 袋中 这样 别人 就\n",
      "Reference: we would cover our books in grocery bags so\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[0.0625, 0.1003, 0.1112, 0.1163, 0.1176, 0.1187, 0.1170, 0.1122, 0.1000,\n",
      "         0.0441],\n",
      "        [0.0574, 0.0986, 0.1114, 0.1174, 0.1191, 0.1204, 0.1188, 0.1135, 0.1004,\n",
      "         0.0431],\n",
      "        [0.0597, 0.0989, 0.1108, 0.1164, 0.1179, 0.1192, 0.1178, 0.1129, 0.1006,\n",
      "         0.0459],\n",
      "        [0.0600, 0.0992, 0.1109, 0.1163, 0.1177, 0.1190, 0.1175, 0.1126, 0.1005,\n",
      "         0.0462],\n",
      "        [0.0598, 0.0992, 0.1110, 0.1164, 0.1178, 0.1190, 0.1176, 0.1127, 0.1005,\n",
      "         0.0461],\n",
      "        [0.0594, 0.0991, 0.1111, 0.1166, 0.1180, 0.1192, 0.1177, 0.1127, 0.1004,\n",
      "         0.0457],\n",
      "        [0.0590, 0.0991, 0.1112, 0.1168, 0.1182, 0.1194, 0.1179, 0.1128, 0.1002,\n",
      "         0.0453],\n",
      "        [0.0589, 0.0991, 0.1113, 0.1169, 0.1184, 0.1196, 0.1180, 0.1128, 0.1001,\n",
      "         0.0451],\n",
      "        [0.0588, 0.0990, 0.1113, 0.1169, 0.1184, 0.1196, 0.1180, 0.1128, 0.1001,\n",
      "         0.0451]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 41.00, Train Loss: 3.82, Val Loss: 11.29, Train BLEU: 7.29, Val BLEU: 0.97\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 这位 是 比尔 <UNK> 我 是 大卫 <UNK>\n",
      "Reference: this is bill lange . i &apos;m dave gallo\n",
      "Model: <SOS> it the the the , , , , ,\n",
      "Attention Weights: tensor([[1.6084e-02, 4.4425e-05, 1.7923e-01, 1.8537e-01, 7.0435e-03, 2.5110e-04,\n",
      "         3.0042e-01, 2.7115e-01, 4.0396e-02, 5.7617e-06],\n",
      "        [1.8309e-02, 1.8875e-04, 1.7776e-01, 1.8504e-01, 9.9283e-03, 7.4455e-04,\n",
      "         2.9926e-01, 2.6597e-01, 4.2765e-02, 3.5952e-05],\n",
      "        [2.1802e-02, 3.4797e-04, 1.7840e-01, 1.8601e-01, 1.2578e-02, 1.2109e-03,\n",
      "         2.9087e-01, 2.6068e-01, 4.8018e-02, 8.0025e-05],\n",
      "        [2.1535e-02, 3.5498e-04, 1.7824e-01, 1.8607e-01, 1.2521e-02, 1.2305e-03,\n",
      "         2.9100e-01, 2.6076e-01, 4.8212e-02, 8.3654e-05],\n",
      "        [2.0906e-02, 3.2908e-04, 1.7756e-01, 1.8570e-01, 1.2046e-02, 1.1567e-03,\n",
      "         2.9241e-01, 2.6201e-01, 4.7811e-02, 7.8021e-05],\n",
      "        [2.0626e-02, 3.2145e-04, 1.7718e-01, 1.8551e-01, 1.1845e-02, 1.1334e-03,\n",
      "         2.9306e-01, 2.6264e-01, 4.7610e-02, 7.6188e-05],\n",
      "        [2.0575e-02, 3.2154e-04, 1.7703e-01, 1.8547e-01, 1.1811e-02, 1.1330e-03,\n",
      "         2.9315e-01, 2.6283e-01, 4.7602e-02, 7.6305e-05],\n",
      "        [2.0589e-02, 3.2346e-04, 1.7697e-01, 1.8546e-01, 1.1829e-02, 1.1385e-03,\n",
      "         2.9310e-01, 2.6287e-01, 4.7653e-02, 7.6889e-05],\n",
      "        [2.0613e-02, 3.2555e-04, 1.7693e-01, 1.8546e-01, 1.1856e-02, 1.1448e-03,\n",
      "         2.9303e-01, 2.6286e-01, 4.7710e-02, 7.7510e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 在 被 跟踪 吗 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: were we being followed ? <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the the the , , , ,\n",
      "Attention Weights: tensor([[0.0988, 0.1526, 0.1602, 0.1582, 0.1428, 0.0892, 0.0034, 0.0002, 0.1254,\n",
      "         0.0693],\n",
      "        [0.0933, 0.1535, 0.1627, 0.1608, 0.1440, 0.0885, 0.0046, 0.0004, 0.1240,\n",
      "         0.0682],\n",
      "        [0.0953, 0.1514, 0.1598, 0.1582, 0.1433, 0.0920, 0.0063, 0.0007, 0.1223,\n",
      "         0.0707],\n",
      "        [0.0957, 0.1514, 0.1595, 0.1577, 0.1428, 0.0921, 0.0066, 0.0008, 0.1222,\n",
      "         0.0712],\n",
      "        [0.0954, 0.1515, 0.1597, 0.1579, 0.1427, 0.0918, 0.0065, 0.0008, 0.1224,\n",
      "         0.0712],\n",
      "        [0.0951, 0.1518, 0.1602, 0.1583, 0.1429, 0.0914, 0.0063, 0.0007, 0.1224,\n",
      "         0.0709],\n",
      "        [0.0947, 0.1520, 0.1605, 0.1587, 0.1430, 0.0911, 0.0061, 0.0007, 0.1225,\n",
      "         0.0707],\n",
      "        [0.0946, 0.1521, 0.1607, 0.1588, 0.1430, 0.0909, 0.0061, 0.0007, 0.1225,\n",
      "         0.0706],\n",
      "        [0.0945, 0.1521, 0.1607, 0.1588, 0.1430, 0.0909, 0.0060, 0.0007, 0.1226,\n",
      "         0.0706]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 42.00, Train Loss: 3.80, Val Loss: 11.33, Train BLEU: 7.31, Val BLEU: 0.98\n",
      "Sampling from training predictions...\n",
      "Source: 是 我 最 喜欢 的 因为 它 哪 都 能动\n",
      "Reference: it &apos;s one of my favorites , because it\n",
      "Model: <SOS> it &apos;s the the the , , , ,\n",
      "Attention Weights: tensor([[0.0758, 0.1089, 0.1164, 0.1199, 0.1219, 0.1215, 0.1206, 0.1150, 0.0923,\n",
      "         0.0077],\n",
      "        [0.0709, 0.1078, 0.1165, 0.1207, 0.1231, 0.1230, 0.1223, 0.1163, 0.0916,\n",
      "         0.0079],\n",
      "        [0.0731, 0.1079, 0.1158, 0.1197, 0.1220, 0.1218, 0.1212, 0.1157, 0.0929,\n",
      "         0.0099],\n",
      "        [0.0737, 0.1082, 0.1159, 0.1195, 0.1217, 0.1215, 0.1209, 0.1155, 0.0929,\n",
      "         0.0102],\n",
      "        [0.0736, 0.1082, 0.1158, 0.1195, 0.1217, 0.1215, 0.1209, 0.1155, 0.0930,\n",
      "         0.0102],\n",
      "        [0.0732, 0.1082, 0.1160, 0.1198, 0.1219, 0.1217, 0.1211, 0.1155, 0.0927,\n",
      "         0.0099],\n",
      "        [0.0728, 0.1081, 0.1161, 0.1200, 0.1222, 0.1219, 0.1212, 0.1156, 0.0924,\n",
      "         0.0096],\n",
      "        [0.0727, 0.1081, 0.1162, 0.1200, 0.1223, 0.1220, 0.1213, 0.1156, 0.0923,\n",
      "         0.0095],\n",
      "        [0.0726, 0.1081, 0.1162, 0.1201, 0.1223, 0.1220, 0.1213, 0.1156, 0.0923,\n",
      "         0.0095]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 但是 我 那 受过 教育 的 母亲 成为 为了 一名\n",
      "Reference: but my educated mother became a teacher . <EOS>\n",
      "Model: <SOS> it &apos;s the the the the the , the\n",
      "Attention Weights: tensor([[1.6421e-01, 1.9802e-01, 9.6156e-02, 1.5098e-04, 4.6598e-02, 2.6192e-01,\n",
      "         2.2033e-01, 1.2614e-02, 1.1591e-11, 1.1591e-11],\n",
      "        [1.5734e-01, 1.9630e-01, 9.7078e-02, 4.9327e-04, 5.0332e-02, 2.6181e-01,\n",
      "         2.2100e-01, 1.5650e-02, 7.1959e-10, 7.1959e-10],\n",
      "        [1.5893e-01, 1.9525e-01, 1.0360e-01, 9.3230e-04, 5.6445e-02, 2.5029e-01,\n",
      "         2.1468e-01, 1.9877e-02, 2.7694e-09, 2.7694e-09],\n",
      "        [1.5909e-01, 1.9499e-01, 1.0415e-01, 1.0214e-03, 5.7318e-02, 2.4916e-01,\n",
      "         2.1394e-01, 2.0327e-02, 3.7117e-09, 3.7117e-09],\n",
      "        [1.5848e-01, 1.9484e-01, 1.0379e-01, 9.7249e-04, 5.7251e-02, 2.5025e-01,\n",
      "         2.1454e-01, 1.9866e-02, 3.2986e-09, 3.2986e-09],\n",
      "        [1.5789e-01, 1.9500e-01, 1.0317e-01, 9.0969e-04, 5.6568e-02, 2.5189e-01,\n",
      "         2.1533e-01, 1.9237e-02, 2.9287e-09, 2.9287e-09],\n",
      "        [1.5750e-01, 1.9515e-01, 1.0272e-01, 8.7869e-04, 5.6076e-02, 2.5300e-01,\n",
      "         2.1581e-01, 1.8859e-02, 2.7924e-09, 2.7924e-09],\n",
      "        [1.5734e-01, 1.9519e-01, 1.0258e-01, 8.7035e-04, 5.5919e-02, 2.5337e-01,\n",
      "         2.1599e-01, 1.8735e-02, 2.7593e-09, 2.7593e-09],\n",
      "        [1.5727e-01, 1.9517e-01, 1.0258e-01, 8.7096e-04, 5.5915e-02, 2.5344e-01,\n",
      "         2.1604e-01, 1.8719e-02, 2.7565e-09, 2.7565e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43.00, Train Loss: 3.78, Val Loss: 11.35, Train BLEU: 7.45, Val BLEU: 1.00\n",
      "Sampling from training predictions...\n",
      "Source: 还有 前面 的 这个 是 推进 引擎 它 一会 一会儿\n",
      "Reference: and it &apos;s got these jet thrusters up in\n",
      "Model: <SOS> it &apos;s the the the , , , ,\n",
      "Attention Weights: tensor([[0.0791, 0.1231, 0.1334, 0.1369, 0.1394, 0.1376, 0.1323, 0.1081, 0.0094,\n",
      "         0.0007],\n",
      "        [0.0738, 0.1221, 0.1344, 0.1386, 0.1414, 0.1394, 0.1333, 0.1066, 0.0094,\n",
      "         0.0010],\n",
      "        [0.0765, 0.1220, 0.1333, 0.1371, 0.1397, 0.1379, 0.1323, 0.1077, 0.0119,\n",
      "         0.0016],\n",
      "        [0.0773, 0.1223, 0.1332, 0.1369, 0.1393, 0.1375, 0.1319, 0.1076, 0.0123,\n",
      "         0.0017],\n",
      "        [0.0772, 0.1223, 0.1332, 0.1368, 0.1393, 0.1374, 0.1319, 0.1078, 0.0124,\n",
      "         0.0017],\n",
      "        [0.0770, 0.1222, 0.1333, 0.1369, 0.1394, 0.1376, 0.1320, 0.1077, 0.0122,\n",
      "         0.0017],\n",
      "        [0.0766, 0.1223, 0.1335, 0.1372, 0.1397, 0.1378, 0.1321, 0.1074, 0.0118,\n",
      "         0.0016],\n",
      "        [0.0763, 0.1223, 0.1336, 0.1374, 0.1399, 0.1379, 0.1321, 0.1073, 0.0116,\n",
      "         0.0016],\n",
      "        [0.0763, 0.1223, 0.1336, 0.1374, 0.1399, 0.1380, 0.1321, 0.1072, 0.0116,\n",
      "         0.0016]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 在 塔利 塔利班 控制 阿富汗 的 那些 年 我 记得\n",
      "Reference: during taliban years , i remember there were times\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[0.0711, 0.1122, 0.1222, 0.1263, 0.1281, 0.1274, 0.1255, 0.1149, 0.0711,\n",
      "         0.0011],\n",
      "        [0.0682, 0.1118, 0.1227, 0.1271, 0.1290, 0.1284, 0.1263, 0.1148, 0.0700,\n",
      "         0.0017],\n",
      "        [0.0708, 0.1118, 0.1217, 0.1258, 0.1275, 0.1270, 0.1251, 0.1147, 0.0730,\n",
      "         0.0026],\n",
      "        [0.0712, 0.1120, 0.1217, 0.1256, 0.1272, 0.1267, 0.1249, 0.1145, 0.0734,\n",
      "         0.0028],\n",
      "        [0.0712, 0.1120, 0.1217, 0.1255, 0.1272, 0.1267, 0.1249, 0.1146, 0.0735,\n",
      "         0.0028],\n",
      "        [0.0709, 0.1120, 0.1218, 0.1257, 0.1274, 0.1268, 0.1249, 0.1145, 0.0732,\n",
      "         0.0027],\n",
      "        [0.0705, 0.1120, 0.1219, 0.1259, 0.1276, 0.1270, 0.1251, 0.1145, 0.0728,\n",
      "         0.0026],\n",
      "        [0.0704, 0.1120, 0.1220, 0.1260, 0.1277, 0.1271, 0.1251, 0.1144, 0.0727,\n",
      "         0.0026],\n",
      "        [0.0704, 0.1120, 0.1220, 0.1260, 0.1277, 0.1271, 0.1251, 0.1144, 0.0726,\n",
      "         0.0026]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 44.00, Train Loss: 3.76, Val Loss: 11.38, Train BLEU: 7.50, Val BLEU: 1.02\n",
      "Sampling from training predictions...\n",
      "Source: 地球 的 大部 大部分 部分 都 是 海水 <EOS> <PAD>\n",
      "Reference: most of the planet is ocean water . <EOS>\n",
      "Model: <SOS> it &apos;s the the the , , , ,\n",
      "Attention Weights: tensor([[8.1883e-02, 1.2886e-01, 1.3602e-01, 1.3863e-01, 1.4103e-01, 1.3984e-01,\n",
      "         1.3152e-01, 9.6606e-02, 5.6157e-03, 5.1251e-12],\n",
      "        [7.5916e-02, 1.2701e-01, 1.3593e-01, 1.3945e-01, 1.4254e-01, 1.4175e-01,\n",
      "         1.3312e-01, 9.7230e-02, 7.0610e-03, 3.0861e-10],\n",
      "        [7.8926e-02, 1.2650e-01, 1.3456e-01, 1.3780e-01, 1.4073e-01, 1.4015e-01,\n",
      "         1.3236e-01, 9.9365e-02, 9.6127e-03, 1.3370e-09],\n",
      "        [7.9737e-02, 1.2668e-01, 1.3436e-01, 1.3744e-01, 1.4029e-01, 1.3972e-01,\n",
      "         1.3208e-01, 9.9601e-02, 1.0094e-02, 1.8958e-09],\n",
      "        [7.9750e-02, 1.2660e-01, 1.3433e-01, 1.3742e-01, 1.4024e-01, 1.3967e-01,\n",
      "         1.3212e-01, 9.9772e-02, 1.0090e-02, 1.7684e-09],\n",
      "        [7.9411e-02, 1.2664e-01, 1.3452e-01, 1.3765e-01, 1.4046e-01, 1.3983e-01,\n",
      "         1.3214e-01, 9.9522e-02, 9.8302e-03, 1.5512e-09],\n",
      "        [7.8974e-02, 1.2673e-01, 1.3474e-01, 1.3792e-01, 1.4073e-01, 1.4004e-01,\n",
      "         1.3217e-01, 9.9142e-02, 9.5461e-03, 1.4368e-09],\n",
      "        [7.8749e-02, 1.2678e-01, 1.3486e-01, 1.3805e-01, 1.4087e-01, 1.4015e-01,\n",
      "         1.3220e-01, 9.8947e-02, 9.3983e-03, 1.3994e-09],\n",
      "        [7.8682e-02, 1.2679e-01, 1.3489e-01, 1.3808e-01, 1.4090e-01, 1.4019e-01,\n",
      "         1.3221e-01, 9.8902e-02, 9.3582e-03, 1.3928e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11 岁 那年 记得 得有 一天 早晨 醒来 听见\n",
      "Reference: when i was 11 , i remember waking up\n",
      "Model: <SOS> it &apos;s the the the the the , the\n",
      "Attention Weights: tensor([[1.8886e-01, 2.8386e-01, 2.8010e-01, 2.1265e-01, 3.4387e-02, 4.3228e-06,\n",
      "         1.4181e-04, 1.1357e-11, 1.1357e-11, 1.1357e-11],\n",
      "        [1.7862e-01, 2.8295e-01, 2.8273e-01, 2.1497e-01, 4.0232e-02, 3.5144e-05,\n",
      "         4.6338e-04, 8.0088e-10, 8.0088e-10, 8.0088e-10],\n",
      "        [1.8109e-01, 2.7670e-01, 2.7693e-01, 2.1621e-01, 4.8071e-02, 9.3385e-05,\n",
      "         9.0481e-04, 3.2739e-09, 3.2739e-09, 3.2739e-09],\n",
      "        [1.8162e-01, 2.7599e-01, 2.7615e-01, 2.1591e-01, 4.9211e-02, 1.1039e-04,\n",
      "         1.0008e-03, 4.3823e-09, 4.3823e-09, 4.3823e-09],\n",
      "        [1.8156e-01, 2.7585e-01, 2.7622e-01, 2.1594e-01, 4.9335e-02, 1.0789e-04,\n",
      "         9.8634e-04, 3.9144e-09, 3.9144e-09, 3.9144e-09],\n",
      "        [1.8102e-01, 2.7641e-01, 2.7688e-01, 2.1585e-01, 4.8792e-02, 1.0210e-04,\n",
      "         9.5280e-04, 3.5506e-09, 3.5506e-09, 3.5506e-09],\n",
      "        [1.8067e-01, 2.7681e-01, 2.7732e-01, 2.1581e-01, 4.8351e-02, 9.8820e-05,\n",
      "         9.3389e-04, 3.4096e-09, 3.4096e-09, 3.4096e-09],\n",
      "        [1.8054e-01, 2.7695e-01, 2.7749e-01, 2.1582e-01, 4.8181e-02, 9.7776e-05,\n",
      "         9.2770e-04, 3.3798e-09, 3.3798e-09, 3.3798e-09],\n",
      "        [1.8048e-01, 2.7695e-01, 2.7753e-01, 2.1585e-01, 4.8162e-02, 9.7913e-05,\n",
      "         9.2889e-04, 3.3879e-09, 3.3879e-09, 3.3879e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 45.00, Train Loss: 3.74, Val Loss: 11.41, Train BLEU: 7.38, Val BLEU: 1.02\n",
      "Sampling from training predictions...\n",
      "Source: 当 你 站 在 海滩 上 或是 当 你 看到\n",
      "Reference: part of the problem , i think , is\n",
      "Model: <SOS> it &apos;s the the the the , , ,\n",
      "Attention Weights: tensor([[0.0722, 0.1030, 0.1104, 0.1140, 0.1150, 0.1164, 0.1143, 0.1113, 0.0986,\n",
      "         0.0448],\n",
      "        [0.0677, 0.1021, 0.1107, 0.1148, 0.1161, 0.1178, 0.1156, 0.1125, 0.0987,\n",
      "         0.0440],\n",
      "        [0.0702, 0.1020, 0.1098, 0.1136, 0.1148, 0.1164, 0.1144, 0.1117, 0.0993,\n",
      "         0.0479],\n",
      "        [0.0711, 0.1023, 0.1097, 0.1132, 0.1143, 0.1159, 0.1139, 0.1113, 0.0993,\n",
      "         0.0489],\n",
      "        [0.0715, 0.1024, 0.1095, 0.1130, 0.1141, 0.1156, 0.1137, 0.1112, 0.0995,\n",
      "         0.0495],\n",
      "        [0.0716, 0.1024, 0.1096, 0.1131, 0.1141, 0.1156, 0.1137, 0.1112, 0.0994,\n",
      "         0.0495],\n",
      "        [0.0714, 0.1024, 0.1097, 0.1132, 0.1143, 0.1157, 0.1138, 0.1112, 0.0992,\n",
      "         0.0491],\n",
      "        [0.0712, 0.1024, 0.1098, 0.1133, 0.1144, 0.1158, 0.1138, 0.1112, 0.0991,\n",
      "         0.0488],\n",
      "        [0.0712, 0.1024, 0.1098, 0.1134, 0.1144, 0.1159, 0.1139, 0.1112, 0.0991,\n",
      "         0.0488]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 对 他 来说 孩子 不 接受 受教 教育 <UNK> 是\n",
      "Reference: to him , there was greater risk in not\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[1.2777e-01, 1.7847e-01, 1.8653e-01, 1.8793e-01, 1.8036e-01, 1.3203e-01,\n",
      "         6.9026e-03, 6.6983e-12, 6.6983e-12, 6.6983e-12],\n",
      "        [1.2127e-01, 1.7738e-01, 1.8758e-01, 1.8985e-01, 1.8212e-01, 1.3288e-01,\n",
      "         8.9249e-03, 4.2003e-10, 4.2003e-10, 4.2003e-10],\n",
      "        [1.2430e-01, 1.7566e-01, 1.8479e-01, 1.8697e-01, 1.8022e-01, 1.3556e-01,\n",
      "         1.2494e-02, 1.9004e-09, 1.9004e-09, 1.9004e-09],\n",
      "        [1.2526e-01, 1.7548e-01, 1.8414e-01, 1.8622e-01, 1.7967e-01, 1.3593e-01,\n",
      "         1.3298e-02, 2.7598e-09, 2.7598e-09, 2.7598e-09],\n",
      "        [1.2527e-01, 1.7523e-01, 1.8394e-01, 1.8608e-01, 1.7971e-01, 1.3635e-01,\n",
      "         1.3415e-02, 2.5688e-09, 2.5688e-09, 2.5688e-09],\n",
      "        [1.2484e-01, 1.7548e-01, 1.8434e-01, 1.8647e-01, 1.7990e-01, 1.3598e-01,\n",
      "         1.2993e-02, 2.2234e-09, 2.2234e-09, 2.2234e-09],\n",
      "        [1.2445e-01, 1.7572e-01, 1.8470e-01, 1.8681e-01, 1.8007e-01, 1.3560e-01,\n",
      "         1.2645e-02, 2.0832e-09, 2.0832e-09, 2.0832e-09],\n",
      "        [1.2426e-01, 1.7581e-01, 1.8485e-01, 1.8697e-01, 1.8016e-01, 1.3545e-01,\n",
      "         1.2498e-02, 2.0557e-09, 2.0557e-09, 2.0557e-09],\n",
      "        [1.2418e-01, 1.7583e-01, 1.8491e-01, 1.8702e-01, 1.8020e-01, 1.3541e-01,\n",
      "         1.2450e-02, 2.0542e-09, 2.0542e-09, 2.0542e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 46.00, Train Loss: 3.72, Val Loss: 11.43, Train BLEU: 7.34, Val BLEU: 1.02\n",
      "Sampling from training predictions...\n",
      "Source: 但 我 想 告诉 你 的 是 当 你 站\n",
      "Reference: but when you &apos;re standing at the beach ,\n",
      "Model: <SOS> most &apos;s the the the the the , ,\n",
      "Attention Weights: tensor([[0.0714, 0.1024, 0.1095, 0.1125, 0.1153, 0.1155, 0.1142, 0.1105, 0.0987,\n",
      "         0.0500],\n",
      "        [0.0667, 0.1013, 0.1098, 0.1134, 0.1167, 0.1170, 0.1157, 0.1117, 0.0988,\n",
      "         0.0490],\n",
      "        [0.0692, 0.1012, 0.1089, 0.1122, 0.1152, 0.1155, 0.1145, 0.1109, 0.0994,\n",
      "         0.0530],\n",
      "        [0.0704, 0.1015, 0.1087, 0.1118, 0.1146, 0.1149, 0.1139, 0.1105, 0.0995,\n",
      "         0.0542],\n",
      "        [0.0708, 0.1015, 0.1085, 0.1115, 0.1143, 0.1146, 0.1136, 0.1104, 0.0997,\n",
      "         0.0549],\n",
      "        [0.0710, 0.1016, 0.1085, 0.1115, 0.1143, 0.1146, 0.1136, 0.1103, 0.0996,\n",
      "         0.0550],\n",
      "        [0.0709, 0.1016, 0.1086, 0.1117, 0.1144, 0.1147, 0.1136, 0.1103, 0.0995,\n",
      "         0.0547],\n",
      "        [0.0707, 0.1016, 0.1087, 0.1118, 0.1146, 0.1148, 0.1137, 0.1103, 0.0994,\n",
      "         0.0544],\n",
      "        [0.0707, 0.1016, 0.1088, 0.1118, 0.1146, 0.1148, 0.1137, 0.1103, 0.0993,\n",
      "         0.0543]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 出身 阿富汗 边远 <UNK> 地区 有着 与 他人 不同\n",
      "Reference: a total maverick from a remote province of afghanistan\n",
      "Model: <SOS> it &apos;s the the the the the the the\n",
      "Attention Weights: tensor([[8.9691e-02, 1.3915e-01, 1.4699e-01, 1.4489e-01, 9.0733e-02, 1.4509e-01,\n",
      "         1.3856e-01, 1.0001e-01, 4.8901e-03, 5.0821e-12],\n",
      "        [8.3470e-02, 1.3705e-01, 1.4671e-01, 1.4492e-01, 9.3933e-02, 1.4674e-01,\n",
      "         1.4001e-01, 1.0071e-01, 6.4569e-03, 3.1028e-10],\n",
      "        [8.6325e-02, 1.3535e-01, 1.4392e-01, 1.4223e-01, 9.6806e-02, 1.4432e-01,\n",
      "         1.3861e-01, 1.0318e-01, 9.2585e-03, 1.4629e-09],\n",
      "        [8.7413e-02, 1.3515e-01, 1.4319e-01, 1.4142e-01, 9.7382e-02, 1.4368e-01,\n",
      "         1.3817e-01, 1.0363e-01, 9.9672e-03, 2.1487e-09],\n",
      "        [8.7580e-02, 1.3490e-01, 1.4290e-01, 1.4120e-01, 9.7767e-02, 1.4350e-01,\n",
      "         1.3813e-01, 1.0393e-01, 1.0106e-02, 2.0240e-09],\n",
      "        [8.7460e-02, 1.3497e-01, 1.4306e-01, 1.4136e-01, 9.7767e-02, 1.4355e-01,\n",
      "         1.3811e-01, 1.0377e-01, 9.9434e-03, 1.7831e-09],\n",
      "        [8.7117e-02, 1.3522e-01, 1.4343e-01, 1.4167e-01, 9.7398e-02, 1.4385e-01,\n",
      "         1.3825e-01, 1.0343e-01, 9.6434e-03, 1.6448e-09],\n",
      "        [8.6936e-02, 1.3533e-01, 1.4360e-01, 1.4182e-01, 9.7193e-02, 1.4400e-01,\n",
      "         1.3834e-01, 1.0327e-01, 9.4945e-03, 1.6071e-09],\n",
      "        [8.6861e-02, 1.3536e-01, 1.4366e-01, 1.4187e-01, 9.7127e-02, 1.4406e-01,\n",
      "         1.3839e-01, 1.0323e-01, 9.4447e-03, 1.6035e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47.00, Train Loss: 3.70, Val Loss: 11.46, Train BLEU: 7.05, Val BLEU: 1.03\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本 基本上 都 没有 被 开发 发过 但是 像\n",
      "Reference: it &apos;s mostly unexplored , and yet there are\n",
      "Model: <SOS> most &apos;s the the the the the , ,\n",
      "Attention Weights: tensor([[0.0657, 0.1021, 0.1088, 0.1152, 0.1161, 0.1172, 0.1150, 0.1113, 0.0987,\n",
      "         0.0500],\n",
      "        [0.0603, 0.1002, 0.1087, 0.1164, 0.1177, 0.1191, 0.1168, 0.1128, 0.0989,\n",
      "         0.0490],\n",
      "        [0.0631, 0.1002, 0.1079, 0.1149, 0.1162, 0.1175, 0.1154, 0.1120, 0.0996,\n",
      "         0.0532],\n",
      "        [0.0646, 0.1005, 0.1077, 0.1144, 0.1155, 0.1167, 0.1148, 0.1115, 0.0997,\n",
      "         0.0546],\n",
      "        [0.0653, 0.1006, 0.1075, 0.1140, 0.1151, 0.1163, 0.1144, 0.1114, 0.0999,\n",
      "         0.0555],\n",
      "        [0.0655, 0.1007, 0.1076, 0.1140, 0.1150, 0.1162, 0.1143, 0.1112, 0.0998,\n",
      "         0.0556],\n",
      "        [0.0654, 0.1008, 0.1077, 0.1141, 0.1151, 0.1163, 0.1144, 0.1112, 0.0997,\n",
      "         0.0553],\n",
      "        [0.0653, 0.1008, 0.1078, 0.1142, 0.1153, 0.1164, 0.1144, 0.1112, 0.0995,\n",
      "         0.0550],\n",
      "        [0.0653, 0.1008, 0.1078, 0.1143, 0.1153, 0.1165, 0.1144, 0.1112, 0.0995,\n",
      "         0.0549]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 父亲 在 用 他 的 灰色 小 收音\n",
      "Reference: my father was listening to bbc news on his\n",
      "Model: <SOS> it &apos;s the the the the the , ,\n",
      "Attention Weights: tensor([[2.5458e-03, 5.0627e-06, 8.5713e-02, 1.3473e-01, 9.4102e-02, 1.6004e-01,\n",
      "         1.6225e-01, 1.5667e-01, 1.3978e-01, 6.4166e-02],\n",
      "        [2.9658e-03, 2.4995e-05, 8.3412e-02, 1.3322e-01, 9.2881e-02, 1.6243e-01,\n",
      "         1.6519e-01, 1.5894e-01, 1.3988e-01, 6.1063e-02],\n",
      "        [4.5055e-03, 6.5116e-05, 8.6240e-02, 1.3184e-01, 9.5052e-02, 1.5881e-01,\n",
      "         1.6163e-01, 1.5626e-01, 1.3948e-01, 6.6111e-02],\n",
      "        [5.1307e-03, 8.5238e-05, 8.7713e-02, 1.3180e-01, 9.6179e-02, 1.5714e-01,\n",
      "         1.5983e-01, 1.5480e-01, 1.3908e-01, 6.8247e-02],\n",
      "        [5.2846e-03, 8.6750e-05, 8.8182e-02, 1.3190e-01, 9.6845e-02, 1.5660e-01,\n",
      "         1.5918e-01, 1.5421e-01, 1.3883e-01, 6.8884e-02],\n",
      "        [5.1707e-03, 8.1607e-05, 8.8022e-02, 1.3214e-01, 9.6862e-02, 1.5689e-01,\n",
      "         1.5938e-01, 1.5427e-01, 1.3869e-01, 6.8492e-02],\n",
      "        [5.0747e-03, 7.8666e-05, 8.7879e-02, 1.3229e-01, 9.6687e-02, 1.5716e-01,\n",
      "         1.5963e-01, 1.5440e-01, 1.3866e-01, 6.8136e-02],\n",
      "        [5.0448e-03, 7.7826e-05, 8.7853e-02, 1.3234e-01, 9.6630e-02, 1.5724e-01,\n",
      "         1.5970e-01, 1.5445e-01, 1.3865e-01, 6.8023e-02],\n",
      "        [5.0412e-03, 7.7736e-05, 8.7870e-02, 1.3236e-01, 9.6632e-02, 1.5724e-01,\n",
      "         1.5970e-01, 1.5444e-01, 1.3864e-01, 6.8007e-02]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 48.00, Train Loss: 3.68, Val Loss: 11.48, Train BLEU: 6.11, Val BLEU: 0.91\n",
      "Sampling from training predictions...\n",
      "Source: 底下 这些 都 是 <UNK> 它们 上上 上上下下 上下 下下\n",
      "Reference: it &apos;s got these fishing <UNK> on the bottom\n",
      "Model: <SOS> it &apos;s the the the , , , ,\n",
      "Attention Weights: tensor([[0.0995, 0.1477, 0.1316, 0.0535, 0.0001, 0.1464, 0.1234, 0.1704, 0.1224,\n",
      "         0.0051],\n",
      "        [0.0943, 0.1497, 0.1335, 0.0544, 0.0002, 0.1464, 0.1230, 0.1719, 0.1210,\n",
      "         0.0055],\n",
      "        [0.0970, 0.1476, 0.1339, 0.0615, 0.0005, 0.1427, 0.1226, 0.1651, 0.1211,\n",
      "         0.0079],\n",
      "        [0.0983, 0.1470, 0.1340, 0.0636, 0.0006, 0.1417, 0.1223, 0.1627, 0.1210,\n",
      "         0.0088],\n",
      "        [0.0985, 0.1463, 0.1337, 0.0646, 0.0006, 0.1414, 0.1225, 0.1618, 0.1212,\n",
      "         0.0092],\n",
      "        [0.0987, 0.1461, 0.1335, 0.0647, 0.0006, 0.1415, 0.1228, 0.1617, 0.1211,\n",
      "         0.0092],\n",
      "        [0.0985, 0.1461, 0.1335, 0.0644, 0.0006, 0.1420, 0.1228, 0.1621, 0.1210,\n",
      "         0.0091],\n",
      "        [0.0983, 0.1461, 0.1334, 0.0642, 0.0006, 0.1423, 0.1228, 0.1623, 0.1210,\n",
      "         0.0090],\n",
      "        [0.0983, 0.1460, 0.1333, 0.0641, 0.0006, 0.1424, 0.1229, 0.1624, 0.1210,\n",
      "         0.0090]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 父亲 那 就是 他 他 是 他家 家族\n",
      "Reference: and my father -- that &apos;s him -- he\n",
      "Model: <SOS> it &apos;s the the the the the , ,\n",
      "Attention Weights: tensor([[0.0995, 0.1477, 0.1316, 0.0535, 0.0001, 0.1464, 0.1234, 0.1704, 0.1224,\n",
      "         0.0051],\n",
      "        [0.0943, 0.1497, 0.1335, 0.0544, 0.0002, 0.1464, 0.1230, 0.1719, 0.1210,\n",
      "         0.0055],\n",
      "        [0.0970, 0.1476, 0.1339, 0.0615, 0.0005, 0.1427, 0.1226, 0.1651, 0.1211,\n",
      "         0.0079],\n",
      "        [0.0983, 0.1470, 0.1340, 0.0636, 0.0006, 0.1417, 0.1223, 0.1627, 0.1210,\n",
      "         0.0088],\n",
      "        [0.0985, 0.1463, 0.1337, 0.0646, 0.0006, 0.1414, 0.1225, 0.1618, 0.1212,\n",
      "         0.0092],\n",
      "        [0.0987, 0.1461, 0.1335, 0.0647, 0.0006, 0.1415, 0.1228, 0.1617, 0.1211,\n",
      "         0.0092],\n",
      "        [0.0985, 0.1461, 0.1335, 0.0644, 0.0006, 0.1420, 0.1228, 0.1621, 0.1210,\n",
      "         0.0091],\n",
      "        [0.0983, 0.1461, 0.1334, 0.0642, 0.0006, 0.1423, 0.1228, 0.1623, 0.1210,\n",
      "         0.0090],\n",
      "        [0.0983, 0.1460, 0.1333, 0.0641, 0.0006, 0.1424, 0.1229, 0.1624, 0.1210,\n",
      "         0.0090]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 49.00, Train Loss: 3.66, Val Loss: 11.50, Train BLEU: 6.21, Val BLEU: 0.26\n",
      "Sampling from training predictions...\n",
      "Source: 它 可以 伸展 <UNK> 150 英尺 长 <EOS> <PAD> <PAD>\n",
      "Reference: it gets up to about 150 feet long .\n",
      "Model: <SOS> it &apos;s the the the . . . .\n",
      "Attention Weights: tensor([[1.8833e-01, 2.0232e-01, 5.9942e-02, 2.8967e-05, 2.0774e-02, 2.8790e-01,\n",
      "         2.3363e-01, 7.0724e-03, 9.7198e-12, 9.7198e-12],\n",
      "        [1.7931e-01, 1.9999e-01, 6.2714e-02, 1.3350e-04, 2.2972e-02, 2.8940e-01,\n",
      "         2.3563e-01, 9.8520e-03, 6.0325e-10, 6.0325e-10],\n",
      "        [1.7937e-01, 1.9966e-01, 7.3722e-02, 3.5101e-04, 2.9714e-02, 2.7275e-01,\n",
      "         2.2950e-01, 1.4926e-02, 3.1103e-09, 3.1103e-09],\n",
      "        [1.8001e-01, 1.9943e-01, 7.7027e-02, 4.6634e-04, 3.2485e-02, 2.6715e-01,\n",
      "         2.2675e-01, 1.6679e-02, 4.8226e-09, 4.8226e-09],\n",
      "        [1.7986e-01, 1.9890e-01, 7.8248e-02, 4.8459e-04, 3.3753e-02, 2.6558e-01,\n",
      "         2.2602e-01, 1.7152e-02, 4.4895e-09, 4.4895e-09],\n",
      "        [1.7973e-01, 1.9880e-01, 7.8294e-02, 4.7305e-04, 3.3878e-02, 2.6573e-01,\n",
      "         2.2602e-01, 1.7075e-02, 4.0000e-09, 4.0000e-09],\n",
      "        [1.7958e-01, 1.9887e-01, 7.7611e-02, 4.5739e-04, 3.3513e-02, 2.6679e-01,\n",
      "         2.2643e-01, 1.6744e-02, 3.7899e-09, 3.7899e-09],\n",
      "        [1.7954e-01, 1.9892e-01, 7.7239e-02, 4.5136e-04, 3.3313e-02, 2.6729e-01,\n",
      "         2.2666e-01, 1.6585e-02, 3.7622e-09, 3.7622e-09],\n",
      "        [1.7952e-01, 1.9894e-01, 7.7080e-02, 4.4998e-04, 3.3234e-02, 2.6748e-01,\n",
      "         2.2677e-01, 1.6531e-02, 3.7745e-09, 3.7745e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 总是 担心 会 被 塔利 塔利班 发现 <EOS> <PAD>\n",
      "Reference: we always wondered what they knew about us .\n",
      "Model: <SOS> it &apos;s the the the the . . .\n",
      "Attention Weights: tensor([[0.0604, 0.0600, 0.1177, 0.1247, 0.1281, 0.1278, 0.1248, 0.1056, 0.1036,\n",
      "         0.0472],\n",
      "        [0.0549, 0.0583, 0.1175, 0.1261, 0.1304, 0.1303, 0.1267, 0.1060, 0.1040,\n",
      "         0.0458],\n",
      "        [0.0582, 0.0620, 0.1157, 0.1236, 0.1276, 0.1275, 0.1244, 0.1062, 0.1045,\n",
      "         0.0504],\n",
      "        [0.0601, 0.0639, 0.1152, 0.1225, 0.1262, 0.1261, 0.1231, 0.1059, 0.1046,\n",
      "         0.0523],\n",
      "        [0.0610, 0.0649, 0.1148, 0.1219, 0.1255, 0.1254, 0.1225, 0.1060, 0.1047,\n",
      "         0.0533],\n",
      "        [0.0614, 0.0652, 0.1148, 0.1217, 0.1252, 0.1251, 0.1222, 0.1060, 0.1046,\n",
      "         0.0536],\n",
      "        [0.0613, 0.0650, 0.1149, 0.1219, 0.1254, 0.1253, 0.1223, 0.1060, 0.1044,\n",
      "         0.0534],\n",
      "        [0.0612, 0.0648, 0.1150, 0.1221, 0.1255, 0.1254, 0.1224, 0.1059, 0.1044,\n",
      "         0.0532],\n",
      "        [0.0613, 0.0648, 0.1151, 0.1221, 0.1256, 0.1254, 0.1224, 0.1059, 0.1043,\n",
      "         0.0532]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 50.00, Train Loss: 3.64, Val Loss: 11.52, Train BLEU: 6.21, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 通过 潜水 潜水艇 拍下 的 影片 把 我们\n",
      "Reference: with vibrant video clips captured by submarines , david\n",
      "Model: <SOS> we of the the the , , , ,\n",
      "Attention Weights: tensor([[1.6623e-03, 2.6991e-06, 8.1963e-02, 1.3666e-01, 8.8234e-02, 1.6226e-01,\n",
      "         1.6426e-01, 1.5832e-01, 1.4142e-01, 6.5220e-02],\n",
      "        [1.8898e-03, 1.3202e-05, 7.8553e-02, 1.3501e-01, 8.6002e-02, 1.6566e-01,\n",
      "         1.6828e-01, 1.6152e-01, 1.4203e-01, 6.1036e-02],\n",
      "        [3.0888e-03, 3.8410e-05, 8.1558e-02, 1.3304e-01, 8.8837e-02, 1.6150e-01,\n",
      "         1.6436e-01, 1.5878e-01, 1.4195e-01, 6.6848e-02],\n",
      "        [3.7950e-03, 5.7011e-05, 8.3618e-02, 1.3283e-01, 9.0744e-02, 1.5909e-01,\n",
      "         1.6186e-01, 1.5679e-01, 1.4140e-01, 6.9812e-02],\n",
      "        [4.0816e-03, 6.1801e-05, 8.4560e-02, 1.3282e-01, 9.1858e-02, 1.5809e-01,\n",
      "         1.6074e-01, 1.5582e-01, 1.4098e-01, 7.0999e-02],\n",
      "        [4.0853e-03, 6.0191e-05, 8.4654e-02, 1.3305e-01, 9.2132e-02, 1.5814e-01,\n",
      "         1.6067e-01, 1.5563e-01, 1.4071e-01, 7.0870e-02],\n",
      "        [4.0486e-03, 5.8943e-05, 8.4616e-02, 1.3321e-01, 9.2035e-02, 1.5831e-01,\n",
      "         1.6079e-01, 1.5566e-01, 1.4064e-01, 7.0634e-02],\n",
      "        [4.0421e-03, 5.8714e-05, 8.4642e-02, 1.3326e-01, 9.2010e-02, 1.5834e-01,\n",
      "         1.6080e-01, 1.5566e-01, 1.4061e-01, 7.0577e-02],\n",
      "        [4.0485e-03, 5.8862e-05, 8.4686e-02, 1.3328e-01, 9.2029e-02, 1.5831e-01,\n",
      "         1.6078e-01, 1.5563e-01, 1.4059e-01, 7.0590e-02]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 出身 阿富汗 边远 <UNK> 地区 有着 与 他人 不同\n",
      "Reference: a total maverick from a remote province of afghanistan\n",
      "Model: <SOS> it of the the the the the , ,\n",
      "Attention Weights: tensor([[9.2171e-02, 1.4348e-01, 1.5110e-01, 1.4770e-01, 8.4722e-02, 1.4466e-01,\n",
      "         1.3775e-01, 9.4971e-02, 3.4483e-03, 4.4530e-12],\n",
      "        [8.5044e-02, 1.4191e-01, 1.5178e-01, 1.4834e-01, 8.6620e-02, 1.4691e-01,\n",
      "         1.3953e-01, 9.5263e-02, 4.6142e-03, 2.4804e-10],\n",
      "        [8.7674e-02, 1.3899e-01, 1.4784e-01, 1.4488e-01, 9.0770e-02, 1.4439e-01,\n",
      "         1.3858e-01, 9.9536e-02, 7.3407e-03, 1.4182e-09],\n",
      "        [8.9385e-02, 1.3809e-01, 1.4623e-01, 1.4339e-01, 9.2284e-02, 1.4329e-01,\n",
      "         1.3798e-01, 1.0087e-01, 8.4865e-03, 2.2958e-09],\n",
      "        [8.9986e-02, 1.3753e-01, 1.4545e-01, 1.4272e-01, 9.3141e-02, 1.4285e-01,\n",
      "         1.3784e-01, 1.0155e-01, 8.9366e-03, 2.2660e-09],\n",
      "        [9.0322e-02, 1.3742e-01, 1.4526e-01, 1.4258e-01, 9.3488e-02, 1.4263e-01,\n",
      "         1.3764e-01, 1.0159e-01, 9.0735e-03, 2.0223e-09],\n",
      "        [9.0211e-02, 1.3764e-01, 1.4551e-01, 1.4277e-01, 9.3182e-02, 1.4281e-01,\n",
      "         1.3769e-01, 1.0130e-01, 8.8937e-03, 1.8633e-09],\n",
      "        [9.0126e-02, 1.3776e-01, 1.4565e-01, 1.4288e-01, 9.2965e-02, 1.4292e-01,\n",
      "         1.3776e-01, 1.0115e-01, 8.7808e-03, 1.8270e-09],\n",
      "        [9.0090e-02, 1.3779e-01, 1.4570e-01, 1.4292e-01, 9.2884e-02, 1.4297e-01,\n",
      "         1.3780e-01, 1.0111e-01, 8.7409e-03, 1.8261e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51.00, Train Loss: 3.62, Val Loss: 11.53, Train BLEU: 6.38, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 但 我 想 告诉 你 的 是 当 你 站\n",
      "Reference: but when you &apos;re standing at the beach ,\n",
      "Model: <SOS> it of the the the the the , ,\n",
      "Attention Weights: tensor([[0.0718, 0.1042, 0.1110, 0.1132, 0.1154, 0.1149, 0.1130, 0.1091, 0.0978,\n",
      "         0.0496],\n",
      "        [0.0662, 0.1031, 0.1118, 0.1147, 0.1174, 0.1168, 0.1148, 0.1104, 0.0976,\n",
      "         0.0472],\n",
      "        [0.0687, 0.1026, 0.1105, 0.1132, 0.1157, 0.1153, 0.1137, 0.1099, 0.0986,\n",
      "         0.0519],\n",
      "        [0.0705, 0.1027, 0.1099, 0.1123, 0.1147, 0.1144, 0.1129, 0.1095, 0.0990,\n",
      "         0.0542],\n",
      "        [0.0713, 0.1026, 0.1095, 0.1119, 0.1142, 0.1139, 0.1126, 0.1093, 0.0993,\n",
      "         0.0554],\n",
      "        [0.0720, 0.1026, 0.1094, 0.1117, 0.1139, 0.1137, 0.1123, 0.1091, 0.0993,\n",
      "         0.0560],\n",
      "        [0.0721, 0.1027, 0.1094, 0.1117, 0.1139, 0.1136, 0.1123, 0.1091, 0.0992,\n",
      "         0.0560],\n",
      "        [0.0722, 0.1027, 0.1094, 0.1117, 0.1140, 0.1137, 0.1123, 0.1090, 0.0991,\n",
      "         0.0559],\n",
      "        [0.0722, 0.1028, 0.1095, 0.1118, 0.1140, 0.1137, 0.1122, 0.1090, 0.0991,\n",
      "         0.0558]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 祖父 在 他 的 年代 是 位非 非凡\n",
      "Reference: my grandfather was an extraordinary man for his time\n",
      "Model: <SOS> it of the the the the , , ,\n",
      "Attention Weights: tensor([[0.0772, 0.1119, 0.1189, 0.1215, 0.1228, 0.1214, 0.1202, 0.1140, 0.0872,\n",
      "         0.0048],\n",
      "        [0.0707, 0.1105, 0.1193, 0.1228, 0.1248, 0.1235, 0.1224, 0.1154, 0.0858,\n",
      "         0.0048],\n",
      "        [0.0734, 0.1098, 0.1179, 0.1211, 0.1230, 0.1221, 0.1213, 0.1154, 0.0890,\n",
      "         0.0071],\n",
      "        [0.0752, 0.1098, 0.1173, 0.1203, 0.1221, 0.1212, 0.1206, 0.1151, 0.0902,\n",
      "         0.0082],\n",
      "        [0.0761, 0.1096, 0.1168, 0.1198, 0.1216, 0.1208, 0.1203, 0.1151, 0.0911,\n",
      "         0.0089],\n",
      "        [0.0767, 0.1096, 0.1167, 0.1196, 0.1213, 0.1206, 0.1200, 0.1150, 0.0913,\n",
      "         0.0092],\n",
      "        [0.0768, 0.1097, 0.1168, 0.1197, 0.1214, 0.1206, 0.1200, 0.1149, 0.0911,\n",
      "         0.0091],\n",
      "        [0.0768, 0.1098, 0.1168, 0.1197, 0.1214, 0.1206, 0.1200, 0.1148, 0.0910,\n",
      "         0.0091],\n",
      "        [0.0769, 0.1098, 0.1168, 0.1197, 0.1214, 0.1206, 0.1200, 0.1148, 0.0910,\n",
      "         0.0091]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 52.00, Train Loss: 3.60, Val Loss: 11.54, Train BLEU: 7.43, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一种 种群 栖 动物 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: it &apos;s a colonial animal . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the the the . . . .\n",
      "Attention Weights: tensor([[1.3046e-01, 1.8465e-01, 1.9083e-01, 1.8968e-01, 1.7986e-01, 1.2082e-01,\n",
      "         3.7058e-03, 5.3981e-12, 5.3981e-12, 5.3981e-12],\n",
      "        [1.2210e-01, 1.8408e-01, 1.9324e-01, 1.9294e-01, 1.8241e-01, 1.2041e-01,\n",
      "         4.8238e-03, 2.8866e-10, 2.8866e-10, 2.8866e-10],\n",
      "        [1.2475e-01, 1.8043e-01, 1.8914e-01, 1.8961e-01, 1.8123e-01, 1.2681e-01,\n",
      "         8.0338e-03, 1.7775e-09, 1.7775e-09, 1.7775e-09],\n",
      "        [1.2682e-01, 1.7909e-01, 1.8720e-01, 1.8784e-01, 1.8033e-01, 1.2908e-01,\n",
      "         9.6378e-03, 3.0487e-09, 3.0487e-09, 3.0487e-09],\n",
      "        [1.2783e-01, 1.7823e-01, 1.8611e-01, 1.8692e-01, 1.7998e-01, 1.3042e-01,\n",
      "         1.0516e-02, 3.0645e-09, 3.0645e-09, 3.0645e-09],\n",
      "        [1.2830e-01, 1.7824e-01, 1.8596e-01, 1.8670e-01, 1.7969e-01, 1.3040e-01,\n",
      "         1.0697e-02, 2.6805e-09, 2.6805e-09, 2.6805e-09],\n",
      "        [1.2828e-01, 1.7846e-01, 1.8614e-01, 1.8681e-01, 1.7971e-01, 1.3006e-01,\n",
      "         1.0542e-02, 2.5305e-09, 2.5305e-09, 2.5305e-09],\n",
      "        [1.2826e-01, 1.7853e-01, 1.8621e-01, 1.8687e-01, 1.7974e-01, 1.2992e-01,\n",
      "         1.0468e-02, 2.5169e-09, 2.5169e-09, 2.5169e-09],\n",
      "        [1.2825e-01, 1.7854e-01, 1.8623e-01, 1.8689e-01, 1.7976e-01, 1.2988e-01,\n",
      "         1.0447e-02, 2.5236e-09, 2.5236e-09, 2.5236e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班 走 了 父亲 大声 叫 着 <EOS> <PAD>\n",
      "Reference: &quot; the taliban are gone ! &quot; my father\n",
      "Model: <SOS> it &apos;s the the the , , , ,\n",
      "Attention Weights: tensor([[0.0671, 0.1060, 0.1133, 0.1150, 0.1164, 0.1163, 0.1144, 0.1099, 0.0972,\n",
      "         0.0444],\n",
      "        [0.0607, 0.1050, 0.1144, 0.1165, 0.1184, 0.1187, 0.1166, 0.1113, 0.0968,\n",
      "         0.0416],\n",
      "        [0.0635, 0.1045, 0.1129, 0.1148, 0.1166, 0.1171, 0.1153, 0.1108, 0.0981,\n",
      "         0.0464],\n",
      "        [0.0656, 0.1045, 0.1122, 0.1139, 0.1155, 0.1160, 0.1145, 0.1103, 0.0985,\n",
      "         0.0489],\n",
      "        [0.0666, 0.1044, 0.1118, 0.1133, 0.1150, 0.1155, 0.1141, 0.1102, 0.0989,\n",
      "         0.0503],\n",
      "        [0.0673, 0.1043, 0.1116, 0.1131, 0.1147, 0.1152, 0.1138, 0.1100, 0.0989,\n",
      "         0.0510],\n",
      "        [0.0676, 0.1044, 0.1115, 0.1131, 0.1147, 0.1151, 0.1137, 0.1099, 0.0988,\n",
      "         0.0511],\n",
      "        [0.0677, 0.1045, 0.1116, 0.1132, 0.1147, 0.1151, 0.1137, 0.1098, 0.0987,\n",
      "         0.0510],\n",
      "        [0.0678, 0.1045, 0.1116, 0.1132, 0.1147, 0.1151, 0.1136, 0.1098, 0.0987,\n",
      "         0.0510]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 53.00, Train Loss: 3.58, Val Loss: 11.55, Train BLEU: 7.15, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里 生物 的 多样 多样性 和 密度 要 比\n",
      "Reference: the biodiversity and the <UNK> in the ocean is\n",
      "Model: <SOS> most of the the the the , , ,\n",
      "Attention Weights: tensor([[0.0658, 0.1080, 0.1140, 0.1183, 0.1174, 0.0965, 0.1175, 0.1118, 0.0998,\n",
      "         0.0507],\n",
      "        [0.0588, 0.1073, 0.1153, 0.1208, 0.1194, 0.0965, 0.1201, 0.1138, 0.1003,\n",
      "         0.0478],\n",
      "        [0.0616, 0.1064, 0.1137, 0.1188, 0.1174, 0.0963, 0.1185, 0.1132, 0.1015,\n",
      "         0.0525],\n",
      "        [0.0638, 0.1062, 0.1128, 0.1175, 0.1162, 0.0965, 0.1174, 0.1126, 0.1018,\n",
      "         0.0551],\n",
      "        [0.0647, 0.1060, 0.1123, 0.1168, 0.1156, 0.0967, 0.1169, 0.1124, 0.1021,\n",
      "         0.0564],\n",
      "        [0.0656, 0.1060, 0.1120, 0.1164, 0.1152, 0.0970, 0.1165, 0.1121, 0.1020,\n",
      "         0.0572],\n",
      "        [0.0660, 0.1060, 0.1120, 0.1163, 0.1152, 0.0971, 0.1163, 0.1119, 0.1018,\n",
      "         0.0573],\n",
      "        [0.0661, 0.1061, 0.1120, 0.1163, 0.1152, 0.0972, 0.1163, 0.1118, 0.1017,\n",
      "         0.0573],\n",
      "        [0.0662, 0.1061, 0.1120, 0.1163, 0.1152, 0.0972, 0.1163, 0.1118, 0.1016,\n",
      "         0.0573]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他们 知道 我们 的 住处 吗 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: do they know where we live ? <EOS> <PAD>\n",
      "Model: <SOS> it &apos;s the the the . . . .\n",
      "Attention Weights: tensor([[1.7978e-09, 1.0225e-09, 9.5184e-10, 2.0914e-09, 1.6267e-05, 1.0997e-01,\n",
      "         2.6390e-01, 2.6835e-01, 2.4339e-01, 1.1438e-01],\n",
      "        [1.5882e-08, 1.0560e-08, 1.0282e-08, 2.0205e-08, 2.1929e-05, 9.6451e-02,\n",
      "         2.6603e-01, 2.7819e-01, 2.5209e-01, 1.0722e-01],\n",
      "        [8.5616e-08, 5.9123e-08, 5.7651e-08, 1.0769e-07, 5.1404e-05, 1.0061e-01,\n",
      "         2.6289e-01, 2.7346e-01, 2.4982e-01, 1.1316e-01],\n",
      "        [1.7926e-07, 1.2554e-07, 1.2224e-07, 2.2275e-07, 8.0084e-05, 1.0377e-01,\n",
      "         2.5926e-01, 2.6977e-01, 2.4856e-01, 1.1856e-01],\n",
      "        [2.3650e-07, 1.6551e-07, 1.6043e-07, 2.8819e-07, 9.4646e-05, 1.0490e-01,\n",
      "         2.5766e-01, 2.6828e-01, 2.4801e-01, 1.2104e-01],\n",
      "        [2.7391e-07, 1.9220e-07, 1.8615e-07, 3.3167e-07, 1.0322e-04, 1.0529e-01,\n",
      "         2.5715e-01, 2.6776e-01, 2.4771e-01, 1.2199e-01],\n",
      "        [2.9573e-07, 2.0773e-07, 2.0125e-07, 3.5786e-07, 1.0872e-04, 1.0552e-01,\n",
      "         2.5692e-01, 2.6747e-01, 2.4751e-01, 1.2247e-01],\n",
      "        [3.0957e-07, 2.1759e-07, 2.1084e-07, 3.7482e-07, 1.1209e-04, 1.0569e-01,\n",
      "         2.5674e-01, 2.6725e-01, 2.4740e-01, 1.2280e-01],\n",
      "        [3.1864e-07, 2.2404e-07, 2.1714e-07, 3.8610e-07, 1.1429e-04, 1.0580e-01,\n",
      "         2.5659e-01, 2.6711e-01, 2.4735e-01, 1.2304e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 54.00, Train Loss: 3.55, Val Loss: 11.56, Train BLEU: 7.15, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 我们 用 的 是 深海 潜水 潜水艇 <UNK> 号 和\n",
      "Reference: we use the submarine alvin and we use cameras\n",
      "Model: <SOS> we of the the the the , , ,\n",
      "Attention Weights: tensor([[1.1373e-01, 1.7591e-01, 1.7856e-01, 1.6771e-01, 1.2517e-01, 3.4742e-02,\n",
      "         1.8418e-04, 7.5885e-06, 1.2676e-01, 7.7217e-02],\n",
      "        [1.0654e-01, 1.8142e-01, 1.8667e-01, 1.7455e-01, 1.2582e-01, 3.2857e-02,\n",
      "         3.2532e-04, 3.0464e-05, 1.2061e-01, 7.1165e-02],\n",
      "        [1.0834e-01, 1.7592e-01, 1.8121e-01, 1.7126e-01, 1.2860e-01, 3.9914e-02,\n",
      "         7.1244e-04, 8.6652e-05, 1.1878e-01, 7.5169e-02],\n",
      "        [1.0999e-01, 1.7267e-01, 1.7750e-01, 1.6867e-01, 1.2942e-01, 4.3498e-02,\n",
      "         1.0141e-03, 1.3817e-04, 1.1904e-01, 7.8050e-02],\n",
      "        [1.1073e-01, 1.7102e-01, 1.7570e-01, 1.6734e-01, 1.2954e-01, 4.5316e-02,\n",
      "         1.1712e-03, 1.6365e-04, 1.1940e-01, 7.9606e-02],\n",
      "        [1.1152e-01, 1.7011e-01, 1.7453e-01, 1.6638e-01, 1.2956e-01, 4.6442e-02,\n",
      "         1.2443e-03, 1.7262e-04, 1.1960e-01, 8.0439e-02],\n",
      "        [1.1170e-01, 1.6981e-01, 1.7410e-01, 1.6599e-01, 1.2958e-01, 4.6795e-02,\n",
      "         1.2604e-03, 1.7311e-04, 1.1986e-01, 8.0736e-02],\n",
      "        [1.1180e-01, 1.6963e-01, 1.7385e-01, 1.6575e-01, 1.2953e-01, 4.6946e-02,\n",
      "         1.2676e-03, 1.7347e-04, 1.2013e-01, 8.0935e-02],\n",
      "        [1.1190e-01, 1.6947e-01, 1.7365e-01, 1.6557e-01, 1.2950e-01, 4.7069e-02,\n",
      "         1.2746e-03, 1.7418e-04, 1.2030e-01, 8.1093e-02]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 她 两年 年前 退休 了 结果 却 把 我家 变成\n",
      "Reference: she retired two years ago , only to turn\n",
      "Model: <SOS> most of the the the the the the ,\n",
      "Attention Weights: tensor([[1.6246e-01, 2.3114e-01, 2.3488e-01, 2.1947e-01, 1.4821e-01, 3.8443e-03,\n",
      "         6.5169e-12, 6.5169e-12, 6.5169e-12, 6.5169e-12],\n",
      "        [1.5186e-01, 2.3229e-01, 2.3963e-01, 2.2399e-01, 1.4740e-01, 4.8444e-03,\n",
      "         3.3804e-10, 3.3804e-10, 3.3804e-10, 3.3804e-10],\n",
      "        [1.5417e-01, 2.2638e-01, 2.3424e-01, 2.2199e-01, 1.5493e-01, 8.2963e-03,\n",
      "         2.1719e-09, 2.1719e-09, 2.1719e-09, 2.1719e-09],\n",
      "        [1.5663e-01, 2.2373e-01, 2.3115e-01, 2.2024e-01, 1.5794e-01, 1.0313e-02,\n",
      "         3.9283e-09, 3.9283e-09, 3.9283e-09, 3.9283e-09],\n",
      "        [1.5769e-01, 2.2242e-01, 2.2977e-01, 2.1954e-01, 1.5929e-01, 1.1298e-02,\n",
      "         3.9064e-09, 3.9064e-09, 3.9064e-09, 3.9064e-09],\n",
      "        [1.5847e-01, 2.2207e-01, 2.2914e-01, 2.1898e-01, 1.5957e-01, 1.1754e-02,\n",
      "         3.5247e-09, 3.5247e-09, 3.5247e-09, 3.5247e-09],\n",
      "        [1.5866e-01, 2.2233e-01, 2.2925e-01, 2.1888e-01, 1.5919e-01, 1.1696e-02,\n",
      "         3.2975e-09, 3.2975e-09, 3.2975e-09, 3.2975e-09],\n",
      "        [1.5871e-01, 2.2246e-01, 2.2933e-01, 2.1888e-01, 1.5899e-01, 1.1629e-02,\n",
      "         3.2690e-09, 3.2690e-09, 3.2690e-09, 3.2690e-09],\n",
      "        [1.5873e-01, 2.2249e-01, 2.2935e-01, 2.1888e-01, 1.5893e-01, 1.1616e-02,\n",
      "         3.2812e-09, 3.2812e-09, 3.2812e-09, 3.2812e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55.00, Train Loss: 3.53, Val Loss: 11.57, Train BLEU: 7.34, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一种 种群 栖 动物 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: it &apos;s a colonial animal . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the the . . . . <EOS>\n",
      "Attention Weights: tensor([[1.3145e-01, 1.8854e-01, 1.9348e-01, 1.9023e-01, 1.7852e-01, 1.1494e-01,\n",
      "         2.8407e-03, 5.1834e-12, 5.1834e-12, 5.1834e-12],\n",
      "        [1.2183e-01, 1.8861e-01, 1.9666e-01, 1.9421e-01, 1.8175e-01, 1.1350e-01,\n",
      "         3.4495e-03, 2.5680e-10, 2.5680e-10, 2.5680e-10],\n",
      "        [1.2417e-01, 1.8437e-01, 1.9240e-01, 1.9116e-01, 1.8115e-01, 1.2072e-01,\n",
      "         6.0194e-03, 1.6961e-09, 1.6961e-09, 1.6961e-09],\n",
      "        [1.2644e-01, 1.8257e-01, 1.9007e-01, 1.8923e-01, 1.8036e-01, 1.2378e-01,\n",
      "         7.5547e-03, 3.1122e-09, 3.1122e-09, 3.1122e-09],\n",
      "        [1.2774e-01, 1.8137e-01, 1.8865e-01, 1.8810e-01, 1.8001e-01, 1.2559e-01,\n",
      "         8.5450e-03, 3.1807e-09, 3.1807e-09, 3.1807e-09],\n",
      "        [1.2853e-01, 1.8127e-01, 1.8831e-01, 1.8766e-01, 1.7954e-01, 1.2580e-01,\n",
      "         8.8968e-03, 2.7875e-09, 2.7875e-09, 2.7875e-09],\n",
      "        [1.2869e-01, 1.8146e-01, 1.8840e-01, 1.8767e-01, 1.7943e-01, 1.2549e-01,\n",
      "         8.8645e-03, 2.6534e-09, 2.6534e-09, 2.6534e-09],\n",
      "        [1.2872e-01, 1.8152e-01, 1.8844e-01, 1.8769e-01, 1.7942e-01, 1.2536e-01,\n",
      "         8.8364e-03, 2.6477e-09, 2.6477e-09, 2.6477e-09],\n",
      "        [1.2873e-01, 1.8154e-01, 1.8846e-01, 1.8770e-01, 1.7942e-01, 1.2533e-01,\n",
      "         8.8300e-03, 2.6529e-09, 2.6529e-09, 2.6529e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在 一个 房屋 房屋里 屋里 我们 100 多 人\n",
      "Reference: the school was in a house , more than\n",
      "Model: <SOS> we of the the the the , , ,\n",
      "Attention Weights: tensor([[0.0525, 0.0613, 0.1198, 0.1255, 0.1273, 0.1247, 0.1218, 0.1173, 0.1034,\n",
      "         0.0463],\n",
      "        [0.0442, 0.0550, 0.1204, 0.1283, 0.1314, 0.1282, 0.1254, 0.1203, 0.1042,\n",
      "         0.0425],\n",
      "        [0.0473, 0.0581, 0.1178, 0.1254, 0.1287, 0.1260, 0.1239, 0.1197, 0.1055,\n",
      "         0.0476],\n",
      "        [0.0500, 0.0604, 0.1167, 0.1237, 0.1268, 0.1243, 0.1225, 0.1190, 0.1059,\n",
      "         0.0506],\n",
      "        [0.0514, 0.0617, 0.1161, 0.1228, 0.1257, 0.1234, 0.1218, 0.1185, 0.1062,\n",
      "         0.0523],\n",
      "        [0.0525, 0.0629, 0.1159, 0.1223, 0.1251, 0.1229, 0.1212, 0.1180, 0.1060,\n",
      "         0.0531],\n",
      "        [0.0529, 0.0632, 0.1160, 0.1223, 0.1250, 0.1228, 0.1211, 0.1177, 0.1057,\n",
      "         0.0532],\n",
      "        [0.0532, 0.0635, 0.1160, 0.1223, 0.1250, 0.1227, 0.1210, 0.1176, 0.1056,\n",
      "         0.0532],\n",
      "        [0.0534, 0.0636, 0.1160, 0.1223, 0.1249, 0.1227, 0.1209, 0.1175, 0.1055,\n",
      "         0.0533]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 56.00, Train Loss: 3.51, Val Loss: 11.59, Train BLEU: 7.58, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的 平均 深度 是 两英里 英里 <EOS> <PAD> <PAD>\n",
      "Reference: the average depth is about two miles . <EOS>\n",
      "Model: <SOS> it &apos;s the the the . . . <EOS>\n",
      "Attention Weights: tensor([[1.0891e-01, 1.7594e-01, 1.8280e-01, 1.8228e-01, 1.7310e-01, 8.3212e-02,\n",
      "         9.1975e-02, 1.7887e-03, 4.7315e-12, 4.7315e-12],\n",
      "        [9.7395e-02, 1.7642e-01, 1.8698e-01, 1.8747e-01, 1.7785e-01, 8.1646e-02,\n",
      "         9.0048e-02, 2.1875e-03, 2.2992e-10, 2.2992e-10],\n",
      "        [9.9817e-02, 1.7177e-01, 1.8208e-01, 1.8290e-01, 1.7470e-01, 8.7728e-02,\n",
      "         9.7021e-02, 3.9885e-03, 1.5433e-09, 1.5433e-09],\n",
      "        [1.0233e-01, 1.6954e-01, 1.7906e-01, 1.7992e-01, 1.7256e-01, 9.1015e-02,\n",
      "         1.0044e-01, 5.1372e-03, 2.8510e-09, 2.8510e-09],\n",
      "        [1.0349e-01, 1.6825e-01, 1.7748e-01, 1.7844e-01, 1.7153e-01, 9.2933e-02,\n",
      "         1.0214e-01, 5.7431e-03, 2.9518e-09, 2.9518e-09],\n",
      "        [1.0466e-01, 1.6760e-01, 1.7650e-01, 1.7742e-01, 1.7068e-01, 9.4158e-02,\n",
      "         1.0284e-01, 6.1459e-03, 2.6409e-09, 2.6409e-09],\n",
      "        [1.0499e-01, 1.6762e-01, 1.7638e-01, 1.7726e-01, 1.7044e-01, 9.4422e-02,\n",
      "         1.0267e-01, 6.2131e-03, 2.4318e-09, 2.4318e-09],\n",
      "        [1.0507e-01, 1.6771e-01, 1.7645e-01, 1.7730e-01, 1.7043e-01, 9.4350e-02,\n",
      "         1.0250e-01, 6.1915e-03, 2.3998e-09, 2.3998e-09],\n",
      "        [1.0509e-01, 1.6774e-01, 1.7647e-01, 1.7732e-01, 1.7043e-01, 9.4320e-02,\n",
      "         1.0245e-01, 6.1843e-03, 2.4033e-09, 2.4033e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在 可以 去 个 真正 的 学校 念书 了\n",
      "Reference: &quot; you can go to a real school now\n",
      "Model: <SOS> we of the the the the , , ,\n",
      "Attention Weights: tensor([[0.0366, 0.0118, 0.0274, 0.0603, 0.1639, 0.1700, 0.1668, 0.1600, 0.1406,\n",
      "         0.0626],\n",
      "        [0.0295, 0.0098, 0.0230, 0.0522, 0.1668, 0.1773, 0.1743, 0.1666, 0.1435,\n",
      "         0.0571],\n",
      "        [0.0336, 0.0128, 0.0272, 0.0557, 0.1602, 0.1713, 0.1696, 0.1634, 0.1433,\n",
      "         0.0629],\n",
      "        [0.0371, 0.0152, 0.0306, 0.0588, 0.1565, 0.1669, 0.1657, 0.1604, 0.1423,\n",
      "         0.0665],\n",
      "        [0.0386, 0.0165, 0.0324, 0.0606, 0.1547, 0.1647, 0.1636, 0.1588, 0.1418,\n",
      "         0.0684],\n",
      "        [0.0398, 0.0173, 0.0336, 0.0622, 0.1541, 0.1633, 0.1621, 0.1574, 0.1409,\n",
      "         0.0693],\n",
      "        [0.0402, 0.0176, 0.0340, 0.0627, 0.1542, 0.1631, 0.1617, 0.1568, 0.1404,\n",
      "         0.0693],\n",
      "        [0.0404, 0.0177, 0.0341, 0.0629, 0.1543, 0.1630, 0.1616, 0.1566, 0.1401,\n",
      "         0.0693],\n",
      "        [0.0405, 0.0177, 0.0343, 0.0631, 0.1543, 0.1629, 0.1614, 0.1564, 0.1400,\n",
      "         0.0694]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 57.00, Train Loss: 3.49, Val Loss: 11.61, Train BLEU: 7.44, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 是 我 最 喜欢 的 因为 它 哪 都 能动\n",
      "Reference: it &apos;s one of my favorites , because it\n",
      "Model: <SOS> it &apos;s the the the , , , ,\n",
      "Attention Weights: tensor([[0.0768, 0.1153, 0.1223, 0.1242, 0.1246, 0.1219, 0.1192, 0.1114, 0.0816,\n",
      "         0.0027],\n",
      "        [0.0682, 0.1144, 0.1237, 0.1262, 0.1273, 0.1244, 0.1218, 0.1128, 0.0788,\n",
      "         0.0024],\n",
      "        [0.0706, 0.1130, 0.1218, 0.1243, 0.1256, 0.1233, 0.1214, 0.1135, 0.0825,\n",
      "         0.0039],\n",
      "        [0.0729, 0.1128, 0.1208, 0.1231, 0.1244, 0.1223, 0.1207, 0.1135, 0.0845,\n",
      "         0.0050],\n",
      "        [0.0740, 0.1124, 0.1201, 0.1224, 0.1236, 0.1218, 0.1204, 0.1137, 0.0858,\n",
      "         0.0057],\n",
      "        [0.0751, 0.1123, 0.1198, 0.1220, 0.1232, 0.1214, 0.1200, 0.1136, 0.0865,\n",
      "         0.0061],\n",
      "        [0.0756, 0.1123, 0.1197, 0.1219, 0.1231, 0.1213, 0.1198, 0.1134, 0.0866,\n",
      "         0.0063],\n",
      "        [0.0759, 0.1124, 0.1197, 0.1219, 0.1230, 0.1213, 0.1198, 0.1133, 0.0866,\n",
      "         0.0063],\n",
      "        [0.0760, 0.1124, 0.1196, 0.1219, 0.1229, 0.1212, 0.1197, 0.1132, 0.0866,\n",
      "         0.0064]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 父亲 在 用 他 的 灰色 小 收音\n",
      "Reference: my father was listening to bbc news on his\n",
      "Model: <SOS> we of the the the the , , ,\n",
      "Attention Weights: tensor([[8.2491e-04, 1.0728e-06, 7.1082e-02, 1.3736e-01, 7.3112e-02, 1.7167e-01,\n",
      "         1.7194e-01, 1.6316e-01, 1.4394e-01, 6.6916e-02],\n",
      "        [7.7057e-04, 4.0171e-06, 6.3165e-02, 1.3421e-01, 6.6068e-02, 1.7780e-01,\n",
      "         1.8020e-01, 1.6994e-01, 1.4743e-01, 6.0410e-02],\n",
      "        [1.3780e-03, 1.3183e-05, 6.6187e-02, 1.3174e-01, 6.9070e-02, 1.7279e-01,\n",
      "         1.7641e-01, 1.6798e-01, 1.4830e-01, 6.6131e-02],\n",
      "        [1.8583e-03, 2.2289e-05, 6.9113e-02, 1.3172e-01, 7.2111e-02, 1.6917e-01,\n",
      "         1.7281e-01, 1.6540e-01, 1.4781e-01, 6.9986e-02],\n",
      "        [2.1232e-03, 2.6136e-05, 7.0774e-02, 1.3183e-01, 7.4275e-02, 1.6730e-01,\n",
      "         1.7073e-01, 1.6370e-01, 1.4715e-01, 7.2081e-02],\n",
      "        [2.2370e-03, 2.6930e-05, 7.1601e-02, 1.3207e-01, 7.5406e-02, 1.6674e-01,\n",
      "         1.6992e-01, 1.6289e-01, 1.4651e-01, 7.2593e-02],\n",
      "        [2.2928e-03, 2.7515e-05, 7.1939e-02, 1.3219e-01, 7.5753e-02, 1.6659e-01,\n",
      "         1.6968e-01, 1.6259e-01, 1.4622e-01, 7.2720e-02],\n",
      "        [2.3329e-03, 2.8115e-05, 7.2185e-02, 1.3226e-01, 7.5951e-02, 1.6646e-01,\n",
      "         1.6949e-01, 1.6239e-01, 1.4606e-01, 7.2836e-02],\n",
      "        [2.3627e-03, 2.8618e-05, 7.2354e-02, 1.3229e-01, 7.6091e-02, 1.6634e-01,\n",
      "         1.6935e-01, 1.6226e-01, 1.4597e-01, 7.2955e-02]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 58.00, Train Loss: 3.46, Val Loss: 11.62, Train BLEU: 7.44, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 这位 是 比尔 <UNK> 我 是 大卫 <UNK>\n",
      "Reference: this is bill lange . i &apos;m dave gallo\n",
      "Model: <SOS> this is the . . . . . .\n",
      "Attention Weights: tensor([[4.7666e-03, 3.2789e-06, 1.1281e-01, 1.0072e-01, 6.7004e-04, 1.6017e-05,\n",
      "         4.4514e-01, 3.1557e-01, 2.0305e-02, 6.3265e-07],\n",
      "        [4.4753e-03, 9.4792e-06, 1.0058e-01, 9.9822e-02, 8.1263e-04, 3.3749e-05,\n",
      "         4.4946e-01, 3.2670e-01, 1.8095e-02, 2.3075e-06],\n",
      "        [7.2272e-03, 3.8688e-05, 1.0984e-01, 1.1192e-01, 1.7556e-03, 1.1567e-04,\n",
      "         4.2128e-01, 3.2288e-01, 2.4935e-02, 1.1509e-05],\n",
      "        [8.8701e-03, 6.1752e-05, 1.1626e-01, 1.1899e-01, 2.3933e-03, 1.7794e-04,\n",
      "         4.0623e-01, 3.1810e-01, 2.8890e-02, 1.9048e-05],\n",
      "        [9.7748e-03, 7.1255e-05, 1.1944e-01, 1.2241e-01, 2.6919e-03, 2.0467e-04,\n",
      "         3.9895e-01, 3.1526e-01, 3.1181e-02, 2.2673e-05],\n",
      "        [1.0099e-02, 7.4776e-05, 1.2050e-01, 1.2383e-01, 2.7964e-03, 2.1522e-04,\n",
      "         3.9586e-01, 3.1448e-01, 3.2117e-02, 2.3897e-05],\n",
      "        [1.0241e-02, 7.7430e-05, 1.2083e-01, 1.2438e-01, 2.8490e-03, 2.2213e-04,\n",
      "         3.9465e-01, 3.1425e-01, 3.2479e-02, 2.4768e-05],\n",
      "        [1.0298e-02, 7.8998e-05, 1.2091e-01, 1.2456e-01, 2.8743e-03, 2.2597e-04,\n",
      "         3.9423e-01, 3.1420e-01, 3.2605e-02, 2.5298e-05],\n",
      "        [1.0325e-02, 7.9979e-05, 1.2092e-01, 1.2461e-01, 2.8883e-03, 2.2829e-04,\n",
      "         3.9407e-01, 3.1420e-01, 3.2654e-02, 2.5649e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 不知 知道 那 意味 意味着 什么 但是 我 能\n",
      "Reference: i didn &apos;t know what it meant , but\n",
      "Model: <SOS> we of the the the the the , ,\n",
      "Attention Weights: tensor([[0.0810, 0.1340, 0.1424, 0.1435, 0.1428, 0.1386, 0.1134, 0.0270, 0.0367,\n",
      "         0.0407],\n",
      "        [0.0724, 0.1369, 0.1484, 0.1495, 0.1490, 0.1438, 0.1125, 0.0226, 0.0299,\n",
      "         0.0350],\n",
      "        [0.0753, 0.1346, 0.1450, 0.1460, 0.1456, 0.1411, 0.1128, 0.0265, 0.0336,\n",
      "         0.0395],\n",
      "        [0.0778, 0.1330, 0.1422, 0.1430, 0.1427, 0.1388, 0.1129, 0.0298, 0.0368,\n",
      "         0.0430],\n",
      "        [0.0784, 0.1323, 0.1412, 0.1420, 0.1417, 0.1380, 0.1129, 0.0311, 0.0381,\n",
      "         0.0442],\n",
      "        [0.0791, 0.1317, 0.1405, 0.1413, 0.1410, 0.1374, 0.1128, 0.0320, 0.0390,\n",
      "         0.0451],\n",
      "        [0.0799, 0.1312, 0.1397, 0.1405, 0.1402, 0.1367, 0.1128, 0.0330, 0.0401,\n",
      "         0.0460],\n",
      "        [0.0803, 0.1309, 0.1393, 0.1401, 0.1398, 0.1362, 0.1127, 0.0335, 0.0406,\n",
      "         0.0466],\n",
      "        [0.0805, 0.1307, 0.1391, 0.1399, 0.1395, 0.1359, 0.1127, 0.0337, 0.0410,\n",
      "         0.0469]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59.00, Train Loss: 3.44, Val Loss: 11.64, Train BLEU: 7.44, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里 生物 的 多样 多样性 和 密度 要 比\n",
      "Reference: the biodiversity and the <UNK> in the ocean is\n",
      "Model: <SOS> we of the the the the the , ,\n",
      "Attention Weights: tensor([[0.0652, 0.1113, 0.1173, 0.1212, 0.1195, 0.0929, 0.1172, 0.1097, 0.0965,\n",
      "         0.0492],\n",
      "        [0.0563, 0.1109, 0.1194, 0.1250, 0.1225, 0.0916, 0.1207, 0.1122, 0.0971,\n",
      "         0.0445],\n",
      "        [0.0591, 0.1097, 0.1174, 0.1227, 0.1203, 0.0916, 0.1192, 0.1121, 0.0987,\n",
      "         0.0492],\n",
      "        [0.0618, 0.1091, 0.1159, 0.1208, 0.1186, 0.0922, 0.1179, 0.1116, 0.0995,\n",
      "         0.0526],\n",
      "        [0.0629, 0.1086, 0.1152, 0.1199, 0.1178, 0.0927, 0.1173, 0.1114, 0.0999,\n",
      "         0.0542],\n",
      "        [0.0640, 0.1084, 0.1148, 0.1193, 0.1174, 0.0933, 0.1167, 0.1110, 0.0999,\n",
      "         0.0553],\n",
      "        [0.0646, 0.1084, 0.1147, 0.1190, 0.1172, 0.0936, 0.1164, 0.1107, 0.0997,\n",
      "         0.0557],\n",
      "        [0.0649, 0.1084, 0.1146, 0.1189, 0.1171, 0.0937, 0.1164, 0.1106, 0.0996,\n",
      "         0.0558],\n",
      "        [0.0652, 0.1084, 0.1146, 0.1188, 0.1170, 0.0938, 0.1163, 0.1105, 0.0995,\n",
      "         0.0559]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 总是 担心 会 被 塔利 塔利班 发现 <EOS> <PAD>\n",
      "Reference: we always wondered what they knew about us .\n",
      "Model: <SOS> it &apos;s the the the . . . <EOS>\n",
      "Attention Weights: tensor([[0.0579, 0.0504, 0.1236, 0.1307, 0.1330, 0.1314, 0.1269, 0.1008, 0.1000,\n",
      "         0.0454],\n",
      "        [0.0503, 0.0452, 0.1245, 0.1346, 0.1385, 0.1366, 0.1307, 0.0990, 0.0998,\n",
      "         0.0407],\n",
      "        [0.0538, 0.0494, 0.1215, 0.1312, 0.1351, 0.1336, 0.1285, 0.1001, 0.1011,\n",
      "         0.0456],\n",
      "        [0.0570, 0.0528, 0.1200, 0.1288, 0.1324, 0.1310, 0.1264, 0.1005, 0.1018,\n",
      "         0.0492],\n",
      "        [0.0583, 0.0546, 0.1192, 0.1276, 0.1310, 0.1297, 0.1255, 0.1010, 0.1021,\n",
      "         0.0509],\n",
      "        [0.0594, 0.0557, 0.1189, 0.1269, 0.1302, 0.1289, 0.1248, 0.1013, 0.1021,\n",
      "         0.0519],\n",
      "        [0.0598, 0.0560, 0.1189, 0.1267, 0.1299, 0.1287, 0.1246, 0.1014, 0.1020,\n",
      "         0.0522],\n",
      "        [0.0600, 0.0561, 0.1189, 0.1266, 0.1297, 0.1285, 0.1245, 0.1013, 0.1019,\n",
      "         0.0524],\n",
      "        [0.0602, 0.0563, 0.1188, 0.1266, 0.1296, 0.1284, 0.1244, 0.1014, 0.1018,\n",
      "         0.0525]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 60.00, Train Loss: 3.42, Val Loss: 11.65, Train BLEU: 7.32, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分 部分 的 动物 也 都 生活 在 海洋\n",
      "Reference: most of the animals are in the oceans .\n",
      "Model: <SOS> we of the the the the the , ,\n",
      "Attention Weights: tensor([[0.0619, 0.1047, 0.1159, 0.1196, 0.1187, 0.1183, 0.1149, 0.1083, 0.0947,\n",
      "         0.0429],\n",
      "        [0.0524, 0.1018, 0.1173, 0.1233, 0.1220, 0.1225, 0.1184, 0.1101, 0.0945,\n",
      "         0.0377],\n",
      "        [0.0552, 0.1007, 0.1154, 0.1212, 0.1202, 0.1210, 0.1176, 0.1101, 0.0962,\n",
      "         0.0424],\n",
      "        [0.0579, 0.1008, 0.1142, 0.1196, 0.1186, 0.1195, 0.1165, 0.1098, 0.0971,\n",
      "         0.0458],\n",
      "        [0.0593, 0.1008, 0.1136, 0.1187, 0.1178, 0.1187, 0.1159, 0.1097, 0.0977,\n",
      "         0.0478],\n",
      "        [0.0605, 0.1010, 0.1133, 0.1181, 0.1173, 0.1182, 0.1155, 0.1094, 0.0978,\n",
      "         0.0489],\n",
      "        [0.0611, 0.1011, 0.1132, 0.1179, 0.1171, 0.1179, 0.1152, 0.1092, 0.0978,\n",
      "         0.0494],\n",
      "        [0.0615, 0.1012, 0.1132, 0.1179, 0.1171, 0.1178, 0.1151, 0.1091, 0.0977,\n",
      "         0.0496],\n",
      "        [0.0617, 0.1013, 0.1132, 0.1178, 0.1170, 0.1177, 0.1150, 0.1090, 0.0976,\n",
      "         0.0497]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 那 就是 她 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: there she is . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the the the . . . <EOS>\n",
      "Attention Weights: tensor([[8.5943e-02, 1.3838e-01, 1.4576e-01, 1.4561e-01, 1.4154e-01, 1.3377e-01,\n",
      "         1.2315e-01, 8.4296e-02, 1.5494e-03, 3.6008e-12],\n",
      "        [7.5638e-02, 1.3707e-01, 1.4800e-01, 1.4883e-01, 1.4470e-01, 1.3642e-01,\n",
      "         1.2498e-01, 8.2587e-02, 1.7645e-03, 1.6495e-10],\n",
      "        [7.8154e-02, 1.3422e-01, 1.4483e-01, 1.4614e-01, 1.4293e-01, 1.3597e-01,\n",
      "         1.2622e-01, 8.8198e-02, 3.3359e-03, 1.1735e-09],\n",
      "        [8.0871e-02, 1.3299e-01, 1.4282e-01, 1.4416e-01, 1.4141e-01, 1.3522e-01,\n",
      "         1.2660e-01, 9.1383e-02, 4.5497e-03, 2.3843e-09],\n",
      "        [8.2155e-02, 1.3227e-01, 1.4177e-01, 1.4317e-01, 1.4068e-01, 1.3491e-01,\n",
      "         1.2693e-01, 9.2935e-02, 5.1802e-03, 2.5592e-09],\n",
      "        [8.3427e-02, 1.3202e-01, 1.4118e-01, 1.4253e-01, 1.4014e-01, 1.3454e-01,\n",
      "         1.2683e-01, 9.3703e-02, 5.6300e-03, 2.3336e-09],\n",
      "        [8.3805e-02, 1.3210e-01, 1.4116e-01, 1.4245e-01, 1.4002e-01, 1.3441e-01,\n",
      "         1.2665e-01, 9.3661e-02, 5.7486e-03, 2.1375e-09],\n",
      "        [8.3835e-02, 1.3215e-01, 1.4121e-01, 1.4248e-01, 1.4004e-01, 1.3440e-01,\n",
      "         1.2662e-01, 9.3529e-02, 5.7367e-03, 2.1040e-09],\n",
      "        [8.3825e-02, 1.3215e-01, 1.4123e-01, 1.4250e-01, 1.4006e-01, 1.3441e-01,\n",
      "         1.2661e-01, 9.3481e-02, 5.7284e-03, 2.1062e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 61.00, Train Loss: 3.40, Val Loss: 11.66, Train BLEU: 7.78, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 原来 它 是 海洋 洋中 最长 的 生物 <EOS> <PAD>\n",
      "Reference: this turns out to be the longest creature in\n",
      "Model: <SOS> it &apos;s the the the . . . <EOS>\n",
      "Attention Weights: tensor([[9.8152e-02, 1.6042e-01, 1.6631e-01, 1.5570e-01, 5.7486e-02, 1.4507e-01,\n",
      "         1.3344e-01, 8.1995e-02, 1.4357e-03, 3.9067e-12],\n",
      "        [8.7412e-02, 1.6127e-01, 1.7095e-01, 1.5959e-01, 5.3866e-02, 1.4785e-01,\n",
      "         1.3633e-01, 8.1033e-02, 1.7030e-03, 1.8297e-10],\n",
      "        [8.9491e-02, 1.5597e-01, 1.6516e-01, 1.5533e-01, 6.0024e-02, 1.4552e-01,\n",
      "         1.3703e-01, 8.8139e-02, 3.3316e-03, 1.3175e-09],\n",
      "        [9.1818e-02, 1.5285e-01, 1.6116e-01, 1.5222e-01, 6.4411e-02, 1.4411e-01,\n",
      "         1.3691e-01, 9.1905e-02, 4.6165e-03, 2.6933e-09],\n",
      "        [9.2817e-02, 1.5116e-01, 1.5914e-01, 1.5073e-01, 6.6963e-02, 1.4339e-01,\n",
      "         1.3691e-01, 9.3609e-02, 5.2810e-03, 2.9554e-09],\n",
      "        [9.3974e-02, 1.5031e-01, 1.5799e-01, 1.4993e-01, 6.8520e-02, 1.4277e-01,\n",
      "         1.3650e-01, 9.4273e-02, 5.7300e-03, 2.7144e-09],\n",
      "        [9.4347e-02, 1.5015e-01, 1.5769e-01, 1.4974e-01, 6.8976e-02, 1.4277e-01,\n",
      "         1.3630e-01, 9.4163e-02, 5.8647e-03, 2.4638e-09],\n",
      "        [9.4394e-02, 1.5021e-01, 1.5773e-01, 1.4976e-01, 6.8843e-02, 1.4289e-01,\n",
      "         1.3635e-01, 9.3972e-02, 5.8500e-03, 2.4185e-09],\n",
      "        [9.4406e-02, 1.5023e-01, 1.5776e-01, 1.4977e-01, 6.8763e-02, 1.4293e-01,\n",
      "         1.3638e-01, 9.3913e-02, 5.8441e-03, 2.4217e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 出身 阿富汗 边远 <UNK> 地区 有着 与 他人 不同\n",
      "Reference: a total maverick from a remote province of afghanistan\n",
      "Model: <SOS> we of the the the the the , ,\n",
      "Attention Weights: tensor([[9.8152e-02, 1.6042e-01, 1.6631e-01, 1.5570e-01, 5.7486e-02, 1.4507e-01,\n",
      "         1.3344e-01, 8.1995e-02, 1.4357e-03, 3.9067e-12],\n",
      "        [8.7412e-02, 1.6127e-01, 1.7095e-01, 1.5959e-01, 5.3866e-02, 1.4785e-01,\n",
      "         1.3633e-01, 8.1033e-02, 1.7030e-03, 1.8297e-10],\n",
      "        [8.9491e-02, 1.5597e-01, 1.6516e-01, 1.5533e-01, 6.0024e-02, 1.4552e-01,\n",
      "         1.3703e-01, 8.8139e-02, 3.3316e-03, 1.3175e-09],\n",
      "        [9.1818e-02, 1.5285e-01, 1.6116e-01, 1.5222e-01, 6.4411e-02, 1.4411e-01,\n",
      "         1.3691e-01, 9.1905e-02, 4.6165e-03, 2.6933e-09],\n",
      "        [9.2817e-02, 1.5116e-01, 1.5914e-01, 1.5073e-01, 6.6963e-02, 1.4339e-01,\n",
      "         1.3691e-01, 9.3609e-02, 5.2810e-03, 2.9554e-09],\n",
      "        [9.3974e-02, 1.5031e-01, 1.5799e-01, 1.4993e-01, 6.8520e-02, 1.4277e-01,\n",
      "         1.3650e-01, 9.4273e-02, 5.7300e-03, 2.7144e-09],\n",
      "        [9.4347e-02, 1.5015e-01, 1.5769e-01, 1.4974e-01, 6.8976e-02, 1.4277e-01,\n",
      "         1.3630e-01, 9.4163e-02, 5.8647e-03, 2.4638e-09],\n",
      "        [9.4394e-02, 1.5021e-01, 1.5773e-01, 1.4976e-01, 6.8843e-02, 1.4289e-01,\n",
      "         1.3635e-01, 9.3972e-02, 5.8500e-03, 2.4185e-09],\n",
      "        [9.4406e-02, 1.5023e-01, 1.5776e-01, 1.4977e-01, 6.8763e-02, 1.4293e-01,\n",
      "         1.3638e-01, 9.3913e-02, 5.8441e-03, 2.4217e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 62.00, Train Loss: 3.37, Val Loss: 11.67, Train BLEU: 8.74, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: <UNK> 塞尔 <UNK> <UNK> 斯特 说 过 真正 的 探索\n",
      "Reference: marcel proust said , &quot; the true voyage of\n",
      "Model: <SOS> marcel proust said , , , , , ,\n",
      "Attention Weights: tensor([[1.2918e-09, 7.8292e-10, 8.0859e-10, 1.9073e-09, 6.6359e-06, 8.6435e-02,\n",
      "         2.6815e-01, 2.7748e-01, 2.4758e-01, 1.2036e-01],\n",
      "        [9.3448e-09, 6.4318e-09, 6.7205e-09, 1.3841e-08, 9.0941e-06, 7.1565e-02,\n",
      "         2.6649e-01, 2.8899e-01, 2.5905e-01, 1.1390e-01],\n",
      "        [6.1735e-08, 4.4160e-08, 4.5951e-08, 8.9078e-08, 2.5712e-05, 7.4923e-02,\n",
      "         2.6219e-01, 2.8464e-01, 2.5831e-01, 1.1991e-01],\n",
      "        [1.4685e-07, 1.0638e-07, 1.1054e-07, 2.1001e-07, 4.6621e-05, 7.9709e-02,\n",
      "         2.5713e-01, 2.7947e-01, 2.5686e-01, 1.2677e-01],\n",
      "        [2.0325e-07, 1.4718e-07, 1.5235e-07, 2.8572e-07, 5.7818e-05, 8.1166e-02,\n",
      "         2.5511e-01, 2.7733e-01, 2.5616e-01, 1.3017e-01],\n",
      "        [2.3844e-07, 1.7332e-07, 1.7943e-07, 3.3410e-07, 6.3593e-05, 8.1664e-02,\n",
      "         2.5443e-01, 2.7666e-01, 2.5586e-01, 1.3131e-01],\n",
      "        [2.5619e-07, 1.8659e-07, 1.9335e-07, 3.5947e-07, 6.6629e-05, 8.1791e-02,\n",
      "         2.5417e-01, 2.7644e-01, 2.5576e-01, 1.3177e-01],\n",
      "        [2.6852e-07, 1.9587e-07, 2.0305e-07, 3.7721e-07, 6.8626e-05, 8.1776e-02,\n",
      "         2.5402e-01, 2.7632e-01, 2.5575e-01, 1.3207e-01],\n",
      "        [2.7775e-07, 2.0281e-07, 2.1031e-07, 3.9053e-07, 7.0117e-05, 8.1776e-02,\n",
      "         2.5390e-01, 2.7622e-01, 2.5573e-01, 1.3230e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 很 害怕 但是 我们 仍然 渴望 望去 学校 <EOS>\n",
      "Reference: we were scared , but still , school was\n",
      "Model: <SOS> it &apos;s the the the . . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0694, 0.1075, 0.1144, 0.1178, 0.1173, 0.1167, 0.1121, 0.1053, 0.0924,\n",
      "         0.0470],\n",
      "        [0.0605, 0.1060, 0.1153, 0.1208, 0.1206, 0.1205, 0.1150, 0.1070, 0.0921,\n",
      "         0.0421],\n",
      "        [0.0632, 0.1048, 0.1134, 0.1187, 0.1186, 0.1188, 0.1141, 0.1071, 0.0940,\n",
      "         0.0472],\n",
      "        [0.0658, 0.1045, 0.1122, 0.1171, 0.1171, 0.1174, 0.1131, 0.1069, 0.0951,\n",
      "         0.0508],\n",
      "        [0.0670, 0.1042, 0.1116, 0.1163, 0.1163, 0.1166, 0.1127, 0.1069, 0.0957,\n",
      "         0.0527],\n",
      "        [0.0681, 0.1042, 0.1113, 0.1158, 0.1158, 0.1161, 0.1123, 0.1067, 0.0959,\n",
      "         0.0539],\n",
      "        [0.0685, 0.1042, 0.1112, 0.1156, 0.1156, 0.1158, 0.1121, 0.1066, 0.0960,\n",
      "         0.0544],\n",
      "        [0.0689, 0.1042, 0.1112, 0.1155, 0.1155, 0.1157, 0.1120, 0.1065, 0.0959,\n",
      "         0.0546],\n",
      "        [0.0692, 0.1042, 0.1112, 0.1154, 0.1154, 0.1156, 0.1119, 0.1064, 0.0958,\n",
      "         0.0548]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63.00, Train Loss: 3.35, Val Loss: 11.68, Train BLEU: 8.81, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 是 我 最 喜欢 的 因为 它 哪 都 能动\n",
      "Reference: it &apos;s one of my favorites , because it\n",
      "Model: <SOS> it &apos;s the the the , , , ,\n",
      "Attention Weights: tensor([[0.0764, 0.1183, 0.1255, 0.1271, 0.1263, 0.1226, 0.1176, 0.1078, 0.0769,\n",
      "         0.0015],\n",
      "        [0.0665, 0.1172, 0.1272, 0.1296, 0.1296, 0.1255, 0.1203, 0.1089, 0.0738,\n",
      "         0.0014],\n",
      "        [0.0689, 0.1152, 0.1248, 0.1273, 0.1277, 0.1244, 0.1203, 0.1103, 0.0786,\n",
      "         0.0027],\n",
      "        [0.0716, 0.1146, 0.1234, 0.1257, 0.1262, 0.1232, 0.1196, 0.1106, 0.0813,\n",
      "         0.0038],\n",
      "        [0.0729, 0.1141, 0.1225, 0.1248, 0.1253, 0.1226, 0.1194, 0.1110, 0.0829,\n",
      "         0.0044],\n",
      "        [0.0743, 0.1139, 0.1220, 0.1242, 0.1247, 0.1222, 0.1191, 0.1110, 0.0838,\n",
      "         0.0049],\n",
      "        [0.0750, 0.1139, 0.1219, 0.1241, 0.1245, 0.1220, 0.1188, 0.1108, 0.0840,\n",
      "         0.0050],\n",
      "        [0.0752, 0.1139, 0.1218, 0.1240, 0.1244, 0.1219, 0.1187, 0.1107, 0.0840,\n",
      "         0.0051],\n",
      "        [0.0754, 0.1139, 0.1218, 0.1240, 0.1244, 0.1219, 0.1187, 0.1107, 0.0840,\n",
      "         0.0052]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正 的 学校 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: a real school . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the the the . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0654, 0.1157, 0.1247, 0.1291, 0.1293, 0.1256, 0.1208, 0.1096, 0.0779,\n",
      "         0.0020],\n",
      "        [0.0568, 0.1129, 0.1251, 0.1322, 0.1327, 0.1277, 0.1234, 0.1110, 0.0763,\n",
      "         0.0019],\n",
      "        [0.0606, 0.1117, 0.1229, 0.1296, 0.1302, 0.1259, 0.1226, 0.1121, 0.0810,\n",
      "         0.0034],\n",
      "        [0.0638, 0.1116, 0.1218, 0.1279, 0.1285, 0.1246, 0.1217, 0.1122, 0.0835,\n",
      "         0.0045],\n",
      "        [0.0649, 0.1115, 0.1213, 0.1272, 0.1278, 0.1241, 0.1214, 0.1123, 0.0845,\n",
      "         0.0050],\n",
      "        [0.0661, 0.1115, 0.1210, 0.1267, 0.1273, 0.1238, 0.1210, 0.1122, 0.0852,\n",
      "         0.0053],\n",
      "        [0.0666, 0.1115, 0.1209, 0.1264, 0.1270, 0.1236, 0.1209, 0.1121, 0.0854,\n",
      "         0.0055],\n",
      "        [0.0670, 0.1115, 0.1209, 0.1263, 0.1269, 0.1236, 0.1208, 0.1120, 0.0855,\n",
      "         0.0056],\n",
      "        [0.0673, 0.1115, 0.1209, 0.1262, 0.1268, 0.1235, 0.1207, 0.1120, 0.0855,\n",
      "         0.0056]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 64.00, Train Loss: 3.33, Val Loss: 11.69, Train BLEU: 8.82, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的 平均 深度 是 两英里 英里 <EOS> <PAD> <PAD>\n",
      "Reference: the average depth is about two miles . <EOS>\n",
      "Model: <SOS> it &apos;s the the the . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.1238e-01, 1.8574e-01, 1.9139e-01, 1.8789e-01, 1.7573e-01, 6.3482e-02,\n",
      "         8.2372e-02, 1.0163e-03, 4.6078e-12, 4.6078e-12],\n",
      "        [9.8261e-02, 1.8541e-01, 1.9637e-01, 1.9412e-01, 1.8159e-01, 6.1878e-02,\n",
      "         8.1007e-02, 1.3607e-03, 2.2058e-10, 2.2058e-10],\n",
      "        [1.0063e-01, 1.7868e-01, 1.8969e-01, 1.8835e-01, 1.7794e-01, 7.0831e-02,\n",
      "         9.0873e-02, 3.0114e-03, 1.6754e-09, 1.6754e-09],\n",
      "        [1.0385e-01, 1.7480e-01, 1.8489e-01, 1.8383e-01, 1.7472e-01, 7.6959e-02,\n",
      "         9.6448e-02, 4.5088e-03, 3.6563e-09, 3.6563e-09],\n",
      "        [1.0537e-01, 1.7282e-01, 1.8247e-01, 1.8168e-01, 1.7335e-01, 8.0081e-02,\n",
      "         9.8961e-02, 5.2762e-03, 4.0323e-09, 4.0323e-09],\n",
      "        [1.0683e-01, 1.7180e-01, 1.8109e-01, 1.8036e-01, 1.7237e-01, 8.1882e-02,\n",
      "         9.9941e-02, 5.7336e-03, 3.7329e-09, 3.7329e-09],\n",
      "        [1.0736e-01, 1.7178e-01, 1.8089e-01, 1.8010e-01, 1.7206e-01, 8.2265e-02,\n",
      "         9.9747e-02, 5.7945e-03, 3.3598e-09, 3.3598e-09],\n",
      "        [1.0751e-01, 1.7193e-01, 1.8101e-01, 1.8018e-01, 1.7204e-01, 8.2111e-02,\n",
      "         9.9460e-02, 5.7596e-03, 3.3171e-09, 3.3171e-09],\n",
      "        [1.0757e-01, 1.7196e-01, 1.8105e-01, 1.8021e-01, 1.7203e-01, 8.2048e-02,\n",
      "         9.9375e-02, 5.7544e-03, 3.3403e-09, 3.3403e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6 岁 那年 塔利 塔利班 占领 阿富汗 并 规定\n",
      "Reference: you see , i was six when the taliban\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[8.6394e-02, 1.4432e-01, 1.4898e-01, 1.4623e-01, 1.4194e-01, 1.3490e-01,\n",
      "         1.2116e-01, 7.4945e-02, 1.1334e-03, 3.5968e-12],\n",
      "        [7.4343e-02, 1.4235e-01, 1.5079e-01, 1.4915e-01, 1.4554e-01, 1.3839e-01,\n",
      "         1.2386e-01, 7.4152e-02, 1.4290e-03, 1.6523e-10],\n",
      "        [7.6716e-02, 1.3795e-01, 1.4644e-01, 1.4589e-01, 1.4356e-01, 1.3803e-01,\n",
      "         1.2606e-01, 8.2306e-02, 3.0455e-03, 1.2787e-09],\n",
      "        [7.9917e-02, 1.3600e-01, 1.4385e-01, 1.4360e-01, 1.4178e-01, 1.3711e-01,\n",
      "         1.2657e-01, 8.6691e-02, 4.4841e-03, 2.8072e-09],\n",
      "        [8.1806e-02, 1.3490e-01, 1.4236e-01, 1.4229e-01, 1.4081e-01, 1.3666e-01,\n",
      "         1.2694e-01, 8.8902e-02, 5.3309e-03, 3.1233e-09],\n",
      "        [8.3167e-02, 1.3462e-01, 1.4181e-01, 1.4177e-01, 1.4028e-01, 1.3626e-01,\n",
      "         1.2676e-01, 8.9570e-02, 5.7630e-03, 2.8627e-09],\n",
      "        [8.3566e-02, 1.3481e-01, 1.4191e-01, 1.4181e-01, 1.4025e-01, 1.3615e-01,\n",
      "         1.2653e-01, 8.9190e-02, 5.7741e-03, 2.6286e-09],\n",
      "        [8.3635e-02, 1.3489e-01, 1.4197e-01, 1.4186e-01, 1.4029e-01, 1.3617e-01,\n",
      "         1.2648e-01, 8.8955e-02, 5.7433e-03, 2.6117e-09],\n",
      "        [8.3664e-02, 1.3490e-01, 1.4197e-01, 1.4187e-01, 1.4030e-01, 1.3618e-01,\n",
      "         1.2649e-01, 8.8892e-02, 5.7400e-03, 2.6306e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 65.00, Train Loss: 3.30, Val Loss: 11.70, Train BLEU: 8.82, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 其实 它们 都 是 由 单独 的 动物 结合 合在\n",
      "Reference: these are all individual animals banding together to make\n",
      "Model: <SOS> and &apos;s the the , , , , ,\n",
      "Attention Weights: tensor([[0.0751, 0.1282, 0.1370, 0.1380, 0.1355, 0.1295, 0.1195, 0.0999, 0.0373,\n",
      "         0.0000],\n",
      "        [0.0654, 0.1251, 0.1385, 0.1407, 0.1387, 0.1321, 0.1224, 0.1013, 0.0356,\n",
      "         0.0000],\n",
      "        [0.0685, 0.1224, 0.1350, 0.1375, 0.1362, 0.1309, 0.1229, 0.1042, 0.0425,\n",
      "         0.0001],\n",
      "        [0.0711, 0.1216, 0.1333, 0.1357, 0.1347, 0.1299, 0.1227, 0.1051, 0.0457,\n",
      "         0.0002],\n",
      "        [0.0724, 0.1212, 0.1324, 0.1348, 0.1339, 0.1294, 0.1225, 0.1057, 0.0476,\n",
      "         0.0002],\n",
      "        [0.0738, 0.1211, 0.1318, 0.1341, 0.1333, 0.1289, 0.1222, 0.1058, 0.0488,\n",
      "         0.0002],\n",
      "        [0.0744, 0.1211, 0.1316, 0.1339, 0.1331, 0.1288, 0.1220, 0.1057, 0.0492,\n",
      "         0.0002],\n",
      "        [0.0748, 0.1212, 0.1316, 0.1339, 0.1330, 0.1286, 0.1218, 0.1056, 0.0494,\n",
      "         0.0002],\n",
      "        [0.0750, 0.1212, 0.1315, 0.1338, 0.1329, 0.1285, 0.1217, 0.1056, 0.0495,\n",
      "         0.0002]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在 可以 去 个 真正 的 学校 念书 了\n",
      "Reference: &quot; you can go to a real school now\n",
      "Model: <SOS> we of the the the the the , ,\n",
      "Attention Weights: tensor([[0.0232, 0.0036, 0.0134, 0.0498, 0.1798, 0.1831, 0.1756, 0.1653, 0.1422,\n",
      "         0.0640],\n",
      "        [0.0191, 0.0032, 0.0112, 0.0410, 0.1785, 0.1895, 0.1829, 0.1715, 0.1447,\n",
      "         0.0585],\n",
      "        [0.0251, 0.0055, 0.0157, 0.0462, 0.1686, 0.1810, 0.1771, 0.1684, 0.1458,\n",
      "         0.0667],\n",
      "        [0.0296, 0.0075, 0.0194, 0.0504, 0.1634, 0.1751, 0.1724, 0.1651, 0.1453,\n",
      "         0.0718],\n",
      "        [0.0317, 0.0085, 0.0213, 0.0526, 0.1611, 0.1722, 0.1700, 0.1634, 0.1449,\n",
      "         0.0744],\n",
      "        [0.0331, 0.0092, 0.0226, 0.0547, 0.1600, 0.1703, 0.1681, 0.1618, 0.1442,\n",
      "         0.0760],\n",
      "        [0.0335, 0.0094, 0.0230, 0.0554, 0.1600, 0.1699, 0.1676, 0.1612, 0.1437,\n",
      "         0.0763],\n",
      "        [0.0337, 0.0095, 0.0233, 0.0558, 0.1601, 0.1698, 0.1673, 0.1609, 0.1434,\n",
      "         0.0764],\n",
      "        [0.0339, 0.0096, 0.0234, 0.0561, 0.1601, 0.1696, 0.1671, 0.1606, 0.1432,\n",
      "         0.0765]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 66.00, Train Loss: 3.28, Val Loss: 11.71, Train BLEU: 8.79, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中 的 生命 大卫 <UNK> <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: life in the deep oceans <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> life in the the . . . <EOS> <EOS>\n",
      "Attention Weights: tensor([[2.2473e-01, 3.2945e-01, 2.9189e-01, 1.4731e-01, 6.6286e-03, 6.8137e-08,\n",
      "         2.9434e-07, 6.4207e-12, 6.4207e-12, 6.4207e-12],\n",
      "        [1.9524e-01, 3.3450e-01, 3.0824e-01, 1.5443e-01, 7.5891e-03, 6.8080e-07,\n",
      "         2.1316e-06, 3.7518e-10, 3.7518e-10, 3.7518e-10],\n",
      "        [1.9407e-01, 3.1682e-01, 3.0100e-01, 1.7328e-01, 1.4806e-02, 5.2053e-06,\n",
      "         1.4332e-05, 3.3386e-09, 3.3386e-09, 3.3386e-09],\n",
      "        [1.9633e-01, 3.0890e-01, 2.9608e-01, 1.7934e-01, 1.9314e-02, 1.1682e-05,\n",
      "         3.0732e-05, 7.0487e-09, 7.0487e-09, 7.0487e-09],\n",
      "        [1.9844e-01, 3.0462e-01, 2.9289e-01, 1.8210e-01, 2.1894e-02, 1.5549e-05,\n",
      "         4.0026e-05, 7.3349e-09, 7.3349e-09, 7.3349e-09],\n",
      "        [2.0013e-01, 3.0296e-01, 2.9109e-01, 1.8277e-01, 2.2998e-02, 1.6357e-05,\n",
      "         4.2344e-05, 6.7199e-09, 6.7199e-09, 6.7199e-09],\n",
      "        [2.0105e-01, 3.0304e-01, 2.9073e-01, 1.8224e-01, 2.2886e-02, 1.6060e-05,\n",
      "         4.1699e-05, 6.4298e-09, 6.4298e-09, 6.4298e-09],\n",
      "        [2.0146e-01, 3.0311e-01, 2.9062e-01, 1.8193e-01, 2.2827e-02, 1.6116e-05,\n",
      "         4.1741e-05, 6.4598e-09, 6.4598e-09, 6.4598e-09],\n",
      "        [2.0163e-01, 3.0310e-01, 2.9054e-01, 1.8184e-01, 2.2831e-02, 1.6231e-05,\n",
      "         4.1948e-05, 6.5377e-09, 6.5377e-09, 6.5377e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他们 知道 我们 的 住处 吗 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: do they know where we live ? <EOS> <PAD>\n",
      "Model: <SOS> it &apos;s the the the . . <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.1004e-09, 6.8692e-10, 7.3747e-10, 1.8761e-09, 4.8441e-06, 7.2927e-02,\n",
      "         2.6332e-01, 2.8385e-01, 2.5397e-01, 1.2593e-01],\n",
      "        [8.2054e-09, 5.7285e-09, 6.1822e-09, 1.3686e-08, 8.0321e-06, 6.0378e-02,\n",
      "         2.5630e-01, 2.9290e-01, 2.6665e-01, 1.2376e-01],\n",
      "        [6.7397e-08, 4.8950e-08, 5.2597e-08, 1.0908e-07, 2.6994e-05, 6.3736e-02,\n",
      "         2.5040e-01, 2.8718e-01, 2.6631e-01, 1.3234e-01],\n",
      "        [1.8176e-07, 1.3376e-07, 1.4346e-07, 2.9119e-07, 5.3419e-05, 6.8925e-02,\n",
      "         2.4518e-01, 2.8102e-01, 2.6441e-01, 1.4040e-01],\n",
      "        [2.5924e-07, 1.9085e-07, 2.0406e-07, 4.0878e-07, 6.6345e-05, 6.9962e-02,\n",
      "         2.4329e-01, 2.7897e-01, 2.6379e-01, 1.4392e-01],\n",
      "        [3.1502e-07, 2.3288e-07, 2.4891e-07, 4.9414e-07, 7.3546e-05, 7.0513e-02,\n",
      "         2.4252e-01, 2.7818e-01, 2.6346e-01, 1.4526e-01],\n",
      "        [3.4497e-07, 2.5567e-07, 2.7354e-07, 5.4168e-07, 7.7444e-05, 7.0643e-02,\n",
      "         2.4218e-01, 2.7787e-01, 2.6337e-01, 1.4585e-01],\n",
      "        [3.6230e-07, 2.6897e-07, 2.8788e-07, 5.6958e-07, 7.9807e-05, 7.0632e-02,\n",
      "         2.4199e-01, 2.7772e-01, 2.6336e-01, 1.4622e-01],\n",
      "        [3.7358e-07, 2.7758e-07, 2.9719e-07, 5.8786e-07, 8.1519e-05, 7.0692e-02,\n",
      "         2.4184e-01, 2.7755e-01, 2.6331e-01, 1.4652e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67.00, Train Loss: 3.26, Val Loss: 11.73, Train BLEU: 8.79, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 看到 这些 在 动 的 东西 了 吗 <EOS> <PAD>\n",
      "Reference: but see all those different working things ? <EOS>\n",
      "Model: <SOS> it &apos;s the the the . . <EOS> <EOS>\n",
      "Attention Weights: tensor([[8.3363e-02, 1.4000e-01, 1.4748e-01, 1.4725e-01, 1.4262e-01, 1.3367e-01,\n",
      "         1.2168e-01, 8.2907e-02, 1.0258e-03, 3.6252e-12],\n",
      "        [7.1982e-02, 1.3649e-01, 1.4853e-01, 1.4998e-01, 1.4588e-01, 1.3694e-01,\n",
      "         1.2482e-01, 8.3876e-02, 1.4969e-03, 1.8044e-10],\n",
      "        [7.5137e-02, 1.3227e-01, 1.4383e-01, 1.4595e-01, 1.4325e-01, 1.3641e-01,\n",
      "         1.2709e-01, 9.2551e-02, 3.5151e-03, 1.5678e-09],\n",
      "        [7.8915e-02, 1.3073e-01, 1.4121e-01, 1.4328e-01, 1.4110e-01, 1.3527e-01,\n",
      "         1.2737e-01, 9.6722e-02, 5.4063e-03, 3.7843e-09],\n",
      "        [8.0520e-02, 1.2992e-01, 1.3995e-01, 1.4206e-01, 1.4016e-01, 1.3484e-01,\n",
      "         1.2765e-01, 9.8565e-02, 6.3296e-03, 4.4394e-09],\n",
      "        [8.1920e-02, 1.2962e-01, 1.3933e-01, 1.4141e-01, 1.3961e-01, 1.3447e-01,\n",
      "         1.2752e-01, 9.9256e-02, 6.8677e-03, 4.1395e-09],\n",
      "        [8.2428e-02, 1.2985e-01, 1.3945e-01, 1.4145e-01, 1.3958e-01, 1.3432e-01,\n",
      "         1.2723e-01, 9.8797e-02, 6.8961e-03, 3.6850e-09],\n",
      "        [8.2525e-02, 1.2996e-01, 1.3956e-01, 1.4155e-01, 1.3964e-01, 1.3432e-01,\n",
      "         1.2715e-01, 9.8466e-02, 6.8311e-03, 3.6214e-09],\n",
      "        [8.2545e-02, 1.2998e-01, 1.3958e-01, 1.4158e-01, 1.3966e-01, 1.3433e-01,\n",
      "         1.2714e-01, 9.8372e-02, 6.8104e-03, 3.6442e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 很 幸运 幸运地 成长 在 一个 珍视 教育 也\n",
      "Reference: i was very lucky to grow up in a\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[2.0482e-01, 3.0900e-01, 2.9673e-01, 1.8722e-01, 2.2246e-03, 9.1536e-12,\n",
      "         9.1536e-12, 9.1536e-12, 9.1536e-12, 9.1536e-12],\n",
      "        [1.8692e-01, 3.1067e-01, 3.0667e-01, 1.9235e-01, 3.3889e-03, 4.8793e-10,\n",
      "         4.8793e-10, 4.8793e-10, 4.8793e-10, 4.8793e-10],\n",
      "        [1.8936e-01, 2.9701e-01, 2.9851e-01, 2.0732e-01, 7.7902e-03, 3.9384e-09,\n",
      "         3.9384e-09, 3.9384e-09, 3.9384e-09, 3.9384e-09],\n",
      "        [1.9364e-01, 2.8972e-01, 2.9204e-01, 2.1296e-01, 1.1648e-02, 9.0942e-09,\n",
      "         9.0942e-09, 9.0942e-09, 9.0942e-09, 9.0942e-09],\n",
      "        [1.9622e-01, 2.8561e-01, 2.8853e-01, 2.1564e-01, 1.4003e-02, 1.0430e-08,\n",
      "         1.0430e-08, 1.0430e-08, 1.0430e-08, 1.0430e-08],\n",
      "        [1.9776e-01, 2.8464e-01, 2.8722e-01, 2.1561e-01, 1.4778e-02, 9.1230e-09,\n",
      "         9.1230e-09, 9.1230e-09, 9.1230e-09, 9.1230e-09],\n",
      "        [1.9830e-01, 2.8512e-01, 2.8727e-01, 2.1467e-01, 1.4638e-02, 8.7519e-09,\n",
      "         8.7519e-09, 8.7519e-09, 8.7519e-09, 8.7519e-09],\n",
      "        [1.9843e-01, 2.8531e-01, 2.8736e-01, 2.1435e-01, 1.4565e-02, 8.7851e-09,\n",
      "         8.7851e-09, 8.7851e-09, 8.7851e-09, 8.7851e-09],\n",
      "        [1.9848e-01, 2.8536e-01, 2.8738e-01, 2.1424e-01, 1.4545e-02, 8.8640e-09,\n",
      "         8.8640e-09, 8.8640e-09, 8.8640e-09, 8.8640e-09]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 68.00, Train Loss: 3.23, Val Loss: 11.74, Train BLEU: 8.49, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 是 我 最 喜欢 的 因为 它 哪 都 能动\n",
      "Reference: it &apos;s one of my favorites , because it\n",
      "Model: <SOS> it &apos;s got the the , , , ,\n",
      "Attention Weights: tensor([[0.0727, 0.1181, 0.1267, 0.1294, 0.1285, 0.1244, 0.1180, 0.1068, 0.0745,\n",
      "         0.0009],\n",
      "        [0.0619, 0.1148, 0.1269, 0.1310, 0.1316, 0.1276, 0.1216, 0.1094, 0.0742,\n",
      "         0.0011],\n",
      "        [0.0653, 0.1122, 0.1234, 0.1275, 0.1286, 0.1258, 0.1215, 0.1116, 0.0814,\n",
      "         0.0026],\n",
      "        [0.0689, 0.1118, 0.1219, 0.1256, 0.1266, 0.1243, 0.1205, 0.1119, 0.0846,\n",
      "         0.0040],\n",
      "        [0.0704, 0.1113, 0.1209, 0.1246, 0.1256, 0.1235, 0.1202, 0.1122, 0.0866,\n",
      "         0.0047],\n",
      "        [0.0717, 0.1111, 0.1204, 0.1240, 0.1250, 0.1231, 0.1198, 0.1122, 0.0874,\n",
      "         0.0052],\n",
      "        [0.0725, 0.1112, 0.1203, 0.1239, 0.1248, 0.1229, 0.1196, 0.1119, 0.0875,\n",
      "         0.0054],\n",
      "        [0.0730, 0.1113, 0.1204, 0.1239, 0.1248, 0.1228, 0.1194, 0.1117, 0.0872,\n",
      "         0.0055],\n",
      "        [0.0732, 0.1113, 0.1204, 0.1239, 0.1248, 0.1228, 0.1194, 0.1117, 0.0872,\n",
      "         0.0055]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把 书 放在 食品 杂货 袋中 这样 别人 就\n",
      "Reference: we would cover our books in grocery bags so\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0568, 0.1042, 0.1165, 0.1211, 0.1209, 0.1200, 0.1161, 0.1086, 0.0931,\n",
      "         0.0428],\n",
      "        [0.0468, 0.0992, 0.1163, 0.1236, 0.1235, 0.1242, 0.1201, 0.1112, 0.0948,\n",
      "         0.0403],\n",
      "        [0.0509, 0.0983, 0.1136, 0.1203, 0.1204, 0.1214, 0.1182, 0.1110, 0.0976,\n",
      "         0.0483],\n",
      "        [0.0545, 0.0986, 0.1123, 0.1182, 0.1184, 0.1193, 0.1167, 0.1104, 0.0987,\n",
      "         0.0529],\n",
      "        [0.0560, 0.0985, 0.1116, 0.1173, 0.1175, 0.1185, 0.1160, 0.1103, 0.0993,\n",
      "         0.0551],\n",
      "        [0.0573, 0.0986, 0.1112, 0.1167, 0.1170, 0.1178, 0.1155, 0.1100, 0.0993,\n",
      "         0.0564],\n",
      "        [0.0580, 0.0987, 0.1111, 0.1165, 0.1168, 0.1176, 0.1153, 0.1099, 0.0992,\n",
      "         0.0567],\n",
      "        [0.0586, 0.0989, 0.1111, 0.1164, 0.1167, 0.1175, 0.1152, 0.1097, 0.0991,\n",
      "         0.0569],\n",
      "        [0.0589, 0.0990, 0.1111, 0.1163, 0.1166, 0.1173, 0.1150, 0.1096, 0.0990,\n",
      "         0.0571]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 69.00, Train Loss: 3.21, Val Loss: 11.75, Train BLEU: 8.49, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 通过 潜水 潜水艇 拍下 的 影片 把 我们\n",
      "Reference: with vibrant video clips captured by submarines , david\n",
      "Model: <SOS> with vibrant the the , , , , ,\n",
      "Attention Weights: tensor([[4.5463e-04, 3.1790e-07, 4.6077e-02, 1.2598e-01, 5.0868e-02, 1.9103e-01,\n",
      "         1.8868e-01, 1.7531e-01, 1.4981e-01, 7.1792e-02],\n",
      "        [7.0580e-04, 2.3056e-06, 3.9443e-02, 1.1903e-01, 4.6082e-02, 1.9093e-01,\n",
      "         1.9507e-01, 1.8245e-01, 1.5581e-01, 7.0482e-02],\n",
      "        [1.7952e-03, 1.2924e-05, 4.4979e-02, 1.1836e-01, 5.2901e-02, 1.8027e-01,\n",
      "         1.8643e-01, 1.7786e-01, 1.5680e-01, 8.0591e-02],\n",
      "        [2.7902e-03, 2.7238e-05, 4.9375e-02, 1.1972e-01, 5.7992e-02, 1.7449e-01,\n",
      "         1.8049e-01, 1.7364e-01, 1.5559e-01, 8.5890e-02],\n",
      "        [3.3527e-03, 3.5360e-05, 5.1374e-02, 1.1992e-01, 6.0298e-02, 1.7209e-01,\n",
      "         1.7797e-01, 1.7161e-01, 1.5485e-01, 8.8504e-02],\n",
      "        [3.5433e-03, 3.6816e-05, 5.2648e-02, 1.2029e-01, 6.1678e-02, 1.7120e-01,\n",
      "         1.7681e-01, 1.7049e-01, 1.5408e-01, 8.9216e-02],\n",
      "        [3.6332e-03, 3.7829e-05, 5.3370e-02, 1.2056e-01, 6.2215e-02, 1.7087e-01,\n",
      "         1.7635e-01, 1.6997e-01, 1.5364e-01, 8.9356e-02],\n",
      "        [3.7094e-03, 3.8924e-05, 5.3787e-02, 1.2073e-01, 6.2496e-02, 1.7065e-01,\n",
      "         1.7605e-01, 1.6965e-01, 1.5339e-01, 8.9496e-02],\n",
      "        [3.7710e-03, 3.9838e-05, 5.4056e-02, 1.2083e-01, 6.2690e-02, 1.7046e-01,\n",
      "         1.7581e-01, 1.6943e-01, 1.5325e-01, 8.9649e-02]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 很 幸运 幸运地 成长 在 一个 珍视 教育 也\n",
      "Reference: i was very lucky to grow up in a\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[1.9952e-01, 3.0967e-01, 3.0102e-01, 1.8778e-01, 2.0063e-03, 9.5336e-12,\n",
      "         9.5336e-12, 9.5336e-12, 9.5336e-12, 9.5336e-12],\n",
      "        [1.8133e-01, 3.0916e-01, 3.1061e-01, 1.9546e-01, 3.4445e-03, 5.5492e-10,\n",
      "         5.5492e-10, 5.5492e-10, 5.5492e-10, 5.5492e-10],\n",
      "        [1.8481e-01, 2.9427e-01, 3.0057e-01, 2.1189e-01, 8.4627e-03, 4.9094e-09,\n",
      "         4.9094e-09, 4.9094e-09, 4.9094e-09, 4.9094e-09],\n",
      "        [1.8974e-01, 2.8686e-01, 2.9322e-01, 2.1735e-01, 1.2825e-02, 1.1928e-08,\n",
      "         1.1928e-08, 1.1928e-08, 1.1928e-08, 1.1928e-08],\n",
      "        [1.9204e-01, 2.8291e-01, 2.8969e-01, 2.2005e-01, 1.5310e-02, 1.4515e-08,\n",
      "         1.4515e-08, 1.4515e-08, 1.4515e-08, 1.4515e-08],\n",
      "        [1.9381e-01, 2.8192e-01, 2.8827e-01, 2.1987e-01, 1.6128e-02, 1.2631e-08,\n",
      "         1.2631e-08, 1.2631e-08, 1.2631e-08, 1.2631e-08],\n",
      "        [1.9449e-01, 2.8240e-01, 2.8830e-01, 2.1881e-01, 1.5995e-02, 1.2032e-08,\n",
      "         1.2032e-08, 1.2032e-08, 1.2032e-08, 1.2032e-08],\n",
      "        [1.9461e-01, 2.8265e-01, 2.8843e-01, 2.1842e-01, 1.5881e-02, 1.2034e-08,\n",
      "         1.2034e-08, 1.2034e-08, 1.2034e-08, 1.2034e-08],\n",
      "        [1.9465e-01, 2.8273e-01, 2.8848e-01, 2.1830e-01, 1.5840e-02, 1.2094e-08,\n",
      "         1.2094e-08, 1.2094e-08, 1.2094e-08, 1.2094e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70.00, Train Loss: 3.19, Val Loss: 11.77, Train BLEU: 8.44, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 这位 是 比尔 <UNK> 我 是 大卫 <UNK>\n",
      "Reference: this is bill lange . i &apos;m dave gallo\n",
      "Model: <SOS> this is bill is . . . . .\n",
      "Attention Weights: tensor([[6.0788e-03, 2.1287e-06, 7.3506e-02, 1.0351e-01, 3.8702e-04, 5.7230e-06,\n",
      "         4.3290e-01, 3.6069e-01, 2.2928e-02, 3.6855e-07],\n",
      "        [8.1365e-03, 6.8467e-06, 7.1213e-02, 1.2527e-01, 5.9942e-04, 1.5246e-05,\n",
      "         3.8371e-01, 3.8449e-01, 2.6561e-02, 1.4026e-06],\n",
      "        [1.6044e-02, 4.7049e-05, 8.6561e-02, 1.5259e-01, 1.9617e-03, 9.1352e-05,\n",
      "         3.3375e-01, 3.6717e-01, 4.1772e-02, 1.1359e-05],\n",
      "        [2.1368e-02, 9.7239e-05, 9.5735e-02, 1.6450e-01, 3.1928e-03, 1.8123e-04,\n",
      "         3.1401e-01, 3.4975e-01, 5.1146e-02, 2.4808e-05],\n",
      "        [2.3775e-02, 1.2820e-04, 9.9194e-02, 1.6796e-01, 3.8778e-03, 2.3669e-04,\n",
      "         3.0720e-01, 3.4223e-01, 5.5361e-02, 3.4337e-05],\n",
      "        [2.4233e-02, 1.3962e-04, 1.0037e-01, 1.6766e-01, 4.1161e-03, 2.5778e-04,\n",
      "         3.0691e-01, 3.3990e-01, 5.6385e-02, 3.8150e-05],\n",
      "        [2.4481e-02, 1.4859e-04, 1.0086e-01, 1.6744e-01, 4.2612e-03, 2.7316e-04,\n",
      "         3.0674e-01, 3.3884e-01, 5.6918e-02, 4.1050e-05],\n",
      "        [2.4599e-02, 1.5357e-04, 1.0103e-01, 1.6743e-01, 4.3328e-03, 2.8136e-04,\n",
      "         3.0652e-01, 3.3845e-01, 5.7155e-02, 4.2681e-05],\n",
      "        [2.4656e-02, 1.5624e-04, 1.0110e-01, 1.6745e-01, 4.3685e-03, 2.8569e-04,\n",
      "         3.0637e-01, 3.3831e-01, 5.7263e-02, 4.3563e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 她 两年 年前 退休 了 结果 却 把 我家 变成\n",
      "Reference: she retired two years ago , only to turn\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[1.5009e-01, 2.3878e-01, 2.4431e-01, 2.2511e-01, 1.4026e-01, 1.4655e-03,\n",
      "         7.1049e-12, 7.1049e-12, 7.1049e-12, 7.1049e-12],\n",
      "        [1.3526e-01, 2.3474e-01, 2.4817e-01, 2.3257e-01, 1.4656e-01, 2.6927e-03,\n",
      "         4.3173e-10, 4.3173e-10, 4.3173e-10, 4.3173e-10],\n",
      "        [1.3993e-01, 2.2444e-01, 2.3797e-01, 2.2864e-01, 1.6204e-01, 6.9817e-03,\n",
      "         4.1418e-09, 4.1418e-09, 4.1418e-09, 4.1418e-09],\n",
      "        [1.4504e-01, 2.1975e-01, 2.3186e-01, 2.2455e-01, 1.6787e-01, 1.0924e-02,\n",
      "         1.0977e-08, 1.0977e-08, 1.0977e-08, 1.0977e-08],\n",
      "        [1.4638e-01, 2.1802e-01, 2.2984e-01, 2.2343e-01, 1.6994e-01, 1.2396e-02,\n",
      "         1.3401e-08, 1.3401e-08, 1.3401e-08, 1.3401e-08],\n",
      "        [1.4793e-01, 2.1711e-01, 2.2861e-01, 2.2251e-01, 1.7061e-01, 1.3224e-02,\n",
      "         1.2577e-08, 1.2577e-08, 1.2577e-08, 1.2577e-08],\n",
      "        [1.4884e-01, 2.1737e-01, 2.2861e-01, 2.2214e-01, 1.6972e-01, 1.3324e-02,\n",
      "         1.0966e-08, 1.0966e-08, 1.0966e-08, 1.0966e-08],\n",
      "        [1.4906e-01, 2.1769e-01, 2.2886e-01, 2.2217e-01, 1.6905e-01, 1.3170e-02,\n",
      "         1.0750e-08, 1.0750e-08, 1.0750e-08, 1.0750e-08],\n",
      "        [1.4909e-01, 2.1779e-01, 2.2896e-01, 2.2221e-01, 1.6884e-01, 1.3100e-02,\n",
      "         1.0778e-08, 1.0778e-08, 1.0778e-08, 1.0778e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 71.00, Train Loss: 3.16, Val Loss: 11.78, Train BLEU: 8.49, Val BLEU: 0.26\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里 生物 的 多样 多样性 和 密度 要 比\n",
      "Reference: the biodiversity and the <UNK> in the ocean is\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0567, 0.1090, 0.1194, 0.1246, 0.1241, 0.0856, 0.1232, 0.1126, 0.0959,\n",
      "         0.0489],\n",
      "        [0.0474, 0.1042, 0.1186, 0.1264, 0.1262, 0.0860, 0.1268, 0.1163, 0.0992,\n",
      "         0.0489],\n",
      "        [0.0527, 0.1026, 0.1151, 0.1217, 0.1220, 0.0891, 0.1222, 0.1147, 0.1016,\n",
      "         0.0583],\n",
      "        [0.0565, 0.1024, 0.1135, 0.1193, 0.1195, 0.0907, 0.1196, 0.1134, 0.1022,\n",
      "         0.0630],\n",
      "        [0.0574, 0.1021, 0.1128, 0.1183, 0.1186, 0.0912, 0.1189, 0.1132, 0.1027,\n",
      "         0.0648],\n",
      "        [0.0584, 0.1019, 0.1123, 0.1177, 0.1181, 0.0919, 0.1184, 0.1129, 0.1026,\n",
      "         0.0658],\n",
      "        [0.0591, 0.1018, 0.1121, 0.1174, 0.1179, 0.0923, 0.1181, 0.1127, 0.1025,\n",
      "         0.0661],\n",
      "        [0.0595, 0.1018, 0.1120, 0.1172, 0.1177, 0.0924, 0.1181, 0.1126, 0.1024,\n",
      "         0.0663],\n",
      "        [0.0600, 0.1018, 0.1120, 0.1171, 0.1177, 0.0926, 0.1179, 0.1124, 0.1022,\n",
      "         0.0663]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 父亲 那 就是 他 他 是 他家 家族\n",
      "Reference: and my father -- that &apos;s him -- he\n",
      "Model: <SOS> we of the the the the the the ,\n",
      "Attention Weights: tensor([[9.7575e-02, 1.5405e-01, 1.0586e-01, 2.2030e-02, 2.7261e-06, 1.1803e-01,\n",
      "         1.2392e-01, 2.3561e-01, 1.4184e-01, 1.0799e-03],\n",
      "        [9.4422e-02, 1.6964e-01, 1.2659e-01, 3.1325e-02, 1.6526e-05, 1.0031e-01,\n",
      "         1.1196e-01, 2.2390e-01, 1.4019e-01, 1.6475e-03],\n",
      "        [1.0042e-01, 1.6928e-01, 1.4106e-01, 4.9069e-02, 9.0293e-05, 9.7519e-02,\n",
      "         1.0962e-01, 1.9265e-01, 1.3625e-01, 4.0365e-03],\n",
      "        [1.0363e-01, 1.6696e-01, 1.4386e-01, 5.8136e-02, 1.9394e-04, 9.8129e-02,\n",
      "         1.0931e-01, 1.8001e-01, 1.3380e-01, 5.9734e-03],\n",
      "        [1.0462e-01, 1.6594e-01, 1.4519e-01, 6.2188e-02, 2.5609e-04, 9.8004e-02,\n",
      "         1.0893e-01, 1.7499e-01, 1.3308e-01, 6.8185e-03],\n",
      "        [1.0532e-01, 1.6479e-01, 1.4491e-01, 6.3388e-02, 2.8446e-04, 9.8572e-02,\n",
      "         1.0923e-01, 1.7338e-01, 1.3284e-01, 7.2812e-03],\n",
      "        [1.0566e-01, 1.6399e-01, 1.4398e-01, 6.2967e-02, 2.9390e-04, 9.9376e-02,\n",
      "         1.0991e-01, 1.7350e-01, 1.3287e-01, 7.4505e-03],\n",
      "        [1.0574e-01, 1.6327e-01, 1.4272e-01, 6.1934e-02, 2.9423e-04, 1.0030e-01,\n",
      "         1.1066e-01, 1.7445e-01, 1.3312e-01, 7.5100e-03],\n",
      "        [1.0580e-01, 1.6314e-01, 1.4240e-01, 6.1559e-02, 2.9573e-04, 1.0052e-01,\n",
      "         1.1087e-01, 1.7473e-01, 1.3315e-01, 7.5390e-03]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 72.00, Train Loss: 3.14, Val Loss: 11.79, Train BLEU: 8.80, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: <UNK> 塞尔 <UNK> <UNK> 斯特 说 过 真正 的 探索\n",
      "Reference: marcel proust said , &quot; the true voyage of\n",
      "Model: <SOS> marcel proust said , , , , , ,\n",
      "Attention Weights: tensor([[9.5869e-10, 6.1626e-10, 6.8368e-10, 1.9624e-09, 3.1452e-06, 5.2564e-02,\n",
      "         2.4565e-01, 2.9493e-01, 2.7015e-01, 1.3670e-01],\n",
      "        [8.5446e-09, 6.0043e-09, 6.6997e-09, 1.7088e-08, 8.3559e-06, 4.5974e-02,\n",
      "         2.3071e-01, 2.9773e-01, 2.8274e-01, 1.4284e-01],\n",
      "        [1.1276e-07, 8.2462e-08, 9.1378e-08, 2.1525e-07, 4.0606e-05, 5.1876e-02,\n",
      "         2.2414e-01, 2.8731e-01, 2.7976e-01, 1.5688e-01],\n",
      "        [3.9622e-07, 2.9370e-07, 3.2306e-07, 7.3618e-07, 9.3787e-05, 5.8429e-02,\n",
      "         2.2075e-01, 2.7899e-01, 2.7535e-01, 1.6639e-01],\n",
      "        [5.9468e-07, 4.4065e-07, 4.8258e-07, 1.0820e-06, 1.1743e-04, 5.9605e-02,\n",
      "         2.1930e-01, 2.7619e-01, 2.7410e-01, 1.7068e-01],\n",
      "        [7.3989e-07, 5.4995e-07, 6.0139e-07, 1.3356e-06, 1.3174e-04, 6.0648e-02,\n",
      "         2.1870e-01, 2.7498e-01, 2.7336e-01, 1.7219e-01],\n",
      "        [8.2343e-07, 6.1337e-07, 6.7098e-07, 1.4851e-06, 1.3991e-04, 6.1081e-02,\n",
      "         2.1839e-01, 2.7438e-01, 2.7305e-01, 1.7296e-01],\n",
      "        [8.7126e-07, 6.4992e-07, 7.1090e-07, 1.5700e-06, 1.4461e-04, 6.1218e-02,\n",
      "         2.1818e-01, 2.7407e-01, 2.7295e-01, 1.7344e-01],\n",
      "        [9.0257e-07, 6.7374e-07, 7.3703e-07, 1.6259e-06, 1.4795e-04, 6.1352e-02,\n",
      "         2.1803e-01, 2.7381e-01, 2.7284e-01, 1.7381e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 但是 我 那 受过 教育 的 母亲 成为 为了 一名\n",
      "Reference: but my educated mother became a teacher . <EOS>\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[2.3032e-01, 2.0155e-01, 3.2611e-02, 1.4249e-06, 3.7580e-04, 2.6365e-01,\n",
      "         2.6940e-01, 2.0891e-03, 1.4786e-11, 1.4786e-11],\n",
      "        [2.2607e-01, 2.3009e-01, 4.8858e-02, 1.4914e-05, 9.3417e-04, 2.3165e-01,\n",
      "         2.5791e-01, 4.4702e-03, 9.5459e-10, 9.5459e-10],\n",
      "        [2.1977e-01, 2.4381e-01, 7.8017e-02, 9.6030e-05, 2.8258e-03, 2.0609e-01,\n",
      "         2.3840e-01, 1.0995e-02, 8.4720e-09, 8.4720e-09],\n",
      "        [2.1735e-01, 2.4235e-01, 9.2193e-02, 2.1369e-04, 4.4915e-03, 1.9879e-01,\n",
      "         2.2889e-01, 1.5716e-02, 2.0408e-08, 2.0408e-08],\n",
      "        [2.1646e-01, 2.4259e-01, 9.6394e-02, 2.5985e-04, 5.0255e-03, 1.9600e-01,\n",
      "         2.2621e-01, 1.7064e-02, 2.4423e-08, 2.4423e-08],\n",
      "        [2.1639e-01, 2.4133e-01, 9.7733e-02, 2.7952e-04, 5.3555e-03, 1.9588e-01,\n",
      "         2.2519e-01, 1.7833e-02, 2.2808e-08, 2.2808e-08],\n",
      "        [2.1644e-01, 2.3929e-01, 9.6541e-02, 2.7951e-04, 5.4947e-03, 1.9796e-01,\n",
      "         2.2588e-01, 1.8102e-02, 2.0076e-08, 2.0076e-08],\n",
      "        [2.1695e-01, 2.3876e-01, 9.5215e-02, 2.7708e-04, 5.4538e-03, 1.9896e-01,\n",
      "         2.2638e-01, 1.7995e-02, 1.9826e-08, 1.9826e-08],\n",
      "        [2.1716e-01, 2.3868e-01, 9.4765e-02, 2.7754e-04, 5.4330e-03, 1.9918e-01,\n",
      "         2.2655e-01, 1.7956e-02, 2.0054e-08, 2.0054e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73.00, Train Loss: 3.11, Val Loss: 11.80, Train BLEU: 8.81, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 原来 它 是 海洋 洋中 最长 的 生物 <EOS> <PAD>\n",
      "Reference: this turns out to be the longest creature in\n",
      "Model: <SOS> it &apos;s the the to . . <EOS> <EOS>\n",
      "Attention Weights: tensor([[9.2496e-02, 1.6656e-01, 1.7680e-01, 1.5852e-01, 2.3131e-02, 1.5278e-01,\n",
      "         1.4503e-01, 8.3900e-02, 7.8395e-04, 4.6303e-12],\n",
      "        [8.1922e-02, 1.6025e-01, 1.7720e-01, 1.6429e-01, 2.7536e-02, 1.4988e-01,\n",
      "         1.4742e-01, 8.9669e-02, 1.8382e-03, 3.4126e-10],\n",
      "        [8.6825e-02, 1.5117e-01, 1.6579e-01, 1.5903e-01, 4.0532e-02, 1.4366e-01,\n",
      "         1.4524e-01, 1.0239e-01, 5.3608e-03, 3.9953e-09],\n",
      "        [9.0936e-02, 1.4728e-01, 1.5988e-01, 1.5460e-01, 4.8644e-02, 1.4035e-01,\n",
      "         1.4276e-01, 1.0702e-01, 8.5285e-03, 1.1477e-08],\n",
      "        [9.1604e-02, 1.4586e-01, 1.5804e-01, 1.5344e-01, 5.1023e-02, 1.3946e-01,\n",
      "         1.4236e-01, 1.0863e-01, 9.5751e-03, 1.4891e-08],\n",
      "        [9.2392e-02, 1.4527e-01, 1.5724e-01, 1.5295e-01, 5.2024e-02, 1.3910e-01,\n",
      "         1.4203e-01, 1.0897e-01, 1.0023e-02, 1.4282e-08],\n",
      "        [9.2850e-02, 1.4533e-01, 1.5722e-01, 1.5284e-01, 5.2018e-02, 1.3947e-01,\n",
      "         1.4192e-01, 1.0833e-01, 1.0021e-02, 1.1941e-08],\n",
      "        [9.2897e-02, 1.4556e-01, 1.5745e-01, 1.5290e-01, 5.1633e-02, 1.3980e-01,\n",
      "         1.4207e-01, 1.0783e-01, 9.8648e-03, 1.1413e-08],\n",
      "        [9.2862e-02, 1.4566e-01, 1.5756e-01, 1.5293e-01, 5.1410e-02, 1.3994e-01,\n",
      "         1.4218e-01, 1.0767e-01, 9.7836e-03, 1.1361e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他们 知道 我们 的 住处 吗 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: do they know where we live ? <EOS> <PAD>\n",
      "Model: <SOS> it &apos;s the the to . . <EOS> <EOS>\n",
      "Attention Weights: tensor([[9.4186e-10, 6.0713e-10, 6.7273e-10, 1.9561e-09, 2.8801e-06, 4.9122e-02,\n",
      "         2.4140e-01, 2.9669e-01, 2.7378e-01, 1.3900e-01],\n",
      "        [8.5847e-09, 6.0282e-09, 6.7233e-09, 1.7463e-08, 8.2219e-06, 4.3434e-02,\n",
      "         2.2530e-01, 2.9833e-01, 2.8650e-01, 1.4642e-01],\n",
      "        [1.2314e-07, 8.9984e-08, 9.9643e-08, 2.3840e-07, 4.2748e-05, 4.9794e-02,\n",
      "         2.1902e-01, 2.8709e-01, 2.8275e-01, 1.6130e-01],\n",
      "        [4.5428e-07, 3.3649e-07, 3.6955e-07, 8.5330e-07, 1.0186e-04, 5.6607e-02,\n",
      "         2.1610e-01, 2.7839e-01, 2.7775e-01, 1.7105e-01],\n",
      "        [6.7850e-07, 5.0235e-07, 5.4929e-07, 1.2481e-06, 1.2714e-04, 5.7737e-02,\n",
      "         2.1480e-01, 2.7553e-01, 2.7640e-01, 1.7540e-01],\n",
      "        [8.4010e-07, 6.2383e-07, 6.8110e-07, 1.5331e-06, 1.4214e-04, 5.8805e-02,\n",
      "         2.1426e-01, 2.7428e-01, 2.7561e-01, 1.7690e-01],\n",
      "        [9.3532e-07, 6.9596e-07, 7.6010e-07, 1.7056e-06, 1.5111e-04, 5.9304e-02,\n",
      "         2.1399e-01, 2.7363e-01, 2.7525e-01, 1.7768e-01],\n",
      "        [9.9094e-07, 7.3833e-07, 8.0626e-07, 1.8052e-06, 1.5636e-04, 5.9478e-02,\n",
      "         2.1378e-01, 2.7329e-01, 2.7511e-01, 1.7817e-01],\n",
      "        [1.0275e-06, 7.6609e-07, 8.3666e-07, 1.8710e-06, 1.6006e-04, 5.9632e-02,\n",
      "         2.1365e-01, 2.7302e-01, 2.7499e-01, 1.7854e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 74.00, Train Loss: 3.09, Val Loss: 11.81, Train BLEU: 8.81, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 和 我们 合作 的 人们 帮 我们 找到 了 新\n",
      "Reference: people that have partnered with us have given us\n",
      "Model: <SOS> we of the the the the , the the\n",
      "Attention Weights: tensor([[0.0560, 0.1026, 0.1153, 0.1210, 0.1221, 0.1211, 0.1164, 0.1076, 0.0915,\n",
      "         0.0464],\n",
      "        [0.0484, 0.0969, 0.1133, 0.1212, 0.1232, 0.1237, 0.1189, 0.1104, 0.0952,\n",
      "         0.0488],\n",
      "        [0.0553, 0.0967, 0.1101, 0.1165, 0.1183, 0.1188, 0.1157, 0.1097, 0.0986,\n",
      "         0.0602],\n",
      "        [0.0592, 0.0970, 0.1088, 0.1144, 0.1160, 0.1165, 0.1140, 0.1090, 0.0998,\n",
      "         0.0654],\n",
      "        [0.0600, 0.0969, 0.1082, 0.1137, 0.1153, 0.1158, 0.1136, 0.1090, 0.1004,\n",
      "         0.0672],\n",
      "        [0.0606, 0.0968, 0.1080, 0.1134, 0.1150, 0.1155, 0.1134, 0.1089, 0.1005,\n",
      "         0.0679],\n",
      "        [0.0610, 0.0968, 0.1080, 0.1132, 0.1149, 0.1154, 0.1133, 0.1088, 0.1004,\n",
      "         0.0682],\n",
      "        [0.0612, 0.0968, 0.1079, 0.1132, 0.1149, 0.1154, 0.1132, 0.1088, 0.1004,\n",
      "         0.0682],\n",
      "        [0.0616, 0.0969, 0.1080, 0.1132, 0.1148, 0.1153, 0.1132, 0.1086, 0.1002,\n",
      "         0.0682]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 祖父 在 他 的 年代 是 位非 非凡\n",
      "Reference: my grandfather was an extraordinary man for his time\n",
      "Model: <SOS> we of the the the , the the the\n",
      "Attention Weights: tensor([[0.0663, 0.1166, 0.1288, 0.1330, 0.1316, 0.1267, 0.1185, 0.1061, 0.0718,\n",
      "         0.0006],\n",
      "        [0.0574, 0.1103, 0.1262, 0.1326, 0.1334, 0.1295, 0.1227, 0.1106, 0.0761,\n",
      "         0.0012],\n",
      "        [0.0634, 0.1080, 0.1215, 0.1273, 0.1287, 0.1263, 0.1219, 0.1130, 0.0861,\n",
      "         0.0038],\n",
      "        [0.0678, 0.1077, 0.1196, 0.1248, 0.1260, 0.1242, 0.1206, 0.1132, 0.0900,\n",
      "         0.0061],\n",
      "        [0.0690, 0.1073, 0.1187, 0.1237, 0.1250, 0.1234, 0.1203, 0.1136, 0.0919,\n",
      "         0.0070],\n",
      "        [0.0698, 0.1073, 0.1184, 0.1233, 0.1246, 0.1231, 0.1200, 0.1135, 0.0925,\n",
      "         0.0074],\n",
      "        [0.0703, 0.1074, 0.1184, 0.1233, 0.1246, 0.1231, 0.1199, 0.1133, 0.0923,\n",
      "         0.0075],\n",
      "        [0.0706, 0.1075, 0.1185, 0.1234, 0.1246, 0.1231, 0.1198, 0.1131, 0.0919,\n",
      "         0.0075],\n",
      "        [0.0708, 0.1075, 0.1185, 0.1235, 0.1246, 0.1230, 0.1198, 0.1130, 0.0918,\n",
      "         0.0075]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 75.00, Train Loss: 3.06, Val Loss: 11.82, Train BLEU: 10.23, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本 基本上 都 没有 被 开发 发过 但是 像\n",
      "Reference: it &apos;s mostly unexplored , and yet there are\n",
      "Model: <SOS> we of the the , the the the the\n",
      "Attention Weights: tensor([[0.0520, 0.1025, 0.1148, 0.1227, 0.1231, 0.1219, 0.1167, 0.1083, 0.0920,\n",
      "         0.0460],\n",
      "        [0.0459, 0.0969, 0.1131, 0.1225, 0.1237, 0.1234, 0.1183, 0.1111, 0.0955,\n",
      "         0.0497],\n",
      "        [0.0542, 0.0968, 0.1098, 0.1171, 0.1183, 0.1182, 0.1149, 0.1100, 0.0987,\n",
      "         0.0621],\n",
      "        [0.0585, 0.0971, 0.1083, 0.1146, 0.1157, 0.1158, 0.1131, 0.1092, 0.1000,\n",
      "         0.0678],\n",
      "        [0.0595, 0.0968, 0.1077, 0.1137, 0.1149, 0.1150, 0.1126, 0.1091, 0.1006,\n",
      "         0.0701],\n",
      "        [0.0598, 0.0968, 0.1078, 0.1137, 0.1149, 0.1150, 0.1126, 0.1090, 0.1005,\n",
      "         0.0700],\n",
      "        [0.0601, 0.0968, 0.1077, 0.1136, 0.1149, 0.1150, 0.1125, 0.1089, 0.1004,\n",
      "         0.0700],\n",
      "        [0.0604, 0.0970, 0.1078, 0.1136, 0.1149, 0.1149, 0.1125, 0.1088, 0.1002,\n",
      "         0.0698],\n",
      "        [0.0606, 0.0970, 0.1079, 0.1136, 0.1149, 0.1149, 0.1124, 0.1087, 0.1001,\n",
      "         0.0698]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11 岁 那年 记得 得有 一天 早晨 醒来 听见\n",
      "Reference: when i was 11 , i remember waking up\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[2.0916e-01, 3.3951e-01, 3.1057e-01, 1.3541e-01, 5.3435e-03, 4.7565e-08,\n",
      "         1.4298e-07, 8.5151e-12, 8.5151e-12, 8.5151e-12],\n",
      "        [1.7767e-01, 3.2560e-01, 3.2222e-01, 1.6347e-01, 1.1039e-02, 1.1009e-06,\n",
      "         2.7404e-06, 6.1264e-10, 6.1264e-10, 6.1264e-10],\n",
      "        [1.8081e-01, 2.9508e-01, 3.0154e-01, 1.9405e-01, 2.8478e-02, 1.5939e-05,\n",
      "         3.5608e-05, 9.5420e-09, 9.5420e-09, 9.5420e-09],\n",
      "        [1.8342e-01, 2.8404e-01, 2.9196e-01, 2.0207e-01, 3.8373e-02, 4.2973e-05,\n",
      "         8.9628e-05, 2.7342e-08, 2.7342e-08, 2.7342e-08],\n",
      "        [1.8379e-01, 2.8074e-01, 2.8963e-01, 2.0437e-01, 4.1310e-02, 5.3724e-05,\n",
      "         1.0921e-04, 3.1126e-08, 3.1126e-08, 3.1126e-08],\n",
      "        [1.8532e-01, 2.8047e-01, 2.8873e-01, 2.0367e-01, 4.1642e-02, 5.2816e-05,\n",
      "         1.0840e-04, 2.7174e-08, 2.7174e-08, 2.7174e-08],\n",
      "        [1.8601e-01, 2.8104e-01, 2.8907e-01, 2.0278e-01, 4.0949e-02, 5.1676e-05,\n",
      "         1.0597e-04, 2.5559e-08, 2.5559e-08, 2.5559e-08],\n",
      "        [1.8618e-01, 2.8115e-01, 2.8914e-01, 2.0254e-01, 4.0818e-02, 5.1773e-05,\n",
      "         1.0605e-04, 2.5472e-08, 2.5472e-08, 2.5472e-08],\n",
      "        [1.8625e-01, 2.8117e-01, 2.8914e-01, 2.0248e-01, 4.0802e-02, 5.1930e-05,\n",
      "         1.0638e-04, 2.5581e-08, 2.5581e-08, 2.5581e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 76.00, Train Loss: 3.04, Val Loss: 11.83, Train BLEU: 10.27, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想 海洋 占 了 地球 球面 面积 的 75\n",
      "Reference: when you think about it , the oceans are\n",
      "Model: <SOS> when the the the , , , , ,\n",
      "Attention Weights: tensor([[0.0522, 0.1102, 0.1260, 0.1330, 0.1349, 0.1327, 0.1258, 0.1115, 0.0731,\n",
      "         0.0006],\n",
      "        [0.0513, 0.1057, 0.1232, 0.1309, 0.1334, 0.1316, 0.1265, 0.1148, 0.0808,\n",
      "         0.0019],\n",
      "        [0.0606, 0.1057, 0.1196, 0.1256, 0.1277, 0.1267, 0.1234, 0.1154, 0.0900,\n",
      "         0.0055],\n",
      "        [0.0644, 0.1058, 0.1182, 0.1236, 0.1255, 0.1247, 0.1220, 0.1152, 0.0930,\n",
      "         0.0076],\n",
      "        [0.0645, 0.1056, 0.1179, 0.1232, 0.1252, 0.1244, 0.1219, 0.1154, 0.0939,\n",
      "         0.0080],\n",
      "        [0.0651, 0.1056, 0.1178, 0.1230, 0.1250, 0.1243, 0.1218, 0.1153, 0.0940,\n",
      "         0.0082],\n",
      "        [0.0652, 0.1055, 0.1178, 0.1230, 0.1250, 0.1244, 0.1219, 0.1153, 0.0939,\n",
      "         0.0081],\n",
      "        [0.0653, 0.1055, 0.1178, 0.1231, 0.1251, 0.1245, 0.1219, 0.1152, 0.0936,\n",
      "         0.0079],\n",
      "        [0.0654, 0.1056, 0.1179, 0.1232, 0.1252, 0.1246, 0.1219, 0.1151, 0.0933,\n",
      "         0.0078]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6 岁 那年 塔利 塔利班 占领 阿富汗 并 规定\n",
      "Reference: you see , i was six when the taliban\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[7.4538e-02, 1.3999e-01, 1.5240e-01, 1.5151e-01, 1.4464e-01, 1.3766e-01,\n",
      "         1.2607e-01, 7.2568e-02, 6.1824e-04, 4.3886e-12],\n",
      "        [6.6399e-02, 1.3164e-01, 1.4760e-01, 1.4997e-01, 1.4675e-01, 1.4175e-01,\n",
      "         1.3215e-01, 8.1689e-02, 2.0405e-03, 4.1589e-10],\n",
      "        [7.4516e-02, 1.2632e-01, 1.3937e-01, 1.4238e-01, 1.4144e-01, 1.3901e-01,\n",
      "         1.3333e-01, 9.6777e-02, 6.8525e-03, 5.9360e-09],\n",
      "        [7.9785e-02, 1.2467e-01, 1.3596e-01, 1.3880e-01, 1.3839e-01, 1.3675e-01,\n",
      "         1.3237e-01, 1.0221e-01, 1.1055e-02, 1.9483e-08],\n",
      "        [8.0483e-02, 1.2401e-01, 1.3496e-01, 1.3789e-01, 1.3771e-01, 1.3637e-01,\n",
      "         1.3252e-01, 1.0388e-01, 1.2172e-02, 2.5258e-08],\n",
      "        [8.1079e-02, 1.2405e-01, 1.3494e-01, 1.3788e-01, 1.3760e-01, 1.3621e-01,\n",
      "         1.3233e-01, 1.0365e-01, 1.2264e-02, 2.2068e-08],\n",
      "        [8.1088e-02, 1.2441e-01, 1.3541e-01, 1.3831e-01, 1.3785e-01, 1.3630e-01,\n",
      "         1.3217e-01, 1.0259e-01, 1.1868e-02, 1.8891e-08],\n",
      "        [8.0937e-02, 1.2447e-01, 1.3556e-01, 1.3848e-01, 1.3799e-01, 1.3642e-01,\n",
      "         1.3223e-01, 1.0223e-01, 1.1687e-02, 1.8361e-08],\n",
      "        [8.0849e-02, 1.2448e-01, 1.3561e-01, 1.3854e-01, 1.3806e-01, 1.3648e-01,\n",
      "         1.3226e-01, 1.0211e-01, 1.1604e-02, 1.8276e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77.00, Train Loss: 3.02, Val Loss: 11.83, Train BLEU: 9.81, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 和 我们 合作 的 人们 帮 我们 找到 了 新\n",
      "Reference: people that have partnered with us have given us\n",
      "Model: <SOS> we of the the the the , the the\n",
      "Attention Weights: tensor([[0.0534, 0.1010, 0.1154, 0.1218, 0.1230, 0.1220, 0.1171, 0.1080, 0.0916,\n",
      "         0.0466],\n",
      "        [0.0482, 0.0954, 0.1129, 0.1208, 0.1228, 0.1227, 0.1184, 0.1103, 0.0965,\n",
      "         0.0521],\n",
      "        [0.0571, 0.0957, 0.1092, 0.1151, 0.1169, 0.1170, 0.1145, 0.1092, 0.0999,\n",
      "         0.0654],\n",
      "        [0.0611, 0.0960, 0.1077, 0.1128, 0.1144, 0.1146, 0.1127, 0.1085, 0.1011,\n",
      "         0.0710],\n",
      "        [0.0617, 0.0959, 0.1072, 0.1122, 0.1138, 0.1141, 0.1124, 0.1085, 0.1017,\n",
      "         0.0726],\n",
      "        [0.0619, 0.0958, 0.1071, 0.1121, 0.1137, 0.1139, 0.1123, 0.1085, 0.1017,\n",
      "         0.0730],\n",
      "        [0.0622, 0.0958, 0.1070, 0.1120, 0.1136, 0.1138, 0.1122, 0.1084, 0.1017,\n",
      "         0.0733],\n",
      "        [0.0623, 0.0957, 0.1070, 0.1120, 0.1136, 0.1139, 0.1122, 0.1084, 0.1016,\n",
      "         0.0732],\n",
      "        [0.0626, 0.0958, 0.1070, 0.1120, 0.1137, 0.1139, 0.1122, 0.1084, 0.1015,\n",
      "         0.0729]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 父亲 在 用 他 的 灰色 小 收音\n",
      "Reference: my father was listening to bbc news on his\n",
      "Model: <SOS> we of the the the , the the the\n",
      "Attention Weights: tensor([[2.6048e-04, 1.5401e-07, 2.5566e-02, 9.4212e-02, 3.2382e-02, 2.0585e-01,\n",
      "         2.0864e-01, 1.9255e-01, 1.6268e-01, 7.7855e-02],\n",
      "        [9.1842e-04, 3.1087e-06, 2.7053e-02, 9.3463e-02, 3.6252e-02, 1.9507e-01,\n",
      "         2.0396e-01, 1.9258e-01, 1.6713e-01, 8.3571e-02],\n",
      "        [3.4275e-03, 3.0157e-05, 3.7902e-02, 1.0258e-01, 4.9308e-02, 1.7747e-01,\n",
      "         1.8675e-01, 1.8091e-01, 1.6375e-01, 9.7882e-02],\n",
      "        [5.6452e-03, 7.2240e-05, 4.3668e-02, 1.0629e-01, 5.6335e-02, 1.6944e-01,\n",
      "         1.7861e-01, 1.7479e-01, 1.6118e-01, 1.0397e-01],\n",
      "        [6.4287e-03, 8.8979e-05, 4.4975e-02, 1.0648e-01, 5.8037e-02, 1.6745e-01,\n",
      "         1.7663e-01, 1.7327e-01, 1.6074e-01, 1.0590e-01],\n",
      "        [6.5738e-03, 8.9680e-05, 4.5414e-02, 1.0633e-01, 5.8505e-02, 1.6719e-01,\n",
      "         1.7624e-01, 1.7286e-01, 1.6050e-01, 1.0629e-01],\n",
      "        [6.5323e-03, 8.7679e-05, 4.5477e-02, 1.0619e-01, 5.8403e-02, 1.6741e-01,\n",
      "         1.7639e-01, 1.7283e-01, 1.6050e-01, 1.0618e-01],\n",
      "        [6.6038e-03, 8.9182e-05, 4.5706e-02, 1.0633e-01, 5.8498e-02, 1.6737e-01,\n",
      "         1.7625e-01, 1.7265e-01, 1.6032e-01, 1.0618e-01],\n",
      "        [6.6920e-03, 9.0889e-05, 4.5948e-02, 1.0651e-01, 5.8662e-02, 1.6723e-01,\n",
      "         1.7603e-01, 1.7243e-01, 1.6015e-01, 1.0626e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 78.00, Train Loss: 2.99, Val Loss: 11.85, Train BLEU: 11.92, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 底下 这些 都 是 <UNK> 它们 上上 上上下下 上下 下下\n",
      "Reference: it &apos;s got these fishing <UNK> on the bottom\n",
      "Model: <SOS> it &apos;s got got the , , , <EOS>\n",
      "Attention Weights: tensor([[9.2564e-02, 1.5694e-01, 9.6233e-02, 1.8504e-02, 1.7344e-06, 9.6127e-02,\n",
      "         1.1446e-01, 2.6707e-01, 1.5719e-01, 9.1072e-04],\n",
      "        [9.6100e-02, 1.7076e-01, 1.2528e-01, 3.8360e-02, 3.0309e-05, 8.6041e-02,\n",
      "         1.0643e-01, 2.2525e-01, 1.4917e-01, 2.5861e-03],\n",
      "        [1.0389e-01, 1.6524e-01, 1.4189e-01, 6.4358e-02, 2.4303e-04, 8.9704e-02,\n",
      "         1.0689e-01, 1.8091e-01, 1.3912e-01, 7.7445e-03],\n",
      "        [1.0710e-01, 1.6103e-01, 1.4513e-01, 7.7138e-02, 5.8199e-04, 9.1440e-02,\n",
      "         1.0643e-01, 1.6475e-01, 1.3465e-01, 1.1747e-02],\n",
      "        [1.0776e-01, 1.6082e-01, 1.4762e-01, 8.1873e-02, 7.2903e-04, 9.0592e-02,\n",
      "         1.0504e-01, 1.5952e-01, 1.3330e-01, 1.2744e-02],\n",
      "        [1.0800e-01, 1.6078e-01, 1.4790e-01, 8.2235e-02, 7.5897e-04, 9.0557e-02,\n",
      "         1.0472e-01, 1.5902e-01, 1.3311e-01, 1.2911e-02],\n",
      "        [1.0823e-01, 1.6080e-01, 1.4718e-01, 8.0703e-02, 7.3618e-04, 9.0960e-02,\n",
      "         1.0507e-01, 1.6022e-01, 1.3340e-01, 1.2700e-02],\n",
      "        [1.0826e-01, 1.6085e-01, 1.4640e-01, 7.9007e-02, 7.0685e-04, 9.1334e-02,\n",
      "         1.0539e-01, 1.6174e-01, 1.3382e-01, 1.2500e-02],\n",
      "        [1.0826e-01, 1.6081e-01, 1.4618e-01, 7.8569e-02, 7.0678e-04, 9.1415e-02,\n",
      "         1.0554e-01, 1.6207e-01, 1.3392e-01, 1.2523e-02]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 那 就是 她 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: there she is . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s the to . . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[7.1833e-02, 1.3404e-01, 1.4591e-01, 1.4854e-01, 1.4603e-01, 1.3861e-01,\n",
      "         1.2898e-01, 8.5365e-02, 6.8985e-04, 4.5595e-12],\n",
      "        [6.6856e-02, 1.2664e-01, 1.4201e-01, 1.4693e-01, 1.4619e-01, 1.4078e-01,\n",
      "         1.3359e-01, 9.4338e-02, 2.6725e-03, 5.2098e-10],\n",
      "        [7.6436e-02, 1.2293e-01, 1.3514e-01, 1.3952e-01, 1.3981e-01, 1.3696e-01,\n",
      "         1.3327e-01, 1.0681e-01, 9.1203e-03, 8.0963e-09],\n",
      "        [8.1698e-02, 1.2171e-01, 1.3221e-01, 1.3609e-01, 1.3658e-01, 1.3454e-01,\n",
      "         1.3195e-01, 1.1080e-01, 1.4423e-02, 2.8815e-08],\n",
      "        [8.2107e-02, 1.2127e-01, 1.3158e-01, 1.3546e-01, 1.3604e-01, 1.3418e-01,\n",
      "         1.3202e-01, 1.1190e-01, 1.5433e-02, 3.7551e-08],\n",
      "        [8.2380e-02, 1.2113e-01, 1.3142e-01, 1.3533e-01, 1.3593e-01, 1.3411e-01,\n",
      "         1.3203e-01, 1.1205e-01, 1.5617e-02, 3.5387e-08],\n",
      "        [8.2373e-02, 1.2137e-01, 1.3178e-01, 1.3571e-01, 1.3626e-01, 1.3428e-01,\n",
      "         1.3198e-01, 1.1119e-01, 1.5058e-02, 2.8606e-08],\n",
      "        [8.2223e-02, 1.2144e-01, 1.3193e-01, 1.3590e-01, 1.3644e-01, 1.3441e-01,\n",
      "         1.3205e-01, 1.1084e-01, 1.4773e-02, 2.7305e-08],\n",
      "        [8.2117e-02, 1.2145e-01, 1.3198e-01, 1.3597e-01, 1.3651e-01, 1.3447e-01,\n",
      "         1.3210e-01, 1.1075e-01, 1.4664e-02, 2.7170e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 79.00, Train Loss: 2.97, Val Loss: 11.86, Train BLEU: 11.79, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 是 我 最 喜欢 的 因为 它 哪 都 能动\n",
      "Reference: it &apos;s one of my favorites , because it\n",
      "Model: <SOS> it &apos;s got got , , , , ,\n",
      "Attention Weights: tensor([[0.0631, 0.1152, 0.1287, 0.1347, 0.1333, 0.1282, 0.1190, 0.1064, 0.0709,\n",
      "         0.0005],\n",
      "        [0.0590, 0.1081, 0.1238, 0.1316, 0.1325, 0.1290, 0.1227, 0.1119, 0.0796,\n",
      "         0.0018],\n",
      "        [0.0683, 0.1064, 0.1185, 0.1247, 0.1258, 0.1241, 0.1204, 0.1137, 0.0915,\n",
      "         0.0066],\n",
      "        [0.0732, 0.1060, 0.1163, 0.1215, 0.1226, 0.1215, 0.1187, 0.1136, 0.0958,\n",
      "         0.0107],\n",
      "        [0.0739, 0.1055, 0.1153, 0.1205, 0.1217, 0.1208, 0.1185, 0.1141, 0.0978,\n",
      "         0.0119],\n",
      "        [0.0740, 0.1054, 0.1152, 0.1204, 0.1216, 0.1207, 0.1185, 0.1141, 0.0980,\n",
      "         0.0121],\n",
      "        [0.0741, 0.1053, 0.1153, 0.1206, 0.1218, 0.1210, 0.1186, 0.1140, 0.0975,\n",
      "         0.0118],\n",
      "        [0.0742, 0.1054, 0.1154, 0.1207, 0.1220, 0.1211, 0.1186, 0.1139, 0.0971,\n",
      "         0.0116],\n",
      "        [0.0743, 0.1054, 0.1154, 0.1208, 0.1220, 0.1211, 0.1185, 0.1138, 0.0970,\n",
      "         0.0117]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 想 过 要 放弃 但 我 的 父亲 这时\n",
      "Reference: i would want to quit , but my father\n",
      "Model: <SOS> and of the the the , the the the\n",
      "Attention Weights: tensor([[0.0697, 0.1327, 0.1474, 0.1515, 0.1483, 0.1404, 0.1249, 0.0843, 0.0007,\n",
      "         0.0000],\n",
      "        [0.0642, 0.1249, 0.1432, 0.1495, 0.1488, 0.1426, 0.1305, 0.0940, 0.0021,\n",
      "         0.0001],\n",
      "        [0.0733, 0.1226, 0.1374, 0.1428, 0.1428, 0.1388, 0.1305, 0.1043, 0.0067,\n",
      "         0.0008],\n",
      "        [0.0790, 0.1218, 0.1344, 0.1391, 0.1392, 0.1362, 0.1297, 0.1083, 0.0106,\n",
      "         0.0016],\n",
      "        [0.0802, 0.1213, 0.1334, 0.1380, 0.1382, 0.1355, 0.1296, 0.1098, 0.0120,\n",
      "         0.0019],\n",
      "        [0.0807, 0.1208, 0.1326, 0.1372, 0.1376, 0.1352, 0.1298, 0.1110, 0.0128,\n",
      "         0.0022],\n",
      "        [0.0807, 0.1209, 0.1326, 0.1374, 0.1377, 0.1353, 0.1298, 0.1108, 0.0126,\n",
      "         0.0022],\n",
      "        [0.0808, 0.1209, 0.1328, 0.1376, 0.1379, 0.1355, 0.1298, 0.1103, 0.0123,\n",
      "         0.0021],\n",
      "        [0.0809, 0.1210, 0.1329, 0.1377, 0.1380, 0.1355, 0.1297, 0.1100, 0.0122,\n",
      "         0.0021]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 80.00, Train Loss: 2.94, Val Loss: 11.86, Train BLEU: 11.11, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 我 真 喜欢 这些 东西 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: i love that kind of stuff . <EOS> <PAD>\n",
      "Model: <SOS> it &apos;s the to to . . <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.3131e-01, 2.2913e-01, 2.4910e-01, 2.4193e-01, 1.4746e-01, 1.0598e-03,\n",
      "         9.0544e-12, 9.0544e-12, 9.0544e-12, 9.0544e-12],\n",
      "        [1.2708e-01, 2.1767e-01, 2.4300e-01, 2.4275e-01, 1.6458e-01, 4.9254e-03,\n",
      "         1.1737e-09, 1.1737e-09, 1.1737e-09, 1.1737e-09],\n",
      "        [1.3915e-01, 2.0657e-01, 2.2656e-01, 2.2969e-01, 1.8157e-01, 1.6466e-02,\n",
      "         1.7623e-08, 1.7623e-08, 1.7623e-08, 1.7623e-08],\n",
      "        [1.4478e-01, 2.0215e-01, 2.1925e-01, 2.2276e-01, 1.8573e-01, 2.5345e-02,\n",
      "         6.4534e-08, 6.4534e-08, 6.4534e-08, 6.4534e-08],\n",
      "        [1.4503e-01, 2.0121e-01, 2.1816e-01, 2.2209e-01, 1.8682e-01, 2.6688e-02,\n",
      "         8.5122e-08, 8.5122e-08, 8.5122e-08, 8.5122e-08],\n",
      "        [1.4518e-01, 2.0073e-01, 2.1774e-01, 2.2197e-01, 1.8726e-01, 2.7115e-02,\n",
      "         8.7702e-08, 8.7702e-08, 8.7702e-08, 8.7702e-08],\n",
      "        [1.4546e-01, 2.0087e-01, 2.1792e-01, 2.2213e-01, 1.8677e-01, 2.6861e-02,\n",
      "         7.2356e-08, 7.2356e-08, 7.2356e-08, 7.2356e-08],\n",
      "        [1.4548e-01, 2.0139e-01, 2.1862e-01, 2.2269e-01, 1.8580e-01, 2.6020e-02,\n",
      "         6.3114e-08, 6.3114e-08, 6.3114e-08, 6.3114e-08],\n",
      "        [1.4539e-01, 2.0150e-01, 2.1883e-01, 2.2291e-01, 1.8557e-01, 2.5813e-02,\n",
      "         6.2566e-08, 6.2566e-08, 6.2566e-08, 6.2566e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 这 是 我们 俩 人 唯一 的 受教 教育 方式\n",
      "Reference: it was the only way we both could be\n",
      "Model: <SOS> we of the the the , the the the\n",
      "Attention Weights: tensor([[0.0528, 0.0996, 0.1139, 0.1213, 0.1242, 0.1229, 0.1177, 0.1082, 0.0944,\n",
      "         0.0449],\n",
      "        [0.0506, 0.0939, 0.1098, 0.1183, 0.1220, 0.1221, 0.1180, 0.1117, 0.1000,\n",
      "         0.0537],\n",
      "        [0.0613, 0.0947, 0.1062, 0.1123, 0.1151, 0.1155, 0.1134, 0.1097, 0.1027,\n",
      "         0.0691],\n",
      "        [0.0652, 0.0949, 0.1049, 0.1102, 0.1126, 0.1131, 0.1116, 0.1090, 0.1036,\n",
      "         0.0749],\n",
      "        [0.0655, 0.0947, 0.1044, 0.1097, 0.1122, 0.1127, 0.1114, 0.1091, 0.1041,\n",
      "         0.0762],\n",
      "        [0.0655, 0.0945, 0.1043, 0.1097, 0.1122, 0.1128, 0.1114, 0.1090, 0.1041,\n",
      "         0.0764],\n",
      "        [0.0656, 0.0944, 0.1042, 0.1097, 0.1123, 0.1128, 0.1115, 0.1091, 0.1042,\n",
      "         0.0763],\n",
      "        [0.0657, 0.0945, 0.1043, 0.1097, 0.1124, 0.1129, 0.1115, 0.1090, 0.1040,\n",
      "         0.0759],\n",
      "        [0.0659, 0.0945, 0.1043, 0.1098, 0.1124, 0.1129, 0.1115, 0.1090, 0.1039,\n",
      "         0.0759]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81.00, Train Loss: 2.91, Val Loss: 11.88, Train BLEU: 11.32, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 我们 得用 非常 特殊 的 仪器 才能 能到 到达 那个\n",
      "Reference: we have to have a very special technology to\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0318, 0.0162, 0.1327, 0.1443, 0.1473, 0.1460, 0.1411, 0.0869, 0.1054,\n",
      "         0.0482],\n",
      "        [0.0389, 0.0268, 0.1236, 0.1365, 0.1407, 0.1403, 0.1371, 0.0900, 0.1069,\n",
      "         0.0592],\n",
      "        [0.0538, 0.0433, 0.1159, 0.1253, 0.1283, 0.1285, 0.1270, 0.0955, 0.1077,\n",
      "         0.0748],\n",
      "        [0.0592, 0.0498, 0.1130, 0.1214, 0.1241, 0.1244, 0.1234, 0.0967, 0.1077,\n",
      "         0.0803],\n",
      "        [0.0595, 0.0506, 0.1125, 0.1208, 0.1236, 0.1239, 0.1230, 0.0969, 0.1080,\n",
      "         0.0813],\n",
      "        [0.0592, 0.0501, 0.1128, 0.1210, 0.1238, 0.1242, 0.1232, 0.0969, 0.1078,\n",
      "         0.0809],\n",
      "        [0.0590, 0.0497, 0.1129, 0.1212, 0.1240, 0.1244, 0.1234, 0.0969, 0.1079,\n",
      "         0.0806],\n",
      "        [0.0588, 0.0492, 0.1131, 0.1214, 0.1242, 0.1246, 0.1236, 0.0970, 0.1079,\n",
      "         0.0802],\n",
      "        [0.0588, 0.0491, 0.1131, 0.1214, 0.1242, 0.1246, 0.1236, 0.0972, 0.1078,\n",
      "         0.0801]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 很 幸运 幸运地 成长 在 一个 珍视 教育 也\n",
      "Reference: i was very lucky to grow up in a\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[1.7354e-01, 3.0381e-01, 3.2350e-01, 1.9778e-01, 1.3729e-03, 1.3355e-11,\n",
      "         1.3355e-11, 1.3355e-11, 1.3355e-11, 1.3355e-11],\n",
      "        [1.7062e-01, 2.8702e-01, 3.1521e-01, 2.1974e-01, 7.4192e-03, 1.9757e-09,\n",
      "         1.9757e-09, 1.9757e-09, 1.9757e-09, 1.9757e-09],\n",
      "        [1.8365e-01, 2.6630e-01, 2.8952e-01, 2.3589e-01, 2.4637e-02, 2.9852e-08,\n",
      "         2.9852e-08, 2.9852e-08, 2.9852e-08, 2.9852e-08],\n",
      "        [1.8867e-01, 2.5797e-01, 2.7811e-01, 2.3834e-01, 3.6914e-02, 1.1063e-07,\n",
      "         1.1063e-07, 1.1063e-07, 1.1063e-07, 1.1063e-07],\n",
      "        [1.8851e-01, 2.5591e-01, 2.7667e-01, 2.3993e-01, 3.8978e-02, 1.4783e-07,\n",
      "         1.4783e-07, 1.4783e-07, 1.4783e-07, 1.4783e-07],\n",
      "        [1.8859e-01, 2.5664e-01, 2.7768e-01, 2.3925e-01, 3.7846e-02, 1.1485e-07,\n",
      "         1.1485e-07, 1.1485e-07, 1.1485e-07, 1.1485e-07],\n",
      "        [1.8885e-01, 2.5745e-01, 2.7859e-01, 2.3834e-01, 3.6775e-02, 1.0372e-07,\n",
      "         1.0372e-07, 1.0372e-07, 1.0372e-07, 1.0372e-07],\n",
      "        [1.8876e-01, 2.5767e-01, 2.7894e-01, 2.3816e-01, 3.6467e-02, 1.0283e-07,\n",
      "         1.0283e-07, 1.0283e-07, 1.0283e-07, 1.0283e-07],\n",
      "        [1.8870e-01, 2.5774e-01, 2.7906e-01, 2.3812e-01, 3.6375e-02, 1.0309e-07,\n",
      "         1.0309e-07, 1.0309e-07, 1.0309e-07, 1.0309e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 82.00, Train Loss: 2.89, Val Loss: 11.89, Train BLEU: 11.32, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 地球 的 大部 大部分 部分 都 是 海水 <EOS> <PAD>\n",
      "Reference: most of the planet is ocean water . <EOS>\n",
      "Model: <SOS> it &apos;s the to . . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[7.0820e-02, 1.3672e-01, 1.5154e-01, 1.5231e-01, 1.4541e-01, 1.3943e-01,\n",
      "         1.2963e-01, 7.3632e-02, 5.1420e-04, 5.2651e-12],\n",
      "        [6.9021e-02, 1.2740e-01, 1.4338e-01, 1.4703e-01, 1.4452e-01, 1.4136e-01,\n",
      "         1.3500e-01, 8.8941e-02, 3.3508e-03, 9.2532e-10],\n",
      "        [8.0483e-02, 1.2193e-01, 1.3373e-01, 1.3749e-01, 1.3740e-01, 1.3663e-01,\n",
      "         1.3395e-01, 1.0574e-01, 1.2649e-02, 1.6917e-08],\n",
      "        [8.5108e-02, 1.2009e-01, 1.3023e-01, 1.3380e-01, 1.3424e-01, 1.3410e-01,\n",
      "         1.3244e-01, 1.1069e-01, 1.9299e-02, 6.7451e-08],\n",
      "        [8.4835e-02, 1.1956e-01, 1.2970e-01, 1.3341e-01, 1.3402e-01, 1.3408e-01,\n",
      "         1.3280e-01, 1.1178e-01, 1.9818e-02, 8.4799e-08],\n",
      "        [8.4656e-02, 1.1958e-01, 1.2982e-01, 1.3364e-01, 1.3422e-01, 1.3428e-01,\n",
      "         1.3300e-01, 1.1145e-01, 1.9363e-02, 7.0377e-08],\n",
      "        [8.4552e-02, 1.1985e-01, 1.3027e-01, 1.3413e-01, 1.3461e-01, 1.3458e-01,\n",
      "         1.3310e-01, 1.1036e-01, 1.8555e-02, 5.8670e-08],\n",
      "        [8.4418e-02, 1.1983e-01, 1.3033e-01, 1.3424e-01, 1.3475e-01, 1.3473e-01,\n",
      "         1.3324e-01, 1.1013e-01, 1.8335e-02, 5.7473e-08],\n",
      "        [8.4335e-02, 1.1981e-01, 1.3035e-01, 1.3427e-01, 1.3480e-01, 1.3480e-01,\n",
      "         1.3331e-01, 1.1007e-01, 1.8246e-02, 5.7317e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 她 两年 年前 退休 了 结果 却 把 我家 变成\n",
      "Reference: she retired two years ago , only to turn\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[1.3020e-01, 2.2740e-01, 2.5008e-01, 2.4387e-01, 1.4743e-01, 1.0192e-03,\n",
      "         9.9574e-12, 9.9574e-12, 9.9574e-12, 9.9574e-12],\n",
      "        [1.2985e-01, 2.1458e-01, 2.4035e-01, 2.4137e-01, 1.6757e-01, 6.2886e-03,\n",
      "         1.6833e-09, 1.6833e-09, 1.6833e-09, 1.6833e-09],\n",
      "        [1.4312e-01, 2.0291e-01, 2.2208e-01, 2.2598e-01, 1.8424e-01, 2.1675e-02,\n",
      "         2.7703e-08, 2.7703e-08, 2.7703e-08, 2.7703e-08],\n",
      "        [1.4795e-01, 1.9823e-01, 2.1456e-01, 2.1882e-01, 1.8796e-01, 3.2481e-02,\n",
      "         1.0977e-07, 1.0977e-07, 1.0977e-07, 1.0977e-07],\n",
      "        [1.4768e-01, 1.9745e-01, 2.1393e-01, 2.1870e-01, 1.8901e-01, 3.3238e-02,\n",
      "         1.3892e-07, 1.3892e-07, 1.3892e-07, 1.3892e-07],\n",
      "        [1.4753e-01, 1.9714e-01, 2.1382e-01, 2.1892e-01, 1.8946e-01, 3.3119e-02,\n",
      "         1.3406e-07, 1.3406e-07, 1.3406e-07, 1.3406e-07],\n",
      "        [1.4766e-01, 1.9773e-01, 2.1461e-01, 2.1960e-01, 1.8844e-01, 3.1963e-02,\n",
      "         1.0317e-07, 1.0317e-07, 1.0317e-07, 1.0317e-07],\n",
      "        [1.4756e-01, 1.9804e-01, 2.1513e-01, 2.2012e-01, 1.8789e-01, 3.1264e-02,\n",
      "         9.6290e-08, 9.6290e-08, 9.6290e-08, 9.6290e-08],\n",
      "        [1.4745e-01, 1.9810e-01, 2.1528e-01, 2.2030e-01, 1.8778e-01, 3.1092e-02,\n",
      "         9.6114e-08, 9.6114e-08, 9.6114e-08, 9.6114e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 83.00, Train Loss: 2.87, Val Loss: 11.90, Train BLEU: 11.79, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 其实 它们 都 是 由 单独 的 动物 结合 合在\n",
      "Reference: these are all individual animals banding together to make\n",
      "Model: <SOS> these &apos;s got these , , , , ,\n",
      "Attention Weights: tensor([[6.0663e-02, 1.2624e-01, 1.4153e-01, 1.4683e-01, 1.4493e-01, 1.3700e-01,\n",
      "         1.2219e-01, 9.8350e-02, 2.2262e-02, 8.0919e-07],\n",
      "        [5.9752e-02, 1.1544e-01, 1.3133e-01, 1.3806e-01, 1.3874e-01, 1.3469e-01,\n",
      "         1.2756e-01, 1.1320e-01, 4.1187e-02, 3.3580e-05],\n",
      "        [6.9704e-02, 1.1185e-01, 1.2377e-01, 1.2915e-01, 1.3047e-01, 1.2883e-01,\n",
      "         1.2558e-01, 1.1798e-01, 6.2377e-02, 2.9484e-04],\n",
      "        [7.3307e-02, 1.1092e-01, 1.2159e-01, 1.2645e-01, 1.2784e-01, 1.2680e-01,\n",
      "         1.2456e-01, 1.1875e-01, 6.9219e-02, 5.6849e-04],\n",
      "        [7.3357e-02, 1.1058e-01, 1.2107e-01, 1.2590e-01, 1.2735e-01, 1.2650e-01,\n",
      "         1.2467e-01, 1.1948e-01, 7.0487e-02, 6.1927e-04],\n",
      "        [7.3477e-02, 1.1054e-01, 1.2095e-01, 1.2577e-01, 1.2722e-01, 1.2639e-01,\n",
      "         1.2463e-01, 1.1960e-01, 7.0796e-02, 6.4075e-04],\n",
      "        [7.3679e-02, 1.1059e-01, 1.2097e-01, 1.2584e-01, 1.2731e-01, 1.2646e-01,\n",
      "         1.2463e-01, 1.1943e-01, 7.0442e-02, 6.4623e-04],\n",
      "        [7.3807e-02, 1.1072e-01, 1.2114e-01, 1.2606e-01, 1.2753e-01, 1.2659e-01,\n",
      "         1.2458e-01, 1.1906e-01, 6.9864e-02, 6.4262e-04],\n",
      "        [7.3990e-02, 1.1089e-01, 1.2130e-01, 1.2622e-01, 1.2766e-01, 1.2664e-01,\n",
      "         1.2446e-01, 1.1875e-01, 6.9441e-02, 6.3802e-04]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 对 他 来说 孩子 不 接受 受教 教育 <UNK> 是\n",
      "Reference: to him , there was greater risk in not\n",
      "Model: <SOS> we use the the the the the the .\n",
      "Attention Weights: tensor([[1.0351e-01, 1.8263e-01, 2.0263e-01, 2.0359e-01, 1.9530e-01, 1.1162e-01,\n",
      "         7.2010e-04, 7.8184e-12, 7.8184e-12, 7.8184e-12],\n",
      "        [1.0339e-01, 1.7170e-01, 1.9359e-01, 1.9888e-01, 1.9610e-01, 1.3146e-01,\n",
      "         4.8816e-03, 1.3900e-09, 1.3900e-09, 1.3900e-09],\n",
      "        [1.1553e-01, 1.6425e-01, 1.8063e-01, 1.8613e-01, 1.8670e-01, 1.4934e-01,\n",
      "         1.7416e-02, 2.3798e-08, 2.3798e-08, 2.3798e-08],\n",
      "        [1.1998e-01, 1.6141e-01, 1.7555e-01, 1.8079e-01, 1.8211e-01, 1.5403e-01,\n",
      "         2.6129e-02, 9.4947e-08, 9.4947e-08, 9.4947e-08],\n",
      "        [1.1983e-01, 1.6050e-01, 1.7466e-01, 1.8016e-01, 1.8215e-01, 1.5564e-01,\n",
      "         2.7063e-02, 1.2672e-07, 1.2672e-07, 1.2672e-07],\n",
      "        [1.1967e-01, 1.6075e-01, 1.7514e-01, 1.8071e-01, 1.8273e-01, 1.5489e-01,\n",
      "         2.6117e-02, 9.8505e-08, 9.8505e-08, 9.8505e-08],\n",
      "        [1.1964e-01, 1.6107e-01, 1.7565e-01, 1.8128e-01, 1.8323e-01, 1.5387e-01,\n",
      "         2.5252e-02, 8.6004e-08, 8.6004e-08, 8.6004e-08],\n",
      "        [1.1951e-01, 1.6110e-01, 1.7579e-01, 1.8148e-01, 1.8345e-01, 1.5366e-01,\n",
      "         2.5011e-02, 8.4873e-08, 8.4873e-08, 8.4873e-08],\n",
      "        [1.1942e-01, 1.6112e-01, 1.7586e-01, 1.8157e-01, 1.8356e-01, 1.5359e-01,\n",
      "         2.4883e-02, 8.4300e-08, 8.4300e-08, 8.4300e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84.00, Train Loss: 2.84, Val Loss: 11.91, Train BLEU: 12.25, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中 的 生命 大卫 <UNK> <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: life in the deep oceans <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> life in the deep . . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.9398e-01, 3.4498e-01, 3.1917e-01, 1.3651e-01, 5.3489e-03, 4.1686e-08,\n",
      "         1.0803e-07, 1.1435e-11, 1.1435e-11, 1.1435e-11],\n",
      "        [1.6655e-01, 3.1076e-01, 3.1999e-01, 1.8402e-01, 1.8674e-02, 2.1631e-06,\n",
      "         4.9692e-06, 1.0425e-09, 1.0425e-09, 1.0425e-09],\n",
      "        [1.7199e-01, 2.6750e-01, 2.8476e-01, 2.1948e-01, 5.6120e-02, 5.3917e-05,\n",
      "         1.0934e-04, 2.2813e-08, 2.2813e-08, 2.2813e-08],\n",
      "        [1.7401e-01, 2.5313e-01, 2.7100e-01, 2.2664e-01, 7.4763e-02, 1.5989e-04,\n",
      "         2.9693e-04, 8.5495e-08, 8.5495e-08, 8.5495e-08],\n",
      "        [1.7283e-01, 2.5131e-01, 2.7076e-01, 2.2847e-01, 7.6110e-02, 1.8106e-04,\n",
      "         3.2631e-04, 1.0485e-07, 1.0485e-07, 1.0485e-07],\n",
      "        [1.7364e-01, 2.5167e-01, 2.7057e-01, 2.2742e-01, 7.6200e-02, 1.7706e-04,\n",
      "         3.2274e-04, 9.2434e-08, 9.2434e-08, 9.2434e-08],\n",
      "        [1.7415e-01, 2.5293e-01, 2.7187e-01, 2.2644e-01, 7.4126e-02, 1.6782e-04,\n",
      "         3.0674e-04, 8.1392e-08, 8.1392e-08, 8.1392e-08],\n",
      "        [1.7430e-01, 2.5309e-01, 2.7211e-01, 2.2617e-01, 7.3859e-02, 1.6966e-04,\n",
      "         3.0935e-04, 8.1507e-08, 8.1507e-08, 8.1507e-08],\n",
      "        [1.7434e-01, 2.5306e-01, 2.7210e-01, 2.2610e-01, 7.3911e-02, 1.7117e-04,\n",
      "         3.1205e-04, 8.2221e-08, 8.2221e-08, 8.2221e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把 书 放在 食品 杂货 袋中 这样 别人 就\n",
      "Reference: we would cover our books in grocery bags so\n",
      "Model: <SOS> and of the the the , the the the\n",
      "Attention Weights: tensor([[0.0442, 0.0988, 0.1173, 0.1247, 0.1244, 0.1234, 0.1187, 0.1101, 0.0937,\n",
      "         0.0447],\n",
      "        [0.0472, 0.0949, 0.1121, 0.1194, 0.1200, 0.1199, 0.1169, 0.1107, 0.1003,\n",
      "         0.0585],\n",
      "        [0.0611, 0.0961, 0.1071, 0.1117, 0.1126, 0.1127, 0.1113, 0.1083, 0.1031,\n",
      "         0.0759],\n",
      "        [0.0646, 0.0959, 0.1056, 0.1096, 0.1106, 0.1108, 0.1099, 0.1076, 0.1041,\n",
      "         0.0813],\n",
      "        [0.0641, 0.0956, 0.1054, 0.1095, 0.1106, 0.1108, 0.1099, 0.1078, 0.1045,\n",
      "         0.0818],\n",
      "        [0.0636, 0.0955, 0.1055, 0.1097, 0.1108, 0.1110, 0.1101, 0.1079, 0.1045,\n",
      "         0.0815],\n",
      "        [0.0635, 0.0953, 0.1054, 0.1097, 0.1109, 0.1111, 0.1102, 0.1080, 0.1046,\n",
      "         0.0813],\n",
      "        [0.0636, 0.0954, 0.1055, 0.1098, 0.1109, 0.1112, 0.1102, 0.1080, 0.1045,\n",
      "         0.0810],\n",
      "        [0.0637, 0.0954, 0.1055, 0.1098, 0.1109, 0.1111, 0.1102, 0.1080, 0.1044,\n",
      "         0.0810]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 85.00, Train Loss: 2.82, Val Loss: 11.93, Train BLEU: 13.19, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 大家 想想 海洋 占 了 地球 球面 面积 的 75\n",
      "Reference: when you think about it , the oceans are\n",
      "Model: <SOS> when the the the , , , , ,\n",
      "Attention Weights: tensor([[0.0470, 0.1077, 0.1258, 0.1351, 0.1375, 0.1345, 0.1278, 0.1132, 0.0711,\n",
      "         0.0003],\n",
      "        [0.0573, 0.1046, 0.1201, 0.1270, 0.1295, 0.1284, 0.1249, 0.1165, 0.0881,\n",
      "         0.0035],\n",
      "        [0.0706, 0.1049, 0.1157, 0.1200, 0.1218, 0.1217, 0.1198, 0.1155, 0.0984,\n",
      "         0.0116],\n",
      "        [0.0733, 0.1045, 0.1144, 0.1183, 0.1201, 0.1201, 0.1187, 0.1153, 0.1008,\n",
      "         0.0146],\n",
      "        [0.0721, 0.1042, 0.1145, 0.1186, 0.1205, 0.1205, 0.1191, 0.1157, 0.1009,\n",
      "         0.0139],\n",
      "        [0.0718, 0.1041, 0.1146, 0.1188, 0.1207, 0.1207, 0.1193, 0.1159, 0.1008,\n",
      "         0.0134],\n",
      "        [0.0715, 0.1039, 0.1145, 0.1189, 0.1210, 0.1210, 0.1196, 0.1161, 0.1006,\n",
      "         0.0129],\n",
      "        [0.0714, 0.1040, 0.1147, 0.1191, 0.1212, 0.1212, 0.1198, 0.1161, 0.1003,\n",
      "         0.0124],\n",
      "        [0.0714, 0.1040, 0.1147, 0.1192, 0.1213, 0.1213, 0.1198, 0.1160, 0.1001,\n",
      "         0.0122]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6 岁 那年 塔利 塔利班 占领 阿富汗 并 规定\n",
      "Reference: you see , i was six when the taliban\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[6.8758e-02, 1.3655e-01, 1.5360e-01, 1.5440e-01, 1.4626e-01, 1.3949e-01,\n",
      "         1.2889e-01, 7.1616e-02, 4.3598e-04, 5.8722e-12],\n",
      "        [6.9800e-02, 1.2599e-01, 1.4230e-01, 1.4641e-01, 1.4438e-01, 1.4136e-01,\n",
      "         1.3511e-01, 9.0703e-02, 3.9560e-03, 1.2880e-09],\n",
      "        [8.2593e-02, 1.2028e-01, 1.3182e-01, 1.3588e-01, 1.3621e-01, 1.3584e-01,\n",
      "         1.3350e-01, 1.0831e-01, 1.5558e-02, 2.5469e-08],\n",
      "        [8.6692e-02, 1.1821e-01, 1.2826e-01, 1.3217e-01, 1.3301e-01, 1.3328e-01,\n",
      "         1.3201e-01, 1.1319e-01, 2.3176e-02, 1.0713e-07],\n",
      "        [8.5741e-02, 1.1764e-01, 1.2786e-01, 1.3201e-01, 1.3312e-01, 1.3365e-01,\n",
      "         1.3273e-01, 1.1424e-01, 2.3013e-02, 1.3253e-07],\n",
      "        [8.5248e-02, 1.1768e-01, 1.2804e-01, 1.3235e-01, 1.3352e-01, 1.3407e-01,\n",
      "         1.3315e-01, 1.1391e-01, 2.2039e-02, 1.0776e-07],\n",
      "        [8.4980e-02, 1.1793e-01, 1.2857e-01, 1.3295e-01, 1.3401e-01, 1.3448e-01,\n",
      "         1.3338e-01, 1.1273e-01, 2.0969e-02, 8.6736e-08],\n",
      "        [8.4792e-02, 1.1789e-01, 1.2864e-01, 1.3307e-01, 1.3416e-01, 1.3467e-01,\n",
      "         1.3356e-01, 1.1252e-01, 2.0708e-02, 8.4417e-08],\n",
      "        [8.4698e-02, 1.1787e-01, 1.2866e-01, 1.3311e-01, 1.3422e-01, 1.3474e-01,\n",
      "         1.3363e-01, 1.1246e-01, 2.0599e-02, 8.3870e-08]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 86.00, Train Loss: 2.79, Val Loss: 11.95, Train BLEU: 13.08, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 我们 将 用 一些 影片 来讲 讲述 一些 深海 海里\n",
      "Reference: and we &apos;re going to tell you some stories\n",
      "Model: <SOS> and of the the the , the the the\n",
      "Attention Weights: tensor([[0.0459, 0.0977, 0.1145, 0.1224, 0.1255, 0.1243, 0.1198, 0.1114, 0.0945,\n",
      "         0.0440],\n",
      "        [0.0508, 0.0925, 0.1083, 0.1172, 0.1204, 0.1200, 0.1171, 0.1118, 0.1010,\n",
      "         0.0609],\n",
      "        [0.0653, 0.0938, 0.1040, 0.1102, 0.1123, 0.1122, 0.1109, 0.1085, 0.1035,\n",
      "         0.0793],\n",
      "        [0.0687, 0.0937, 0.1028, 0.1084, 0.1103, 0.1103, 0.1094, 0.1077, 0.1043,\n",
      "         0.0845],\n",
      "        [0.0679, 0.0934, 0.1026, 0.1083, 0.1103, 0.1103, 0.1095, 0.1079, 0.1047,\n",
      "         0.0850],\n",
      "        [0.0674, 0.0933, 0.1026, 0.1085, 0.1105, 0.1106, 0.1097, 0.1081, 0.1048,\n",
      "         0.0846],\n",
      "        [0.0669, 0.0930, 0.1025, 0.1086, 0.1107, 0.1108, 0.1099, 0.1083, 0.1049,\n",
      "         0.0843],\n",
      "        [0.0668, 0.0929, 0.1025, 0.1087, 0.1108, 0.1110, 0.1100, 0.1084, 0.1050,\n",
      "         0.0840],\n",
      "        [0.0668, 0.0930, 0.1026, 0.1087, 0.1108, 0.1110, 0.1101, 0.1084, 0.1049,\n",
      "         0.0837]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 但是 我 那 受过 教育 的 母亲 成为 为了 一名\n",
      "Reference: but my educated mother became a teacher . <EOS>\n",
      "Model: <SOS> most of the the the the the the the\n",
      "Attention Weights: tensor([[2.8348e-01, 2.4018e-01, 3.4446e-02, 9.7483e-07, 6.0024e-05, 1.8442e-01,\n",
      "         2.5568e-01, 1.7300e-03, 2.7896e-11, 2.7896e-11],\n",
      "        [2.6137e-01, 2.7916e-01, 8.9019e-02, 5.2637e-05, 9.8689e-04, 1.5108e-01,\n",
      "         2.0893e-01, 9.4004e-03, 2.9323e-09, 2.9323e-09],\n",
      "        [2.2836e-01, 2.6500e-01, 1.4619e-01, 6.9229e-04, 5.8367e-03, 1.4134e-01,\n",
      "         1.8374e-01, 2.8847e-02, 4.0039e-08, 4.0039e-08],\n",
      "        [2.1740e-01, 2.5729e-01, 1.6454e-01, 1.6306e-03, 9.8036e-03, 1.3720e-01,\n",
      "         1.7374e-01, 3.8396e-02, 1.4074e-07, 1.4074e-07],\n",
      "        [2.1897e-01, 2.6103e-01, 1.6654e-01, 1.6537e-03, 9.5310e-03, 1.3365e-01,\n",
      "         1.7099e-01, 3.7639e-02, 1.7832e-07, 1.7832e-07],\n",
      "        [2.2002e-01, 2.6249e-01, 1.6649e-01, 1.5719e-03, 9.1262e-03, 1.3287e-01,\n",
      "         1.7070e-01, 3.6727e-02, 1.7082e-07, 1.7082e-07],\n",
      "        [2.2154e-01, 2.6268e-01, 1.6426e-01, 1.4473e-03, 8.6876e-03, 1.3405e-01,\n",
      "         1.7161e-01, 3.5725e-02, 1.3680e-07, 1.3680e-07],\n",
      "        [2.2284e-01, 2.6321e-01, 1.6221e-01, 1.3846e-03, 8.4205e-03, 1.3450e-01,\n",
      "         1.7208e-01, 3.5353e-02, 1.2708e-07, 1.2708e-07],\n",
      "        [2.2308e-01, 2.6320e-01, 1.6183e-01, 1.3885e-03, 8.3982e-03, 1.3452e-01,\n",
      "         1.7217e-01, 3.5425e-02, 1.2815e-07, 1.2815e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 87.00, Train Loss: 2.77, Val Loss: 11.95, Train BLEU: 12.99, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中 的 生命 大卫 <UNK> <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: life in the deep oceans <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> life in the deep . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.9038e-01, 3.4891e-01, 3.1967e-01, 1.3561e-01, 5.4393e-03, 4.1108e-08,\n",
      "         9.9690e-08, 1.2826e-11, 1.2826e-11, 1.2826e-11],\n",
      "        [1.6530e-01, 3.0995e-01, 3.1786e-01, 1.8632e-01, 2.0560e-02, 2.4334e-06,\n",
      "         5.3207e-06, 1.1119e-09, 1.1119e-09, 1.1119e-09],\n",
      "        [1.7127e-01, 2.6191e-01, 2.7884e-01, 2.2305e-01, 6.4724e-02, 7.4263e-05,\n",
      "         1.4238e-04, 2.6598e-08, 2.6598e-08, 2.6598e-08],\n",
      "        [1.7275e-01, 2.4566e-01, 2.6370e-01, 2.3025e-01, 8.6992e-02, 2.3660e-04,\n",
      "         4.1311e-04, 1.0813e-07, 1.0813e-07, 1.0813e-07],\n",
      "        [1.7105e-01, 2.4442e-01, 2.6440e-01, 2.3224e-01, 8.7204e-02, 2.5495e-04,\n",
      "         4.3084e-04, 1.3628e-07, 1.3628e-07, 1.3628e-07],\n",
      "        [1.7182e-01, 2.4519e-01, 2.6465e-01, 2.3117e-01, 8.6507e-02, 2.4239e-04,\n",
      "         4.1550e-04, 1.2037e-07, 1.2037e-07, 1.2037e-07],\n",
      "        [1.7239e-01, 2.4651e-01, 2.6592e-01, 2.3023e-01, 8.4323e-02, 2.3173e-04,\n",
      "         3.9809e-04, 1.0659e-07, 1.0659e-07, 1.0659e-07],\n",
      "        [1.7251e-01, 2.4670e-01, 2.6618e-01, 2.2998e-01, 8.3994e-02, 2.3293e-04,\n",
      "         3.9945e-04, 1.0579e-07, 1.0579e-07, 1.0579e-07],\n",
      "        [1.7254e-01, 2.4671e-01, 2.6620e-01, 2.2991e-01, 8.3994e-02, 2.3372e-04,\n",
      "         4.0098e-04, 1.0611e-07, 1.0611e-07, 1.0611e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在 一个 房屋 房屋里 屋里 我们 100 多 人\n",
      "Reference: the school was in a house , more than\n",
      "Model: <SOS> we of the the the , the the the\n",
      "Attention Weights: tensor([[0.0340, 0.0365, 0.1302, 0.1372, 0.1385, 0.1349, 0.1265, 0.1149, 0.0996,\n",
      "         0.0475],\n",
      "        [0.0447, 0.0532, 0.1180, 0.1257, 0.1277, 0.1260, 0.1208, 0.1145, 0.1052,\n",
      "         0.0643],\n",
      "        [0.0631, 0.0724, 0.1091, 0.1141, 0.1154, 0.1151, 0.1128, 0.1102, 0.1061,\n",
      "         0.0818],\n",
      "        [0.0666, 0.0763, 0.1066, 0.1114, 0.1126, 0.1127, 0.1110, 0.1094, 0.1066,\n",
      "         0.0867],\n",
      "        [0.0657, 0.0756, 0.1064, 0.1114, 0.1127, 0.1129, 0.1112, 0.1097, 0.1072,\n",
      "         0.0872],\n",
      "        [0.0644, 0.0744, 0.1068, 0.1120, 0.1133, 0.1135, 0.1117, 0.1100, 0.1074,\n",
      "         0.0865],\n",
      "        [0.0638, 0.0737, 0.1070, 0.1122, 0.1136, 0.1137, 0.1120, 0.1103, 0.1076,\n",
      "         0.0862],\n",
      "        [0.0635, 0.0732, 0.1072, 0.1124, 0.1138, 0.1139, 0.1121, 0.1103, 0.1076,\n",
      "         0.0859],\n",
      "        [0.0635, 0.0732, 0.1073, 0.1125, 0.1138, 0.1140, 0.1121, 0.1103, 0.1075,\n",
      "         0.0858]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 88.00, Train Loss: 2.75, Val Loss: 11.97, Train BLEU: 13.20, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 底下 这些 都 是 <UNK> 它们 上上 上上下下 上下 下下\n",
      "Reference: it &apos;s got these fishing <UNK> on the bottom\n",
      "Model: <SOS> it &apos;s got these these , , , ,\n",
      "Attention Weights: tensor([[9.0825e-02, 1.5825e-01, 8.9971e-02, 1.8387e-02, 1.7608e-06, 9.0157e-02,\n",
      "         1.0926e-01, 2.8153e-01, 1.6090e-01, 7.2269e-04],\n",
      "        [1.0253e-01, 1.6873e-01, 1.3092e-01, 5.5786e-02, 1.0420e-04, 8.6725e-02,\n",
      "         1.0695e-01, 2.0159e-01, 1.4218e-01, 4.4767e-03],\n",
      "        [1.0978e-01, 1.5554e-01, 1.4471e-01, 9.4375e-02, 1.2315e-03, 9.0436e-02,\n",
      "         1.0711e-01, 1.5178e-01, 1.2884e-01, 1.6196e-02],\n",
      "        [1.1027e-01, 1.4996e-01, 1.4779e-01, 1.0989e-01, 2.7506e-03, 8.9822e-02,\n",
      "         1.0492e-01, 1.3753e-01, 1.2413e-01, 2.2935e-02],\n",
      "        [1.1040e-01, 1.5188e-01, 1.5187e-01, 1.1449e-01, 2.8981e-03, 8.6585e-02,\n",
      "         1.0195e-01, 1.3419e-01, 1.2319e-01, 2.2544e-02],\n",
      "        [1.1052e-01, 1.5329e-01, 1.5310e-01, 1.1398e-01, 2.7496e-03, 8.5692e-02,\n",
      "         1.0110e-01, 1.3461e-01, 1.2336e-01, 2.1592e-02],\n",
      "        [1.1083e-01, 1.5424e-01, 1.5341e-01, 1.1277e-01, 2.5507e-03, 8.5423e-02,\n",
      "         1.0089e-01, 1.3548e-01, 1.2370e-01, 2.0694e-02],\n",
      "        [1.1105e-01, 1.5481e-01, 1.5298e-01, 1.1089e-01, 2.3943e-03, 8.5656e-02,\n",
      "         1.0102e-01, 1.3691e-01, 1.2417e-01, 2.0113e-02],\n",
      "        [1.1109e-01, 1.5498e-01, 1.5279e-01, 1.1030e-01, 2.3667e-03, 8.5758e-02,\n",
      "         1.0119e-01, 1.3726e-01, 1.2421e-01, 2.0060e-02]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 想 过 要 放弃 但 我 的 父亲 这时\n",
      "Reference: i would want to quit , but my father\n",
      "Model: <SOS> and of the the the , the the the\n",
      "Attention Weights: tensor([[0.0668, 0.1367, 0.1538, 0.1572, 0.1503, 0.1396, 0.1207, 0.0746, 0.0003,\n",
      "         0.0000],\n",
      "        [0.0665, 0.1258, 0.1440, 0.1502, 0.1475, 0.1409, 0.1292, 0.0931, 0.0025,\n",
      "         0.0003],\n",
      "        [0.0794, 0.1212, 0.1338, 0.1390, 0.1384, 0.1354, 0.1299, 0.1096, 0.0112,\n",
      "         0.0021],\n",
      "        [0.0857, 0.1187, 0.1289, 0.1334, 0.1335, 0.1319, 0.1288, 0.1154, 0.0191,\n",
      "         0.0046],\n",
      "        [0.0869, 0.1177, 0.1272, 0.1317, 0.1319, 0.1309, 0.1285, 0.1172, 0.0222,\n",
      "         0.0058],\n",
      "        [0.0859, 0.1171, 0.1268, 0.1314, 0.1320, 0.1312, 0.1295, 0.1189, 0.0217,\n",
      "         0.0056],\n",
      "        [0.0851, 0.1173, 0.1273, 0.1321, 0.1327, 0.1318, 0.1300, 0.1186, 0.0201,\n",
      "         0.0050],\n",
      "        [0.0850, 0.1175, 0.1277, 0.1326, 0.1331, 0.1322, 0.1301, 0.1179, 0.0192,\n",
      "         0.0048],\n",
      "        [0.0851, 0.1176, 0.1279, 0.1328, 0.1333, 0.1323, 0.1301, 0.1174, 0.0189,\n",
      "         0.0046]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 89.00, Train Loss: 2.72, Val Loss: 11.99, Train BLEU: 14.07, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一种 种群 栖 动物 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: it &apos;s a colonial animal . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a to . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[9.8413e-02, 1.7987e-01, 2.0363e-01, 2.0795e-01, 1.9933e-01, 1.1025e-01,\n",
      "         5.5208e-04, 9.9282e-12, 9.9282e-12, 9.9282e-12],\n",
      "        [1.0542e-01, 1.6713e-01, 1.8959e-01, 1.9783e-01, 1.9644e-01, 1.3692e-01,\n",
      "         6.6696e-03, 2.4669e-09, 2.4669e-09, 2.4669e-09],\n",
      "        [1.2017e-01, 1.5950e-01, 1.7474e-01, 1.8162e-01, 1.8327e-01, 1.5479e-01,\n",
      "         2.5911e-02, 5.1094e-08, 5.1094e-08, 5.1094e-08],\n",
      "        [1.2340e-01, 1.5613e-01, 1.6954e-01, 1.7608e-01, 1.7856e-01, 1.5901e-01,\n",
      "         3.7278e-02, 2.3075e-07, 2.3075e-07, 2.3075e-07],\n",
      "        [1.2146e-01, 1.5539e-01, 1.6969e-01, 1.7688e-01, 1.8020e-01, 1.6085e-01,\n",
      "         3.5537e-02, 2.8759e-07, 2.8759e-07, 2.8759e-07],\n",
      "        [1.2059e-01, 1.5588e-01, 1.7081e-01, 1.7827e-01, 1.8164e-01, 1.5998e-01,\n",
      "         3.2825e-02, 2.0428e-07, 2.0428e-07, 2.0428e-07],\n",
      "        [1.2037e-01, 1.5616e-01, 1.7137e-01, 1.7901e-01, 1.8240e-01, 1.5909e-01,\n",
      "         3.1602e-02, 1.7479e-07, 1.7479e-07, 1.7479e-07],\n",
      "        [1.2022e-01, 1.5618e-01, 1.7150e-01, 1.7921e-01, 1.8263e-01, 1.5894e-01,\n",
      "         3.1311e-02, 1.7094e-07, 1.7094e-07, 1.7094e-07],\n",
      "        [1.2013e-01, 1.5620e-01, 1.7158e-01, 1.7931e-01, 1.8275e-01, 1.5890e-01,\n",
      "         3.1125e-02, 1.6849e-07, 1.6849e-07, 1.6849e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 但是 我 那 受过 教育 的 母亲 成为 为了 一名\n",
      "Reference: but my educated mother became a teacher . <EOS>\n",
      "Model: <SOS> most of the the the the the the the\n",
      "Attention Weights: tensor([[2.7909e-01, 2.3923e-01, 3.5822e-02, 1.0372e-06, 5.1204e-05, 1.8381e-01,\n",
      "         2.6030e-01, 1.6897e-03, 3.1799e-11, 3.1799e-11],\n",
      "        [2.5842e-01, 2.7987e-01, 9.7119e-02, 6.8849e-05, 1.0756e-03, 1.4871e-01,\n",
      "         2.0443e-01, 1.0303e-02, 3.2654e-09, 3.2654e-09],\n",
      "        [2.2425e-01, 2.6179e-01, 1.5870e-01, 1.0696e-03, 7.1772e-03, 1.3749e-01,\n",
      "         1.7665e-01, 3.2870e-02, 4.9613e-08, 4.9613e-08],\n",
      "        [2.1341e-01, 2.5484e-01, 1.7706e-01, 2.4862e-03, 1.1885e-02, 1.3189e-01,\n",
      "         1.6573e-01, 4.2706e-02, 1.8540e-07, 1.8540e-07],\n",
      "        [2.1617e-01, 2.6061e-01, 1.7925e-01, 2.3565e-03, 1.0960e-02, 1.2727e-01,\n",
      "         1.6269e-01, 4.0691e-02, 2.2976e-07, 2.2976e-07],\n",
      "        [2.1745e-01, 2.6283e-01, 1.7933e-01, 2.1830e-03, 1.0266e-02, 1.2626e-01,\n",
      "         1.6238e-01, 3.9306e-02, 2.2118e-07, 2.2118e-07],\n",
      "        [2.1923e-01, 2.6389e-01, 1.7706e-01, 1.9431e-03, 9.5214e-03, 1.2723e-01,\n",
      "         1.6323e-01, 3.7882e-02, 1.7559e-07, 1.7559e-07],\n",
      "        [2.2049e-01, 2.6446e-01, 1.7499e-01, 1.8496e-03, 9.2062e-03, 1.2778e-01,\n",
      "         1.6372e-01, 3.7509e-02, 1.6037e-07, 1.6037e-07],\n",
      "        [2.2068e-01, 2.6443e-01, 1.7461e-01, 1.8504e-03, 9.1763e-03, 1.2784e-01,\n",
      "         1.6381e-01, 3.7597e-02, 1.6111e-07, 1.6111e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 90.00, Train Loss: 2.70, Val Loss: 11.99, Train BLEU: 14.07, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 其实 它们 都 是 由 单独 的 动物 结合 合在\n",
      "Reference: these are all individual animals banding together to make\n",
      "Model: <SOS> these these all these animals , , , ,\n",
      "Attention Weights: tensor([[5.6916e-02, 1.2705e-01, 1.4532e-01, 1.4987e-01, 1.4656e-01, 1.3794e-01,\n",
      "         1.2208e-01, 9.5811e-02, 1.8452e-02, 5.5293e-07],\n",
      "        [6.0215e-02, 1.1426e-01, 1.3049e-01, 1.3675e-01, 1.3708e-01, 1.3384e-01,\n",
      "         1.2807e-01, 1.1500e-01, 4.4241e-02, 5.3863e-05],\n",
      "        [7.2508e-02, 1.0976e-01, 1.2067e-01, 1.2553e-01, 1.2687e-01, 1.2640e-01,\n",
      "         1.2509e-01, 1.2059e-01, 7.1934e-02, 6.2755e-04],\n",
      "        [7.6376e-02, 1.0826e-01, 1.1778e-01, 1.2227e-01, 1.2382e-01, 1.2401e-01,\n",
      "         1.2377e-01, 1.2149e-01, 8.0910e-02, 1.3103e-03],\n",
      "        [7.5639e-02, 1.0767e-01, 1.1731e-01, 1.2188e-01, 1.2354e-01, 1.2394e-01,\n",
      "         1.2424e-01, 1.2260e-01, 8.1867e-02, 1.3225e-03],\n",
      "        [7.4975e-02, 1.0758e-01, 1.1740e-01, 1.2205e-01, 1.2373e-01, 1.2412e-01,\n",
      "         1.2461e-01, 1.2298e-01, 8.1281e-02, 1.2826e-03],\n",
      "        [7.4997e-02, 1.0767e-01, 1.1756e-01, 1.2229e-01, 1.2398e-01, 1.2434e-01,\n",
      "         1.2477e-01, 1.2288e-01, 8.0295e-02, 1.2244e-03],\n",
      "        [7.4955e-02, 1.0789e-01, 1.1787e-01, 1.2263e-01, 1.2429e-01, 1.2456e-01,\n",
      "         1.2483e-01, 1.2256e-01, 7.9242e-02, 1.1707e-03],\n",
      "        [7.4967e-02, 1.0812e-01, 1.1815e-01, 1.2291e-01, 1.2454e-01, 1.2472e-01,\n",
      "         1.2481e-01, 1.2226e-01, 7.8404e-02, 1.1234e-03]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 父亲 那 就是 他 他 是 他家 家族\n",
      "Reference: and my father -- that &apos;s him -- he\n",
      "Model: <SOS> and of the the the , , the the\n",
      "Attention Weights: tensor([[8.8815e-02, 1.5358e-01, 8.8348e-02, 1.8643e-02, 1.8480e-06, 9.0532e-02,\n",
      "         1.1067e-01, 2.8474e-01, 1.6394e-01, 7.2903e-04],\n",
      "        [1.0132e-01, 1.6432e-01, 1.3010e-01, 5.8093e-02, 1.2071e-04, 8.7199e-02,\n",
      "         1.0884e-01, 2.0135e-01, 1.4376e-01, 4.9047e-03],\n",
      "        [1.0893e-01, 1.5213e-01, 1.4393e-01, 9.8213e-02, 1.4853e-03, 9.0307e-02,\n",
      "         1.0821e-01, 1.4983e-01, 1.2902e-01, 1.7948e-02],\n",
      "        [1.0932e-01, 1.4737e-01, 1.4743e-01, 1.1389e-01, 3.2129e-03, 8.9032e-02,\n",
      "         1.0543e-01, 1.3558e-01, 1.2391e-01, 2.4825e-02],\n",
      "        [1.0949e-01, 1.5001e-01, 1.5215e-01, 1.1865e-01, 3.2408e-03, 8.5135e-02,\n",
      "         1.0203e-01, 1.3249e-01, 1.2301e-01, 2.3790e-02],\n",
      "        [1.0961e-01, 1.5159e-01, 1.5360e-01, 1.1819e-01, 3.0430e-03, 8.4034e-02,\n",
      "         1.0108e-01, 1.3293e-01, 1.2326e-01, 2.2674e-02],\n",
      "        [1.0988e-01, 1.5253e-01, 1.5411e-01, 1.1737e-01, 2.8515e-03, 8.3562e-02,\n",
      "         1.0074e-01, 1.3357e-01, 1.2353e-01, 2.1852e-02],\n",
      "        [1.1008e-01, 1.5322e-01, 1.5388e-01, 1.1563e-01, 2.6498e-03, 8.3624e-02,\n",
      "         1.0083e-01, 1.3498e-01, 1.2401e-01, 2.1089e-02],\n",
      "        [1.1010e-01, 1.5342e-01, 1.5370e-01, 1.1502e-01, 2.6058e-03, 8.3727e-02,\n",
      "         1.0100e-01, 1.3538e-01, 1.2406e-01, 2.0985e-02]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91.00, Train Loss: 2.67, Val Loss: 12.01, Train BLEU: 14.11, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 我们 得用 非常 特殊 的 仪器 才能 能到 到达 那个\n",
      "Reference: we have to have a very special technology to\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[0.0222, 0.0076, 0.1330, 0.1557, 0.1589, 0.1553, 0.1483, 0.0634, 0.1049,\n",
      "         0.0508],\n",
      "        [0.0420, 0.0274, 0.1196, 0.1339, 0.1375, 0.1373, 0.1355, 0.0840, 0.1090,\n",
      "         0.0738],\n",
      "        [0.0628, 0.0511, 0.1106, 0.1184, 0.1207, 0.1214, 0.1217, 0.0953, 0.1083,\n",
      "         0.0898],\n",
      "        [0.0661, 0.0557, 0.1085, 0.1157, 0.1180, 0.1189, 0.1195, 0.0963, 0.1080,\n",
      "         0.0932],\n",
      "        [0.0652, 0.0546, 0.1084, 0.1160, 0.1185, 0.1194, 0.1201, 0.0956, 0.1085,\n",
      "         0.0937],\n",
      "        [0.0633, 0.0521, 0.1089, 0.1172, 0.1198, 0.1208, 0.1214, 0.0947, 0.1089,\n",
      "         0.0929],\n",
      "        [0.0623, 0.0510, 0.1092, 0.1177, 0.1204, 0.1214, 0.1221, 0.0945, 0.1090,\n",
      "         0.0924],\n",
      "        [0.0615, 0.0496, 0.1096, 0.1184, 0.1211, 0.1220, 0.1226, 0.0941, 0.1091,\n",
      "         0.0918],\n",
      "        [0.0613, 0.0492, 0.1098, 0.1186, 0.1213, 0.1222, 0.1228, 0.0941, 0.1091,\n",
      "         0.0916]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 总是 担心 会 被 塔利 塔利班 发现 <EOS> <PAD>\n",
      "Reference: we always wondered what they knew about us .\n",
      "Model: <SOS> it &apos;s a to to to . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0222, 0.0076, 0.1330, 0.1557, 0.1589, 0.1553, 0.1483, 0.0634, 0.1049,\n",
      "         0.0508],\n",
      "        [0.0420, 0.0274, 0.1196, 0.1339, 0.1375, 0.1373, 0.1355, 0.0840, 0.1090,\n",
      "         0.0738],\n",
      "        [0.0628, 0.0511, 0.1106, 0.1184, 0.1207, 0.1214, 0.1217, 0.0953, 0.1083,\n",
      "         0.0898],\n",
      "        [0.0661, 0.0557, 0.1085, 0.1157, 0.1180, 0.1189, 0.1195, 0.0963, 0.1080,\n",
      "         0.0932],\n",
      "        [0.0652, 0.0546, 0.1084, 0.1160, 0.1185, 0.1194, 0.1201, 0.0956, 0.1085,\n",
      "         0.0937],\n",
      "        [0.0633, 0.0521, 0.1089, 0.1172, 0.1198, 0.1208, 0.1214, 0.0947, 0.1089,\n",
      "         0.0929],\n",
      "        [0.0623, 0.0510, 0.1092, 0.1177, 0.1204, 0.1214, 0.1221, 0.0945, 0.1090,\n",
      "         0.0924],\n",
      "        [0.0615, 0.0496, 0.1096, 0.1184, 0.1211, 0.1220, 0.1226, 0.0941, 0.1091,\n",
      "         0.0918],\n",
      "        [0.0613, 0.0492, 0.1098, 0.1186, 0.1213, 0.1222, 0.1228, 0.0941, 0.1091,\n",
      "         0.0916]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 92.00, Train Loss: 2.65, Val Loss: 12.03, Train BLEU: 14.38, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本 基本上 都 没有 被 开发 发过 但是 像\n",
      "Reference: it &apos;s mostly unexplored , and yet there are\n",
      "Model: <SOS> and of the the , , the the the\n",
      "Attention Weights: tensor([[0.0440, 0.1004, 0.1146, 0.1274, 0.1247, 0.1235, 0.1168, 0.1080, 0.0931,\n",
      "         0.0473],\n",
      "        [0.0546, 0.0957, 0.1098, 0.1161, 0.1164, 0.1157, 0.1126, 0.1083, 0.1009,\n",
      "         0.0699],\n",
      "        [0.0712, 0.0963, 0.1055, 0.1074, 0.1083, 0.1079, 0.1070, 0.1055, 0.1029,\n",
      "         0.0882],\n",
      "        [0.0731, 0.0957, 0.1045, 0.1059, 0.1070, 0.1067, 0.1061, 0.1051, 0.1036,\n",
      "         0.0923],\n",
      "        [0.0708, 0.0950, 0.1044, 0.1061, 0.1074, 0.1071, 0.1065, 0.1056, 0.1043,\n",
      "         0.0928],\n",
      "        [0.0684, 0.0945, 0.1048, 0.1069, 0.1082, 0.1079, 0.1072, 0.1061, 0.1045,\n",
      "         0.0916],\n",
      "        [0.0683, 0.0944, 0.1047, 0.1069, 0.1082, 0.1079, 0.1072, 0.1062, 0.1046,\n",
      "         0.0916],\n",
      "        [0.0679, 0.0944, 0.1048, 0.1072, 0.1085, 0.1082, 0.1074, 0.1063, 0.1045,\n",
      "         0.0909],\n",
      "        [0.0678, 0.0945, 0.1049, 0.1073, 0.1085, 0.1083, 0.1074, 0.1063, 0.1045,\n",
      "         0.0907]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 出身 阿富汗 边远 <UNK> 地区 有着 与 他人 不同\n",
      "Reference: a total maverick from a remote province of afghanistan\n",
      "Model: <SOS> we of the the the the the the the\n",
      "Attention Weights: tensor([[9.1726e-02, 1.8285e-01, 1.9681e-01, 9.5787e-02, 1.6309e-03, 1.5995e-01,\n",
      "         1.7299e-01, 9.7775e-02, 4.9050e-04, 1.0575e-11],\n",
      "        [9.6058e-02, 1.6096e-01, 1.8016e-01, 1.3211e-01, 1.3514e-02, 1.4079e-01,\n",
      "         1.5534e-01, 1.1452e-01, 6.5463e-03, 2.5205e-09],\n",
      "        [1.0416e-01, 1.4150e-01, 1.5612e-01, 1.4575e-01, 3.9840e-02, 1.2745e-01,\n",
      "         1.3791e-01, 1.2278e-01, 2.4496e-02, 5.3826e-08],\n",
      "        [1.0500e-01, 1.3589e-01, 1.4987e-01, 1.4728e-01, 5.0701e-02, 1.2221e-01,\n",
      "         1.3222e-01, 1.2375e-01, 3.3076e-02, 2.3474e-07],\n",
      "        [1.0337e-01, 1.3688e-01, 1.5308e-01, 1.5088e-01, 4.7676e-02, 1.2105e-01,\n",
      "         1.3268e-01, 1.2420e-01, 3.0178e-02, 2.6813e-07],\n",
      "        [1.0271e-01, 1.3746e-01, 1.5447e-01, 1.5215e-01, 4.5733e-02, 1.2087e-01,\n",
      "         1.3320e-01, 1.2449e-01, 2.8920e-02, 2.5792e-07],\n",
      "        [1.0248e-01, 1.3874e-01, 1.5629e-01, 1.5256e-01, 4.3071e-02, 1.2167e-01,\n",
      "         1.3415e-01, 1.2397e-01, 2.7046e-02, 1.9019e-07],\n",
      "        [1.0241e-01, 1.3954e-01, 1.5741e-01, 1.5235e-01, 4.1438e-02, 1.2239e-01,\n",
      "         1.3499e-01, 1.2348e-01, 2.6009e-02, 1.5799e-07],\n",
      "        [1.0234e-01, 1.3965e-01, 1.5760e-01, 1.5218e-01, 4.0944e-02, 1.2262e-01,\n",
      "         1.3534e-01, 1.2353e-01, 2.5800e-02, 1.5390e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 93.00, Train Loss: 2.63, Val Loss: 12.04, Train BLEU: 14.67, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: <UNK> 塞尔 <UNK> <UNK> 斯特 说 过 真正 的 探索\n",
      "Reference: marcel proust said , &quot; the true voyage of\n",
      "Model: <SOS> marcel proust said , , , , , the\n",
      "Attention Weights: tensor([[1.4753e-09, 9.8486e-10, 1.0811e-09, 3.9851e-09, 1.9940e-06, 1.9964e-02,\n",
      "         1.9201e-01, 2.9583e-01, 3.1056e-01, 1.8163e-01],\n",
      "        [2.5530e-08, 1.7214e-08, 1.8863e-08, 6.9420e-08, 2.1058e-05, 2.9308e-02,\n",
      "         1.8513e-01, 2.7890e-01, 3.0652e-01, 2.0012e-01],\n",
      "        [1.4978e-06, 1.0389e-06, 1.1348e-06, 3.8050e-06, 3.8993e-04, 5.3069e-02,\n",
      "         1.8741e-01, 2.5562e-01, 2.8146e-01, 2.2204e-01],\n",
      "        [8.6044e-06, 6.0979e-06, 6.5627e-06, 2.0385e-05, 1.1956e-03, 6.7362e-02,\n",
      "         1.8713e-01, 2.4315e-01, 2.6908e-01, 2.3204e-01],\n",
      "        [1.0506e-05, 7.4901e-06, 8.0468e-06, 2.4400e-05, 1.2753e-03, 6.5828e-02,\n",
      "         1.8496e-01, 2.4184e-01, 2.6953e-01, 2.3651e-01],\n",
      "        [1.1612e-05, 8.3206e-06, 8.9274e-06, 2.6536e-05, 1.3015e-03, 6.6329e-02,\n",
      "         1.8398e-01, 2.4064e-01, 2.6907e-01, 2.3863e-01],\n",
      "        [1.3472e-05, 9.6716e-06, 1.0374e-05, 3.0544e-05, 1.4052e-03, 6.7698e-02,\n",
      "         1.8386e-01, 2.3953e-01, 2.6795e-01, 2.3949e-01],\n",
      "        [1.4735e-05, 1.0585e-05, 1.1346e-05, 3.3238e-05, 1.4826e-03, 6.8597e-02,\n",
      "         1.8375e-01, 2.3888e-01, 2.6729e-01, 2.3993e-01],\n",
      "        [1.5514e-05, 1.1148e-05, 1.1949e-05, 3.4937e-05, 1.5296e-03, 6.9138e-02,\n",
      "         1.8373e-01, 2.3850e-01, 2.6688e-01, 2.4014e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 想 过 要 放弃 但 我 的 父亲 这时\n",
      "Reference: i would want to quit , but my father\n",
      "Model: <SOS> and of the the the , , the the\n",
      "Attention Weights: tensor([[6.4344e-02, 1.3744e-01, 1.5794e-01, 1.5985e-01, 1.5067e-01, 1.3929e-01,\n",
      "         1.1979e-01, 7.0429e-02, 2.3808e-04, 9.5915e-06],\n",
      "        [6.5373e-02, 1.2517e-01, 1.4528e-01, 1.5087e-01, 1.4708e-01, 1.4071e-01,\n",
      "         1.2981e-01, 9.2860e-02, 2.5582e-03, 2.8346e-04],\n",
      "        [7.9528e-02, 1.1977e-01, 1.3296e-01, 1.3789e-01, 1.3686e-01, 1.3457e-01,\n",
      "         1.3069e-01, 1.1228e-01, 1.2773e-02, 2.6846e-03],\n",
      "        [8.6166e-02, 1.1678e-01, 1.2683e-01, 1.3120e-01, 1.3108e-01, 1.3029e-01,\n",
      "         1.2896e-01, 1.1918e-01, 2.3148e-02, 6.3592e-03],\n",
      "        [8.7307e-02, 1.1552e-01, 1.2489e-01, 1.2920e-01, 1.2938e-01, 1.2902e-01,\n",
      "         1.2847e-01, 1.2108e-01, 2.7030e-02, 8.0971e-03],\n",
      "        [8.5368e-02, 1.1484e-01, 1.2475e-01, 1.2938e-01, 1.2991e-01, 1.2983e-01,\n",
      "         1.3009e-01, 1.2331e-01, 2.5206e-02, 7.3172e-03],\n",
      "        [8.4203e-02, 1.1498e-01, 1.2546e-01, 1.3032e-01, 1.3081e-01, 1.3066e-01,\n",
      "         1.3083e-01, 1.2319e-01, 2.3143e-02, 6.4065e-03],\n",
      "        [8.3866e-02, 1.1526e-01, 1.2602e-01, 1.3101e-01, 1.3143e-01, 1.3117e-01,\n",
      "         1.3112e-01, 1.2246e-01, 2.1729e-02, 5.9278e-03],\n",
      "        [8.3915e-02, 1.1554e-01, 1.2638e-01, 1.3136e-01, 1.3169e-01, 1.3134e-01,\n",
      "         1.3111e-01, 1.2183e-01, 2.1144e-02, 5.6961e-03]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 94.00, Train Loss: 2.60, Val Loss: 12.05, Train BLEU: 15.54, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 我 真 喜欢 这些 东西 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: i love that kind of stuff . <EOS> <PAD>\n",
      "Model: <SOS> it &apos;s a to about . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.2325e-01, 2.2716e-01, 2.5440e-01, 2.4951e-01, 1.4503e-01, 6.5899e-04,\n",
      "         1.5998e-11, 1.5998e-11, 1.5998e-11, 1.5998e-11],\n",
      "        [1.3388e-01, 2.0612e-01, 2.3223e-01, 2.3846e-01, 1.7907e-01, 1.0245e-02,\n",
      "         4.3257e-09, 4.3257e-09, 4.3257e-09, 4.3257e-09],\n",
      "        [1.4977e-01, 1.9171e-01, 2.0876e-01, 2.1611e-01, 1.9372e-01, 3.9923e-02,\n",
      "         1.0186e-07, 1.0186e-07, 1.0186e-07, 1.0186e-07],\n",
      "        [1.5125e-01, 1.8627e-01, 2.0193e-01, 2.0994e-01, 1.9658e-01, 5.4035e-02,\n",
      "         4.7945e-07, 4.7945e-07, 4.7945e-07, 4.7945e-07],\n",
      "        [1.4825e-01, 1.8613e-01, 2.0373e-01, 2.1312e-01, 1.9946e-01, 4.9313e-02,\n",
      "         5.3693e-07, 5.3693e-07, 5.3693e-07, 5.3693e-07],\n",
      "        [1.4715e-01, 1.8627e-01, 2.0457e-01, 2.1444e-01, 2.0033e-01, 4.7245e-02,\n",
      "         5.1774e-07, 5.1774e-07, 5.1774e-07, 5.1774e-07],\n",
      "        [1.4655e-01, 1.8709e-01, 2.0596e-01, 2.1603e-01, 2.0013e-01, 4.4243e-02,\n",
      "         3.8486e-07, 3.8486e-07, 3.8486e-07, 3.8486e-07],\n",
      "        [1.4632e-01, 1.8788e-01, 2.0715e-01, 2.1729e-01, 1.9923e-01, 4.2133e-02,\n",
      "         2.9967e-07, 2.9967e-07, 2.9967e-07, 2.9967e-07],\n",
      "        [1.4620e-01, 1.8799e-01, 2.0740e-01, 2.1760e-01, 1.9911e-01, 4.1702e-02,\n",
      "         2.8999e-07, 2.8999e-07, 2.8999e-07, 2.8999e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 不知 知道 那 意味 意味着 什么 但是 我 能\n",
      "Reference: i didn &apos;t know what it meant , but\n",
      "Model: <SOS> we of the the the the , the the\n",
      "Attention Weights: tensor([[0.0710, 0.1605, 0.1893, 0.1896, 0.1736, 0.1377, 0.0536, 0.0009, 0.0014,\n",
      "         0.0223],\n",
      "        [0.0788, 0.1308, 0.1515, 0.1601, 0.1577, 0.1476, 0.0981, 0.0128, 0.0136,\n",
      "         0.0489],\n",
      "        [0.0876, 0.1156, 0.1277, 0.1347, 0.1354, 0.1349, 0.1164, 0.0383, 0.0374,\n",
      "         0.0721],\n",
      "        [0.0875, 0.1122, 0.1233, 0.1302, 0.1317, 0.1334, 0.1205, 0.0443, 0.0420,\n",
      "         0.0750],\n",
      "        [0.0865, 0.1120, 0.1237, 0.1310, 0.1327, 0.1349, 0.1221, 0.0429, 0.0402,\n",
      "         0.0740],\n",
      "        [0.0859, 0.1121, 0.1241, 0.1316, 0.1334, 0.1358, 0.1227, 0.0420, 0.0391,\n",
      "         0.0732],\n",
      "        [0.0855, 0.1124, 0.1247, 0.1323, 0.1342, 0.1366, 0.1229, 0.0409, 0.0380,\n",
      "         0.0724],\n",
      "        [0.0847, 0.1135, 0.1266, 0.1345, 0.1362, 0.1383, 0.1228, 0.0377, 0.0351,\n",
      "         0.0704],\n",
      "        [0.0842, 0.1141, 0.1277, 0.1359, 0.1376, 0.1395, 0.1228, 0.0359, 0.0333,\n",
      "         0.0691]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 95.00, Train Loss: 2.58, Val Loss: 12.07, Train BLEU: 15.73, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 这位 是 比尔 <UNK> 我 是 大卫 <UNK>\n",
      "Reference: this is bill lange . i &apos;m dave gallo\n",
      "Model: <SOS> this is bill lange . . &apos;m &apos;m dave\n",
      "Attention Weights: tensor([[1.1864e-02, 4.7586e-06, 4.4490e-02, 9.3344e-02, 2.1182e-04, 4.5140e-06,\n",
      "         3.6887e-01, 4.3567e-01, 4.5546e-02, 1.5759e-06],\n",
      "        [1.8938e-02, 1.7597e-05, 5.8744e-02, 1.1466e-01, 5.2373e-04, 1.7810e-05,\n",
      "         3.2789e-01, 4.2153e-01, 5.7676e-02, 5.8799e-06],\n",
      "        [4.5027e-02, 2.6152e-04, 8.8279e-02, 1.4389e-01, 3.8029e-03, 2.6680e-04,\n",
      "         2.7276e-01, 3.4819e-01, 9.7419e-02, 9.8552e-05],\n",
      "        [6.3195e-02, 6.5208e-04, 1.0105e-01, 1.5862e-01, 7.3070e-03, 6.5609e-04,\n",
      "         2.4092e-01, 3.1033e-01, 1.1701e-01, 2.4980e-04],\n",
      "        [7.0116e-02, 8.5187e-04, 1.0260e-01, 1.6561e-01, 8.8675e-03, 8.4337e-04,\n",
      "         2.2479e-01, 3.0079e-01, 1.2519e-01, 3.3582e-04],\n",
      "        [7.1943e-02, 8.6365e-04, 1.0340e-01, 1.6840e-01, 9.0992e-03, 8.5188e-04,\n",
      "         2.2042e-01, 2.9700e-01, 1.2769e-01, 3.4236e-04],\n",
      "        [7.4398e-02, 9.5301e-04, 1.0443e-01, 1.7040e-01, 9.7790e-03, 9.3655e-04,\n",
      "         2.1581e-01, 2.9287e-01, 1.3003e-01, 3.8123e-04],\n",
      "        [7.5585e-02, 1.0081e-03, 1.0497e-01, 1.7107e-01, 1.0187e-02, 9.9044e-04,\n",
      "         2.1398e-01, 2.9073e-01, 1.3106e-01, 4.0482e-04],\n",
      "        [7.6152e-02, 1.0355e-03, 1.0520e-01, 1.7134e-01, 1.0387e-02, 1.0173e-03,\n",
      "         2.1312e-01, 2.8974e-01, 1.3158e-01, 4.1652e-04]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很 舒服 但 夏天 却 <UNK> <EOS> <PAD> <PAD>\n",
      "Reference: it was cozy in winter but extremely hot in\n",
      "Model: <SOS> life in the deep oceans <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0498, 0.1158, 0.1337, 0.1392, 0.1097, 0.0228, 0.1355, 0.1264, 0.1074,\n",
      "         0.0595],\n",
      "        [0.0633, 0.1017, 0.1172, 0.1227, 0.1144, 0.0566, 0.1181, 0.1155, 0.1085,\n",
      "         0.0820],\n",
      "        [0.0780, 0.0973, 0.1072, 0.1102, 0.1111, 0.0823, 0.1070, 0.1069, 0.1053,\n",
      "         0.0947],\n",
      "        [0.0786, 0.0961, 0.1057, 0.1087, 0.1110, 0.0865, 0.1051, 0.1057, 0.1051,\n",
      "         0.0974],\n",
      "        [0.0764, 0.0955, 0.1059, 0.1092, 0.1118, 0.0847, 0.1056, 0.1065, 0.1062,\n",
      "         0.0981],\n",
      "        [0.0737, 0.0953, 0.1067, 0.1106, 0.1128, 0.0811, 0.1068, 0.1077, 0.1074,\n",
      "         0.0978],\n",
      "        [0.0727, 0.0954, 0.1072, 0.1112, 0.1131, 0.0793, 0.1075, 0.1083, 0.1078,\n",
      "         0.0974],\n",
      "        [0.0725, 0.0956, 0.1074, 0.1114, 0.1131, 0.0785, 0.1078, 0.1085, 0.1080,\n",
      "         0.0972],\n",
      "        [0.0724, 0.0957, 0.1075, 0.1116, 0.1130, 0.0780, 0.1081, 0.1087, 0.1080,\n",
      "         0.0970]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 96.00, Train Loss: 2.56, Val Loss: 12.08, Train BLEU: 18.10, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: <UNK> 塞尔 <UNK> <UNK> 斯特 说 过 真正 的 探索\n",
      "Reference: marcel proust said , &quot; the true voyage of\n",
      "Model: <SOS> marcel proust said , , , , , the\n",
      "Attention Weights: tensor([[1.7602e-09, 1.1681e-09, 1.2898e-09, 4.7766e-09, 2.2242e-06, 1.9196e-02,\n",
      "         1.9087e-01, 2.9728e-01, 3.0889e-01, 1.8377e-01],\n",
      "        [3.2188e-08, 2.1421e-08, 2.3529e-08, 8.8738e-08, 2.6294e-05, 2.9792e-02,\n",
      "         1.8610e-01, 2.7845e-01, 3.0288e-01, 2.0275e-01],\n",
      "        [2.3632e-06, 1.6169e-06, 1.7693e-06, 6.0615e-06, 5.7574e-04, 5.7267e-02,\n",
      "         1.8788e-01, 2.5260e-01, 2.7645e-01, 2.2521e-01],\n",
      "        [1.4244e-05, 9.9777e-06, 1.0731e-05, 3.3655e-05, 1.7609e-03, 7.2534e-02,\n",
      "         1.8678e-01, 2.3940e-01, 2.6405e-01, 2.3541e-01],\n",
      "        [1.6312e-05, 1.1502e-05, 1.2344e-05, 3.7729e-05, 1.7956e-03, 7.0112e-02,\n",
      "         1.8415e-01, 2.3835e-01, 2.6518e-01, 2.4033e-01],\n",
      "        [1.7972e-05, 1.2730e-05, 1.3638e-05, 4.0791e-05, 1.8344e-03, 7.0763e-02,\n",
      "         1.8319e-01, 2.3714e-01, 2.6462e-01, 2.4236e-01],\n",
      "        [2.0995e-05, 1.4897e-05, 1.5943e-05, 4.7125e-05, 1.9870e-03, 7.2276e-02,\n",
      "         1.8308e-01, 2.3598e-01, 2.6342e-01, 2.4317e-01],\n",
      "        [2.3042e-05, 1.6359e-05, 1.7492e-05, 5.1404e-05, 2.1011e-03, 7.3286e-02,\n",
      "         1.8300e-01, 2.3531e-01, 2.6269e-01, 2.4351e-01],\n",
      "        [2.4148e-05, 1.7144e-05, 1.8326e-05, 5.3756e-05, 2.1601e-03, 7.3809e-02,\n",
      "         1.8302e-01, 2.3498e-01, 2.6229e-01, 2.4363e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天 要 走 不同 的 路线 这样 才 没有\n",
      "Reference: each day , we took a different route so\n",
      "Model: <SOS> and of the the , , the the the\n",
      "Attention Weights: tensor([[0.0446, 0.0997, 0.1183, 0.1252, 0.1247, 0.1233, 0.1167, 0.1064, 0.0934,\n",
      "         0.0477],\n",
      "        [0.0564, 0.0943, 0.1101, 0.1139, 0.1156, 0.1149, 0.1122, 0.1079, 0.1020,\n",
      "         0.0728],\n",
      "        [0.0737, 0.0951, 0.1044, 0.1055, 0.1073, 0.1069, 0.1064, 0.1050, 0.1037,\n",
      "         0.0920],\n",
      "        [0.0750, 0.0946, 0.1034, 0.1043, 0.1062, 0.1058, 0.1057, 0.1048, 0.1043,\n",
      "         0.0958],\n",
      "        [0.0717, 0.0936, 0.1035, 0.1049, 0.1069, 0.1066, 0.1064, 0.1056, 0.1052,\n",
      "         0.0955],\n",
      "        [0.0694, 0.0929, 0.1038, 0.1054, 0.1076, 0.1073, 0.1071, 0.1062, 0.1056,\n",
      "         0.0946],\n",
      "        [0.0688, 0.0929, 0.1039, 0.1057, 0.1079, 0.1076, 0.1073, 0.1064, 0.1057,\n",
      "         0.0939],\n",
      "        [0.0686, 0.0930, 0.1040, 0.1059, 0.1080, 0.1078, 0.1074, 0.1064, 0.1056,\n",
      "         0.0934],\n",
      "        [0.0686, 0.0930, 0.1040, 0.1059, 0.1080, 0.1078, 0.1074, 0.1063, 0.1056,\n",
      "         0.0933]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 97.00, Train Loss: 2.53, Val Loss: 12.10, Train BLEU: 18.10, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分 部分 的 动物 也 都 生活 在 海洋\n",
      "Reference: most of the animals are in the oceans .\n",
      "Model: <SOS> most of the the , the the the the\n",
      "Attention Weights: tensor([[0.0427, 0.0980, 0.1184, 0.1253, 0.1238, 0.1220, 0.1181, 0.1113, 0.0928,\n",
      "         0.0476],\n",
      "        [0.0575, 0.0971, 0.1095, 0.1136, 0.1146, 0.1131, 0.1116, 0.1090, 0.1011,\n",
      "         0.0729],\n",
      "        [0.0764, 0.0986, 0.1036, 0.1051, 0.1065, 0.1052, 0.1050, 0.1048, 0.1027,\n",
      "         0.0920],\n",
      "        [0.0775, 0.0981, 0.1027, 0.1040, 0.1056, 0.1044, 0.1043, 0.1045, 0.1033,\n",
      "         0.0957],\n",
      "        [0.0738, 0.0971, 0.1029, 0.1046, 0.1064, 0.1052, 0.1051, 0.1052, 0.1042,\n",
      "         0.0954],\n",
      "        [0.0713, 0.0966, 0.1032, 0.1052, 0.1070, 0.1059, 0.1058, 0.1058, 0.1047,\n",
      "         0.0944],\n",
      "        [0.0706, 0.0964, 0.1033, 0.1055, 0.1073, 0.1062, 0.1061, 0.1060, 0.1048,\n",
      "         0.0938],\n",
      "        [0.0704, 0.0965, 0.1035, 0.1057, 0.1074, 0.1063, 0.1062, 0.1061, 0.1047,\n",
      "         0.0933],\n",
      "        [0.0704, 0.0965, 0.1035, 0.1057, 0.1074, 0.1064, 0.1062, 0.1061, 0.1047,\n",
      "         0.0932]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 那 就是 她 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: there she is . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a to about . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[6.6310e-02, 1.2995e-01, 1.4207e-01, 1.4816e-01, 1.4990e-01, 1.4525e-01,\n",
      "         1.3256e-01, 8.5369e-02, 4.3736e-04, 9.4729e-12],\n",
      "        [7.4179e-02, 1.1993e-01, 1.3180e-01, 1.3839e-01, 1.4185e-01, 1.4166e-01,\n",
      "         1.3667e-01, 1.0784e-01, 7.6655e-03, 3.2677e-09],\n",
      "        [8.9802e-02, 1.1565e-01, 1.2318e-01, 1.2755e-01, 1.3022e-01, 1.3154e-01,\n",
      "         1.3093e-01, 1.1949e-01, 3.1634e-02, 1.0409e-07],\n",
      "        [9.2046e-02, 1.1353e-01, 1.2044e-01, 1.2451e-01, 1.2714e-01, 1.2885e-01,\n",
      "         1.2929e-01, 1.2216e-01, 4.2046e-02, 5.3595e-07],\n",
      "        [8.8680e-02, 1.1277e-01, 1.2073e-01, 1.2545e-01, 1.2852e-01, 1.3065e-01,\n",
      "         1.3162e-01, 1.2428e-01, 3.7310e-02, 5.4733e-07],\n",
      "        [8.7252e-02, 1.1262e-01, 1.2100e-01, 1.2600e-01, 1.2921e-01, 1.3142e-01,\n",
      "         1.3253e-01, 1.2487e-01, 3.5099e-02, 4.8446e-07],\n",
      "        [8.6478e-02, 1.1286e-01, 1.2151e-01, 1.2670e-01, 1.3002e-01, 1.3225e-01,\n",
      "         1.3326e-01, 1.2457e-01, 3.2360e-02, 3.3758e-07],\n",
      "        [8.6085e-02, 1.1303e-01, 1.2184e-01, 1.2715e-01, 1.3055e-01, 1.3278e-01,\n",
      "         1.3371e-01, 1.2412e-01, 3.0727e-02, 2.6486e-07],\n",
      "        [8.5938e-02, 1.1303e-01, 1.2189e-01, 1.2724e-01, 1.3067e-01, 1.3292e-01,\n",
      "         1.3387e-01, 1.2410e-01, 3.0336e-02, 2.5440e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 98.00, Train Loss: 2.51, Val Loss: 12.12, Train BLEU: 18.20, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 和 我们 合作 的 人们 帮 我们 找到 了 新\n",
      "Reference: people that have partnered with us have given us\n",
      "Model: <SOS> and of the the the , , the the\n",
      "Attention Weights: tensor([[0.0474, 0.0978, 0.1163, 0.1241, 0.1245, 0.1229, 0.1193, 0.1097, 0.0894,\n",
      "         0.0488],\n",
      "        [0.0595, 0.0932, 0.1084, 0.1129, 0.1147, 0.1137, 0.1131, 0.1092, 0.1003,\n",
      "         0.0750],\n",
      "        [0.0764, 0.0947, 0.1035, 0.1049, 0.1064, 0.1055, 0.1062, 0.1054, 0.1031,\n",
      "         0.0938],\n",
      "        [0.0776, 0.0943, 0.1027, 0.1039, 0.1054, 0.1046, 0.1054, 0.1050, 0.1037,\n",
      "         0.0973],\n",
      "        [0.0751, 0.0935, 0.1027, 0.1041, 0.1058, 0.1050, 0.1059, 0.1056, 0.1045,\n",
      "         0.0977],\n",
      "        [0.0724, 0.0926, 0.1028, 0.1047, 0.1066, 0.1058, 0.1067, 0.1062, 0.1051,\n",
      "         0.0972],\n",
      "        [0.0718, 0.0924, 0.1029, 0.1049, 0.1068, 0.1060, 0.1069, 0.1065, 0.1052,\n",
      "         0.0967],\n",
      "        [0.0714, 0.0923, 0.1029, 0.1050, 0.1070, 0.1062, 0.1071, 0.1066, 0.1053,\n",
      "         0.0964],\n",
      "        [0.0709, 0.0923, 0.1030, 0.1053, 0.1072, 0.1065, 0.1073, 0.1067, 0.1052,\n",
      "         0.0957]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 永远 不会 忘记 那个 早晨 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: a morning that i will never forget . <EOS>\n",
      "Model: <SOS> it &apos;s a to about . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0562, 0.1249, 0.1458, 0.1540, 0.1527, 0.1514, 0.1427, 0.0718, 0.0003,\n",
      "         0.0000],\n",
      "        [0.0731, 0.1177, 0.1337, 0.1419, 0.1412, 0.1422, 0.1406, 0.1008, 0.0072,\n",
      "         0.0016],\n",
      "        [0.0899, 0.1147, 0.1240, 0.1294, 0.1285, 0.1295, 0.1309, 0.1159, 0.0270,\n",
      "         0.0101],\n",
      "        [0.0889, 0.1141, 0.1238, 0.1293, 0.1284, 0.1295, 0.1311, 0.1169, 0.0275,\n",
      "         0.0106],\n",
      "        [0.0859, 0.1146, 0.1258, 0.1319, 0.1311, 0.1321, 0.1334, 0.1158, 0.0216,\n",
      "         0.0078],\n",
      "        [0.0854, 0.1149, 0.1264, 0.1326, 0.1320, 0.1330, 0.1340, 0.1151, 0.0198,\n",
      "         0.0069],\n",
      "        [0.0854, 0.1151, 0.1266, 0.1329, 0.1323, 0.1333, 0.1341, 0.1146, 0.0190,\n",
      "         0.0066],\n",
      "        [0.0854, 0.1152, 0.1267, 0.1330, 0.1324, 0.1334, 0.1342, 0.1145, 0.0188,\n",
      "         0.0065],\n",
      "        [0.0854, 0.1152, 0.1267, 0.1330, 0.1324, 0.1334, 0.1342, 0.1145, 0.0187,\n",
      "         0.0065]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99.00, Train Loss: 2.49, Val Loss: 12.14, Train BLEU: 20.07, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 还有 前面 的 这个 是 推进 引擎 它 一会 一会儿\n",
      "Reference: and it &apos;s got these jet thrusters up in\n",
      "Model: <SOS> and it &apos;s got these , , , ,\n",
      "Attention Weights: tensor([[6.5814e-02, 1.3908e-01, 1.5639e-01, 1.6082e-01, 1.5119e-01, 1.4081e-01,\n",
      "         1.1921e-01, 6.6476e-02, 2.0146e-04, 9.2932e-06],\n",
      "        [6.7408e-02, 1.2536e-01, 1.4255e-01, 1.5036e-01, 1.4624e-01, 1.4153e-01,\n",
      "         1.3057e-01, 9.2858e-02, 2.7737e-03, 3.4894e-04],\n",
      "        [8.1673e-02, 1.1816e-01, 1.2922e-01, 1.3543e-01, 1.3455e-01, 1.3391e-01,\n",
      "         1.3159e-01, 1.1545e-01, 1.6068e-02, 3.9615e-03],\n",
      "        [8.8462e-02, 1.1401e-01, 1.2203e-01, 1.2707e-01, 1.2709e-01, 1.2775e-01,\n",
      "         1.2834e-01, 1.2262e-01, 3.1840e-02, 1.0784e-02],\n",
      "        [8.9529e-02, 1.1230e-01, 1.1967e-01, 1.2445e-01, 1.2472e-01, 1.2571e-01,\n",
      "         1.2714e-01, 1.2445e-01, 3.7832e-02, 1.4187e-02],\n",
      "        [8.7030e-02, 1.1173e-01, 1.1984e-01, 1.2509e-01, 1.2571e-01, 1.2705e-01,\n",
      "         1.2953e-01, 1.2767e-01, 3.4271e-02, 1.2071e-02],\n",
      "        [8.5572e-02, 1.1207e-01, 1.2083e-01, 1.2645e-01, 1.2696e-01, 1.2832e-01,\n",
      "         1.3081e-01, 1.2798e-01, 3.0856e-02, 1.0152e-02],\n",
      "        [8.5340e-02, 1.1269e-01, 1.2175e-01, 1.2754e-01, 1.2789e-01, 1.2911e-01,\n",
      "         1.3129e-01, 1.2693e-01, 2.8395e-02, 9.0698e-03],\n",
      "        [8.5351e-02, 1.1310e-01, 1.2226e-01, 1.2809e-01, 1.2836e-01, 1.2948e-01,\n",
      "         1.3144e-01, 1.2615e-01, 2.7238e-02, 8.5316e-03]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 但是 我 那 受过 教育 的 母亲 成为 为了 一名\n",
      "Reference: but my educated mother became a teacher . <EOS>\n",
      "Model: <SOS> most of the the the , the the the\n",
      "Attention Weights: tensor([[2.9697e-01, 2.3845e-01, 3.9829e-02, 1.4260e-06, 2.8867e-05, 1.6369e-01,\n",
      "         2.5936e-01, 1.6764e-03, 5.0387e-11, 5.0387e-11],\n",
      "        [2.7093e-01, 2.9465e-01, 1.1737e-01, 1.1160e-04, 9.1011e-04, 1.2370e-01,\n",
      "         1.8085e-01, 1.1474e-02, 4.1551e-09, 4.1551e-09],\n",
      "        [2.2095e-01, 2.7004e-01, 1.9415e-01, 2.7867e-03, 9.5611e-03, 1.1310e-01,\n",
      "         1.4809e-01, 4.1331e-02, 9.6013e-08, 9.6013e-08],\n",
      "        [2.0913e-01, 2.6387e-01, 2.1211e-01, 6.0824e-03, 1.5544e-02, 1.0654e-01,\n",
      "         1.3617e-01, 5.0553e-02, 4.5192e-07, 4.5192e-07],\n",
      "        [2.1462e-01, 2.7653e-01, 2.1741e-01, 4.8063e-03, 1.2384e-02, 9.8765e-02,\n",
      "         1.3116e-01, 4.4319e-02, 4.7862e-07, 4.7862e-07],\n",
      "        [2.1667e-01, 2.8036e-01, 2.1795e-01, 4.2045e-03, 1.0983e-02, 9.7105e-02,\n",
      "         1.3074e-01, 4.1991e-02, 4.5176e-07, 4.5176e-07],\n",
      "        [2.2005e-01, 2.8294e-01, 2.1436e-01, 3.4114e-03, 9.4419e-03, 9.8031e-02,\n",
      "         1.3222e-01, 3.9542e-02, 3.3765e-07, 3.3765e-07],\n",
      "        [2.2155e-01, 2.8275e-01, 2.1173e-01, 3.2038e-03, 8.9905e-03, 9.9348e-02,\n",
      "         1.3327e-01, 3.9159e-02, 2.9242e-07, 2.9242e-07],\n",
      "        [2.2199e-01, 2.8279e-01, 2.1085e-01, 3.1410e-03, 8.8656e-03, 9.9674e-02,\n",
      "         1.3356e-01, 3.9125e-02, 2.8093e-07, 2.8093e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 100.00, Train Loss: 2.46, Val Loss: 12.15, Train BLEU: 22.53, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 我们 用 的 是 深海 潜水 潜水艇 <UNK> 号 和\n",
      "Reference: we use the submarine alvin and we use cameras\n",
      "Model: <SOS> we use the the alvin the the the .\n",
      "Attention Weights: tensor([[1.2443e-01, 2.4791e-01, 2.6965e-01, 2.0919e-01, 8.3732e-02, 1.0464e-02,\n",
      "         2.2113e-06, 1.5301e-07, 1.7675e-02, 3.6945e-02],\n",
      "        [1.1473e-01, 1.9283e-01, 2.1833e-01, 2.0457e-01, 1.4267e-01, 4.9365e-02,\n",
      "         2.6759e-04, 3.9392e-05, 2.8616e-02, 4.8587e-02],\n",
      "        [1.1394e-01, 1.4995e-01, 1.6530e-01, 1.7078e-01, 1.6618e-01, 1.0889e-01,\n",
      "         5.3010e-03, 1.2128e-03, 4.9715e-02, 6.8738e-02],\n",
      "        [1.0983e-01, 1.4052e-01, 1.5572e-01, 1.6570e-01, 1.7265e-01, 1.2593e-01,\n",
      "         8.9349e-03, 2.4391e-03, 5.0408e-02, 6.7873e-02],\n",
      "        [1.0747e-01, 1.4093e-01, 1.5829e-01, 1.7041e-01, 1.7822e-01, 1.2667e-01,\n",
      "         7.7209e-03, 2.0123e-03, 4.5306e-02, 6.2974e-02],\n",
      "        [1.0630e-01, 1.4236e-01, 1.6153e-01, 1.7501e-01, 1.8153e-01, 1.2408e-01,\n",
      "         6.3855e-03, 1.6043e-03, 4.1678e-02, 5.9530e-02],\n",
      "        [1.0625e-01, 1.4279e-01, 1.6218e-01, 1.7561e-01, 1.8179e-01, 1.2350e-01,\n",
      "         6.1741e-03, 1.5504e-03, 4.1217e-02, 5.8933e-02],\n",
      "        [1.0649e-01, 1.4336e-01, 1.6284e-01, 1.7605e-01, 1.8140e-01, 1.2256e-01,\n",
      "         5.8843e-03, 1.4543e-03, 4.1165e-02, 5.8796e-02],\n",
      "        [1.0678e-01, 1.4453e-01, 1.6432e-01, 1.7728e-01, 1.8071e-01, 1.2025e-01,\n",
      "         5.3636e-03, 1.2856e-03, 4.0978e-02, 5.8508e-02]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 祖父 在 他 的 年代 是 位非 非凡\n",
      "Reference: my grandfather was an extraordinary man for his time\n",
      "Model: <SOS> we of the the the , , the the\n",
      "Attention Weights: tensor([[0.0575, 0.1149, 0.1343, 0.1440, 0.1406, 0.1330, 0.1156, 0.1000, 0.0599,\n",
      "         0.0003],\n",
      "        [0.0629, 0.1038, 0.1203, 0.1315, 0.1312, 0.1286, 0.1205, 0.1120, 0.0848,\n",
      "         0.0044],\n",
      "        [0.0778, 0.1007, 0.1100, 0.1167, 0.1174, 0.1177, 0.1160, 0.1141, 0.1045,\n",
      "         0.0251],\n",
      "        [0.0806, 0.0989, 0.1068, 0.1127, 0.1135, 0.1145, 0.1139, 0.1137, 0.1092,\n",
      "         0.0363],\n",
      "        [0.0783, 0.0975, 0.1060, 0.1123, 0.1135, 0.1148, 0.1150, 0.1155, 0.1121,\n",
      "         0.0349],\n",
      "        [0.0763, 0.0971, 0.1063, 0.1132, 0.1144, 0.1158, 0.1161, 0.1168, 0.1128,\n",
      "         0.0312],\n",
      "        [0.0759, 0.0973, 0.1068, 0.1140, 0.1152, 0.1165, 0.1166, 0.1170, 0.1120,\n",
      "         0.0287],\n",
      "        [0.0759, 0.0976, 0.1072, 0.1145, 0.1157, 0.1169, 0.1168, 0.1170, 0.1110,\n",
      "         0.0275],\n",
      "        [0.0759, 0.0976, 0.1073, 0.1145, 0.1157, 0.1170, 0.1168, 0.1170, 0.1108,\n",
      "         0.0274]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 101.00, Train Loss: 2.44, Val Loss: 12.16, Train BLEU: 23.59, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的 平均 深度 是 两英里 英里 <EOS> <PAD> <PAD>\n",
      "Reference: the average depth is about two miles . <EOS>\n",
      "Model: <SOS> it &apos;s a to about . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[9.9790e-02, 2.0075e-01, 2.1822e-01, 2.2491e-01, 1.9182e-01, 7.8112e-03,\n",
      "         5.6280e-02, 4.1479e-04, 2.0243e-11, 2.0243e-11],\n",
      "        [1.0735e-01, 1.6838e-01, 1.8541e-01, 1.9527e-01, 1.8745e-01, 4.4407e-02,\n",
      "         1.0085e-01, 1.0874e-02, 8.0748e-09, 8.0748e-09],\n",
      "        [1.1643e-01, 1.4478e-01, 1.5485e-01, 1.6160e-01, 1.6536e-01, 8.9466e-02,\n",
      "         1.2573e-01, 4.1783e-02, 2.5023e-07, 2.5023e-07],\n",
      "        [1.1616e-01, 1.3933e-01, 1.4889e-01, 1.5553e-01, 1.6145e-01, 9.8055e-02,\n",
      "         1.2875e-01, 5.1827e-02, 1.2243e-06, 1.2243e-06],\n",
      "        [1.1304e-01, 1.4087e-01, 1.5257e-01, 1.6088e-01, 1.6887e-01, 9.1360e-02,\n",
      "         1.2854e-01, 4.3882e-02, 1.1075e-06, 1.1075e-06],\n",
      "        [1.1217e-01, 1.4212e-01, 1.5465e-01, 1.6345e-01, 1.7161e-01, 8.7460e-02,\n",
      "         1.2802e-01, 4.0533e-02, 8.8884e-07, 8.8884e-07],\n",
      "        [1.1228e-01, 1.4378e-01, 1.5678e-01, 1.6592e-01, 1.7355e-01, 8.3866e-02,\n",
      "         1.2661e-01, 3.7205e-02, 5.8410e-07, 5.8410e-07],\n",
      "        [1.1237e-01, 1.4454e-01, 1.5769e-01, 1.6698e-01, 1.7429e-01, 8.1894e-02,\n",
      "         1.2623e-01, 3.6011e-02, 4.9432e-07, 4.9432e-07],\n",
      "        [1.1234e-01, 1.4477e-01, 1.5799e-01, 1.6732e-01, 1.7451e-01, 8.1230e-02,\n",
      "         1.2618e-01, 3.5663e-02, 4.7637e-07, 4.7637e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 因此 毫无 毫无疑问 无疑 疑问 他 的 孩子 应当 受到\n",
      "Reference: there was no question that his children would receive\n",
      "Model: <SOS> most of the the , the the the the\n",
      "Attention Weights: tensor([[7.8050e-02, 1.6255e-01, 1.7818e-01, 1.7949e-01, 1.6696e-01, 2.7006e-02,\n",
      "         1.3050e-01, 7.6819e-02, 4.4598e-04, 1.2568e-11],\n",
      "        [8.1854e-02, 1.3648e-01, 1.5215e-01, 1.5735e-01, 1.5794e-01, 6.7066e-02,\n",
      "         1.3477e-01, 1.0419e-01, 8.1918e-03, 4.0104e-09],\n",
      "        [9.4173e-02, 1.2138e-01, 1.3031e-01, 1.3422e-01, 1.3937e-01, 1.0238e-01,\n",
      "         1.2617e-01, 1.1723e-01, 3.4775e-02, 1.5675e-07],\n",
      "        [9.5346e-02, 1.1756e-01, 1.2579e-01, 1.2967e-01, 1.3580e-01, 1.0912e-01,\n",
      "         1.2292e-01, 1.1898e-01, 4.4815e-02, 8.6965e-07],\n",
      "        [9.1367e-02, 1.1759e-01, 1.2764e-01, 1.3297e-01, 1.4113e-01, 1.0652e-01,\n",
      "         1.2431e-01, 1.2059e-01, 3.7882e-02, 8.5659e-07],\n",
      "        [9.0346e-02, 1.1835e-01, 1.2914e-01, 1.3475e-01, 1.4329e-01, 1.0441e-01,\n",
      "         1.2491e-01, 1.2025e-01, 3.4558e-02, 6.1362e-07],\n",
      "        [9.0086e-02, 1.1923e-01, 1.3038e-01, 1.3612e-01, 1.4470e-01, 1.0248e-01,\n",
      "         1.2569e-01, 1.1939e-01, 3.1932e-02, 4.1077e-07],\n",
      "        [8.9950e-02, 1.1946e-01, 1.3070e-01, 1.3651e-01, 1.4500e-01, 1.0166e-01,\n",
      "         1.2623e-01, 1.1934e-01, 3.1164e-02, 3.6088e-07],\n",
      "        [8.9872e-02, 1.1952e-01, 1.3080e-01, 1.3663e-01, 1.4506e-01, 1.0131e-01,\n",
      "         1.2646e-01, 1.1945e-01, 3.0895e-02, 3.4908e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 102.00, Train Loss: 2.42, Val Loss: 12.17, Train BLEU: 23.64, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 其实 它们 都 是 由 单独 的 动物 结合 合在\n",
      "Reference: these are all individual animals banding together to make\n",
      "Model: <SOS> these are all individual animals , , , ,\n",
      "Attention Weights: tensor([[5.3608e-02, 1.2366e-01, 1.4240e-01, 1.4878e-01, 1.4877e-01, 1.4385e-01,\n",
      "         1.2533e-01, 9.8124e-02, 1.5477e-02, 3.8611e-07],\n",
      "        [5.9287e-02, 1.0995e-01, 1.2513e-01, 1.3242e-01, 1.3496e-01, 1.3537e-01,\n",
      "         1.3089e-01, 1.2302e-01, 4.8896e-02, 7.3472e-05],\n",
      "        [7.4174e-02, 1.0526e-01, 1.1399e-01, 1.1882e-01, 1.2131e-01, 1.2376e-01,\n",
      "         1.2483e-01, 1.2776e-01, 8.8553e-02, 1.5420e-03],\n",
      "        [7.8630e-02, 1.0342e-01, 1.1055e-01, 1.1475e-01, 1.1711e-01, 1.1993e-01,\n",
      "         1.2213e-01, 1.2792e-01, 1.0154e-01, 4.0159e-03],\n",
      "        [7.6370e-02, 1.0263e-01, 1.1033e-01, 1.1481e-01, 1.1731e-01, 1.2036e-01,\n",
      "         1.2319e-01, 1.3009e-01, 1.0169e-01, 3.2233e-03],\n",
      "        [7.4752e-02, 1.0253e-01, 1.1074e-01, 1.1544e-01, 1.1802e-01, 1.2112e-01,\n",
      "         1.2412e-01, 1.3105e-01, 9.9596e-02, 2.6470e-03],\n",
      "        [7.4667e-02, 1.0275e-01, 1.1116e-01, 1.1599e-01, 1.1859e-01, 1.2165e-01,\n",
      "         1.2450e-01, 1.3101e-01, 9.7288e-02, 2.3785e-03],\n",
      "        [7.4492e-02, 1.0313e-01, 1.1167e-01, 1.1653e-01, 1.1911e-01, 1.2208e-01,\n",
      "         1.2469e-01, 1.3073e-01, 9.5377e-02, 2.1930e-03],\n",
      "        [7.4347e-02, 1.0348e-01, 1.1212e-01, 1.1701e-01, 1.1958e-01, 1.2248e-01,\n",
      "         1.2487e-01, 1.3048e-01, 9.3643e-02, 1.9900e-03]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 因此 毫无 毫无疑问 无疑 疑问 他 的 孩子 应当 受到\n",
      "Reference: there was no question that his children would receive\n",
      "Model: <SOS> most of the the , the the the the\n",
      "Attention Weights: tensor([[7.8545e-02, 1.6347e-01, 1.7877e-01, 1.7992e-01, 1.6491e-01, 2.5656e-02,\n",
      "         1.3149e-01, 7.6771e-02, 4.6055e-04, 1.2880e-11],\n",
      "        [8.1686e-02, 1.3706e-01, 1.5266e-01, 1.5773e-01, 1.5714e-01, 6.5179e-02,\n",
      "         1.3587e-01, 1.0451e-01, 8.1568e-03, 3.9306e-09],\n",
      "        [9.3918e-02, 1.2135e-01, 1.3029e-01, 1.3424e-01, 1.3917e-01, 1.0177e-01,\n",
      "         1.2653e-01, 1.1756e-01, 3.5186e-02, 1.6284e-07],\n",
      "        [9.5055e-02, 1.1737e-01, 1.2563e-01, 1.2960e-01, 1.3574e-01, 1.0896e-01,\n",
      "         1.2304e-01, 1.1918e-01, 4.5428e-02, 9.3205e-07],\n",
      "        [9.1068e-02, 1.1745e-01, 1.2755e-01, 1.3298e-01, 1.4124e-01, 1.0626e-01,\n",
      "         1.2433e-01, 1.2073e-01, 3.8391e-02, 9.1791e-07],\n",
      "        [9.0055e-02, 1.1817e-01, 1.2902e-01, 1.3473e-01, 1.4339e-01, 1.0422e-01,\n",
      "         1.2484e-01, 1.2042e-01, 3.5160e-02, 6.6696e-07],\n",
      "        [8.9822e-02, 1.1905e-01, 1.3025e-01, 1.3608e-01, 1.4477e-01, 1.0224e-01,\n",
      "         1.2563e-01, 1.1960e-01, 3.2566e-02, 4.4948e-07],\n",
      "        [8.9701e-02, 1.1931e-01, 1.3062e-01, 1.3652e-01, 1.4509e-01, 1.0132e-01,\n",
      "         1.2622e-01, 1.1952e-01, 3.1709e-02, 3.8665e-07],\n",
      "        [8.9622e-02, 1.1938e-01, 1.3072e-01, 1.3664e-01, 1.4515e-01, 1.0093e-01,\n",
      "         1.2648e-01, 1.1965e-01, 3.1430e-02, 3.7278e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 103.00, Train Loss: 2.40, Val Loss: 12.18, Train BLEU: 23.74, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 地球 的 大部 大部分 部分 都 是 海水 <EOS> <PAD>\n",
      "Reference: most of the planet is ocean water . <EOS>\n",
      "Model: <SOS> it &apos;s the to is <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[6.7893e-02, 1.4375e-01, 1.5972e-01, 1.6013e-01, 1.4564e-01, 1.3477e-01,\n",
      "         1.2338e-01, 6.4393e-02, 3.2626e-04, 1.1799e-11],\n",
      "        [7.4500e-02, 1.2309e-01, 1.4100e-01, 1.4583e-01, 1.4221e-01, 1.3819e-01,\n",
      "         1.3372e-01, 9.5020e-02, 6.4570e-03, 3.6792e-09],\n",
      "        [9.1229e-02, 1.1434e-01, 1.2619e-01, 1.3027e-01, 1.2968e-01, 1.2980e-01,\n",
      "         1.2958e-01, 1.1608e-01, 3.2837e-02, 1.7013e-07],\n",
      "        [9.3114e-02, 1.1126e-01, 1.2231e-01, 1.2652e-01, 1.2640e-01, 1.2734e-01,\n",
      "         1.2828e-01, 1.2067e-01, 4.4098e-02, 1.0341e-06],\n",
      "        [8.8771e-02, 1.1020e-01, 1.2288e-01, 1.2799e-01, 1.2850e-01, 1.2992e-01,\n",
      "         1.3150e-01, 1.2322e-01, 3.7012e-02, 9.0582e-07],\n",
      "        [8.7264e-02, 1.1048e-01, 1.2374e-01, 1.2904e-01, 1.2958e-01, 1.3095e-01,\n",
      "         1.3255e-01, 1.2305e-01, 3.3356e-02, 6.5051e-07],\n",
      "        [8.6819e-02, 1.1106e-01, 1.2470e-01, 1.3005e-01, 1.3037e-01, 1.3168e-01,\n",
      "         1.3309e-01, 1.2151e-01, 3.0726e-02, 4.3294e-07],\n",
      "        [8.6573e-02, 1.1107e-01, 1.2466e-01, 1.3010e-01, 1.3060e-01, 1.3200e-01,\n",
      "         1.3345e-01, 1.2137e-01, 3.0181e-02, 3.9539e-07],\n",
      "        [8.6481e-02, 1.1104e-01, 1.2460e-01, 1.3007e-01, 1.3067e-01, 1.3211e-01,\n",
      "         1.3358e-01, 1.2138e-01, 3.0070e-02, 3.9007e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 她 两年 年前 退休 了 结果 却 把 我家 变成\n",
      "Reference: she retired two years ago , only to turn\n",
      "Model: <SOS> the of the the the the the the the\n",
      "Attention Weights: tensor([[1.2448e-01, 2.2721e-01, 2.5240e-01, 2.5158e-01, 1.4364e-01, 6.8410e-04,\n",
      "         2.2234e-11, 2.2234e-11, 2.2234e-11, 2.2234e-11],\n",
      "        [1.3412e-01, 2.0310e-01, 2.2868e-01, 2.3936e-01, 1.8274e-01, 1.2007e-02,\n",
      "         6.1107e-09, 6.1107e-09, 6.1107e-09, 6.1107e-09],\n",
      "        [1.5058e-01, 1.8590e-01, 2.0170e-01, 2.1155e-01, 1.9665e-01, 5.3627e-02,\n",
      "         2.4636e-07, 2.4636e-07, 2.4636e-07, 2.4636e-07],\n",
      "        [1.5130e-01, 1.7980e-01, 1.9439e-01, 2.0460e-01, 1.9876e-01, 7.1150e-02,\n",
      "         1.5633e-06, 1.5633e-06, 1.5633e-06, 1.5633e-06],\n",
      "        [1.4747e-01, 1.7966e-01, 1.9695e-01, 2.0936e-01, 2.0381e-01, 6.2733e-02,\n",
      "         1.5734e-06, 1.5734e-06, 1.5734e-06, 1.5734e-06],\n",
      "        [1.4634e-01, 1.8000e-01, 1.9822e-01, 2.1129e-01, 2.0529e-01, 5.8855e-02,\n",
      "         1.3778e-06, 1.3778e-06, 1.3778e-06, 1.3778e-06],\n",
      "        [1.4590e-01, 1.8101e-01, 1.9983e-01, 2.1326e-01, 2.0542e-01, 5.4580e-02,\n",
      "         9.7824e-07, 9.7824e-07, 9.7824e-07, 9.7824e-07],\n",
      "        [1.4609e-01, 1.8204e-01, 2.0122e-01, 2.1477e-01, 2.0429e-01, 5.1587e-02,\n",
      "         6.9336e-07, 6.9336e-07, 6.9336e-07, 6.9336e-07],\n",
      "        [1.4596e-01, 1.8212e-01, 2.0143e-01, 2.1514e-01, 2.0425e-01, 5.1085e-02,\n",
      "         6.6062e-07, 6.6062e-07, 6.6062e-07, 6.6062e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 104.00, Train Loss: 2.38, Val Loss: 12.20, Train BLEU: 24.35, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中 的 生命 大卫 <UNK> <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: life in the deep oceans <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> life in the deep . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.9586e-01, 3.6658e-01, 3.1511e-01, 1.1788e-01, 4.5700e-03, 6.1871e-08,\n",
      "         8.7924e-08, 2.7014e-11, 2.7014e-11, 2.7014e-11],\n",
      "        [1.6438e-01, 3.1003e-01, 3.1720e-01, 1.8626e-01, 2.2119e-02, 3.4251e-06,\n",
      "         4.6762e-06, 1.2420e-09, 1.2420e-09, 1.2420e-09],\n",
      "        [1.6376e-01, 2.3747e-01, 2.6164e-01, 2.3729e-01, 9.8993e-02, 3.8879e-04,\n",
      "         4.5713e-04, 6.5380e-08, 6.5380e-08, 6.5380e-08],\n",
      "        [1.6129e-01, 2.1398e-01, 2.3945e-01, 2.4351e-01, 1.3819e-01, 1.7506e-03,\n",
      "         1.8260e-03, 4.8534e-07, 4.8534e-07, 4.8534e-07],\n",
      "        [1.5603e-01, 2.1509e-01, 2.4528e-01, 2.5037e-01, 1.3093e-01, 1.1345e-03,\n",
      "         1.1657e-03, 4.7375e-07, 4.7375e-07, 4.7375e-07],\n",
      "        [1.5696e-01, 2.1819e-01, 2.4834e-01, 2.5014e-01, 1.2456e-01, 8.8447e-04,\n",
      "         9.2352e-04, 3.6148e-07, 3.6148e-07, 3.6148e-07],\n",
      "        [1.5808e-01, 2.1989e-01, 2.4987e-01, 2.4937e-01, 1.2112e-01, 8.1803e-04,\n",
      "         8.5442e-04, 3.1210e-07, 3.1210e-07, 3.1210e-07],\n",
      "        [1.5817e-01, 2.1982e-01, 2.4974e-01, 2.4916e-01, 1.2142e-01, 8.3364e-04,\n",
      "         8.7147e-04, 3.1576e-07, 3.1576e-07, 3.1576e-07],\n",
      "        [1.5818e-01, 2.1975e-01, 2.4964e-01, 2.4911e-01, 1.2161e-01, 8.4000e-04,\n",
      "         8.7914e-04, 3.1884e-07, 3.1884e-07, 3.1884e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 那 就是 她 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: there she is . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a to about . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[6.8752e-02, 1.3302e-01, 1.4149e-01, 1.4620e-01, 1.4843e-01, 1.4549e-01,\n",
      "         1.3258e-01, 8.3503e-02, 5.2389e-04, 1.2531e-11],\n",
      "        [7.4884e-02, 1.2071e-01, 1.3060e-01, 1.3644e-01, 1.4051e-01, 1.4205e-01,\n",
      "         1.3767e-01, 1.0832e-01, 8.8179e-03, 4.1032e-09],\n",
      "        [9.1616e-02, 1.1486e-01, 1.2105e-01, 1.2478e-01, 1.2762e-01, 1.2986e-01,\n",
      "         1.3004e-01, 1.2045e-01, 3.9722e-02, 2.0957e-07],\n",
      "        [9.3501e-02, 1.1229e-01, 1.1797e-01, 1.2148e-01, 1.2426e-01, 1.2692e-01,\n",
      "         1.2821e-01, 1.2315e-01, 5.2233e-02, 1.3755e-06],\n",
      "        [8.9267e-02, 1.1143e-01, 1.1830e-01, 1.2261e-01, 1.2600e-01, 1.2942e-01,\n",
      "         1.3143e-01, 1.2630e-01, 4.5235e-02, 1.2388e-06],\n",
      "        [8.7679e-02, 1.1138e-01, 1.1869e-01, 1.2330e-01, 1.2688e-01, 1.3048e-01,\n",
      "         1.3260e-01, 1.2714e-01, 4.1853e-02, 9.8197e-07],\n",
      "        [8.7005e-02, 1.1167e-01, 1.1921e-01, 1.2402e-01, 1.2774e-01, 1.3141e-01,\n",
      "         1.3347e-01, 1.2690e-01, 3.8568e-02, 6.5934e-07],\n",
      "        [8.6701e-02, 1.1186e-01, 1.1949e-01, 1.2441e-01, 1.2821e-01, 1.3193e-01,\n",
      "         1.3399e-01, 1.2656e-01, 3.6853e-02, 5.0580e-07],\n",
      "        [8.6598e-02, 1.1183e-01, 1.1950e-01, 1.2444e-01, 1.2826e-01, 1.3201e-01,\n",
      "         1.3412e-01, 1.2661e-01, 3.6629e-02, 4.9275e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 105.00, Train Loss: 2.35, Val Loss: 12.21, Train BLEU: 25.83, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本 基本上 都 没有 被 开发 发过 但是 像\n",
      "Reference: it &apos;s mostly unexplored , and yet there are\n",
      "Model: <SOS> and of the the , , the the the\n",
      "Attention Weights: tensor([[0.0430, 0.0944, 0.1099, 0.1241, 0.1265, 0.1244, 0.1216, 0.1118, 0.0960,\n",
      "         0.0484],\n",
      "        [0.0562, 0.0921, 0.1071, 0.1118, 0.1158, 0.1138, 0.1141, 0.1099, 0.1039,\n",
      "         0.0752],\n",
      "        [0.0760, 0.0951, 0.1044, 0.1028, 0.1060, 0.1043, 0.1058, 0.1047, 0.1046,\n",
      "         0.0963],\n",
      "        [0.0766, 0.0944, 0.1040, 0.1016, 0.1051, 0.1033, 0.1050, 0.1043, 0.1053,\n",
      "         0.1005],\n",
      "        [0.0727, 0.0928, 0.1037, 0.1019, 0.1058, 0.1040, 0.1059, 0.1053, 0.1065,\n",
      "         0.1014],\n",
      "        [0.0689, 0.0914, 0.1038, 0.1026, 0.1069, 0.1049, 0.1070, 0.1063, 0.1075,\n",
      "         0.1008],\n",
      "        [0.0690, 0.0914, 0.1038, 0.1026, 0.1069, 0.1049, 0.1070, 0.1063, 0.1075,\n",
      "         0.1006],\n",
      "        [0.0682, 0.0913, 0.1039, 0.1030, 0.1073, 0.1054, 0.1073, 0.1065, 0.1075,\n",
      "         0.0996],\n",
      "        [0.0679, 0.0913, 0.1039, 0.1031, 0.1074, 0.1055, 0.1075, 0.1066, 0.1075,\n",
      "         0.0992]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 面带 <UNK> <UNK> 笑容 这 很少 少见 因为 大部\n",
      "Reference: there was a big smile on his face which\n",
      "Model: <SOS> with vibrant video clips , , , , ,\n",
      "Attention Weights: tensor([[1.8801e-02, 1.2817e-05, 3.5423e-02, 9.7801e-02, 3.8298e-04, 1.0343e-05,\n",
      "         3.5781e-01, 4.3285e-01, 5.6900e-02, 5.2446e-06],\n",
      "        [2.5256e-02, 2.6266e-05, 4.3017e-02, 1.0720e-01, 6.4782e-04, 2.2559e-05,\n",
      "         3.2767e-01, 4.3019e-01, 6.5967e-02, 1.0049e-05],\n",
      "        [5.3088e-02, 3.9660e-04, 6.6991e-02, 1.2864e-01, 4.6137e-03, 3.5975e-04,\n",
      "         2.7299e-01, 3.6215e-01, 1.1060e-01, 1.7563e-04],\n",
      "        [7.1083e-02, 9.6062e-04, 7.9830e-02, 1.4108e-01, 8.5954e-03, 8.7926e-04,\n",
      "         2.4385e-01, 3.2227e-01, 1.3100e-01, 4.4187e-04],\n",
      "        [8.0234e-02, 1.2532e-03, 8.2667e-02, 1.4913e-01, 1.0583e-02, 1.1332e-03,\n",
      "         2.2281e-01, 3.0977e-01, 1.4183e-01, 5.9129e-04],\n",
      "        [8.2669e-02, 1.2247e-03, 8.3414e-02, 1.5302e-01, 1.0785e-02, 1.1014e-03,\n",
      "         2.1684e-01, 3.0436e-01, 1.4601e-01, 5.7860e-04],\n",
      "        [8.6809e-02, 1.3707e-03, 8.5570e-02, 1.5660e-01, 1.1858e-02, 1.2260e-03,\n",
      "         2.0967e-01, 2.9632e-01, 1.4992e-01, 6.5041e-04],\n",
      "        [8.8596e-02, 1.4614e-03, 8.6530e-02, 1.5780e-01, 1.2456e-02, 1.3064e-03,\n",
      "         2.0690e-01, 2.9281e-01, 1.5144e-01, 6.9510e-04],\n",
      "        [8.9240e-02, 1.4979e-03, 8.6841e-02, 1.5816e-01, 1.2689e-02, 1.3393e-03,\n",
      "         2.0588e-01, 2.9160e-01, 1.5203e-01, 7.1322e-04]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 106.00, Train Loss: 2.33, Val Loss: 12.22, Train BLEU: 25.84, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 其实 它们 都 是 由 单独 的 动物 结合 合在\n",
      "Reference: these are all individual animals banding together to make\n",
      "Model: <SOS> these are all individual animals , , , make\n",
      "Attention Weights: tensor([[5.1607e-02, 1.1985e-01, 1.4097e-01, 1.4902e-01, 1.5089e-01, 1.4837e-01,\n",
      "         1.2724e-01, 9.8136e-02, 1.3918e-02, 3.9477e-07],\n",
      "        [5.7372e-02, 1.0717e-01, 1.2358e-01, 1.3198e-01, 1.3582e-01, 1.3845e-01,\n",
      "         1.3247e-01, 1.2464e-01, 4.8429e-02, 9.1724e-05],\n",
      "        [7.3206e-02, 1.0291e-01, 1.1197e-01, 1.1734e-01, 1.2059e-01, 1.2481e-01,\n",
      "         1.2516e-01, 1.2948e-01, 9.2140e-02, 2.3887e-03],\n",
      "        [7.7709e-02, 1.0101e-01, 1.0827e-01, 1.1289e-01, 1.1589e-01, 1.2032e-01,\n",
      "         1.2210e-01, 1.2951e-01, 1.0597e-01, 6.3177e-03],\n",
      "        [7.4911e-02, 9.9938e-02, 1.0789e-01, 1.1289e-01, 1.1612e-01, 1.2098e-01,\n",
      "         1.2357e-01, 1.3251e-01, 1.0641e-01, 4.7806e-03],\n",
      "        [7.3124e-02, 9.9691e-02, 1.0821e-01, 1.1350e-01, 1.1685e-01, 1.2184e-01,\n",
      "         1.2467e-01, 1.3378e-01, 1.0445e-01, 3.8867e-03],\n",
      "        [7.3058e-02, 9.9894e-02, 1.0864e-01, 1.1407e-01, 1.1745e-01, 1.2237e-01,\n",
      "         1.2510e-01, 1.3378e-01, 1.0215e-01, 3.4834e-03],\n",
      "        [7.2879e-02, 1.0024e-01, 1.0913e-01, 1.1462e-01, 1.1799e-01, 1.2282e-01,\n",
      "         1.2535e-01, 1.3356e-01, 1.0021e-01, 3.2034e-03],\n",
      "        [7.2733e-02, 1.0061e-01, 1.0963e-01, 1.1514e-01, 1.1851e-01, 1.2328e-01,\n",
      "         1.2556e-01, 1.3334e-01, 9.8320e-02, 2.8845e-03]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 不知 知道 那 意味 意味着 什么 但是 我 能\n",
      "Reference: i didn &apos;t know what it meant , but\n",
      "Model: <SOS> most of the the the the , the the\n",
      "Attention Weights: tensor([[0.0771, 0.1643, 0.1889, 0.1946, 0.1741, 0.1240, 0.0512, 0.0013, 0.0015,\n",
      "         0.0230],\n",
      "        [0.0834, 0.1260, 0.1438, 0.1553, 0.1533, 0.1384, 0.1008, 0.0222, 0.0197,\n",
      "         0.0571],\n",
      "        [0.0871, 0.1057, 0.1164, 0.1253, 0.1271, 0.1261, 0.1194, 0.0610, 0.0527,\n",
      "         0.0791],\n",
      "        [0.0851, 0.1014, 0.1118, 0.1213, 0.1242, 0.1262, 0.1248, 0.0683, 0.0571,\n",
      "         0.0797],\n",
      "        [0.0838, 0.1014, 0.1126, 0.1230, 0.1264, 0.1291, 0.1276, 0.0652, 0.0534,\n",
      "         0.0776],\n",
      "        [0.0832, 0.1016, 0.1131, 0.1238, 0.1275, 0.1304, 0.1286, 0.0635, 0.0517,\n",
      "         0.0767],\n",
      "        [0.0828, 0.1019, 0.1138, 0.1248, 0.1286, 0.1315, 0.1292, 0.0618, 0.0501,\n",
      "         0.0756],\n",
      "        [0.0816, 0.1029, 0.1159, 0.1278, 0.1318, 0.1346, 0.1306, 0.0565, 0.0454,\n",
      "         0.0729],\n",
      "        [0.0813, 0.1037, 0.1171, 0.1294, 0.1335, 0.1359, 0.1307, 0.0540, 0.0430,\n",
      "         0.0715]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 107.00, Train Loss: 2.31, Val Loss: 12.24, Train BLEU: 26.01, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里 生物 的 多样 多样性 和 密度 要 比\n",
      "Reference: the biodiversity and the <UNK> in the ocean is\n",
      "Model: <SOS> the of the the , the the the the\n",
      "Attention Weights: tensor([[0.0496, 0.1063, 0.1228, 0.1202, 0.0753, 0.0096, 0.1560, 0.1553, 0.1276,\n",
      "         0.0774],\n",
      "        [0.0664, 0.0973, 0.1116, 0.1129, 0.0978, 0.0462, 0.1261, 0.1266, 0.1179,\n",
      "         0.0972],\n",
      "        [0.0815, 0.0944, 0.1039, 0.1061, 0.1081, 0.0837, 0.1069, 0.1074, 0.1058,\n",
      "         0.1022],\n",
      "        [0.0802, 0.0925, 0.1028, 0.1060, 0.1111, 0.0890, 0.1040, 0.1052, 0.1051,\n",
      "         0.1040],\n",
      "        [0.0769, 0.0913, 0.1028, 0.1070, 0.1124, 0.0858, 0.1046, 0.1065, 0.1070,\n",
      "         0.1057],\n",
      "        [0.0732, 0.0902, 0.1033, 0.1083, 0.1135, 0.0799, 0.1063, 0.1088, 0.1094,\n",
      "         0.1071],\n",
      "        [0.0724, 0.0904, 0.1038, 0.1089, 0.1132, 0.0770, 0.1071, 0.1097, 0.1102,\n",
      "         0.1072],\n",
      "        [0.0723, 0.0906, 0.1040, 0.1091, 0.1129, 0.0759, 0.1075, 0.1101, 0.1105,\n",
      "         0.1071],\n",
      "        [0.0720, 0.0906, 0.1041, 0.1092, 0.1126, 0.0749, 0.1080, 0.1106, 0.1109,\n",
      "         0.1072]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 那 就是 她 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: there she is . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a to about . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[6.8034e-02, 1.3437e-01, 1.4395e-01, 1.4738e-01, 1.4871e-01, 1.4451e-01,\n",
      "         1.3106e-01, 8.1499e-02, 5.0084e-04, 1.3610e-11],\n",
      "        [7.3154e-02, 1.2059e-01, 1.3168e-01, 1.3703e-01, 1.4081e-01, 1.4200e-01,\n",
      "         1.3771e-01, 1.0818e-01, 8.8480e-03, 4.5901e-09],\n",
      "        [9.0644e-02, 1.1428e-01, 1.2087e-01, 1.2443e-01, 1.2725e-01, 1.2961e-01,\n",
      "         1.3002e-01, 1.2127e-01, 4.1629e-02, 2.9560e-07],\n",
      "        [9.2289e-02, 1.1157e-01, 1.1761e-01, 1.2105e-01, 1.2394e-01, 1.2687e-01,\n",
      "         1.2851e-01, 1.2417e-01, 5.3989e-02, 2.0432e-06],\n",
      "        [8.7559e-02, 1.1066e-01, 1.1805e-01, 1.2236e-01, 1.2592e-01, 1.2975e-01,\n",
      "         1.3222e-01, 1.2757e-01, 4.5907e-02, 1.6711e-06],\n",
      "        [8.6037e-02, 1.1061e-01, 1.1847e-01, 1.2304e-01, 1.2677e-01, 1.3074e-01,\n",
      "         1.3329e-01, 1.2826e-01, 4.2777e-02, 1.3261e-06],\n",
      "        [8.5395e-02, 1.1089e-01, 1.1900e-01, 1.2373e-01, 1.2756e-01, 1.3155e-01,\n",
      "         1.3403e-01, 1.2800e-01, 3.9848e-02, 9.1392e-07],\n",
      "        [8.5087e-02, 1.1118e-01, 1.1939e-01, 1.2421e-01, 1.2810e-01, 1.3212e-01,\n",
      "         1.3455e-01, 1.2750e-01, 3.7851e-02, 6.5421e-07],\n",
      "        [8.4978e-02, 1.1115e-01, 1.1938e-01, 1.2423e-01, 1.2815e-01, 1.3221e-01,\n",
      "         1.3469e-01, 1.2756e-01, 3.7650e-02, 6.3689e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 108.00, Train Loss: 2.29, Val Loss: 12.25, Train BLEU: 26.12, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 当 你 站 在 海滩 上 或是 当 你 看到\n",
      "Reference: part of the problem , i think , is\n",
      "Model: <SOS> and of the the , , the the the\n",
      "Attention Weights: tensor([[0.0438, 0.0860, 0.1067, 0.1200, 0.1296, 0.1298, 0.1276, 0.1090, 0.0945,\n",
      "         0.0529],\n",
      "        [0.0551, 0.0840, 0.0987, 0.1095, 0.1192, 0.1180, 0.1199, 0.1108, 0.1041,\n",
      "         0.0807],\n",
      "        [0.0743, 0.0889, 0.0964, 0.1023, 0.1088, 0.1065, 0.1095, 0.1060, 0.1053,\n",
      "         0.1019],\n",
      "        [0.0747, 0.0881, 0.0953, 0.1011, 0.1078, 0.1054, 0.1088, 0.1061, 0.1064,\n",
      "         0.1064],\n",
      "        [0.0700, 0.0855, 0.0941, 0.1010, 0.1087, 0.1064, 0.1102, 0.1078, 0.1084,\n",
      "         0.1079],\n",
      "        [0.0665, 0.0837, 0.0934, 0.1012, 0.1096, 0.1074, 0.1115, 0.1091, 0.1097,\n",
      "         0.1078],\n",
      "        [0.0660, 0.0836, 0.0934, 0.1013, 0.1098, 0.1078, 0.1118, 0.1093, 0.1098,\n",
      "         0.1072],\n",
      "        [0.0658, 0.0836, 0.0936, 0.1015, 0.1100, 0.1080, 0.1120, 0.1094, 0.1097,\n",
      "         0.1065],\n",
      "        [0.0657, 0.0836, 0.0936, 0.1015, 0.1100, 0.1081, 0.1121, 0.1094, 0.1097,\n",
      "         0.1063]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11 岁 那年 记得 得有 一天 早晨 醒来 听见\n",
      "Reference: when i was 11 , i remember waking up\n",
      "Model: <SOS> most of the the the , the the the\n",
      "Attention Weights: tensor([[1.8928e-01, 3.6403e-01, 3.2209e-01, 1.1998e-01, 4.6199e-03, 7.4908e-08,\n",
      "         8.9332e-08, 3.2730e-11, 3.2730e-11, 3.2730e-11],\n",
      "        [1.5390e-01, 3.0519e-01, 3.2588e-01, 1.9270e-01, 2.2329e-02, 3.0100e-06,\n",
      "         3.4857e-06, 1.0524e-09, 1.0524e-09, 1.0524e-09],\n",
      "        [1.5088e-01, 2.3084e-01, 2.6511e-01, 2.4743e-01, 1.0494e-01, 4.0156e-04,\n",
      "         4.0394e-04, 6.5093e-08, 6.5093e-08, 6.5093e-08],\n",
      "        [1.4893e-01, 2.0675e-01, 2.4024e-01, 2.5294e-01, 1.4754e-01, 1.9001e-03,\n",
      "         1.6957e-03, 5.4359e-07, 5.4359e-07, 5.4359e-07],\n",
      "        [1.4404e-01, 2.0813e-01, 2.4643e-01, 2.5985e-01, 1.3926e-01, 1.2136e-03,\n",
      "         1.0652e-03, 5.2221e-07, 5.2221e-07, 5.2221e-07],\n",
      "        [1.4483e-01, 2.1044e-01, 2.4857e-01, 2.5977e-01, 1.3454e-01, 9.8267e-04,\n",
      "         8.7904e-04, 4.3086e-07, 4.3086e-07, 4.3086e-07],\n",
      "        [1.4670e-01, 2.1302e-01, 2.5076e-01, 2.5839e-01, 1.2946e-01, 8.8007e-04,\n",
      "         7.9094e-04, 3.4539e-07, 3.4539e-07, 3.4539e-07],\n",
      "        [1.4690e-01, 2.1297e-01, 2.5061e-01, 2.5804e-01, 1.2976e-01, 9.0278e-04,\n",
      "         8.1149e-04, 3.4880e-07, 3.4880e-07, 3.4880e-07],\n",
      "        [1.4688e-01, 2.1280e-01, 2.5042e-01, 2.5799e-01, 1.3017e-01, 9.1702e-04,\n",
      "         8.2462e-04, 3.5450e-07, 3.5450e-07, 3.5450e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 109.00, Train Loss: 2.27, Val Loss: 12.26, Train BLEU: 26.71, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的 平均 深度 是 两英里 英里 <EOS> <PAD> <PAD>\n",
      "Reference: the average depth is about two miles . <EOS>\n",
      "Model: <SOS> it &apos;s the to about . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.0963e-01, 2.1770e-01, 2.3168e-01, 2.3047e-01, 1.6445e-01, 3.9103e-03,\n",
      "         4.1815e-02, 3.4444e-04, 3.5305e-11, 3.5305e-11],\n",
      "        [1.1368e-01, 1.7398e-01, 1.8982e-01, 1.9709e-01, 1.7525e-01, 4.0346e-02,\n",
      "         9.6526e-02, 1.3310e-02, 1.6740e-08, 1.6740e-08],\n",
      "        [1.1784e-01, 1.4238e-01, 1.5154e-01, 1.5779e-01, 1.5911e-01, 9.3001e-02,\n",
      "         1.2591e-01, 5.2426e-02, 7.2137e-07, 7.2137e-07],\n",
      "        [1.1562e-01, 1.3573e-01, 1.4486e-01, 1.5184e-01, 1.5730e-01, 1.0328e-01,\n",
      "         1.2837e-01, 6.2990e-02, 3.7848e-06, 3.7848e-06],\n",
      "        [1.1249e-01, 1.3785e-01, 1.4984e-01, 1.5942e-01, 1.6721e-01, 9.4737e-02,\n",
      "         1.2658e-01, 5.1875e-02, 2.8780e-06, 2.8780e-06],\n",
      "        [1.1175e-01, 1.3907e-01, 1.5224e-01, 1.6266e-01, 1.7091e-01, 9.0467e-02,\n",
      "         1.2506e-01, 4.7845e-02, 2.2007e-06, 2.2007e-06],\n",
      "        [1.1221e-01, 1.4104e-01, 1.5477e-01, 1.6554e-01, 1.7291e-01, 8.6468e-02,\n",
      "         1.2286e-01, 4.4196e-02, 1.4197e-06, 1.4197e-06],\n",
      "        [1.1247e-01, 1.4214e-01, 1.5605e-01, 1.6697e-01, 1.7356e-01, 8.3715e-02,\n",
      "         1.2247e-01, 4.2622e-02, 1.1607e-06, 1.1607e-06],\n",
      "        [1.1246e-01, 1.4236e-01, 1.5634e-01, 1.6729e-01, 1.7368e-01, 8.3065e-02,\n",
      "         1.2249e-01, 4.2312e-02, 1.1266e-06, 1.1266e-06]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正 的 学校 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: a real school . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a to about . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0462, 0.0999, 0.1216, 0.1320, 0.1366, 0.1400, 0.1351, 0.1171, 0.0711,\n",
      "         0.0005],\n",
      "        [0.0692, 0.0995, 0.1137, 0.1158, 0.1190, 0.1261, 0.1232, 0.1174, 0.1003,\n",
      "         0.0158],\n",
      "        [0.0805, 0.0989, 0.1087, 0.1076, 0.1100, 0.1173, 0.1145, 0.1128, 0.1079,\n",
      "         0.0419],\n",
      "        [0.0790, 0.0975, 0.1081, 0.1069, 0.1096, 0.1173, 0.1145, 0.1135, 0.1101,\n",
      "         0.0434],\n",
      "        [0.0751, 0.0965, 0.1086, 0.1080, 0.1111, 0.1194, 0.1167, 0.1157, 0.1117,\n",
      "         0.0371],\n",
      "        [0.0739, 0.0962, 0.1090, 0.1087, 0.1119, 0.1202, 0.1176, 0.1165, 0.1120,\n",
      "         0.0339],\n",
      "        [0.0735, 0.0963, 0.1093, 0.1093, 0.1126, 0.1207, 0.1181, 0.1168, 0.1117,\n",
      "         0.0318],\n",
      "        [0.0732, 0.0965, 0.1096, 0.1098, 0.1131, 0.1211, 0.1185, 0.1171, 0.1113,\n",
      "         0.0299],\n",
      "        [0.0730, 0.0965, 0.1097, 0.1101, 0.1134, 0.1213, 0.1187, 0.1172, 0.1111,\n",
      "         0.0290]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 110.00, Train Loss: 2.24, Val Loss: 12.28, Train BLEU: 28.07, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 我们 用 的 是 深海 潜水 潜水艇 <UNK> 号 和\n",
      "Reference: we use the submarine alvin and we use cameras\n",
      "Model: <SOS> we use the submarine alvin alvin the the the\n",
      "Attention Weights: tensor([[1.2541e-01, 2.4320e-01, 2.7580e-01, 2.1930e-01, 8.6218e-02, 9.8254e-03,\n",
      "         2.7473e-06, 1.9772e-07, 1.2768e-02, 2.7476e-02],\n",
      "        [1.1105e-01, 1.8735e-01, 2.2009e-01, 2.1180e-01, 1.5278e-01, 5.3445e-02,\n",
      "         3.7740e-04, 5.4578e-05, 2.2392e-02, 4.0659e-02],\n",
      "        [1.0791e-01, 1.4081e-01, 1.5861e-01, 1.6910e-01, 1.7694e-01, 1.2723e-01,\n",
      "         1.0081e-02, 2.5136e-03, 4.3944e-02, 6.2863e-02],\n",
      "        [1.0200e-01, 1.2994e-01, 1.4740e-01, 1.6278e-01, 1.8382e-01, 1.4777e-01,\n",
      "         1.7256e-02, 5.1538e-03, 4.3625e-02, 6.0261e-02],\n",
      "        [9.8910e-02, 1.3002e-01, 1.5035e-01, 1.6882e-01, 1.9249e-01, 1.4974e-01,\n",
      "         1.4033e-02, 3.8588e-03, 3.7737e-02, 5.4037e-02],\n",
      "        [9.7948e-02, 1.3147e-01, 1.5392e-01, 1.7427e-01, 1.9658e-01, 1.4681e-01,\n",
      "         1.1521e-02, 3.0166e-03, 3.4181e-02, 5.0295e-02],\n",
      "        [9.7945e-02, 1.3187e-01, 1.5469e-01, 1.7514e-01, 1.9684e-01, 1.4585e-01,\n",
      "         1.1173e-02, 2.9165e-03, 3.3893e-02, 4.9685e-02],\n",
      "        [9.7997e-02, 1.3256e-01, 1.5578e-01, 1.7624e-01, 1.9721e-01, 1.4456e-01,\n",
      "         1.0385e-02, 2.6475e-03, 3.3456e-02, 4.9164e-02],\n",
      "        [9.8435e-02, 1.3370e-01, 1.5731e-01, 1.7755e-01, 1.9654e-01, 1.4205e-01,\n",
      "         9.4975e-03, 2.3376e-03, 3.3507e-02, 4.9066e-02]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天 要 走 不同 的 路线 这样 才 没有\n",
      "Reference: each day , we took a different route so\n",
      "Model: <SOS> and of the the , , the the the\n",
      "Attention Weights: tensor([[0.0409, 0.0895, 0.1128, 0.1245, 0.1282, 0.1281, 0.1227, 0.1081, 0.0939,\n",
      "         0.0512],\n",
      "        [0.0538, 0.0878, 0.1066, 0.1121, 0.1171, 0.1166, 0.1156, 0.1088, 0.1026,\n",
      "         0.0791],\n",
      "        [0.0749, 0.0926, 0.1028, 0.1024, 0.1064, 0.1053, 0.1066, 0.1041, 0.1036,\n",
      "         0.1014],\n",
      "        [0.0752, 0.0918, 0.1020, 0.1011, 0.1054, 0.1042, 0.1059, 0.1040, 0.1046,\n",
      "         0.1058],\n",
      "        [0.0696, 0.0892, 0.1014, 0.1014, 0.1064, 0.1053, 0.1072, 0.1056, 0.1066,\n",
      "         0.1073],\n",
      "        [0.0667, 0.0879, 0.1014, 0.1018, 0.1072, 0.1061, 0.1081, 0.1065, 0.1074,\n",
      "         0.1068],\n",
      "        [0.0664, 0.0879, 0.1014, 0.1021, 0.1074, 0.1064, 0.1083, 0.1066, 0.1074,\n",
      "         0.1060],\n",
      "        [0.0662, 0.0879, 0.1015, 0.1023, 0.1075, 0.1066, 0.1085, 0.1067, 0.1074,\n",
      "         0.1055],\n",
      "        [0.0662, 0.0879, 0.1015, 0.1023, 0.1075, 0.1066, 0.1085, 0.1067, 0.1074,\n",
      "         0.1054]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 111.00, Train Loss: 2.22, Val Loss: 12.29, Train BLEU: 27.63, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 还有 前面 的 这个 是 推进 引擎 它 一会 一会儿\n",
      "Reference: and it &apos;s got these jet thrusters up in\n",
      "Model: <SOS> and it &apos;s got these jet , , ,\n",
      "Attention Weights: tensor([[0.0618, 0.1305, 0.1533, 0.1630, 0.1562, 0.1466, 0.1243, 0.0641, 0.0002,\n",
      "         0.0000],\n",
      "        [0.0625, 0.1188, 0.1397, 0.1525, 0.1509, 0.1470, 0.1346, 0.0912, 0.0025,\n",
      "         0.0004],\n",
      "        [0.0759, 0.1115, 0.1246, 0.1339, 0.1353, 0.1361, 0.1349, 0.1198, 0.0215,\n",
      "         0.0065],\n",
      "        [0.0835, 0.1060, 0.1145, 0.1213, 0.1228, 0.1251, 0.1277, 0.1273, 0.0500,\n",
      "         0.0218],\n",
      "        [0.0842, 0.1028, 0.1101, 0.1164, 0.1179, 0.1207, 0.1249, 0.1290, 0.0630,\n",
      "         0.0308],\n",
      "        [0.0810, 0.1015, 0.1097, 0.1170, 0.1192, 0.1229, 0.1290, 0.1353, 0.0585,\n",
      "         0.0260],\n",
      "        [0.0793, 0.1015, 0.1105, 0.1184, 0.1208, 0.1248, 0.1315, 0.1376, 0.0536,\n",
      "         0.0220],\n",
      "        [0.0794, 0.1024, 0.1117, 0.1198, 0.1221, 0.1261, 0.1327, 0.1369, 0.0494,\n",
      "         0.0197],\n",
      "        [0.0796, 0.1030, 0.1125, 0.1207, 0.1230, 0.1269, 0.1333, 0.1361, 0.0466,\n",
      "         0.0182]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 祖父 在 他 的 年代 是 位非 非凡\n",
      "Reference: my grandfather was an extraordinary man for his time\n",
      "Model: <SOS> we of the the the , , the the\n",
      "Attention Weights: tensor([[0.0543, 0.1060, 0.1292, 0.1442, 0.1456, 0.1404, 0.1190, 0.1004, 0.0607,\n",
      "         0.0004],\n",
      "        [0.0597, 0.0974, 0.1157, 0.1306, 0.1337, 0.1339, 0.1231, 0.1124, 0.0869,\n",
      "         0.0066],\n",
      "        [0.0758, 0.0956, 0.1051, 0.1134, 0.1157, 0.1180, 0.1154, 0.1131, 0.1080,\n",
      "         0.0398],\n",
      "        [0.0784, 0.0937, 0.1015, 0.1085, 0.1107, 0.1134, 0.1124, 0.1122, 0.1126,\n",
      "         0.0565],\n",
      "        [0.0753, 0.0913, 0.0998, 0.1078, 0.1104, 0.1140, 0.1141, 0.1149, 0.1167,\n",
      "         0.0556],\n",
      "        [0.0726, 0.0903, 0.0997, 0.1084, 0.1113, 0.1154, 0.1159, 0.1171, 0.1186,\n",
      "         0.0506],\n",
      "        [0.0723, 0.0904, 0.1000, 0.1091, 0.1121, 0.1162, 0.1166, 0.1177, 0.1183,\n",
      "         0.0473],\n",
      "        [0.0725, 0.0908, 0.1005, 0.1097, 0.1127, 0.1168, 0.1170, 0.1178, 0.1173,\n",
      "         0.0450],\n",
      "        [0.0724, 0.0908, 0.1006, 0.1098, 0.1128, 0.1169, 0.1171, 0.1178, 0.1171,\n",
      "         0.0446]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 112.00, Train Loss: 2.21, Val Loss: 12.31, Train BLEU: 27.82, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里 生物 的 多样 多样性 和 密度 要 比\n",
      "Reference: the biodiversity and the <UNK> in the ocean is\n",
      "Model: <SOS> the of the the , the the the the\n",
      "Attention Weights: tensor([[0.0459, 0.0917, 0.1104, 0.1042, 0.0679, 0.0075, 0.1701, 0.1714, 0.1406,\n",
      "         0.0903],\n",
      "        [0.0637, 0.0899, 0.1049, 0.1046, 0.0937, 0.0463, 0.1327, 0.1340, 0.1244,\n",
      "         0.1058],\n",
      "        [0.0790, 0.0908, 0.1006, 0.1033, 0.1085, 0.0887, 0.1081, 0.1086, 0.1070,\n",
      "         0.1054],\n",
      "        [0.0777, 0.0890, 0.0995, 0.1037, 0.1122, 0.0953, 0.1045, 0.1058, 0.1058,\n",
      "         0.1065],\n",
      "        [0.0748, 0.0875, 0.0991, 0.1043, 0.1136, 0.0934, 0.1047, 0.1067, 0.1075,\n",
      "         0.1085],\n",
      "        [0.0711, 0.0858, 0.0991, 0.1053, 0.1147, 0.0875, 0.1063, 0.1091, 0.1103,\n",
      "         0.1109],\n",
      "        [0.0704, 0.0860, 0.0996, 0.1058, 0.1142, 0.0836, 0.1071, 0.1102, 0.1115,\n",
      "         0.1115],\n",
      "        [0.0703, 0.0861, 0.0997, 0.1059, 0.1138, 0.0823, 0.1076, 0.1107, 0.1119,\n",
      "         0.1115],\n",
      "        [0.0700, 0.0861, 0.0998, 0.1060, 0.1135, 0.0812, 0.1080, 0.1112, 0.1124,\n",
      "         0.1118]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 都 知道 自己 正 冒 着 生命 的 危险\n",
      "Reference: we all knew we were risking our lives --\n",
      "Model: <SOS> and of the the , , the the the\n",
      "Attention Weights: tensor([[0.0401, 0.0850, 0.1059, 0.1258, 0.1279, 0.1280, 0.1245, 0.1142, 0.0978,\n",
      "         0.0508],\n",
      "        [0.0539, 0.0861, 0.1050, 0.1123, 0.1168, 0.1153, 0.1159, 0.1116, 0.1056,\n",
      "         0.0775],\n",
      "        [0.0756, 0.0930, 0.1040, 0.1022, 0.1061, 0.1039, 0.1059, 0.1047, 0.1054,\n",
      "         0.0992],\n",
      "        [0.0763, 0.0925, 0.1035, 0.1010, 0.1051, 0.1028, 0.1050, 0.1043, 0.1061,\n",
      "         0.1034],\n",
      "        [0.0723, 0.0904, 0.1031, 0.1012, 0.1057, 0.1035, 0.1059, 0.1053, 0.1076,\n",
      "         0.1050],\n",
      "        [0.0685, 0.0886, 0.1029, 0.1017, 0.1067, 0.1044, 0.1070, 0.1064, 0.1086,\n",
      "         0.1051],\n",
      "        [0.0687, 0.0887, 0.1029, 0.1018, 0.1067, 0.1044, 0.1070, 0.1064, 0.1086,\n",
      "         0.1049],\n",
      "        [0.0679, 0.0885, 0.1029, 0.1022, 0.1071, 0.1049, 0.1074, 0.1066, 0.1086,\n",
      "         0.1041],\n",
      "        [0.0676, 0.0884, 0.1028, 0.1023, 0.1072, 0.1051, 0.1075, 0.1067, 0.1086,\n",
      "         0.1038]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 113.00, Train Loss: 2.18, Val Loss: 12.33, Train BLEU: 28.54, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 我们 得用 非常 特殊 的 仪器 才能 能到 到达 那个\n",
      "Reference: we have to have a very special technology to\n",
      "Model: <SOS> we have have have to , the the the\n",
      "Attention Weights: tensor([[0.0136, 0.0035, 0.1316, 0.1683, 0.1800, 0.1721, 0.1561, 0.0311, 0.0890,\n",
      "         0.0547],\n",
      "        [0.0391, 0.0295, 0.1187, 0.1325, 0.1369, 0.1388, 0.1375, 0.0737, 0.1052,\n",
      "         0.0881],\n",
      "        [0.0633, 0.0612, 0.1074, 0.1123, 0.1138, 0.1177, 0.1212, 0.0972, 0.1051,\n",
      "         0.1009],\n",
      "        [0.0642, 0.0640, 0.1052, 0.1106, 0.1124, 0.1169, 0.1211, 0.0985, 0.1045,\n",
      "         0.1027],\n",
      "        [0.0631, 0.0623, 0.1050, 0.1111, 0.1132, 0.1179, 0.1223, 0.0973, 0.1046,\n",
      "         0.1031],\n",
      "        [0.0607, 0.0593, 0.1052, 0.1123, 0.1149, 0.1198, 0.1245, 0.0954, 0.1047,\n",
      "         0.1032],\n",
      "        [0.0593, 0.0571, 0.1056, 0.1132, 0.1161, 0.1211, 0.1257, 0.0941, 0.1049,\n",
      "         0.1029],\n",
      "        [0.0581, 0.0547, 0.1060, 0.1143, 0.1176, 0.1224, 0.1268, 0.0926, 0.1049,\n",
      "         0.1025],\n",
      "        [0.0576, 0.0535, 0.1064, 0.1149, 0.1182, 0.1230, 0.1273, 0.0919, 0.1050,\n",
      "         0.1022]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 她 两年 年前 退休 了 结果 却 把 我家 变成\n",
      "Reference: she retired two years ago , only to turn\n",
      "Model: <SOS> the of the the the the the the the\n",
      "Attention Weights: tensor([[1.2482e-01, 2.2502e-01, 2.5411e-01, 2.5967e-01, 1.3554e-01, 8.4955e-04,\n",
      "         3.3914e-11, 3.3914e-11, 3.3914e-11, 3.3914e-11],\n",
      "        [1.2936e-01, 1.9860e-01, 2.2877e-01, 2.4622e-01, 1.8148e-01, 1.5568e-02,\n",
      "         8.9919e-09, 8.9919e-09, 8.9919e-09, 8.9919e-09],\n",
      "        [1.4469e-01, 1.7772e-01, 1.9586e-01, 2.0931e-01, 1.9748e-01, 7.4940e-02,\n",
      "         7.2751e-07, 7.2751e-07, 7.2751e-07, 7.2751e-07],\n",
      "        [1.4439e-01, 1.7039e-01, 1.8686e-01, 1.9994e-01, 1.9864e-01, 9.9751e-02,\n",
      "         6.6688e-06, 6.6688e-06, 6.6688e-06, 6.6688e-06],\n",
      "        [1.4001e-01, 1.6977e-01, 1.8945e-01, 2.0552e-01, 2.0495e-01, 9.0281e-02,\n",
      "         6.1557e-06, 6.1557e-06, 6.1557e-06, 6.1557e-06],\n",
      "        [1.3906e-01, 1.6999e-01, 1.9063e-01, 2.0758e-01, 2.0671e-01, 8.6009e-02,\n",
      "         4.9601e-06, 4.9601e-06, 4.9601e-06, 4.9601e-06],\n",
      "        [1.3869e-01, 1.7094e-01, 1.9232e-01, 2.0992e-01, 2.0718e-01, 8.0930e-02,\n",
      "         3.3395e-06, 3.3395e-06, 3.3395e-06, 3.3395e-06],\n",
      "        [1.3931e-01, 1.7229e-01, 1.9386e-01, 2.1158e-01, 2.0605e-01, 7.6901e-02,\n",
      "         2.2206e-06, 2.2206e-06, 2.2206e-06, 2.2206e-06],\n",
      "        [1.3921e-01, 1.7242e-01, 1.9412e-01, 2.1199e-01, 2.0605e-01, 7.6211e-02,\n",
      "         2.1323e-06, 2.1323e-06, 2.1323e-06, 2.1323e-06]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 114.00, Train Loss: 2.17, Val Loss: 12.34, Train BLEU: 27.64, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的 平均 深度 是 两英里 英里 <EOS> <PAD> <PAD>\n",
      "Reference: the average depth is about two miles . <EOS>\n",
      "Model: <SOS> the &apos;s the to about . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.0852e-01, 2.2040e-01, 2.3473e-01, 2.4015e-01, 1.6296e-01, 2.1036e-03,\n",
      "         3.0932e-02, 2.1605e-04, 4.7093e-11, 4.7093e-11],\n",
      "        [1.1059e-01, 1.7537e-01, 1.9412e-01, 2.0736e-01, 1.8296e-01, 3.1636e-02,\n",
      "         8.7190e-02, 1.0781e-02, 1.8596e-08, 1.8596e-08],\n",
      "        [1.1465e-01, 1.4180e-01, 1.5368e-01, 1.6366e-01, 1.6753e-01, 8.7460e-02,\n",
      "         1.2270e-01, 4.8518e-02, 8.9330e-07, 8.9330e-07],\n",
      "        [1.1167e-01, 1.3390e-01, 1.4563e-01, 1.5614e-01, 1.6520e-01, 1.0096e-01,\n",
      "         1.2648e-01, 6.0001e-02, 5.2414e-06, 5.2414e-06],\n",
      "        [1.0847e-01, 1.3541e-01, 1.5003e-01, 1.6365e-01, 1.7605e-01, 9.2507e-02,\n",
      "         1.2390e-01, 4.9983e-02, 4.2204e-06, 4.2204e-06],\n",
      "        [1.0783e-01, 1.3614e-01, 1.5186e-01, 1.6647e-01, 1.7988e-01, 8.8801e-02,\n",
      "         1.2228e-01, 4.6731e-02, 3.4370e-06, 3.4370e-06],\n",
      "        [1.0817e-01, 1.3753e-01, 1.5372e-01, 1.6873e-01, 1.8157e-01, 8.5699e-02,\n",
      "         1.2061e-01, 4.3955e-02, 2.4834e-06, 2.4834e-06],\n",
      "        [1.0887e-01, 1.3910e-01, 1.5536e-01, 1.7053e-01, 1.8197e-01, 8.2352e-02,\n",
      "         1.1962e-01, 4.2176e-02, 1.8796e-06, 1.8796e-06],\n",
      "        [1.0884e-01, 1.3959e-01, 1.5599e-01, 1.7127e-01, 1.8223e-01, 8.1006e-02,\n",
      "         1.1954e-01, 4.1527e-02, 1.7570e-06, 1.7570e-06]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 不知 知道 那 意味 意味着 什么 但是 我 能\n",
      "Reference: i didn &apos;t know what it meant , but\n",
      "Model: <SOS> the of the the the the , the the\n",
      "Attention Weights: tensor([[0.0730, 0.1468, 0.1764, 0.1994, 0.1814, 0.1301, 0.0620, 0.0018, 0.0018,\n",
      "         0.0272],\n",
      "        [0.0780, 0.1150, 0.1352, 0.1545, 0.1546, 0.1392, 0.1098, 0.0293, 0.0224,\n",
      "         0.0621],\n",
      "        [0.0807, 0.0974, 0.1097, 0.1219, 0.1256, 0.1258, 0.1257, 0.0743, 0.0579,\n",
      "         0.0809],\n",
      "        [0.0786, 0.0935, 0.1054, 0.1175, 0.1224, 0.1256, 0.1305, 0.0829, 0.0629,\n",
      "         0.0806],\n",
      "        [0.0773, 0.0931, 0.1058, 0.1189, 0.1244, 0.1284, 0.1336, 0.0805, 0.0596,\n",
      "         0.0785],\n",
      "        [0.0767, 0.0931, 0.1060, 0.1195, 0.1253, 0.1296, 0.1348, 0.0791, 0.0582,\n",
      "         0.0777],\n",
      "        [0.0763, 0.0931, 0.1064, 0.1202, 0.1262, 0.1306, 0.1357, 0.0778, 0.0568,\n",
      "         0.0770],\n",
      "        [0.0748, 0.0934, 0.1077, 0.1228, 0.1293, 0.1338, 0.1380, 0.0732, 0.0525,\n",
      "         0.0745],\n",
      "        [0.0742, 0.0938, 0.1088, 0.1245, 0.1314, 0.1357, 0.1390, 0.0701, 0.0495,\n",
      "         0.0731]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 115.00, Train Loss: 2.14, Val Loss: 12.36, Train BLEU: 29.10, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 它 可以 伸展 <UNK> 150 英尺 长 <EOS> <PAD> <PAD>\n",
      "Reference: it gets up to about 150 feet long .\n",
      "Model: <SOS> it gets up to about . . . .\n",
      "Attention Weights: tensor([[3.9133e-01, 3.5505e-01, 4.7995e-02, 2.6850e-06, 1.2760e-05, 6.2699e-02,\n",
      "         1.4146e-01, 1.4433e-03, 1.1863e-10, 1.1863e-10],\n",
      "        [2.8749e-01, 3.7969e-01, 1.5649e-01, 1.7079e-04, 4.5380e-04, 5.6456e-02,\n",
      "         1.0882e-01, 1.0441e-02, 5.3784e-09, 5.3784e-09],\n",
      "        [2.0970e-01, 3.0632e-01, 2.5816e-01, 7.6445e-03, 9.7235e-03, 6.4598e-02,\n",
      "         9.7180e-02, 4.6678e-02, 3.1824e-07, 3.1824e-07],\n",
      "        [1.9362e-01, 2.8606e-01, 2.7370e-01, 1.6776e-02, 1.7257e-02, 6.3645e-02,\n",
      "         9.1293e-02, 5.7644e-02, 2.4381e-06, 2.4381e-06],\n",
      "        [1.9857e-01, 3.0253e-01, 2.8321e-01, 1.2954e-02, 1.3211e-02, 5.5713e-02,\n",
      "         8.4122e-02, 4.9691e-02, 2.2806e-06, 2.2806e-06],\n",
      "        [2.0068e-01, 3.0723e-01, 2.8418e-01, 1.1367e-02, 1.1571e-02, 5.4274e-02,\n",
      "         8.3477e-02, 4.7219e-02, 1.9815e-06, 1.9815e-06],\n",
      "        [2.0369e-01, 3.1131e-01, 2.8110e-01, 9.4689e-03, 9.9447e-03, 5.4705e-02,\n",
      "         8.4603e-02, 4.5179e-02, 1.4359e-06, 1.4359e-06],\n",
      "        [2.0391e-01, 3.0979e-01, 2.7870e-01, 9.2960e-03, 9.7089e-03, 5.6399e-02,\n",
      "         8.6265e-02, 4.5922e-02, 1.2752e-06, 1.2752e-06],\n",
      "        [2.0383e-01, 3.0896e-01, 2.7823e-01, 9.3903e-03, 9.8237e-03, 5.6863e-02,\n",
      "         8.6537e-02, 4.6358e-02, 1.2778e-06, 1.2778e-06]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 那 就是 她 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: there she is . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a kind about . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[6.6530e-02, 1.2869e-01, 1.3995e-01, 1.4767e-01, 1.5175e-01, 1.4847e-01,\n",
      "         1.3406e-01, 8.2129e-02, 7.4864e-04, 1.8913e-11],\n",
      "        [6.8874e-02, 1.1480e-01, 1.2775e-01, 1.3599e-01, 1.4231e-01, 1.4534e-01,\n",
      "         1.4195e-01, 1.1102e-01, 1.1964e-02, 6.1834e-09],\n",
      "        [8.6470e-02, 1.0904e-01, 1.1709e-01, 1.2189e-01, 1.2591e-01, 1.2947e-01,\n",
      "         1.3057e-01, 1.2338e-01, 5.6177e-02, 7.4525e-07],\n",
      "        [8.8069e-02, 1.0620e-01, 1.1344e-01, 1.1778e-01, 1.2158e-01, 1.2566e-01,\n",
      "         1.2813e-01, 1.2609e-01, 7.3035e-02, 7.2200e-06],\n",
      "        [8.3387e-02, 1.0478e-01, 1.1326e-01, 1.1853e-01, 1.2315e-01, 1.2836e-01,\n",
      "         1.3192e-01, 1.3013e-01, 6.6470e-02, 6.0271e-06],\n",
      "        [8.1996e-02, 1.0465e-01, 1.1351e-01, 1.1908e-01, 1.2393e-01, 1.2938e-01,\n",
      "         1.3319e-01, 1.3121e-01, 6.3048e-02, 4.3071e-06],\n",
      "        [8.1624e-02, 1.0494e-01, 1.1400e-01, 1.1977e-01, 1.2475e-01, 1.3022e-01,\n",
      "         1.3399e-01, 1.3110e-01, 5.9594e-02, 2.8889e-06],\n",
      "        [8.1457e-02, 1.0524e-01, 1.1433e-01, 1.2022e-01, 1.2531e-01, 1.3086e-01,\n",
      "         1.3459e-01, 1.3080e-01, 5.7204e-02, 2.0581e-06],\n",
      "        [8.1371e-02, 1.0520e-01, 1.1432e-01, 1.2025e-01, 1.2536e-01, 1.3096e-01,\n",
      "         1.3474e-01, 1.3086e-01, 5.6929e-02, 2.0106e-06]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 116.00, Train Loss: 2.11, Val Loss: 12.36, Train BLEU: 29.20, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 原来 它 是 海洋 洋中 最长 的 生物 <EOS> <PAD>\n",
      "Reference: this turns out to be the longest creature in\n",
      "Model: <SOS> this &apos;s a to be . . <EOS> <EOS>\n",
      "Attention Weights: tensor([[9.3308e-02, 1.7524e-01, 1.6949e-01, 6.7934e-02, 3.0616e-04, 1.7574e-01,\n",
      "         2.0606e-01, 1.1064e-01, 1.2832e-03, 4.0201e-11],\n",
      "        [8.6611e-02, 1.3649e-01, 1.4594e-01, 1.2491e-01, 1.1036e-02, 1.5376e-01,\n",
      "         1.8051e-01, 1.4042e-01, 2.0312e-02, 1.1248e-08],\n",
      "        [9.0366e-02, 1.1382e-01, 1.2749e-01, 1.5095e-01, 5.8362e-02, 1.2287e-01,\n",
      "         1.3487e-01, 1.3396e-01, 6.7307e-02, 1.0254e-06],\n",
      "        [8.9884e-02, 1.1026e-01, 1.2566e-01, 1.5723e-01, 7.5076e-02, 1.1221e-01,\n",
      "         1.2277e-01, 1.2816e-01, 7.8738e-02, 8.6572e-06],\n",
      "        [8.7194e-02, 1.1166e-01, 1.3131e-01, 1.6964e-01, 6.6532e-02, 1.0935e-01,\n",
      "         1.2326e-01, 1.3025e-01, 7.0796e-02, 7.0986e-06],\n",
      "        [8.6464e-02, 1.1214e-01, 1.3361e-01, 1.7438e-01, 6.2525e-02, 1.0826e-01,\n",
      "         1.2322e-01, 1.3096e-01, 6.8435e-02, 5.7399e-06],\n",
      "        [8.6621e-02, 1.1328e-01, 1.3547e-01, 1.7525e-01, 5.7915e-02, 1.0928e-01,\n",
      "         1.2493e-01, 1.3175e-01, 6.5502e-02, 3.9852e-06],\n",
      "        [8.7386e-02, 1.1469e-01, 1.3662e-01, 1.7343e-01, 5.4491e-02, 1.1081e-01,\n",
      "         1.2677e-01, 1.3212e-01, 6.3683e-02, 2.8019e-06],\n",
      "        [8.7435e-02, 1.1505e-01, 1.3697e-01, 1.7274e-01, 5.3320e-02, 1.1127e-01,\n",
      "         1.2750e-01, 1.3256e-01, 6.3147e-02, 2.6275e-06]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 在 被 跟踪 吗 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: were we being followed ? <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a kind about . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.1618e-01, 2.3031e-01, 2.7528e-01, 2.3859e-01, 9.9905e-02, 1.0199e-02,\n",
      "         2.8740e-06, 2.2144e-07, 9.0459e-03, 2.0485e-02],\n",
      "        [1.0082e-01, 1.7532e-01, 2.1489e-01, 2.2125e-01, 1.7643e-01, 6.2049e-02,\n",
      "         4.5836e-04, 6.5619e-05, 1.6751e-02, 3.1974e-02],\n",
      "        [9.8401e-02, 1.3034e-01, 1.5067e-01, 1.6773e-01, 1.9469e-01, 1.5143e-01,\n",
      "         1.4041e-02, 3.5260e-03, 3.6146e-02, 5.3023e-02],\n",
      "        [9.2994e-02, 1.1949e-01, 1.3839e-01, 1.5864e-01, 1.9705e-01, 1.7354e-01,\n",
      "         2.4486e-02, 7.4368e-03, 3.6691e-02, 5.1280e-02],\n",
      "        [9.0300e-02, 1.1937e-01, 1.4094e-01, 1.6452e-01, 2.0558e-01, 1.7591e-01,\n",
      "         2.0197e-02, 5.6033e-03, 3.1777e-02, 4.5801e-02],\n",
      "        [8.9496e-02, 1.2068e-01, 1.4413e-01, 1.6987e-01, 2.1000e-01, 1.7272e-01,\n",
      "         1.6879e-02, 4.4837e-03, 2.8892e-02, 4.2842e-02],\n",
      "        [8.9430e-02, 1.2114e-01, 1.4504e-01, 1.7096e-01, 2.1074e-01, 1.7137e-01,\n",
      "         1.6265e-02, 4.2951e-03, 2.8542e-02, 4.2211e-02],\n",
      "        [8.9419e-02, 1.2200e-01, 1.4646e-01, 1.7257e-01, 2.1157e-01, 1.6957e-01,\n",
      "         1.4814e-02, 3.7900e-03, 2.8050e-02, 4.1761e-02],\n",
      "        [9.0063e-02, 1.2310e-01, 1.4782e-01, 1.7371e-01, 2.1082e-01, 1.6696e-01,\n",
      "         1.3821e-02, 3.4429e-03, 2.8314e-02, 4.1942e-02]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 117.00, Train Loss: 2.10, Val Loss: 12.36, Train BLEU: 29.83, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 这位 是 比尔 <UNK> 我 是 大卫 <UNK>\n",
      "Reference: this is bill lange . i &apos;m dave gallo\n",
      "Model: <SOS> this is bill lange . &apos;m &apos;m dave gallo\n",
      "Attention Weights: tensor([[0.0285, 0.0000, 0.0358, 0.1082, 0.0008, 0.0000, 0.2646, 0.4824, 0.0795,\n",
      "         0.0000],\n",
      "        [0.0377, 0.0001, 0.0400, 0.1139, 0.0012, 0.0000, 0.2353, 0.4766, 0.0951,\n",
      "         0.0000],\n",
      "        [0.0739, 0.0008, 0.0592, 0.1305, 0.0084, 0.0006, 0.1977, 0.3715, 0.1569,\n",
      "         0.0004],\n",
      "        [0.0933, 0.0021, 0.0708, 0.1382, 0.0158, 0.0016, 0.1830, 0.3167, 0.1773,\n",
      "         0.0012],\n",
      "        [0.1067, 0.0030, 0.0746, 0.1462, 0.0209, 0.0024, 0.1622, 0.2914, 0.1909,\n",
      "         0.0018],\n",
      "        [0.1094, 0.0029, 0.0744, 0.1498, 0.0211, 0.0022, 0.1569, 0.2855, 0.1961,\n",
      "         0.0017],\n",
      "        [0.1144, 0.0032, 0.0758, 0.1534, 0.0232, 0.0025, 0.1514, 0.2746, 0.1998,\n",
      "         0.0019],\n",
      "        [0.1170, 0.0034, 0.0768, 0.1548, 0.0247, 0.0027, 0.1488, 0.2687, 0.2011,\n",
      "         0.0020],\n",
      "        [0.1180, 0.0036, 0.0772, 0.1551, 0.0253, 0.0028, 0.1479, 0.2666, 0.2015,\n",
      "         0.0021]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 11 岁 那年 记得 得有 一天 早晨 醒来 听见\n",
      "Reference: when i was 11 , i remember waking up\n",
      "Model: <SOS> most of the the the , the the the\n",
      "Attention Weights: tensor([[1.7207e-01, 3.5071e-01, 3.3783e-01, 1.3470e-01, 4.6878e-03, 1.1735e-07,\n",
      "         1.1624e-07, 5.4748e-11, 5.4748e-11, 5.4748e-11],\n",
      "        [1.3589e-01, 2.8887e-01, 3.3425e-01, 2.1709e-01, 2.3895e-02, 2.9628e-06,\n",
      "         2.8950e-06, 1.0001e-09, 1.0001e-09, 1.0001e-09],\n",
      "        [1.2935e-01, 2.0994e-01, 2.5671e-01, 2.7053e-01, 1.3218e-01, 7.0894e-04,\n",
      "         5.7977e-04, 1.0823e-07, 1.0823e-07, 1.0823e-07],\n",
      "        [1.2797e-01, 1.8493e-01, 2.2586e-01, 2.6682e-01, 1.8740e-01, 4.0919e-03,\n",
      "         2.9260e-03, 1.3891e-06, 1.3891e-06, 1.3891e-06],\n",
      "        [1.2395e-01, 1.8479e-01, 2.3024e-01, 2.7471e-01, 1.8150e-01, 2.8332e-03,\n",
      "         1.9728e-03, 1.4168e-06, 1.4168e-06, 1.4168e-06],\n",
      "        [1.2449e-01, 1.8696e-01, 2.3272e-01, 2.7602e-01, 1.7590e-01, 2.2862e-03,\n",
      "         1.6117e-03, 1.1358e-06, 1.1358e-06, 1.1358e-06],\n",
      "        [1.2633e-01, 1.8941e-01, 2.3487e-01, 2.7530e-01, 1.7053e-01, 2.0858e-03,\n",
      "         1.4742e-03, 8.9068e-07, 8.9068e-07, 8.9068e-07],\n",
      "        [1.2643e-01, 1.8936e-01, 2.3468e-01, 2.7485e-01, 1.7101e-01, 2.1506e-03,\n",
      "         1.5190e-03, 9.0296e-07, 9.0296e-07, 9.0296e-07],\n",
      "        [1.2639e-01, 1.8921e-01, 2.3450e-01, 2.7470e-01, 1.7148e-01, 2.1838e-03,\n",
      "         1.5419e-03, 9.1865e-07, 9.1865e-07, 9.1865e-07]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 118.00, Train Loss: 2.07, Val Loss: 12.37, Train BLEU: 31.08, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一只 水母 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: here &apos;s a jelly . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> here &apos;s a jelly . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.6756e-01, 3.1367e-01, 3.4515e-01, 1.7210e-01, 1.5165e-03, 6.9504e-11,\n",
      "         6.9504e-11, 6.9504e-11, 6.9504e-11, 6.9504e-11],\n",
      "        [1.6596e-01, 2.6514e-01, 3.0974e-01, 2.3259e-01, 2.6557e-02, 1.6368e-08,\n",
      "         1.6368e-08, 1.6368e-08, 1.6368e-08, 1.6368e-08],\n",
      "        [1.7344e-01, 2.1932e-01, 2.5003e-01, 2.4495e-01, 1.1224e-01, 1.6142e-06,\n",
      "         1.6142e-06, 1.6142e-06, 1.6142e-06, 1.6142e-06],\n",
      "        [1.7049e-01, 2.0710e-01, 2.3590e-01, 2.4412e-01, 1.4231e-01, 1.6726e-05,\n",
      "         1.6726e-05, 1.6726e-05, 1.6726e-05, 1.6726e-05],\n",
      "        [1.6526e-01, 2.0766e-01, 2.4203e-01, 2.5342e-01, 1.3156e-01, 1.4660e-05,\n",
      "         1.4660e-05, 1.4660e-05, 1.4660e-05, 1.4660e-05],\n",
      "        [1.6501e-01, 2.1063e-01, 2.4666e-01, 2.5557e-01, 1.2209e-01, 8.1749e-06,\n",
      "         8.1749e-06, 8.1749e-06, 8.1749e-06, 8.1749e-06],\n",
      "        [1.6607e-01, 2.1257e-01, 2.4901e-01, 2.5515e-01, 1.1718e-01, 5.5333e-06,\n",
      "         5.5333e-06, 5.5333e-06, 5.5333e-06, 5.5333e-06],\n",
      "        [1.6606e-01, 2.1281e-01, 2.4940e-01, 2.5518e-01, 1.1652e-01, 5.3766e-06,\n",
      "         5.3766e-06, 5.3766e-06, 5.3766e-06, 5.3766e-06],\n",
      "        [1.6604e-01, 2.1283e-01, 2.4945e-01, 2.5516e-01, 1.1650e-01, 5.3523e-06,\n",
      "         5.3523e-06, 5.3523e-06, 5.3523e-06, 5.3523e-06]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 出身 阿富汗 边远 <UNK> 地区 有着 与 他人 不同\n",
      "Reference: a total maverick from a remote province of afghanistan\n",
      "Model: <SOS> we use the the to , the the the\n",
      "Attention Weights: tensor([[9.0190e-02, 1.7287e-01, 1.7011e-01, 6.8360e-02, 3.1365e-04, 1.7587e-01,\n",
      "         2.1007e-01, 1.1068e-01, 1.5323e-03, 4.4264e-11],\n",
      "        [8.2853e-02, 1.3332e-01, 1.4481e-01, 1.2773e-01, 1.1590e-02, 1.5323e-01,\n",
      "         1.8294e-01, 1.4085e-01, 2.2672e-02, 1.1869e-08],\n",
      "        [8.6377e-02, 1.1047e-01, 1.2595e-01, 1.5516e-01, 6.2387e-02, 1.2049e-01,\n",
      "         1.3369e-01, 1.3323e-01, 7.2252e-02, 1.2497e-06],\n",
      "        [8.6018e-02, 1.0699e-01, 1.2401e-01, 1.6106e-01, 7.9579e-02, 1.0986e-01,\n",
      "         1.2130e-01, 1.2747e-01, 8.3699e-02, 1.0916e-05],\n",
      "        [8.3431e-02, 1.0823e-01, 1.2949e-01, 1.7350e-01, 7.1259e-02, 1.0666e-01,\n",
      "         1.2147e-01, 1.2939e-01, 7.6550e-02, 9.0936e-06],\n",
      "        [8.2748e-02, 1.0862e-01, 1.3162e-01, 1.7818e-01, 6.7427e-02, 1.0544e-01,\n",
      "         1.2130e-01, 1.3004e-01, 7.4625e-02, 7.6601e-06],\n",
      "        [8.2706e-02, 1.0951e-01, 1.3335e-01, 1.7960e-01, 6.2862e-02, 1.0621e-01,\n",
      "         1.2286e-01, 1.3094e-01, 7.1952e-02, 5.4276e-06],\n",
      "        [8.3489e-02, 1.1089e-01, 1.3448e-01, 1.7796e-01, 5.9076e-02, 1.0793e-01,\n",
      "         1.2490e-01, 1.3141e-01, 6.9869e-02, 3.6638e-06],\n",
      "        [8.3515e-02, 1.1128e-01, 1.3486e-01, 1.7721e-01, 5.7636e-02, 1.0852e-01,\n",
      "         1.2579e-01, 1.3197e-01, 6.9222e-02, 3.3685e-06]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 119.00, Train Loss: 2.05, Val Loss: 12.38, Train BLEU: 31.64, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 和 我们 合作 的 人们 帮 我们 找到 了 新\n",
      "Reference: people that have partnered with us have given us\n",
      "Model: <SOS> and of the the , , , , the\n",
      "Attention Weights: tensor([[0.0409, 0.0825, 0.1121, 0.1207, 0.1290, 0.1272, 0.1239, 0.1163, 0.0919,\n",
      "         0.0556],\n",
      "        [0.0517, 0.0813, 0.1049, 0.1099, 0.1184, 0.1149, 0.1172, 0.1163, 0.1027,\n",
      "         0.0827],\n",
      "        [0.0728, 0.0880, 0.1010, 0.1010, 0.1060, 0.1033, 0.1066, 0.1092, 0.1061,\n",
      "         0.1062],\n",
      "        [0.0735, 0.0876, 0.1001, 0.1000, 0.1047, 0.1023, 0.1057, 0.1085, 0.1073,\n",
      "         0.1104],\n",
      "        [0.0700, 0.0856, 0.0992, 0.0999, 0.1051, 0.1029, 0.1064, 0.1094, 0.1090,\n",
      "         0.1125],\n",
      "        [0.0662, 0.0836, 0.0987, 0.1000, 0.1058, 0.1036, 0.1074, 0.1106, 0.1105,\n",
      "         0.1136],\n",
      "        [0.0659, 0.0834, 0.0986, 0.1000, 0.1059, 0.1038, 0.1076, 0.1107, 0.1106,\n",
      "         0.1135],\n",
      "        [0.0654, 0.0832, 0.0985, 0.1001, 0.1060, 0.1039, 0.1077, 0.1108, 0.1109,\n",
      "         0.1135],\n",
      "        [0.0648, 0.0829, 0.0985, 0.1002, 0.1063, 0.1043, 0.1080, 0.1110, 0.1110,\n",
      "         0.1130]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在 可以 去 个 真正 的 学校 念书 了\n",
      "Reference: &quot; you can go to a real school now\n",
      "Model: <SOS> and of the the and , , the the\n",
      "Attention Weights: tensor([[0.0100, 0.0028, 0.0074, 0.0140, 0.1572, 0.1685, 0.1768, 0.1792, 0.1700,\n",
      "         0.1141],\n",
      "        [0.0363, 0.0305, 0.0420, 0.0540, 0.1348, 0.1373, 0.1427, 0.1461, 0.1460,\n",
      "         0.1305],\n",
      "        [0.0729, 0.0826, 0.0891, 0.0943, 0.1071, 0.1044, 0.1073, 0.1099, 0.1132,\n",
      "         0.1192],\n",
      "        [0.0769, 0.0895, 0.0934, 0.0949, 0.1010, 0.0998, 0.1038, 0.1073, 0.1119,\n",
      "         0.1216],\n",
      "        [0.0757, 0.0879, 0.0915, 0.0924, 0.1001, 0.0999, 0.1046, 0.1088, 0.1142,\n",
      "         0.1249],\n",
      "        [0.0710, 0.0805, 0.0854, 0.0868, 0.1012, 0.1022, 0.1081, 0.1135, 0.1200,\n",
      "         0.1314],\n",
      "        [0.0684, 0.0758, 0.0817, 0.0838, 0.1025, 0.1040, 0.1104, 0.1162, 0.1231,\n",
      "         0.1341],\n",
      "        [0.0670, 0.0734, 0.0797, 0.0822, 0.1038, 0.1053, 0.1117, 0.1176, 0.1244,\n",
      "         0.1350],\n",
      "        [0.0664, 0.0724, 0.0788, 0.0816, 0.1042, 0.1058, 0.1122, 0.1181, 0.1249,\n",
      "         0.1354]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 120.00, Train Loss: 2.02, Val Loss: 12.39, Train BLEU: 31.26, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 大卫 <UNK> 通过 潜水 潜水艇 拍下 的 影片 把 我们\n",
      "Reference: with vibrant video clips captured by submarines , david\n",
      "Model: <SOS> with vibrant video clips captured by submarines david david\n",
      "Attention Weights: tensor([[3.9603e-04, 4.7811e-07, 7.3593e-03, 2.1896e-02, 1.0304e-02, 1.8999e-01,\n",
      "         2.1697e-01, 2.3435e-01, 2.0384e-01, 1.1490e-01],\n",
      "        [6.0311e-03, 7.9585e-05, 1.7289e-02, 3.6984e-02, 3.1782e-02, 1.7168e-01,\n",
      "         1.9220e-01, 2.0827e-01, 1.9496e-01, 1.4073e-01],\n",
      "        [4.4680e-02, 3.4011e-03, 4.0548e-02, 6.5095e-02, 7.9423e-02, 1.4079e-01,\n",
      "         1.5082e-01, 1.6142e-01, 1.6141e-01, 1.5241e-01],\n",
      "        [6.9724e-02, 7.9482e-03, 4.5116e-02, 6.8801e-02, 9.2016e-02, 1.2743e-01,\n",
      "         1.3712e-01, 1.4766e-01, 1.5179e-01, 1.5240e-01],\n",
      "        [7.0374e-02, 7.1657e-03, 4.1891e-02, 6.5728e-02, 8.8804e-02, 1.2651e-01,\n",
      "         1.3778e-01, 1.4951e-01, 1.5535e-01, 1.5688e-01],\n",
      "        [6.5425e-02, 5.8309e-03, 3.9984e-02, 6.3752e-02, 8.5793e-02, 1.2798e-01,\n",
      "         1.4029e-01, 1.5276e-01, 1.5876e-01, 1.5942e-01],\n",
      "        [6.5048e-02, 5.6084e-03, 3.9649e-02, 6.3552e-02, 8.4897e-02, 1.2803e-01,\n",
      "         1.4066e-01, 1.5321e-01, 1.5950e-01, 1.5983e-01],\n",
      "        [6.6133e-02, 5.7636e-03, 4.0201e-02, 6.3970e-02, 8.5369e-02, 1.2762e-01,\n",
      "         1.4010e-01, 1.5258e-01, 1.5891e-01, 1.5936e-01],\n",
      "        [6.6556e-02, 5.8427e-03, 4.0475e-02, 6.4198e-02, 8.5653e-02, 1.2741e-01,\n",
      "         1.3977e-01, 1.5227e-01, 1.5865e-01, 1.5918e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 但是 我 那 受过 教育 的 母亲 成为 为了 一名\n",
      "Reference: but my educated mother became a teacher . <EOS>\n",
      "Model: <SOS> the of the the the , the the the\n",
      "Attention Weights: tensor([[3.7873e-01, 3.9335e-01, 5.8045e-02, 4.0155e-06, 1.4607e-05, 5.2588e-02,\n",
      "         1.1531e-01, 1.9672e-03, 1.4894e-10, 1.4894e-10],\n",
      "        [2.6399e-01, 4.0486e-01, 1.8646e-01, 2.4618e-04, 4.7919e-04, 4.4725e-02,\n",
      "         8.6581e-02, 1.2654e-02, 5.8457e-09, 5.8457e-09],\n",
      "        [1.9112e-01, 3.1420e-01, 2.9304e-01, 1.1435e-02, 1.0877e-02, 5.0635e-02,\n",
      "         7.7129e-02, 5.1558e-02, 5.2038e-07, 5.2038e-07],\n",
      "        [1.7723e-01, 2.8864e-01, 3.0360e-01, 2.4196e-02, 1.9113e-02, 5.0451e-02,\n",
      "         7.3796e-02, 6.2965e-02, 4.6499e-06, 4.6499e-06],\n",
      "        [1.8159e-01, 3.0096e-01, 3.1107e-01, 1.9863e-02, 1.5458e-02, 4.5333e-02,\n",
      "         6.8920e-02, 5.6799e-02, 4.3780e-06, 4.3780e-06],\n",
      "        [1.8288e-01, 3.0397e-01, 3.1212e-01, 1.8526e-02, 1.4208e-02, 4.4444e-02,\n",
      "         6.8545e-02, 5.5307e-02, 4.1800e-06, 4.1800e-06],\n",
      "        [1.8490e-01, 3.0993e-01, 3.1164e-01, 1.5440e-02, 1.2198e-02, 4.4172e-02,\n",
      "         6.8933e-02, 5.2790e-02, 2.9211e-06, 2.9211e-06],\n",
      "        [1.8515e-01, 3.0944e-01, 3.0994e-01, 1.4859e-02, 1.1641e-02, 4.5284e-02,\n",
      "         7.0380e-02, 5.3309e-02, 2.5262e-06, 2.5262e-06],\n",
      "        [1.8496e-01, 3.0890e-01, 3.0948e-01, 1.4758e-02, 1.1623e-02, 4.5840e-02,\n",
      "         7.0803e-02, 5.3628e-02, 2.4112e-06, 2.4112e-06]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 121.00, Train Loss: 2.01, Val Loss: 12.40, Train BLEU: 30.95, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: <UNK> 塞尔 <UNK> <UNK> 斯特 说 过 真正 的 探索\n",
      "Reference: marcel proust said , &quot; the true voyage of\n",
      "Model: <SOS> marcel proust said , &quot; true true true true\n",
      "Attention Weights: tensor([[2.5427e-08, 1.6427e-08, 1.8199e-08, 5.1123e-08, 4.3989e-06, 1.0461e-02,\n",
      "         1.2580e-01, 2.6703e-01, 3.3172e-01, 2.6499e-01],\n",
      "        [1.1337e-07, 6.8739e-08, 7.5333e-08, 2.4114e-07, 3.1542e-05, 1.9361e-02,\n",
      "         1.3186e-01, 2.4350e-01, 3.1112e-01, 2.9413e-01],\n",
      "        [2.7458e-05, 1.7040e-05, 1.8155e-05, 5.0553e-05, 1.7327e-03, 5.1561e-02,\n",
      "         1.4547e-01, 2.2289e-01, 2.7578e-01, 3.0246e-01],\n",
      "        [2.9507e-04, 1.9093e-04, 1.9873e-04, 4.6801e-04, 7.1523e-03, 7.4373e-02,\n",
      "         1.5065e-01, 2.0862e-01, 2.5538e-01, 3.0268e-01],\n",
      "        [4.0950e-04, 2.6642e-04, 2.7649e-04, 6.2811e-04, 8.4246e-03, 7.5063e-02,\n",
      "         1.4758e-01, 2.0498e-01, 2.5399e-01, 3.0838e-01],\n",
      "        [4.6712e-04, 3.0448e-04, 3.1415e-04, 6.9350e-04, 8.8849e-03, 7.6640e-02,\n",
      "         1.4777e-01, 2.0435e-01, 2.5298e-01, 3.0759e-01],\n",
      "        [5.9435e-04, 3.9033e-04, 4.0085e-04, 8.5644e-04, 1.0125e-02, 8.0333e-02,\n",
      "         1.4929e-01, 2.0302e-01, 2.5015e-01, 3.0484e-01],\n",
      "        [6.7219e-04, 4.4244e-04, 4.5333e-04, 9.5723e-04, 1.0877e-02, 8.2215e-02,\n",
      "         1.4992e-01, 2.0231e-01, 2.4869e-01, 3.0347e-01],\n",
      "        [7.0147e-04, 4.6191e-04, 4.7302e-04, 9.9494e-04, 1.1147e-02, 8.2895e-02,\n",
      "         1.5019e-01, 2.0207e-01, 2.4813e-01, 3.0294e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 在 被 跟踪 吗 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: were we being followed ? <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a kind about . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.0679e-01, 2.2829e-01, 2.8175e-01, 2.5045e-01, 1.0129e-01, 1.0806e-02,\n",
      "         2.9793e-06, 2.3317e-07, 6.1643e-03, 1.4456e-02],\n",
      "        [9.1151e-02, 1.7208e-01, 2.1951e-01, 2.3364e-01, 1.8360e-01, 6.5606e-02,\n",
      "         4.1172e-04, 5.4688e-05, 1.1288e-02, 2.2661e-02],\n",
      "        [8.9364e-02, 1.2413e-01, 1.4791e-01, 1.6962e-01, 2.0850e-01, 1.7300e-01,\n",
      "         1.5559e-02, 3.6768e-03, 2.7108e-02, 4.1119e-02],\n",
      "        [8.5002e-02, 1.1285e-01, 1.3397e-01, 1.5748e-01, 2.0702e-01, 1.9763e-01,\n",
      "         2.8841e-02, 8.1983e-03, 2.8407e-02, 4.0601e-02],\n",
      "        [8.2871e-02, 1.1231e-01, 1.3504e-01, 1.6113e-01, 2.1297e-01, 2.0122e-01,\n",
      "         2.5464e-02, 6.7094e-03, 2.5255e-02, 3.7035e-02],\n",
      "        [8.2673e-02, 1.1397e-01, 1.3813e-01, 1.6587e-01, 2.1568e-01, 1.9734e-01,\n",
      "         2.2045e-02, 5.6133e-03, 2.3427e-02, 3.5234e-02],\n",
      "        [8.2478e-02, 1.1426e-01, 1.3887e-01, 1.6690e-01, 2.1671e-01, 1.9630e-01,\n",
      "         2.1435e-02, 5.4296e-03, 2.3063e-02, 3.4555e-02],\n",
      "        [8.2235e-02, 1.1470e-01, 1.3974e-01, 1.6797e-01, 2.1782e-01, 1.9536e-01,\n",
      "         2.0357e-02, 5.0857e-03, 2.2673e-02, 3.4059e-02],\n",
      "        [8.2557e-02, 1.1602e-01, 1.4170e-01, 1.6996e-01, 2.1826e-01, 1.9252e-01,\n",
      "         1.8215e-02, 4.3695e-03, 2.2468e-02, 3.3931e-02]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 122.00, Train Loss: 1.99, Val Loss: 12.42, Train BLEU: 32.88, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本 基本上 都 没有 被 开发 发过 但是 像\n",
      "Reference: it &apos;s mostly unexplored , and yet there are\n",
      "Model: <SOS> and of the the , , , the the\n",
      "Attention Weights: tensor([[0.0409, 0.0881, 0.1106, 0.1265, 0.1251, 0.1277, 0.1193, 0.1119, 0.0945,\n",
      "         0.0555],\n",
      "        [0.0517, 0.0857, 0.1078, 0.1120, 0.1163, 0.1153, 0.1143, 0.1107, 0.1045,\n",
      "         0.0817],\n",
      "        [0.0739, 0.0919, 0.1059, 0.0998, 0.1050, 0.1023, 0.1049, 0.1046, 0.1068,\n",
      "         0.1047],\n",
      "        [0.0742, 0.0912, 0.1051, 0.0988, 0.1042, 0.1015, 0.1044, 0.1044, 0.1075,\n",
      "         0.1088],\n",
      "        [0.0699, 0.0887, 0.1044, 0.0991, 0.1048, 0.1024, 0.1052, 0.1054, 0.1088,\n",
      "         0.1113],\n",
      "        [0.0662, 0.0869, 0.1042, 0.0994, 0.1056, 0.1032, 0.1061, 0.1064, 0.1098,\n",
      "         0.1120],\n",
      "        [0.0664, 0.0869, 0.1041, 0.0994, 0.1056, 0.1032, 0.1061, 0.1064, 0.1098,\n",
      "         0.1121],\n",
      "        [0.0654, 0.0867, 0.1041, 0.0998, 0.1059, 0.1037, 0.1065, 0.1066, 0.1099,\n",
      "         0.1115],\n",
      "        [0.0651, 0.0865, 0.1040, 0.0999, 0.1060, 0.1038, 0.1066, 0.1068, 0.1100,\n",
      "         0.1112]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 永远 不会 忘记 那个 早晨 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: a morning that i will never forget . <EOS>\n",
      "Model: <SOS> it &apos;s a kind different . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0557, 0.1151, 0.1442, 0.1601, 0.1624, 0.1581, 0.1418, 0.0619, 0.0007,\n",
      "         0.0000],\n",
      "        [0.0704, 0.1066, 0.1260, 0.1409, 0.1395, 0.1396, 0.1408, 0.1069, 0.0232,\n",
      "         0.0062],\n",
      "        [0.0813, 0.0959, 0.1056, 0.1159, 0.1119, 0.1136, 0.1234, 0.1274, 0.0831,\n",
      "         0.0420],\n",
      "        [0.0792, 0.0948, 0.1052, 0.1156, 0.1122, 0.1141, 0.1237, 0.1294, 0.0835,\n",
      "         0.0423],\n",
      "        [0.0772, 0.0957, 0.1080, 0.1195, 0.1164, 0.1184, 0.1279, 0.1315, 0.0726,\n",
      "         0.0328],\n",
      "        [0.0770, 0.0962, 0.1088, 0.1205, 0.1176, 0.1197, 0.1287, 0.1313, 0.0694,\n",
      "         0.0307],\n",
      "        [0.0771, 0.0967, 0.1095, 0.1212, 0.1184, 0.1204, 0.1293, 0.1310, 0.0671,\n",
      "         0.0292],\n",
      "        [0.0772, 0.0969, 0.1098, 0.1216, 0.1188, 0.1208, 0.1297, 0.1308, 0.0659,\n",
      "         0.0285],\n",
      "        [0.0772, 0.0970, 0.1099, 0.1218, 0.1189, 0.1210, 0.1299, 0.1308, 0.0653,\n",
      "         0.0282]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 123.00, Train Loss: 1.96, Val Loss: 12.44, Train BLEU: 34.42, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 当 你 站 在 海滩 上 或是 当 你 看到\n",
      "Reference: part of the problem , i think , is\n",
      "Model: <SOS> and of the the , , , , ,\n",
      "Attention Weights: tensor([[0.0408, 0.0768, 0.1002, 0.1172, 0.1320, 0.1351, 0.1265, 0.1144, 0.1014,\n",
      "         0.0556],\n",
      "        [0.0505, 0.0760, 0.0938, 0.1077, 0.1221, 0.1206, 0.1210, 0.1132, 0.1091,\n",
      "         0.0860],\n",
      "        [0.0710, 0.0830, 0.0921, 0.0996, 0.1100, 0.1051, 0.1101, 0.1065, 0.1086,\n",
      "         0.1140],\n",
      "        [0.0718, 0.0826, 0.0913, 0.0985, 0.1085, 0.1037, 0.1090, 0.1065, 0.1095,\n",
      "         0.1186],\n",
      "        [0.0664, 0.0791, 0.0892, 0.0979, 0.1090, 0.1046, 0.1103, 0.1087, 0.1125,\n",
      "         0.1223],\n",
      "        [0.0631, 0.0770, 0.0881, 0.0976, 0.1096, 0.1055, 0.1114, 0.1102, 0.1143,\n",
      "         0.1232],\n",
      "        [0.0626, 0.0768, 0.0881, 0.0977, 0.1096, 0.1059, 0.1116, 0.1106, 0.1146,\n",
      "         0.1225],\n",
      "        [0.0623, 0.0767, 0.0881, 0.0978, 0.1098, 0.1061, 0.1118, 0.1107, 0.1147,\n",
      "         0.1220],\n",
      "        [0.0622, 0.0767, 0.0881, 0.0978, 0.1098, 0.1062, 0.1119, 0.1107, 0.1146,\n",
      "         0.1219]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 出身 阿富汗 边远 <UNK> 地区 有着 与 他人 不同\n",
      "Reference: a total maverick from a remote province of afghanistan\n",
      "Model: <SOS> it use the the to , the the the\n",
      "Attention Weights: tensor([[8.9094e-02, 1.7369e-01, 1.7290e-01, 6.9287e-02, 3.5451e-04, 1.6686e-01,\n",
      "         2.0660e-01, 1.1863e-01, 2.5825e-03, 5.8802e-11],\n",
      "        [7.8502e-02, 1.2742e-01, 1.4062e-01, 1.3101e-01, 1.3260e-02, 1.4860e-01,\n",
      "         1.8194e-01, 1.4753e-01, 3.1118e-02, 1.4632e-08],\n",
      "        [8.0444e-02, 1.0238e-01, 1.2051e-01, 1.6138e-01, 7.4654e-02, 1.1304e-01,\n",
      "         1.2669e-01, 1.3240e-01, 8.8496e-02, 2.4839e-06],\n",
      "        [7.9849e-02, 9.8691e-02, 1.1857e-01, 1.6708e-01, 9.3557e-02, 1.0279e-01,\n",
      "         1.1410e-01, 1.2572e-01, 9.9619e-02, 2.4707e-05],\n",
      "        [7.7110e-02, 9.9295e-02, 1.2368e-01, 1.8100e-01, 8.5984e-02, 9.8254e-02,\n",
      "         1.1265e-01, 1.2737e-01, 9.4641e-02, 2.1032e-05],\n",
      "        [7.6070e-02, 9.9469e-02, 1.2562e-01, 1.8618e-01, 8.2106e-02, 9.6572e-02,\n",
      "         1.1213e-01, 1.2813e-01, 9.3710e-02, 1.7609e-05],\n",
      "        [7.5920e-02, 1.0006e-01, 1.2686e-01, 1.8788e-01, 7.7808e-02, 9.7180e-02,\n",
      "         1.1346e-01, 1.2924e-01, 9.1574e-02, 1.2599e-05],\n",
      "        [7.6454e-02, 1.0119e-01, 1.2751e-01, 1.8650e-01, 7.3708e-02, 9.8913e-02,\n",
      "         1.1556e-01, 1.3022e-01, 8.9930e-02, 8.4531e-06],\n",
      "        [7.6466e-02, 1.0146e-01, 1.2774e-01, 1.8609e-01, 7.2448e-02, 9.9372e-02,\n",
      "         1.1625e-01, 1.3071e-01, 8.9455e-02, 7.9967e-06]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 124.00, Train Loss: 1.94, Val Loss: 12.45, Train BLEU: 35.19, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 原因 在于 我们 一直 没 把 海洋 当回事 回事 回事儿\n",
      "Reference: and the problem , i think , is that\n",
      "Model: <SOS> and the problem , , , , , ,\n",
      "Attention Weights: tensor([[0.0546, 0.1129, 0.1420, 0.1619, 0.1627, 0.1600, 0.1434, 0.0618, 0.0007,\n",
      "         0.0000],\n",
      "        [0.0677, 0.1047, 0.1255, 0.1429, 0.1416, 0.1423, 0.1425, 0.1063, 0.0211,\n",
      "         0.0054],\n",
      "        [0.0788, 0.0938, 0.1046, 0.1168, 0.1123, 0.1144, 0.1252, 0.1296, 0.0829,\n",
      "         0.0415],\n",
      "        [0.0766, 0.0924, 0.1039, 0.1162, 0.1122, 0.1145, 0.1253, 0.1319, 0.0845,\n",
      "         0.0425],\n",
      "        [0.0744, 0.0929, 0.1064, 0.1201, 0.1164, 0.1189, 0.1296, 0.1346, 0.0737,\n",
      "         0.0330],\n",
      "        [0.0742, 0.0935, 0.1073, 0.1211, 0.1177, 0.1202, 0.1304, 0.1342, 0.0705,\n",
      "         0.0309],\n",
      "        [0.0743, 0.0940, 0.1080, 0.1219, 0.1185, 0.1210, 0.1310, 0.1338, 0.0680,\n",
      "         0.0294],\n",
      "        [0.0744, 0.0942, 0.1082, 0.1223, 0.1189, 0.1214, 0.1314, 0.1336, 0.0669,\n",
      "         0.0287],\n",
      "        [0.0745, 0.0943, 0.1084, 0.1224, 0.1190, 0.1215, 0.1315, 0.1336, 0.0664,\n",
      "         0.0284]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在 一个 房屋 房屋里 屋里 我们 100 多 人\n",
      "Reference: the school was in a house , more than\n",
      "Model: <SOS> the biodiversity the the the , the the the\n",
      "Attention Weights: tensor([[0.0284, 0.0373, 0.1201, 0.1368, 0.1406, 0.1338, 0.1303, 0.1159, 0.1000,\n",
      "         0.0567],\n",
      "        [0.0448, 0.0733, 0.1075, 0.1178, 0.1184, 0.1223, 0.1187, 0.1081, 0.1039,\n",
      "         0.0852],\n",
      "        [0.0730, 0.1111, 0.0992, 0.1029, 0.1001, 0.1080, 0.1029, 0.0979, 0.0998,\n",
      "         0.1051],\n",
      "        [0.0725, 0.1139, 0.0970, 0.1014, 0.0989, 0.1069, 0.1017, 0.0977, 0.1007,\n",
      "         0.1092],\n",
      "        [0.0672, 0.1115, 0.0956, 0.1013, 0.0996, 0.1076, 0.1027, 0.0992, 0.1031,\n",
      "         0.1123],\n",
      "        [0.0631, 0.1087, 0.0951, 0.1018, 0.1005, 0.1087, 0.1036, 0.1003, 0.1047,\n",
      "         0.1135],\n",
      "        [0.0622, 0.1070, 0.0952, 0.1021, 0.1010, 0.1089, 0.1040, 0.1009, 0.1053,\n",
      "         0.1133],\n",
      "        [0.0614, 0.1060, 0.0955, 0.1024, 0.1014, 0.1093, 0.1044, 0.1012, 0.1055,\n",
      "         0.1129],\n",
      "        [0.0612, 0.1056, 0.0955, 0.1025, 0.1015, 0.1094, 0.1046, 0.1014, 0.1056,\n",
      "         0.1129]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 125.00, Train Loss: 1.92, Val Loss: 12.47, Train BLEU: 35.24, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 底下 这些 都 是 <UNK> 它们 上上 上上下下 上下 下下\n",
      "Reference: it &apos;s got these fishing <UNK> on the bottom\n",
      "Model: <SOS> it &apos;s got these fishing <UNK> on on bottom\n",
      "Attention Weights: tensor([[0.0767, 0.1280, 0.1146, 0.0319, 0.0000, 0.0684, 0.1221, 0.2723, 0.1825,\n",
      "         0.0034],\n",
      "        [0.0833, 0.1323, 0.1617, 0.1222, 0.0016, 0.0613, 0.1010, 0.1660, 0.1463,\n",
      "         0.0243],\n",
      "        [0.0865, 0.1166, 0.1576, 0.1914, 0.0282, 0.0609, 0.0874, 0.0988, 0.1050,\n",
      "         0.0677],\n",
      "        [0.0851, 0.1133, 0.1569, 0.2041, 0.0436, 0.0575, 0.0808, 0.0870, 0.0963,\n",
      "         0.0754],\n",
      "        [0.0845, 0.1170, 0.1666, 0.2162, 0.0378, 0.0513, 0.0754, 0.0841, 0.0959,\n",
      "         0.0712],\n",
      "        [0.0843, 0.1182, 0.1688, 0.2161, 0.0352, 0.0496, 0.0751, 0.0847, 0.0973,\n",
      "         0.0706],\n",
      "        [0.0841, 0.1182, 0.1693, 0.2166, 0.0338, 0.0495, 0.0752, 0.0852, 0.0980,\n",
      "         0.0703],\n",
      "        [0.0843, 0.1182, 0.1688, 0.2151, 0.0317, 0.0501, 0.0761, 0.0868, 0.0990,\n",
      "         0.0698],\n",
      "        [0.0843, 0.1185, 0.1692, 0.2152, 0.0299, 0.0502, 0.0765, 0.0875, 0.0993,\n",
      "         0.0695]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天 要 走 不同 的 路线 这样 才 没有\n",
      "Reference: each day , we took a different route so\n",
      "Model: <SOS> and of the the , , , , ,\n",
      "Attention Weights: tensor([[0.0407, 0.0878, 0.1154, 0.1258, 0.1279, 0.1289, 0.1193, 0.1092, 0.0968,\n",
      "         0.0483],\n",
      "        [0.0517, 0.0849, 0.1081, 0.1121, 0.1180, 0.1168, 0.1144, 0.1078, 0.1047,\n",
      "         0.0815],\n",
      "        [0.0752, 0.0912, 0.1037, 0.0989, 0.1062, 0.1025, 0.1053, 0.1014, 0.1040,\n",
      "         0.1117],\n",
      "        [0.0749, 0.0899, 0.1024, 0.0977, 0.1053, 0.1015, 0.1049, 0.1016, 0.1051,\n",
      "         0.1167],\n",
      "        [0.0682, 0.0862, 0.1014, 0.0977, 0.1063, 0.1025, 0.1061, 0.1032, 0.1079,\n",
      "         0.1205],\n",
      "        [0.0654, 0.0848, 0.1012, 0.0981, 0.1069, 0.1033, 0.1068, 0.1042, 0.1092,\n",
      "         0.1203],\n",
      "        [0.0650, 0.0849, 0.1013, 0.0984, 0.1070, 0.1036, 0.1069, 0.1044, 0.1093,\n",
      "         0.1191],\n",
      "        [0.0647, 0.0848, 0.1013, 0.0985, 0.1072, 0.1038, 0.1071, 0.1046, 0.1093,\n",
      "         0.1188],\n",
      "        [0.0647, 0.0848, 0.1012, 0.0986, 0.1072, 0.1038, 0.1071, 0.1046, 0.1093,\n",
      "         0.1188]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 126.00, Train Loss: 1.90, Val Loss: 12.48, Train BLEU: 35.14, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一种 种群 栖 动物 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: it &apos;s a colonial animal . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a jelly . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[9.0371e-02, 1.6763e-01, 2.1102e-01, 2.2998e-01, 2.1795e-01, 8.1967e-02,\n",
      "         1.0755e-03, 5.5892e-11, 5.5892e-11, 5.5892e-11],\n",
      "        [9.2425e-02, 1.4719e-01, 1.8423e-01, 2.0821e-01, 2.1349e-01, 1.3486e-01,\n",
      "         1.9595e-02, 1.2008e-08, 1.2008e-08, 1.2008e-08],\n",
      "        [1.0574e-01, 1.3070e-01, 1.5279e-01, 1.6851e-01, 1.7583e-01, 1.6837e-01,\n",
      "         9.8056e-02, 2.5997e-06, 2.5997e-06, 2.5997e-06],\n",
      "        [1.0602e-01, 1.2486e-01, 1.4419e-01, 1.5819e-01, 1.6612e-01, 1.7300e-01,\n",
      "         1.2751e-01, 3.6755e-05, 3.6755e-05, 3.6755e-05],\n",
      "        [1.0035e-01, 1.2143e-01, 1.4295e-01, 1.5918e-01, 1.6949e-01, 1.8073e-01,\n",
      "         1.2576e-01, 3.5676e-05, 3.5676e-05, 3.5676e-05],\n",
      "        [9.9150e-02, 1.2179e-01, 1.4412e-01, 1.6114e-01, 1.7173e-01, 1.8182e-01,\n",
      "         1.2019e-01, 2.0029e-05, 2.0029e-05, 2.0029e-05],\n",
      "        [9.9559e-02, 1.2272e-01, 1.4528e-01, 1.6267e-01, 1.7319e-01, 1.8081e-01,\n",
      "         1.1573e-01, 1.3052e-05, 1.3052e-05, 1.3052e-05],\n",
      "        [9.9564e-02, 1.2277e-01, 1.4541e-01, 1.6286e-01, 1.7339e-01, 1.8066e-01,\n",
      "         1.1530e-01, 1.2994e-05, 1.2994e-05, 1.2994e-05],\n",
      "        [9.9531e-02, 1.2277e-01, 1.4543e-01, 1.6290e-01, 1.7346e-01, 1.8067e-01,\n",
      "         1.1519e-01, 1.2870e-05, 1.2870e-05, 1.2870e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天 要 走 不同 的 路线 这样 才 没有\n",
      "Reference: each day , we took a different route so\n",
      "Model: <SOS> and of the the , , , , ,\n",
      "Attention Weights: tensor([[0.0396, 0.0853, 0.1131, 0.1277, 0.1291, 0.1302, 0.1201, 0.1092, 0.0970,\n",
      "         0.0487],\n",
      "        [0.0518, 0.0837, 0.1069, 0.1128, 0.1188, 0.1172, 0.1148, 0.1070, 0.1042,\n",
      "         0.0828],\n",
      "        [0.0763, 0.0913, 0.1038, 0.0991, 0.1068, 0.1023, 0.1051, 0.1002, 0.1029,\n",
      "         0.1122],\n",
      "        [0.0759, 0.0899, 0.1025, 0.0979, 0.1060, 0.1013, 0.1048, 0.1003, 0.1040,\n",
      "         0.1173],\n",
      "        [0.0689, 0.0859, 0.1015, 0.0980, 0.1071, 0.1023, 0.1061, 0.1018, 0.1067,\n",
      "         0.1217],\n",
      "        [0.0662, 0.0846, 0.1013, 0.0984, 0.1078, 0.1031, 0.1067, 0.1027, 0.1079,\n",
      "         0.1213],\n",
      "        [0.0659, 0.0847, 0.1014, 0.0987, 0.1079, 0.1035, 0.1068, 0.1029, 0.1079,\n",
      "         0.1202],\n",
      "        [0.0656, 0.0846, 0.1013, 0.0988, 0.1080, 0.1036, 0.1070, 0.1031, 0.1080,\n",
      "         0.1199],\n",
      "        [0.0656, 0.0846, 0.1013, 0.0989, 0.1080, 0.1037, 0.1070, 0.1031, 0.1080,\n",
      "         0.1199]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 127.00, Train Loss: 1.88, Val Loss: 12.49, Train BLEU: 36.72, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一只 水母 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: here &apos;s a jelly . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> here &apos;s a jelly . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.6852e-01, 3.0756e-01, 3.6005e-01, 1.6163e-01, 2.2414e-03, 1.3361e-10,\n",
      "         1.3361e-10, 1.3361e-10, 1.3361e-10, 1.3361e-10],\n",
      "        [1.6210e-01, 2.5737e-01, 3.1442e-01, 2.3025e-01, 3.5857e-02, 2.2186e-08,\n",
      "         2.2186e-08, 2.2186e-08, 2.2186e-08, 2.2186e-08],\n",
      "        [1.6283e-01, 2.0202e-01, 2.3811e-01, 2.4603e-01, 1.5100e-01, 3.7401e-06,\n",
      "         3.7401e-06, 3.7401e-06, 3.7401e-06, 3.7401e-06],\n",
      "        [1.5815e-01, 1.8738e-01, 2.2019e-01, 2.4385e-01, 1.9016e-01, 5.3730e-05,\n",
      "         5.3730e-05, 5.3730e-05, 5.3730e-05, 5.3730e-05],\n",
      "        [1.5046e-01, 1.8389e-01, 2.2200e-01, 2.5417e-01, 1.8921e-01, 5.4536e-05,\n",
      "         5.4536e-05, 5.4536e-05, 5.4536e-05, 5.4536e-05],\n",
      "        [1.4958e-01, 1.8575e-01, 2.2541e-01, 2.5679e-01, 1.8231e-01, 3.0276e-05,\n",
      "         3.0276e-05, 3.0276e-05, 3.0276e-05, 3.0276e-05],\n",
      "        [1.5094e-01, 1.8785e-01, 2.2767e-01, 2.5637e-01, 1.7706e-01, 2.0941e-05,\n",
      "         2.0941e-05, 2.0941e-05, 2.0941e-05, 2.0941e-05],\n",
      "        [1.5102e-01, 1.8804e-01, 2.2794e-01, 2.5629e-01, 1.7661e-01, 2.0840e-05,\n",
      "         2.0840e-05, 2.0840e-05, 2.0840e-05, 2.0840e-05],\n",
      "        [1.5101e-01, 1.8803e-01, 2.2795e-01, 2.5624e-01, 1.7666e-01, 2.0852e-05,\n",
      "         2.0852e-05, 2.0852e-05, 2.0852e-05, 2.0852e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 那 就是 她 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: there she is . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a kind about . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[6.6765e-02, 1.2594e-01, 1.3964e-01, 1.4950e-01, 1.5490e-01, 1.4440e-01,\n",
      "         1.3552e-01, 8.1841e-02, 1.5039e-03, 3.6055e-11],\n",
      "        [6.5869e-02, 1.1093e-01, 1.2638e-01, 1.3635e-01, 1.4431e-01, 1.4321e-01,\n",
      "         1.4384e-01, 1.1140e-01, 1.7705e-02, 7.4196e-09],\n",
      "        [8.1544e-02, 1.0164e-01, 1.1172e-01, 1.1742e-01, 1.2263e-01, 1.2658e-01,\n",
      "         1.2877e-01, 1.2511e-01, 8.4589e-02, 2.3984e-06],\n",
      "        [8.3083e-02, 9.8273e-02, 1.0733e-01, 1.1238e-01, 1.1713e-01, 1.2200e-01,\n",
      "         1.2477e-01, 1.2744e-01, 1.0758e-01, 3.3722e-05],\n",
      "        [7.8237e-02, 9.5791e-02, 1.0594e-01, 1.1176e-01, 1.1725e-01, 1.2307e-01,\n",
      "         1.2703e-01, 1.3195e-01, 1.0895e-01, 3.4946e-05],\n",
      "        [7.6529e-02, 9.5190e-02, 1.0562e-01, 1.1167e-01, 1.1739e-01, 1.2352e-01,\n",
      "         1.2783e-01, 1.3347e-01, 1.0877e-01, 2.7894e-05],\n",
      "        [7.5909e-02, 9.5292e-02, 1.0597e-01, 1.1219e-01, 1.1803e-01, 1.2415e-01,\n",
      "         1.2847e-01, 1.3364e-01, 1.0634e-01, 2.0101e-05],\n",
      "        [7.5822e-02, 9.5931e-02, 1.0656e-01, 1.1288e-01, 1.1881e-01, 1.2498e-01,\n",
      "         1.2920e-01, 1.3316e-01, 1.0264e-01, 1.2353e-05],\n",
      "        [7.5731e-02, 9.5906e-02, 1.0659e-01, 1.1299e-01, 1.1898e-01, 1.2520e-01,\n",
      "         1.2950e-01, 1.3325e-01, 1.0185e-01, 1.1870e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 128.00, Train Loss: 1.86, Val Loss: 12.50, Train BLEU: 37.20, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 但 我 想 告诉 你 的 是 当 你 站\n",
      "Reference: but when you &apos;re standing at the beach ,\n",
      "Model: <SOS> but of the the and , , , ,\n",
      "Attention Weights: tensor([[0.0421, 0.0773, 0.0992, 0.1191, 0.1268, 0.1294, 0.1237, 0.1140, 0.1025,\n",
      "         0.0659],\n",
      "        [0.0510, 0.0768, 0.0943, 0.1117, 0.1167, 0.1203, 0.1186, 0.1144, 0.1091,\n",
      "         0.0871],\n",
      "        [0.0731, 0.0839, 0.0925, 0.1018, 0.1032, 0.1065, 0.1078, 0.1085, 0.1106,\n",
      "         0.1122],\n",
      "        [0.0748, 0.0839, 0.0918, 0.1006, 0.1018, 0.1051, 0.1068, 0.1081, 0.1110,\n",
      "         0.1160],\n",
      "        [0.0711, 0.0813, 0.0902, 0.1002, 0.1018, 0.1057, 0.1077, 0.1096, 0.1131,\n",
      "         0.1194],\n",
      "        [0.0670, 0.0785, 0.0886, 0.1000, 0.1020, 0.1064, 0.1089, 0.1111, 0.1152,\n",
      "         0.1222],\n",
      "        [0.0661, 0.0779, 0.0883, 0.1000, 0.1022, 0.1067, 0.1092, 0.1115, 0.1157,\n",
      "         0.1223],\n",
      "        [0.0654, 0.0775, 0.0881, 0.1001, 0.1024, 0.1070, 0.1095, 0.1119, 0.1160,\n",
      "         0.1222],\n",
      "        [0.0650, 0.0775, 0.0881, 0.1002, 0.1027, 0.1072, 0.1097, 0.1121, 0.1160,\n",
      "         0.1215]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 对 他 来说 孩子 不 接受 受教 教育 <UNK> 是\n",
      "Reference: to him , there was greater risk in not\n",
      "Model: <SOS> we use the the alvin alvin the the the\n",
      "Attention Weights: tensor([[9.1219e-02, 1.6703e-01, 2.1113e-01, 2.3076e-01, 2.1727e-01, 8.1428e-02,\n",
      "         1.1641e-03, 6.1132e-11, 6.1132e-11, 6.1132e-11],\n",
      "        [9.2616e-02, 1.4747e-01, 1.8531e-01, 2.0957e-01, 2.1312e-01, 1.3274e-01,\n",
      "         1.9174e-02, 1.0721e-08, 1.0721e-08, 1.0721e-08],\n",
      "        [1.0581e-01, 1.3048e-01, 1.5240e-01, 1.6796e-01, 1.7460e-01, 1.6798e-01,\n",
      "         1.0075e-01, 2.5035e-06, 2.5035e-06, 2.5035e-06],\n",
      "        [1.0623e-01, 1.2435e-01, 1.4322e-01, 1.5692e-01, 1.6429e-01, 1.7266e-01,\n",
      "         1.3222e-01, 3.8433e-05, 3.8433e-05, 3.8433e-05],\n",
      "        [1.0010e-01, 1.2038e-01, 1.4146e-01, 1.5746e-01, 1.6735e-01, 1.8090e-01,\n",
      "         1.3222e-01, 4.0321e-05, 4.0321e-05, 4.0321e-05],\n",
      "        [9.8604e-02, 1.2037e-01, 1.4229e-01, 1.5915e-01, 1.6940e-01, 1.8242e-01,\n",
      "         1.2770e-01, 2.2958e-05, 2.2958e-05, 2.2958e-05],\n",
      "        [9.8989e-02, 1.2125e-01, 1.4339e-01, 1.6063e-01, 1.7086e-01, 1.8145e-01,\n",
      "         1.2339e-01, 1.4913e-05, 1.4913e-05, 1.4913e-05],\n",
      "        [9.9025e-02, 1.2131e-01, 1.4352e-01, 1.6081e-01, 1.7104e-01, 1.8126e-01,\n",
      "         1.2299e-01, 1.4931e-05, 1.4931e-05, 1.4931e-05],\n",
      "        [9.9002e-02, 1.2131e-01, 1.4354e-01, 1.6084e-01, 1.7110e-01, 1.8126e-01,\n",
      "         1.2289e-01, 1.4807e-05, 1.4807e-05, 1.4807e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 129.00, Train Loss: 1.84, Val Loss: 12.51, Train BLEU: 37.64, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 和 我们 合作 的 人们 帮 我们 找到 了 新\n",
      "Reference: people that have partnered with us have given us\n",
      "Model: <SOS> but of the the and and , , the\n",
      "Attention Weights: tensor([[0.0384, 0.0795, 0.1122, 0.1190, 0.1260, 0.1307, 0.1251, 0.1139, 0.0968,\n",
      "         0.0585],\n",
      "        [0.0482, 0.0792, 0.1062, 0.1111, 0.1194, 0.1189, 0.1194, 0.1158, 0.1024,\n",
      "         0.0795],\n",
      "        [0.0719, 0.0856, 0.1003, 0.1001, 0.1067, 0.1030, 0.1076, 0.1105, 0.1065,\n",
      "         0.1078],\n",
      "        [0.0739, 0.0856, 0.0993, 0.0989, 0.1055, 0.1014, 0.1065, 0.1100, 0.1070,\n",
      "         0.1120],\n",
      "        [0.0702, 0.0831, 0.0986, 0.0986, 0.1059, 0.1016, 0.1074, 0.1110, 0.1084,\n",
      "         0.1152],\n",
      "        [0.0659, 0.0805, 0.0978, 0.0983, 0.1067, 0.1022, 0.1085, 0.1124, 0.1100,\n",
      "         0.1177],\n",
      "        [0.0656, 0.0803, 0.0979, 0.0984, 0.1069, 0.1023, 0.1087, 0.1125, 0.1099,\n",
      "         0.1174],\n",
      "        [0.0649, 0.0799, 0.0978, 0.0984, 0.1070, 0.1025, 0.1089, 0.1126, 0.1103,\n",
      "         0.1178],\n",
      "        [0.0640, 0.0795, 0.0977, 0.0987, 0.1071, 0.1030, 0.1092, 0.1126, 0.1106,\n",
      "         0.1176]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 想 过 要 放弃 但 我 的 父亲 这时\n",
      "Reference: i would want to quit , but my father\n",
      "Model: <SOS> and of the the the , , , ,\n",
      "Attention Weights: tensor([[0.0587, 0.1189, 0.1424, 0.1573, 0.1552, 0.1496, 0.1439, 0.0735, 0.0005,\n",
      "         0.0000],\n",
      "        [0.0614, 0.1116, 0.1324, 0.1469, 0.1488, 0.1460, 0.1458, 0.1010, 0.0053,\n",
      "         0.0008],\n",
      "        [0.0711, 0.0989, 0.1115, 0.1223, 0.1256, 0.1297, 0.1399, 0.1330, 0.0509,\n",
      "         0.0171],\n",
      "        [0.0745, 0.0876, 0.0947, 0.1020, 0.1041, 0.1101, 0.1208, 0.1333, 0.1132,\n",
      "         0.0598],\n",
      "        [0.0729, 0.0833, 0.0894, 0.0964, 0.0984, 0.1049, 0.1159, 0.1340, 0.1306,\n",
      "         0.0742],\n",
      "        [0.0680, 0.0799, 0.0871, 0.0953, 0.0981, 0.1060, 0.1200, 0.1447, 0.1340,\n",
      "         0.0670],\n",
      "        [0.0659, 0.0788, 0.0867, 0.0957, 0.0988, 0.1076, 0.1231, 0.1491, 0.1329,\n",
      "         0.0614],\n",
      "        [0.0664, 0.0798, 0.0880, 0.0972, 0.1004, 0.1091, 0.1249, 0.1490, 0.1277,\n",
      "         0.0575],\n",
      "        [0.0667, 0.0805, 0.0888, 0.0983, 0.1015, 0.1102, 0.1260, 0.1487, 0.1242,\n",
      "         0.0550]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 130.00, Train Loss: 1.82, Val Loss: 12.52, Train BLEU: 37.66, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中 的 生命 大卫 <UNK> <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: life in the deep oceans <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> life in the deep oceans <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.6766e-01, 3.4086e-01, 3.4448e-01, 1.4165e-01, 5.3398e-03, 4.0568e-07,\n",
      "         2.4192e-07, 1.3617e-10, 1.3617e-10, 1.3617e-10],\n",
      "        [1.3575e-01, 2.7557e-01, 3.3268e-01, 2.3091e-01, 2.5078e-02, 4.8399e-06,\n",
      "         2.9902e-06, 1.0628e-09, 1.0628e-09, 1.0628e-09],\n",
      "        [1.2130e-01, 1.8772e-01, 2.3784e-01, 2.8036e-01, 1.6975e-01, 1.9531e-03,\n",
      "         1.0687e-03, 1.9674e-07, 1.9674e-07, 1.9674e-07],\n",
      "        [1.1658e-01, 1.5603e-01, 1.9467e-01, 2.6390e-01, 2.4775e-01, 1.4050e-02,\n",
      "         6.9982e-03, 4.5367e-06, 4.5367e-06, 4.5367e-06],\n",
      "        [1.0920e-01, 1.4984e-01, 1.9181e-01, 2.7264e-01, 2.5897e-01, 1.1909e-02,\n",
      "         5.6156e-03, 5.9720e-06, 5.9720e-06, 5.9720e-06],\n",
      "        [1.0874e-01, 1.5105e-01, 1.9389e-01, 2.7521e-01, 2.5624e-01, 1.0150e-02,\n",
      "         4.7044e-03, 4.8680e-06, 4.8680e-06, 4.8680e-06],\n",
      "        [1.0975e-01, 1.5265e-01, 1.9525e-01, 2.7517e-01, 2.5292e-01, 9.7374e-03,\n",
      "         4.5142e-03, 3.9732e-06, 3.9732e-06, 3.9732e-06],\n",
      "        [1.0980e-01, 1.5251e-01, 1.9490e-01, 2.7462e-01, 2.5347e-01, 1.0033e-02,\n",
      "         4.6519e-03, 4.1151e-06, 4.1151e-06, 4.1151e-06],\n",
      "        [1.0979e-01, 1.5238e-01, 1.9470e-01, 2.7441e-01, 2.5384e-01, 1.0168e-02,\n",
      "         4.7128e-03, 4.1960e-06, 4.1960e-06, 4.1960e-06]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 很 害怕 但是 我们 仍然 渴望 望去 学校 <EOS>\n",
      "Reference: we were scared , but still , school was\n",
      "Model: <SOS> it &apos;s a those planet is . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0383, 0.0796, 0.1130, 0.1195, 0.1260, 0.1312, 0.1248, 0.1134, 0.0964,\n",
      "         0.0576],\n",
      "        [0.0480, 0.0796, 0.1070, 0.1117, 0.1197, 0.1197, 0.1195, 0.1158, 0.1017,\n",
      "         0.0773],\n",
      "        [0.0722, 0.0860, 0.1005, 0.1003, 0.1067, 0.1032, 0.1077, 0.1108, 0.1061,\n",
      "         0.1064],\n",
      "        [0.0746, 0.0861, 0.0995, 0.0990, 0.1054, 0.1015, 0.1066, 0.1102, 0.1065,\n",
      "         0.1106],\n",
      "        [0.0708, 0.0836, 0.0988, 0.0987, 0.1059, 0.1017, 0.1074, 0.1112, 0.1079,\n",
      "         0.1139],\n",
      "        [0.0665, 0.0809, 0.0980, 0.0984, 0.1067, 0.1022, 0.1086, 0.1126, 0.1095,\n",
      "         0.1164],\n",
      "        [0.0663, 0.0808, 0.0981, 0.0985, 0.1069, 0.1024, 0.1088, 0.1128, 0.1095,\n",
      "         0.1161],\n",
      "        [0.0655, 0.0804, 0.0980, 0.0985, 0.1070, 0.1026, 0.1090, 0.1129, 0.1098,\n",
      "         0.1164],\n",
      "        [0.0645, 0.0799, 0.0980, 0.0988, 0.1072, 0.1031, 0.1093, 0.1129, 0.1101,\n",
      "         0.1163]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 131.00, Train Loss: 1.79, Val Loss: 12.53, Train BLEU: 37.22, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的 平均 深度 是 两英里 英里 <EOS> <PAD> <PAD>\n",
      "Reference: the average depth is about two miles . <EOS>\n",
      "Model: <SOS> the average the is about . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.2562e-01, 2.1154e-01, 2.3709e-01, 2.4072e-01, 1.7365e-01, 1.2082e-03,\n",
      "         1.0088e-02, 9.1234e-05, 1.1576e-10, 1.1576e-10],\n",
      "        [1.1984e-01, 1.6928e-01, 1.9784e-01, 2.1625e-01, 2.0398e-01, 3.2119e-02,\n",
      "         5.2724e-02, 7.9617e-03, 3.3674e-08, 3.3674e-08],\n",
      "        [1.1593e-01, 1.2902e-01, 1.4727e-01, 1.6295e-01, 1.7927e-01, 1.1480e-01,\n",
      "         1.0134e-01, 4.9425e-02, 2.6283e-06, 2.6283e-06],\n",
      "        [1.0987e-01, 1.1833e-01, 1.3447e-01, 1.5002e-01, 1.7275e-01, 1.3739e-01,\n",
      "         1.1054e-01, 6.6592e-02, 2.1922e-05, 2.1922e-05],\n",
      "        [1.0650e-01, 1.1790e-01, 1.3672e-01, 1.5578e-01, 1.8580e-01, 1.3187e-01,\n",
      "         1.0621e-01, 5.9181e-02, 2.4034e-05, 2.4034e-05],\n",
      "        [1.0474e-01, 1.1710e-01, 1.3688e-01, 1.5723e-01, 1.9035e-01, 1.3051e-01,\n",
      "         1.0538e-01, 5.7756e-02, 2.3489e-05, 2.3489e-05],\n",
      "        [1.0431e-01, 1.1726e-01, 1.3785e-01, 1.5906e-01, 1.9287e-01, 1.2930e-01,\n",
      "         1.0371e-01, 5.5598e-02, 1.8193e-05, 1.8193e-05],\n",
      "        [1.0450e-01, 1.1833e-01, 1.3925e-01, 1.6063e-01, 1.9342e-01, 1.2663e-01,\n",
      "         1.0306e-01, 5.4154e-02, 1.3823e-05, 1.3823e-05],\n",
      "        [1.0446e-01, 1.1863e-01, 1.3982e-01, 1.6127e-01, 1.9383e-01, 1.2578e-01,\n",
      "         1.0267e-01, 5.3511e-02, 1.2884e-05, 1.2884e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 这 是 我们 俩 人 唯一 的 受教 教育 方式\n",
      "Reference: it was the only way we both could be\n",
      "Model: <SOS> we we the the the , the the the\n",
      "Attention Weights: tensor([[0.0386, 0.0725, 0.0970, 0.1150, 0.1364, 0.1377, 0.1278, 0.1176, 0.1018,\n",
      "         0.0556],\n",
      "        [0.0478, 0.0742, 0.0937, 0.1084, 0.1272, 0.1246, 0.1236, 0.1146, 0.1066,\n",
      "         0.0793],\n",
      "        [0.0713, 0.0824, 0.0914, 0.0986, 0.1112, 0.1052, 0.1117, 0.1065, 0.1074,\n",
      "         0.1143],\n",
      "        [0.0741, 0.0830, 0.0907, 0.0971, 0.1091, 0.1028, 0.1102, 0.1055, 0.1076,\n",
      "         0.1200],\n",
      "        [0.0685, 0.0789, 0.0881, 0.0961, 0.1101, 0.1033, 0.1119, 0.1071, 0.1102,\n",
      "         0.1258],\n",
      "        [0.0642, 0.0758, 0.0862, 0.0954, 0.1111, 0.1041, 0.1135, 0.1087, 0.1123,\n",
      "         0.1287],\n",
      "        [0.0633, 0.0754, 0.0861, 0.0956, 0.1114, 0.1046, 0.1137, 0.1092, 0.1127,\n",
      "         0.1279],\n",
      "        [0.0630, 0.0754, 0.0862, 0.0957, 0.1116, 0.1049, 0.1138, 0.1094, 0.1127,\n",
      "         0.1273],\n",
      "        [0.0629, 0.0753, 0.0862, 0.0957, 0.1116, 0.1050, 0.1139, 0.1094, 0.1127,\n",
      "         0.1272]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 132.00, Train Loss: 1.77, Val Loss: 12.54, Train BLEU: 37.22, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 当 你 站 在 海滩 上 或是 当 你 看到\n",
      "Reference: part of the problem , i think , is\n",
      "Model: <SOS> and of the the , , , , ,\n",
      "Attention Weights: tensor([[0.0385, 0.0726, 0.0975, 0.1156, 0.1383, 0.1366, 0.1285, 0.1162, 0.1007,\n",
      "         0.0557],\n",
      "        [0.0475, 0.0743, 0.0943, 0.1092, 0.1286, 0.1245, 0.1240, 0.1138, 0.1055,\n",
      "         0.0783],\n",
      "        [0.0711, 0.0824, 0.0917, 0.0989, 0.1117, 0.1053, 0.1118, 0.1063, 0.1069,\n",
      "         0.1139],\n",
      "        [0.0742, 0.0831, 0.0909, 0.0974, 0.1093, 0.1028, 0.1103, 0.1053, 0.1072,\n",
      "         0.1196],\n",
      "        [0.0683, 0.0788, 0.0882, 0.0963, 0.1105, 0.1033, 0.1121, 0.1070, 0.1099,\n",
      "         0.1257],\n",
      "        [0.0641, 0.0757, 0.0863, 0.0956, 0.1115, 0.1040, 0.1136, 0.1086, 0.1119,\n",
      "         0.1287],\n",
      "        [0.0632, 0.0753, 0.0862, 0.0958, 0.1118, 0.1046, 0.1139, 0.1091, 0.1122,\n",
      "         0.1279],\n",
      "        [0.0629, 0.0753, 0.0863, 0.0959, 0.1120, 0.1048, 0.1141, 0.1092, 0.1122,\n",
      "         0.1274],\n",
      "        [0.0627, 0.0752, 0.0863, 0.0959, 0.1120, 0.1049, 0.1142, 0.1092, 0.1122,\n",
      "         0.1273]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6 岁 那年 塔利 塔利班 占领 阿富汗 并 规定\n",
      "Reference: you see , i was six when the taliban\n",
      "Model: <SOS> the of the the and the the the the\n",
      "Attention Weights: tensor([[7.2927e-02, 1.5695e-01, 1.9998e-01, 1.6731e-01, 1.3989e-01, 1.2589e-01,\n",
      "         1.0378e-01, 3.2664e-02, 6.0464e-04, 4.3877e-11],\n",
      "        [7.2674e-02, 1.2523e-01, 1.6276e-01, 1.5493e-01, 1.4070e-01, 1.3590e-01,\n",
      "         1.2611e-01, 7.0677e-02, 1.1015e-02, 1.0566e-08],\n",
      "        [9.1213e-02, 1.0999e-01, 1.3127e-01, 1.3573e-01, 1.2071e-01, 1.1682e-01,\n",
      "         1.1703e-01, 1.0990e-01, 6.7325e-02, 3.0366e-06],\n",
      "        [9.1013e-02, 1.0338e-01, 1.2108e-01, 1.2849e-01, 1.1603e-01, 1.1357e-01,\n",
      "         1.1632e-01, 1.2029e-01, 8.9791e-02, 3.3746e-05],\n",
      "        [8.5698e-02, 1.0035e-01, 1.2139e-01, 1.2929e-01, 1.1524e-01, 1.1419e-01,\n",
      "         1.1854e-01, 1.2566e-01, 8.9612e-02, 2.9510e-05],\n",
      "        [8.3480e-02, 9.9771e-02, 1.2224e-01, 1.3032e-01, 1.1529e-01, 1.1455e-01,\n",
      "         1.1935e-01, 1.2693e-01, 8.8056e-02, 2.1594e-05],\n",
      "        [8.2368e-02, 1.0037e-01, 1.2327e-01, 1.3165e-01, 1.1600e-01, 1.1529e-01,\n",
      "         1.1985e-01, 1.2588e-01, 8.5307e-02, 1.2356e-05],\n",
      "        [8.1971e-02, 1.0018e-01, 1.2300e-01, 1.3155e-01, 1.1628e-01, 1.1595e-01,\n",
      "         1.2053e-01, 1.2592e-01, 8.4603e-02, 1.1570e-05],\n",
      "        [8.1984e-02, 1.0012e-01, 1.2286e-01, 1.3143e-01, 1.1628e-01, 1.1603e-01,\n",
      "         1.2063e-01, 1.2598e-01, 8.4685e-02, 1.1751e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 133.00, Train Loss: 1.75, Val Loss: 12.56, Train BLEU: 37.09, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 还有 前面 的 这个 是 推进 引擎 它 一会 一会儿\n",
      "Reference: and it &apos;s got these jet thrusters up in\n",
      "Model: <SOS> and it &apos;s got these jet thrusters thrusters in\n",
      "Attention Weights: tensor([[0.0587, 0.1209, 0.1457, 0.1577, 0.1563, 0.1468, 0.1431, 0.0704, 0.0005,\n",
      "         0.0000],\n",
      "        [0.0604, 0.1138, 0.1361, 0.1480, 0.1507, 0.1444, 0.1451, 0.0967, 0.0042,\n",
      "         0.0005],\n",
      "        [0.0700, 0.1013, 0.1157, 0.1260, 0.1301, 0.1324, 0.1424, 0.1280, 0.0415,\n",
      "         0.0126],\n",
      "        [0.0745, 0.0889, 0.0967, 0.1041, 0.1065, 0.1125, 0.1243, 0.1327, 0.1062,\n",
      "         0.0535],\n",
      "        [0.0730, 0.0842, 0.0908, 0.0981, 0.1001, 0.1071, 0.1191, 0.1341, 0.1248,\n",
      "         0.0687],\n",
      "        [0.0674, 0.0801, 0.0879, 0.0965, 0.0998, 0.1082, 0.1235, 0.1452, 0.1289,\n",
      "         0.0624],\n",
      "        [0.0649, 0.0786, 0.0871, 0.0966, 0.1002, 0.1096, 0.1266, 0.1494, 0.1291,\n",
      "         0.0580],\n",
      "        [0.0649, 0.0791, 0.0878, 0.0976, 0.1011, 0.1108, 0.1283, 0.1495, 0.1257,\n",
      "         0.0552],\n",
      "        [0.0652, 0.0797, 0.0886, 0.0986, 0.1022, 0.1117, 0.1292, 0.1491, 0.1227,\n",
      "         0.0530]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 但是 我 那 受过 教育 的 母亲 成为 为了 一名\n",
      "Reference: but my educated mother became a teacher . <EOS>\n",
      "Model: <SOS> the of the the the , the the the\n",
      "Attention Weights: tensor([[3.5682e-01, 4.8122e-01, 8.6688e-02, 8.9532e-06, 1.6386e-05, 2.3129e-02,\n",
      "         5.0107e-02, 2.0080e-03, 2.3668e-10, 2.3668e-10],\n",
      "        [2.3724e-01, 4.5335e-01, 2.2978e-01, 2.8586e-04, 3.2226e-04, 2.4309e-02,\n",
      "         4.4890e-02, 9.8242e-03, 4.3461e-09, 4.3461e-09],\n",
      "        [1.6900e-01, 3.2423e-01, 3.4893e-01, 1.7730e-02, 1.1071e-02, 3.4057e-02,\n",
      "         4.8707e-02, 4.6276e-02, 6.1682e-07, 6.1682e-07],\n",
      "        [1.5594e-01, 2.8289e-01, 3.4676e-01, 4.2662e-02, 2.3355e-02, 3.6890e-02,\n",
      "         5.0096e-02, 6.1393e-02, 9.4870e-06, 9.4870e-06],\n",
      "        [1.5496e-01, 2.9029e-01, 3.5860e-01, 3.9442e-02, 2.0568e-02, 3.3115e-02,\n",
      "         4.5856e-02, 5.7153e-02, 1.0866e-05, 1.0866e-05],\n",
      "        [1.5351e-01, 2.9407e-01, 3.6410e-01, 3.7929e-02, 1.9070e-02, 3.1327e-02,\n",
      "         4.4309e-02, 5.5669e-02, 1.0760e-05, 1.0760e-05],\n",
      "        [1.5279e-01, 2.9949e-01, 3.6817e-01, 3.4265e-02, 1.7047e-02, 3.0498e-02,\n",
      "         4.3714e-02, 5.4010e-02, 8.1508e-06, 8.1508e-06],\n",
      "        [1.5199e-01, 2.9944e-01, 3.6932e-01, 3.3541e-02, 1.6179e-02, 3.0820e-02,\n",
      "         4.4182e-02, 5.4522e-02, 7.2662e-06, 7.2662e-06],\n",
      "        [1.5129e-01, 2.9855e-01, 3.6982e-01, 3.3773e-02, 1.6193e-02, 3.1079e-02,\n",
      "         4.4407e-02, 5.4873e-02, 7.0971e-06, 7.0971e-06]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 134.00, Train Loss: 1.73, Val Loss: 12.58, Train BLEU: 38.92, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 是 我 最 喜欢 的 因为 它 哪 都 能动\n",
      "Reference: it &apos;s one of my favorites , because it\n",
      "Model: <SOS> it &apos;s one of my favorites , , ,\n",
      "Attention Weights: tensor([[0.0490, 0.0929, 0.1223, 0.1438, 0.1495, 0.1417, 0.1258, 0.1058, 0.0682,\n",
      "         0.0011],\n",
      "        [0.0548, 0.0888, 0.1128, 0.1322, 0.1373, 0.1355, 0.1253, 0.1132, 0.0894,\n",
      "         0.0106],\n",
      "        [0.0708, 0.0863, 0.0985, 0.1100, 0.1127, 0.1174, 0.1130, 0.1113, 0.1118,\n",
      "         0.0682],\n",
      "        [0.0737, 0.0847, 0.0939, 0.1035, 0.1054, 0.1115, 0.1081, 0.1089, 0.1165,\n",
      "         0.0936],\n",
      "        [0.0693, 0.0812, 0.0910, 0.1016, 0.1041, 0.1112, 0.1091, 0.1113, 0.1229,\n",
      "         0.0983],\n",
      "        [0.0659, 0.0788, 0.0895, 0.1012, 0.1040, 0.1121, 0.1101, 0.1129, 0.1265,\n",
      "         0.0992],\n",
      "        [0.0655, 0.0783, 0.0892, 0.1013, 0.1042, 0.1125, 0.1105, 0.1133, 0.1269,\n",
      "         0.0983],\n",
      "        [0.0657, 0.0786, 0.0896, 0.1017, 0.1048, 0.1129, 0.1110, 0.1136, 0.1260,\n",
      "         0.0960],\n",
      "        [0.0657, 0.0786, 0.0896, 0.1018, 0.1049, 0.1131, 0.1112, 0.1137, 0.1257,\n",
      "         0.0957]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 她 两年 年前 退休 了 结果 却 把 我家 变成\n",
      "Reference: she retired two years ago , only to turn\n",
      "Model: <SOS> the of the the matter the the the the\n",
      "Attention Weights: tensor([[1.2307e-01, 2.2264e-01, 2.7246e-01, 2.7396e-01, 1.0631e-01, 1.5624e-03,\n",
      "         1.2018e-10, 1.2018e-10, 1.2018e-10, 1.2018e-10],\n",
      "        [1.1913e-01, 1.9212e-01, 2.4109e-01, 2.6150e-01, 1.6543e-01, 2.0734e-02,\n",
      "         1.1225e-08, 1.1225e-08, 1.1225e-08, 1.1225e-08],\n",
      "        [1.2657e-01, 1.5841e-01, 1.8721e-01, 2.0776e-01, 2.0303e-01, 1.1701e-01,\n",
      "         2.1143e-06, 2.1143e-06, 2.1143e-06, 2.1143e-06],\n",
      "        [1.2509e-01, 1.4729e-01, 1.7157e-01, 1.9093e-01, 2.0592e-01, 1.5905e-01,\n",
      "         3.5597e-05, 3.5597e-05, 3.5597e-05, 3.5597e-05],\n",
      "        [1.1885e-01, 1.4301e-01, 1.6972e-01, 1.9240e-01, 2.1383e-01, 1.6200e-01,\n",
      "         4.9004e-05, 4.9004e-05, 4.9004e-05, 4.9004e-05],\n",
      "        [1.1674e-01, 1.4158e-01, 1.6906e-01, 1.9291e-01, 2.1643e-01, 1.6310e-01,\n",
      "         4.5469e-05, 4.5469e-05, 4.5469e-05, 4.5469e-05],\n",
      "        [1.1547e-01, 1.4118e-01, 1.6945e-01, 1.9445e-01, 2.1811e-01, 1.6121e-01,\n",
      "         3.3919e-05, 3.3919e-05, 3.3919e-05, 3.3919e-05],\n",
      "        [1.1573e-01, 1.4224e-01, 1.7071e-01, 1.9613e-01, 2.1747e-01, 1.5765e-01,\n",
      "         2.0750e-05, 2.0750e-05, 2.0750e-05, 2.0750e-05],\n",
      "        [1.1570e-01, 1.4241e-01, 1.7118e-01, 1.9678e-01, 2.1726e-01, 1.5659e-01,\n",
      "         2.0035e-05, 2.0035e-05, 2.0035e-05, 2.0035e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 135.00, Train Loss: 1.71, Val Loss: 12.59, Train BLEU: 38.92, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 原因 在于 我们 一直 没 把 海洋 当回事 回事 回事儿\n",
      "Reference: and the problem , i think , is that\n",
      "Model: <SOS> and the problem , , , , , ,\n",
      "Attention Weights: tensor([[0.0552, 0.1126, 0.1429, 0.1713, 0.1652, 0.1604, 0.1344, 0.0573, 0.0007,\n",
      "         0.0000],\n",
      "        [0.0663, 0.1048, 0.1279, 0.1518, 0.1442, 0.1430, 0.1408, 0.0996, 0.0174,\n",
      "         0.0043],\n",
      "        [0.0758, 0.0884, 0.0998, 0.1166, 0.1063, 0.1087, 0.1286, 0.1331, 0.0933,\n",
      "         0.0494],\n",
      "        [0.0728, 0.0854, 0.0972, 0.1145, 0.1043, 0.1070, 0.1284, 0.1374, 0.0996,\n",
      "         0.0536],\n",
      "        [0.0701, 0.0848, 0.0986, 0.1180, 0.1074, 0.1104, 0.1328, 0.1419, 0.0917,\n",
      "         0.0443],\n",
      "        [0.0698, 0.0851, 0.0994, 0.1189, 0.1087, 0.1116, 0.1335, 0.1418, 0.0890,\n",
      "         0.0420],\n",
      "        [0.0700, 0.0858, 0.1002, 0.1199, 0.1096, 0.1125, 0.1342, 0.1413, 0.0863,\n",
      "         0.0402],\n",
      "        [0.0702, 0.0861, 0.1006, 0.1203, 0.1101, 0.1130, 0.1344, 0.1408, 0.0850,\n",
      "         0.0395],\n",
      "        [0.0703, 0.0863, 0.1008, 0.1205, 0.1103, 0.1132, 0.1346, 0.1406, 0.0843,\n",
      "         0.0391]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 总是 担心 会 被 塔利 塔利班 发现 <EOS> <PAD>\n",
      "Reference: we always wondered what they knew about us .\n",
      "Model: <SOS> it &apos;s got to to about about . <EOS>\n",
      "Attention Weights: tensor([[0.0082, 0.0023, 0.1466, 0.1895, 0.1950, 0.1790, 0.1475, 0.0258, 0.0636,\n",
      "         0.0426],\n",
      "        [0.0259, 0.0230, 0.1284, 0.1492, 0.1525, 0.1512, 0.1456, 0.0674, 0.0845,\n",
      "         0.0725],\n",
      "        [0.0558, 0.0722, 0.1044, 0.1090, 0.1113, 0.1194, 0.1293, 0.1095, 0.0955,\n",
      "         0.0937],\n",
      "        [0.0596, 0.0799, 0.1001, 0.1044, 0.1075, 0.1170, 0.1287, 0.1128, 0.0944,\n",
      "         0.0955],\n",
      "        [0.0596, 0.0802, 0.0993, 0.1040, 0.1073, 0.1175, 0.1297, 0.1127, 0.0940,\n",
      "         0.0957],\n",
      "        [0.0584, 0.0800, 0.0988, 0.1039, 0.1075, 0.1186, 0.1317, 0.1127, 0.0931,\n",
      "         0.0954],\n",
      "        [0.0566, 0.0779, 0.0991, 0.1047, 0.1085, 0.1201, 0.1333, 0.1119, 0.0925,\n",
      "         0.0952],\n",
      "        [0.0550, 0.0755, 0.0997, 0.1061, 0.1102, 0.1218, 0.1346, 0.1104, 0.0921,\n",
      "         0.0946],\n",
      "        [0.0543, 0.0742, 0.1001, 0.1066, 0.1108, 0.1225, 0.1352, 0.1094, 0.0921,\n",
      "         0.0946]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 136.00, Train Loss: 1.69, Val Loss: 12.61, Train BLEU: 38.95, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地 地球 上 最长 的 山脉 都 在 海洋\n",
      "Reference: and in the oceans , there are the longest\n",
      "Model: <SOS> and of the the , the the the the\n",
      "Attention Weights: tensor([[0.0417, 0.0950, 0.1248, 0.1234, 0.1267, 0.1285, 0.1162, 0.1091, 0.0924,\n",
      "         0.0423],\n",
      "        [0.0494, 0.0888, 0.1165, 0.1141, 0.1207, 0.1196, 0.1162, 0.1070, 0.0982,\n",
      "         0.0696],\n",
      "        [0.0743, 0.0916, 0.1065, 0.0979, 0.1073, 0.1024, 0.1075, 0.0997, 0.1002,\n",
      "         0.1127],\n",
      "        [0.0756, 0.0902, 0.1045, 0.0958, 0.1058, 0.1005, 0.1066, 0.0990, 0.1012,\n",
      "         0.1208],\n",
      "        [0.0678, 0.0856, 0.1040, 0.0951, 0.1071, 0.1009, 0.1081, 0.0998, 0.1034,\n",
      "         0.1282],\n",
      "        [0.0644, 0.0839, 0.1042, 0.0951, 0.1079, 0.1015, 0.1089, 0.1004, 0.1044,\n",
      "         0.1292],\n",
      "        [0.0639, 0.0840, 0.1045, 0.0954, 0.1082, 0.1019, 0.1090, 0.1006, 0.1044,\n",
      "         0.1280],\n",
      "        [0.0636, 0.0839, 0.1046, 0.0955, 0.1083, 0.1020, 0.1092, 0.1007, 0.1044,\n",
      "         0.1278],\n",
      "        [0.0636, 0.0839, 0.1046, 0.0956, 0.1083, 0.1020, 0.1092, 0.1008, 0.1044,\n",
      "         0.1277]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 祖父 在 他 的 年代 是 位非 非凡\n",
      "Reference: my grandfather was an extraordinary man for his time\n",
      "Model: <SOS> we we the the the , , the the\n",
      "Attention Weights: tensor([[0.0492, 0.0940, 0.1231, 0.1439, 0.1504, 0.1391, 0.1252, 0.1055, 0.0686,\n",
      "         0.0011],\n",
      "        [0.0540, 0.0889, 0.1131, 0.1327, 0.1381, 0.1349, 0.1254, 0.1131, 0.0895,\n",
      "         0.0104],\n",
      "        [0.0697, 0.0858, 0.0984, 0.1104, 0.1131, 0.1180, 0.1135, 0.1114, 0.1118,\n",
      "         0.0678],\n",
      "        [0.0726, 0.0841, 0.0937, 0.1037, 0.1057, 0.1123, 0.1086, 0.1090, 0.1167,\n",
      "         0.0936],\n",
      "        [0.0681, 0.0803, 0.0906, 0.1017, 0.1041, 0.1119, 0.1096, 0.1114, 0.1233,\n",
      "         0.0990],\n",
      "        [0.0648, 0.0779, 0.0889, 0.1011, 0.1038, 0.1128, 0.1106, 0.1130, 0.1267,\n",
      "         0.1005],\n",
      "        [0.0644, 0.0775, 0.0886, 0.1011, 0.1040, 0.1131, 0.1109, 0.1133, 0.1271,\n",
      "         0.1000],\n",
      "        [0.0646, 0.0778, 0.0890, 0.1015, 0.1046, 0.1134, 0.1114, 0.1136, 0.1262,\n",
      "         0.0978],\n",
      "        [0.0646, 0.0778, 0.0890, 0.1016, 0.1047, 0.1136, 0.1115, 0.1136, 0.1260,\n",
      "         0.0976]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 137.00, Train Loss: 1.67, Val Loss: 12.62, Train BLEU: 39.55, Val BLEU: 0.26\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一只 水母 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: here &apos;s a jelly . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> here &apos;s a jelly . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.7087e-01, 3.1574e-01, 3.6505e-01, 1.4589e-01, 2.4534e-03, 2.1434e-10,\n",
      "         2.1434e-10, 2.1434e-10, 2.1434e-10, 2.1434e-10],\n",
      "        [1.5936e-01, 2.6784e-01, 3.2896e-01, 2.1688e-01, 2.6956e-02, 1.3748e-08,\n",
      "         1.3748e-08, 1.3748e-08, 1.3748e-08, 1.3748e-08],\n",
      "        [1.5663e-01, 2.0424e-01, 2.4608e-01, 2.5091e-01, 1.4213e-01, 1.9880e-06,\n",
      "         1.9880e-06, 1.9880e-06, 1.9880e-06, 1.9880e-06],\n",
      "        [1.5123e-01, 1.8414e-01, 2.2013e-01, 2.4983e-01, 1.9448e-01, 3.4878e-05,\n",
      "         3.4878e-05, 3.4878e-05, 3.4878e-05, 3.4878e-05],\n",
      "        [1.4138e-01, 1.7709e-01, 2.1798e-01, 2.6079e-01, 2.0249e-01, 5.3648e-05,\n",
      "         5.3648e-05, 5.3648e-05, 5.3648e-05, 5.3648e-05],\n",
      "        [1.3955e-01, 1.7715e-01, 2.1962e-01, 2.6347e-01, 2.0004e-01, 3.3640e-05,\n",
      "         3.3640e-05, 3.3640e-05, 3.3640e-05, 3.3640e-05],\n",
      "        [1.4070e-01, 1.7913e-01, 2.2194e-01, 2.6250e-01, 1.9562e-01, 2.3665e-05,\n",
      "         2.3665e-05, 2.3665e-05, 2.3665e-05, 2.3665e-05],\n",
      "        [1.4075e-01, 1.7921e-01, 2.2209e-01, 2.6229e-01, 1.9555e-01, 2.3953e-05,\n",
      "         2.3953e-05, 2.3953e-05, 2.3953e-05, 2.3953e-05],\n",
      "        [1.4074e-01, 1.7912e-01, 2.2197e-01, 2.6219e-01, 1.9586e-01, 2.4344e-05,\n",
      "         2.4344e-05, 2.4344e-05, 2.4344e-05, 2.4344e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 所以 在 那 之后 5 年 我 <UNK> <UNK> 陪\n",
      "Reference: so for the next five years , i dressed\n",
      "Model: <SOS> we use the the alvin alvin the the the\n",
      "Attention Weights: tensor([[1.3043e-01, 2.1723e-01, 2.4500e-01, 2.3208e-01, 1.6816e-01, 7.7130e-04,\n",
      "         6.2771e-03, 5.8147e-05, 1.1369e-10, 1.1369e-10],\n",
      "        [1.1776e-01, 1.7389e-01, 2.0914e-01, 2.2697e-01, 2.1168e-01, 2.0640e-02,\n",
      "         3.5593e-02, 4.3344e-03, 1.9275e-08, 1.9275e-08],\n",
      "        [1.1524e-01, 1.3443e-01, 1.5807e-01, 1.7907e-01, 1.9395e-01, 9.8700e-02,\n",
      "         8.3192e-02, 3.7350e-02, 1.5093e-06, 1.5093e-06],\n",
      "        [1.0798e-01, 1.2019e-01, 1.4070e-01, 1.6285e-01, 1.8713e-01, 1.2822e-01,\n",
      "         9.6681e-02, 5.6220e-02, 1.4133e-05, 1.4133e-05],\n",
      "        [1.0328e-01, 1.1830e-01, 1.4156e-01, 1.6800e-01, 2.0139e-01, 1.2403e-01,\n",
      "         9.2358e-02, 5.1032e-02, 1.8463e-05, 1.8463e-05],\n",
      "        [1.0111e-01, 1.1663e-01, 1.4050e-01, 1.6856e-01, 2.0600e-01, 1.2463e-01,\n",
      "         9.1795e-02, 5.0724e-02, 2.0708e-05, 2.0708e-05],\n",
      "        [1.0066e-01, 1.1649e-01, 1.4089e-01, 1.6974e-01, 2.0770e-01, 1.2469e-01,\n",
      "         9.0430e-02, 4.9384e-02, 1.7379e-05, 1.7379e-05],\n",
      "        [1.0087e-01, 1.1724e-01, 1.4187e-01, 1.7074e-01, 2.0765e-01, 1.2318e-01,\n",
      "         8.9915e-02, 4.8512e-02, 1.3601e-05, 1.3601e-05],\n",
      "        [1.0077e-01, 1.1748e-01, 1.4239e-01, 1.7133e-01, 2.0808e-01, 1.2249e-01,\n",
      "         8.9425e-02, 4.8017e-02, 1.2562e-05, 1.2562e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 138.00, Train Loss: 1.65, Val Loss: 12.63, Train BLEU: 41.50, Val BLEU: 0.26\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里 生物 的 多样 多样性 和 密度 要 比\n",
      "Reference: the biodiversity and the <UNK> in the ocean is\n",
      "Model: <SOS> the biodiversity the the and the the the the\n",
      "Attention Weights: tensor([[0.0419, 0.0908, 0.1176, 0.1083, 0.0671, 0.0035, 0.1537, 0.1734, 0.1437,\n",
      "         0.1002],\n",
      "        [0.0497, 0.0812, 0.1023, 0.0979, 0.0876, 0.0293, 0.1432, 0.1536, 0.1398,\n",
      "         0.1154],\n",
      "        [0.0707, 0.0840, 0.0991, 0.1005, 0.1191, 0.1052, 0.1049, 0.1062, 0.1052,\n",
      "         0.1051],\n",
      "        [0.0694, 0.0812, 0.0969, 0.1013, 0.1276, 0.1218, 0.0970, 0.0991, 0.1007,\n",
      "         0.1050],\n",
      "        [0.0661, 0.0786, 0.0956, 0.1022, 0.1333, 0.1262, 0.0942, 0.0973, 0.1001,\n",
      "         0.1064],\n",
      "        [0.0621, 0.0759, 0.0953, 0.1041, 0.1411, 0.1274, 0.0911, 0.0957, 0.0994,\n",
      "         0.1078],\n",
      "        [0.0605, 0.0752, 0.0956, 0.1047, 0.1428, 0.1260, 0.0909, 0.0958, 0.0998,\n",
      "         0.1086],\n",
      "        [0.0602, 0.0752, 0.0958, 0.1048, 0.1428, 0.1250, 0.0912, 0.0962, 0.1001,\n",
      "         0.1087],\n",
      "        [0.0597, 0.0752, 0.0961, 0.1052, 0.1434, 0.1242, 0.0911, 0.0963, 0.1001,\n",
      "         0.1088]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他们 知道 我们 的 住处 吗 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: do they know where we live ? <EOS> <PAD>\n",
      "Model: <SOS> it &apos;s a kind different working . <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.2479e-07, 8.1560e-08, 8.9465e-08, 2.6164e-07, 1.1030e-05, 1.1399e-02,\n",
      "         1.0994e-01, 2.4853e-01, 3.3457e-01, 2.9555e-01],\n",
      "        [9.4381e-08, 5.6077e-08, 6.2023e-08, 2.1772e-07, 2.2625e-05, 1.7077e-02,\n",
      "         1.1179e-01, 2.2803e-01, 3.1385e-01, 3.2922e-01],\n",
      "        [2.1602e-05, 1.2813e-05, 1.3419e-05, 3.7890e-05, 1.1322e-03, 4.3790e-02,\n",
      "         1.2656e-01, 2.1505e-01, 2.8436e-01, 3.2902e-01],\n",
      "        [4.5665e-04, 2.8310e-04, 2.8840e-04, 6.6945e-04, 7.6277e-03, 7.2696e-02,\n",
      "         1.4034e-01, 2.0159e-01, 2.5392e-01, 3.2212e-01],\n",
      "        [1.0334e-03, 6.4438e-04, 6.5138e-04, 1.4341e-03, 1.2964e-02, 7.9829e-02,\n",
      "         1.3878e-01, 1.9350e-01, 2.4421e-01, 3.2695e-01],\n",
      "        [1.3961e-03, 8.7246e-04, 8.7506e-04, 1.8659e-03, 1.5391e-02, 8.3936e-02,\n",
      "         1.3995e-01, 1.9156e-01, 2.4057e-01, 3.2357e-01],\n",
      "        [1.9737e-03, 1.2495e-03, 1.2456e-03, 2.5489e-03, 1.8847e-02, 8.9591e-02,\n",
      "         1.4215e-01, 1.8923e-01, 2.3565e-01, 3.1751e-01],\n",
      "        [2.3495e-03, 1.4972e-03, 1.4888e-03, 2.9952e-03, 2.0773e-02, 9.1915e-02,\n",
      "         1.4273e-01, 1.8785e-01, 2.3326e-01, 3.1515e-01],\n",
      "        [2.4556e-03, 1.5675e-03, 1.5584e-03, 3.1181e-03, 2.1244e-02, 9.2445e-02,\n",
      "         1.4290e-01, 1.8758e-01, 2.3268e-01, 3.1445e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 139.00, Train Loss: 1.63, Val Loss: 12.63, Train BLEU: 41.53, Val BLEU: 0.27\n",
      "Sampling from training predictions...\n",
      "Source: 还有 前面 的 这个 是 推进 引擎 它 一会 一会儿\n",
      "Reference: and it &apos;s got these jet thrusters up in\n",
      "Model: <SOS> and it &apos;s got these jet thrusters thrusters in\n",
      "Attention Weights: tensor([[0.0593, 0.1248, 0.1478, 0.1571, 0.1565, 0.1455, 0.1410, 0.0673, 0.0006,\n",
      "         0.0000],\n",
      "        [0.0597, 0.1167, 0.1388, 0.1490, 0.1522, 0.1435, 0.1436, 0.0921, 0.0039,\n",
      "         0.0005],\n",
      "        [0.0671, 0.1032, 0.1193, 0.1301, 0.1349, 0.1348, 0.1440, 0.1210, 0.0360,\n",
      "         0.0097],\n",
      "        [0.0716, 0.0882, 0.0971, 0.1054, 0.1085, 0.1148, 0.1288, 0.1311, 0.1054,\n",
      "         0.0491],\n",
      "        [0.0701, 0.0827, 0.0903, 0.0983, 0.1011, 0.1086, 0.1230, 0.1331, 0.1269,\n",
      "         0.0658],\n",
      "        [0.0637, 0.0776, 0.0861, 0.0956, 0.0998, 0.1090, 0.1270, 0.1443, 0.1346,\n",
      "         0.0622],\n",
      "        [0.0613, 0.0758, 0.0849, 0.0952, 0.0997, 0.1099, 0.1296, 0.1478, 0.1364,\n",
      "         0.0594],\n",
      "        [0.0609, 0.0758, 0.0849, 0.0955, 0.0999, 0.1105, 0.1310, 0.1480, 0.1355,\n",
      "         0.0578],\n",
      "        [0.0614, 0.0766, 0.0858, 0.0964, 0.1009, 0.1114, 0.1317, 0.1474, 0.1327,\n",
      "         0.0558]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 有时 学校 <UNK> 突然 <UNK> 一周 因为 被 塔利 塔利班\n",
      "Reference: from time to time , the school would suddenly\n",
      "Model: <SOS> it vibrant got about , , , , ,\n",
      "Attention Weights: tensor([[0.0412, 0.0805, 0.1040, 0.1248, 0.1307, 0.1316, 0.1228, 0.1106, 0.0957,\n",
      "         0.0581],\n",
      "        [0.0470, 0.0797, 0.1007, 0.1195, 0.1239, 0.1254, 0.1196, 0.1119, 0.1009,\n",
      "         0.0715],\n",
      "        [0.0687, 0.0843, 0.0957, 0.1065, 0.1080, 0.1103, 0.1100, 0.1090, 0.1071,\n",
      "         0.1005],\n",
      "        [0.0741, 0.0857, 0.0949, 0.1038, 0.1047, 0.1070, 0.1077, 0.1077, 0.1076,\n",
      "         0.1068],\n",
      "        [0.0707, 0.0831, 0.0931, 0.1032, 0.1045, 0.1072, 0.1084, 0.1092, 0.1098,\n",
      "         0.1108],\n",
      "        [0.0665, 0.0801, 0.0913, 0.1030, 0.1047, 0.1080, 0.1095, 0.1109, 0.1120,\n",
      "         0.1140],\n",
      "        [0.0653, 0.0794, 0.0909, 0.1032, 0.1050, 0.1084, 0.1100, 0.1112, 0.1123,\n",
      "         0.1143],\n",
      "        [0.0644, 0.0786, 0.0905, 0.1032, 0.1053, 0.1088, 0.1104, 0.1117, 0.1127,\n",
      "         0.1144],\n",
      "        [0.0639, 0.0785, 0.0906, 0.1034, 0.1056, 0.1091, 0.1106, 0.1119, 0.1127,\n",
      "         0.1137]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 140.00, Train Loss: 1.61, Val Loss: 12.64, Train BLEU: 41.53, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 它 可以 伸展 <UNK> 150 英尺 长 <EOS> <PAD> <PAD>\n",
      "Reference: it gets up to about 150 feet long .\n",
      "Model: <SOS> it gets up to about 150 . . .\n",
      "Attention Weights: tensor([[3.4756e-01, 5.1613e-01, 9.3500e-02, 1.2121e-05, 1.4789e-05, 1.3469e-02,\n",
      "         2.7580e-02, 1.7326e-03, 3.0843e-10, 3.0843e-10],\n",
      "        [2.4472e-01, 4.8275e-01, 2.1709e-01, 2.3009e-04, 1.9589e-04, 1.7472e-02,\n",
      "         3.0099e-02, 7.4445e-03, 3.0712e-09, 3.0712e-09],\n",
      "        [1.7248e-01, 3.4351e-01, 3.4643e-01, 1.7611e-02, 8.8981e-03, 2.9199e-02,\n",
      "         4.0283e-02, 4.1581e-02, 4.6596e-07, 4.6596e-07],\n",
      "        [1.5542e-01, 2.9222e-01, 3.4769e-01, 4.6911e-02, 2.1497e-02, 3.3544e-02,\n",
      "         4.3611e-02, 5.9091e-02, 8.6125e-06, 8.6125e-06],\n",
      "        [1.5231e-01, 2.9381e-01, 3.5563e-01, 4.6972e-02, 2.0566e-02, 3.1555e-02,\n",
      "         4.1492e-02, 5.7636e-02, 1.1727e-05, 1.1727e-05],\n",
      "        [1.4926e-01, 2.9644e-01, 3.6221e-01, 4.6306e-02, 1.9431e-02, 2.9853e-02,\n",
      "         3.9960e-02, 5.6513e-02, 1.2218e-05, 1.2218e-05],\n",
      "        [1.4727e-01, 2.9986e-01, 3.6616e-01, 4.4349e-02, 1.8222e-02, 2.9163e-02,\n",
      "         3.9223e-02, 5.5730e-02, 1.0518e-05, 1.0518e-05],\n",
      "        [1.4598e-01, 2.9978e-01, 3.6787e-01, 4.4249e-02, 1.7374e-02, 2.9177e-02,\n",
      "         3.9154e-02, 5.6392e-02, 9.4724e-06, 9.4724e-06],\n",
      "        [1.4486e-01, 2.9955e-01, 3.6910e-01, 4.4651e-02, 1.7351e-02, 2.9094e-02,\n",
      "         3.8964e-02, 5.6409e-02, 9.4428e-06, 9.4428e-06]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 在 被 跟踪 吗 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: were we being followed ? <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a kind different working <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[9.9026e-02, 2.1223e-01, 2.9059e-01, 2.7094e-01, 1.0581e-01, 1.1067e-02,\n",
      "         3.6273e-06, 3.9020e-07, 3.4960e-03, 6.8272e-03],\n",
      "        [8.3819e-02, 1.7055e-01, 2.3947e-01, 2.6174e-01, 1.8123e-01, 4.6264e-02,\n",
      "         1.3089e-04, 1.8517e-05, 6.0359e-03, 1.0744e-02],\n",
      "        [7.8266e-02, 1.1713e-01, 1.5112e-01, 1.8247e-01, 2.4735e-01, 1.7094e-01,\n",
      "         9.9130e-03, 2.4856e-03, 1.6467e-02, 2.3852e-02],\n",
      "        [7.4589e-02, 9.9883e-02, 1.2400e-01, 1.5374e-01, 2.3938e-01, 2.2018e-01,\n",
      "         3.0747e-02, 9.5150e-03, 2.0442e-02, 2.7533e-02],\n",
      "        [7.0039e-02, 9.4779e-02, 1.1903e-01, 1.5232e-01, 2.4642e-01, 2.3418e-01,\n",
      "         3.1203e-02, 9.0736e-03, 1.8143e-02, 2.4808e-02],\n",
      "        [6.8664e-02, 9.3491e-02, 1.1825e-01, 1.5364e-01, 2.4976e-01, 2.3736e-01,\n",
      "         3.0146e-02, 8.4996e-03, 1.6794e-02, 2.3396e-02],\n",
      "        [6.7679e-02, 9.2534e-02, 1.1752e-01, 1.5328e-01, 2.5189e-01, 2.3941e-01,\n",
      "         3.0189e-02, 8.5374e-03, 1.6346e-02, 2.2608e-02],\n",
      "        [6.7272e-02, 9.2664e-02, 1.1821e-01, 1.5441e-01, 2.5332e-01, 2.3894e-01,\n",
      "         2.8759e-02, 8.0316e-03, 1.6076e-02, 2.2316e-02],\n",
      "        [6.7617e-02, 9.3326e-02, 1.1912e-01, 1.5533e-01, 2.5341e-01, 2.3774e-01,\n",
      "         2.7298e-02, 7.4615e-03, 1.6243e-02, 2.2462e-02]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 141.00, Train Loss: 1.59, Val Loss: 12.65, Train BLEU: 43.03, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 其实 它们 都 是 由 单独 的 动物 结合 合在\n",
      "Reference: these are all individual animals banding together to make\n",
      "Model: <SOS> these are all individual animals banding together make make\n",
      "Attention Weights: tensor([[4.4661e-02, 1.0921e-01, 1.3253e-01, 1.4683e-01, 1.5699e-01, 1.5800e-01,\n",
      "         1.4506e-01, 9.5267e-02, 1.1446e-02, 1.1799e-06],\n",
      "        [4.6081e-02, 9.7131e-02, 1.1775e-01, 1.3116e-01, 1.4112e-01, 1.4755e-01,\n",
      "         1.4679e-01, 1.2854e-01, 4.3762e-02, 1.1377e-04],\n",
      "        [5.8116e-02, 8.4525e-02, 9.6158e-02, 1.0446e-01, 1.1067e-01, 1.2155e-01,\n",
      "         1.2604e-01, 1.4923e-01, 1.3787e-01, 1.1376e-02],\n",
      "        [6.3506e-02, 8.0855e-02, 8.9306e-02, 9.5631e-02, 1.0035e-01, 1.1112e-01,\n",
      "         1.1575e-01, 1.4492e-01, 1.6318e-01, 3.5372e-02],\n",
      "        [6.0527e-02, 7.8302e-02, 8.6971e-02, 9.3629e-02, 9.8694e-02, 1.1046e-01,\n",
      "         1.1621e-01, 1.4983e-01, 1.7366e-01, 3.1713e-02],\n",
      "        [5.8508e-02, 7.6865e-02, 8.5919e-02, 9.2984e-02, 9.8380e-02, 1.1093e-01,\n",
      "         1.1705e-01, 1.5290e-01, 1.7678e-01, 2.9680e-02],\n",
      "        [5.8497e-02, 7.6842e-02, 8.6111e-02, 9.3452e-02, 9.8984e-02, 1.1149e-01,\n",
      "         1.1757e-01, 1.5307e-01, 1.7537e-01, 2.8609e-02],\n",
      "        [5.8757e-02, 7.7175e-02, 8.6521e-02, 9.3958e-02, 9.9552e-02, 1.1176e-01,\n",
      "         1.1796e-01, 1.5269e-01, 1.7359e-01, 2.8034e-02],\n",
      "        [5.8645e-02, 7.7597e-02, 8.7101e-02, 9.4607e-02, 1.0026e-01, 1.1252e-01,\n",
      "         1.1850e-01, 1.5292e-01, 1.7142e-01, 2.6432e-02]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 想 过 要 放弃 但 我 的 父亲 这时\n",
      "Reference: i would want to quit , but my father\n",
      "Model: <SOS> and of the the standing , , , ,\n",
      "Attention Weights: tensor([[0.0591, 0.1240, 0.1474, 0.1563, 0.1581, 0.1450, 0.1424, 0.0670, 0.0006,\n",
      "         0.0000],\n",
      "        [0.0599, 0.1160, 0.1385, 0.1480, 0.1533, 0.1426, 0.1448, 0.0921, 0.0044,\n",
      "         0.0005],\n",
      "        [0.0664, 0.1011, 0.1172, 0.1280, 0.1336, 0.1334, 0.1457, 0.1219, 0.0413,\n",
      "         0.0114],\n",
      "        [0.0696, 0.0850, 0.0936, 0.1022, 0.1051, 0.1125, 0.1290, 0.1308, 0.1170,\n",
      "         0.0554],\n",
      "        [0.0675, 0.0792, 0.0865, 0.0951, 0.0976, 0.1064, 0.1232, 0.1329, 0.1391,\n",
      "         0.0724],\n",
      "        [0.0609, 0.0738, 0.0821, 0.0921, 0.0960, 0.1068, 0.1274, 0.1439, 0.1480,\n",
      "         0.0690],\n",
      "        [0.0587, 0.0721, 0.0808, 0.0917, 0.0959, 0.1077, 0.1299, 0.1469, 0.1501,\n",
      "         0.0664],\n",
      "        [0.0586, 0.0722, 0.0810, 0.0920, 0.0962, 0.1082, 0.1311, 0.1465, 0.1493,\n",
      "         0.0650],\n",
      "        [0.0591, 0.0730, 0.0819, 0.0929, 0.0972, 0.1090, 0.1316, 0.1458, 0.1465,\n",
      "         0.0630]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 142.00, Train Loss: 1.58, Val Loss: 12.66, Train BLEU: 44.33, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 我 真 喜欢 这些 东西 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: i love that kind of stuff . <EOS> <PAD>\n",
      "Model: <SOS> here &apos;s a kind different stuff . <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.2647e-01, 2.3076e-01, 2.8221e-01, 2.7124e-01, 8.7869e-02, 1.4490e-03,\n",
      "         1.8929e-10, 1.8929e-10, 1.8929e-10, 1.8929e-10],\n",
      "        [1.2097e-01, 2.0051e-01, 2.5376e-01, 2.6501e-01, 1.4413e-01, 1.5630e-02,\n",
      "         8.0748e-09, 8.0748e-09, 8.0748e-09, 8.0748e-09],\n",
      "        [1.2379e-01, 1.6033e-01, 1.9377e-01, 2.1513e-01, 1.9976e-01, 1.0722e-01,\n",
      "         1.3673e-06, 1.3673e-06, 1.3673e-06, 1.3673e-06],\n",
      "        [1.2117e-01, 1.4551e-01, 1.7257e-01, 1.9410e-01, 2.0771e-01, 1.5884e-01,\n",
      "         2.6362e-05, 2.6362e-05, 2.6362e-05, 2.6362e-05],\n",
      "        [1.1423e-01, 1.3978e-01, 1.6874e-01, 1.9396e-01, 2.1659e-01, 1.6651e-01,\n",
      "         4.4810e-05, 4.4810e-05, 4.4810e-05, 4.4810e-05],\n",
      "        [1.1219e-01, 1.3784e-01, 1.6719e-01, 1.9344e-01, 2.1931e-01, 1.6985e-01,\n",
      "         4.6766e-05, 4.6766e-05, 4.6766e-05, 4.6766e-05],\n",
      "        [1.1108e-01, 1.3716e-01, 1.6675e-01, 1.9398e-01, 2.2083e-01, 1.7005e-01,\n",
      "         3.8125e-05, 3.8125e-05, 3.8125e-05, 3.8125e-05],\n",
      "        [1.1157e-01, 1.3837e-01, 1.6767e-01, 1.9511e-01, 2.1921e-01, 1.6797e-01,\n",
      "         2.5758e-05, 2.5758e-05, 2.5758e-05, 2.5758e-05],\n",
      "        [1.1166e-01, 1.3871e-01, 1.6832e-01, 1.9588e-01, 2.1874e-01, 1.6660e-01,\n",
      "         2.4559e-05, 2.4559e-05, 2.4559e-05, 2.4559e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 出身 阿富汗 边远 <UNK> 地区 有着 与 他人 不同\n",
      "Reference: a total maverick from a remote province of afghanistan\n",
      "Model: <SOS> it &apos;s the the to and the the the\n",
      "Attention Weights: tensor([[1.0932e-01, 2.0373e-01, 2.4271e-01, 1.1970e-01, 6.2876e-04, 1.1092e-01,\n",
      "         1.2954e-01, 7.8250e-02, 5.2062e-03, 1.4846e-10],\n",
      "        [8.2025e-02, 1.3540e-01, 1.7404e-01, 1.6702e-01, 1.1178e-02, 1.3088e-01,\n",
      "         1.4974e-01, 1.1703e-01, 3.2687e-02, 7.9749e-09],\n",
      "        [7.3274e-02, 9.3335e-02, 1.1932e-01, 1.8814e-01, 8.7467e-02, 1.0429e-01,\n",
      "         1.1211e-01, 1.1933e-01, 1.0273e-01, 1.9015e-06],\n",
      "        [7.0626e-02, 8.5710e-02, 1.1083e-01, 1.8424e-01, 1.1912e-01, 9.4341e-02,\n",
      "         1.0051e-01, 1.1395e-01, 1.2064e-01, 3.2342e-05],\n",
      "        [6.6887e-02, 8.3570e-02, 1.1365e-01, 2.0237e-01, 1.1707e-01, 8.6489e-02,\n",
      "         9.4789e-02, 1.1302e-01, 1.2211e-01, 4.2082e-05],\n",
      "        [6.5010e-02, 8.2332e-02, 1.1441e-01, 2.1090e-01, 1.1656e-01, 8.2809e-02,\n",
      "         9.1687e-02, 1.1209e-01, 1.2417e-01, 4.2462e-05],\n",
      "        [6.4289e-02, 8.1736e-02, 1.1438e-01, 2.1463e-01, 1.1647e-01, 8.1793e-02,\n",
      "         9.0353e-02, 1.1119e-01, 1.2512e-01, 3.3860e-05],\n",
      "        [6.3984e-02, 8.1574e-02, 1.1409e-01, 2.1584e-01, 1.1508e-01, 8.2042e-02,\n",
      "         9.0731e-02, 1.1099e-01, 1.2565e-01, 2.7111e-05],\n",
      "        [6.3636e-02, 8.1283e-02, 1.1386e-01, 2.1710e-01, 1.1449e-01, 8.2148e-02,\n",
      "         9.0856e-02, 1.1104e-01, 1.2556e-01, 2.6162e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 143.00, Train Loss: 1.56, Val Loss: 12.69, Train BLEU: 44.98, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一种 种群 栖 动物 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: it &apos;s a colonial animal . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a colonial . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[9.6042e-02, 1.7840e-01, 2.2354e-01, 2.3133e-01, 2.0623e-01, 6.3160e-02,\n",
      "         1.2941e-03, 1.3065e-10, 1.3065e-10, 1.3065e-10],\n",
      "        [9.2694e-02, 1.5690e-01, 2.0148e-01, 2.2144e-01, 2.0904e-01, 1.0624e-01,\n",
      "         1.2194e-02, 5.0349e-09, 5.0349e-09, 5.0349e-09],\n",
      "        [1.0178e-01, 1.3202e-01, 1.5972e-01, 1.7861e-01, 1.7651e-01, 1.6073e-01,\n",
      "         9.0623e-02, 1.1729e-06, 1.1729e-06, 1.1729e-06],\n",
      "        [1.0154e-01, 1.2155e-01, 1.4397e-01, 1.6132e-01, 1.6210e-01, 1.7265e-01,\n",
      "         1.3680e-01, 2.3984e-05, 2.3984e-05, 2.3984e-05],\n",
      "        [9.3098e-02, 1.1397e-01, 1.3837e-01, 1.5900e-01, 1.6230e-01, 1.8431e-01,\n",
      "         1.4881e-01, 4.6228e-05, 4.6228e-05, 4.6228e-05],\n",
      "        [9.1134e-02, 1.1269e-01, 1.3751e-01, 1.5918e-01, 1.6269e-01, 1.8657e-01,\n",
      "         1.5013e-01, 3.3336e-05, 3.3336e-05, 3.3336e-05],\n",
      "        [9.1527e-02, 1.1364e-01, 1.3855e-01, 1.6048e-01, 1.6419e-01, 1.8476e-01,\n",
      "         1.4677e-01, 2.2602e-05, 2.2602e-05, 2.2602e-05],\n",
      "        [9.1660e-02, 1.1376e-01, 1.3871e-01, 1.6060e-01, 1.6438e-01, 1.8442e-01,\n",
      "         1.4641e-01, 2.2879e-05, 2.2879e-05, 2.2879e-05],\n",
      "        [9.1685e-02, 1.1374e-01, 1.3868e-01, 1.6055e-01, 1.6436e-01, 1.8442e-01,\n",
      "         1.4649e-01, 2.3098e-05, 2.3098e-05, 2.3098e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天 要 走 不同 的 路线 这样 才 没有\n",
      "Reference: each day , we took a different route so\n",
      "Model: <SOS> part of the the , , , , ,\n",
      "Attention Weights: tensor([[0.0419, 0.1005, 0.1308, 0.1259, 0.1301, 0.1275, 0.1114, 0.1046, 0.0871,\n",
      "         0.0402],\n",
      "        [0.0480, 0.0932, 0.1238, 0.1171, 0.1254, 0.1205, 0.1135, 0.1036, 0.0924,\n",
      "         0.0624],\n",
      "        [0.0745, 0.0943, 0.1116, 0.0992, 0.1099, 0.1024, 0.1063, 0.0971, 0.0959,\n",
      "         0.1087],\n",
      "        [0.0777, 0.0931, 0.1090, 0.0957, 0.1075, 0.0991, 0.1054, 0.0957, 0.0966,\n",
      "         0.1201],\n",
      "        [0.0701, 0.0886, 0.1089, 0.0946, 0.1089, 0.0991, 0.1069, 0.0958, 0.0980,\n",
      "         0.1291],\n",
      "        [0.0667, 0.0868, 0.1093, 0.0947, 0.1098, 0.0997, 0.1075, 0.0963, 0.0988,\n",
      "         0.1304],\n",
      "        [0.0662, 0.0870, 0.1097, 0.0951, 0.1100, 0.1002, 0.1077, 0.0966, 0.0987,\n",
      "         0.1289],\n",
      "        [0.0658, 0.0868, 0.1097, 0.0952, 0.1103, 0.1003, 0.1079, 0.0967, 0.0987,\n",
      "         0.1286],\n",
      "        [0.0657, 0.0868, 0.1097, 0.0953, 0.1103, 0.1004, 0.1080, 0.0967, 0.0986,\n",
      "         0.1285]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 144.00, Train Loss: 1.54, Val Loss: 12.70, Train BLEU: 44.82, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: <UNK> 塞尔 <UNK> <UNK> 斯特 说 过 真正 的 探索\n",
      "Reference: marcel proust said , &quot; the true voyage of\n",
      "Model: <SOS> marcel proust said , &quot; true true voyage voyage\n",
      "Attention Weights: tensor([[2.2558e-07, 1.4966e-07, 1.6490e-07, 4.9170e-07, 1.8706e-05, 1.3534e-02,\n",
      "         1.1277e-01, 2.4824e-01, 3.2998e-01, 2.9546e-01],\n",
      "        [1.0566e-07, 6.3480e-08, 7.1146e-08, 2.6247e-07, 2.7629e-05, 1.8328e-02,\n",
      "         1.1204e-01, 2.2897e-01, 3.1166e-01, 3.2898e-01],\n",
      "        [2.1260e-05, 1.2709e-05, 1.3438e-05, 3.9155e-05, 1.1790e-03, 4.5396e-02,\n",
      "         1.2725e-01, 2.1770e-01, 2.8201e-01, 3.2638e-01],\n",
      "        [5.2170e-04, 3.2369e-04, 3.3105e-04, 7.8884e-04, 8.7586e-03, 7.6797e-02,\n",
      "         1.4071e-01, 2.0262e-01, 2.5059e-01, 3.1856e-01],\n",
      "        [1.4641e-03, 9.1566e-04, 9.2663e-04, 2.0757e-03, 1.7479e-02, 8.8103e-02,\n",
      "         1.3999e-01, 1.9188e-01, 2.3668e-01, 3.2049e-01],\n",
      "        [2.1034e-03, 1.3187e-03, 1.3232e-03, 2.8752e-03, 2.1770e-02, 9.3569e-02,\n",
      "         1.4109e-01, 1.8878e-01, 2.3154e-01, 3.1564e-01],\n",
      "        [3.1227e-03, 1.9866e-03, 1.9788e-03, 4.1093e-03, 2.7438e-02, 1.0010e-01,\n",
      "         1.4293e-01, 1.8536e-01, 2.2523e-01, 3.0775e-01],\n",
      "        [3.7309e-03, 2.3925e-03, 2.3779e-03, 4.8453e-03, 3.0192e-02, 1.0238e-01,\n",
      "         1.4318e-01, 1.8352e-01, 2.2241e-01, 3.0497e-01],\n",
      "        [3.8915e-03, 2.5010e-03, 2.4855e-03, 5.0350e-03, 3.0827e-02, 1.0288e-01,\n",
      "         1.4330e-01, 1.8319e-01, 2.2178e-01, 3.0413e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 她 两年 年前 退休 了 结果 却 把 我家 变成\n",
      "Reference: she retired two years ago , only to turn\n",
      "Model: <SOS> the of the the matter the the the the\n",
      "Attention Weights: tensor([[1.2823e-01, 2.3138e-01, 2.8318e-01, 2.7043e-01, 8.5223e-02, 1.5495e-03,\n",
      "         2.2733e-10, 2.2733e-10, 2.2733e-10, 2.2733e-10],\n",
      "        [1.2411e-01, 2.0206e-01, 2.5447e-01, 2.6383e-01, 1.3978e-01, 1.5759e-02,\n",
      "         8.4158e-09, 8.4158e-09, 8.4158e-09, 8.4158e-09],\n",
      "        [1.2553e-01, 1.6098e-01, 1.9388e-01, 2.1487e-01, 1.9675e-01, 1.0797e-01,\n",
      "         1.3854e-06, 1.3854e-06, 1.3854e-06, 1.3854e-06],\n",
      "        [1.2209e-01, 1.4507e-01, 1.7149e-01, 1.9303e-01, 2.0590e-01, 1.6231e-01,\n",
      "         2.8103e-05, 2.8103e-05, 2.8103e-05, 2.8103e-05],\n",
      "        [1.1421e-01, 1.3847e-01, 1.6714e-01, 1.9286e-01, 2.1576e-01, 1.7137e-01,\n",
      "         4.9526e-05, 4.9526e-05, 4.9526e-05, 4.9526e-05],\n",
      "        [1.1193e-01, 1.3629e-01, 1.6542e-01, 1.9224e-01, 2.1864e-01, 1.7525e-01,\n",
      "         5.2309e-05, 5.2309e-05, 5.2309e-05, 5.2309e-05],\n",
      "        [1.1066e-01, 1.3533e-01, 1.6466e-01, 1.9254e-01, 2.2037e-01, 1.7627e-01,\n",
      "         4.3837e-05, 4.3837e-05, 4.3837e-05, 4.3837e-05],\n",
      "        [1.1116e-01, 1.3648e-01, 1.6544e-01, 1.9351e-01, 2.1865e-01, 1.7465e-01,\n",
      "         3.0078e-05, 3.0078e-05, 3.0078e-05, 3.0078e-05],\n",
      "        [1.1134e-01, 1.3678e-01, 1.6598e-01, 1.9411e-01, 2.1817e-01, 1.7351e-01,\n",
      "         2.9536e-05, 2.9536e-05, 2.9536e-05, 2.9536e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 145.00, Train Loss: 1.52, Val Loss: 12.71, Train BLEU: 47.78, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 这儿 基本 基本上 都 没有 被 开发 发过 但是 像\n",
      "Reference: it &apos;s mostly unexplored , and yet there are\n",
      "Model: <SOS> people &apos;s the unexplored , , , , ,\n",
      "Attention Weights: tensor([[0.0362, 0.0963, 0.1284, 0.1280, 0.1272, 0.1269, 0.1192, 0.1074, 0.0811,\n",
      "         0.0494],\n",
      "        [0.0414, 0.0914, 0.1258, 0.1202, 0.1242, 0.1198, 0.1186, 0.1089, 0.0901,\n",
      "         0.0596],\n",
      "        [0.0663, 0.0909, 0.1156, 0.1031, 0.1099, 0.1039, 0.1086, 0.1055, 0.1056,\n",
      "         0.0907],\n",
      "        [0.0719, 0.0907, 0.1133, 0.0989, 0.1068, 0.0999, 0.1066, 0.1050, 0.1090,\n",
      "         0.0980],\n",
      "        [0.0668, 0.0873, 0.1145, 0.0980, 0.1078, 0.0996, 0.1078, 0.1061, 0.1113,\n",
      "         0.1008],\n",
      "        [0.0623, 0.0845, 0.1159, 0.0974, 0.1091, 0.0996, 0.1093, 0.1071, 0.1128,\n",
      "         0.1019],\n",
      "        [0.0621, 0.0843, 0.1159, 0.0974, 0.1092, 0.0997, 0.1095, 0.1072, 0.1129,\n",
      "         0.1018],\n",
      "        [0.0609, 0.0838, 0.1160, 0.0981, 0.1097, 0.1005, 0.1099, 0.1075, 0.1126,\n",
      "         0.1011],\n",
      "        [0.0605, 0.0837, 0.1161, 0.0982, 0.1098, 0.1006, 0.1101, 0.1076, 0.1127,\n",
      "         0.1008]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 父亲 在 用 他 的 灰色 小 收音\n",
      "Reference: my father was listening to bbc news on his\n",
      "Model: <SOS> part of the the , , , , ,\n",
      "Attention Weights: tensor([[6.9305e-04, 2.2549e-06, 6.2671e-03, 1.6252e-02, 1.4663e-02, 1.7792e-01,\n",
      "         2.1852e-01, 2.4540e-01, 2.0109e-01, 1.1920e-01],\n",
      "        [3.4057e-03, 5.2630e-05, 1.0738e-02, 2.2753e-02, 2.8530e-02, 1.6771e-01,\n",
      "         2.0049e-01, 2.2606e-01, 2.0056e-01, 1.3970e-01],\n",
      "        [2.6451e-02, 3.0014e-03, 2.7494e-02, 4.4746e-02, 7.5708e-02, 1.5047e-01,\n",
      "         1.6679e-01, 1.8149e-01, 1.7148e-01, 1.5236e-01],\n",
      "        [5.6516e-02, 1.2530e-02, 3.6445e-02, 5.4387e-02, 1.0481e-01, 1.3330e-01,\n",
      "         1.4298e-01, 1.5438e-01, 1.5147e-01, 1.5318e-01],\n",
      "        [7.1817e-02, 1.7005e-02, 3.6632e-02, 5.5341e-02, 1.1161e-01, 1.2352e-01,\n",
      "         1.3351e-01, 1.4671e-01, 1.4671e-01, 1.5716e-01],\n",
      "        [7.5695e-02, 1.7794e-02, 3.5971e-02, 5.4510e-02, 1.1269e-01, 1.2117e-01,\n",
      "         1.3181e-01, 1.4568e-01, 1.4604e-01, 1.5864e-01],\n",
      "        [8.2504e-02, 2.0081e-02, 3.6475e-02, 5.4834e-02, 1.1376e-01, 1.1866e-01,\n",
      "         1.2922e-01, 1.4302e-01, 1.4379e-01, 1.5766e-01],\n",
      "        [8.7586e-02, 2.2272e-02, 3.7464e-02, 5.5500e-02, 1.1547e-01, 1.1698e-01,\n",
      "         1.2701e-01, 1.4053e-01, 1.4139e-01, 1.5579e-01],\n",
      "        [8.9908e-02, 2.3281e-02, 3.8002e-02, 5.5899e-02, 1.1640e-01, 1.1611e-01,\n",
      "         1.2587e-01, 1.3930e-01, 1.4024e-01, 1.5500e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 146.00, Train Loss: 1.50, Val Loss: 12.72, Train BLEU: 46.79, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 当 你 站 在 海滩 上 或是 当 你 看到\n",
      "Reference: part of the problem , i think , is\n",
      "Model: <SOS> part of the problem , , , , ,\n",
      "Attention Weights: tensor([[0.0377, 0.0748, 0.1013, 0.1221, 0.1440, 0.1421, 0.1259, 0.1145, 0.0934,\n",
      "         0.0442],\n",
      "        [0.0442, 0.0756, 0.0984, 0.1159, 0.1409, 0.1309, 0.1258, 0.1115, 0.0957,\n",
      "         0.0611],\n",
      "        [0.0670, 0.0820, 0.0940, 0.1036, 0.1227, 0.1093, 0.1142, 0.1045, 0.1008,\n",
      "         0.1019],\n",
      "        [0.0727, 0.0829, 0.0918, 0.0993, 0.1190, 0.1029, 0.1122, 0.1016, 0.1010,\n",
      "         0.1166],\n",
      "        [0.0670, 0.0783, 0.0884, 0.0975, 0.1215, 0.1023, 0.1146, 0.1022, 0.1027,\n",
      "         0.1254],\n",
      "        [0.0624, 0.0744, 0.0858, 0.0964, 0.1240, 0.1028, 0.1168, 0.1032, 0.1040,\n",
      "         0.1300],\n",
      "        [0.0614, 0.0739, 0.0857, 0.0967, 0.1244, 0.1037, 0.1172, 0.1038, 0.1043,\n",
      "         0.1288],\n",
      "        [0.0611, 0.0737, 0.0856, 0.0967, 0.1248, 0.1039, 0.1175, 0.1039, 0.1042,\n",
      "         0.1286],\n",
      "        [0.0609, 0.0736, 0.0856, 0.0967, 0.1249, 0.1040, 0.1176, 0.1039, 0.1042,\n",
      "         0.1285]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 这 是 我们 俩 人 唯一 的 受教 教育 方式\n",
      "Reference: it was the only way we both could be\n",
      "Model: <SOS> we we the the the and the the the\n",
      "Attention Weights: tensor([[0.0377, 0.0748, 0.1013, 0.1221, 0.1440, 0.1421, 0.1259, 0.1145, 0.0934,\n",
      "         0.0442],\n",
      "        [0.0442, 0.0756, 0.0984, 0.1159, 0.1409, 0.1309, 0.1258, 0.1115, 0.0957,\n",
      "         0.0611],\n",
      "        [0.0670, 0.0820, 0.0940, 0.1036, 0.1227, 0.1093, 0.1142, 0.1045, 0.1008,\n",
      "         0.1019],\n",
      "        [0.0727, 0.0829, 0.0918, 0.0993, 0.1190, 0.1029, 0.1122, 0.1016, 0.1010,\n",
      "         0.1166],\n",
      "        [0.0670, 0.0783, 0.0884, 0.0975, 0.1215, 0.1023, 0.1146, 0.1022, 0.1027,\n",
      "         0.1254],\n",
      "        [0.0624, 0.0744, 0.0858, 0.0964, 0.1240, 0.1028, 0.1168, 0.1032, 0.1040,\n",
      "         0.1300],\n",
      "        [0.0614, 0.0739, 0.0857, 0.0967, 0.1244, 0.1037, 0.1172, 0.1038, 0.1043,\n",
      "         0.1288],\n",
      "        [0.0611, 0.0737, 0.0856, 0.0967, 0.1248, 0.1039, 0.1175, 0.1039, 0.1042,\n",
      "         0.1286],\n",
      "        [0.0609, 0.0736, 0.0856, 0.0967, 0.1249, 0.1040, 0.1176, 0.1039, 0.1042,\n",
      "         0.1285]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 147.00, Train Loss: 1.48, Val Loss: 12.73, Train BLEU: 48.45, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 其实 它们 都 是 由 单独 的 动物 结合 合在\n",
      "Reference: these are all individual animals banding together to make\n",
      "Model: <SOS> these are all individual animals banding together make make\n",
      "Attention Weights: tensor([[4.4626e-02, 1.0994e-01, 1.3371e-01, 1.4775e-01, 1.5836e-01, 1.6095e-01,\n",
      "         1.4513e-01, 8.9553e-02, 9.9968e-03, 1.3111e-06],\n",
      "        [4.6689e-02, 9.9891e-02, 1.2104e-01, 1.3380e-01, 1.4391e-01, 1.5187e-01,\n",
      "         1.4765e-01, 1.1951e-01, 3.5556e-02, 8.1014e-05],\n",
      "        [5.8573e-02, 8.6210e-02, 9.8069e-02, 1.0620e-01, 1.1240e-01, 1.2538e-01,\n",
      "         1.2635e-01, 1.4680e-01, 1.2971e-01, 1.0315e-02],\n",
      "        [6.4174e-02, 8.1307e-02, 8.9394e-02, 9.5459e-02, 1.0003e-01, 1.1343e-01,\n",
      "         1.1456e-01, 1.4497e-01, 1.6105e-01, 3.5632e-02],\n",
      "        [6.0771e-02, 7.8152e-02, 8.6516e-02, 9.3025e-02, 9.8008e-02, 1.1301e-01,\n",
      "         1.1512e-01, 1.5071e-01, 1.7200e-01, 3.2683e-02],\n",
      "        [5.8460e-02, 7.6347e-02, 8.5140e-02, 9.2102e-02, 9.7432e-02, 1.1364e-01,\n",
      "         1.1571e-01, 1.5427e-01, 1.7584e-01, 3.1061e-02],\n",
      "        [5.8342e-02, 7.6051e-02, 8.5051e-02, 9.2293e-02, 9.7760e-02, 1.1408e-01,\n",
      "         1.1594e-01, 1.5459e-01, 1.7537e-01, 3.0517e-02],\n",
      "        [5.8493e-02, 7.6157e-02, 8.5220e-02, 9.2558e-02, 9.8094e-02, 1.1418e-01,\n",
      "         1.1621e-01, 1.5431e-01, 1.7440e-01, 3.0386e-02],\n",
      "        [5.8139e-02, 7.6179e-02, 8.5387e-02, 9.2789e-02, 9.8385e-02, 1.1470e-01,\n",
      "         1.1649e-01, 1.5499e-01, 1.7360e-01, 2.9334e-02]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 出身 阿富汗 边远 <UNK> 地区 有着 与 他人 不同\n",
      "Reference: a total maverick from a remote province of afghanistan\n",
      "Model: <SOS> it &apos;s the the to and the the the\n",
      "Attention Weights: tensor([[1.1431e-01, 2.1757e-01, 2.6581e-01, 1.3731e-01, 7.2093e-04, 9.1377e-02,\n",
      "         1.0494e-01, 6.2317e-02, 5.6557e-03, 1.8494e-10],\n",
      "        [8.8604e-02, 1.5015e-01, 1.9592e-01, 1.8337e-01, 1.0224e-02, 1.1713e-01,\n",
      "         1.2936e-01, 9.6214e-02, 2.9024e-02, 6.0204e-09],\n",
      "        [7.4439e-02, 9.6817e-02, 1.2614e-01, 2.0348e-01, 9.0532e-02, 9.9739e-02,\n",
      "         1.0370e-01, 1.0781e-01, 9.7337e-02, 1.4799e-06],\n",
      "        [7.0871e-02, 8.5817e-02, 1.1170e-01, 1.9679e-01, 1.3257e-01, 8.9727e-02,\n",
      "         9.1680e-02, 1.0321e-01, 1.1760e-01, 3.0723e-05],\n",
      "        [6.6454e-02, 8.2757e-02, 1.1423e-01, 2.1846e-01, 1.3414e-01, 8.0096e-02,\n",
      "         8.3810e-02, 1.0056e-01, 1.1945e-01, 4.7743e-05],\n",
      "        [6.4630e-02, 8.1545e-02, 1.1508e-01, 2.2794e-01, 1.3364e-01, 7.6018e-02,\n",
      "         8.0414e-02, 9.9310e-02, 1.2137e-01, 5.2289e-05],\n",
      "        [6.3744e-02, 8.0490e-02, 1.1470e-01, 2.3259e-01, 1.3463e-01, 7.4477e-02,\n",
      "         7.8538e-02, 9.8203e-02, 1.2258e-01, 4.6500e-05],\n",
      "        [6.3375e-02, 8.0006e-02, 1.1410e-01, 2.3388e-01, 1.3415e-01, 7.4237e-02,\n",
      "         7.8460e-02, 9.7945e-02, 1.2381e-01, 3.9837e-05],\n",
      "        [6.3149e-02, 7.9786e-02, 1.1391e-01, 2.3447e-01, 1.3405e-01, 7.4340e-02,\n",
      "         7.8636e-02, 9.8039e-02, 1.2358e-01, 3.8605e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 148.00, Train Loss: 1.46, Val Loss: 12.75, Train BLEU: 48.07, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 但 我 想 告诉 你 的 是 当 你 站\n",
      "Reference: but when you &apos;re standing at the beach ,\n",
      "Model: <SOS> but when the &apos;re standing , , , ,\n",
      "Attention Weights: tensor([[0.0413, 0.0806, 0.1067, 0.1300, 0.1343, 0.1348, 0.1237, 0.1083, 0.0896,\n",
      "         0.0507],\n",
      "        [0.0477, 0.0814, 0.1044, 0.1252, 0.1275, 0.1288, 0.1204, 0.1089, 0.0937,\n",
      "         0.0621],\n",
      "        [0.0697, 0.0862, 0.0987, 0.1111, 0.1110, 0.1130, 0.1105, 0.1068, 0.1019,\n",
      "         0.0912],\n",
      "        [0.0767, 0.0875, 0.0966, 0.1068, 0.1057, 0.1081, 0.1073, 0.1055, 0.1039,\n",
      "         0.1019],\n",
      "        [0.0740, 0.0848, 0.0945, 0.1062, 0.1049, 0.1081, 0.1079, 0.1067, 0.1061,\n",
      "         0.1068],\n",
      "        [0.0694, 0.0812, 0.0922, 0.1064, 0.1051, 0.1091, 0.1093, 0.1084, 0.1084,\n",
      "         0.1104],\n",
      "        [0.0681, 0.0803, 0.0917, 0.1067, 0.1055, 0.1097, 0.1099, 0.1089, 0.1087,\n",
      "         0.1107],\n",
      "        [0.0672, 0.0795, 0.0913, 0.1067, 0.1059, 0.1102, 0.1103, 0.1094, 0.1090,\n",
      "         0.1106],\n",
      "        [0.0667, 0.0794, 0.0913, 0.1070, 0.1062, 0.1105, 0.1106, 0.1095, 0.1089,\n",
      "         0.1098]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 对 他 来说 孩子 不 接受 受教 教育 <UNK> 是\n",
      "Reference: to him , there was greater risk in not\n",
      "Model: <SOS> we use the submarine alvin and use use cameras\n",
      "Attention Weights: tensor([[9.7060e-02, 1.7981e-01, 2.3104e-01, 2.3357e-01, 2.0093e-01, 5.6277e-02,\n",
      "         1.3102e-03, 1.8163e-10, 1.8163e-10, 1.8163e-10],\n",
      "        [9.7031e-02, 1.6254e-01, 2.0934e-01, 2.2419e-01, 2.0260e-01, 9.3918e-02,\n",
      "         1.0376e-02, 4.4313e-09, 4.4313e-09, 4.4313e-09],\n",
      "        [1.0513e-01, 1.3701e-01, 1.6647e-01, 1.8382e-01, 1.7457e-01, 1.5083e-01,\n",
      "         8.2163e-02, 9.2710e-07, 9.2710e-07, 9.2710e-07],\n",
      "        [1.0367e-01, 1.2346e-01, 1.4624e-01, 1.6351e-01, 1.5849e-01, 1.6836e-01,\n",
      "         1.3621e-01, 2.2614e-05, 2.2614e-05, 2.2614e-05],\n",
      "        [9.3510e-02, 1.1377e-01, 1.3888e-01, 1.6025e-01, 1.5787e-01, 1.8271e-01,\n",
      "         1.5284e-01, 5.4595e-05, 5.4595e-05, 5.4595e-05],\n",
      "        [9.1436e-02, 1.1201e-01, 1.3737e-01, 1.5971e-01, 1.5780e-01, 1.8570e-01,\n",
      "         1.5583e-01, 4.6268e-05, 4.6268e-05, 4.6268e-05],\n",
      "        [9.1932e-02, 1.1282e-01, 1.3811e-01, 1.6053e-01, 1.5898e-01, 1.8392e-01,\n",
      "         1.5361e-01, 3.2833e-05, 3.2833e-05, 3.2833e-05],\n",
      "        [9.2071e-02, 1.1293e-01, 1.3825e-01, 1.6063e-01, 1.5911e-01, 1.8363e-01,\n",
      "         1.5328e-01, 3.3578e-05, 3.3578e-05, 3.3578e-05],\n",
      "        [9.2110e-02, 1.1293e-01, 1.3823e-01, 1.6059e-01, 1.5911e-01, 1.8361e-01,\n",
      "         1.5331e-01, 3.3847e-05, 3.3847e-05, 3.3847e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 149.00, Train Loss: 1.44, Val Loss: 12.76, Train BLEU: 50.06, Val BLEU: 0.32\n",
      "Sampling from training predictions...\n",
      "Source: 这 是 一只 水母 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: here &apos;s a jelly . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> here &apos;s a jelly . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.8530e-01, 3.3054e-01, 3.5471e-01, 1.2637e-01, 3.0837e-03, 5.5243e-10,\n",
      "         5.5243e-10, 5.5243e-10, 5.5243e-10, 5.5243e-10],\n",
      "        [1.7659e-01, 2.8392e-01, 3.2353e-01, 1.9112e-01, 2.4847e-02, 1.3051e-08,\n",
      "         1.3051e-08, 1.3051e-08, 1.3051e-08, 1.3051e-08],\n",
      "        [1.5682e-01, 2.0405e-01, 2.4333e-01, 2.4746e-01, 1.4833e-01, 1.6510e-06,\n",
      "         1.6510e-06, 1.6510e-06, 1.6510e-06, 1.6510e-06],\n",
      "        [1.4400e-01, 1.7268e-01, 2.0874e-01, 2.5149e-01, 2.2290e-01, 3.9121e-05,\n",
      "         3.9121e-05, 3.9121e-05, 3.9121e-05, 3.9121e-05],\n",
      "        [1.3027e-01, 1.5971e-01, 2.0107e-01, 2.6502e-01, 2.4346e-01, 9.5284e-05,\n",
      "         9.5284e-05, 9.5284e-05, 9.5284e-05, 9.5284e-05],\n",
      "        [1.2917e-01, 1.5934e-01, 2.0064e-01, 2.6598e-01, 2.4450e-01, 7.6508e-05,\n",
      "         7.6508e-05, 7.6508e-05, 7.6508e-05, 7.6508e-05],\n",
      "        [1.3071e-01, 1.6120e-01, 2.0223e-01, 2.6407e-01, 2.4148e-01, 6.1710e-05,\n",
      "         6.1710e-05, 6.1710e-05, 6.1710e-05, 6.1710e-05],\n",
      "        [1.3093e-01, 1.6138e-01, 2.0241e-01, 2.6376e-01, 2.4120e-01, 6.3291e-05,\n",
      "         6.3291e-05, 6.3291e-05, 6.3291e-05, 6.3291e-05],\n",
      "        [1.3098e-01, 1.6137e-01, 2.0237e-01, 2.6366e-01, 2.4130e-01, 6.4101e-05,\n",
      "         6.4101e-05, 6.4101e-05, 6.4101e-05, 6.4101e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天 要 走 不同 的 路线 这样 才 没有\n",
      "Reference: each day , we took a different route so\n",
      "Model: <SOS> part of the the , , , , ,\n",
      "Attention Weights: tensor([[0.0436, 0.1069, 0.1366, 0.1269, 0.1340, 0.1278, 0.1124, 0.0991, 0.0783,\n",
      "         0.0345],\n",
      "        [0.0505, 0.1013, 0.1315, 0.1182, 0.1297, 0.1208, 0.1144, 0.0982, 0.0830,\n",
      "         0.0524],\n",
      "        [0.0762, 0.0986, 0.1178, 0.1022, 0.1134, 0.1047, 0.1071, 0.0941, 0.0898,\n",
      "         0.0962],\n",
      "        [0.0799, 0.0959, 0.1142, 0.0963, 0.1104, 0.0996, 0.1067, 0.0918, 0.0912,\n",
      "         0.1139],\n",
      "        [0.0724, 0.0908, 0.1145, 0.0941, 0.1124, 0.0989, 0.1092, 0.0910, 0.0919,\n",
      "         0.1248],\n",
      "        [0.0689, 0.0889, 0.1151, 0.0939, 0.1135, 0.0994, 0.1102, 0.0911, 0.0922,\n",
      "         0.1266],\n",
      "        [0.0682, 0.0888, 0.1155, 0.0942, 0.1140, 0.0998, 0.1105, 0.0913, 0.0920,\n",
      "         0.1257],\n",
      "        [0.0678, 0.0887, 0.1155, 0.0943, 0.1142, 0.0999, 0.1107, 0.0914, 0.0920,\n",
      "         0.1256],\n",
      "        [0.0677, 0.0886, 0.1155, 0.0943, 0.1142, 0.1000, 0.1108, 0.0914, 0.0920,\n",
      "         0.1255]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 150.00, Train Loss: 1.43, Val Loss: 12.77, Train BLEU: 50.72, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 我们 得用 非常 特殊 的 仪器 才能 能到 到达 那个\n",
      "Reference: we have to have a very special technology to\n",
      "Model: <SOS> we have to have to very special technology technology\n",
      "Attention Weights: tensor([[0.0049, 0.0018, 0.1486, 0.1983, 0.2037, 0.1849, 0.1604, 0.0281, 0.0438,\n",
      "         0.0256],\n",
      "        [0.0127, 0.0124, 0.1459, 0.1755, 0.1752, 0.1631, 0.1489, 0.0599, 0.0618,\n",
      "         0.0446],\n",
      "        [0.0390, 0.0628, 0.1167, 0.1227, 0.1230, 0.1276, 0.1377, 0.1141, 0.0825,\n",
      "         0.0739],\n",
      "        [0.0458, 0.0803, 0.1069, 0.1104, 0.1119, 0.1214, 0.1385, 0.1235, 0.0829,\n",
      "         0.0784],\n",
      "        [0.0476, 0.0847, 0.1044, 0.1078, 0.1096, 0.1203, 0.1391, 0.1252, 0.0825,\n",
      "         0.0789],\n",
      "        [0.0483, 0.0894, 0.1018, 0.1053, 0.1074, 0.1195, 0.1407, 0.1278, 0.0813,\n",
      "         0.0785],\n",
      "        [0.0472, 0.0905, 0.1008, 0.1047, 0.1071, 0.1205, 0.1433, 0.1291, 0.0796,\n",
      "         0.0772],\n",
      "        [0.0465, 0.0895, 0.1010, 0.1056, 0.1082, 0.1219, 0.1445, 0.1281, 0.0787,\n",
      "         0.0762],\n",
      "        [0.0462, 0.0891, 0.1012, 0.1059, 0.1086, 0.1224, 0.1450, 0.1271, 0.0786,\n",
      "         0.0759]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在 一个 房屋 房屋里 屋里 我们 100 多 人\n",
      "Reference: the school was in a house , more than\n",
      "Model: <SOS> the biodiversity the the the and the the the\n",
      "Attention Weights: tensor([[0.0317, 0.0525, 0.1491, 0.1555, 0.1421, 0.1382, 0.1116, 0.0993, 0.0771,\n",
      "         0.0429],\n",
      "        [0.0396, 0.0833, 0.1350, 0.1409, 0.1257, 0.1354, 0.1131, 0.0930, 0.0778,\n",
      "         0.0562],\n",
      "        [0.0707, 0.1426, 0.1150, 0.1136, 0.1013, 0.1166, 0.1005, 0.0828, 0.0778,\n",
      "         0.0790],\n",
      "        [0.0752, 0.1521, 0.1080, 0.1068, 0.0951, 0.1148, 0.0994, 0.0802, 0.0783,\n",
      "         0.0900],\n",
      "        [0.0699, 0.1584, 0.1049, 0.1052, 0.0933, 0.1164, 0.0999, 0.0787, 0.0780,\n",
      "         0.0952],\n",
      "        [0.0657, 0.1618, 0.1033, 0.1052, 0.0926, 0.1193, 0.1008, 0.0769, 0.0767,\n",
      "         0.0977],\n",
      "        [0.0642, 0.1602, 0.1030, 0.1057, 0.0932, 0.1202, 0.1014, 0.0773, 0.0770,\n",
      "         0.0978],\n",
      "        [0.0630, 0.1585, 0.1030, 0.1063, 0.0938, 0.1211, 0.1020, 0.0777, 0.0772,\n",
      "         0.0974],\n",
      "        [0.0627, 0.1574, 0.1029, 0.1064, 0.0941, 0.1214, 0.1024, 0.0779, 0.0773,\n",
      "         0.0976]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 151.00, Train Loss: 1.41, Val Loss: 12.78, Train BLEU: 51.60, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 底下 这些 都 是 <UNK> 它们 上上 上上下下 上下 下下\n",
      "Reference: it &apos;s got these fishing <UNK> on the bottom\n",
      "Model: <SOS> it &apos;s got these fishing <UNK> on the bottom\n",
      "Attention Weights: tensor([[0.0718, 0.1356, 0.1521, 0.0585, 0.0000, 0.0631, 0.1496, 0.2223, 0.1412,\n",
      "         0.0056],\n",
      "        [0.0727, 0.1288, 0.1750, 0.1229, 0.0013, 0.0644, 0.1233, 0.1671, 0.1263,\n",
      "         0.0182],\n",
      "        [0.0771, 0.1095, 0.1689, 0.2223, 0.0411, 0.0600, 0.0910, 0.0893, 0.0846,\n",
      "         0.0562],\n",
      "        [0.0742, 0.1009, 0.1603, 0.2432, 0.0771, 0.0538, 0.0777, 0.0710, 0.0736,\n",
      "         0.0683],\n",
      "        [0.0706, 0.1008, 0.1687, 0.2628, 0.0808, 0.0457, 0.0690, 0.0639, 0.0696,\n",
      "         0.0682],\n",
      "        [0.0701, 0.1007, 0.1680, 0.2599, 0.0851, 0.0443, 0.0682, 0.0630, 0.0694,\n",
      "         0.0713],\n",
      "        [0.0693, 0.0990, 0.1656, 0.2597, 0.0890, 0.0442, 0.0676, 0.0625, 0.0693,\n",
      "         0.0737],\n",
      "        [0.0686, 0.0975, 0.1633, 0.2592, 0.0901, 0.0446, 0.0677, 0.0630, 0.0697,\n",
      "         0.0763],\n",
      "        [0.0683, 0.0971, 0.1629, 0.2593, 0.0881, 0.0450, 0.0685, 0.0635, 0.0698,\n",
      "         0.0774]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 很 幸运 幸运地 成长 在 一个 珍视 教育 也\n",
      "Reference: i was very lucky to grow up in a\n",
      "Model: <SOS> we biodiversity the the the and the the the\n",
      "Attention Weights: tensor([[1.8020e-01, 3.2871e-01, 3.5354e-01, 1.3416e-01, 3.3903e-03, 5.9640e-10,\n",
      "         5.9640e-10, 5.9640e-10, 5.9640e-10, 5.9640e-10],\n",
      "        [1.7161e-01, 2.8435e-01, 3.2404e-01, 1.9632e-01, 2.3681e-02, 1.0786e-08,\n",
      "         1.0786e-08, 1.0786e-08, 1.0786e-08, 1.0786e-08],\n",
      "        [1.5109e-01, 2.0409e-01, 2.4645e-01, 2.5339e-01, 1.4497e-01, 1.2520e-06,\n",
      "         1.2520e-06, 1.2520e-06, 1.2520e-06, 1.2520e-06],\n",
      "        [1.3715e-01, 1.6914e-01, 2.0793e-01, 2.5789e-01, 2.2775e-01, 2.9799e-05,\n",
      "         2.9799e-05, 2.9799e-05, 2.9799e-05, 2.9799e-05],\n",
      "        [1.2375e-01, 1.5514e-01, 1.9827e-01, 2.7032e-01, 2.5211e-01, 8.0251e-05,\n",
      "         8.0251e-05, 8.0251e-05, 8.0251e-05, 8.0251e-05],\n",
      "        [1.2392e-01, 1.5567e-01, 1.9820e-01, 2.6958e-01, 2.5227e-01, 7.0629e-05,\n",
      "         7.0629e-05, 7.0629e-05, 7.0629e-05, 7.0629e-05],\n",
      "        [1.2570e-01, 1.5770e-01, 1.9966e-01, 2.6730e-01, 2.4934e-01, 5.8062e-05,\n",
      "         5.8062e-05, 5.8062e-05, 5.8062e-05, 5.8062e-05],\n",
      "        [1.2593e-01, 1.5787e-01, 1.9978e-01, 2.6695e-01, 2.4917e-01, 5.9990e-05,\n",
      "         5.9990e-05, 5.9990e-05, 5.9990e-05, 5.9990e-05],\n",
      "        [1.2596e-01, 1.5785e-01, 1.9974e-01, 2.6687e-01, 2.4928e-01, 6.0710e-05,\n",
      "         6.0710e-05, 6.0710e-05, 6.0710e-05, 6.0710e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 152.00, Train Loss: 1.39, Val Loss: 12.79, Train BLEU: 52.95, Val BLEU: 0.31\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分 部分 的 动物 也 都 生活 在 海洋\n",
      "Reference: most of the animals are in the oceans .\n",
      "Model: <SOS> most of the animals , the the the the\n",
      "Attention Weights: tensor([[0.0369, 0.1179, 0.1366, 0.1325, 0.1347, 0.1142, 0.1094, 0.1028, 0.0814,\n",
      "         0.0336],\n",
      "        [0.0458, 0.1121, 0.1290, 0.1231, 0.1335, 0.1085, 0.1053, 0.1082, 0.0842,\n",
      "         0.0503],\n",
      "        [0.0772, 0.1125, 0.1147, 0.1077, 0.1169, 0.0980, 0.0967, 0.1036, 0.0876,\n",
      "         0.0852],\n",
      "        [0.0849, 0.1101, 0.1090, 0.1006, 0.1140, 0.0915, 0.0912, 0.1053, 0.0882,\n",
      "         0.1052],\n",
      "        [0.0790, 0.1072, 0.1071, 0.0976, 0.1167, 0.0879, 0.0879, 0.1094, 0.0880,\n",
      "         0.1192],\n",
      "        [0.0762, 0.1062, 0.1074, 0.0979, 0.1178, 0.0880, 0.0880, 0.1101, 0.0882,\n",
      "         0.1202],\n",
      "        [0.0753, 0.1057, 0.1077, 0.0982, 0.1183, 0.0883, 0.0883, 0.1103, 0.0882,\n",
      "         0.1196],\n",
      "        [0.0750, 0.1055, 0.1077, 0.0983, 0.1184, 0.0884, 0.0884, 0.1105, 0.0882,\n",
      "         0.1196],\n",
      "        [0.0748, 0.1053, 0.1077, 0.0984, 0.1185, 0.0885, 0.0884, 0.1106, 0.0883,\n",
      "         0.1195]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 很 害怕 但是 我们 仍然 渴望 望去 学校 <EOS>\n",
      "Reference: we were scared , but still , school was\n",
      "Model: <SOS> it &apos;s all those planet dangling . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0349, 0.0844, 0.1271, 0.1275, 0.1323, 0.1357, 0.1282, 0.1047, 0.0829,\n",
      "         0.0422],\n",
      "        [0.0402, 0.0831, 0.1219, 0.1212, 0.1304, 0.1273, 0.1263, 0.1107, 0.0866,\n",
      "         0.0524],\n",
      "        [0.0626, 0.0882, 0.1133, 0.1108, 0.1167, 0.1120, 0.1138, 0.1092, 0.0937,\n",
      "         0.0796],\n",
      "        [0.0697, 0.0880, 0.1084, 0.1047, 0.1131, 0.1050, 0.1108, 0.1128, 0.0961,\n",
      "         0.0914],\n",
      "        [0.0669, 0.0844, 0.1065, 0.1026, 0.1138, 0.1030, 0.1115, 0.1166, 0.0977,\n",
      "         0.0970],\n",
      "        [0.0620, 0.0803, 0.1056, 0.1014, 0.1159, 0.1022, 0.1135, 0.1211, 0.0986,\n",
      "         0.0996],\n",
      "        [0.0616, 0.0799, 0.1055, 0.1013, 0.1163, 0.1021, 0.1139, 0.1217, 0.0984,\n",
      "         0.0993],\n",
      "        [0.0614, 0.0797, 0.1054, 0.1013, 0.1163, 0.1022, 0.1139, 0.1217, 0.0986,\n",
      "         0.0995],\n",
      "        [0.0601, 0.0787, 0.1054, 0.1016, 0.1167, 0.1028, 0.1144, 0.1219, 0.0989,\n",
      "         0.0994]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 153.00, Train Loss: 1.37, Val Loss: 12.79, Train BLEU: 54.02, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数 多数 地震 和 火山 喷发 也 都 发生\n",
      "Reference: most of the earthquakes and volcanoes are in the\n",
      "Model: <SOS> most of the earthquakes and the the the the\n",
      "Attention Weights: tensor([[0.0329, 0.0597, 0.1528, 0.1589, 0.1441, 0.1363, 0.1075, 0.0943, 0.0732,\n",
      "         0.0403],\n",
      "        [0.0389, 0.0893, 0.1387, 0.1446, 0.1283, 0.1351, 0.1088, 0.0891, 0.0744,\n",
      "         0.0527],\n",
      "        [0.0679, 0.1491, 0.1177, 0.1178, 0.1049, 0.1177, 0.0984, 0.0801, 0.0744,\n",
      "         0.0719],\n",
      "        [0.0729, 0.1620, 0.1092, 0.1090, 0.0970, 0.1160, 0.0973, 0.0772, 0.0747,\n",
      "         0.0846],\n",
      "        [0.0679, 0.1719, 0.1049, 0.1063, 0.0938, 0.1179, 0.0975, 0.0747, 0.0737,\n",
      "         0.0912],\n",
      "        [0.0642, 0.1772, 0.1028, 0.1058, 0.0924, 0.1211, 0.0978, 0.0722, 0.0719,\n",
      "         0.0946],\n",
      "        [0.0629, 0.1764, 0.1023, 0.1063, 0.0929, 0.1221, 0.0982, 0.0721, 0.0719,\n",
      "         0.0949],\n",
      "        [0.0619, 0.1744, 0.1023, 0.1069, 0.0935, 0.1230, 0.0988, 0.0725, 0.0721,\n",
      "         0.0947],\n",
      "        [0.0617, 0.1729, 0.1022, 0.1071, 0.0938, 0.1233, 0.0990, 0.0728, 0.0722,\n",
      "         0.0949]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 很 幸运 幸运地 成长 在 一个 珍视 教育 也\n",
      "Reference: i was very lucky to grow up in a\n",
      "Model: <SOS> we biodiversity the the the and and the the\n",
      "Attention Weights: tensor([[1.8058e-01, 3.3663e-01, 3.5845e-01, 1.2193e-01, 2.4060e-03, 6.5156e-10,\n",
      "         6.5156e-10, 6.5156e-10, 6.5156e-10, 6.5156e-10],\n",
      "        [1.7263e-01, 2.9358e-01, 3.3165e-01, 1.8506e-01, 1.7079e-02, 9.5976e-09,\n",
      "         9.5976e-09, 9.5976e-09, 9.5976e-09, 9.5976e-09],\n",
      "        [1.5139e-01, 2.1271e-01, 2.5945e-01, 2.5699e-01, 1.1946e-01, 9.1722e-07,\n",
      "         9.1722e-07, 9.1722e-07, 9.1722e-07, 9.1722e-07],\n",
      "        [1.3610e-01, 1.7226e-01, 2.1497e-01, 2.6924e-01, 2.0732e-01, 2.2089e-05,\n",
      "         2.2089e-05, 2.2089e-05, 2.2089e-05, 2.2089e-05],\n",
      "        [1.2253e-01, 1.5657e-01, 2.0327e-01, 2.8398e-01, 2.3331e-01, 6.7924e-05,\n",
      "         6.7924e-05, 6.7924e-05, 6.7924e-05, 6.7924e-05],\n",
      "        [1.2332e-01, 1.5719e-01, 2.0288e-01, 2.8170e-01, 2.3458e-01, 6.6206e-05,\n",
      "         6.6206e-05, 6.6206e-05, 6.6206e-05, 6.6206e-05],\n",
      "        [1.2522e-01, 1.5915e-01, 2.0389e-01, 2.7851e-01, 2.3295e-01, 5.4932e-05,\n",
      "         5.4932e-05, 5.4932e-05, 5.4932e-05, 5.4932e-05],\n",
      "        [1.2547e-01, 1.5935e-01, 2.0401e-01, 2.7805e-01, 2.3284e-01, 5.7432e-05,\n",
      "         5.7432e-05, 5.7432e-05, 5.7432e-05, 5.7432e-05],\n",
      "        [1.2550e-01, 1.5932e-01, 2.0398e-01, 2.7797e-01, 2.3293e-01, 5.8130e-05,\n",
      "         5.8130e-05, 5.8130e-05, 5.8130e-05, 5.8130e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 154.00, Train Loss: 1.35, Val Loss: 12.80, Train BLEU: 54.03, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 当 你 站 在 海滩 上 或是 当 你 看到\n",
      "Reference: part of the problem , i think , is\n",
      "Model: <SOS> part of the problem , , , , ,\n",
      "Attention Weights: tensor([[0.0353, 0.0720, 0.0989, 0.1230, 0.1540, 0.1480, 0.1303, 0.1108, 0.0868,\n",
      "         0.0409],\n",
      "        [0.0403, 0.0727, 0.0965, 0.1174, 0.1532, 0.1365, 0.1303, 0.1082, 0.0890,\n",
      "         0.0560],\n",
      "        [0.0610, 0.0811, 0.0968, 0.1100, 0.1314, 0.1173, 0.1166, 0.1035, 0.0954,\n",
      "         0.0869],\n",
      "        [0.0681, 0.0811, 0.0925, 0.1026, 0.1272, 0.1069, 0.1143, 0.0997, 0.0967,\n",
      "         0.1109],\n",
      "        [0.0623, 0.0746, 0.0868, 0.0983, 0.1319, 0.1040, 0.1177, 0.0992, 0.0979,\n",
      "         0.1274],\n",
      "        [0.0587, 0.0707, 0.0837, 0.0965, 0.1349, 0.1037, 0.1198, 0.0994, 0.0984,\n",
      "         0.1342],\n",
      "        [0.0579, 0.0701, 0.0833, 0.0964, 0.1355, 0.1042, 0.1202, 0.0997, 0.0984,\n",
      "         0.1341],\n",
      "        [0.0578, 0.0700, 0.0832, 0.0963, 0.1359, 0.1042, 0.1203, 0.0996, 0.0983,\n",
      "         0.1343],\n",
      "        [0.0577, 0.0700, 0.0832, 0.0963, 0.1359, 0.1043, 0.1204, 0.0997, 0.0983,\n",
      "         0.1342]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 她 两年 年前 退休 了 结果 却 把 我家 变成\n",
      "Reference: she retired two years ago , only to turn\n",
      "Model: <SOS> most of the the matter the the the the\n",
      "Attention Weights: tensor([[1.3248e-01, 2.4336e-01, 2.9628e-01, 2.5734e-01, 6.9367e-02, 1.1767e-03,\n",
      "         4.7010e-10, 4.7010e-10, 4.7010e-10, 4.7010e-10],\n",
      "        [1.3103e-01, 2.1454e-01, 2.6567e-01, 2.5634e-01, 1.2112e-01, 1.1303e-02,\n",
      "         8.8195e-09, 8.8195e-09, 8.8195e-09, 8.8195e-09],\n",
      "        [1.2155e-01, 1.6320e-01, 2.0212e-01, 2.2112e-01, 1.9731e-01, 9.4700e-02,\n",
      "         9.9754e-07, 9.9754e-07, 9.9754e-07, 9.9754e-07],\n",
      "        [1.1111e-01, 1.3516e-01, 1.6487e-01, 1.9181e-01, 2.2273e-01, 1.7422e-01,\n",
      "         2.5680e-05, 2.5680e-05, 2.5680e-05, 2.5680e-05],\n",
      "        [1.0268e-01, 1.2547e-01, 1.5558e-01, 1.8740e-01, 2.3648e-01, 1.9213e-01,\n",
      "         6.6203e-05, 6.6203e-05, 6.6203e-05, 6.6203e-05],\n",
      "        [1.0062e-01, 1.2302e-01, 1.5319e-01, 1.8604e-01, 2.3978e-01, 1.9703e-01,\n",
      "         7.8096e-05, 7.8096e-05, 7.8096e-05, 7.8096e-05],\n",
      "        [1.0069e-01, 1.2295e-01, 1.5250e-01, 1.8535e-01, 2.4046e-01, 1.9777e-01,\n",
      "         7.4205e-05, 7.4205e-05, 7.4205e-05, 7.4205e-05],\n",
      "        [1.0204e-01, 1.2439e-01, 1.5262e-01, 1.8483e-01, 2.3642e-01, 1.9944e-01,\n",
      "         6.2984e-05, 6.2984e-05, 6.2984e-05, 6.2984e-05],\n",
      "        [1.0267e-01, 1.2487e-01, 1.5299e-01, 1.8505e-01, 2.3549e-01, 1.9867e-01,\n",
      "         6.5200e-05, 6.5200e-05, 6.5200e-05, 6.5200e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 155.00, Train Loss: 1.33, Val Loss: 12.81, Train BLEU: 54.85, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 我们 得用 非常 特殊 的 仪器 才能 能到 到达 那个\n",
      "Reference: we have to have a very special technology to\n",
      "Model: <SOS> we have to have have very special technology technology\n",
      "Attention Weights: tensor([[0.0045, 0.0021, 0.1469, 0.1951, 0.2036, 0.1960, 0.1616, 0.0309, 0.0381,\n",
      "         0.0213],\n",
      "        [0.0111, 0.0127, 0.1453, 0.1749, 0.1757, 0.1730, 0.1521, 0.0633, 0.0543,\n",
      "         0.0376],\n",
      "        [0.0344, 0.0658, 0.1165, 0.1215, 0.1224, 0.1341, 0.1456, 0.1213, 0.0745,\n",
      "         0.0639],\n",
      "        [0.0422, 0.0892, 0.1042, 0.1059, 0.1078, 0.1256, 0.1475, 0.1341, 0.0749,\n",
      "         0.0684],\n",
      "        [0.0444, 0.0962, 0.1008, 0.1022, 0.1043, 0.1237, 0.1480, 0.1370, 0.0744,\n",
      "         0.0690],\n",
      "        [0.0461, 0.1034, 0.0974, 0.0987, 0.1009, 0.1218, 0.1488, 0.1408, 0.0733,\n",
      "         0.0688],\n",
      "        [0.0457, 0.1065, 0.0957, 0.0972, 0.0998, 0.1222, 0.1509, 0.1430, 0.0715,\n",
      "         0.0673],\n",
      "        [0.0451, 0.1062, 0.0955, 0.0976, 0.1005, 0.1237, 0.1525, 0.1419, 0.0706,\n",
      "         0.0664],\n",
      "        [0.0450, 0.1061, 0.0956, 0.0978, 0.1009, 0.1241, 0.1530, 0.1409, 0.0704,\n",
      "         0.0661]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 她 两年 年前 退休 了 结果 却 把 我家 变成\n",
      "Reference: she retired two years ago , only to turn\n",
      "Model: <SOS> most of the the matter the the the the\n",
      "Attention Weights: tensor([[1.3648e-01, 2.4739e-01, 2.9531e-01, 2.5254e-01, 6.7120e-02, 1.1555e-03,\n",
      "         5.4834e-10, 5.4834e-10, 5.4834e-10, 5.4834e-10],\n",
      "        [1.3489e-01, 2.1682e-01, 2.6373e-01, 2.5242e-01, 1.2034e-01, 1.1806e-02,\n",
      "         1.0720e-08, 1.0720e-08, 1.0720e-08, 1.0720e-08],\n",
      "        [1.2195e-01, 1.6144e-01, 1.9828e-01, 2.1892e-01, 2.0026e-01, 9.9148e-02,\n",
      "         1.1678e-06, 1.1678e-06, 1.1678e-06, 1.1678e-06],\n",
      "        [1.1044e-01, 1.3281e-01, 1.6127e-01, 1.8987e-01, 2.2557e-01, 1.7992e-01,\n",
      "         3.0315e-05, 3.0315e-05, 3.0315e-05, 3.0315e-05],\n",
      "        [1.0225e-01, 1.2327e-01, 1.5200e-01, 1.8513e-01, 2.3889e-01, 1.9813e-01,\n",
      "         8.1687e-05, 8.1687e-05, 8.1687e-05, 8.1687e-05],\n",
      "        [1.0042e-01, 1.2104e-01, 1.4984e-01, 1.8386e-01, 2.4195e-01, 2.0249e-01,\n",
      "         9.7200e-05, 9.7200e-05, 9.7200e-05, 9.7200e-05],\n",
      "        [1.0063e-01, 1.2119e-01, 1.4940e-01, 1.8339e-01, 2.4244e-01, 2.0258e-01,\n",
      "         9.2459e-05, 9.2459e-05, 9.2459e-05, 9.2459e-05],\n",
      "        [1.0209e-01, 1.2279e-01, 1.4950e-01, 1.8261e-01, 2.3798e-01, 2.0471e-01,\n",
      "         7.9044e-05, 7.9044e-05, 7.9044e-05, 7.9044e-05],\n",
      "        [1.0274e-01, 1.2332e-01, 1.4991e-01, 1.8287e-01, 2.3693e-01, 2.0391e-01,\n",
      "         8.0229e-05, 8.0229e-05, 8.0229e-05, 8.0229e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 156.00, Train Loss: 1.32, Val Loss: 12.82, Train BLEU: 56.75, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中 的 生命 大卫 <UNK> <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: life in the deep oceans <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> life in the deep oceans <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.8448e-01, 3.2385e-01, 3.2330e-01, 1.5964e-01, 8.7276e-03, 2.1881e-06,\n",
      "         6.2102e-07, 5.0654e-10, 5.0654e-10, 5.0654e-10],\n",
      "        [1.6853e-01, 2.7564e-01, 3.0485e-01, 2.2766e-01, 2.3320e-02, 6.4596e-06,\n",
      "         2.0021e-06, 1.1234e-09, 1.1234e-09, 1.1234e-09],\n",
      "        [1.2712e-01, 1.7868e-01, 2.1956e-01, 2.9336e-01, 1.7837e-01, 2.2431e-03,\n",
      "         6.5835e-04, 1.5956e-07, 1.5956e-07, 1.5956e-07],\n",
      "        [1.0376e-01, 1.2447e-01, 1.5415e-01, 2.6601e-01, 3.2145e-01, 2.3291e-02,\n",
      "         6.8525e-03, 4.4379e-06, 4.4379e-06, 4.4379e-06],\n",
      "        [9.3537e-02, 1.1155e-01, 1.4139e-01, 2.5929e-01, 3.5280e-01, 3.1929e-02,\n",
      "         9.4693e-03, 1.3615e-05, 1.3615e-05, 1.3615e-05],\n",
      "        [9.5444e-02, 1.1299e-01, 1.4223e-01, 2.5470e-01, 3.4945e-01, 3.4714e-02,\n",
      "         1.0409e-02, 1.7946e-05, 1.7946e-05, 1.7946e-05],\n",
      "        [9.6658e-02, 1.1336e-01, 1.4174e-01, 2.5169e-01, 3.4528e-01, 3.9220e-02,\n",
      "         1.1999e-02, 1.9971e-05, 1.9971e-05, 1.9971e-05],\n",
      "        [9.6306e-02, 1.1288e-01, 1.4113e-01, 2.5123e-01, 3.4556e-01, 4.0419e-02,\n",
      "         1.2420e-02, 2.1681e-05, 2.1681e-05, 2.1681e-05],\n",
      "        [9.6151e-02, 1.1262e-01, 1.4081e-01, 2.5113e-01, 3.4591e-01, 4.0750e-02,\n",
      "         1.2552e-02, 2.2279e-05, 2.2279e-05, 2.2279e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 对 他 来说 孩子 不 接受 受教 教育 <UNK> 是\n",
      "Reference: to him , there was greater risk in not\n",
      "Model: <SOS> we use the submarine alvin and use use cameras\n",
      "Attention Weights: tensor([[1.0085e-01, 1.8951e-01, 2.4027e-01, 2.3120e-01, 1.8389e-01, 5.2518e-02,\n",
      "         1.7671e-03, 3.7836e-10, 3.7836e-10, 3.7836e-10],\n",
      "        [1.0261e-01, 1.7049e-01, 2.1686e-01, 2.2284e-01, 1.8788e-01, 8.7582e-02,\n",
      "         1.1739e-02, 5.2706e-09, 5.2706e-09, 5.2706e-09],\n",
      "        [1.0097e-01, 1.3515e-01, 1.6891e-01, 1.8700e-01, 1.6580e-01, 1.4680e-01,\n",
      "         9.5361e-02, 9.9974e-07, 9.9974e-07, 9.9974e-07],\n",
      "        [9.5326e-02, 1.1467e-01, 1.4049e-01, 1.6180e-01, 1.4732e-01, 1.6962e-01,\n",
      "         1.7067e-01, 3.2364e-05, 3.2364e-05, 3.2364e-05],\n",
      "        [8.6479e-02, 1.0365e-01, 1.2889e-01, 1.5357e-01, 1.4239e-01, 1.8368e-01,\n",
      "         2.0099e-01, 1.2002e-04, 1.2002e-04, 1.2002e-04],\n",
      "        [8.7197e-02, 1.0439e-01, 1.2838e-01, 1.5247e-01, 1.4228e-01, 1.8326e-01,\n",
      "         2.0165e-01, 1.2277e-04, 1.2277e-04, 1.2277e-04],\n",
      "        [8.8390e-02, 1.0551e-01, 1.2868e-01, 1.5256e-01, 1.4253e-01, 1.8127e-01,\n",
      "         2.0079e-01, 9.1267e-05, 9.1267e-05, 9.1267e-05],\n",
      "        [8.8584e-02, 1.0557e-01, 1.2867e-01, 1.5253e-01, 1.4249e-01, 1.8103e-01,\n",
      "         2.0084e-01, 9.5308e-05, 9.5308e-05, 9.5308e-05],\n",
      "        [8.8640e-02, 1.0559e-01, 1.2865e-01, 1.5248e-01, 1.4248e-01, 1.8097e-01,\n",
      "         2.0091e-01, 9.6479e-05, 9.6479e-05, 9.6479e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 157.00, Train Loss: 1.30, Val Loss: 12.82, Train BLEU: 56.30, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 它 可以 伸展 <UNK> 150 英尺 长 <EOS> <PAD> <PAD>\n",
      "Reference: it gets up to about 150 feet long .\n",
      "Model: <SOS> it gets up to about 150 feet long .\n",
      "Attention Weights: tensor([[2.6524e-01, 5.7016e-01, 1.5161e-01, 4.9675e-05, 2.8916e-05, 4.5615e-03,\n",
      "         7.1537e-03, 1.1912e-03, 6.0850e-10, 6.0850e-10],\n",
      "        [1.9023e-01, 5.1439e-01, 2.7816e-01, 3.5476e-04, 1.6014e-04, 5.7992e-03,\n",
      "         7.7410e-03, 3.1619e-03, 2.4293e-09, 2.4293e-09],\n",
      "        [1.1970e-01, 3.4500e-01, 4.4888e-01, 2.7730e-02, 8.7549e-03, 1.2529e-02,\n",
      "         1.4389e-02, 2.3022e-02, 3.2514e-07, 3.2514e-07],\n",
      "        [9.9327e-02, 2.6965e-01, 4.4567e-01, 8.5096e-02, 2.6788e-02, 1.7470e-02,\n",
      "         1.8822e-02, 3.7161e-02, 9.6746e-06, 9.6746e-06],\n",
      "        [9.7128e-02, 2.5991e-01, 4.4040e-01, 9.7222e-02, 2.9467e-02, 1.7780e-02,\n",
      "         1.9213e-02, 3.8839e-02, 2.1226e-05, 2.1226e-05],\n",
      "        [9.6226e-02, 2.5465e-01, 4.3695e-01, 1.0372e-01, 3.0572e-02, 1.8192e-02,\n",
      "         1.9747e-02, 3.9882e-02, 3.0069e-05, 3.0069e-05],\n",
      "        [9.5611e-02, 2.4943e-01, 4.2917e-01, 1.0937e-01, 3.2790e-02, 1.9694e-02,\n",
      "         2.1211e-02, 4.2652e-02, 3.6179e-05, 3.6179e-05],\n",
      "        [9.5538e-02, 2.4493e-01, 4.2394e-01, 1.1401e-01, 3.3678e-02, 2.0673e-02,\n",
      "         2.2195e-02, 4.4960e-02, 4.0582e-05, 4.0582e-05],\n",
      "        [9.4706e-02, 2.4213e-01, 4.2242e-01, 1.1687e-01, 3.4290e-02, 2.1063e-02,\n",
      "         2.2552e-02, 4.5889e-02, 4.2295e-05, 4.2295e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6 岁 那年 塔利 塔利班 占领 阿富汗 并 规定\n",
      "Reference: you see , i was six when the taliban\n",
      "Model: <SOS> the biodiversity the the <UNK> the the the the\n",
      "Attention Weights: tensor([[9.6915e-02, 2.2683e-01, 3.1280e-01, 1.8700e-01, 7.7554e-02, 5.4102e-02,\n",
      "         3.4940e-02, 9.6004e-03, 2.6202e-04, 1.0207e-10],\n",
      "        [1.0322e-01, 1.8798e-01, 2.7259e-01, 1.9887e-01, 9.1384e-02, 6.6304e-02,\n",
      "         4.9634e-02, 2.6200e-02, 3.8105e-03, 6.2819e-09],\n",
      "        [1.1685e-01, 1.5087e-01, 2.0521e-01, 1.8596e-01, 9.8824e-02, 7.0581e-02,\n",
      "         6.3687e-02, 6.7467e-02, 4.0553e-02, 1.6619e-06],\n",
      "        [1.1333e-01, 1.3030e-01, 1.7519e-01, 1.7700e-01, 9.8466e-02, 7.0100e-02,\n",
      "         6.8325e-02, 9.2230e-02, 7.5030e-02, 2.5358e-05],\n",
      "        [1.0537e-01, 1.2194e-01, 1.7095e-01, 1.7907e-01, 9.5712e-02, 6.7371e-02,\n",
      "         6.8257e-02, 1.0434e-01, 8.6936e-02, 4.8705e-05],\n",
      "        [1.0281e-01, 1.1994e-01, 1.6930e-01, 1.7841e-01, 9.5428e-02, 6.7463e-02,\n",
      "         6.8823e-02, 1.0763e-01, 9.0143e-02, 5.2431e-05],\n",
      "        [1.0071e-01, 1.1840e-01, 1.6666e-01, 1.7782e-01, 9.5948e-02, 6.8725e-02,\n",
      "         6.9735e-02, 1.0885e-01, 9.3105e-02, 4.8012e-05],\n",
      "        [1.0042e-01, 1.1794e-01, 1.6531e-01, 1.7709e-01, 9.6450e-02, 6.9475e-02,\n",
      "         7.0407e-02, 1.0915e-01, 9.3719e-02, 4.7872e-05],\n",
      "        [1.0055e-01, 1.1788e-01, 1.6472e-01, 1.7638e-01, 9.6643e-02, 6.9825e-02,\n",
      "         7.0770e-02, 1.0929e-01, 9.3893e-02, 4.8198e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 158.00, Train Loss: 1.28, Val Loss: 12.84, Train BLEU: 57.49, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克 泰坦尼克号 坦尼 尼克 号 是 拿 了 不少\n",
      "Reference: the truth of the matter is that the titanic\n",
      "Model: <SOS> the truth of the matter is the the the\n",
      "Attention Weights: tensor([[0.0169, 0.0080, 0.0118, 0.0184, 0.1263, 0.1397, 0.1685, 0.1831, 0.1819,\n",
      "         0.1455],\n",
      "        [0.0285, 0.0292, 0.0337, 0.0429, 0.1257, 0.1299, 0.1490, 0.1587, 0.1588,\n",
      "         0.1437],\n",
      "        [0.0618, 0.1256, 0.1088, 0.1090, 0.1011, 0.0922, 0.0964, 0.0991, 0.1001,\n",
      "         0.1058],\n",
      "        [0.0695, 0.1767, 0.1380, 0.1231, 0.0837, 0.0743, 0.0766, 0.0790, 0.0814,\n",
      "         0.0977],\n",
      "        [0.0745, 0.2146, 0.1572, 0.1285, 0.0708, 0.0626, 0.0644, 0.0670, 0.0699,\n",
      "         0.0906],\n",
      "        [0.0779, 0.2508, 0.1725, 0.1304, 0.0591, 0.0521, 0.0539, 0.0569, 0.0604,\n",
      "         0.0860],\n",
      "        [0.0785, 0.2547, 0.1720, 0.1284, 0.0578, 0.0512, 0.0533, 0.0566, 0.0604,\n",
      "         0.0870],\n",
      "        [0.0784, 0.2531, 0.1706, 0.1270, 0.0584, 0.0519, 0.0540, 0.0573, 0.0612,\n",
      "         0.0880],\n",
      "        [0.0783, 0.2516, 0.1698, 0.1270, 0.0588, 0.0522, 0.0544, 0.0578, 0.0616,\n",
      "         0.0884]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 但是 我 那 受过 教育 的 母亲 成为 为了 一名\n",
      "Reference: but my educated mother became a teacher . <EOS>\n",
      "Model: <SOS> and of the the and and the the the\n",
      "Attention Weights: tensor([[2.5430e-01, 5.7913e-01, 1.5520e-01, 4.3655e-05, 2.4738e-05, 3.9025e-03,\n",
      "         6.3093e-03, 1.0952e-03, 5.5662e-10, 5.5662e-10],\n",
      "        [1.8338e-01, 5.2499e-01, 2.7728e-01, 2.6316e-04, 1.1729e-04, 4.7408e-03,\n",
      "         6.5418e-03, 2.6860e-03, 2.0047e-09, 2.0047e-09],\n",
      "        [1.1687e-01, 3.5686e-01, 4.5540e-01, 2.1285e-02, 6.5195e-03, 1.0428e-02,\n",
      "         1.2339e-02, 2.0297e-02, 2.3316e-07, 2.3316e-07],\n",
      "        [9.8112e-02, 2.8136e-01, 4.6143e-01, 7.1622e-02, 2.1712e-02, 1.5067e-02,\n",
      "         1.6568e-02, 3.4114e-02, 6.5821e-06, 6.5821e-06],\n",
      "        [9.5662e-02, 2.7132e-01, 4.5809e-01, 8.2630e-02, 2.4097e-02, 1.5405e-02,\n",
      "         1.6972e-02, 3.5792e-02, 1.4263e-05, 1.4263e-05],\n",
      "        [9.4821e-02, 2.6556e-01, 4.5529e-01, 8.8665e-02, 2.5340e-02, 1.5871e-02,\n",
      "         1.7581e-02, 3.6827e-02, 2.0722e-05, 2.0722e-05],\n",
      "        [9.4255e-02, 2.6033e-01, 4.4896e-01, 9.3722e-02, 2.7197e-02, 1.7228e-02,\n",
      "         1.8928e-02, 3.9328e-02, 2.4463e-05, 2.4463e-05],\n",
      "        [9.4463e-02, 2.5500e-01, 4.4219e-01, 9.9248e-02, 2.8563e-02, 1.8396e-02,\n",
      "         2.0115e-02, 4.1967e-02, 2.8561e-05, 2.8561e-05],\n",
      "        [9.3829e-02, 2.5098e-01, 4.3919e-01, 1.0342e-01, 2.9473e-02, 1.8977e-02,\n",
      "         2.0656e-02, 4.3411e-02, 3.1269e-05, 3.1269e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 159.00, Train Loss: 1.26, Val Loss: 12.86, Train BLEU: 57.35, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 但 我 想 告诉 你 的 是 当 你 站\n",
      "Reference: but when you &apos;re standing at the beach ,\n",
      "Model: <SOS> but when you &apos;re standing , , , ,\n",
      "Attention Weights: tensor([[0.0408, 0.0803, 0.1105, 0.1349, 0.1353, 0.1363, 0.1229, 0.1056, 0.0844,\n",
      "         0.0491],\n",
      "        [0.0465, 0.0807, 0.1074, 0.1299, 0.1291, 0.1310, 0.1207, 0.1065, 0.0883,\n",
      "         0.0599],\n",
      "        [0.0644, 0.0839, 0.1010, 0.1167, 0.1151, 0.1174, 0.1125, 0.1058, 0.0972,\n",
      "         0.0861],\n",
      "        [0.0723, 0.0849, 0.0975, 0.1109, 0.1085, 0.1115, 0.1089, 0.1049, 0.1009,\n",
      "         0.0997],\n",
      "        [0.0707, 0.0816, 0.0940, 0.1094, 0.1065, 0.1106, 0.1094, 0.1063, 0.1040,\n",
      "         0.1074],\n",
      "        [0.0670, 0.0778, 0.0914, 0.1095, 0.1059, 0.1112, 0.1106, 0.1080, 0.1063,\n",
      "         0.1121],\n",
      "        [0.0668, 0.0775, 0.0911, 0.1095, 0.1060, 0.1114, 0.1108, 0.1082, 0.1064,\n",
      "         0.1124],\n",
      "        [0.0666, 0.0771, 0.0908, 0.1094, 0.1061, 0.1116, 0.1111, 0.1084, 0.1065,\n",
      "         0.1122],\n",
      "        [0.0667, 0.0772, 0.0909, 0.1094, 0.1062, 0.1117, 0.1112, 0.1085, 0.1065,\n",
      "         0.1117]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把 书 放在 食品 杂货 袋中 这样 别人 就\n",
      "Reference: we would cover our books in grocery bags so\n",
      "Model: <SOS> people &apos;s mostly &apos;re standing , , the the\n",
      "Attention Weights: tensor([[0.0437, 0.1340, 0.1473, 0.1323, 0.1317, 0.1088, 0.1017, 0.0937, 0.0749,\n",
      "         0.0320],\n",
      "        [0.0533, 0.1250, 0.1377, 0.1228, 0.1313, 0.1040, 0.0987, 0.1007, 0.0766,\n",
      "         0.0498],\n",
      "        [0.0849, 0.1208, 0.1181, 0.1051, 0.1162, 0.0928, 0.0907, 0.1001, 0.0809,\n",
      "         0.0905],\n",
      "        [0.0917, 0.1175, 0.1112, 0.0973, 0.1139, 0.0859, 0.0851, 0.1033, 0.0810,\n",
      "         0.1131],\n",
      "        [0.0865, 0.1150, 0.1092, 0.0929, 0.1168, 0.0801, 0.0796, 0.1084, 0.0788,\n",
      "         0.1325],\n",
      "        [0.0840, 0.1141, 0.1098, 0.0930, 0.1178, 0.0799, 0.0794, 0.1092, 0.0786,\n",
      "         0.1342],\n",
      "        [0.0834, 0.1137, 0.1100, 0.0932, 0.1180, 0.0801, 0.0796, 0.1094, 0.0788,\n",
      "         0.1338],\n",
      "        [0.0831, 0.1135, 0.1100, 0.0932, 0.1182, 0.0802, 0.0796, 0.1096, 0.0788,\n",
      "         0.1339],\n",
      "        [0.0828, 0.1134, 0.1101, 0.0933, 0.1183, 0.0802, 0.0797, 0.1097, 0.0788,\n",
      "         0.1338]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 160.00, Train Loss: 1.25, Val Loss: 12.87, Train BLEU: 59.69, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 和 我们 合作 的 人们 帮 我们 找到 了 新\n",
      "Reference: people that have partnered with us have given us\n",
      "Model: <SOS> people &apos;s have partnered standing us and , ,\n",
      "Attention Weights: tensor([[0.0346, 0.0853, 0.1350, 0.1289, 0.1301, 0.1407, 0.1273, 0.0972, 0.0773,\n",
      "         0.0436],\n",
      "        [0.0398, 0.0836, 0.1284, 0.1224, 0.1297, 0.1319, 0.1261, 0.1050, 0.0804,\n",
      "         0.0526],\n",
      "        [0.0608, 0.0881, 0.1180, 0.1119, 0.1177, 0.1139, 0.1143, 0.1085, 0.0888,\n",
      "         0.0780],\n",
      "        [0.0679, 0.0873, 0.1117, 0.1049, 0.1148, 0.1054, 0.1117, 0.1158, 0.0917,\n",
      "         0.0888],\n",
      "        [0.0654, 0.0831, 0.1094, 0.1020, 0.1162, 0.1022, 0.1130, 0.1226, 0.0926,\n",
      "         0.0936],\n",
      "        [0.0600, 0.0783, 0.1085, 0.0998, 0.1194, 0.1001, 0.1157, 0.1312, 0.0920,\n",
      "         0.0950],\n",
      "        [0.0600, 0.0779, 0.1081, 0.0993, 0.1197, 0.0998, 0.1159, 0.1325, 0.0919,\n",
      "         0.0949],\n",
      "        [0.0596, 0.0776, 0.1080, 0.0992, 0.1197, 0.0998, 0.1160, 0.1328, 0.0921,\n",
      "         0.0952],\n",
      "        [0.0588, 0.0768, 0.1080, 0.0994, 0.1202, 0.1002, 0.1164, 0.1334, 0.0920,\n",
      "         0.0948]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在 可以 去 个 真正 的 学校 念书 了\n",
      "Reference: &quot; you can go to a real school now\n",
      "Model: <SOS> people &apos;s have partnered standing , , , ,\n",
      "Attention Weights: tensor([[0.0154, 0.0069, 0.0098, 0.0157, 0.1187, 0.1362, 0.1698, 0.1884, 0.1899,\n",
      "         0.1493],\n",
      "        [0.0247, 0.0225, 0.0262, 0.0350, 0.1221, 0.1308, 0.1544, 0.1671, 0.1686,\n",
      "         0.1487],\n",
      "        [0.0556, 0.1006, 0.0890, 0.0941, 0.1073, 0.1014, 0.1087, 0.1133, 0.1146,\n",
      "         0.1152],\n",
      "        [0.0652, 0.1531, 0.1210, 0.1130, 0.0903, 0.0819, 0.0860, 0.0896, 0.0924,\n",
      "         0.1076],\n",
      "        [0.0722, 0.1983, 0.1452, 0.1219, 0.0750, 0.0673, 0.0701, 0.0735, 0.0770,\n",
      "         0.0994],\n",
      "        [0.0762, 0.2482, 0.1672, 0.1248, 0.0589, 0.0525, 0.0552, 0.0591, 0.0636,\n",
      "         0.0942],\n",
      "        [0.0763, 0.2560, 0.1680, 0.1225, 0.0568, 0.0508, 0.0537, 0.0581, 0.0630,\n",
      "         0.0948],\n",
      "        [0.0761, 0.2553, 0.1667, 0.1212, 0.0574, 0.0514, 0.0543, 0.0586, 0.0635,\n",
      "         0.0955],\n",
      "        [0.0760, 0.2542, 0.1660, 0.1211, 0.0577, 0.0517, 0.0546, 0.0590, 0.0639,\n",
      "         0.0958]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 161.00, Train Loss: 1.24, Val Loss: 12.88, Train BLEU: 60.92, Val BLEU: 0.30\n",
      "Sampling from training predictions...\n",
      "Source: 其实 它们 都 是 由 单独 的 动物 结合 合在\n",
      "Reference: these are all individual animals banding together to make\n",
      "Model: <SOS> these are all individual animals banding together together make\n",
      "Attention Weights: tensor([[4.0963e-02, 1.0989e-01, 1.3958e-01, 1.5093e-01, 1.6203e-01, 1.5913e-01,\n",
      "         1.4316e-01, 8.5203e-02, 9.1165e-03, 2.2038e-06],\n",
      "        [4.3182e-02, 1.0071e-01, 1.2686e-01, 1.3746e-01, 1.4778e-01, 1.5109e-01,\n",
      "         1.4444e-01, 1.1560e-01, 3.2802e-02, 7.7222e-05],\n",
      "        [5.2259e-02, 8.2089e-02, 9.6049e-02, 1.0373e-01, 1.1017e-01, 1.2481e-01,\n",
      "         1.1978e-01, 1.5143e-01, 1.4917e-01, 1.0528e-02],\n",
      "        [5.6236e-02, 7.3811e-02, 8.2638e-02, 8.8447e-02, 9.3106e-02, 1.1060e-01,\n",
      "         1.0546e-01, 1.5194e-01, 1.9686e-01, 4.0908e-02],\n",
      "        [5.3419e-02, 7.0617e-02, 7.9439e-02, 8.5350e-02, 9.0256e-02, 1.1008e-01,\n",
      "         1.0477e-01, 1.5740e-01, 2.0895e-01, 3.9721e-02],\n",
      "        [5.1577e-02, 6.8858e-02, 7.7988e-02, 8.4186e-02, 8.9287e-02, 1.1087e-01,\n",
      "         1.0460e-01, 1.6049e-01, 2.1257e-01, 3.9568e-02],\n",
      "        [5.1209e-02, 6.7910e-02, 7.7013e-02, 8.3417e-02, 8.8574e-02, 1.1087e-01,\n",
      "         1.0372e-01, 1.6095e-01, 2.1517e-01, 4.1160e-02],\n",
      "        [5.1189e-02, 6.7730e-02, 7.6769e-02, 8.3177e-02, 8.8336e-02, 1.1048e-01,\n",
      "         1.0342e-01, 1.6079e-01, 2.1579e-01, 4.2323e-02],\n",
      "        [5.0988e-02, 6.7415e-02, 7.6363e-02, 8.2691e-02, 8.7821e-02, 1.1035e-01,\n",
      "         1.0295e-01, 1.6142e-01, 2.1667e-01, 4.3332e-02]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 在 被 跟踪 吗 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: were we being followed ? <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a kind different working . <EOS> <EOS>\n",
      "Attention Weights: tensor([[8.2890e-02, 1.8440e-01, 2.8625e-01, 3.2024e-01, 1.0702e-01, 1.2631e-02,\n",
      "         9.8869e-06, 1.4524e-06, 2.5813e-03, 3.9662e-03],\n",
      "        [6.8018e-02, 1.4452e-01, 2.3136e-01, 3.0829e-01, 1.9499e-01, 4.3024e-02,\n",
      "         9.9872e-05, 1.5478e-05, 3.8900e-03, 5.7865e-03],\n",
      "        [5.6240e-02, 9.1460e-02, 1.3473e-01, 1.9692e-01, 3.0651e-01, 1.8617e-01,\n",
      "         6.6084e-03, 1.6888e-03, 8.5000e-03, 1.1181e-02],\n",
      "        [4.9803e-02, 6.9233e-02, 9.5178e-02, 1.3986e-01, 3.0497e-01, 2.7791e-01,\n",
      "         2.7831e-02, 8.8754e-03, 1.1865e-02, 1.4478e-02],\n",
      "        [4.4549e-02, 6.1055e-02, 8.4524e-02, 1.2810e-01, 3.1006e-01, 3.0293e-01,\n",
      "         3.3698e-02, 1.0795e-02, 1.0975e-02, 1.3309e-02],\n",
      "        [4.3423e-02, 5.8763e-02, 8.1291e-02, 1.2356e-01, 3.0574e-01, 3.1300e-01,\n",
      "         3.7512e-02, 1.2387e-02, 1.0978e-02, 1.3352e-02],\n",
      "        [4.2881e-02, 5.7533e-02, 7.9327e-02, 1.2047e-01, 3.0256e-01, 3.1652e-01,\n",
      "         4.1644e-02, 1.4263e-02, 1.1280e-02, 1.3515e-02],\n",
      "        [4.2516e-02, 5.7024e-02, 7.8637e-02, 1.1929e-01, 3.0152e-01, 3.1810e-01,\n",
      "         4.2822e-02, 1.4979e-02, 1.1470e-02, 1.3650e-02],\n",
      "        [4.3077e-02, 5.7483e-02, 7.8882e-02, 1.1902e-01, 2.9904e-01, 3.1858e-01,\n",
      "         4.2873e-02, 1.5064e-02, 1.1896e-02, 1.4087e-02]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 162.00, Train Loss: 1.23, Val Loss: 12.89, Train BLEU: 58.14, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 我们 用 的 是 深海 潜水 潜水艇 <UNK> 号 和\n",
      "Reference: we use the submarine alvin and we use cameras\n",
      "Model: <SOS> we use the submarine alvin and use cameras cameras\n",
      "Attention Weights: tensor([[8.5777e-02, 1.8412e-01, 2.8447e-01, 3.1770e-01, 1.0689e-01, 1.3435e-02,\n",
      "         1.3614e-05, 2.2110e-06, 3.0367e-03, 4.5590e-03],\n",
      "        [7.2041e-02, 1.4459e-01, 2.2772e-01, 3.0227e-01, 1.9539e-01, 4.5972e-02,\n",
      "         1.5282e-04, 2.6040e-05, 4.8605e-03, 6.9697e-03],\n",
      "        [5.8025e-02, 8.9167e-02, 1.2903e-01, 1.8842e-01, 3.0316e-01, 1.9547e-01,\n",
      "         1.0238e-02, 2.8618e-03, 1.0481e-02, 1.3135e-02],\n",
      "        [5.0311e-02, 6.6760e-02, 9.0373e-02, 1.3281e-01, 2.9520e-01, 2.8013e-01,\n",
      "         4.0323e-02, 1.4040e-02, 1.3876e-02, 1.6168e-02],\n",
      "        [4.4652e-02, 5.8359e-02, 7.9628e-02, 1.2105e-01, 2.9837e-01, 3.0431e-01,\n",
      "         4.8980e-02, 1.7219e-02, 1.2703e-02, 1.4731e-02],\n",
      "        [4.3601e-02, 5.6151e-02, 7.6242e-02, 1.1574e-01, 2.9198e-01, 3.1378e-01,\n",
      "         5.4537e-02, 2.0095e-02, 1.2880e-02, 1.4998e-02],\n",
      "        [4.2690e-02, 5.4626e-02, 7.3982e-02, 1.1225e-01, 2.8836e-01, 3.1652e-01,\n",
      "         6.0190e-02, 2.3173e-02, 1.3153e-02, 1.5065e-02],\n",
      "        [4.2603e-02, 5.4503e-02, 7.3730e-02, 1.1153e-01, 2.8760e-01, 3.1860e-01,\n",
      "         5.9562e-02, 2.3089e-02, 1.3435e-02, 1.5346e-02],\n",
      "        [4.3150e-02, 5.4713e-02, 7.3443e-02, 1.1053e-01, 2.8454e-01, 3.1870e-01,\n",
      "         6.1236e-02, 2.3887e-02, 1.3965e-02, 1.5833e-02]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 想 过 要 放弃 但 我 的 父亲 这时\n",
      "Reference: i would want to quit , but my father\n",
      "Model: <SOS> and of the &apos;re standing , , , ,\n",
      "Attention Weights: tensor([[0.0592, 0.1249, 0.1496, 0.1530, 0.1658, 0.1467, 0.1302, 0.0688, 0.0017,\n",
      "         0.0001],\n",
      "        [0.0609, 0.1178, 0.1424, 0.1446, 0.1583, 0.1419, 0.1333, 0.0939, 0.0065,\n",
      "         0.0006],\n",
      "        [0.0649, 0.1035, 0.1225, 0.1281, 0.1372, 0.1300, 0.1366, 0.1213, 0.0467,\n",
      "         0.0093],\n",
      "        [0.0596, 0.0738, 0.0830, 0.0917, 0.0940, 0.1028, 0.1279, 0.1333, 0.1704,\n",
      "         0.0636],\n",
      "        [0.0536, 0.0620, 0.0693, 0.0795, 0.0801, 0.0934, 0.1221, 0.1325, 0.2160,\n",
      "         0.0914],\n",
      "        [0.0459, 0.0539, 0.0615, 0.0735, 0.0744, 0.0906, 0.1235, 0.1387, 0.2434,\n",
      "         0.0947],\n",
      "        [0.0442, 0.0521, 0.0595, 0.0724, 0.0730, 0.0908, 0.1246, 0.1356, 0.2514,\n",
      "         0.0965],\n",
      "        [0.0435, 0.0511, 0.0580, 0.0710, 0.0713, 0.0897, 0.1242, 0.1316, 0.2601,\n",
      "         0.0995],\n",
      "        [0.0432, 0.0508, 0.0576, 0.0707, 0.0711, 0.0897, 0.1242, 0.1306, 0.2634,\n",
      "         0.0986]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 163.00, Train Loss: 1.20, Val Loss: 12.90, Train BLEU: 60.74, Val BLEU: 0.26\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数 多数 地震 和 火山 喷发 也 都 发生\n",
      "Reference: most of the earthquakes and volcanoes are in the\n",
      "Model: <SOS> most of the earthquakes and the the the the\n",
      "Attention Weights: tensor([[0.0412, 0.1004, 0.1654, 0.1684, 0.1436, 0.1346, 0.0889, 0.0697, 0.0570,\n",
      "         0.0309],\n",
      "        [0.0461, 0.1419, 0.1459, 0.1479, 0.1248, 0.1326, 0.0937, 0.0680, 0.0575,\n",
      "         0.0416],\n",
      "        [0.0729, 0.2088, 0.1188, 0.1140, 0.0965, 0.1183, 0.0892, 0.0630, 0.0588,\n",
      "         0.0596],\n",
      "        [0.0761, 0.2241, 0.1103, 0.1054, 0.0887, 0.1176, 0.0894, 0.0606, 0.0583,\n",
      "         0.0696],\n",
      "        [0.0709, 0.2411, 0.1059, 0.1022, 0.0841, 0.1209, 0.0891, 0.0558, 0.0548,\n",
      "         0.0753],\n",
      "        [0.0669, 0.2455, 0.1039, 0.1018, 0.0823, 0.1254, 0.0902, 0.0525, 0.0520,\n",
      "         0.0795],\n",
      "        [0.0653, 0.2453, 0.1032, 0.1024, 0.0826, 0.1268, 0.0906, 0.0521, 0.0516,\n",
      "         0.0800],\n",
      "        [0.0641, 0.2471, 0.1028, 0.1028, 0.0827, 0.1280, 0.0905, 0.0517, 0.0510,\n",
      "         0.0793],\n",
      "        [0.0640, 0.2462, 0.1026, 0.1029, 0.0828, 0.1285, 0.0907, 0.0517, 0.0510,\n",
      "         0.0796]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 都 知道 自己 正 冒 着 生命 的 危险\n",
      "Reference: we all knew we were risking our lives --\n",
      "Model: <SOS> part of the partnered , , , the ,\n",
      "Attention Weights: tensor([[0.0351, 0.1157, 0.1554, 0.1365, 0.1262, 0.1280, 0.1110, 0.0896, 0.0654,\n",
      "         0.0370],\n",
      "        [0.0390, 0.1069, 0.1523, 0.1274, 0.1257, 0.1209, 0.1139, 0.0943, 0.0745,\n",
      "         0.0450],\n",
      "        [0.0617, 0.1038, 0.1374, 0.1108, 0.1147, 0.1081, 0.1080, 0.0964, 0.0895,\n",
      "         0.0696],\n",
      "        [0.0680, 0.0989, 0.1336, 0.1014, 0.1114, 0.1006, 0.1078, 0.0999, 0.0987,\n",
      "         0.0796],\n",
      "        [0.0635, 0.0940, 0.1384, 0.0968, 0.1129, 0.0972, 0.1106, 0.1019, 0.1030,\n",
      "         0.0817],\n",
      "        [0.0594, 0.0904, 0.1427, 0.0933, 0.1145, 0.0944, 0.1132, 0.1038, 0.1066,\n",
      "         0.0818],\n",
      "        [0.0590, 0.0899, 0.1427, 0.0930, 0.1144, 0.0941, 0.1134, 0.1042, 0.1073,\n",
      "         0.0820],\n",
      "        [0.0583, 0.0896, 0.1441, 0.0928, 0.1146, 0.0940, 0.1137, 0.1043, 0.1073,\n",
      "         0.0812],\n",
      "        [0.0580, 0.0895, 0.1443, 0.0929, 0.1147, 0.0941, 0.1138, 0.1045, 0.1074,\n",
      "         0.0808]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 164.00, Train Loss: 1.18, Val Loss: 12.91, Train BLEU: 60.88, Val BLEU: 0.26\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数 多数 地震 和 火山 喷发 也 都 发生\n",
      "Reference: most of the earthquakes and volcanoes are in the\n",
      "Model: <SOS> most of the earthquakes and the the the the\n",
      "Attention Weights: tensor([[0.0423, 0.1060, 0.1665, 0.1683, 0.1402, 0.1365, 0.0890, 0.0675, 0.0537,\n",
      "         0.0300],\n",
      "        [0.0471, 0.1486, 0.1466, 0.1474, 0.1218, 0.1337, 0.0937, 0.0659, 0.0545,\n",
      "         0.0407],\n",
      "        [0.0743, 0.2170, 0.1190, 0.1128, 0.0942, 0.1176, 0.0885, 0.0613, 0.0566,\n",
      "         0.0587],\n",
      "        [0.0774, 0.2324, 0.1106, 0.1043, 0.0866, 0.1165, 0.0887, 0.0590, 0.0564,\n",
      "         0.0681],\n",
      "        [0.0719, 0.2513, 0.1062, 0.1009, 0.0816, 0.1196, 0.0885, 0.0540, 0.0528,\n",
      "         0.0733],\n",
      "        [0.0678, 0.2565, 0.1041, 0.1005, 0.0796, 0.1239, 0.0897, 0.0507, 0.0500,\n",
      "         0.0772],\n",
      "        [0.0662, 0.2566, 0.1034, 0.1011, 0.0799, 0.1252, 0.0902, 0.0503, 0.0495,\n",
      "         0.0775],\n",
      "        [0.0651, 0.2585, 0.1029, 0.1014, 0.0799, 0.1263, 0.0901, 0.0499, 0.0490,\n",
      "         0.0769],\n",
      "        [0.0650, 0.2573, 0.1027, 0.1016, 0.0801, 0.1269, 0.0904, 0.0499, 0.0490,\n",
      "         0.0772]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 这 是 我们 俩 人 唯一 的 受教 教育 方式\n",
      "Reference: it was the only way we both could be\n",
      "Model: <SOS> we we have the to and the the the\n",
      "Attention Weights: tensor([[0.0334, 0.0705, 0.1035, 0.1279, 0.1678, 0.1501, 0.1247, 0.1044, 0.0795,\n",
      "         0.0382],\n",
      "        [0.0388, 0.0715, 0.1003, 0.1210, 0.1662, 0.1393, 0.1265, 0.1027, 0.0813,\n",
      "         0.0524],\n",
      "        [0.0591, 0.0793, 0.0977, 0.1112, 0.1420, 0.1180, 0.1153, 0.0993, 0.0892,\n",
      "         0.0891],\n",
      "        [0.0657, 0.0792, 0.0927, 0.1038, 0.1377, 0.1074, 0.1133, 0.0958, 0.0906,\n",
      "         0.1138],\n",
      "        [0.0601, 0.0717, 0.0856, 0.0983, 0.1448, 0.1025, 0.1165, 0.0936, 0.0908,\n",
      "         0.1362],\n",
      "        [0.0564, 0.0673, 0.0815, 0.0949, 0.1494, 0.1003, 0.1186, 0.0923, 0.0902,\n",
      "         0.1491],\n",
      "        [0.0559, 0.0667, 0.0809, 0.0945, 0.1504, 0.1004, 0.1189, 0.0923, 0.0900,\n",
      "         0.1501],\n",
      "        [0.0559, 0.0664, 0.0806, 0.0941, 0.1513, 0.1000, 0.1190, 0.0919, 0.0896,\n",
      "         0.1512],\n",
      "        [0.0557, 0.0662, 0.0805, 0.0941, 0.1516, 0.1000, 0.1192, 0.0918, 0.0895,\n",
      "         0.1514]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 165.00, Train Loss: 1.17, Val Loss: 12.92, Train BLEU: 61.73, Val BLEU: 0.28\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这 有 不少 精彩 的 泰坦 泰坦尼克 坦尼 尼克\n",
      "Reference: we &apos;ve got some of the most incredible video\n",
      "Model: <SOS> we &apos;ve got some the the most incredible incredible\n",
      "Attention Weights: tensor([[0.0397, 0.0921, 0.1799, 0.2766, 0.2070, 0.1490, 0.0493, 0.0024, 0.0009,\n",
      "         0.0032],\n",
      "        [0.0446, 0.0868, 0.1542, 0.2352, 0.1944, 0.1603, 0.0880, 0.0183, 0.0070,\n",
      "         0.0112],\n",
      "        [0.0497, 0.0670, 0.0950, 0.1370, 0.1459, 0.1300, 0.1452, 0.1339, 0.0625,\n",
      "         0.0337],\n",
      "        [0.0440, 0.0532, 0.0721, 0.1073, 0.1252, 0.1122, 0.1562, 0.2016, 0.0918,\n",
      "         0.0364],\n",
      "        [0.0388, 0.0468, 0.0649, 0.1011, 0.1222, 0.1091, 0.1628, 0.2285, 0.0939,\n",
      "         0.0320],\n",
      "        [0.0371, 0.0447, 0.0622, 0.0982, 0.1202, 0.1073, 0.1644, 0.2403, 0.0950,\n",
      "         0.0306],\n",
      "        [0.0358, 0.0431, 0.0604, 0.0968, 0.1197, 0.1066, 0.1667, 0.2468, 0.0950,\n",
      "         0.0293],\n",
      "        [0.0329, 0.0398, 0.0574, 0.0951, 0.1198, 0.1067, 0.1718, 0.2569, 0.0936,\n",
      "         0.0260],\n",
      "        [0.0317, 0.0384, 0.0561, 0.0945, 0.1199, 0.1065, 0.1745, 0.2633, 0.0907,\n",
      "         0.0244]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 很 害怕 但是 我们 仍然 渴望 望去 学校 <EOS>\n",
      "Reference: we were scared , but still , school was\n",
      "Model: <SOS> it &apos;s all those planet dangling . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0349, 0.0877, 0.1414, 0.1278, 0.1303, 0.1354, 0.1242, 0.1017, 0.0748,\n",
      "         0.0417],\n",
      "        [0.0411, 0.0862, 0.1326, 0.1208, 0.1296, 0.1266, 0.1244, 0.1105, 0.0780,\n",
      "         0.0502],\n",
      "        [0.0626, 0.0895, 0.1200, 0.1110, 0.1173, 0.1119, 0.1133, 0.1130, 0.0862,\n",
      "         0.0752],\n",
      "        [0.0700, 0.0887, 0.1133, 0.1046, 0.1137, 0.1046, 0.1109, 0.1193, 0.0892,\n",
      "         0.0856],\n",
      "        [0.0673, 0.0842, 0.1110, 0.1014, 0.1147, 0.1013, 0.1123, 0.1272, 0.0899,\n",
      "         0.0906],\n",
      "        [0.0621, 0.0790, 0.1097, 0.0983, 0.1171, 0.0983, 0.1149, 0.1380, 0.0894,\n",
      "         0.0931],\n",
      "        [0.0619, 0.0785, 0.1092, 0.0977, 0.1174, 0.0979, 0.1153, 0.1397, 0.0894,\n",
      "         0.0930],\n",
      "        [0.0616, 0.0782, 0.1091, 0.0977, 0.1175, 0.0979, 0.1153, 0.1401, 0.0895,\n",
      "         0.0932],\n",
      "        [0.0611, 0.0776, 0.1091, 0.0976, 0.1176, 0.0979, 0.1156, 0.1412, 0.0894,\n",
      "         0.0929]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 166.00, Train Loss: 1.15, Val Loss: 12.92, Train BLEU: 64.67, Val BLEU: 0.29\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 里 生物 的 多样 多样性 和 密度 要 比\n",
      "Reference: the biodiversity and the <UNK> in the ocean is\n",
      "Model: <SOS> the biodiversity the the <UNK> the the the the\n",
      "Attention Weights: tensor([[0.0553, 0.1196, 0.2003, 0.1602, 0.1108, 0.0056, 0.0944, 0.1031, 0.0878,\n",
      "         0.0628],\n",
      "        [0.0551, 0.0929, 0.1485, 0.1290, 0.1223, 0.0333, 0.1185, 0.1185, 0.1016,\n",
      "         0.0804],\n",
      "        [0.0690, 0.0791, 0.1138, 0.1083, 0.1441, 0.1539, 0.0928, 0.0852, 0.0783,\n",
      "         0.0755],\n",
      "        [0.0643, 0.0688, 0.1007, 0.1004, 0.1531, 0.2241, 0.0788, 0.0714, 0.0677,\n",
      "         0.0707],\n",
      "        [0.0575, 0.0603, 0.0928, 0.0956, 0.1663, 0.2864, 0.0643, 0.0582, 0.0563,\n",
      "         0.0623],\n",
      "        [0.0510, 0.0524, 0.0866, 0.0921, 0.1830, 0.3474, 0.0482, 0.0439, 0.0435,\n",
      "         0.0518],\n",
      "        [0.0487, 0.0502, 0.0841, 0.0900, 0.1858, 0.3647, 0.0453, 0.0413, 0.0409,\n",
      "         0.0488],\n",
      "        [0.0484, 0.0502, 0.0843, 0.0901, 0.1866, 0.3648, 0.0450, 0.0411, 0.0407,\n",
      "         0.0486],\n",
      "        [0.0486, 0.0504, 0.0846, 0.0904, 0.1865, 0.3640, 0.0450, 0.0411, 0.0407,\n",
      "         0.0486]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在 可以 去 个 真正 的 学校 念书 了\n",
      "Reference: &quot; you can go to a real school now\n",
      "Model: <SOS> people when have partnered standing , , , ,\n",
      "Attention Weights: tensor([[0.0160, 0.0075, 0.0099, 0.0162, 0.1209, 0.1329, 0.1699, 0.1892, 0.1908,\n",
      "         0.1465],\n",
      "        [0.0237, 0.0215, 0.0243, 0.0353, 0.1266, 0.1306, 0.1565, 0.1683, 0.1680,\n",
      "         0.1452],\n",
      "        [0.0542, 0.0994, 0.0886, 0.1005, 0.1124, 0.1012, 0.1082, 0.1114, 0.1118,\n",
      "         0.1122],\n",
      "        [0.0631, 0.1562, 0.1233, 0.1239, 0.0936, 0.0805, 0.0839, 0.0862, 0.0882,\n",
      "         0.1012],\n",
      "        [0.0699, 0.2084, 0.1518, 0.1358, 0.0763, 0.0644, 0.0662, 0.0680, 0.0705,\n",
      "         0.0888],\n",
      "        [0.0751, 0.2793, 0.1833, 0.1424, 0.0537, 0.0442, 0.0457, 0.0482, 0.0516,\n",
      "         0.0764],\n",
      "        [0.0754, 0.2932, 0.1867, 0.1396, 0.0504, 0.0415, 0.0430, 0.0458, 0.0494,\n",
      "         0.0749],\n",
      "        [0.0752, 0.2957, 0.1865, 0.1381, 0.0504, 0.0416, 0.0429, 0.0456, 0.0493,\n",
      "         0.0747],\n",
      "        [0.0749, 0.2961, 0.1861, 0.1379, 0.0506, 0.0417, 0.0430, 0.0457, 0.0493,\n",
      "         0.0747]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 167.00, Train Loss: 1.14, Val Loss: 12.92, Train BLEU: 64.53, Val BLEU: 0.26\n",
      "Sampling from training predictions...\n",
      "Source: 我 真 喜欢 这些 东西 <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: i love that kind of stuff . <EOS> <PAD>\n",
      "Model: <SOS> i &apos;s a kind jelly stuff . <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.3282e-01, 2.4329e-01, 2.9682e-01, 2.4963e-01, 7.5929e-02, 1.5086e-03,\n",
      "         1.2910e-09, 1.2910e-09, 1.2910e-09, 1.2910e-09],\n",
      "        [1.3461e-01, 2.1117e-01, 2.5664e-01, 2.4609e-01, 1.3678e-01, 1.4722e-02,\n",
      "         1.6392e-08, 1.6392e-08, 1.6392e-08, 1.6392e-08],\n",
      "        [1.1026e-01, 1.4294e-01, 1.7795e-01, 2.0917e-01, 2.3455e-01, 1.2512e-01,\n",
      "         1.0500e-06, 1.0500e-06, 1.0500e-06, 1.0500e-06],\n",
      "        [9.7230e-02, 1.1516e-01, 1.4113e-01, 1.7599e-01, 2.5525e-01, 2.1516e-01,\n",
      "         2.0672e-05, 2.0672e-05, 2.0672e-05, 2.0672e-05],\n",
      "        [8.5308e-02, 1.0064e-01, 1.2558e-01, 1.6605e-01, 2.7367e-01, 2.4850e-01,\n",
      "         6.2827e-05, 6.2827e-05, 6.2827e-05, 6.2827e-05],\n",
      "        [8.2913e-02, 9.7478e-02, 1.2190e-01, 1.6309e-01, 2.7637e-01, 2.5793e-01,\n",
      "         8.0659e-05, 8.0659e-05, 8.0659e-05, 8.0659e-05],\n",
      "        [8.2589e-02, 9.6471e-02, 1.1982e-01, 1.6020e-01, 2.7456e-01, 2.6603e-01,\n",
      "         8.4287e-05, 8.4287e-05, 8.4287e-05, 8.4287e-05],\n",
      "        [8.3411e-02, 9.7101e-02, 1.1904e-01, 1.5761e-01, 2.6688e-01, 2.7560e-01,\n",
      "         8.8569e-05, 8.8569e-05, 8.8569e-05, 8.8569e-05],\n",
      "        [8.4477e-02, 9.8187e-02, 1.2020e-01, 1.5858e-01, 2.6515e-01, 2.7304e-01,\n",
      "         9.1022e-05, 9.1022e-05, 9.1022e-05, 9.1022e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很 舒服 但 夏天 却 <UNK> <EOS> <PAD> <PAD>\n",
      "Reference: it was cozy in winter but extremely hot in\n",
      "Model: <SOS> life in the deep deep <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0552, 0.1199, 0.2102, 0.1698, 0.1124, 0.0051, 0.0861, 0.0965, 0.0840,\n",
      "         0.0607],\n",
      "        [0.0548, 0.0932, 0.1557, 0.1369, 0.1283, 0.0325, 0.1100, 0.1126, 0.0980,\n",
      "         0.0781],\n",
      "        [0.0678, 0.0777, 0.1168, 0.1123, 0.1542, 0.1587, 0.0864, 0.0800, 0.0740,\n",
      "         0.0722],\n",
      "        [0.0627, 0.0669, 0.1021, 0.1026, 0.1624, 0.2318, 0.0736, 0.0670, 0.0637,\n",
      "         0.0672],\n",
      "        [0.0557, 0.0581, 0.0931, 0.0968, 0.1754, 0.2955, 0.0598, 0.0544, 0.0526,\n",
      "         0.0586],\n",
      "        [0.0490, 0.0502, 0.0865, 0.0928, 0.1919, 0.3565, 0.0442, 0.0405, 0.0402,\n",
      "         0.0481],\n",
      "        [0.0470, 0.0483, 0.0839, 0.0908, 0.1941, 0.3729, 0.0416, 0.0381, 0.0379,\n",
      "         0.0454],\n",
      "        [0.0468, 0.0483, 0.0842, 0.0910, 0.1949, 0.3724, 0.0414, 0.0380, 0.0377,\n",
      "         0.0453],\n",
      "        [0.0471, 0.0486, 0.0846, 0.0914, 0.1949, 0.3708, 0.0414, 0.0381, 0.0378,\n",
      "         0.0453]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 168.00, Train Loss: 1.12, Val Loss: 12.93, Train BLEU: 63.49, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 是 我 最 喜欢 的 因为 它 哪 都 能动\n",
      "Reference: it &apos;s one of my favorites , because it\n",
      "Model: <SOS> it &apos;s one of my favorites , because because\n",
      "Attention Weights: tensor([[0.0488, 0.0933, 0.1339, 0.1596, 0.1651, 0.1416, 0.1178, 0.0857, 0.0509,\n",
      "         0.0033],\n",
      "        [0.0557, 0.0916, 0.1261, 0.1493, 0.1526, 0.1412, 0.1161, 0.0898, 0.0641,\n",
      "         0.0135],\n",
      "        [0.0700, 0.0856, 0.1038, 0.1207, 0.1209, 0.1231, 0.1030, 0.0924, 0.0876,\n",
      "         0.0930],\n",
      "        [0.0722, 0.0804, 0.0932, 0.1079, 0.1074, 0.1168, 0.0962, 0.0913, 0.0964,\n",
      "         0.1382],\n",
      "        [0.0666, 0.0740, 0.0867, 0.1022, 0.1020, 0.1159, 0.0941, 0.0914, 0.1025,\n",
      "         0.1646],\n",
      "        [0.0618, 0.0683, 0.0809, 0.0969, 0.0969, 0.1157, 0.0917, 0.0901, 0.1050,\n",
      "         0.1926],\n",
      "        [0.0615, 0.0670, 0.0791, 0.0950, 0.0951, 0.1149, 0.0904, 0.0888, 0.1036,\n",
      "         0.2047],\n",
      "        [0.0610, 0.0664, 0.0782, 0.0937, 0.0940, 0.1140, 0.0899, 0.0882, 0.1024,\n",
      "         0.2123],\n",
      "        [0.0607, 0.0661, 0.0779, 0.0933, 0.0936, 0.1138, 0.0896, 0.0879, 0.1021,\n",
      "         0.2149]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 这 是 我们 俩 人 唯一 的 受教 教育 方式\n",
      "Reference: it was the only way we both could be\n",
      "Model: <SOS> we we the the and and the the the\n",
      "Attention Weights: tensor([[0.0317, 0.0649, 0.0979, 0.1259, 0.1863, 0.1492, 0.1296, 0.1009, 0.0759,\n",
      "         0.0376],\n",
      "        [0.0372, 0.0661, 0.0949, 0.1189, 0.1848, 0.1384, 0.1316, 0.0988, 0.0771,\n",
      "         0.0523],\n",
      "        [0.0574, 0.0737, 0.0917, 0.1075, 0.1552, 0.1147, 0.1192, 0.0956, 0.0862,\n",
      "         0.0988],\n",
      "        [0.0638, 0.0737, 0.0872, 0.1001, 0.1487, 0.1037, 0.1163, 0.0918, 0.0875,\n",
      "         0.1273],\n",
      "        [0.0573, 0.0653, 0.0789, 0.0930, 0.1584, 0.0977, 0.1199, 0.0883, 0.0863,\n",
      "         0.1550],\n",
      "        [0.0552, 0.0621, 0.0756, 0.0899, 0.1618, 0.0960, 0.1214, 0.0870, 0.0853,\n",
      "         0.1657],\n",
      "        [0.0552, 0.0619, 0.0752, 0.0894, 0.1623, 0.0958, 0.1215, 0.0869, 0.0851,\n",
      "         0.1668],\n",
      "        [0.0551, 0.0617, 0.0749, 0.0891, 0.1629, 0.0955, 0.1216, 0.0867, 0.0849,\n",
      "         0.1676],\n",
      "        [0.0548, 0.0615, 0.0748, 0.0890, 0.1633, 0.0955, 0.1218, 0.0866, 0.0849,\n",
      "         0.1678]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 169.00, Train Loss: 1.10, Val Loss: 12.93, Train BLEU: 63.75, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 其实 它们 都 是 由 单独 的 动物 结合 合在\n",
      "Reference: these are all individual animals banding together to make\n",
      "Model: <SOS> these are all individual animals banding together make make\n",
      "Attention Weights: tensor([[4.3535e-02, 1.0881e-01, 1.3455e-01, 1.4521e-01, 1.5599e-01, 1.6555e-01,\n",
      "         1.4316e-01, 9.0952e-02, 1.2228e-02, 6.6016e-06],\n",
      "        [4.6908e-02, 9.5859e-02, 1.1631e-01, 1.2628e-01, 1.3612e-01, 1.5382e-01,\n",
      "         1.3944e-01, 1.3171e-01, 5.3198e-02, 3.6240e-04],\n",
      "        [4.8980e-02, 6.6226e-02, 7.5058e-02, 8.1397e-02, 8.6975e-02, 1.1057e-01,\n",
      "         1.0415e-01, 1.6938e-01, 2.2333e-01, 3.3934e-02],\n",
      "        [5.0543e-02, 5.9481e-02, 6.5253e-02, 7.0082e-02, 7.4132e-02, 9.4701e-02,\n",
      "         8.9919e-02, 1.5686e-01, 2.4972e-01, 8.9307e-02],\n",
      "        [4.8856e-02, 5.7717e-02, 6.3586e-02, 6.8459e-02, 7.2593e-02, 9.4375e-02,\n",
      "         8.9767e-02, 1.5934e-01, 2.5483e-01, 9.0479e-02],\n",
      "        [4.7882e-02, 5.6536e-02, 6.2662e-02, 6.7677e-02, 7.1893e-02, 9.4639e-02,\n",
      "         8.9550e-02, 1.6069e-01, 2.5516e-01, 9.3311e-02],\n",
      "        [4.7802e-02, 5.6025e-02, 6.2116e-02, 6.7142e-02, 7.1300e-02, 9.4132e-02,\n",
      "         8.8669e-02, 1.6058e-01, 2.5610e-01, 9.6138e-02],\n",
      "        [4.7782e-02, 5.5882e-02, 6.1867e-02, 6.6806e-02, 7.0899e-02, 9.3508e-02,\n",
      "         8.8017e-02, 1.6070e-01, 2.5657e-01, 9.7961e-02],\n",
      "        [4.7335e-02, 5.5347e-02, 6.1224e-02, 6.6054e-02, 7.0060e-02, 9.2926e-02,\n",
      "         8.6952e-02, 1.6157e-01, 2.5858e-01, 9.9953e-02]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 一个 真正 的 学校 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: a real school . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> here &apos;s a kind different . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0485, 0.1140, 0.1965, 0.1270, 0.1425, 0.1693, 0.1014, 0.0665, 0.0341,\n",
      "         0.0003],\n",
      "        [0.0625, 0.1037, 0.1696, 0.1131, 0.1236, 0.1686, 0.1101, 0.0829, 0.0537,\n",
      "         0.0121],\n",
      "        [0.0717, 0.0874, 0.1379, 0.0873, 0.0949, 0.1666, 0.1120, 0.0933, 0.0713,\n",
      "         0.0776],\n",
      "        [0.0702, 0.0831, 0.1333, 0.0826, 0.0901, 0.1685, 0.1114, 0.0934, 0.0723,\n",
      "         0.0951],\n",
      "        [0.0662, 0.0793, 0.1333, 0.0796, 0.0875, 0.1750, 0.1126, 0.0939, 0.0725,\n",
      "         0.1000],\n",
      "        [0.0652, 0.0778, 0.1320, 0.0782, 0.0864, 0.1762, 0.1135, 0.0942, 0.0726,\n",
      "         0.1039],\n",
      "        [0.0649, 0.0773, 0.1317, 0.0780, 0.0861, 0.1779, 0.1144, 0.0947, 0.0725,\n",
      "         0.1025],\n",
      "        [0.0647, 0.0769, 0.1316, 0.0773, 0.0855, 0.1794, 0.1147, 0.0948, 0.0723,\n",
      "         0.1028],\n",
      "        [0.0645, 0.0769, 0.1321, 0.0773, 0.0856, 0.1803, 0.1149, 0.0947, 0.0720,\n",
      "         0.1018]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 170.00, Train Loss: 1.09, Val Loss: 12.94, Train BLEU: 66.51, Val BLEU: 0.39\n",
      "Sampling from training predictions...\n",
      "Source: 看到 这些 在 动 的 东西 了 吗 <EOS> <PAD>\n",
      "Reference: but see all those different working things ? <EOS>\n",
      "Model: <SOS> but see all those different working things <EOS> <EOS>\n",
      "Attention Weights: tensor([[9.9780e-02, 1.8621e-01, 1.8608e-01, 1.7073e-01, 1.4850e-01, 1.0278e-01,\n",
      "         7.0350e-02, 3.2343e-02, 3.2200e-03, 3.0652e-10],\n",
      "        [1.0589e-01, 1.7083e-01, 1.7271e-01, 1.6163e-01, 1.4508e-01, 1.1055e-01,\n",
      "         7.8315e-02, 4.4598e-02, 1.0405e-02, 1.8786e-09],\n",
      "        [1.0993e-01, 1.3065e-01, 1.3523e-01, 1.3142e-01, 1.2590e-01, 1.2225e-01,\n",
      "         9.0554e-02, 7.5459e-02, 7.8603e-02, 6.0831e-07],\n",
      "        [1.0770e-01, 1.1337e-01, 1.1693e-01, 1.1550e-01, 1.1336e-01, 1.2134e-01,\n",
      "         9.2638e-02, 8.8814e-02, 1.3033e-01, 1.7306e-05],\n",
      "        [9.8882e-02, 1.0300e-01, 1.0690e-01, 1.0659e-01, 1.0620e-01, 1.2365e-01,\n",
      "         9.4061e-02, 9.6339e-02, 1.6431e-01, 7.1816e-05],\n",
      "        [9.5390e-02, 9.9484e-02, 1.0351e-01, 1.0343e-01, 1.0354e-01, 1.2437e-01,\n",
      "         9.4125e-02, 9.8437e-02, 1.7760e-01, 1.1488e-04],\n",
      "        [9.4095e-02, 9.7938e-02, 1.0191e-01, 1.0187e-01, 1.0213e-01, 1.2356e-01,\n",
      "         9.4020e-02, 9.8462e-02, 1.8588e-01, 1.3341e-04],\n",
      "        [9.1927e-02, 9.6489e-02, 1.0047e-01, 1.0070e-01, 1.0119e-01, 1.2247e-01,\n",
      "         9.4158e-02, 9.7993e-02, 1.9447e-01, 1.2665e-04],\n",
      "        [9.1121e-02, 9.5706e-02, 9.9646e-02, 1.0008e-01, 1.0082e-01, 1.2237e-01,\n",
      "         9.4519e-02, 9.8107e-02, 1.9750e-01, 1.2308e-04]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 出身 阿富汗 边远 <UNK> 地区 有着 与 他人 不同\n",
      "Reference: a total maverick from a remote province of afghanistan\n",
      "Model: <SOS> it &apos;s the the and and the the the\n",
      "Attention Weights: tensor([[8.6117e-02, 1.8839e-01, 3.3263e-01, 3.0161e-01, 4.1256e-03, 2.7810e-02,\n",
      "         2.9302e-02, 2.2957e-02, 7.0614e-03, 4.0458e-10],\n",
      "        [7.4728e-02, 1.4039e-01, 2.4400e-01, 3.7245e-01, 2.8527e-02, 4.1212e-02,\n",
      "         4.1091e-02, 3.5303e-02, 2.2300e-02, 4.1159e-09],\n",
      "        [5.5294e-02, 7.6711e-02, 1.2496e-01, 3.3856e-01, 2.0690e-01, 4.3955e-02,\n",
      "         4.0101e-02, 4.5731e-02, 6.7785e-02, 5.9734e-07],\n",
      "        [4.6012e-02, 5.7247e-02, 9.1617e-02, 2.9025e-01, 3.1590e-01, 3.9497e-02,\n",
      "         3.4964e-02, 4.3554e-02, 8.0951e-02, 1.4623e-05],\n",
      "        [3.8323e-02, 4.8047e-02, 8.2641e-02, 2.9644e-01, 3.6335e-01, 3.0084e-02,\n",
      "         2.7088e-02, 3.6240e-02, 7.7759e-02, 3.9414e-05],\n",
      "        [3.7291e-02, 4.6602e-02, 8.0381e-02, 2.8960e-01, 3.7638e-01, 2.8764e-02,\n",
      "         2.5893e-02, 3.5440e-02, 7.9588e-02, 6.3754e-05],\n",
      "        [3.6781e-02, 4.5255e-02, 7.6564e-02, 2.8183e-01, 3.8761e-01, 2.9354e-02,\n",
      "         2.6037e-02, 3.4943e-02, 8.1549e-02, 7.3228e-05],\n",
      "        [3.7674e-02, 4.5936e-02, 7.6397e-02, 2.7817e-01, 3.8254e-01, 3.0511e-02,\n",
      "         2.7164e-02, 3.6000e-02, 8.5524e-02, 8.5465e-05],\n",
      "        [3.7287e-02, 4.5472e-02, 7.5651e-02, 2.7845e-01, 3.8377e-01, 3.0398e-02,\n",
      "         2.7211e-02, 3.6005e-02, 8.5675e-02, 8.1495e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 171.00, Train Loss: 1.07, Val Loss: 12.96, Train BLEU: 65.57, Val BLEU: 0.38\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数 多数 地震 和 火山 喷发 也 都 发生\n",
      "Reference: most of the earthquakes and volcanoes are in the\n",
      "Model: <SOS> most of the earthquakes and volcanoes the the the\n",
      "Attention Weights: tensor([[0.0452, 0.1422, 0.1754, 0.1716, 0.1292, 0.1405, 0.0817, 0.0514, 0.0393,\n",
      "         0.0235],\n",
      "        [0.0488, 0.2005, 0.1490, 0.1467, 0.1100, 0.1367, 0.0858, 0.0506, 0.0402,\n",
      "         0.0318],\n",
      "        [0.0764, 0.2843, 0.1155, 0.1061, 0.0818, 0.1164, 0.0803, 0.0476, 0.0431,\n",
      "         0.0484],\n",
      "        [0.0788, 0.3019, 0.1069, 0.0967, 0.0745, 0.1148, 0.0803, 0.0465, 0.0436,\n",
      "         0.0561],\n",
      "        [0.0724, 0.3232, 0.1016, 0.0930, 0.0697, 0.1182, 0.0803, 0.0425, 0.0405,\n",
      "         0.0586],\n",
      "        [0.0690, 0.3243, 0.0989, 0.0932, 0.0683, 0.1242, 0.0828, 0.0401, 0.0384,\n",
      "         0.0609],\n",
      "        [0.0676, 0.3213, 0.0985, 0.0940, 0.0688, 0.1262, 0.0840, 0.0400, 0.0383,\n",
      "         0.0614],\n",
      "        [0.0666, 0.3215, 0.0983, 0.0942, 0.0686, 0.1276, 0.0843, 0.0398, 0.0379,\n",
      "         0.0611],\n",
      "        [0.0665, 0.3188, 0.0984, 0.0946, 0.0690, 0.1283, 0.0848, 0.0400, 0.0380,\n",
      "         0.0615]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很 舒服 但 夏天 却 <UNK> <EOS> <PAD> <PAD>\n",
      "Reference: it was cozy in winter but extremely hot in\n",
      "Model: <SOS> life in the deep deep <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0590, 0.1229, 0.2118, 0.1636, 0.1281, 0.0065, 0.0833, 0.0934, 0.0763,\n",
      "         0.0552],\n",
      "        [0.0583, 0.0932, 0.1539, 0.1298, 0.1422, 0.0440, 0.1079, 0.1093, 0.0900,\n",
      "         0.0714],\n",
      "        [0.0674, 0.0731, 0.1097, 0.1033, 0.1602, 0.2076, 0.0792, 0.0718, 0.0646,\n",
      "         0.0631],\n",
      "        [0.0604, 0.0614, 0.0926, 0.0919, 0.1603, 0.2930, 0.0674, 0.0599, 0.0554,\n",
      "         0.0577],\n",
      "        [0.0527, 0.0524, 0.0813, 0.0832, 0.1642, 0.3684, 0.0545, 0.0485, 0.0455,\n",
      "         0.0494],\n",
      "        [0.0463, 0.0449, 0.0738, 0.0773, 0.1713, 0.4363, 0.0402, 0.0358, 0.0344,\n",
      "         0.0397],\n",
      "        [0.0452, 0.0439, 0.0727, 0.0767, 0.1737, 0.4442, 0.0385, 0.0342, 0.0329,\n",
      "         0.0380],\n",
      "        [0.0449, 0.0437, 0.0729, 0.0767, 0.1740, 0.4451, 0.0382, 0.0340, 0.0327,\n",
      "         0.0378],\n",
      "        [0.0456, 0.0445, 0.0741, 0.0779, 0.1753, 0.4388, 0.0385, 0.0342, 0.0329,\n",
      "         0.0381]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 172.00, Train Loss: 1.06, Val Loss: 12.98, Train BLEU: 65.49, Val BLEU: 0.40\n",
      "Sampling from training predictions...\n",
      "Source: 我们 用 的 是 深海 潜水 潜水艇 <UNK> 号 和\n",
      "Reference: we use the submarine alvin and we use cameras\n",
      "Model: <SOS> we use the submarine alvin and use use cameras\n",
      "Attention Weights: tensor([[8.6542e-02, 1.8140e-01, 2.7260e-01, 3.0069e-01, 1.3349e-01, 1.8251e-02,\n",
      "         3.1779e-05, 5.1382e-06, 2.7685e-03, 4.2195e-03],\n",
      "        [6.9474e-02, 1.3345e-01, 2.0652e-01, 2.7776e-01, 2.4460e-01, 5.7805e-02,\n",
      "         2.5878e-04, 4.0844e-05, 4.2068e-03, 5.8771e-03],\n",
      "        [5.0525e-02, 7.4240e-02, 1.0596e-01, 1.5743e-01, 3.4433e-01, 2.3096e-01,\n",
      "         1.4126e-02, 3.7113e-03, 8.6316e-03, 1.0093e-02],\n",
      "        [4.4212e-02, 5.5237e-02, 7.2491e-02, 1.0675e-01, 3.0509e-01, 3.1771e-01,\n",
      "         5.4355e-02, 1.9023e-02, 1.2070e-02, 1.3068e-02],\n",
      "        [4.0440e-02, 4.9357e-02, 6.4464e-02, 9.6736e-02, 2.9562e-01, 3.3563e-01,\n",
      "         6.8319e-02, 2.4799e-02, 1.1811e-02, 1.2825e-02],\n",
      "        [3.9357e-02, 4.7000e-02, 6.1039e-02, 9.0753e-02, 2.8206e-01, 3.4304e-01,\n",
      "         8.0025e-02, 3.0888e-02, 1.2406e-02, 1.3433e-02],\n",
      "        [3.7625e-02, 4.4423e-02, 5.7579e-02, 8.5706e-02, 2.7443e-01, 3.4438e-01,\n",
      "         9.2079e-02, 3.7703e-02, 1.2696e-02, 1.3376e-02],\n",
      "        [3.7231e-02, 4.3992e-02, 5.7111e-02, 8.4977e-02, 2.7359e-01, 3.4578e-01,\n",
      "         9.2794e-02, 3.8147e-02, 1.2862e-02, 1.3512e-02],\n",
      "        [3.7383e-02, 4.3798e-02, 5.6522e-02, 8.3845e-02, 2.7039e-01, 3.4466e-01,\n",
      "         9.6120e-02, 4.0076e-02, 1.3317e-02, 1.3886e-02]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 6 岁 那年 塔利 塔利班 占领 阿富汗 并 规定\n",
      "Reference: you see , i was six when the taliban\n",
      "Model: <SOS> the biodiversity the the <UNK> the the the the\n",
      "Attention Weights: tensor([[1.0112e-01, 2.4057e-01, 3.7798e-01, 1.8716e-01, 4.9941e-02, 2.4504e-02,\n",
      "         1.4217e-02, 4.3211e-03, 1.8250e-04, 1.1091e-10],\n",
      "        [1.1339e-01, 1.9615e-01, 3.3255e-01, 2.2001e-01, 6.6494e-02, 3.3047e-02,\n",
      "         2.2695e-02, 1.3271e-02, 2.3940e-03, 5.4709e-09],\n",
      "        [1.3514e-01, 1.6087e-01, 2.5252e-01, 2.1538e-01, 8.2692e-02, 4.4045e-02,\n",
      "         3.7451e-02, 4.4153e-02, 2.7744e-02, 1.2184e-06],\n",
      "        [1.3430e-01, 1.4199e-01, 2.1775e-01, 2.0790e-01, 8.7253e-02, 4.8007e-02,\n",
      "         4.4103e-02, 6.5000e-02, 5.3682e-02, 1.6613e-05],\n",
      "        [1.2452e-01, 1.3145e-01, 2.1003e-01, 2.1373e-01, 8.6085e-02, 4.5189e-02,\n",
      "         4.3653e-02, 7.6575e-02, 6.8733e-02, 4.1284e-05],\n",
      "        [1.1900e-01, 1.2578e-01, 2.0307e-01, 2.1643e-01, 8.7062e-02, 4.4763e-02,\n",
      "         4.3949e-02, 8.1412e-02, 7.8476e-02, 5.3780e-05],\n",
      "        [1.1448e-01, 1.2222e-01, 1.9968e-01, 2.1818e-01, 8.7229e-02, 4.5223e-02,\n",
      "         4.4300e-02, 8.3420e-02, 8.5207e-02, 5.5107e-05],\n",
      "        [1.1321e-01, 1.2116e-01, 1.9825e-01, 2.1840e-01, 8.7667e-02, 4.5740e-02,\n",
      "         4.4827e-02, 8.4081e-02, 8.6611e-02, 5.6215e-05],\n",
      "        [1.1316e-01, 1.2112e-01, 1.9791e-01, 2.1818e-01, 8.7802e-02, 4.5822e-02,\n",
      "         4.4971e-02, 8.4175e-02, 8.6807e-02, 5.6636e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 173.00, Train Loss: 1.04, Val Loss: 12.98, Train BLEU: 68.35, Val BLEU: 0.39\n",
      "Sampling from training predictions...\n",
      "Source: 还有 前面 的 这个 是 推进 引擎 它 一会 一会儿\n",
      "Reference: and it &apos;s got these jet thrusters up in\n",
      "Model: <SOS> and it &apos;s got these jet thrusters up in\n",
      "Attention Weights: tensor([[0.0581, 0.1167, 0.1340, 0.1436, 0.1552, 0.1531, 0.1519, 0.0839, 0.0032,\n",
      "         0.0002],\n",
      "        [0.0607, 0.1099, 0.1262, 0.1349, 0.1451, 0.1469, 0.1543, 0.1101, 0.0110,\n",
      "         0.0010],\n",
      "        [0.0596, 0.0883, 0.1010, 0.1120, 0.1170, 0.1305, 0.1594, 0.1411, 0.0769,\n",
      "         0.0142],\n",
      "        [0.0501, 0.0584, 0.0646, 0.0743, 0.0754, 0.0958, 0.1378, 0.1409, 0.2255,\n",
      "         0.0772],\n",
      "        [0.0472, 0.0518, 0.0568, 0.0662, 0.0666, 0.0868, 0.1280, 0.1351, 0.2597,\n",
      "         0.1019],\n",
      "        [0.0409, 0.0455, 0.0508, 0.0612, 0.0617, 0.0837, 0.1261, 0.1364, 0.2837,\n",
      "         0.1100],\n",
      "        [0.0397, 0.0438, 0.0491, 0.0600, 0.0605, 0.0835, 0.1253, 0.1310, 0.2920,\n",
      "         0.1151],\n",
      "        [0.0385, 0.0421, 0.0471, 0.0580, 0.0583, 0.0816, 0.1239, 0.1263, 0.3048,\n",
      "         0.1196],\n",
      "        [0.0374, 0.0409, 0.0457, 0.0567, 0.0570, 0.0804, 0.1234, 0.1246, 0.3144,\n",
      "         0.1195]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他 面带 <UNK> <UNK> 笑容 这 很少 少见 因为 大部\n",
      "Reference: there was a big smile on his face which\n",
      "Model: <SOS> with vibrant video clips captured submarines david david david\n",
      "Attention Weights: tensor([[0.1117, 0.0019, 0.0557, 0.1312, 0.0157, 0.0012, 0.1430, 0.2731, 0.2653,\n",
      "         0.0012],\n",
      "        [0.1087, 0.0010, 0.0555, 0.1214, 0.0116, 0.0006, 0.1561, 0.2934, 0.2511,\n",
      "         0.0005],\n",
      "        [0.1435, 0.0121, 0.0677, 0.1195, 0.0595, 0.0082, 0.1192, 0.2106, 0.2500,\n",
      "         0.0095],\n",
      "        [0.1518, 0.0379, 0.0715, 0.1106, 0.1158, 0.0274, 0.0921, 0.1444, 0.2141,\n",
      "         0.0344],\n",
      "        [0.1509, 0.0762, 0.0629, 0.0976, 0.1589, 0.0567, 0.0539, 0.0883, 0.1775,\n",
      "         0.0770],\n",
      "        [0.1472, 0.0955, 0.0586, 0.0912, 0.1709, 0.0723, 0.0439, 0.0707, 0.1553,\n",
      "         0.0945],\n",
      "        [0.1415, 0.1104, 0.0544, 0.0847, 0.1789, 0.0833, 0.0378, 0.0604, 0.1419,\n",
      "         0.1068],\n",
      "        [0.1395, 0.1152, 0.0528, 0.0824, 0.1811, 0.0868, 0.0359, 0.0573, 0.1376,\n",
      "         0.1116],\n",
      "        [0.1390, 0.1165, 0.0524, 0.0816, 0.1816, 0.0878, 0.0353, 0.0564, 0.1363,\n",
      "         0.1131]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 174.00, Train Loss: 1.03, Val Loss: 12.98, Train BLEU: 68.17, Val BLEU: 0.43\n",
      "Sampling from training predictions...\n",
      "Source: 看到 这些 在 动 的 东西 了 吗 <EOS> <PAD>\n",
      "Reference: but see all those different working things ? <EOS>\n",
      "Model: <SOS> but see all those different working things <EOS> <EOS>\n",
      "Attention Weights: tensor([[9.7736e-02, 1.7223e-01, 1.8421e-01, 1.7460e-01, 1.5731e-01, 1.1065e-01,\n",
      "         6.8948e-02, 3.1071e-02, 3.2398e-03, 3.8004e-10],\n",
      "        [1.0571e-01, 1.5919e-01, 1.7090e-01, 1.6491e-01, 1.5185e-01, 1.1875e-01,\n",
      "         7.5849e-02, 4.2576e-02, 1.0257e-02, 2.2462e-09],\n",
      "        [1.0788e-01, 1.2346e-01, 1.3302e-01, 1.3209e-01, 1.2915e-01, 1.3184e-01,\n",
      "         8.9857e-02, 7.3877e-02, 7.8826e-02, 6.4156e-07],\n",
      "        [1.0649e-01, 1.1032e-01, 1.1701e-01, 1.1697e-01, 1.1621e-01, 1.2942e-01,\n",
      "         9.2512e-02, 8.6550e-02, 1.2451e-01, 1.7673e-05],\n",
      "        [9.8719e-02, 1.0110e-01, 1.0773e-01, 1.0851e-01, 1.0925e-01, 1.3209e-01,\n",
      "         9.4428e-02, 9.3991e-02, 1.5411e-01, 7.6880e-05],\n",
      "        [9.5214e-02, 9.7692e-02, 1.0443e-01, 1.0540e-01, 1.0663e-01, 1.3310e-01,\n",
      "         9.4622e-02, 9.6163e-02, 1.6661e-01, 1.3069e-04],\n",
      "        [9.3715e-02, 9.6181e-02, 1.0282e-01, 1.0386e-01, 1.0526e-01, 1.3211e-01,\n",
      "         9.4729e-02, 9.6531e-02, 1.7463e-01, 1.6046e-04],\n",
      "        [9.1129e-02, 9.4334e-02, 1.0110e-01, 1.0255e-01, 1.0428e-01, 1.3101e-01,\n",
      "         9.4858e-02, 9.6346e-02, 1.8423e-01, 1.6115e-04],\n",
      "        [8.9557e-02, 9.2974e-02, 9.9805e-02, 1.0158e-01, 1.0364e-01, 1.3083e-01,\n",
      "         9.5104e-02, 9.6547e-02, 1.8980e-01, 1.6097e-04]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班 走 了 父亲 大声 叫 着 <EOS> <PAD>\n",
      "Reference: &quot; the taliban are gone ! &quot; my father\n",
      "Model: <SOS> most of the planet is . . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0226, 0.0468, 0.0754, 0.1675, 0.1717, 0.1497, 0.1511, 0.1228, 0.0696,\n",
      "         0.0226],\n",
      "        [0.0267, 0.0466, 0.0695, 0.1557, 0.1694, 0.1448, 0.1466, 0.1251, 0.0809,\n",
      "         0.0346],\n",
      "        [0.0418, 0.0506, 0.0642, 0.1257, 0.1592, 0.1312, 0.1285, 0.1198, 0.1012,\n",
      "         0.0778],\n",
      "        [0.0455, 0.0507, 0.0617, 0.1180, 0.1576, 0.1273, 0.1232, 0.1181, 0.1062,\n",
      "         0.0918],\n",
      "        [0.0424, 0.0469, 0.0579, 0.1169, 0.1626, 0.1286, 0.1235, 0.1189, 0.1075,\n",
      "         0.0948],\n",
      "        [0.0394, 0.0434, 0.0544, 0.1163, 0.1675, 0.1302, 0.1246, 0.1203, 0.1084,\n",
      "         0.0957],\n",
      "        [0.0379, 0.0413, 0.0523, 0.1156, 0.1702, 0.1312, 0.1255, 0.1214, 0.1088,\n",
      "         0.0958],\n",
      "        [0.0376, 0.0407, 0.0517, 0.1149, 0.1710, 0.1318, 0.1258, 0.1218, 0.1090,\n",
      "         0.0956],\n",
      "        [0.0372, 0.0403, 0.0512, 0.1149, 0.1724, 0.1323, 0.1260, 0.1221, 0.1088,\n",
      "         0.0949]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 175.00, Train Loss: 1.01, Val Loss: 13.00, Train BLEU: 68.31, Val BLEU: 0.43\n",
      "Sampling from training predictions...\n",
      "Source: 地球 的 大部 大部分 部分 都 是 海水 <EOS> <PAD>\n",
      "Reference: most of the planet is ocean water . <EOS>\n",
      "Model: <SOS> most of the planet is . . <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.0361e-01, 2.4059e-01, 3.9542e-01, 1.8284e-01, 4.1129e-02, 2.0565e-02,\n",
      "         1.1805e-02, 3.8860e-03, 1.4186e-04, 1.1018e-10],\n",
      "        [1.1527e-01, 1.9301e-01, 3.5095e-01, 2.2300e-01, 5.6680e-02, 2.7558e-02,\n",
      "         1.8901e-02, 1.2538e-02, 2.0973e-03, 5.7847e-09],\n",
      "        [1.3582e-01, 1.5815e-01, 2.6892e-01, 2.2674e-01, 7.4567e-02, 3.7135e-02,\n",
      "         3.1497e-02, 4.2207e-02, 2.4967e-02, 1.1151e-06],\n",
      "        [1.3505e-01, 1.4018e-01, 2.3471e-01, 2.2189e-01, 8.0020e-02, 4.0697e-02,\n",
      "         3.7165e-02, 6.1948e-02, 4.8319e-02, 1.4200e-05],\n",
      "        [1.2517e-01, 1.2976e-01, 2.2474e-01, 2.2586e-01, 8.0181e-02, 3.9222e-02,\n",
      "         3.7699e-02, 7.4330e-02, 6.3005e-02, 3.7140e-05],\n",
      "        [1.1972e-01, 1.2427e-01, 2.1598e-01, 2.2706e-01, 8.2091e-02, 3.9573e-02,\n",
      "         3.8675e-02, 8.0007e-02, 7.2570e-02, 5.0761e-05],\n",
      "        [1.1483e-01, 1.2009e-01, 2.1144e-01, 2.2827e-01, 8.2646e-02, 4.0233e-02,\n",
      "         3.9257e-02, 8.2934e-02, 8.0242e-02, 5.5393e-05],\n",
      "        [1.1330e-01, 1.1896e-01, 2.0967e-01, 2.2784e-01, 8.3329e-02, 4.0828e-02,\n",
      "         3.9865e-02, 8.4015e-02, 8.2146e-02, 5.6358e-05],\n",
      "        [1.1311e-01, 1.1888e-01, 2.0927e-01, 2.2747e-01, 8.3540e-02, 4.0984e-02,\n",
      "         4.0085e-02, 8.4194e-02, 8.2411e-02, 5.6698e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 不知 知道 那 意味 意味着 什么 但是 我 能\n",
      "Reference: i didn &apos;t know what it meant , but\n",
      "Model: <SOS> people &apos;s have the the and and the the\n",
      "Attention Weights: tensor([[0.0340, 0.0761, 0.1594, 0.3034, 0.2225, 0.1452, 0.0545, 0.0027, 0.0007,\n",
      "         0.0016],\n",
      "        [0.0356, 0.0657, 0.1266, 0.2555, 0.2158, 0.1594, 0.1059, 0.0232, 0.0062,\n",
      "         0.0061],\n",
      "        [0.0338, 0.0437, 0.0676, 0.1318, 0.1564, 0.1291, 0.1694, 0.1849, 0.0635,\n",
      "         0.0198],\n",
      "        [0.0288, 0.0335, 0.0489, 0.0961, 0.1262, 0.1068, 0.1701, 0.2735, 0.0943,\n",
      "         0.0218],\n",
      "        [0.0256, 0.0293, 0.0431, 0.0873, 0.1195, 0.1011, 0.1716, 0.3072, 0.0960,\n",
      "         0.0193],\n",
      "        [0.0249, 0.0284, 0.0417, 0.0843, 0.1162, 0.0982, 0.1706, 0.3202, 0.0968,\n",
      "         0.0187],\n",
      "        [0.0244, 0.0278, 0.0409, 0.0830, 0.1153, 0.0973, 0.1714, 0.3253, 0.0963,\n",
      "         0.0183],\n",
      "        [0.0236, 0.0268, 0.0402, 0.0827, 0.1156, 0.0977, 0.1729, 0.3279, 0.0956,\n",
      "         0.0170],\n",
      "        [0.0240, 0.0271, 0.0412, 0.0843, 0.1172, 0.0994, 0.1736, 0.3235, 0.0928,\n",
      "         0.0169]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 176.00, Train Loss: 0.99, Val Loss: 13.01, Train BLEU: 68.31, Val BLEU: 0.25\n",
      "Sampling from training predictions...\n",
      "Source: 我们 将 用 一些 影片 来讲 讲述 一些 深海 海里\n",
      "Reference: and we &apos;re going to tell you some stories\n",
      "Model: <SOS> and we &apos;re going to tell , the stories\n",
      "Attention Weights: tensor([[0.0206, 0.0438, 0.0825, 0.1859, 0.1737, 0.1514, 0.1419, 0.1154, 0.0649,\n",
      "         0.0199],\n",
      "        [0.0243, 0.0423, 0.0719, 0.1704, 0.1748, 0.1502, 0.1405, 0.1188, 0.0760,\n",
      "         0.0308],\n",
      "        [0.0370, 0.0446, 0.0628, 0.1372, 0.1700, 0.1412, 0.1291, 0.1156, 0.0939,\n",
      "         0.0686],\n",
      "        [0.0398, 0.0443, 0.0599, 0.1294, 0.1693, 0.1380, 0.1254, 0.1147, 0.0984,\n",
      "         0.0808],\n",
      "        [0.0370, 0.0408, 0.0564, 0.1294, 0.1747, 0.1396, 0.1258, 0.1150, 0.0985,\n",
      "         0.0826],\n",
      "        [0.0346, 0.0379, 0.0538, 0.1291, 0.1786, 0.1411, 0.1269, 0.1161, 0.0989,\n",
      "         0.0829],\n",
      "        [0.0336, 0.0365, 0.0525, 0.1287, 0.1804, 0.1420, 0.1276, 0.1170, 0.0989,\n",
      "         0.0828],\n",
      "        [0.0334, 0.0361, 0.0521, 0.1280, 0.1810, 0.1423, 0.1277, 0.1174, 0.0993,\n",
      "         0.0828],\n",
      "        [0.0328, 0.0354, 0.0513, 0.1281, 0.1829, 0.1430, 0.1280, 0.1176, 0.0989,\n",
      "         0.0819]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 他们 知道 我们 的 住处 吗 <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: do they know where we live ? <EOS> <PAD>\n",
      "Model: <SOS> but &apos;s all those different working . <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.4872e-05, 1.0929e-05, 1.3691e-05, 4.5623e-05, 1.0376e-03, 3.6565e-02,\n",
      "         1.3405e-01, 2.3529e-01, 2.7859e-01, 3.1439e-01],\n",
      "        [6.3078e-07, 4.1454e-07, 5.5094e-07, 2.7477e-06, 3.0832e-04, 3.3145e-02,\n",
      "         1.3006e-01, 2.2786e-01, 2.7970e-01, 3.2892e-01],\n",
      "        [2.3672e-05, 1.4710e-05, 1.8064e-05, 7.7889e-05, 4.0907e-03, 6.8041e-02,\n",
      "         1.4590e-01, 2.2078e-01, 2.5312e-01, 3.0794e-01],\n",
      "        [6.1956e-04, 3.8473e-04, 4.4220e-04, 1.4734e-03, 2.5506e-02, 1.1615e-01,\n",
      "         1.6427e-01, 2.0591e-01, 2.1978e-01, 2.6547e-01],\n",
      "        [3.8066e-03, 2.3457e-03, 2.5783e-03, 7.4323e-03, 7.5897e-02, 1.4089e-01,\n",
      "         1.5726e-01, 1.7920e-01, 1.8890e-01, 2.4168e-01],\n",
      "        [9.0010e-03, 5.5407e-03, 5.9799e-03, 1.6354e-02, 1.2696e-01, 1.4686e-01,\n",
      "         1.4399e-01, 1.5697e-01, 1.6571e-01, 2.2263e-01],\n",
      "        [1.9041e-02, 1.2100e-02, 1.2904e-02, 3.3139e-02, 1.8344e-01, 1.4200e-01,\n",
      "         1.2714e-01, 1.3388e-01, 1.4104e-01, 1.9533e-01],\n",
      "        [2.4781e-02, 1.6068e-02, 1.7076e-02, 4.2302e-02, 2.0192e-01, 1.3761e-01,\n",
      "         1.1964e-01, 1.2463e-01, 1.3133e-01, 1.8465e-01],\n",
      "        [2.6081e-02, 1.6976e-02, 1.8034e-02, 4.4303e-02, 2.0474e-01, 1.3620e-01,\n",
      "         1.1816e-01, 1.2294e-01, 1.2969e-01, 1.8287e-01]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 177.00, Train Loss: 0.98, Val Loss: 13.01, Train BLEU: 71.64, Val BLEU: 0.40\n",
      "Sampling from training predictions...\n",
      "Source: 还有 前面 的 这个 是 推进 引擎 它 一会 一会儿\n",
      "Reference: and it &apos;s got these jet thrusters up in\n",
      "Model: <SOS> and it &apos;s got these jet thrusters up in\n",
      "Attention Weights: tensor([[0.0574, 0.1148, 0.1284, 0.1400, 0.1496, 0.1642, 0.1631, 0.0789, 0.0033,\n",
      "         0.0002],\n",
      "        [0.0597, 0.1077, 0.1207, 0.1329, 0.1410, 0.1579, 0.1671, 0.1023, 0.0099,\n",
      "         0.0009],\n",
      "        [0.0583, 0.0870, 0.0981, 0.1130, 0.1161, 0.1403, 0.1762, 0.1336, 0.0661,\n",
      "         0.0112],\n",
      "        [0.0477, 0.0555, 0.0615, 0.0736, 0.0735, 0.0990, 0.1547, 0.1410, 0.2222,\n",
      "         0.0713],\n",
      "        [0.0448, 0.0489, 0.0537, 0.0647, 0.0641, 0.0872, 0.1409, 0.1344, 0.2628,\n",
      "         0.0984],\n",
      "        [0.0400, 0.0441, 0.0493, 0.0609, 0.0606, 0.0845, 0.1373, 0.1348, 0.2824,\n",
      "         0.1062],\n",
      "        [0.0395, 0.0430, 0.0481, 0.0601, 0.0598, 0.0840, 0.1346, 0.1283, 0.2909,\n",
      "         0.1118],\n",
      "        [0.0381, 0.0412, 0.0461, 0.0580, 0.0577, 0.0821, 0.1333, 0.1242, 0.3037,\n",
      "         0.1155],\n",
      "        [0.0365, 0.0396, 0.0443, 0.0563, 0.0560, 0.0806, 0.1330, 0.1227, 0.3152,\n",
      "         0.1159]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在 一个 房屋 房屋里 屋里 我们 100 多 人\n",
      "Reference: the school was in a house , more than\n",
      "Model: <SOS> the biodiversity the the the and the the the\n",
      "Attention Weights: tensor([[0.0474, 0.1784, 0.1723, 0.1729, 0.1263, 0.1388, 0.0764, 0.0395, 0.0293,\n",
      "         0.0188],\n",
      "        [0.0495, 0.2584, 0.1410, 0.1431, 0.1033, 0.1348, 0.0787, 0.0377, 0.0291,\n",
      "         0.0243],\n",
      "        [0.0734, 0.3642, 0.1047, 0.0981, 0.0724, 0.1133, 0.0716, 0.0349, 0.0309,\n",
      "         0.0366],\n",
      "        [0.0746, 0.3878, 0.0957, 0.0882, 0.0649, 0.1108, 0.0710, 0.0342, 0.0314,\n",
      "         0.0415],\n",
      "        [0.0690, 0.3996, 0.0911, 0.0855, 0.0619, 0.1143, 0.0722, 0.0322, 0.0302,\n",
      "         0.0439],\n",
      "        [0.0681, 0.3775, 0.0910, 0.0886, 0.0636, 0.1231, 0.0779, 0.0320, 0.0302,\n",
      "         0.0481],\n",
      "        [0.0673, 0.3679, 0.0914, 0.0902, 0.0646, 0.1261, 0.0800, 0.0323, 0.0306,\n",
      "         0.0495],\n",
      "        [0.0661, 0.3684, 0.0911, 0.0902, 0.0642, 0.1280, 0.0804, 0.0319, 0.0302,\n",
      "         0.0494],\n",
      "        [0.0658, 0.3666, 0.0911, 0.0905, 0.0645, 0.1288, 0.0809, 0.0320, 0.0302,\n",
      "         0.0496]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 178.00, Train Loss: 0.96, Val Loss: 13.00, Train BLEU: 71.06, Val BLEU: 0.40\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的 平均 深度 是 两英里 英里 <EOS> <PAD> <PAD>\n",
      "Reference: the average depth is about two miles . <EOS>\n",
      "Model: <SOS> the average depth is about two miles <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.6255e-01, 1.7487e-01, 2.0633e-01, 2.4078e-01, 2.0943e-01, 4.8564e-03,\n",
      "         1.1553e-03, 3.3461e-05, 2.8223e-10, 2.8223e-10],\n",
      "        [1.5039e-01, 1.4485e-01, 1.7669e-01, 2.3753e-01, 2.3942e-01, 4.4963e-02,\n",
      "         5.4976e-03, 6.6855e-04, 4.7269e-09, 4.7269e-09],\n",
      "        [1.0884e-01, 8.8236e-02, 1.0917e-01, 1.6459e-01, 1.8773e-01, 3.0440e-01,\n",
      "         2.3874e-02, 1.3158e-02, 2.6082e-07, 2.6082e-07],\n",
      "        [8.0412e-02, 6.1914e-02, 7.5520e-02, 1.1665e-01, 1.4150e-01, 4.6209e-01,\n",
      "         3.3045e-02, 2.8865e-02, 3.6059e-06, 3.6059e-06],\n",
      "        [6.9957e-02, 5.4075e-02, 6.7151e-02, 1.0730e-01, 1.3485e-01, 5.0174e-01,\n",
      "         3.2261e-02, 3.2638e-02, 1.5360e-05, 1.5360e-05],\n",
      "        [7.0895e-02, 5.5268e-02, 6.8729e-02, 1.0858e-01, 1.3655e-01, 4.8988e-01,\n",
      "         3.4419e-02, 3.5620e-02, 2.9836e-05, 2.9836e-05],\n",
      "        [7.1884e-02, 5.6824e-02, 7.0227e-02, 1.0982e-01, 1.3572e-01, 4.7963e-01,\n",
      "         3.6552e-02, 3.9264e-02, 4.0734e-05, 4.0734e-05],\n",
      "        [7.2038e-02, 5.7406e-02, 7.0999e-02, 1.1100e-01, 1.3725e-01, 4.7254e-01,\n",
      "         3.7238e-02, 4.1432e-02, 4.6098e-05, 4.6098e-05],\n",
      "        [7.2200e-02, 5.7681e-02, 7.1403e-02, 1.1201e-01, 1.3882e-01, 4.6984e-01,\n",
      "         3.6853e-02, 4.1114e-02, 3.9584e-05, 3.9584e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班 走 了 父亲 大声 叫 着 <EOS> <PAD>\n",
      "Reference: &quot; the taliban are gone ! &quot; my father\n",
      "Model: <SOS> most of the planet is . . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0209, 0.0429, 0.0761, 0.1677, 0.1758, 0.1578, 0.1496, 0.1220, 0.0665,\n",
      "         0.0207],\n",
      "        [0.0247, 0.0428, 0.0692, 0.1549, 0.1756, 0.1534, 0.1468, 0.1246, 0.0772,\n",
      "         0.0308],\n",
      "        [0.0383, 0.0465, 0.0621, 0.1238, 0.1659, 0.1416, 0.1337, 0.1213, 0.0975,\n",
      "         0.0694],\n",
      "        [0.0423, 0.0471, 0.0597, 0.1150, 0.1633, 0.1380, 0.1290, 0.1198, 0.1028,\n",
      "         0.0829],\n",
      "        [0.0401, 0.0442, 0.0567, 0.1134, 0.1675, 0.1396, 0.1294, 0.1203, 0.1033,\n",
      "         0.0854],\n",
      "        [0.0378, 0.0413, 0.0540, 0.1122, 0.1710, 0.1411, 0.1306, 0.1217, 0.1040,\n",
      "         0.0862],\n",
      "        [0.0368, 0.0398, 0.0526, 0.1113, 0.1726, 0.1422, 0.1315, 0.1227, 0.1041,\n",
      "         0.0863],\n",
      "        [0.0365, 0.0392, 0.0520, 0.1106, 0.1733, 0.1428, 0.1316, 0.1231, 0.1045,\n",
      "         0.0864],\n",
      "        [0.0360, 0.0386, 0.0512, 0.1104, 0.1748, 0.1434, 0.1319, 0.1234, 0.1043,\n",
      "         0.0859]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 179.00, Train Loss: 0.95, Val Loss: 13.01, Train BLEU: 70.48, Val BLEU: 0.41\n",
      "Sampling from training predictions...\n",
      "Source: 底下 这些 都 是 <UNK> 它们 上上 上上下下 上下 下下\n",
      "Reference: it &apos;s got these fishing <UNK> on the bottom\n",
      "Model: <SOS> it &apos;s got these fishing <UNK> on the bottom\n",
      "Attention Weights: tensor([[0.0464, 0.0934, 0.1464, 0.0887, 0.0004, 0.0892, 0.2398, 0.1733, 0.1089,\n",
      "         0.0136],\n",
      "        [0.0497, 0.0878, 0.1579, 0.1582, 0.0046, 0.0908, 0.1935, 0.1329, 0.0953,\n",
      "         0.0291],\n",
      "        [0.0513, 0.0704, 0.1340, 0.2675, 0.1199, 0.0672, 0.1085, 0.0593, 0.0530,\n",
      "         0.0690],\n",
      "        [0.0467, 0.0590, 0.1104, 0.2537, 0.2289, 0.0572, 0.0832, 0.0447, 0.0426,\n",
      "         0.0735],\n",
      "        [0.0447, 0.0567, 0.1070, 0.2438, 0.2653, 0.0509, 0.0733, 0.0398, 0.0400,\n",
      "         0.0785],\n",
      "        [0.0441, 0.0551, 0.1012, 0.2275, 0.2906, 0.0493, 0.0705, 0.0389, 0.0391,\n",
      "         0.0837],\n",
      "        [0.0428, 0.0532, 0.0974, 0.2238, 0.3044, 0.0473, 0.0675, 0.0379, 0.0382,\n",
      "         0.0874],\n",
      "        [0.0411, 0.0509, 0.0943, 0.2268, 0.3120, 0.0451, 0.0654, 0.0367, 0.0371,\n",
      "         0.0906],\n",
      "        [0.0398, 0.0496, 0.0929, 0.2309, 0.3158, 0.0441, 0.0644, 0.0356, 0.0360,\n",
      "         0.0908]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 有时 学校 <UNK> 突然 <UNK> 一周 因为 被 塔利 塔利班\n",
      "Reference: from time to time , the school would suddenly\n",
      "Model: <SOS> this vibrant video about about , , . .\n",
      "Attention Weights: tensor([[0.0406, 0.0799, 0.1095, 0.1421, 0.1405, 0.1432, 0.1237, 0.1004, 0.0765,\n",
      "         0.0437],\n",
      "        [0.0470, 0.0804, 0.1063, 0.1386, 0.1344, 0.1380, 0.1219, 0.1011, 0.0800,\n",
      "         0.0524],\n",
      "        [0.0642, 0.0830, 0.1012, 0.1237, 0.1201, 0.1231, 0.1140, 0.1026, 0.0908,\n",
      "         0.0773],\n",
      "        [0.0760, 0.0862, 0.0994, 0.1159, 0.1131, 0.1156, 0.1092, 0.1014, 0.0941,\n",
      "         0.0891],\n",
      "        [0.0772, 0.0849, 0.0973, 0.1130, 0.1104, 0.1134, 0.1085, 0.1022, 0.0970,\n",
      "         0.0962],\n",
      "        [0.0753, 0.0808, 0.0941, 0.1120, 0.1090, 0.1129, 0.1093, 0.1039, 0.1001,\n",
      "         0.1028],\n",
      "        [0.0758, 0.0806, 0.0936, 0.1114, 0.1085, 0.1125, 0.1093, 0.1041, 0.1006,\n",
      "         0.1035],\n",
      "        [0.0755, 0.0801, 0.0932, 0.1112, 0.1083, 0.1125, 0.1095, 0.1043, 0.1011,\n",
      "         0.1043],\n",
      "        [0.0754, 0.0799, 0.0930, 0.1113, 0.1082, 0.1125, 0.1096, 0.1044, 0.1012,\n",
      "         0.1045]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 180.00, Train Loss: 0.93, Val Loss: 13.03, Train BLEU: 72.08, Val BLEU: 0.44\n",
      "Sampling from training predictions...\n",
      "Source: 看到 这些 在 动 的 东西 了 吗 <EOS> <PAD>\n",
      "Reference: but see all those different working things ? <EOS>\n",
      "Model: <SOS> but see all those different working things <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.0942e-01, 1.9955e-01, 1.9545e-01, 1.7213e-01, 1.4303e-01, 9.7550e-02,\n",
      "         5.6011e-02, 2.3982e-02, 2.8774e-03, 3.3928e-10],\n",
      "        [1.2026e-01, 1.8528e-01, 1.8167e-01, 1.6349e-01, 1.3939e-01, 1.0604e-01,\n",
      "         6.2107e-02, 3.3091e-02, 8.6757e-03, 1.9023e-09],\n",
      "        [1.2503e-01, 1.4226e-01, 1.4311e-01, 1.3416e-01, 1.2402e-01, 1.2142e-01,\n",
      "         7.8697e-02, 6.2470e-02, 6.8836e-02, 5.3294e-07],\n",
      "        [1.2389e-01, 1.2676e-01, 1.2703e-01, 1.2079e-01, 1.1437e-01, 1.2081e-01,\n",
      "         8.2513e-02, 7.3741e-02, 1.1009e-01, 1.4318e-05],\n",
      "        [1.1650e-01, 1.1721e-01, 1.1775e-01, 1.1259e-01, 1.0799e-01, 1.2258e-01,\n",
      "         8.4672e-02, 8.0596e-02, 1.4004e-01, 6.3370e-05],\n",
      "        [1.1204e-01, 1.1273e-01, 1.1410e-01, 1.0956e-01, 1.0581e-01, 1.2364e-01,\n",
      "         8.5565e-02, 8.3775e-02, 1.5266e-01, 1.1547e-04],\n",
      "        [1.0904e-01, 1.0984e-01, 1.1195e-01, 1.0804e-01, 1.0491e-01, 1.2337e-01,\n",
      "         8.6440e-02, 8.5087e-02, 1.6118e-01, 1.4737e-04],\n",
      "        [1.0444e-01, 1.0615e-01, 1.0891e-01, 1.0583e-01, 1.0346e-01, 1.2331e-01,\n",
      "         8.6950e-02, 8.5839e-02, 1.7495e-01, 1.6533e-04],\n",
      "        [1.0279e-01, 1.0464e-01, 1.0747e-01, 1.0482e-01, 1.0294e-01, 1.2353e-01,\n",
      "         8.7756e-02, 8.6537e-02, 1.7936e-01, 1.5877e-04]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 总是 担心 会 被 塔利 塔利班 发现 <EOS> <PAD>\n",
      "Reference: we always wondered what they knew about us .\n",
      "Model: <SOS> it &apos;s got to about about stuff . .\n",
      "Attention Weights: tensor([[0.0028, 0.0028, 0.1349, 0.1622, 0.1722, 0.1959, 0.2491, 0.0476, 0.0222,\n",
      "         0.0105],\n",
      "        [0.0068, 0.0163, 0.1366, 0.1461, 0.1482, 0.1679, 0.2232, 0.1005, 0.0346,\n",
      "         0.0197],\n",
      "        [0.0233, 0.0998, 0.1075, 0.0940, 0.0946, 0.1123, 0.1786, 0.1985, 0.0532,\n",
      "         0.0382],\n",
      "        [0.0300, 0.1442, 0.0941, 0.0798, 0.0810, 0.0979, 0.1656, 0.2135, 0.0530,\n",
      "         0.0409],\n",
      "        [0.0334, 0.1714, 0.0859, 0.0728, 0.0744, 0.0918, 0.1603, 0.2183, 0.0509,\n",
      "         0.0408],\n",
      "        [0.0353, 0.1974, 0.0787, 0.0666, 0.0685, 0.0868, 0.1580, 0.2216, 0.0478,\n",
      "         0.0394],\n",
      "        [0.0363, 0.2107, 0.0753, 0.0636, 0.0659, 0.0863, 0.1622, 0.2161, 0.0456,\n",
      "         0.0379],\n",
      "        [0.0368, 0.2160, 0.0741, 0.0628, 0.0652, 0.0857, 0.1624, 0.2129, 0.0458,\n",
      "         0.0383],\n",
      "        [0.0363, 0.2189, 0.0730, 0.0618, 0.0643, 0.0850, 0.1635, 0.2142, 0.0453,\n",
      "         0.0377]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 181.00, Train Loss: 0.92, Val Loss: 13.04, Train BLEU: 74.91, Val BLEU: 0.44\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数 多数 地震 和 火山 喷发 也 都 发生\n",
      "Reference: most of the earthquakes and volcanoes are in the\n",
      "Model: <SOS> most of the earthquakes and volcanoes the the the\n",
      "Attention Weights: tensor([[0.0475, 0.1919, 0.1635, 0.1685, 0.1239, 0.1478, 0.0774, 0.0347, 0.0272,\n",
      "         0.0177],\n",
      "        [0.0485, 0.2690, 0.1341, 0.1407, 0.1023, 0.1446, 0.0786, 0.0337, 0.0268,\n",
      "         0.0216],\n",
      "        [0.0725, 0.3835, 0.0977, 0.0956, 0.0707, 0.1191, 0.0711, 0.0314, 0.0278,\n",
      "         0.0305],\n",
      "        [0.0735, 0.4132, 0.0885, 0.0852, 0.0631, 0.1145, 0.0697, 0.0308, 0.0280,\n",
      "         0.0336],\n",
      "        [0.0678, 0.4317, 0.0827, 0.0811, 0.0591, 0.1178, 0.0699, 0.0285, 0.0264,\n",
      "         0.0350],\n",
      "        [0.0668, 0.4090, 0.0826, 0.0842, 0.0605, 0.1286, 0.0759, 0.0279, 0.0259,\n",
      "         0.0386],\n",
      "        [0.0660, 0.4010, 0.0828, 0.0856, 0.0614, 0.1316, 0.0777, 0.0280, 0.0261,\n",
      "         0.0398],\n",
      "        [0.0646, 0.4037, 0.0820, 0.0852, 0.0607, 0.1337, 0.0777, 0.0274, 0.0256,\n",
      "         0.0394],\n",
      "        [0.0643, 0.4025, 0.0820, 0.0855, 0.0608, 0.1345, 0.0781, 0.0273, 0.0255,\n",
      "         0.0395]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 所以 在 那 之后 5 年 我 <UNK> <UNK> 陪\n",
      "Reference: so for the next five years , i dressed\n",
      "Model: <SOS> we use the submarine alvin and we cameras cameras\n",
      "Attention Weights: tensor([[1.6374e-01, 1.7671e-01, 2.0589e-01, 2.4156e-01, 2.0684e-01, 4.3486e-03,\n",
      "         8.8134e-04, 2.3441e-05, 2.5466e-10, 2.5466e-10],\n",
      "        [1.5493e-01, 1.4856e-01, 1.7846e-01, 2.4206e-01, 2.3599e-01, 3.5518e-02,\n",
      "         4.0591e-03, 4.1954e-04, 3.5399e-09, 3.5399e-09],\n",
      "        [1.1864e-01, 9.3664e-02, 1.1425e-01, 1.7793e-01, 1.9302e-01, 2.7358e-01,\n",
      "         1.9429e-02, 9.4798e-03, 1.8840e-07, 1.8840e-07],\n",
      "        [8.6432e-02, 6.3850e-02, 7.6972e-02, 1.2501e-01, 1.4303e-01, 4.5279e-01,\n",
      "         2.8488e-02, 2.3415e-02, 2.4047e-06, 2.4047e-06],\n",
      "        [7.2012e-02, 5.2915e-02, 6.5316e-02, 1.1205e-01, 1.3353e-01, 5.0977e-01,\n",
      "         2.7465e-02, 2.6928e-02, 1.0926e-05, 1.0926e-05],\n",
      "        [7.2121e-02, 5.3355e-02, 6.6155e-02, 1.1264e-01, 1.3472e-01, 5.0306e-01,\n",
      "         2.8981e-02, 2.8925e-02, 2.1717e-05, 2.1717e-05],\n",
      "        [7.2429e-02, 5.4353e-02, 6.7173e-02, 1.1358e-01, 1.3425e-01, 4.9525e-01,\n",
      "         3.0757e-02, 3.2150e-02, 3.1548e-05, 3.1548e-05],\n",
      "        [7.2012e-02, 5.4232e-02, 6.7220e-02, 1.1419e-01, 1.3538e-01, 4.9192e-01,\n",
      "         3.1122e-02, 3.3848e-02, 3.7104e-05, 3.7104e-05],\n",
      "        [7.2188e-02, 5.4551e-02, 6.7639e-02, 1.1496e-01, 1.3688e-01, 4.8875e-01,\n",
      "         3.1009e-02, 3.3960e-02, 3.2677e-05, 3.2677e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 182.00, Train Loss: 0.90, Val Loss: 13.04, Train BLEU: 75.59, Val BLEU: 0.44\n",
      "Sampling from training predictions...\n",
      "Source: 大多 大多数 多数 地震 和 火山 喷发 也 都 发生\n",
      "Reference: most of the earthquakes and volcanoes are in the\n",
      "Model: <SOS> most of the earthquakes and volcanoes the the the\n",
      "Attention Weights: tensor([[0.0477, 0.1992, 0.1634, 0.1685, 0.1216, 0.1472, 0.0767, 0.0329, 0.0258,\n",
      "         0.0170],\n",
      "        [0.0488, 0.2772, 0.1337, 0.1405, 0.1005, 0.1436, 0.0774, 0.0320, 0.0254,\n",
      "         0.0208],\n",
      "        [0.0725, 0.3915, 0.0982, 0.0956, 0.0694, 0.1176, 0.0695, 0.0298, 0.0265,\n",
      "         0.0294],\n",
      "        [0.0735, 0.4216, 0.0890, 0.0851, 0.0619, 0.1127, 0.0680, 0.0293, 0.0266,\n",
      "         0.0323],\n",
      "        [0.0675, 0.4432, 0.0827, 0.0805, 0.0574, 0.1158, 0.0678, 0.0268, 0.0248,\n",
      "         0.0335],\n",
      "        [0.0662, 0.4204, 0.0825, 0.0836, 0.0588, 0.1271, 0.0739, 0.0261, 0.0243,\n",
      "         0.0370],\n",
      "        [0.0654, 0.4132, 0.0827, 0.0849, 0.0596, 0.1300, 0.0757, 0.0261, 0.0245,\n",
      "         0.0380],\n",
      "        [0.0640, 0.4164, 0.0818, 0.0844, 0.0588, 0.1319, 0.0756, 0.0256, 0.0239,\n",
      "         0.0376],\n",
      "        [0.0636, 0.4151, 0.0818, 0.0847, 0.0590, 0.1327, 0.0760, 0.0255, 0.0239,\n",
      "         0.0378]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 有时 学校 <UNK> 突然 <UNK> 一周 因为 被 塔利 塔利班\n",
      "Reference: from time to time , the school would suddenly\n",
      "Model: <SOS> this vibrant video about about , the . .\n",
      "Attention Weights: tensor([[0.0391, 0.0798, 0.1114, 0.1435, 0.1425, 0.1449, 0.1237, 0.0987, 0.0742,\n",
      "         0.0421],\n",
      "        [0.0449, 0.0799, 0.1081, 0.1401, 0.1367, 0.1401, 0.1226, 0.0997, 0.0778,\n",
      "         0.0502],\n",
      "        [0.0613, 0.0822, 0.1025, 0.1267, 0.1227, 0.1257, 0.1151, 0.1015, 0.0886,\n",
      "         0.0738],\n",
      "        [0.0741, 0.0860, 0.1005, 0.1185, 0.1152, 0.1179, 0.1101, 0.1004, 0.0918,\n",
      "         0.0855],\n",
      "        [0.0760, 0.0851, 0.0983, 0.1155, 0.1123, 0.1154, 0.1094, 0.1010, 0.0947,\n",
      "         0.0925],\n",
      "        [0.0737, 0.0804, 0.0944, 0.1145, 0.1106, 0.1150, 0.1104, 0.1030, 0.0983,\n",
      "         0.0999],\n",
      "        [0.0739, 0.0797, 0.0936, 0.1138, 0.1100, 0.1146, 0.1106, 0.1034, 0.0991,\n",
      "         0.1013],\n",
      "        [0.0738, 0.0791, 0.0930, 0.1133, 0.1096, 0.1143, 0.1107, 0.1038, 0.0998,\n",
      "         0.1027],\n",
      "        [0.0738, 0.0790, 0.0927, 0.1132, 0.1094, 0.1143, 0.1108, 0.1039, 0.1000,\n",
      "         0.1030]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 183.00, Train Loss: 0.89, Val Loss: 13.04, Train BLEU: 75.59, Val BLEU: 0.45\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克 泰坦尼克号 坦尼 尼克 号 是 拿 了 不少\n",
      "Reference: the truth of the matter is that the titanic\n",
      "Model: <SOS> the truth of the matter is the the titanic\n",
      "Attention Weights: tensor([[0.0158, 0.0088, 0.0071, 0.0145, 0.1057, 0.1215, 0.1796, 0.2042, 0.1852,\n",
      "         0.1576],\n",
      "        [0.0215, 0.0209, 0.0160, 0.0311, 0.1161, 0.1234, 0.1662, 0.1812, 0.1653,\n",
      "         0.1580],\n",
      "        [0.0478, 0.1139, 0.0752, 0.1112, 0.1118, 0.0969, 0.1090, 0.1118, 0.1059,\n",
      "         0.1165],\n",
      "        [0.0539, 0.2035, 0.1194, 0.1520, 0.0875, 0.0705, 0.0746, 0.0756, 0.0733,\n",
      "         0.0898],\n",
      "        [0.0568, 0.2762, 0.1528, 0.1676, 0.0668, 0.0524, 0.0534, 0.0535, 0.0525,\n",
      "         0.0681],\n",
      "        [0.0590, 0.3777, 0.1882, 0.1668, 0.0389, 0.0293, 0.0298, 0.0308, 0.0316,\n",
      "         0.0478],\n",
      "        [0.0604, 0.3939, 0.1925, 0.1632, 0.0350, 0.0261, 0.0266, 0.0278, 0.0289,\n",
      "         0.0455],\n",
      "        [0.0603, 0.3998, 0.1935, 0.1620, 0.0342, 0.0253, 0.0257, 0.0268, 0.0279,\n",
      "         0.0446],\n",
      "        [0.0603, 0.3995, 0.1930, 0.1622, 0.0342, 0.0253, 0.0257, 0.0269, 0.0281,\n",
      "         0.0449]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 冬天 很 舒服 但 夏天 却 <UNK> <EOS> <PAD> <PAD>\n",
      "Reference: it was cozy in winter but extremely hot in\n",
      "Model: <SOS> life in the deep oceans <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0603, 0.1271, 0.2460, 0.1829, 0.1677, 0.0073, 0.0490, 0.0657, 0.0550,\n",
      "         0.0389],\n",
      "        [0.0619, 0.0987, 0.1817, 0.1449, 0.1856, 0.0483, 0.0727, 0.0832, 0.0691,\n",
      "         0.0538],\n",
      "        [0.0650, 0.0697, 0.1194, 0.1037, 0.1893, 0.2387, 0.0603, 0.0565, 0.0500,\n",
      "         0.0474],\n",
      "        [0.0547, 0.0533, 0.0902, 0.0828, 0.1717, 0.3695, 0.0511, 0.0452, 0.0406,\n",
      "         0.0408],\n",
      "        [0.0444, 0.0413, 0.0712, 0.0678, 0.1639, 0.4779, 0.0381, 0.0334, 0.0304,\n",
      "         0.0316],\n",
      "        [0.0355, 0.0319, 0.0582, 0.0571, 0.1614, 0.5691, 0.0241, 0.0209, 0.0197,\n",
      "         0.0221],\n",
      "        [0.0338, 0.0304, 0.0561, 0.0558, 0.1633, 0.5799, 0.0224, 0.0192, 0.0183,\n",
      "         0.0208],\n",
      "        [0.0331, 0.0298, 0.0554, 0.0549, 0.1616, 0.5859, 0.0220, 0.0188, 0.0179,\n",
      "         0.0204],\n",
      "        [0.0336, 0.0303, 0.0568, 0.0564, 0.1649, 0.5786, 0.0220, 0.0188, 0.0179,\n",
      "         0.0206]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 184.00, Train Loss: 0.87, Val Loss: 13.04, Train BLEU: 74.26, Val BLEU: 0.44\n",
      "Sampling from training predictions...\n",
      "Source: 和 我们 合作 的 人们 帮 我们 找到 了 新\n",
      "Reference: people that have partnered with us have given us\n",
      "Model: <SOS> people &apos;s have partnered standing us us given us\n",
      "Attention Weights: tensor([[0.0295, 0.0844, 0.1514, 0.1215, 0.1431, 0.1291, 0.1360, 0.1151, 0.0576,\n",
      "         0.0321],\n",
      "        [0.0340, 0.0809, 0.1431, 0.1144, 0.1466, 0.1190, 0.1408, 0.1269, 0.0580,\n",
      "         0.0363],\n",
      "        [0.0534, 0.0833, 0.1298, 0.1061, 0.1337, 0.1059, 0.1296, 0.1351, 0.0670,\n",
      "         0.0561],\n",
      "        [0.0633, 0.0848, 0.1224, 0.1014, 0.1271, 0.1008, 0.1245, 0.1395, 0.0718,\n",
      "         0.0644],\n",
      "        [0.0635, 0.0825, 0.1198, 0.0985, 0.1268, 0.0979, 0.1251, 0.1455, 0.0727,\n",
      "         0.0678],\n",
      "        [0.0588, 0.0760, 0.1166, 0.0934, 0.1299, 0.0932, 0.1297, 0.1620, 0.0716,\n",
      "         0.0687],\n",
      "        [0.0594, 0.0757, 0.1148, 0.0924, 0.1292, 0.0925, 0.1294, 0.1640, 0.0728,\n",
      "         0.0699],\n",
      "        [0.0587, 0.0749, 0.1146, 0.0921, 0.1295, 0.0922, 0.1299, 0.1657, 0.0726,\n",
      "         0.0700],\n",
      "        [0.0584, 0.0740, 0.1138, 0.0915, 0.1294, 0.0918, 0.1301, 0.1678, 0.0727,\n",
      "         0.0704]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在 一个 房屋 房屋里 屋里 我们 100 多 人\n",
      "Reference: the school was in a house , more than\n",
      "Model: <SOS> the biodiversity the the the and the the the\n",
      "Attention Weights: tensor([[0.0483, 0.2146, 0.1616, 0.1683, 0.1182, 0.1463, 0.0721, 0.0303, 0.0239,\n",
      "         0.0163],\n",
      "        [0.0493, 0.2961, 0.1307, 0.1396, 0.0973, 0.1429, 0.0721, 0.0289, 0.0232,\n",
      "         0.0199],\n",
      "        [0.0721, 0.4104, 0.0953, 0.0945, 0.0666, 0.1169, 0.0653, 0.0268, 0.0239,\n",
      "         0.0283],\n",
      "        [0.0730, 0.4401, 0.0864, 0.0841, 0.0593, 0.1117, 0.0638, 0.0264, 0.0240,\n",
      "         0.0312],\n",
      "        [0.0671, 0.4584, 0.0806, 0.0800, 0.0552, 0.1153, 0.0640, 0.0242, 0.0224,\n",
      "         0.0326],\n",
      "        [0.0659, 0.4285, 0.0812, 0.0841, 0.0574, 0.1280, 0.0712, 0.0240, 0.0224,\n",
      "         0.0372],\n",
      "        [0.0649, 0.4214, 0.0813, 0.0853, 0.0581, 0.1309, 0.0729, 0.0241, 0.0226,\n",
      "         0.0384],\n",
      "        [0.0634, 0.4260, 0.0802, 0.0847, 0.0571, 0.1327, 0.0725, 0.0235, 0.0220,\n",
      "         0.0378],\n",
      "        [0.0631, 0.4249, 0.0802, 0.0849, 0.0572, 0.1335, 0.0728, 0.0234, 0.0219,\n",
      "         0.0380]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 185.00, Train Loss: 0.86, Val Loss: 13.05, Train BLEU: 74.57, Val BLEU: 0.40\n",
      "Sampling from training predictions...\n",
      "Source: 还有 这些 摇晃 着 旋转 转着 的 触角 <EOS> <PAD>\n",
      "Reference: it &apos;s got tentacles dangling , swirling around like\n",
      "Model: <SOS> it &apos;s got tentacles dangling , swirling like like\n",
      "Attention Weights: tensor([[8.2981e-02, 1.7107e-01, 2.1067e-01, 2.2483e-01, 2.6951e-01, 2.7273e-02,\n",
      "         7.4183e-03, 5.0680e-03, 1.1893e-03, 1.9754e-10],\n",
      "        [8.4669e-02, 1.4857e-01, 1.8852e-01, 2.0295e-01, 2.8515e-01, 6.6090e-02,\n",
      "         1.1633e-02, 8.7522e-03, 3.6646e-03, 1.0968e-09],\n",
      "        [8.0103e-02, 1.0532e-01, 1.3313e-01, 1.3790e-01, 2.2814e-01, 2.4678e-01,\n",
      "         2.1700e-02, 2.0477e-02, 2.6446e-02, 1.7221e-07],\n",
      "        [7.7487e-02, 9.0081e-02, 1.0961e-01, 1.1161e-01, 1.8759e-01, 3.2402e-01,\n",
      "         2.8374e-02, 2.7464e-02, 4.3757e-02, 4.3272e-06],\n",
      "        [6.7607e-02, 7.7604e-02, 9.7073e-02, 1.0029e-01, 1.8355e-01, 3.7476e-01,\n",
      "         2.4741e-02, 2.5237e-02, 4.9110e-02, 2.7025e-05],\n",
      "        [6.2555e-02, 7.1419e-02, 9.0692e-02, 9.4358e-02, 1.8011e-01, 4.0006e-01,\n",
      "         2.4150e-02, 2.5540e-02, 5.1044e-02, 6.8365e-05],\n",
      "        [5.8218e-02, 6.6234e-02, 8.4237e-02, 8.7703e-02, 1.7071e-01, 4.3115e-01,\n",
      "         2.4025e-02, 2.5102e-02, 5.2524e-02, 9.4693e-05],\n",
      "        [5.4409e-02, 6.2054e-02, 7.9622e-02, 8.3199e-02, 1.6718e-01, 4.4958e-01,\n",
      "         2.3740e-02, 2.4965e-02, 5.5142e-02, 1.0930e-04],\n",
      "        [5.3662e-02, 6.1408e-02, 7.9266e-02, 8.2862e-02, 1.6715e-01, 4.5118e-01,\n",
      "         2.3859e-02, 2.5089e-02, 5.5434e-02, 9.8981e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 很 幸运 幸运地 成长 在 一个 珍视 教育 也\n",
      "Reference: i was very lucky to grow up in a\n",
      "Model: <SOS> we biodiversity have the earthquakes and and the the\n",
      "Attention Weights: tensor([[1.5401e-01, 2.8092e-01, 3.4004e-01, 2.0806e-01, 1.6975e-02, 5.7261e-09,\n",
      "         5.7261e-09, 5.7261e-09, 5.7261e-09, 5.7261e-09],\n",
      "        [1.5246e-01, 2.4073e-01, 2.9470e-01, 2.4945e-01, 6.2671e-02, 3.4767e-08,\n",
      "         3.4767e-08, 3.4767e-08, 3.4767e-08, 3.4767e-08],\n",
      "        [1.1464e-01, 1.4714e-01, 1.9399e-01, 2.8744e-01, 2.5679e-01, 1.1753e-06,\n",
      "         1.1753e-06, 1.1753e-06, 1.1753e-06, 1.1753e-06],\n",
      "        [1.0346e-01, 1.2110e-01, 1.5782e-01, 2.6323e-01, 3.5427e-01, 2.3804e-05,\n",
      "         2.3804e-05, 2.3804e-05, 2.3804e-05, 2.3804e-05],\n",
      "        [9.0885e-02, 1.0216e-01, 1.3429e-01, 2.5590e-01, 4.1612e-01, 1.2938e-04,\n",
      "         1.2938e-04, 1.2938e-04, 1.2938e-04, 1.2938e-04],\n",
      "        [8.9242e-02, 1.0005e-01, 1.2925e-01, 2.4323e-01, 4.3704e-01, 2.3902e-04,\n",
      "         2.3902e-04, 2.3902e-04, 2.3902e-04, 2.3902e-04],\n",
      "        [8.9527e-02, 1.0028e-01, 1.2848e-01, 2.3971e-01, 4.4069e-01, 2.6393e-04,\n",
      "         2.6393e-04, 2.6393e-04, 2.6393e-04, 2.6393e-04],\n",
      "        [8.9814e-02, 1.0049e-01, 1.2860e-01, 2.3963e-01, 4.4004e-01, 2.8298e-04,\n",
      "         2.8298e-04, 2.8298e-04, 2.8298e-04, 2.8298e-04],\n",
      "        [8.9982e-02, 1.0064e-01, 1.2881e-01, 2.3988e-01, 4.3927e-01, 2.8363e-04,\n",
      "         2.8363e-04, 2.8363e-04, 2.8363e-04, 2.8363e-04]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 186.00, Train Loss: 0.84, Val Loss: 13.07, Train BLEU: 75.40, Val BLEU: 0.40\n",
      "Sampling from training predictions...\n",
      "Source: 海洋 的 平均 深度 是 两英里 英里 <EOS> <PAD> <PAD>\n",
      "Reference: the average depth is about two miles . <EOS>\n",
      "Model: <SOS> the average depth is about two miles <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.4840e-01, 1.5720e-01, 1.9557e-01, 2.5241e-01, 2.3999e-01, 5.5911e-03,\n",
      "         8.0923e-04, 2.4669e-05, 2.8360e-10, 2.8360e-10],\n",
      "        [1.4225e-01, 1.3182e-01, 1.6846e-01, 2.5319e-01, 2.6564e-01, 3.5150e-02,\n",
      "         3.1654e-03, 3.2425e-04, 2.7994e-09, 2.7994e-09],\n",
      "        [1.0793e-01, 8.2720e-02, 1.0665e-01, 1.8756e-01, 2.1190e-01, 2.7987e-01,\n",
      "         1.5545e-02, 7.8310e-03, 1.4093e-07, 1.4093e-07],\n",
      "        [7.6231e-02, 5.4372e-02, 6.8462e-02, 1.2689e-01, 1.4756e-01, 4.8145e-01,\n",
      "         2.3746e-02, 2.1283e-02, 1.7308e-06, 1.7308e-06],\n",
      "        [6.1841e-02, 4.3462e-02, 5.6175e-02, 1.1218e-01, 1.3561e-01, 5.4214e-01,\n",
      "         2.3248e-02, 2.5326e-02, 8.1414e-06, 8.1414e-06],\n",
      "        [6.1179e-02, 4.3280e-02, 5.6088e-02, 1.1101e-01, 1.3475e-01, 5.4222e-01,\n",
      "         2.4367e-02, 2.7073e-02, 1.6437e-05, 1.6437e-05],\n",
      "        [6.0605e-02, 4.3534e-02, 5.6274e-02, 1.1066e-01, 1.3381e-01, 5.3917e-01,\n",
      "         2.5721e-02, 3.0176e-02, 2.5305e-05, 2.5305e-05],\n",
      "        [5.9525e-02, 4.2921e-02, 5.5601e-02, 1.0978e-01, 1.3348e-01, 5.4072e-01,\n",
      "         2.5851e-02, 3.2057e-02, 3.3445e-05, 3.3445e-05],\n",
      "        [5.9292e-02, 4.2770e-02, 5.5501e-02, 1.0991e-01, 1.3451e-01, 5.3989e-01,\n",
      "         2.5745e-02, 3.2322e-02, 3.0883e-05, 3.0883e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 总是 担心 会 被 塔利 塔利班 发现 <EOS> <PAD>\n",
      "Reference: we always wondered what they knew about us .\n",
      "Model: <SOS> it &apos;s got kind to about about . .\n",
      "Attention Weights: tensor([[0.0025, 0.0030, 0.1330, 0.1500, 0.1601, 0.1995, 0.2789, 0.0475, 0.0176,\n",
      "         0.0079],\n",
      "        [0.0060, 0.0172, 0.1337, 0.1362, 0.1377, 0.1758, 0.2550, 0.0964, 0.0273,\n",
      "         0.0148],\n",
      "        [0.0201, 0.1061, 0.1076, 0.0875, 0.0881, 0.1178, 0.2025, 0.1951, 0.0448,\n",
      "         0.0305],\n",
      "        [0.0257, 0.1540, 0.0942, 0.0736, 0.0748, 0.1014, 0.1872, 0.2110, 0.0453,\n",
      "         0.0329],\n",
      "        [0.0286, 0.1874, 0.0845, 0.0659, 0.0673, 0.0935, 0.1802, 0.2167, 0.0431,\n",
      "         0.0327],\n",
      "        [0.0302, 0.2182, 0.0762, 0.0591, 0.0608, 0.0873, 0.1771, 0.2196, 0.0401,\n",
      "         0.0314],\n",
      "        [0.0313, 0.2363, 0.0714, 0.0554, 0.0576, 0.0858, 0.1803, 0.2139, 0.0378,\n",
      "         0.0301],\n",
      "        [0.0319, 0.2443, 0.0698, 0.0542, 0.0566, 0.0847, 0.1799, 0.2111, 0.0374,\n",
      "         0.0301],\n",
      "        [0.0316, 0.2485, 0.0684, 0.0532, 0.0557, 0.0838, 0.1803, 0.2120, 0.0368,\n",
      "         0.0297]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 187.00, Train Loss: 0.83, Val Loss: 13.09, Train BLEU: 78.30, Val BLEU: 0.39\n",
      "Sampling from training predictions...\n",
      "Source: 当 你 站 在 海滩 上 或是 当 你 看到\n",
      "Reference: part of the problem , i think , is\n",
      "Model: <SOS> part of the problem , , , , ,\n",
      "Attention Weights: tensor([[0.0259, 0.0582, 0.0944, 0.1374, 0.2400, 0.1294, 0.1378, 0.0795, 0.0570,\n",
      "         0.0403],\n",
      "        [0.0301, 0.0574, 0.0894, 0.1290, 0.2462, 0.1194, 0.1413, 0.0762, 0.0571,\n",
      "         0.0539],\n",
      "        [0.0480, 0.0640, 0.0857, 0.1131, 0.2078, 0.1047, 0.1294, 0.0780, 0.0673,\n",
      "         0.1020],\n",
      "        [0.0566, 0.0669, 0.0840, 0.1065, 0.1924, 0.0988, 0.1236, 0.0780, 0.0695,\n",
      "         0.1237],\n",
      "        [0.0529, 0.0613, 0.0782, 0.1003, 0.1973, 0.0935, 0.1250, 0.0762, 0.0697,\n",
      "         0.1455],\n",
      "        [0.0504, 0.0573, 0.0742, 0.0956, 0.1988, 0.0909, 0.1266, 0.0757, 0.0701,\n",
      "         0.1605],\n",
      "        [0.0493, 0.0557, 0.0723, 0.0935, 0.2014, 0.0893, 0.1267, 0.0747, 0.0696,\n",
      "         0.1676],\n",
      "        [0.0481, 0.0543, 0.0707, 0.0921, 0.2051, 0.0879, 0.1269, 0.0735, 0.0687,\n",
      "         0.1727],\n",
      "        [0.0475, 0.0538, 0.0703, 0.0919, 0.2061, 0.0877, 0.1272, 0.0733, 0.0685,\n",
      "         0.1737]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 所以 在 那 之后 5 年 我 <UNK> <UNK> 陪\n",
      "Reference: so for the next five years , i dressed\n",
      "Model: <SOS> we use the submarine alvin and we cameras cameras\n",
      "Attention Weights: tensor([[1.5239e-01, 1.5955e-01, 1.9458e-01, 2.4946e-01, 2.3731e-01, 5.8835e-03,\n",
      "         7.9160e-04, 2.4353e-05, 2.7653e-10, 2.7653e-10],\n",
      "        [1.4651e-01, 1.3330e-01, 1.6791e-01, 2.5136e-01, 2.6289e-01, 3.4773e-02,\n",
      "         2.9598e-03, 2.9967e-04, 2.5721e-09, 2.5721e-09],\n",
      "        [1.1148e-01, 8.3949e-02, 1.0738e-01, 1.8838e-01, 2.1206e-01, 2.7497e-01,\n",
      "         1.4531e-02, 7.2588e-03, 1.2851e-07, 1.2851e-07],\n",
      "        [7.8762e-02, 5.4901e-02, 6.8797e-02, 1.2751e-01, 1.4739e-01, 4.7961e-01,\n",
      "         2.2662e-02, 2.0362e-02, 1.5466e-06, 1.5466e-06],\n",
      "        [6.4297e-02, 4.4205e-02, 5.6894e-02, 1.1346e-01, 1.3623e-01, 5.3726e-01,\n",
      "         2.2709e-02, 2.4942e-02, 7.3408e-06, 7.3408e-06],\n",
      "        [6.3647e-02, 4.4095e-02, 5.6891e-02, 1.1226e-01, 1.3541e-01, 5.3689e-01,\n",
      "         2.3921e-02, 2.6858e-02, 1.5083e-05, 1.5083e-05],\n",
      "        [6.2604e-02, 4.4091e-02, 5.6798e-02, 1.1153e-01, 1.3411e-01, 5.3552e-01,\n",
      "         2.5245e-02, 3.0053e-02, 2.3833e-05, 2.3833e-05],\n",
      "        [6.1183e-02, 4.3229e-02, 5.5824e-02, 1.1011e-01, 1.3323e-01, 5.3908e-01,\n",
      "         2.5327e-02, 3.1953e-02, 3.1824e-05, 3.1824e-05],\n",
      "        [6.0770e-02, 4.2878e-02, 5.5510e-02, 1.0992e-01, 1.3392e-01, 5.3949e-01,\n",
      "         2.5193e-02, 3.2264e-02, 2.9940e-05, 2.9940e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 188.00, Train Loss: 0.82, Val Loss: 13.09, Train BLEU: 80.17, Val BLEU: 0.43\n",
      "Sampling from training predictions...\n",
      "Source: 其实 实地 地球 上 最长 的 山脉 都 在 海洋\n",
      "Reference: and in the oceans , there are the longest\n",
      "Model: <SOS> and in the animals , are are are are\n",
      "Attention Weights: tensor([[0.0411, 0.1147, 0.2123, 0.1065, 0.1660, 0.1179, 0.1241, 0.0534, 0.0363,\n",
      "         0.0277],\n",
      "        [0.0457, 0.1053, 0.2101, 0.0984, 0.1663, 0.1133, 0.1301, 0.0522, 0.0371,\n",
      "         0.0415],\n",
      "        [0.0649, 0.0988, 0.1833, 0.0865, 0.1453, 0.1015, 0.1256, 0.0552, 0.0458,\n",
      "         0.0931],\n",
      "        [0.0713, 0.0948, 0.1717, 0.0818, 0.1363, 0.0967, 0.1240, 0.0559, 0.0484,\n",
      "         0.1191],\n",
      "        [0.0662, 0.0888, 0.1694, 0.0757, 0.1357, 0.0932, 0.1299, 0.0523, 0.0476,\n",
      "         0.1413],\n",
      "        [0.0625, 0.0843, 0.1656, 0.0735, 0.1349, 0.0923, 0.1338, 0.0521, 0.0483,\n",
      "         0.1526],\n",
      "        [0.0611, 0.0823, 0.1665, 0.0716, 0.1351, 0.0910, 0.1348, 0.0508, 0.0474,\n",
      "         0.1595],\n",
      "        [0.0606, 0.0818, 0.1668, 0.0710, 0.1354, 0.0907, 0.1352, 0.0504, 0.0471,\n",
      "         0.1611],\n",
      "        [0.0604, 0.0817, 0.1665, 0.0711, 0.1353, 0.0907, 0.1353, 0.0506, 0.0472,\n",
      "         0.1613]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 每天 要 走 不同 的 路线 这样 才 没有\n",
      "Reference: each day , we took a different route so\n",
      "Model: <SOS> part of the problem , , , , ,\n",
      "Attention Weights: tensor([[0.0411, 0.1147, 0.2123, 0.1065, 0.1660, 0.1179, 0.1241, 0.0534, 0.0363,\n",
      "         0.0277],\n",
      "        [0.0457, 0.1053, 0.2101, 0.0984, 0.1663, 0.1133, 0.1301, 0.0522, 0.0371,\n",
      "         0.0415],\n",
      "        [0.0649, 0.0988, 0.1833, 0.0865, 0.1453, 0.1015, 0.1256, 0.0552, 0.0458,\n",
      "         0.0931],\n",
      "        [0.0713, 0.0948, 0.1717, 0.0818, 0.1363, 0.0967, 0.1240, 0.0559, 0.0484,\n",
      "         0.1191],\n",
      "        [0.0662, 0.0888, 0.1694, 0.0757, 0.1357, 0.0932, 0.1299, 0.0523, 0.0476,\n",
      "         0.1413],\n",
      "        [0.0625, 0.0843, 0.1656, 0.0735, 0.1349, 0.0923, 0.1338, 0.0521, 0.0483,\n",
      "         0.1526],\n",
      "        [0.0611, 0.0823, 0.1665, 0.0716, 0.1351, 0.0910, 0.1348, 0.0508, 0.0474,\n",
      "         0.1595],\n",
      "        [0.0606, 0.0818, 0.1668, 0.0710, 0.1354, 0.0907, 0.1352, 0.0504, 0.0471,\n",
      "         0.1611],\n",
      "        [0.0604, 0.0817, 0.1665, 0.0711, 0.1353, 0.0907, 0.1353, 0.0506, 0.0472,\n",
      "         0.1613]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 189.00, Train Loss: 0.80, Val Loss: 13.10, Train BLEU: 80.04, Val BLEU: 0.43\n",
      "Sampling from training predictions...\n",
      "Source: 我们 这 有 不少 精彩 的 泰坦 泰坦尼克 坦尼 尼克\n",
      "Reference: we &apos;ve got some of the most incredible video\n",
      "Model: <SOS> we &apos;ve got some of the most incredible video\n",
      "Attention Weights: tensor([[0.0244, 0.0588, 0.1408, 0.3001, 0.2500, 0.1606, 0.0611, 0.0028, 0.0006,\n",
      "         0.0007],\n",
      "        [0.0253, 0.0507, 0.1128, 0.2641, 0.2469, 0.1688, 0.1079, 0.0174, 0.0038,\n",
      "         0.0023],\n",
      "        [0.0253, 0.0352, 0.0635, 0.1460, 0.1807, 0.1377, 0.1818, 0.1699, 0.0501,\n",
      "         0.0098],\n",
      "        [0.0221, 0.0266, 0.0429, 0.0966, 0.1339, 0.1054, 0.1765, 0.2922, 0.0906,\n",
      "         0.0131],\n",
      "        [0.0195, 0.0228, 0.0367, 0.0840, 0.1212, 0.0968, 0.1730, 0.3367, 0.0971,\n",
      "         0.0120],\n",
      "        [0.0194, 0.0226, 0.0362, 0.0818, 0.1177, 0.0946, 0.1709, 0.3464, 0.0983,\n",
      "         0.0120],\n",
      "        [0.0193, 0.0224, 0.0359, 0.0812, 0.1174, 0.0944, 0.1716, 0.3479, 0.0980,\n",
      "         0.0120],\n",
      "        [0.0192, 0.0222, 0.0365, 0.0820, 0.1189, 0.0961, 0.1735, 0.3429, 0.0971,\n",
      "         0.0115],\n",
      "        [0.0197, 0.0227, 0.0376, 0.0831, 0.1202, 0.0970, 0.1746, 0.3398, 0.0934,\n",
      "         0.0119]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 很 幸运 幸运地 成长 在 一个 珍视 教育 也\n",
      "Reference: i was very lucky to grow up in a\n",
      "Model: <SOS> we biodiversity have have earthquakes and and the the\n",
      "Attention Weights: tensor([[1.4802e-01, 2.6968e-01, 3.2946e-01, 2.3058e-01, 2.2258e-02, 6.3249e-09,\n",
      "         6.3249e-09, 6.3249e-09, 6.3249e-09, 6.3249e-09],\n",
      "        [1.4732e-01, 2.3101e-01, 2.8375e-01, 2.6484e-01, 7.3079e-02, 3.4733e-08,\n",
      "         3.4733e-08, 3.4733e-08, 3.4733e-08, 3.4733e-08],\n",
      "        [1.0906e-01, 1.3778e-01, 1.8262e-01, 2.9194e-01, 2.7858e-01, 1.0515e-06,\n",
      "         1.0515e-06, 1.0515e-06, 1.0515e-06, 1.0515e-06],\n",
      "        [9.8228e-02, 1.1329e-01, 1.4758e-01, 2.6211e-01, 3.7868e-01, 1.9754e-05,\n",
      "         1.9754e-05, 1.9754e-05, 1.9754e-05, 1.9754e-05],\n",
      "        [8.6627e-02, 9.5947e-02, 1.2602e-01, 2.5412e-01, 4.3681e-01, 9.5899e-05,\n",
      "         9.5899e-05, 9.5899e-05, 9.5899e-05, 9.5899e-05],\n",
      "        [8.2997e-02, 9.1656e-02, 1.1868e-01, 2.3987e-01, 4.6575e-01, 2.0855e-04,\n",
      "         2.0855e-04, 2.0855e-04, 2.0855e-04, 2.0855e-04],\n",
      "        [8.2146e-02, 9.0630e-02, 1.1668e-01, 2.3567e-01, 4.7367e-01, 2.4323e-04,\n",
      "         2.4323e-04, 2.4323e-04, 2.4323e-04, 2.4323e-04],\n",
      "        [8.2364e-02, 9.0817e-02, 1.1683e-01, 2.3572e-01, 4.7294e-01, 2.6706e-04,\n",
      "         2.6706e-04, 2.6706e-04, 2.6706e-04, 2.6706e-04],\n",
      "        [8.2773e-02, 9.1179e-02, 1.1728e-01, 2.3617e-01, 4.7126e-01, 2.6742e-04,\n",
      "         2.6742e-04, 2.6742e-04, 2.6742e-04, 2.6742e-04]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 190.00, Train Loss: 0.79, Val Loss: 13.11, Train BLEU: 80.04, Val BLEU: 0.45\n",
      "Sampling from training predictions...\n",
      "Source: 大部 大部分 部分 的 动物 也 都 生活 在 海洋\n",
      "Reference: most of the animals are in the oceans .\n",
      "Model: <SOS> most of the animals are the the are the\n",
      "Attention Weights: tensor([[0.0637, 0.2173, 0.1792, 0.1138, 0.1505, 0.0622, 0.0583, 0.0901, 0.0402,\n",
      "         0.0248],\n",
      "        [0.0713, 0.1926, 0.1740, 0.1076, 0.1561, 0.0604, 0.0569, 0.0991, 0.0424,\n",
      "         0.0396],\n",
      "        [0.1057, 0.1775, 0.1468, 0.0909, 0.1339, 0.0573, 0.0548, 0.1018, 0.0495,\n",
      "         0.0819],\n",
      "        [0.1160, 0.1696, 0.1365, 0.0856, 0.1264, 0.0564, 0.0543, 0.1025, 0.0516,\n",
      "         0.1010],\n",
      "        [0.1091, 0.1578, 0.1339, 0.0814, 0.1297, 0.0519, 0.0500, 0.1094, 0.0533,\n",
      "         0.1234],\n",
      "        [0.1025, 0.1492, 0.1322, 0.0797, 0.1321, 0.0507, 0.0487, 0.1137, 0.0552,\n",
      "         0.1361],\n",
      "        [0.1020, 0.1486, 0.1319, 0.0785, 0.1326, 0.0498, 0.0477, 0.1143, 0.0548,\n",
      "         0.1397],\n",
      "        [0.1017, 0.1479, 0.1319, 0.0784, 0.1328, 0.0498, 0.0477, 0.1148, 0.0548,\n",
      "         0.1403],\n",
      "        [0.1016, 0.1479, 0.1322, 0.0783, 0.1331, 0.0495, 0.0474, 0.1149, 0.0546,\n",
      "         0.1406]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 塔利 塔利班 走 了 父亲 大声 叫 着 <EOS> <PAD>\n",
      "Reference: &quot; the taliban are gone ! &quot; my father\n",
      "Model: <SOS> most of the planet is ocean . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0134, 0.0297, 0.0590, 0.1633, 0.2038, 0.1762, 0.1542, 0.1240, 0.0602,\n",
      "         0.0162],\n",
      "        [0.0162, 0.0304, 0.0551, 0.1586, 0.2039, 0.1713, 0.1510, 0.1240, 0.0672,\n",
      "         0.0223],\n",
      "        [0.0262, 0.0339, 0.0500, 0.1329, 0.1930, 0.1607, 0.1423, 0.1225, 0.0870,\n",
      "         0.0514],\n",
      "        [0.0318, 0.0364, 0.0492, 0.1223, 0.1850, 0.1549, 0.1378, 0.1216, 0.0948,\n",
      "         0.0662],\n",
      "        [0.0295, 0.0331, 0.0457, 0.1216, 0.1899, 0.1564, 0.1381, 0.1214, 0.0950,\n",
      "         0.0693],\n",
      "        [0.0272, 0.0302, 0.0427, 0.1204, 0.1930, 0.1577, 0.1390, 0.1226, 0.0961,\n",
      "         0.0712],\n",
      "        [0.0261, 0.0288, 0.0411, 0.1196, 0.1955, 0.1584, 0.1393, 0.1229, 0.0961,\n",
      "         0.0721],\n",
      "        [0.0258, 0.0281, 0.0401, 0.1185, 0.1974, 0.1590, 0.1391, 0.1227, 0.0963,\n",
      "         0.0730],\n",
      "        [0.0252, 0.0272, 0.0389, 0.1185, 0.2005, 0.1601, 0.1392, 0.1226, 0.0956,\n",
      "         0.0722]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 191.00, Train Loss: 0.78, Val Loss: 13.11, Train BLEU: 79.78, Val BLEU: 0.41\n",
      "Sampling from training predictions...\n",
      "Source: 还有 这些 摇晃 着 旋转 转着 的 触角 <EOS> <PAD>\n",
      "Reference: it &apos;s got tentacles dangling , swirling around like\n",
      "Model: <SOS> it &apos;s got tentacles dangling , swirling around like\n",
      "Attention Weights: tensor([[7.7244e-02, 1.7028e-01, 2.0916e-01, 2.1447e-01, 2.8408e-01, 3.3307e-02,\n",
      "         6.0463e-03, 4.2268e-03, 1.1896e-03, 2.0122e-10],\n",
      "        [8.0110e-02, 1.4813e-01, 1.8634e-01, 1.9399e-01, 2.9973e-01, 7.3016e-02,\n",
      "         8.9189e-03, 6.7474e-03, 3.0207e-03, 8.6300e-10],\n",
      "        [7.5967e-02, 1.0273e-01, 1.2979e-01, 1.3293e-01, 2.3728e-01, 2.6536e-01,\n",
      "         1.7389e-02, 1.6234e-02, 2.2313e-02, 1.1953e-07],\n",
      "        [7.5220e-02, 8.8837e-02, 1.0797e-01, 1.0903e-01, 1.9213e-01, 3.4446e-01,\n",
      "         2.3223e-02, 2.1880e-02, 3.7245e-02, 2.8354e-06],\n",
      "        [6.5956e-02, 7.6643e-02, 9.5540e-02, 9.8010e-02, 1.8607e-01, 3.9342e-01,\n",
      "         2.0536e-02, 2.0372e-02, 4.3440e-02, 1.7896e-05],\n",
      "        [5.9068e-02, 6.8034e-02, 8.6440e-02, 8.9701e-02, 1.8088e-01, 4.2941e-01,\n",
      "         1.9960e-02, 2.0723e-02, 4.5732e-02, 4.9964e-05],\n",
      "        [5.2209e-02, 5.9910e-02, 7.6610e-02, 7.9805e-02, 1.6720e-01, 4.7760e-01,\n",
      "         1.9358e-02, 2.0129e-02, 4.7102e-02, 7.4839e-05],\n",
      "        [4.7613e-02, 5.4555e-02, 7.0340e-02, 7.3646e-02, 1.6058e-01, 5.0406e-01,\n",
      "         1.9144e-02, 2.0125e-02, 4.9840e-02, 1.0136e-04],\n",
      "        [4.6358e-02, 5.3283e-02, 6.9298e-02, 7.2617e-02, 1.6012e-01, 5.0887e-01,\n",
      "         1.9102e-02, 2.0159e-02, 5.0098e-02, 9.3965e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 祖父 在 他 的 年代 是 位非 非凡\n",
      "Reference: my grandfather was an extraordinary man for his time\n",
      "Model: <SOS> and we &apos;re &apos;re going , the stories stories\n",
      "Attention Weights: tensor([[0.0430, 0.0889, 0.1277, 0.1754, 0.1664, 0.1680, 0.1032, 0.0732, 0.0477,\n",
      "         0.0065],\n",
      "        [0.0490, 0.0862, 0.1197, 0.1678, 0.1576, 0.1700, 0.1004, 0.0740, 0.0568,\n",
      "         0.0185],\n",
      "        [0.0608, 0.0769, 0.0968, 0.1297, 0.1204, 0.1433, 0.0886, 0.0758, 0.0762,\n",
      "         0.1317],\n",
      "        [0.0655, 0.0742, 0.0888, 0.1141, 0.1063, 0.1285, 0.0824, 0.0742, 0.0797,\n",
      "         0.1864],\n",
      "        [0.0609, 0.0683, 0.0825, 0.1073, 0.1000, 0.1244, 0.0799, 0.0737, 0.0839,\n",
      "         0.2189],\n",
      "        [0.0557, 0.0608, 0.0735, 0.0976, 0.0908, 0.1196, 0.0767, 0.0724, 0.0862,\n",
      "         0.2668],\n",
      "        [0.0525, 0.0561, 0.0678, 0.0909, 0.0848, 0.1156, 0.0738, 0.0701, 0.0852,\n",
      "         0.3031],\n",
      "        [0.0489, 0.0522, 0.0633, 0.0854, 0.0797, 0.1121, 0.0710, 0.0677, 0.0831,\n",
      "         0.3365],\n",
      "        [0.0472, 0.0505, 0.0613, 0.0832, 0.0775, 0.1108, 0.0697, 0.0666, 0.0826,\n",
      "         0.3506]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 192.00, Train Loss: 0.76, Val Loss: 13.12, Train BLEU: 80.88, Val BLEU: 0.39\n",
      "Sampling from training predictions...\n",
      "Source: 地球 的 大部 大部分 部分 都 是 海水 <EOS> <PAD>\n",
      "Reference: most of the planet is ocean water . <EOS>\n",
      "Model: <SOS> most of the planet is ocean . <EOS> <EOS>\n",
      "Attention Weights: tensor([[8.6427e-02, 2.1368e-01, 4.3401e-01, 2.1584e-01, 3.5153e-02, 8.3219e-03,\n",
      "         4.6086e-03, 1.9011e-03, 6.4937e-05, 5.4844e-11],\n",
      "        [9.6171e-02, 1.7502e-01, 3.9291e-01, 2.6523e-01, 4.6945e-02, 1.0768e-02,\n",
      "         6.8519e-03, 5.3430e-03, 7.5443e-04, 1.4054e-09],\n",
      "        [1.2341e-01, 1.5265e-01, 3.2225e-01, 2.7888e-01, 6.2717e-02, 1.6909e-02,\n",
      "         1.3086e-02, 1.9456e-02, 1.0645e-02, 2.2506e-07],\n",
      "        [1.3045e-01, 1.4133e-01, 2.9623e-01, 2.8001e-01, 6.7480e-02, 1.8527e-02,\n",
      "         1.5086e-02, 2.7835e-02, 2.3057e-02, 2.3925e-06],\n",
      "        [1.2345e-01, 1.3138e-01, 2.8409e-01, 2.8433e-01, 6.9549e-02, 1.7823e-02,\n",
      "         1.5563e-02, 3.7730e-02, 3.6081e-02, 6.8213e-06],\n",
      "        [1.1684e-01, 1.2263e-01, 2.6685e-01, 2.8715e-01, 7.4045e-02, 1.8697e-02,\n",
      "         1.6998e-02, 4.6818e-02, 4.9953e-02, 1.3406e-05],\n",
      "        [1.0994e-01, 1.1484e-01, 2.5615e-01, 2.8832e-01, 7.5430e-02, 1.9263e-02,\n",
      "         1.7822e-02, 5.4018e-02, 6.4200e-02, 2.2973e-05],\n",
      "        [1.0802e-01, 1.1257e-01, 2.5141e-01, 2.8714e-01, 7.6175e-02, 1.9938e-02,\n",
      "         1.8586e-02, 5.7084e-02, 6.9056e-02, 2.7299e-05],\n",
      "        [1.0768e-01, 1.1215e-01, 2.5047e-01, 2.8628e-01, 7.6347e-02, 2.0078e-02,\n",
      "         1.8746e-02, 5.7862e-02, 7.0354e-02, 2.7901e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 你 现在 可以 去 个 真正 的 学校 念书 了\n",
      "Reference: &quot; you can go to a real school now\n",
      "Model: <SOS> people &apos;s have partnered standing , there there there\n",
      "Attention Weights: tensor([[0.0185, 0.0139, 0.0101, 0.0188, 0.0983, 0.1160, 0.1771, 0.2042, 0.1785,\n",
      "         0.1646],\n",
      "        [0.0253, 0.0310, 0.0220, 0.0396, 0.1087, 0.1154, 0.1589, 0.1751, 0.1562,\n",
      "         0.1678],\n",
      "        [0.0495, 0.1417, 0.0933, 0.1309, 0.0977, 0.0839, 0.0964, 0.0995, 0.0926,\n",
      "         0.1145],\n",
      "        [0.0514, 0.2362, 0.1398, 0.1704, 0.0744, 0.0585, 0.0624, 0.0633, 0.0608,\n",
      "         0.0828],\n",
      "        [0.0507, 0.2976, 0.1710, 0.1844, 0.0573, 0.0439, 0.0451, 0.0449, 0.0436,\n",
      "         0.0615],\n",
      "        [0.0508, 0.4042, 0.2075, 0.1748, 0.0309, 0.0227, 0.0228, 0.0232, 0.0235,\n",
      "         0.0396],\n",
      "        [0.0515, 0.4299, 0.2146, 0.1677, 0.0254, 0.0182, 0.0183, 0.0190, 0.0197,\n",
      "         0.0358],\n",
      "        [0.0509, 0.4400, 0.2164, 0.1655, 0.0238, 0.0169, 0.0169, 0.0175, 0.0183,\n",
      "         0.0338],\n",
      "        [0.0507, 0.4416, 0.2163, 0.1650, 0.0235, 0.0167, 0.0167, 0.0174, 0.0182,\n",
      "         0.0339]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 193.00, Train Loss: 0.75, Val Loss: 13.13, Train BLEU: 81.18, Val BLEU: 0.42\n",
      "Sampling from training predictions...\n",
      "Source: 它 可以 伸展 <UNK> 150 英尺 长 <EOS> <PAD> <PAD>\n",
      "Reference: it gets up to about 150 feet long .\n",
      "Model: <SOS> it gets up to about 150 feet long .\n",
      "Attention Weights: tensor([[1.5049e-01, 5.7964e-01, 2.6773e-01, 1.5140e-04, 4.1269e-05, 6.5498e-04,\n",
      "         8.4910e-04, 4.3930e-04, 5.7636e-10, 5.7636e-10],\n",
      "        [1.2509e-01, 5.2647e-01, 3.4555e-01, 3.8458e-04, 9.1270e-05, 8.7323e-04,\n",
      "         8.7410e-04, 6.6142e-04, 1.1394e-09, 1.1394e-09],\n",
      "        [8.9109e-02, 3.6772e-01, 5.1236e-01, 1.6995e-02, 3.5770e-03, 2.7589e-03,\n",
      "         2.4024e-03, 5.0718e-03, 3.6565e-08, 3.6565e-08],\n",
      "        [7.5086e-02, 2.6899e-01, 5.1553e-01, 9.7374e-02, 2.0019e-02, 5.9784e-03,\n",
      "         4.8763e-03, 1.2149e-02, 7.8250e-07, 7.8250e-07],\n",
      "        [6.9723e-02, 2.3460e-01, 4.8860e-01, 1.5039e-01, 2.9550e-02, 6.8689e-03,\n",
      "         5.7771e-03, 1.4487e-02, 2.5221e-06, 2.5221e-06],\n",
      "        [6.2958e-02, 2.1304e-01, 4.7717e-01, 1.8540e-01, 3.4366e-02, 6.7263e-03,\n",
      "         5.7553e-03, 1.4574e-02, 5.3794e-06, 5.3794e-06],\n",
      "        [5.7179e-02, 1.9693e-01, 4.6334e-01, 2.1478e-01, 3.9470e-02, 6.9167e-03,\n",
      "         5.8733e-03, 1.5485e-02, 9.1316e-06, 9.1316e-06],\n",
      "        [5.3064e-02, 1.8276e-01, 4.5157e-01, 2.3962e-01, 4.3675e-02, 7.0810e-03,\n",
      "         5.9808e-03, 1.6218e-02, 1.4068e-05, 1.4068e-05],\n",
      "        [4.8730e-02, 1.7105e-01, 4.4358e-01, 2.6128e-01, 4.5982e-02, 6.9892e-03,\n",
      "         5.8694e-03, 1.6471e-02, 2.1907e-05, 2.1907e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我们 把 书 放在 食品 杂货 袋中 这样 别人 就\n",
      "Reference: we would cover our books in grocery bags so\n",
      "Model: <SOS> people when mostly partnered standing , given there there\n",
      "Attention Weights: tensor([[0.0526, 0.2076, 0.2061, 0.1252, 0.1519, 0.0597, 0.0541, 0.0866, 0.0349,\n",
      "         0.0213],\n",
      "        [0.0581, 0.1852, 0.1983, 0.1197, 0.1610, 0.0582, 0.0533, 0.0961, 0.0371,\n",
      "         0.0330],\n",
      "        [0.0896, 0.1791, 0.1708, 0.1023, 0.1407, 0.0553, 0.0517, 0.0980, 0.0444,\n",
      "         0.0680],\n",
      "        [0.1005, 0.1720, 0.1596, 0.0961, 0.1333, 0.0551, 0.0519, 0.0990, 0.0474,\n",
      "         0.0852],\n",
      "        [0.0963, 0.1619, 0.1567, 0.0918, 0.1368, 0.0500, 0.0470, 0.1046, 0.0483,\n",
      "         0.1066],\n",
      "        [0.0903, 0.1511, 0.1538, 0.0894, 0.1402, 0.0483, 0.0450, 0.1096, 0.0502,\n",
      "         0.1221],\n",
      "        [0.0896, 0.1493, 0.1530, 0.0880, 0.1407, 0.0474, 0.0441, 0.1107, 0.0501,\n",
      "         0.1270],\n",
      "        [0.0893, 0.1486, 0.1528, 0.0879, 0.1410, 0.0474, 0.0441, 0.1112, 0.0502,\n",
      "         0.1277],\n",
      "        [0.0893, 0.1487, 0.1533, 0.0879, 0.1413, 0.0470, 0.0438, 0.1112, 0.0498,\n",
      "         0.1276]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 194.00, Train Loss: 0.74, Val Loss: 13.13, Train BLEU: 81.72, Val BLEU: 0.39\n",
      "Sampling from training predictions...\n",
      "Source: 泰坦 泰坦尼克 泰坦尼克号 坦尼 尼克 号 是 拿 了 不少\n",
      "Reference: the truth of the matter is that the titanic\n",
      "Model: <SOS> the truth of the matter is the titanic titanic\n",
      "Attention Weights: tensor([[0.0186, 0.0144, 0.0104, 0.0189, 0.0966, 0.1155, 0.1773, 0.2041, 0.1791,\n",
      "         0.1651],\n",
      "        [0.0250, 0.0307, 0.0218, 0.0387, 0.1068, 0.1153, 0.1600, 0.1763, 0.1576,\n",
      "         0.1678],\n",
      "        [0.0482, 0.1382, 0.0930, 0.1292, 0.0973, 0.0845, 0.0983, 0.1017, 0.0945,\n",
      "         0.1153],\n",
      "        [0.0496, 0.2276, 0.1379, 0.1685, 0.0762, 0.0606, 0.0653, 0.0662, 0.0634,\n",
      "         0.0847],\n",
      "        [0.0490, 0.2836, 0.1684, 0.1847, 0.0605, 0.0467, 0.0483, 0.0481, 0.0467,\n",
      "         0.0640],\n",
      "        [0.0494, 0.3941, 0.2084, 0.1776, 0.0326, 0.0241, 0.0242, 0.0245, 0.0248,\n",
      "         0.0403],\n",
      "        [0.0498, 0.4259, 0.2172, 0.1695, 0.0257, 0.0185, 0.0187, 0.0193, 0.0200,\n",
      "         0.0354],\n",
      "        [0.0492, 0.4392, 0.2194, 0.1666, 0.0235, 0.0168, 0.0168, 0.0173, 0.0182,\n",
      "         0.0330],\n",
      "        [0.0488, 0.4422, 0.2193, 0.1655, 0.0232, 0.0165, 0.0166, 0.0172, 0.0180,\n",
      "         0.0328]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 那 就是 她 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: there she is . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> here &apos;s a kind stuff . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.1201e-01, 2.1555e-01, 1.9470e-01, 1.6447e-01, 1.3589e-01, 1.0493e-01,\n",
      "         4.6708e-02, 2.1866e-02, 3.8776e-03, 3.8923e-10],\n",
      "        [1.2783e-01, 2.0678e-01, 1.8497e-01, 1.5860e-01, 1.3289e-01, 1.0744e-01,\n",
      "         4.8081e-02, 2.5912e-02, 7.4990e-03, 1.1252e-09],\n",
      "        [1.3205e-01, 1.5852e-01, 1.4812e-01, 1.3505e-01, 1.2412e-01, 1.2877e-01,\n",
      "         6.5891e-02, 5.0833e-02, 5.6651e-02, 1.7971e-07],\n",
      "        [1.3458e-01, 1.4362e-01, 1.3416e-01, 1.2303e-01, 1.1581e-01, 1.2644e-01,\n",
      "         6.9546e-02, 5.8721e-02, 9.4094e-02, 4.1332e-06],\n",
      "        [1.2769e-01, 1.3334e-01, 1.2488e-01, 1.1478e-01, 1.0908e-01, 1.2883e-01,\n",
      "         7.0276e-02, 6.3272e-02, 1.2783e-01, 1.7033e-05],\n",
      "        [1.2098e-01, 1.2578e-01, 1.1860e-01, 1.0969e-01, 1.0519e-01, 1.3175e-01,\n",
      "         7.1729e-02, 6.7879e-02, 1.4836e-01, 3.6472e-05],\n",
      "        [1.1423e-01, 1.1773e-01, 1.1226e-01, 1.0491e-01, 1.0156e-01, 1.3230e-01,\n",
      "         7.3349e-02, 7.1541e-02, 1.7204e-01, 6.2311e-05],\n",
      "        [1.0678e-01, 1.0946e-01, 1.0537e-01, 9.9554e-02, 9.7347e-02, 1.3064e-01,\n",
      "         7.3699e-02, 7.4169e-02, 2.0287e-01, 1.1057e-04],\n",
      "        [1.0339e-01, 1.0592e-01, 1.0239e-01, 9.7152e-02, 9.5522e-02, 1.2996e-01,\n",
      "         7.4042e-02, 7.5120e-02, 2.1637e-01, 1.3577e-04]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 195.00, Train Loss: 0.72, Val Loss: 13.12, Train BLEU: 82.03, Val BLEU: 0.40\n",
      "Sampling from training predictions...\n",
      "Source: 我们 得用 非常 特殊 的 仪器 才能 能到 到达 那个\n",
      "Reference: we have to have a very special technology to\n",
      "Model: <SOS> we have to have a very special technology technology\n",
      "Attention Weights: tensor([[0.0020, 0.0032, 0.1169, 0.1384, 0.1486, 0.1988, 0.3226, 0.0498, 0.0140,\n",
      "         0.0059],\n",
      "        [0.0046, 0.0154, 0.1189, 0.1278, 0.1314, 0.1785, 0.3006, 0.0908, 0.0213,\n",
      "         0.0106],\n",
      "        [0.0143, 0.0882, 0.1060, 0.0920, 0.0939, 0.1284, 0.2324, 0.1836, 0.0380,\n",
      "         0.0232],\n",
      "        [0.0198, 0.1296, 0.0981, 0.0810, 0.0833, 0.1126, 0.2076, 0.1986, 0.0418,\n",
      "         0.0276],\n",
      "        [0.0234, 0.1684, 0.0873, 0.0715, 0.0742, 0.1025, 0.1967, 0.2072, 0.0406,\n",
      "         0.0283],\n",
      "        [0.0255, 0.2084, 0.0764, 0.0619, 0.0646, 0.0926, 0.1900, 0.2159, 0.0375,\n",
      "         0.0272],\n",
      "        [0.0264, 0.2416, 0.0677, 0.0542, 0.0570, 0.0859, 0.1893, 0.2185, 0.0341,\n",
      "         0.0253],\n",
      "        [0.0267, 0.2685, 0.0620, 0.0493, 0.0522, 0.0801, 0.1851, 0.2196, 0.0321,\n",
      "         0.0244],\n",
      "        [0.0266, 0.2775, 0.0598, 0.0475, 0.0505, 0.0781, 0.1840, 0.2207, 0.0313,\n",
      "         0.0239]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 学校 在 一个 房屋 房屋里 屋里 我们 100 多 人\n",
      "Reference: the school was in a house , more than\n",
      "Model: <SOS> the biodiversity the the the and the the the\n",
      "Attention Weights: tensor([[0.0416, 0.2428, 0.1625, 0.1738, 0.1169, 0.1546, 0.0627, 0.0184, 0.0147,\n",
      "         0.0119],\n",
      "        [0.0415, 0.3214, 0.1283, 0.1459, 0.0980, 0.1551, 0.0637, 0.0175, 0.0142,\n",
      "         0.0144],\n",
      "        [0.0610, 0.4449, 0.0921, 0.0991, 0.0666, 0.1243, 0.0583, 0.0177, 0.0155,\n",
      "         0.0204],\n",
      "        [0.0627, 0.4793, 0.0844, 0.0885, 0.0592, 0.1145, 0.0561, 0.0180, 0.0158,\n",
      "         0.0216],\n",
      "        [0.0603, 0.4795, 0.0829, 0.0887, 0.0585, 0.1170, 0.0573, 0.0173, 0.0154,\n",
      "         0.0230],\n",
      "        [0.0604, 0.4310, 0.0852, 0.0950, 0.0627, 0.1342, 0.0682, 0.0182, 0.0163,\n",
      "         0.0288],\n",
      "        [0.0593, 0.4220, 0.0843, 0.0955, 0.0630, 0.1393, 0.0713, 0.0181, 0.0165,\n",
      "         0.0308],\n",
      "        [0.0575, 0.4293, 0.0821, 0.0938, 0.0610, 0.1417, 0.0708, 0.0175, 0.0159,\n",
      "         0.0305],\n",
      "        [0.0571, 0.4292, 0.0820, 0.0937, 0.0608, 0.1425, 0.0709, 0.0173, 0.0158,\n",
      "         0.0306]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 196.00, Train Loss: 0.71, Val Loss: 13.13, Train BLEU: 82.10, Val BLEU: 0.40\n",
      "Sampling from training predictions...\n",
      "Source: 深海 海中 的 生命 大卫 <UNK> <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: life in the deep oceans <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> life in the deep oceans <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.8588e-01, 2.5818e-01, 2.3456e-01, 2.7884e-01, 4.2508e-02, 2.3759e-05,\n",
      "         2.8757e-06, 2.0830e-09, 2.0830e-09, 2.0830e-09],\n",
      "        [1.9538e-01, 2.2674e-01, 2.0537e-01, 3.1310e-01, 5.9384e-02, 2.1790e-05,\n",
      "         2.7449e-06, 2.3538e-09, 2.3538e-09, 2.3538e-09],\n",
      "        [1.5192e-01, 1.5832e-01, 1.5891e-01, 3.3651e-01, 1.9235e-01, 1.7643e-03,\n",
      "         2.3132e-04, 8.7504e-08, 8.7504e-08, 8.7504e-08],\n",
      "        [1.1866e-01, 1.0539e-01, 1.0804e-01, 2.7420e-01, 3.6765e-01, 2.2931e-02,\n",
      "         3.1204e-03, 1.4173e-06, 1.4173e-06, 1.4173e-06],\n",
      "        [8.1266e-02, 7.1763e-02, 7.9111e-02, 2.3733e-01, 4.6860e-01, 5.5044e-02,\n",
      "         6.8720e-03, 4.0814e-06, 4.0814e-06, 4.0814e-06],\n",
      "        [6.7157e-02, 5.8841e-02, 6.6574e-02, 2.0914e-01, 4.9619e-01, 9.0454e-02,\n",
      "         1.1616e-02, 8.5400e-06, 8.5400e-06, 8.5400e-06],\n",
      "        [5.8136e-02, 5.0597e-02, 5.8140e-02, 1.8604e-01, 4.9108e-01, 1.3762e-01,\n",
      "         1.8333e-02, 1.6326e-05, 1.6326e-05, 1.6326e-05],\n",
      "        [5.8080e-02, 5.0567e-02, 5.8097e-02, 1.8500e-01, 4.8911e-01, 1.4015e-01,\n",
      "         1.8954e-02, 1.6707e-05, 1.6707e-05, 1.6707e-05],\n",
      "        [5.8254e-02, 5.0739e-02, 5.8251e-02, 1.8490e-01, 4.8766e-01, 1.4108e-01,\n",
      "         1.9055e-02, 1.6754e-05, 1.6754e-05, 1.6754e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 父亲 那 就是 他 他 是 他家 家族\n",
      "Reference: and my father -- that &apos;s him -- he\n",
      "Model: <SOS> part of the problem , , , are are\n",
      "Attention Weights: tensor([[0.0332, 0.0835, 0.1482, 0.1094, 0.0006, 0.0893, 0.2769, 0.1442, 0.0952,\n",
      "         0.0195],\n",
      "        [0.0362, 0.0787, 0.1574, 0.1664, 0.0044, 0.0949, 0.2331, 0.1145, 0.0822,\n",
      "         0.0322],\n",
      "        [0.0395, 0.0621, 0.1290, 0.2706, 0.1208, 0.0749, 0.1302, 0.0545, 0.0462,\n",
      "         0.0721],\n",
      "        [0.0357, 0.0492, 0.0961, 0.2394, 0.2706, 0.0635, 0.0955, 0.0407, 0.0359,\n",
      "         0.0736],\n",
      "        [0.0338, 0.0459, 0.0906, 0.2257, 0.3241, 0.0542, 0.0811, 0.0345, 0.0322,\n",
      "         0.0777],\n",
      "        [0.0316, 0.0421, 0.0819, 0.2086, 0.3732, 0.0481, 0.0726, 0.0306, 0.0289,\n",
      "         0.0825],\n",
      "        [0.0281, 0.0372, 0.0737, 0.2042, 0.4169, 0.0412, 0.0623, 0.0264, 0.0255,\n",
      "         0.0845],\n",
      "        [0.0243, 0.0321, 0.0660, 0.2047, 0.4581, 0.0342, 0.0525, 0.0220, 0.0218,\n",
      "         0.0842],\n",
      "        [0.0226, 0.0300, 0.0624, 0.2061, 0.4730, 0.0319, 0.0495, 0.0204, 0.0204,\n",
      "         0.0836]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 197.00, Train Loss: 0.70, Val Loss: 13.15, Train BLEU: 82.64, Val BLEU: 0.39\n",
      "Sampling from training predictions...\n",
      "Source: 原来 它 是 海洋 洋中 最长 的 生物 <EOS> <PAD>\n",
      "Reference: this turns out to be the longest creature in\n",
      "Model: <SOS> this turns out to be the longest creature creature\n",
      "Attention Weights: tensor([[4.8328e-02, 1.2098e-01, 2.8613e-01, 5.0714e-01, 1.3819e-02, 6.6974e-03,\n",
      "         5.9994e-03, 6.5378e-03, 4.3709e-03, 2.9266e-10],\n",
      "        [3.9302e-02, 8.3088e-02, 1.9390e-01, 5.8637e-01, 6.4239e-02, 8.7685e-03,\n",
      "         7.1344e-03, 8.2381e-03, 8.9643e-03, 1.4733e-09],\n",
      "        [2.4978e-02, 3.9351e-02, 8.2731e-02, 4.2723e-01, 3.6935e-01, 1.1398e-02,\n",
      "         7.9640e-03, 1.1111e-02, 2.5890e-02, 1.0662e-07],\n",
      "        [1.9049e-02, 2.5804e-02, 4.9014e-02, 2.9699e-01, 5.4744e-01, 1.1747e-02,\n",
      "         7.9321e-03, 1.1040e-02, 3.0980e-02, 1.7140e-06],\n",
      "        [1.4106e-02, 1.8388e-02, 3.6277e-02, 2.5449e-01, 6.2739e-01, 8.1175e-03,\n",
      "         5.7763e-03, 8.2720e-03, 2.7181e-02, 5.2715e-06],\n",
      "        [1.2266e-02, 1.5715e-02, 3.1586e-02, 2.3174e-01, 6.6402e-01, 6.9555e-03,\n",
      "         5.0647e-03, 7.4166e-03, 2.5219e-02, 1.0265e-05],\n",
      "        [1.0378e-02, 1.2984e-02, 2.5734e-02, 2.1270e-01, 6.9713e-01, 6.2858e-03,\n",
      "         4.6177e-03, 6.6651e-03, 2.3491e-02, 1.8269e-05],\n",
      "        [1.0062e-02, 1.2488e-02, 2.4836e-02, 2.1098e-01, 6.9928e-01, 6.2729e-03,\n",
      "         4.5518e-03, 6.6673e-03, 2.4836e-02, 2.7499e-05],\n",
      "        [1.0012e-02, 1.2407e-02, 2.4796e-02, 2.1546e-01, 6.9309e-01, 6.4176e-03,\n",
      "         4.6741e-03, 6.9024e-03, 2.6215e-02, 3.0127e-05]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 那 就是 她 <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: there she is . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> here &apos;s a kind stuff . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[1.0962e-01, 2.1025e-01, 1.9584e-01, 1.6506e-01, 1.3463e-01, 1.1274e-01,\n",
      "         4.5922e-02, 2.1600e-02, 4.3605e-03, 4.3122e-10],\n",
      "        [1.2682e-01, 2.0167e-01, 1.8581e-01, 1.5919e-01, 1.3170e-01, 1.1392e-01,\n",
      "         4.6835e-02, 2.5584e-02, 8.4843e-03, 1.1570e-09],\n",
      "        [1.3003e-01, 1.5479e-01, 1.4769e-01, 1.3451e-01, 1.2289e-01, 1.3476e-01,\n",
      "         6.3809e-02, 4.9381e-02, 6.2141e-02, 1.8932e-07],\n",
      "        [1.3319e-01, 1.4186e-01, 1.3460e-01, 1.2331e-01, 1.1535e-01, 1.2990e-01,\n",
      "         6.7641e-02, 5.6647e-02, 9.7503e-02, 4.2316e-06],\n",
      "        [1.2702e-01, 1.3233e-01, 1.2549e-01, 1.1505e-01, 1.0857e-01, 1.3157e-01,\n",
      "         6.8285e-02, 6.0806e-02, 1.3085e-01, 1.7271e-05],\n",
      "        [1.2037e-01, 1.2517e-01, 1.1941e-01, 1.1009e-01, 1.0482e-01, 1.3441e-01,\n",
      "         6.9877e-02, 6.5483e-02, 1.5033e-01, 3.6336e-05],\n",
      "        [1.1268e-01, 1.1634e-01, 1.1210e-01, 1.0447e-01, 1.0053e-01, 1.3504e-01,\n",
      "         7.1754e-02, 6.9644e-02, 1.7738e-01, 6.5102e-05],\n",
      "        [1.0381e-01, 1.0687e-01, 1.0404e-01, 9.8169e-02, 9.5575e-02, 1.3284e-01,\n",
      "         7.2349e-02, 7.2896e-02, 2.1333e-01, 1.2174e-04],\n",
      "        [9.9788e-02, 1.0257e-01, 1.0033e-01, 9.5116e-02, 9.3185e-02, 1.3193e-01,\n",
      "         7.2656e-02, 7.4038e-02, 2.3024e-01, 1.5224e-04]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "\n",
      "Epoch: 198.00, Train Loss: 0.69, Val Loss: 13.16, Train BLEU: 83.61, Val BLEU: 0.39\n",
      "Sampling from training predictions...\n",
      "Source: 底下 这些 都 是 <UNK> 它们 上上 上上下下 上下 下下\n",
      "Reference: it &apos;s got these fishing <UNK> on the bottom\n",
      "Model: <SOS> it &apos;s got these fishing <UNK> on the bottom\n",
      "Attention Weights: tensor([[0.0312, 0.0800, 0.1473, 0.1145, 0.0007, 0.0891, 0.2857, 0.1386, 0.0915,\n",
      "         0.0214],\n",
      "        [0.0336, 0.0744, 0.1554, 0.1764, 0.0055, 0.0939, 0.2382, 0.1087, 0.0785,\n",
      "         0.0355],\n",
      "        [0.0353, 0.0563, 0.1224, 0.2786, 0.1417, 0.0713, 0.1275, 0.0498, 0.0425,\n",
      "         0.0748],\n",
      "        [0.0311, 0.0435, 0.0884, 0.2400, 0.3059, 0.0586, 0.0904, 0.0365, 0.0323,\n",
      "         0.0733],\n",
      "        [0.0294, 0.0405, 0.0833, 0.2254, 0.3584, 0.0496, 0.0763, 0.0308, 0.0289,\n",
      "         0.0773],\n",
      "        [0.0271, 0.0367, 0.0746, 0.2062, 0.4111, 0.0432, 0.0674, 0.0268, 0.0255,\n",
      "         0.0814],\n",
      "        [0.0240, 0.0322, 0.0663, 0.1999, 0.4563, 0.0364, 0.0569, 0.0228, 0.0222,\n",
      "         0.0828],\n",
      "        [0.0203, 0.0272, 0.0580, 0.1980, 0.5017, 0.0295, 0.0466, 0.0186, 0.0186,\n",
      "         0.0814],\n",
      "        [0.0188, 0.0252, 0.0544, 0.1976, 0.5182, 0.0273, 0.0436, 0.0172, 0.0173,\n",
      "         0.0804]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 在 塔利 塔利班 控制 阿富汗 的 那些 年 我 记得\n",
      "Reference: during taliban years , i remember there were times\n",
      "Model: <SOS> the of the the and the the the the\n",
      "Attention Weights: tensor([[0.0372, 0.1059, 0.1239, 0.1392, 0.1445, 0.1737, 0.1301, 0.1223, 0.0231,\n",
      "         0.0000],\n",
      "        [0.0411, 0.0952, 0.1094, 0.1238, 0.1293, 0.1609, 0.1271, 0.1520, 0.0609,\n",
      "         0.0003],\n",
      "        [0.0417, 0.0620, 0.0684, 0.0764, 0.0801, 0.1114, 0.0971, 0.1814, 0.2428,\n",
      "         0.0387],\n",
      "        [0.0454, 0.0573, 0.0616, 0.0675, 0.0701, 0.0942, 0.0843, 0.1553, 0.2528,\n",
      "         0.1115],\n",
      "        [0.0479, 0.0594, 0.0636, 0.0694, 0.0720, 0.0953, 0.0864, 0.1515, 0.2412,\n",
      "         0.1133],\n",
      "        [0.0447, 0.0549, 0.0590, 0.0648, 0.0675, 0.0922, 0.0839, 0.1550, 0.2547,\n",
      "         0.1234],\n",
      "        [0.0401, 0.0484, 0.0524, 0.0576, 0.0601, 0.0851, 0.0781, 0.1554, 0.2755,\n",
      "         0.1472],\n",
      "        [0.0371, 0.0444, 0.0479, 0.0527, 0.0551, 0.0795, 0.0730, 0.1551, 0.2890,\n",
      "         0.1661],\n",
      "        [0.0328, 0.0390, 0.0422, 0.0465, 0.0487, 0.0730, 0.0666, 0.1536, 0.3033,\n",
      "         0.1941]], grad_fn=<SelectBackward>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 199.00, Train Loss: 0.67, Val Loss: 13.17, Train BLEU: 83.98, Val BLEU: 0.39\n",
      "Sampling from training predictions...\n",
      "Source: 和 我们 合作 的 人们 帮 我们 找到 了 新\n",
      "Reference: people that have partnered with us have given us\n",
      "Model: <SOS> people &apos;s have partnered with us us given us\n",
      "Attention Weights: tensor([[0.0231, 0.0781, 0.1574, 0.1099, 0.1459, 0.1177, 0.1494, 0.1422, 0.0479,\n",
      "         0.0286],\n",
      "        [0.0272, 0.0748, 0.1486, 0.1039, 0.1505, 0.1089, 0.1563, 0.1524, 0.0465,\n",
      "         0.0310],\n",
      "        [0.0427, 0.0793, 0.1359, 0.1006, 0.1416, 0.1021, 0.1467, 0.1525, 0.0542,\n",
      "         0.0443],\n",
      "        [0.0530, 0.0826, 0.1287, 0.0986, 0.1338, 0.0997, 0.1387, 0.1513, 0.0610,\n",
      "         0.0526],\n",
      "        [0.0541, 0.0811, 0.1267, 0.0969, 0.1325, 0.0984, 0.1383, 0.1540, 0.0626,\n",
      "         0.0556],\n",
      "        [0.0488, 0.0732, 0.1231, 0.0894, 0.1355, 0.0916, 0.1451, 0.1753, 0.0611,\n",
      "         0.0569],\n",
      "        [0.0488, 0.0711, 0.1192, 0.0868, 0.1348, 0.0892, 0.1459, 0.1828, 0.0626,\n",
      "         0.0587],\n",
      "        [0.0484, 0.0703, 0.1190, 0.0863, 0.1350, 0.0889, 0.1464, 0.1841, 0.0624,\n",
      "         0.0590],\n",
      "        [0.0481, 0.0689, 0.1176, 0.0852, 0.1348, 0.0878, 0.1469, 0.1881, 0.0626,\n",
      "         0.0601]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: 我 的 祖父 在 他 的 年代 是 位非 非凡\n",
      "Reference: my grandfather was an extraordinary man for his time\n",
      "Model: <SOS> and we &apos;re &apos;re going , the stories stories\n",
      "Attention Weights: tensor([[0.0390, 0.0858, 0.1268, 0.1769, 0.1652, 0.1794, 0.0981, 0.0731, 0.0488,\n",
      "         0.0070],\n",
      "        [0.0452, 0.0852, 0.1204, 0.1688, 0.1570, 0.1791, 0.0962, 0.0737, 0.0572,\n",
      "         0.0173],\n",
      "        [0.0573, 0.0785, 0.1008, 0.1340, 0.1250, 0.1542, 0.0888, 0.0759, 0.0735,\n",
      "         0.1120],\n",
      "        [0.0645, 0.0780, 0.0947, 0.1200, 0.1128, 0.1374, 0.0847, 0.0753, 0.0768,\n",
      "         0.1559],\n",
      "        [0.0610, 0.0729, 0.0892, 0.1137, 0.1072, 0.1330, 0.0833, 0.0758, 0.0818,\n",
      "         0.1821],\n",
      "        [0.0557, 0.0645, 0.0793, 0.1039, 0.0975, 0.1274, 0.0798, 0.0744, 0.0860,\n",
      "         0.2316],\n",
      "        [0.0514, 0.0578, 0.0712, 0.0948, 0.0890, 0.1222, 0.0762, 0.0720, 0.0867,\n",
      "         0.2788],\n",
      "        [0.0472, 0.0526, 0.0648, 0.0871, 0.0820, 0.1168, 0.0725, 0.0688, 0.0844,\n",
      "         0.3236],\n",
      "        [0.0451, 0.0501, 0.0618, 0.0831, 0.0782, 0.1136, 0.0701, 0.0669, 0.0834,\n",
      "         0.3477]], grad_fn=<SelectBackward>)\n",
      "\n",
      "Experiment completed in 12 minutes with 8.64 best validation loss and 1.03 best validation BLEU.\n"
     ]
    }
   ],
   "source": [
    "model, results = train_and_eval_attn(\n",
    "    model=model, loaders_full=loaders_full, loaders_minibatch=loaders_minibatch, loaders_minitrain=loaders_minitrain, \n",
    "    params=params, vocab=vocab, print_intermediate=True, save_checkpoint=True, save_to_log=True, \n",
    "    lazy_eval=False, inspect_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt_created</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>clip_grad_max_norm</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2018-12-05 19:40:19</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.638109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2018-12-05 12:50:28</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.559556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2018-12-05 12:01:54</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.550900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2018-12-05 00:57:30</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.644947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2018-12-05 00:36:58</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.638907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             dt_created  num_epochs  learning_rate  clip_grad_max_norm  \\\n",
       "76  2018-12-05 19:40:19         200         0.0005                 1.0   \n",
       "75  2018-12-05 12:50:28         200         0.0005                 1.0   \n",
       "74  2018-12-05 12:01:54         200         0.0005                 1.0   \n",
       "73  2018-12-05 00:57:30         200         0.0005                 1.0   \n",
       "72  2018-12-05 00:36:58         200         0.0005                 1.0   \n",
       "\n",
       "    val_loss  \n",
       "76  8.638109  \n",
       "75  8.559556  \n",
       "74  8.550900  \n",
       "73  8.644947  \n",
       "72  8.638907  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_results(load_experiment_log())[['dt_created', 'num_epochs', 'learning_rate', 'clip_grad_max_norm', 'val_loss']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_learning_curve(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch: 199.00, Train Loss: 0.32, Val Loss: 13.19, Train BLEU: 98.94, Val BLEU: 0.27\n",
    "plot_single_learning_curve(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with attention energies = v_broadcast.bmm(torch.tanh(self.attn(concat)).transpose(1, 2)) # switched order  \n",
    "# Epoch: 199.00, Train Loss: 0.63, Val Loss: 12.82, Train BLEU: 92.05, Val BLEU: 0.38\n",
    "plot_single_learning_curve(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, token in enumerate(vocab[SRC_LANG]['id2token']): \n",
    "    if i < 20: \n",
    "        print(\"{}: {}\".format(i, token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, token in enumerate(vocab[TARG_LANG]['id2token']): \n",
    "    if i < 20: \n",
    "        print(\"{}: {}\".format(i, token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.arange(0, 3*5*10).view(3, 5, 10)\n",
    "print(x)\n",
    "y = x[1:, :, :]\n",
    "print(y)\n",
    "z = y.view(-1, 10)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.arange(0, 2*5).view(5, 2)\n",
    "print(t)\n",
    "u = t.contiguous().view(-1)\n",
    "print(u)\n",
    "v = t.permute(1, 0)\n",
    "print(v)\n",
    "w = v.contiguous().view(-1)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(0, 2*1*300)\n",
    "print(a)\n",
    "b = a.view(-1, 1, 300)\n",
    "print(b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (src_idxs, targ_idxs, src_lens, targ_lens) in enumerate(full_loaders['train']):\n",
    "#     print(i)\n",
    "#     print(src_idxs.size())\n",
    "#     print(src_idxs)\n",
    "#     print(src_lens)\n",
    "#     print(targ_idxs.size())\n",
    "#     print(targ_idxs)\n",
    "#     print(targ_lens)\n",
    "    id2token = vocab[SRC_LANG]['id2token']\n",
    "    test_tensor = src_idxs\n",
    "    list_of_lists = test_tensor.numpy().astype(int).tolist()\n",
    "    to_token = lambda l: ' '.join([id2token[idx] for idx in l])\n",
    "    list_of_lists_tokens = [to_token(l) for l in list_of_lists] \n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
