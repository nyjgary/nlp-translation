{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from data_processing import generate_vocab, process_data, create_dataloaders\n",
    "from model import get_pretrained_emb, EncoderRNN, DecoderRNN, DecoderAttnRNN, EncoderDecoder, EncoderDecoderAttn\n",
    "from train_eval import train_and_eval, count_parameters, summarize_results, plot_single_learning_curve, load_experiment_log\n",
    "import pickle as pkl \n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to train model vi-rnn-additive-attn\n"
     ]
    }
   ],
   "source": [
    "# model identification\n",
    "SRC_LANG = 'vi'\n",
    "TARG_LANG = 'en'\n",
    "\n",
    "# data processing params  \n",
    "SRC_MAX_SENTENCE_LEN = 10\n",
    "TARG_MAX_SENTENCE_LEN = 10\n",
    "SRC_VOCAB_SIZE = 30000 \n",
    "TARG_VOCAB_SIZE = 30000 \n",
    "\n",
    "# model architecture params \n",
    "NETWORK_TYPE = 'rnn'\n",
    "RNN_CELL_TYPE = 'gru'\n",
    "NUM_LAYERS = 2 \n",
    "ENC_HIDDEN_DIM = 512\n",
    "DEC_HIDDEN_DIM = 2 * ENC_HIDDEN_DIM \n",
    "TEACHER_FORCING_RATIO = 1\n",
    "CLIP_GRAD_MAX_NORM = 1\n",
    "ENC_DROPOUT = 0.2 \n",
    "DEC_DROPOUT = 0.2 \n",
    "ATTENTION_TYPE = 'additive'\n",
    "\n",
    "# training params  \n",
    "BATCH_SIZE = 64 #32\n",
    "NUM_EPOCHS = 15\n",
    "LR = 0.0003 # 0.0005\n",
    "OPTIMIZER = 'Adam'\n",
    "LAZY_TRAIN = False\n",
    "\n",
    "# name the model \n",
    "if NETWORK_TYPE == 'rnn': \n",
    "    MODEL_NAME = '{}-rnn-{}-attn'.format(SRC_LANG, ATTENTION_TYPE)\n",
    "elif NETWORK_TYPE == 'cnn': \n",
    "    MODEL_NAME = '{}-cnn'.format(SRC_LANG)\n",
    "    \n",
    "print(\"Preparing to train model {}\".format(MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store as dict to save to results later \n",
    "params = {'model_name': MODEL_NAME, 'src_lang': SRC_LANG, 'targ_lang': TARG_LANG, 'rnn_cell_type': RNN_CELL_TYPE, \n",
    "          'src_max_sentence_len': SRC_MAX_SENTENCE_LEN, 'targ_max_sentence_len': TARG_MAX_SENTENCE_LEN, \n",
    "          'src_vocab_size': SRC_VOCAB_SIZE, 'targ_vocab_size': TARG_VOCAB_SIZE, \n",
    "          'num_layers': NUM_LAYERS, 'enc_hidden_dim': ENC_HIDDEN_DIM, 'dec_hidden_dim': DEC_HIDDEN_DIM,\n",
    "          'teacher_forcing_ratio': TEACHER_FORCING_RATIO, 'clip_grad_max_norm': CLIP_GRAD_MAX_NORM,\n",
    "          'enc_dropout': ENC_DROPOUT, 'dec_dropout': DEC_DROPOUT, 'attention_type': ATTENTION_TYPE, \n",
    "          'batch_size': BATCH_SIZE, 'num_epochs': NUM_EPOCHS, 'learning_rate': LR, 'optimizer': OPTIMIZER, \n",
    "          'lazy_train': LAZY_TRAIN} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a long time to process, save to pickle for reimport in future \n",
    "# vocab = generate_vocab(SRC_LANG, TARG_LANG, SRC_VOCAB_SIZE, TARG_VOCAB_SIZE)\n",
    "# vocab_filename = \"{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n",
    "# pkl.dump(vocab, open(vocab_filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload from pickle \n",
    "vocab_filename = \"{}-{}-vocab.p\".format(SRC_LANG, TARG_LANG)\n",
    "vocab = pkl.load(open(vocab_filename, \"rb\"))\n",
    "data = process_data(SRC_LANG, TARG_LANG, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, vocab, filter_long=False)\n",
    "data_minibatch = process_data(SRC_LANG, TARG_LANG, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, vocab, sample_limit=BATCH_SIZE, filter_long=False) \n",
    "data_minitrain = process_data(SRC_LANG, TARG_LANG, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, vocab, sample_limit=1000, filter_long=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders \n",
    "loaders_full = create_dataloaders(data, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)\n",
    "loaders_minibatch = create_dataloaders(data_minibatch, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)\n",
    "loaders_minitrain = create_dataloaders(data_minitrain, SRC_MAX_SENTENCE_LEN, TARG_MAX_SENTENCE_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model \n",
    "\n",
    "encoder = EncoderRNN(rnn_cell_type=RNN_CELL_TYPE, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, \n",
    "                     src_max_sentence_len=SRC_MAX_SENTENCE_LEN, enc_dropout=ENC_DROPOUT, \n",
    "                     pretrained_word2vec=get_pretrained_emb(vocab[SRC_LANG]['word2vec'], vocab[SRC_LANG]['token2id']))\n",
    "\n",
    "if ATTENTION_TYPE == 'without': \n",
    "    # without attention \n",
    "    decoder = DecoderRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS,\n",
    "                         targ_vocab_size=TARG_VOCAB_SIZE, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "                         pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], \n",
    "                                                                vocab[TARG_LANG]['token2id']))\n",
    "    model = EncoderDecoder(encoder, decoder, vocab[TARG_LANG]['token2id']).to(device)\n",
    "    \n",
    "else: \n",
    "    # with attention \n",
    "    decoder = DecoderAttnRNN(rnn_cell_type=RNN_CELL_TYPE, dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, \n",
    "                             num_layers=NUM_LAYERS, targ_vocab_size=TARG_VOCAB_SIZE, \n",
    "                             src_max_sentence_len=SRC_MAX_SENTENCE_LEN, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "                             dec_dropout=DEC_DROPOUT, attention_type=ATTENTION_TYPE,\n",
    "                             pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], \n",
    "                                                                    vocab[TARG_LANG]['token2id']))\n",
    "    model = EncoderDecoderAttn(encoder, decoder, vocab[TARG_LANG]['token2id']).to(device) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.00, Train Loss: 10.23, Val Loss: 10.24, Train BLEU: 0.29, Val BLEU: 0.27, Minutes Elapsed: 0.15\n",
      "Sampling from training predictions...\n",
      "Source: micrô giúp cho đặc_biệt là ca_sĩ cũng_như nhạc_công và nhạc_sĩ\n",
      "Reference: microphones enabled singers , in particular , and musicians\n",
      "Model: <SOS> and the the the the the the the the\n",
      "Attention Weights: tensor([[0.0991, 0.1000, 0.1005, 0.1002, 0.1001, 0.1007, 0.1001, 0.0998, 0.0999,\n",
      "         0.0997],\n",
      "        [0.0991, 0.1000, 0.1005, 0.1002, 0.1001, 0.1007, 0.1001, 0.0998, 0.0999,\n",
      "         0.0997],\n",
      "        [0.0991, 0.1000, 0.1005, 0.1002, 0.1001, 0.1007, 0.1001, 0.0998, 0.0999,\n",
      "         0.0997],\n",
      "        [0.0991, 0.1000, 0.1005, 0.1002, 0.1001, 0.1007, 0.1001, 0.0998, 0.0999,\n",
      "         0.0997],\n",
      "        [0.0991, 0.1000, 0.1005, 0.1002, 0.1001, 0.1007, 0.1001, 0.0998, 0.0999,\n",
      "         0.0997],\n",
      "        [0.0991, 0.1000, 0.1005, 0.1002, 0.1001, 0.1007, 0.1001, 0.0998, 0.0999,\n",
      "         0.0997],\n",
      "        [0.0991, 0.1000, 0.1005, 0.1002, 0.1001, 0.1007, 0.1001, 0.0998, 0.0999,\n",
      "         0.0997],\n",
      "        [0.0991, 0.1000, 0.1005, 0.1002, 0.1001, 0.1007, 0.1001, 0.0998, 0.0999,\n",
      "         0.0997],\n",
      "        [0.0991, 0.1000, 0.1005, 0.1002, 0.1001, 0.1007, 0.1001, 0.0998, 0.0999,\n",
      "         0.0997]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: trồng một cây sẽ cho bạn 1.000 , 10.000 hạt_giống\n",
      "Reference: growing one plant will give you 1,000 , 10,000\n",
      "Model: <SOS> and the the the the the the the the\n",
      "Attention Weights: tensor([[0.0990, 0.0990, 0.0995, 0.1001, 0.1002, 0.0993, 0.0999, 0.1009, 0.1013,\n",
      "         0.1008],\n",
      "        [0.0990, 0.0990, 0.0995, 0.1001, 0.1002, 0.0993, 0.1000, 0.1009, 0.1013,\n",
      "         0.1008],\n",
      "        [0.0990, 0.0990, 0.0995, 0.1000, 0.1002, 0.0993, 0.1000, 0.1009, 0.1013,\n",
      "         0.1008],\n",
      "        [0.0990, 0.0990, 0.0995, 0.1000, 0.1002, 0.0993, 0.1000, 0.1009, 0.1013,\n",
      "         0.1008],\n",
      "        [0.0990, 0.0990, 0.0995, 0.1001, 0.1002, 0.0993, 0.0999, 0.1009, 0.1013,\n",
      "         0.1008],\n",
      "        [0.0990, 0.0990, 0.0995, 0.1001, 0.1002, 0.0993, 0.0999, 0.1009, 0.1013,\n",
      "         0.1008],\n",
      "        [0.0990, 0.0990, 0.0995, 0.1001, 0.1002, 0.0993, 0.0999, 0.1009, 0.1013,\n",
      "         0.1008],\n",
      "        [0.0990, 0.0990, 0.0995, 0.1001, 0.1002, 0.0993, 0.0999, 0.1009, 0.1013,\n",
      "         0.1008],\n",
      "        [0.0990, 0.0990, 0.0995, 0.1001, 0.1002, 0.0993, 0.0999, 0.1009, 0.1013,\n",
      "         0.1008]])\n",
      "\n",
      "Epoch: 0.05, Train Loss: 6.00, Val Loss: 6.40, Train BLEU: 0.39, Val BLEU: 0.37, Minutes Elapsed: 2.09\n",
      "Sampling from training predictions...\n",
      "Source: nó có tiềm_năng để thay_thế nhiên_liệu hoá_thạch , cách_mạng hoá\n",
      "Reference: it has the power , potentially , to replace\n",
      "Model: <SOS> and the , , , , , , ,\n",
      "Attention Weights: tensor([[0.0001, 0.0123, 0.0437, 0.0629, 0.0865, 0.1125, 0.1604, 0.2224, 0.2384,\n",
      "         0.0607],\n",
      "        [0.0005, 0.0169, 0.0497, 0.0679, 0.0872, 0.1021, 0.1340, 0.1860, 0.2265,\n",
      "         0.1293],\n",
      "        [0.0009, 0.0202, 0.0528, 0.0700, 0.0873, 0.1001, 0.1285, 0.1754, 0.2168,\n",
      "         0.1479],\n",
      "        [0.0009, 0.0201, 0.0520, 0.0688, 0.0857, 0.0984, 0.1266, 0.1734, 0.2170,\n",
      "         0.1570],\n",
      "        [0.0010, 0.0200, 0.0516, 0.0683, 0.0850, 0.0977, 0.1259, 0.1728, 0.2172,\n",
      "         0.1604],\n",
      "        [0.0010, 0.0200, 0.0514, 0.0680, 0.0847, 0.0973, 0.1255, 0.1725, 0.2173,\n",
      "         0.1622],\n",
      "        [0.0010, 0.0200, 0.0513, 0.0679, 0.0845, 0.0971, 0.1253, 0.1723, 0.2174,\n",
      "         0.1633],\n",
      "        [0.0010, 0.0200, 0.0512, 0.0678, 0.0844, 0.0970, 0.1252, 0.1721, 0.2174,\n",
      "         0.1640],\n",
      "        [0.0010, 0.0200, 0.0512, 0.0677, 0.0843, 0.0969, 0.1251, 0.1720, 0.2173,\n",
      "         0.1646]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: kenya sẽ có_một cánh_đồng quạt_gió lớn nhất tại châu phi\n",
      "Reference: kenya is going to have one of the largest\n",
      "Model: <SOS> and the , , , , , , ,\n",
      "Attention Weights: tensor([[0.0001, 0.0132, 0.0405, 0.0632, 0.0878, 0.1242, 0.1759, 0.2073, 0.2179,\n",
      "         0.0700],\n",
      "        [0.0005, 0.0177, 0.0457, 0.0649, 0.0806, 0.1061, 0.1477, 0.1776, 0.2120,\n",
      "         0.1473],\n",
      "        [0.0010, 0.0209, 0.0487, 0.0665, 0.0805, 0.1036, 0.1410, 0.1684, 0.2038,\n",
      "         0.1658],\n",
      "        [0.0010, 0.0207, 0.0479, 0.0653, 0.0791, 0.1020, 0.1390, 0.1665, 0.2037,\n",
      "         0.1748],\n",
      "        [0.0010, 0.0206, 0.0476, 0.0648, 0.0785, 0.1014, 0.1383, 0.1659, 0.2038,\n",
      "         0.1782],\n",
      "        [0.0011, 0.0205, 0.0474, 0.0645, 0.0783, 0.1011, 0.1379, 0.1655, 0.2038,\n",
      "         0.1799],\n",
      "        [0.0011, 0.0205, 0.0473, 0.0644, 0.0781, 0.1009, 0.1377, 0.1653, 0.2038,\n",
      "         0.1810],\n",
      "        [0.0011, 0.0205, 0.0472, 0.0643, 0.0780, 0.1008, 0.1375, 0.1652, 0.2038,\n",
      "         0.1817],\n",
      "        [0.0011, 0.0205, 0.0472, 0.0642, 0.0779, 0.1007, 0.1374, 0.1651, 0.2037,\n",
      "         0.1823]])\n",
      "\n",
      "Epoch: 0.14, Train Loss: 6.01, Val Loss: 6.26, Train BLEU: 0.36, Val BLEU: 0.39, Minutes Elapsed: 7.07\n",
      "Sampling from training predictions...\n",
      "Source: cô cảm_thấy trực_giác của cô là đúng . \" <EOS>\n",
      "Reference: i felt my intuition was correct . &quot; <EOS>\n",
      "Model: <SOS> and is is the the . . . .\n",
      "Attention Weights: tensor([[2.4765e-06, 1.8603e-05, 5.8465e-05, 1.0405e-04, 1.4420e-04, 1.9035e-04,\n",
      "         3.0090e-04, 8.7821e-04, 9.4361e-03, 9.8887e-01],\n",
      "        [2.5940e-02, 7.7148e-02, 1.1232e-01, 1.1980e-01, 1.2418e-01, 1.2399e-01,\n",
      "         1.1876e-01, 1.0784e-01, 9.6890e-02, 9.3128e-02],\n",
      "        [7.6524e-02, 9.6550e-02, 1.0373e-01, 1.0495e-01, 1.0595e-01, 1.0615e-01,\n",
      "         1.0505e-01, 1.0300e-01, 1.0034e-01, 9.7754e-02],\n",
      "        [8.5382e-02, 9.7256e-02, 1.0130e-01, 1.0209e-01, 1.0273e-01, 1.0299e-01,\n",
      "         1.0270e-01, 1.0202e-01, 1.0142e-01, 1.0212e-01],\n",
      "        [8.6696e-02, 9.6597e-02, 1.0005e-01, 1.0085e-01, 1.0142e-01, 1.0171e-01,\n",
      "         1.0176e-01, 1.0177e-01, 1.0258e-01, 1.0657e-01],\n",
      "        [8.6692e-02, 9.6080e-02, 9.9383e-02, 1.0022e-01, 1.0079e-01, 1.0112e-01,\n",
      "         1.0134e-01, 1.0169e-01, 1.0319e-01, 1.0947e-01],\n",
      "        [8.6284e-02, 9.5631e-02, 9.8911e-02, 9.9787e-02, 1.0038e-01, 1.0076e-01,\n",
      "         1.0110e-01, 1.0168e-01, 1.0369e-01, 1.1177e-01],\n",
      "        [8.5698e-02, 9.5218e-02, 9.8533e-02, 9.9450e-02, 1.0008e-01, 1.0050e-01,\n",
      "         1.0092e-01, 1.0169e-01, 1.0420e-01, 1.1371e-01],\n",
      "        [8.5010e-02, 9.4827e-02, 9.8212e-02, 9.9172e-02, 9.9830e-02, 1.0029e-01,\n",
      "         1.0079e-01, 1.0173e-01, 1.0478e-01, 1.1537e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: nó rất tốn thời_gian . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: it was very time-consuming . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> and is is the . . . . .\n",
      "Attention Weights: tensor([[0.0000, 0.0000, 0.0001, 0.0005, 0.0076, 0.9919, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0621, 0.1485, 0.1992, 0.2059, 0.1929, 0.1914, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1385, 0.1661, 0.1751, 0.1762, 0.1736, 0.1706, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1486, 0.1648, 0.1702, 0.1714, 0.1709, 0.1742, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1487, 0.1625, 0.1676, 0.1698, 0.1717, 0.1796, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1476, 0.1610, 0.1662, 0.1691, 0.1724, 0.1837, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1461, 0.1598, 0.1651, 0.1685, 0.1730, 0.1875, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1443, 0.1586, 0.1644, 0.1681, 0.1739, 0.1907, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1426, 0.1577, 0.1637, 0.1679, 0.1748, 0.1933, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 0.19, Train Loss: 5.92, Val Loss: 6.14, Train BLEU: 1.04, Val BLEU: 1.42, Minutes Elapsed: 9.62\n",
      "Sampling from training predictions...\n",
      "Source: [ nhạc_sống ] không thay_đổi nhiều tới_mức đó . <EOS>\n",
      "Reference: &#91; live music &#93; doesn &apos;t really change that\n",
      "Model: <SOS> so i is the . . . . .\n",
      "Attention Weights: tensor([[0.0001, 0.0001, 0.0002, 0.0002, 0.0002, 0.0003, 0.0005, 0.0013, 0.0084,\n",
      "         0.9886],\n",
      "        [0.0968, 0.1012, 0.0993, 0.1016, 0.1018, 0.1016, 0.0993, 0.0981, 0.0986,\n",
      "         0.1016],\n",
      "        [0.0966, 0.1019, 0.1006, 0.1032, 0.1024, 0.1005, 0.0983, 0.0971, 0.0984,\n",
      "         0.1009],\n",
      "        [0.0906, 0.0985, 0.0982, 0.1018, 0.1023, 0.1025, 0.1024, 0.1027, 0.1020,\n",
      "         0.0991],\n",
      "        [0.0855, 0.0971, 0.0979, 0.1026, 0.1034, 0.1038, 0.1037, 0.1037, 0.1029,\n",
      "         0.0995],\n",
      "        [0.0844, 0.0989, 0.0987, 0.1035, 0.1039, 0.1038, 0.1032, 0.1029, 0.1021,\n",
      "         0.0986],\n",
      "        [0.0835, 0.0994, 0.0986, 0.1039, 0.1042, 0.1039, 0.1031, 0.1027, 0.1020,\n",
      "         0.0987],\n",
      "        [0.0826, 0.0994, 0.0985, 0.1042, 0.1045, 0.1041, 0.1031, 0.1027, 0.1021,\n",
      "         0.0989],\n",
      "        [0.0821, 0.0993, 0.0983, 0.1044, 0.1046, 0.1042, 0.1032, 0.1027, 0.1021,\n",
      "         0.0990]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: em ấy không tham_lam . em không phân_biệt màu_da .\n",
      "Reference: he &apos;s not greedy . he doesn &apos;t see\n",
      "Model: <SOS> so i the the the the the . .\n",
      "Attention Weights: tensor([[0.0020, 0.0030, 0.0031, 0.0033, 0.0036, 0.0042, 0.0049, 0.0075, 0.0307,\n",
      "         0.9376],\n",
      "        [0.0904, 0.0953, 0.0979, 0.1002, 0.1001, 0.1006, 0.1010, 0.1017, 0.1055,\n",
      "         0.1071],\n",
      "        [0.0936, 0.0992, 0.1022, 0.1024, 0.1028, 0.1018, 0.1013, 0.0995, 0.0989,\n",
      "         0.0983],\n",
      "        [0.0897, 0.0965, 0.1014, 0.1025, 0.1032, 0.1028, 0.1029, 0.1023, 0.1015,\n",
      "         0.0971],\n",
      "        [0.0834, 0.0932, 0.1005, 0.1027, 0.1037, 0.1034, 0.1039, 0.1041, 0.1045,\n",
      "         0.1005],\n",
      "        [0.0813, 0.0937, 0.1016, 0.1036, 0.1041, 0.1039, 0.1041, 0.1040, 0.1039,\n",
      "         0.0999],\n",
      "        [0.0804, 0.0938, 0.1020, 0.1039, 0.1043, 0.1040, 0.1042, 0.1039, 0.1037,\n",
      "         0.0997],\n",
      "        [0.0798, 0.0937, 0.1022, 0.1041, 0.1044, 0.1041, 0.1043, 0.1039, 0.1038,\n",
      "         0.0997],\n",
      "        [0.0792, 0.0935, 0.1023, 0.1043, 0.1045, 0.1042, 0.1044, 0.1040, 0.1038,\n",
      "         0.0998]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.24, Train Loss: 5.81, Val Loss: 6.04, Train BLEU: 2.54, Val BLEU: 1.83, Minutes Elapsed: 12.12\n",
      "Sampling from training predictions...\n",
      "Source: khán_giả trong những nhà_hát này , vào thời_điểm chúng được\n",
      "Reference: people in the audience in these opera houses ,\n",
      "Model: <SOS> but , , , , , , , ,\n",
      "Attention Weights: tensor([[4.9766e-06, 4.7869e-06, 4.0799e-06, 4.5744e-06, 7.2873e-06, 8.9860e-06,\n",
      "         3.0712e-05, 1.9463e-05, 1.0780e-03, 9.9884e-01],\n",
      "        [1.2297e-01, 1.3403e-01, 1.2151e-01, 1.0332e-01, 8.0040e-02, 9.5958e-02,\n",
      "         8.2527e-02, 1.0016e-01, 9.3666e-02, 6.5816e-02],\n",
      "        [6.2320e-02, 1.1860e-01, 1.4700e-01, 1.3399e-01, 9.5942e-02, 1.2036e-01,\n",
      "         8.1785e-02, 1.2264e-01, 8.4484e-02, 3.2875e-02],\n",
      "        [3.4485e-02, 1.0227e-01, 1.6591e-01, 1.5389e-01, 9.6284e-02, 1.3617e-01,\n",
      "         7.8903e-02, 1.3844e-01, 6.9309e-02, 2.4338e-02],\n",
      "        [2.7110e-02, 8.9917e-02, 1.5499e-01, 1.5141e-01, 9.9820e-02, 1.4135e-01,\n",
      "         8.4378e-02, 1.4518e-01, 7.6437e-02, 2.9413e-02],\n",
      "        [2.4132e-02, 8.4788e-02, 1.4990e-01, 1.4975e-01, 1.0167e-01, 1.4301e-01,\n",
      "         8.7361e-02, 1.4676e-01, 8.0085e-02, 3.2543e-02],\n",
      "        [2.2503e-02, 8.1936e-02, 1.4804e-01, 1.4938e-01, 1.0242e-01, 1.4359e-01,\n",
      "         8.8401e-02, 1.4722e-01, 8.2008e-02, 3.4494e-02],\n",
      "        [2.1502e-02, 8.0002e-02, 1.4723e-01, 1.4948e-01, 1.0279e-01, 1.4392e-01,\n",
      "         8.8750e-02, 1.4750e-01, 8.3155e-02, 3.5672e-02],\n",
      "        [2.0853e-02, 7.8507e-02, 1.4675e-01, 1.4971e-01, 1.0301e-01, 1.4417e-01,\n",
      "         8.8838e-02, 1.4773e-01, 8.3952e-02, 3.6480e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: em không quan_tâm về sự khác_biệt tôn_giáo , và hãy\n",
      "Reference: he doesn &apos;t care about religious differences , and\n",
      "Model: <SOS> but , , , , , , , ,\n",
      "Attention Weights: tensor([[1.0146e-06, 1.0424e-06, 1.0204e-06, 1.6206e-06, 2.6000e-06, 1.9750e-06,\n",
      "         5.0674e-06, 1.4833e-04, 1.0062e-01, 8.9922e-01],\n",
      "        [1.2173e-01, 1.2144e-01, 9.6566e-02, 7.9001e-02, 6.9511e-02, 8.7031e-02,\n",
      "         8.4347e-02, 9.6863e-02, 1.2016e-01, 1.2336e-01],\n",
      "        [8.4943e-02, 1.3444e-01, 1.4341e-01, 1.1457e-01, 9.7684e-02, 1.3978e-01,\n",
      "         1.1900e-01, 9.2226e-02, 3.7735e-02, 3.6212e-02],\n",
      "        [4.5040e-02, 1.1835e-01, 1.7843e-01, 1.2794e-01, 1.0583e-01, 1.7284e-01,\n",
      "         1.2580e-01, 7.4872e-02, 2.6735e-02, 2.4170e-02],\n",
      "        [3.4505e-02, 1.0347e-01, 1.7251e-01, 1.2974e-01, 1.0828e-01, 1.7900e-01,\n",
      "         1.3107e-01, 8.0864e-02, 3.1368e-02, 2.9189e-02],\n",
      "        [3.0960e-02, 9.6883e-02, 1.6742e-01, 1.2995e-01, 1.0985e-01, 1.8073e-01,\n",
      "         1.3466e-01, 8.4956e-02, 3.3331e-02, 3.1254e-02],\n",
      "        [2.7701e-02, 9.1635e-02, 1.6473e-01, 1.2982e-01, 1.1048e-01, 1.8239e-01,\n",
      "         1.3729e-01, 8.7992e-02, 3.4915e-02, 3.3041e-02],\n",
      "        [2.6379e-02, 8.9098e-02, 1.6361e-01, 1.2968e-01, 1.1059e-01, 1.8303e-01,\n",
      "         1.3837e-01, 8.9298e-02, 3.5768e-02, 3.4169e-02],\n",
      "        [2.5549e-02, 8.7275e-02, 1.6301e-01, 1.2962e-01, 1.1057e-01, 1.8365e-01,\n",
      "         1.3906e-01, 9.0004e-02, 3.6277e-02, 3.4977e-02]])\n",
      "\n",
      "Epoch: 0.34, Train Loss: 5.56, Val Loss: 5.75, Train BLEU: 2.52, Val BLEU: 2.25, Minutes Elapsed: 17.10\n",
      "Sampling from training predictions...\n",
      "Source: trong 9 tháng đầu_tiên chúng_tôi cho chạy 25 câu_lạc_bộ dọc\n",
      "Reference: in the first nine months we ran 25 clubs\n",
      "Model: <SOS> in , , , , , , and and\n",
      "Attention Weights: tensor([[0.1610, 0.4527, 0.2021, 0.0788, 0.0237, 0.0206, 0.0185, 0.0133, 0.0146,\n",
      "         0.0147],\n",
      "        [0.4256, 0.4688, 0.0826, 0.0129, 0.0035, 0.0025, 0.0016, 0.0011, 0.0008,\n",
      "         0.0006],\n",
      "        [0.0810, 0.2093, 0.3749, 0.1826, 0.0678, 0.0316, 0.0196, 0.0127, 0.0114,\n",
      "         0.0091],\n",
      "        [0.0028, 0.0067, 0.0259, 0.3008, 0.2134, 0.1259, 0.1022, 0.0841, 0.0711,\n",
      "         0.0671],\n",
      "        [0.0006, 0.0012, 0.0041, 0.0902, 0.1950, 0.1708, 0.1578, 0.1371, 0.1215,\n",
      "         0.1218],\n",
      "        [0.0002, 0.0004, 0.0011, 0.0176, 0.1410, 0.1648, 0.1796, 0.1632, 0.1621,\n",
      "         0.1700],\n",
      "        [0.0002, 0.0003, 0.0007, 0.0077, 0.0963, 0.1389, 0.1745, 0.1670, 0.1990,\n",
      "         0.2156],\n",
      "        [0.0001, 0.0003, 0.0006, 0.0060, 0.0686, 0.1129, 0.1601, 0.1611, 0.2324,\n",
      "         0.2579],\n",
      "        [0.0001, 0.0003, 0.0007, 0.0061, 0.0563, 0.0970, 0.1478, 0.1548, 0.2524,\n",
      "         0.2847]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: chúng_ta , những quốc_gia viện_trợ tây_phương đã mang đến lục_địa\n",
      "Reference: we western donor countries have given the african continent\n",
      "Model: <SOS> we we we , , , , , ,\n",
      "Attention Weights: tensor([[0.3572, 0.4140, 0.0199, 0.0143, 0.0115, 0.0181, 0.0257, 0.0252, 0.0530,\n",
      "         0.0612],\n",
      "        [0.6670, 0.1942, 0.0468, 0.0264, 0.0198, 0.0144, 0.0105, 0.0080, 0.0062,\n",
      "         0.0067],\n",
      "        [0.4019, 0.2730, 0.1030, 0.0623, 0.0474, 0.0342, 0.0253, 0.0196, 0.0158,\n",
      "         0.0175],\n",
      "        [0.0108, 0.0778, 0.1891, 0.1734, 0.1393, 0.1035, 0.0870, 0.0754, 0.0693,\n",
      "         0.0744],\n",
      "        [0.0010, 0.0048, 0.0309, 0.1010, 0.1259, 0.1397, 0.1456, 0.1405, 0.1492,\n",
      "         0.1616],\n",
      "        [0.0005, 0.0016, 0.0078, 0.0539, 0.0970, 0.1326, 0.1570, 0.1629, 0.1847,\n",
      "         0.2020],\n",
      "        [0.0004, 0.0011, 0.0044, 0.0355, 0.0791, 0.1220, 0.1569, 0.1714, 0.2060,\n",
      "         0.2233],\n",
      "        [0.0003, 0.0009, 0.0035, 0.0274, 0.0683, 0.1140, 0.1550, 0.1753, 0.2198,\n",
      "         0.2355],\n",
      "        [0.0003, 0.0009, 0.0033, 0.0249, 0.0640, 0.1101, 0.1536, 0.1766, 0.2262,\n",
      "         0.2401]])\n",
      "\n",
      "Epoch: 0.38, Train Loss: 5.46, Val Loss: 5.64, Train BLEU: 2.23, Val BLEU: 3.01, Minutes Elapsed: 19.61\n",
      "Sampling from training predictions...\n",
      "Source: chúng tôi trả họ 10 cent cho 1 câu trả_lời\n",
      "Reference: we paid them 10 cents per correct question ,\n",
      "Model: <SOS> i i i to to to , , .\n",
      "Attention Weights: tensor([[0.0010, 0.0318, 0.1764, 0.1480, 0.3098, 0.1948, 0.0639, 0.0315, 0.0229,\n",
      "         0.0198],\n",
      "        [0.0889, 0.6639, 0.1725, 0.0322, 0.0255, 0.0102, 0.0029, 0.0016, 0.0012,\n",
      "         0.0010],\n",
      "        [0.0153, 0.4524, 0.3645, 0.0849, 0.0509, 0.0182, 0.0053, 0.0030, 0.0028,\n",
      "         0.0027],\n",
      "        [0.0005, 0.0163, 0.1934, 0.2944, 0.2962, 0.1175, 0.0283, 0.0178, 0.0176,\n",
      "         0.0179],\n",
      "        [0.0001, 0.0007, 0.0215, 0.1886, 0.4429, 0.2163, 0.0455, 0.0270, 0.0284,\n",
      "         0.0292],\n",
      "        [0.0001, 0.0003, 0.0043, 0.0579, 0.3646, 0.3125, 0.0863, 0.0540, 0.0598,\n",
      "         0.0604],\n",
      "        [0.0001, 0.0003, 0.0024, 0.0187, 0.1842, 0.2800, 0.1284, 0.1092, 0.1359,\n",
      "         0.1408],\n",
      "        [0.0001, 0.0003, 0.0020, 0.0099, 0.0766, 0.1762, 0.1392, 0.1532, 0.2107,\n",
      "         0.2318],\n",
      "        [0.0001, 0.0004, 0.0020, 0.0086, 0.0564, 0.1463, 0.1381, 0.1631, 0.2268,\n",
      "         0.2583]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: họ hầu_như không thể chế_độ một vợ - một chồng\n",
      "Reference: they are hardly monogamous . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> they they they to to a a a a\n",
      "Attention Weights: tensor([[0.2787, 0.3519, 0.1675, 0.0567, 0.0278, 0.0485, 0.0284, 0.0242, 0.0101,\n",
      "         0.0062],\n",
      "        [0.5259, 0.4237, 0.0400, 0.0036, 0.0015, 0.0015, 0.0013, 0.0011, 0.0008,\n",
      "         0.0007],\n",
      "        [0.1248, 0.6840, 0.1529, 0.0120, 0.0057, 0.0051, 0.0052, 0.0040, 0.0029,\n",
      "         0.0033],\n",
      "        [0.0049, 0.1467, 0.4387, 0.1050, 0.0598, 0.0563, 0.0638, 0.0471, 0.0355,\n",
      "         0.0422],\n",
      "        [0.0010, 0.0169, 0.1849, 0.1525, 0.1116, 0.1137, 0.1273, 0.1055, 0.0912,\n",
      "         0.0953],\n",
      "        [0.0005, 0.0040, 0.0229, 0.0905, 0.1206, 0.1465, 0.1738, 0.1568, 0.1393,\n",
      "         0.1451],\n",
      "        [0.0003, 0.0015, 0.0051, 0.0398, 0.0899, 0.1449, 0.1871, 0.1842, 0.1687,\n",
      "         0.1785],\n",
      "        [0.0003, 0.0011, 0.0027, 0.0225, 0.0693, 0.1377, 0.1933, 0.1986, 0.1798,\n",
      "         0.1947],\n",
      "        [0.0002, 0.0008, 0.0019, 0.0133, 0.0498, 0.1272, 0.1946, 0.2081, 0.1869,\n",
      "         0.2172]])\n",
      "\n",
      "Epoch: 0.43, Train Loss: 5.33, Val Loss: 5.48, Train BLEU: 4.04, Val BLEU: 3.54, Minutes Elapsed: 22.08\n",
      "Sampling from training predictions...\n",
      "Source: thế_nhưng giờ thứ âm_nhạc đó đang phát_triển thêm . <EOS>\n",
      "Reference: but now that &apos;s evolved into something else .\n",
      "Model: <SOS> but the &apos;t &apos;t to to . . <EOS>\n",
      "Attention Weights: tensor([[0.0382, 0.3310, 0.3050, 0.2790, 0.0414, 0.0023, 0.0001, 0.0001, 0.0008,\n",
      "         0.0021],\n",
      "        [0.0479, 0.3496, 0.4337, 0.1609, 0.0062, 0.0010, 0.0003, 0.0002, 0.0001,\n",
      "         0.0001],\n",
      "        [0.0055, 0.0328, 0.1468, 0.7665, 0.0415, 0.0047, 0.0011, 0.0006, 0.0004,\n",
      "         0.0003],\n",
      "        [0.0071, 0.0197, 0.0329, 0.3791, 0.4131, 0.0819, 0.0287, 0.0170, 0.0108,\n",
      "         0.0097],\n",
      "        [0.0047, 0.0112, 0.0119, 0.0463, 0.2777, 0.3670, 0.1322, 0.0702, 0.0421,\n",
      "         0.0367],\n",
      "        [0.0016, 0.0039, 0.0040, 0.0091, 0.0379, 0.3174, 0.3371, 0.1396, 0.0752,\n",
      "         0.0743],\n",
      "        [0.0005, 0.0014, 0.0019, 0.0046, 0.0200, 0.2056, 0.3669, 0.1882, 0.1100,\n",
      "         0.1009],\n",
      "        [0.0003, 0.0007, 0.0009, 0.0026, 0.0047, 0.0274, 0.2283, 0.3216, 0.2098,\n",
      "         0.2037],\n",
      "        [0.0003, 0.0007, 0.0009, 0.0025, 0.0043, 0.0141, 0.1168, 0.3250, 0.2752,\n",
      "         0.2603]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: hơn 85 phần_trăm kẻ bạo_hành là đàn_ông , và bạo_lực\n",
      "Reference: over 85 percent of <UNK> are men , and\n",
      "Model: <SOS> we we have , , , , and and\n",
      "Attention Weights: tensor([[0.2636, 0.4690, 0.1263, 0.0491, 0.0518, 0.0268, 0.0064, 0.0046, 0.0016,\n",
      "         0.0008],\n",
      "        [0.6677, 0.3019, 0.0240, 0.0045, 0.0010, 0.0004, 0.0002, 0.0002, 0.0001,\n",
      "         0.0000],\n",
      "        [0.0194, 0.7967, 0.1436, 0.0312, 0.0054, 0.0018, 0.0010, 0.0006, 0.0002,\n",
      "         0.0001],\n",
      "        [0.0020, 0.5272, 0.3038, 0.0929, 0.0293, 0.0154, 0.0114, 0.0092, 0.0058,\n",
      "         0.0031],\n",
      "        [0.0013, 0.0876, 0.4144, 0.2456, 0.0765, 0.0463, 0.0409, 0.0431, 0.0297,\n",
      "         0.0147],\n",
      "        [0.0005, 0.0109, 0.1133, 0.2273, 0.1417, 0.1310, 0.1281, 0.1245, 0.0809,\n",
      "         0.0418],\n",
      "        [0.0004, 0.0059, 0.0239, 0.0922, 0.1609, 0.1973, 0.1829, 0.1714, 0.1064,\n",
      "         0.0586],\n",
      "        [0.0002, 0.0026, 0.0057, 0.0201, 0.1064, 0.2124, 0.2324, 0.2177, 0.1276,\n",
      "         0.0748],\n",
      "        [0.0002, 0.0023, 0.0046, 0.0125, 0.0778, 0.1962, 0.2406, 0.2406, 0.1389,\n",
      "         0.0863]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.48, Train Loss: 5.24, Val Loss: 5.38, Train BLEU: 3.85, Val BLEU: 3.36, Minutes Elapsed: 24.55\n",
      "Sampling from training predictions...\n",
      "Source: nếu bạn tham_gia thí_nghiệm , tôi sẽ đưa cho bạn\n",
      "Reference: if you were in the experiment , i would\n",
      "Model: <SOS> if you you you , , , you you\n",
      "Attention Weights: tensor([[0.0121, 0.8093, 0.1537, 0.0190, 0.0022, 0.0021, 0.0007, 0.0003, 0.0002,\n",
      "         0.0003],\n",
      "        [0.2137, 0.7216, 0.0412, 0.0133, 0.0048, 0.0025, 0.0012, 0.0007, 0.0005,\n",
      "         0.0004],\n",
      "        [0.0174, 0.7685, 0.0988, 0.0540, 0.0232, 0.0185, 0.0090, 0.0046, 0.0032,\n",
      "         0.0028],\n",
      "        [0.0013, 0.1319, 0.3384, 0.2941, 0.1234, 0.0679, 0.0228, 0.0096, 0.0058,\n",
      "         0.0048],\n",
      "        [0.0002, 0.0173, 0.2271, 0.3622, 0.2397, 0.1012, 0.0262, 0.0113, 0.0078,\n",
      "         0.0070],\n",
      "        [0.0002, 0.0060, 0.0651, 0.2610, 0.3285, 0.2167, 0.0606, 0.0254, 0.0194,\n",
      "         0.0171],\n",
      "        [0.0002, 0.0031, 0.0127, 0.0839, 0.2509, 0.3702, 0.1540, 0.0563, 0.0372,\n",
      "         0.0316],\n",
      "        [0.0001, 0.0022, 0.0080, 0.0474, 0.1931, 0.3665, 0.2078, 0.0841, 0.0505,\n",
      "         0.0401],\n",
      "        [0.0001, 0.0008, 0.0042, 0.0258, 0.1217, 0.3293, 0.2635, 0.1270, 0.0740,\n",
      "         0.0537]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi không giống môt nhà tư_vấn bạo_lực gia_đình . <EOS>\n",
      "Reference: i don &apos;t look like a typical domestic violence\n",
      "Model: <SOS> i don &apos;t &apos;t to . . . .\n",
      "Attention Weights: tensor([[9.4045e-01, 5.5165e-02, 4.0211e-03, 2.8635e-04, 3.9228e-05, 2.1991e-05,\n",
      "         3.2477e-06, 6.7158e-07, 3.6610e-06, 1.2374e-05],\n",
      "        [9.7893e-02, 8.8607e-01, 1.2703e-02, 1.7834e-03, 7.7401e-04, 3.5542e-04,\n",
      "         1.5604e-04, 8.9878e-05, 8.5638e-05, 8.6336e-05],\n",
      "        [4.7832e-02, 9.2921e-01, 1.9100e-02, 2.1764e-03, 8.0384e-04, 3.6500e-04,\n",
      "         1.8544e-04, 1.2159e-04, 1.0274e-04, 1.0123e-04],\n",
      "        [8.4625e-03, 5.1498e-01, 3.3687e-01, 7.1749e-02, 3.4448e-02, 1.4209e-02,\n",
      "         6.9801e-03, 4.1703e-03, 3.9336e-03, 4.1956e-03],\n",
      "        [2.0188e-03, 6.0041e-02, 4.7162e-01, 2.1083e-01, 1.0862e-01, 6.1845e-02,\n",
      "         2.7716e-02, 1.8055e-02, 1.8879e-02, 2.0368e-02],\n",
      "        [1.0062e-03, 1.9612e-02, 2.7883e-01, 3.1175e-01, 1.9070e-01, 1.0634e-01,\n",
      "         3.2608e-02, 1.9849e-02, 1.9502e-02, 1.9803e-02],\n",
      "        [3.2591e-04, 2.8969e-03, 1.6330e-02, 1.6319e-01, 3.2230e-01, 2.9497e-01,\n",
      "         9.4511e-02, 3.6259e-02, 3.3646e-02, 3.5569e-02],\n",
      "        [3.1841e-04, 2.3845e-03, 7.9857e-03, 6.7979e-02, 2.3767e-01, 3.3828e-01,\n",
      "         1.7478e-01, 6.7546e-02, 5.1088e-02, 5.1960e-02],\n",
      "        [3.5590e-04, 3.1106e-03, 8.2090e-03, 5.8581e-02, 2.2748e-01, 3.3425e-01,\n",
      "         1.9545e-01, 7.7036e-02, 4.8125e-02, 4.7402e-02]])\n",
      "\n",
      "Epoch: 0.53, Train Loss: 5.15, Val Loss: 5.31, Train BLEU: 4.68, Val BLEU: 4.26, Minutes Elapsed: 27.04\n",
      "Sampling from training predictions...\n",
      "Source: vấn_đề ở chỗ nào ? <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: and what went wrong ? <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> so what is the ? <EOS> <EOS> ? ?\n",
      "Attention Weights: tensor([[0.4799, 0.4746, 0.0354, 0.0066, 0.0025, 0.0010, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.5887, 0.3902, 0.0170, 0.0029, 0.0008, 0.0004, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0626, 0.7135, 0.1877, 0.0272, 0.0064, 0.0026, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0069, 0.0804, 0.5187, 0.2941, 0.0688, 0.0312, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0018, 0.0047, 0.0666, 0.3714, 0.3604, 0.1951, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0014, 0.0030, 0.0183, 0.1865, 0.4938, 0.2972, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0014, 0.0031, 0.0101, 0.0502, 0.4762, 0.4591, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0016, 0.0036, 0.0107, 0.0397, 0.3561, 0.5883, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0020, 0.0038, 0.0110, 0.0516, 0.4756, 0.4560, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: vì có mắc chứng tự_kỷ hay không , sự khác_biệt\n",
      "Reference: because autistic or not , the differences that we\n",
      "Model: <SOS> there there &apos;s a , , , , ,\n",
      "Attention Weights: tensor([[2.6500e-01, 6.2651e-01, 1.0494e-01, 3.2983e-03, 1.6466e-04, 5.2738e-05,\n",
      "         1.9868e-05, 5.1454e-06, 2.1085e-06, 1.1961e-06],\n",
      "        [1.6626e-01, 8.0668e-01, 2.6181e-02, 7.1834e-04, 9.1678e-05, 3.6857e-05,\n",
      "         1.7397e-05, 7.3547e-06, 3.7333e-06, 2.3853e-06],\n",
      "        [4.1199e-02, 3.2287e-01, 5.2003e-01, 9.5438e-02, 1.2461e-02, 4.9232e-03,\n",
      "         1.7532e-03, 6.5981e-04, 3.5240e-04, 3.1190e-04],\n",
      "        [3.0572e-03, 5.7693e-03, 3.1106e-02, 3.1018e-01, 2.7292e-01, 2.1778e-01,\n",
      "         1.1752e-01, 2.5428e-02, 8.5031e-03, 7.7429e-03],\n",
      "        [9.3894e-05, 2.1401e-04, 1.5794e-03, 4.6361e-02, 1.8956e-01, 3.1698e-01,\n",
      "         2.8677e-01, 9.4884e-02, 3.4592e-02, 2.8964e-02],\n",
      "        [8.1518e-05, 1.9428e-04, 7.6354e-04, 1.0647e-02, 9.4076e-02, 2.7334e-01,\n",
      "         2.8766e-01, 1.7957e-01, 8.6151e-02, 6.7521e-02],\n",
      "        [7.8732e-05, 1.5159e-04, 4.5847e-04, 2.0771e-03, 1.2592e-02, 1.0464e-01,\n",
      "         3.0013e-01, 3.1452e-01, 1.5415e-01, 1.1119e-01],\n",
      "        [1.5566e-04, 2.2794e-04, 4.5031e-04, 1.4259e-03, 6.4124e-03, 4.8635e-02,\n",
      "         1.8825e-01, 3.4494e-01, 2.5486e-01, 1.5464e-01],\n",
      "        [9.7964e-05, 1.1024e-04, 4.4671e-04, 1.8307e-03, 9.4935e-03, 8.0511e-02,\n",
      "         2.3299e-01, 3.2143e-01, 2.0897e-01, 1.4413e-01]])\n",
      "\n",
      "Epoch: 0.58, Train Loss: 5.10, Val Loss: 5.24, Train BLEU: 5.15, Val BLEU: 4.66, Minutes Elapsed: 29.54\n",
      "Sampling from training predictions...\n",
      "Source: và đây là la scala . <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: this is la scala . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> and this is . . <EOS> <EOS> . .\n",
      "Attention Weights: tensor([[0.0003, 0.0272, 0.9581, 0.0142, 0.0001, 0.0001, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0029, 0.6406, 0.3553, 0.0011, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0013, 0.0412, 0.9013, 0.0537, 0.0015, 0.0006, 0.0004, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0008, 0.0588, 0.8313, 0.0716, 0.0214, 0.0161, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0003, 0.0035, 0.6483, 0.2396, 0.0611, 0.0473, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0003, 0.0010, 0.0200, 0.4774, 0.2863, 0.2150, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0004, 0.0019, 0.0198, 0.1647, 0.4225, 0.3906, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0012, 0.0051, 0.0317, 0.1492, 0.4149, 0.3977, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0003, 0.0013, 0.0127, 0.1876, 0.4322, 0.3659, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: nhưng những cuộc trao_đổi hiệu_quả không_thể diễn ra nếu các\n",
      "Reference: but these great conversations can &apos;t occur if our\n",
      "Model: <SOS> but the the the the the the to ,\n",
      "Attention Weights: tensor([[2.6071e-01, 6.6698e-01, 6.3086e-02, 8.6751e-03, 4.9441e-04, 4.1417e-05,\n",
      "         8.0804e-06, 2.1280e-06, 1.0505e-06, 1.2391e-06],\n",
      "        [9.5601e-02, 5.0067e-01, 3.2310e-01, 7.2784e-02, 6.1133e-03, 9.6836e-04,\n",
      "         3.4408e-04, 1.8004e-04, 1.3166e-04, 1.0538e-04],\n",
      "        [1.8294e-02, 8.8328e-02, 2.9699e-01, 5.1726e-01, 6.1957e-02, 9.1514e-03,\n",
      "         3.3356e-03, 2.1129e-03, 1.4866e-03, 1.0778e-03],\n",
      "        [4.2635e-03, 1.9455e-02, 4.4809e-02, 4.6883e-01, 3.1125e-01, 8.7229e-02,\n",
      "         3.1321e-02, 1.6461e-02, 9.5976e-03, 6.7816e-03],\n",
      "        [3.7164e-04, 1.2912e-03, 3.9892e-03, 7.3437e-02, 3.4757e-01, 2.8937e-01,\n",
      "         1.6090e-01, 7.4768e-02, 2.9437e-02, 1.8871e-02],\n",
      "        [1.0338e-04, 2.6785e-04, 1.0171e-03, 7.4068e-03, 1.1986e-01, 2.7980e-01,\n",
      "         2.6227e-01, 1.9443e-01, 8.8017e-02, 4.6830e-02],\n",
      "        [4.3331e-05, 9.5305e-05, 4.0438e-04, 2.0698e-03, 1.9530e-02, 1.4582e-01,\n",
      "         2.2709e-01, 2.9295e-01, 1.9069e-01, 1.2131e-01],\n",
      "        [3.8795e-05, 7.6277e-05, 2.5257e-04, 1.4975e-03, 6.6673e-03, 7.5705e-02,\n",
      "         1.8318e-01, 3.3586e-01, 2.4286e-01, 1.5386e-01],\n",
      "        [6.5589e-05, 1.1550e-04, 2.8855e-04, 1.6531e-03, 7.4315e-03, 7.8321e-02,\n",
      "         1.8761e-01, 3.4210e-01, 2.3668e-01, 1.4573e-01]])\n",
      "\n",
      "Epoch: 0.62, Train Loss: 5.01, Val Loss: 5.12, Train BLEU: 4.97, Val BLEU: 4.54, Minutes Elapsed: 32.06\n",
      "Sampling from training predictions...\n",
      "Source: một trong số những phân_tử tôi nghiên_cứu tên là isoprene\n",
      "Reference: and one of the molecules i study is called\n",
      "Model: <SOS> one of of of of i i that the\n",
      "Attention Weights: tensor([[8.6058e-01, 1.3849e-01, 8.5325e-04, 5.0157e-05, 1.0384e-05, 6.7250e-06,\n",
      "         3.2378e-06, 2.3681e-06, 1.6785e-06, 1.0372e-06],\n",
      "        [3.6026e-02, 7.7908e-01, 1.1550e-01, 3.4180e-02, 2.4105e-02, 4.7117e-03,\n",
      "         2.8565e-03, 1.6450e-03, 1.0068e-03, 8.9527e-04],\n",
      "        [1.9645e-03, 7.5519e-02, 3.8972e-01, 2.9932e-01, 1.6970e-01, 2.7865e-02,\n",
      "         1.5472e-02, 9.4360e-03, 5.9772e-03, 5.0258e-03],\n",
      "        [4.8766e-04, 1.1795e-02, 1.0417e-01, 3.1704e-01, 3.8259e-01, 9.5256e-02,\n",
      "         3.8349e-02, 2.1097e-02, 1.4737e-02, 1.4481e-02],\n",
      "        [1.2560e-04, 1.8063e-03, 3.3602e-02, 2.5195e-01, 4.6069e-01, 1.3686e-01,\n",
      "         5.0150e-02, 2.7308e-02, 1.9110e-02, 1.8395e-02],\n",
      "        [2.3841e-04, 3.1605e-03, 3.1932e-02, 1.9780e-01, 4.0176e-01, 2.1302e-01,\n",
      "         6.4919e-02, 3.5674e-02, 2.6495e-02, 2.5002e-02],\n",
      "        [1.3949e-04, 1.8272e-03, 1.5051e-02, 1.5251e-01, 3.9684e-01, 2.4423e-01,\n",
      "         9.2141e-02, 4.2283e-02, 2.9016e-02, 2.5967e-02],\n",
      "        [2.5070e-05, 2.0042e-04, 9.9889e-04, 1.7854e-02, 1.4980e-01, 2.0989e-01,\n",
      "         2.9085e-01, 1.8029e-01, 8.4626e-02, 6.5460e-02],\n",
      "        [2.1813e-05, 1.4262e-04, 3.1209e-04, 2.9500e-03, 2.9431e-02, 7.8079e-02,\n",
      "         2.4234e-01, 2.8296e-01, 2.0523e-01, 1.5854e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi muốn tất_cả chúng_ta trở_thành những kẻ nổi_loạn xanh hoá\n",
      "Reference: so i want us all to become <UNK> <UNK>\n",
      "Model: <SOS> i i we we to the the the the\n",
      "Attention Weights: tensor([[7.3091e-01, 2.6703e-01, 1.7104e-03, 2.2023e-04, 9.5666e-05, 2.6535e-05,\n",
      "         5.3199e-06, 2.9535e-06, 7.9042e-07, 7.1847e-07],\n",
      "        [9.6832e-02, 8.9157e-01, 1.0188e-02, 9.1704e-04, 2.9772e-04, 1.1313e-04,\n",
      "         3.9685e-05, 1.8495e-05, 1.0882e-05, 9.0518e-06],\n",
      "        [1.1456e-02, 8.0417e-01, 1.6285e-01, 1.7271e-02, 2.8396e-03, 8.9388e-04,\n",
      "         2.8732e-04, 1.0434e-04, 6.7741e-05, 5.9880e-05],\n",
      "        [1.4914e-02, 6.4783e-01, 2.7773e-01, 4.4701e-02, 9.5831e-03, 2.9515e-03,\n",
      "         1.1775e-03, 5.0128e-04, 3.2497e-04, 2.8844e-04],\n",
      "        [1.1632e-03, 5.2528e-02, 2.2733e-01, 2.8029e-01, 2.8344e-01, 9.6235e-02,\n",
      "         3.5387e-02, 9.8755e-03, 7.2568e-03, 6.4929e-03],\n",
      "        [3.2894e-04, 5.6182e-03, 3.4663e-02, 1.2383e-01, 4.4209e-01, 2.4188e-01,\n",
      "         8.3136e-02, 2.6420e-02, 2.1450e-02, 2.0589e-02],\n",
      "        [1.4173e-04, 2.4348e-03, 2.2574e-03, 2.6449e-02, 1.8597e-01, 3.3936e-01,\n",
      "         2.5147e-01, 8.4570e-02, 5.2805e-02, 5.4533e-02],\n",
      "        [2.5406e-04, 8.0318e-03, 2.0577e-03, 1.3686e-02, 4.8041e-02, 1.7131e-01,\n",
      "         2.4022e-01, 1.4871e-01, 1.4673e-01, 2.2096e-01],\n",
      "        [3.4762e-04, 6.4890e-03, 3.4275e-03, 7.3277e-03, 2.6351e-02, 9.5663e-02,\n",
      "         1.5062e-01, 1.3853e-01, 2.0406e-01, 3.6719e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.67, Train Loss: 4.99, Val Loss: 5.08, Train BLEU: 4.99, Val BLEU: 4.74, Minutes Elapsed: 34.55\n",
      "Sampling from training predictions...\n",
      "Source: điều đó có nghĩa rằng giờ_đây có_thể tạo nên thứ\n",
      "Reference: it meant that there could be extreme dynamics ,\n",
      "Model: <SOS> so that &apos;s that that that that that that\n",
      "Attention Weights: tensor([[4.5178e-01, 4.7398e-01, 7.3966e-02, 2.6371e-04, 1.2090e-06, 3.9652e-08,\n",
      "         3.8110e-09, 2.1823e-09, 7.8669e-10, 5.5426e-10],\n",
      "        [2.7495e-01, 4.1909e-01, 2.7872e-01, 2.5057e-02, 1.9249e-03, 1.9290e-04,\n",
      "         3.3421e-05, 1.8956e-05, 1.1782e-05, 1.0372e-05],\n",
      "        [3.2322e-02, 7.8238e-02, 5.4808e-01, 3.0551e-01, 2.9983e-02, 3.8501e-03,\n",
      "         8.3236e-04, 4.8016e-04, 3.5310e-04, 3.4564e-04],\n",
      "        [1.5273e-03, 3.2333e-03, 1.3340e-01, 5.0641e-01, 2.6784e-01, 6.4025e-02,\n",
      "         1.1596e-02, 5.7385e-03, 3.3376e-03, 2.8942e-03],\n",
      "        [3.6641e-04, 4.0534e-04, 9.6350e-03, 7.6149e-02, 5.6824e-01, 2.6564e-01,\n",
      "         3.7289e-02, 1.9724e-02, 1.2075e-02, 1.0470e-02],\n",
      "        [3.0962e-04, 2.0541e-04, 1.0916e-03, 5.2898e-03, 1.5512e-01, 5.7011e-01,\n",
      "         1.3408e-01, 5.6236e-02, 3.9750e-02, 3.7802e-02],\n",
      "        [1.2463e-04, 7.5195e-05, 3.0226e-04, 1.5754e-03, 2.2003e-02, 3.8351e-01,\n",
      "         2.9797e-01, 1.2942e-01, 8.5935e-02, 7.9088e-02],\n",
      "        [6.8428e-05, 4.4376e-05, 1.5182e-04, 8.0287e-04, 4.4760e-03, 1.1153e-01,\n",
      "         2.8697e-01, 1.8936e-01, 1.9816e-01, 2.0843e-01],\n",
      "        [7.4215e-05, 4.9000e-05, 1.5146e-04, 7.9903e-04, 3.1204e-03, 6.7779e-02,\n",
      "         2.4183e-01, 1.8261e-01, 2.3539e-01, 2.6819e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: anh ta bảo chúng_tôi đi theo trên con đường lầy_lội\n",
      "Reference: he told us to follow him down a dirt\n",
      "Model: <SOS> he he we we the the the the the\n",
      "Attention Weights: tensor([[6.2561e-01, 3.5743e-01, 1.6835e-02, 9.8888e-05, 2.1068e-05, 1.5830e-06,\n",
      "         2.7503e-07, 8.8275e-08, 5.3012e-08, 3.1494e-08],\n",
      "        [4.8371e-02, 4.2423e-01, 5.1088e-01, 1.5078e-02, 1.1008e-03, 2.1201e-04,\n",
      "         7.2774e-05, 2.8583e-05, 1.4453e-05, 7.5758e-06],\n",
      "        [5.2959e-03, 8.4189e-02, 4.3055e-01, 3.8586e-01, 6.7357e-02, 1.6055e-02,\n",
      "         5.8600e-03, 2.4559e-03, 1.4531e-03, 9.1742e-04],\n",
      "        [8.2609e-04, 4.2251e-03, 3.8463e-02, 2.8350e-01, 3.8561e-01, 1.9543e-01,\n",
      "         5.4472e-02, 1.7774e-02, 1.1364e-02, 8.3331e-03],\n",
      "        [4.9468e-04, 9.3746e-04, 1.6117e-03, 2.6286e-02, 6.9504e-02, 2.6048e-01,\n",
      "         3.5885e-01, 1.4798e-01, 7.6772e-02, 5.7073e-02],\n",
      "        [2.0165e-04, 3.7533e-04, 7.7912e-04, 3.2247e-03, 9.2607e-03, 6.0429e-02,\n",
      "         2.0872e-01, 3.1279e-01, 2.2446e-01, 1.7976e-01],\n",
      "        [2.0302e-04, 2.9553e-04, 1.1544e-03, 2.2721e-03, 5.4822e-03, 2.4876e-02,\n",
      "         9.4681e-02, 2.4342e-01, 2.8845e-01, 3.3917e-01],\n",
      "        [4.9675e-04, 8.4679e-04, 3.1518e-03, 6.8484e-03, 1.4134e-02, 3.6240e-02,\n",
      "         7.0806e-02, 1.7190e-01, 2.6812e-01, 4.2746e-01],\n",
      "        [8.0730e-04, 1.1367e-03, 5.0262e-03, 9.7535e-03, 1.9249e-02, 4.4838e-02,\n",
      "         8.5186e-02, 1.6760e-01, 2.5714e-01, 4.0926e-01]])\n",
      "\n",
      "Epoch: 0.72, Train Loss: 4.93, Val Loss: 5.00, Train BLEU: 5.51, Val BLEU: 5.33, Minutes Elapsed: 37.05\n",
      "Sampling from training predictions...\n",
      "Source: và chúng_tôi càng nói về lợi_ích của việc tăng sự\n",
      "Reference: and the more we talked about how great it\n",
      "Model: <SOS> and we think that that about the the the\n",
      "Attention Weights: tensor([[7.2825e-03, 4.3573e-01, 5.4707e-01, 9.5675e-03, 3.1035e-04, 3.7451e-05,\n",
      "         4.3394e-06, 8.7366e-07, 6.0481e-07, 3.7798e-07],\n",
      "        [1.5838e-02, 7.9671e-01, 1.7782e-01, 9.4081e-03, 2.1072e-04, 8.1834e-06,\n",
      "         7.0138e-07, 2.8013e-07, 1.7476e-07, 1.3293e-07],\n",
      "        [7.2620e-06, 9.4225e-03, 8.3824e-01, 1.5141e-01, 8.5309e-04, 4.8123e-05,\n",
      "         8.6962e-06, 4.9512e-06, 3.2277e-06, 2.1044e-06],\n",
      "        [1.9230e-06, 2.1727e-03, 5.1196e-01, 4.6776e-01, 1.7251e-02, 7.4256e-04,\n",
      "         6.2383e-05, 2.8002e-05, 1.4622e-05, 8.3300e-06],\n",
      "        [2.9621e-06, 3.6807e-03, 5.0241e-01, 4.3289e-01, 5.4908e-02, 4.8858e-03,\n",
      "         6.7711e-04, 3.0242e-04, 1.5652e-04, 8.6112e-05],\n",
      "        [1.7073e-06, 7.4388e-04, 4.8934e-02, 5.9677e-01, 3.1875e-01, 2.8307e-02,\n",
      "         3.3764e-03, 1.6254e-03, 9.2276e-04, 5.6692e-04],\n",
      "        [1.5072e-06, 5.6522e-05, 1.8893e-03, 4.0465e-02, 5.0201e-01, 3.8999e-01,\n",
      "         3.6506e-02, 1.6793e-02, 8.0514e-03, 4.2421e-03],\n",
      "        [2.6467e-05, 5.5674e-05, 1.0610e-03, 8.0153e-03, 3.0389e-02, 2.8285e-01,\n",
      "         2.5838e-01, 2.2025e-01, 1.1461e-01, 8.4359e-02],\n",
      "        [3.6773e-05, 6.8241e-05, 6.2151e-04, 1.6666e-03, 3.4473e-03, 1.4091e-02,\n",
      "         3.0130e-02, 1.7069e-01, 3.9527e-01, 3.8397e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: bấy_giờ , điều cuối_cùng tôi muốn làm là rời_bỏ new_york\n",
      "Reference: now , the last thing i wanted to do\n",
      "Model: <SOS> so , i i i i i to to\n",
      "Attention Weights: tensor([[7.8904e-01, 1.9256e-01, 1.8366e-02, 2.8775e-05, 5.8411e-07, 2.5390e-07,\n",
      "         1.4680e-07, 3.2939e-08, 3.9682e-09, 1.8927e-09],\n",
      "        [1.4138e-01, 6.7063e-01, 1.8613e-01, 1.7919e-03, 4.7612e-05, 1.8505e-05,\n",
      "         5.7264e-06, 1.9906e-06, 6.0125e-07, 2.9148e-07],\n",
      "        [1.2719e-02, 4.9028e-01, 4.7212e-01, 2.0160e-02, 2.2826e-03, 1.7634e-03,\n",
      "         4.6729e-04, 1.4240e-04, 4.5270e-05, 1.9516e-05],\n",
      "        [1.3660e-03, 7.6989e-02, 7.3754e-01, 1.2916e-01, 1.6886e-02, 2.5478e-02,\n",
      "         7.8557e-03, 3.1466e-03, 1.0929e-03, 4.9230e-04],\n",
      "        [3.4478e-03, 4.2046e-02, 3.6762e-01, 2.0998e-01, 1.0888e-01, 2.0569e-01,\n",
      "         4.8753e-02, 9.8533e-03, 2.4401e-03, 1.2802e-03],\n",
      "        [8.8308e-04, 1.5050e-02, 2.7935e-01, 3.0914e-01, 1.3508e-01, 1.9528e-01,\n",
      "         4.7584e-02, 1.2037e-02, 3.5320e-03, 2.0613e-03],\n",
      "        [3.1488e-04, 1.3159e-03, 8.0234e-03, 4.9119e-02, 1.6183e-01, 5.1081e-01,\n",
      "         1.9735e-01, 4.6803e-02, 1.5555e-02, 8.8803e-03],\n",
      "        [1.8281e-04, 1.1747e-04, 3.4459e-04, 1.4649e-03, 2.1204e-02, 4.5124e-01,\n",
      "         3.6997e-01, 1.1749e-01, 2.6119e-02, 1.1864e-02],\n",
      "        [1.4236e-04, 1.6526e-04, 2.0959e-04, 5.8880e-04, 3.8491e-03, 7.7047e-02,\n",
      "         3.1282e-01, 3.2859e-01, 1.9858e-01, 7.8011e-02]])\n",
      "\n",
      "Epoch: 0.77, Train Loss: 4.89, Val Loss: 4.95, Train BLEU: 5.98, Val BLEU: 5.32, Minutes Elapsed: 39.53\n",
      "Sampling from training predictions...\n",
      "Source: trong mỗi bản đánh_giá chúng_tôi viết , chúng_tôi luôn đính\n",
      "Reference: in each one of those assessments that we write\n",
      "Model: <SOS> in the of , we we we we we\n",
      "Attention Weights: tensor([[9.8755e-01, 1.2367e-02, 8.4731e-05, 7.0105e-07, 3.1985e-07, 8.8578e-08,\n",
      "         6.8233e-09, 4.8559e-09, 1.1092e-08, 6.4753e-09],\n",
      "        [6.2115e-01, 3.5644e-01, 2.1787e-02, 4.9995e-04, 6.4386e-05, 3.6488e-05,\n",
      "         1.1786e-05, 4.5840e-06, 3.4072e-06, 2.0193e-06],\n",
      "        [7.2214e-02, 4.6312e-01, 4.2101e-01, 3.2885e-02, 7.4944e-03, 2.4514e-03,\n",
      "         4.2746e-04, 1.9431e-04, 1.3864e-04, 6.9306e-05],\n",
      "        [4.9825e-03, 3.9582e-02, 6.5108e-01, 1.9672e-01, 6.5210e-02, 2.4668e-02,\n",
      "         1.1338e-02, 3.1434e-03, 2.1251e-03, 1.1571e-03],\n",
      "        [1.5435e-03, 4.6850e-03, 7.6689e-02, 3.8340e-01, 2.4109e-01, 1.2001e-01,\n",
      "         1.0318e-01, 4.2790e-02, 1.7218e-02, 9.3930e-03],\n",
      "        [1.3530e-03, 2.8687e-03, 1.4919e-02, 1.7150e-01, 3.2084e-01, 1.3766e-01,\n",
      "         1.7751e-01, 1.1820e-01, 3.5908e-02, 1.9248e-02],\n",
      "        [4.5496e-03, 1.0334e-02, 2.7496e-02, 1.1555e-01, 3.3988e-01, 1.2093e-01,\n",
      "         1.7440e-01, 1.3995e-01, 4.6325e-02, 2.0586e-02],\n",
      "        [1.0421e-03, 1.6055e-03, 4.9738e-03, 6.0880e-02, 2.4580e-01, 1.3196e-01,\n",
      "         1.8448e-01, 2.1199e-01, 1.1486e-01, 4.2410e-02],\n",
      "        [2.7256e-04, 3.8122e-04, 1.5414e-03, 1.4138e-02, 1.3679e-01, 9.3268e-02,\n",
      "         1.5106e-01, 2.6688e-01, 2.5246e-01, 8.3212e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: ngày xảy_ra sóng_thần , anh chịu trách_nhiệm đóng chặt cửa\n",
      "Reference: the day of the tsunami , he &apos;d actually\n",
      "Model: <SOS> and the , , , , , the the\n",
      "Attention Weights: tensor([[9.6613e-01, 3.3788e-02, 8.1887e-05, 5.7715e-07, 1.5231e-07, 4.2683e-08,\n",
      "         8.8061e-09, 5.8591e-09, 2.5224e-09, 1.4333e-09],\n",
      "        [2.1267e-01, 7.8381e-01, 3.4757e-03, 3.2088e-05, 6.7359e-06, 2.3135e-06,\n",
      "         6.9623e-07, 4.0303e-07, 1.5159e-07, 7.7874e-08],\n",
      "        [1.2840e-02, 9.6493e-01, 2.1287e-02, 5.9941e-04, 2.3334e-04, 7.1610e-05,\n",
      "         1.9392e-05, 1.0935e-05, 4.7868e-06, 2.3458e-06],\n",
      "        [5.8509e-04, 5.5742e-01, 3.9050e-01, 3.7560e-02, 1.0570e-02, 2.1822e-03,\n",
      "         6.2556e-04, 3.3933e-04, 1.4624e-04, 7.0150e-05],\n",
      "        [1.0217e-03, 7.1533e-02, 4.1795e-01, 1.3977e-01, 2.4559e-01, 9.0537e-02,\n",
      "         1.6587e-02, 1.0439e-02, 4.4591e-03, 2.1117e-03],\n",
      "        [1.5553e-03, 4.5471e-02, 1.5719e-01, 2.0663e-01, 3.6167e-01, 1.7547e-01,\n",
      "         2.3802e-02, 1.6107e-02, 7.6137e-03, 4.4833e-03],\n",
      "        [4.7456e-04, 8.3652e-03, 4.4352e-02, 1.2206e-01, 4.0239e-01, 3.2348e-01,\n",
      "         5.0676e-02, 2.9776e-02, 1.1743e-02, 6.6813e-03],\n",
      "        [3.4001e-05, 2.0819e-04, 7.8600e-04, 6.9720e-03, 1.5987e-01, 4.3631e-01,\n",
      "         1.9970e-01, 1.4384e-01, 3.8084e-02, 1.4200e-02],\n",
      "        [4.0930e-05, 7.4034e-04, 6.9384e-04, 2.0522e-03, 5.9852e-02, 3.4989e-01,\n",
      "         2.3660e-01, 2.2657e-01, 9.3823e-02, 2.9738e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.82, Train Loss: 4.85, Val Loss: 4.91, Train BLEU: 6.64, Val BLEU: 5.76, Minutes Elapsed: 42.00\n",
      "Sampling from training predictions...\n",
      "Source: cái này được gọi_là cấu_hình sao chết . <EOS> <PAD>\n",
      "Reference: this is called the death star configuration . <EOS>\n",
      "Model: <SOS> this is the the . . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.8370, 0.1620, 0.0010, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4585, 0.3233, 0.2140, 0.0038, 0.0004, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0354, 0.1047, 0.6869, 0.1580, 0.0125, 0.0020, 0.0003, 0.0001, 0.0001,\n",
      "         0.0000],\n",
      "        [0.0030, 0.0179, 0.1700, 0.4273, 0.2629, 0.0991, 0.0154, 0.0028, 0.0017,\n",
      "         0.0000],\n",
      "        [0.0008, 0.0053, 0.0385, 0.1934, 0.3672, 0.2979, 0.0663, 0.0178, 0.0129,\n",
      "         0.0000],\n",
      "        [0.0005, 0.0011, 0.0031, 0.0325, 0.1912, 0.3624, 0.3082, 0.0532, 0.0480,\n",
      "         0.0000],\n",
      "        [0.0009, 0.0022, 0.0069, 0.0266, 0.0934, 0.2594, 0.4480, 0.0846, 0.0781,\n",
      "         0.0000],\n",
      "        [0.0020, 0.0027, 0.0130, 0.0583, 0.1014, 0.1558, 0.3536, 0.1682, 0.1450,\n",
      "         0.0000],\n",
      "        [0.0031, 0.0037, 0.0155, 0.0659, 0.1100, 0.1362, 0.3127, 0.1895, 0.1635,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: em chia_sẻ nó một_cách vô điều_kiện dù bất kể ra_sao\n",
      "Reference: he shares it unconditionally and he shares it regardless\n",
      "Model: <SOS> the was about the the the &apos;s that that\n",
      "Attention Weights: tensor([[9.6462e-01, 3.5068e-02, 2.9140e-04, 1.7234e-05, 2.1027e-06, 7.7026e-07,\n",
      "         2.7316e-07, 1.0679e-07, 5.6152e-08, 4.6406e-08],\n",
      "        [1.7155e-01, 8.2071e-01, 5.7622e-03, 1.5233e-03, 2.6788e-04, 9.7387e-05,\n",
      "         5.3732e-05, 1.9821e-05, 9.7066e-06, 5.9194e-06],\n",
      "        [1.1570e-02, 6.8759e-01, 1.7807e-01, 9.8593e-02, 1.6014e-02, 4.6451e-03,\n",
      "         1.9977e-03, 7.8983e-04, 4.3651e-04, 2.9205e-04],\n",
      "        [2.0301e-04, 2.0947e-02, 2.6527e-01, 3.7950e-01, 1.8663e-01, 8.0119e-02,\n",
      "         4.3719e-02, 1.4843e-02, 6.3999e-03, 2.3673e-03],\n",
      "        [4.4127e-05, 3.9524e-04, 3.2418e-02, 1.7457e-01, 1.9230e-01, 1.8574e-01,\n",
      "         1.8773e-01, 1.1398e-01, 9.0559e-02, 2.2250e-02],\n",
      "        [7.0739e-06, 7.6725e-05, 7.5783e-03, 8.2720e-02, 1.4492e-01, 1.8508e-01,\n",
      "         1.9855e-01, 1.1728e-01, 1.7456e-01, 8.9230e-02],\n",
      "        [9.9107e-06, 1.4475e-04, 7.6011e-03, 4.5819e-02, 7.9349e-02, 1.0906e-01,\n",
      "         1.2016e-01, 8.2752e-02, 1.7197e-01, 3.8313e-01],\n",
      "        [2.9232e-05, 2.9111e-04, 1.8532e-02, 6.6940e-02, 7.8087e-02, 1.1565e-01,\n",
      "         1.3212e-01, 1.0735e-01, 1.5784e-01, 3.2316e-01],\n",
      "        [8.7018e-06, 1.1857e-04, 7.2235e-03, 3.7398e-02, 6.8358e-02, 1.0350e-01,\n",
      "         1.2652e-01, 8.7850e-02, 1.5841e-01, 4.1061e-01]])\n",
      "\n",
      "Epoch: 0.86, Train Loss: 4.82, Val Loss: 4.86, Train BLEU: 6.05, Val BLEU: 5.70, Minutes Elapsed: 44.45\n",
      "Sampling from training predictions...\n",
      "Source: và hãy nghĩ đến cuộc_sống của tôi lẽ_ra sẽ tốt\n",
      "Reference: and just think about how better my life would\n",
      "Model: <SOS> and i think the the i would would to\n",
      "Attention Weights: tensor([[9.5489e-04, 7.8030e-01, 2.1833e-01, 4.1499e-04, 3.8766e-06, 5.6619e-08,\n",
      "         3.0930e-09, 8.4620e-10, 1.2807e-09, 7.8596e-10],\n",
      "        [1.8338e-02, 7.9031e-01, 1.8800e-01, 3.2541e-03, 8.5847e-05, 6.9032e-06,\n",
      "         3.2911e-06, 1.0683e-06, 7.3489e-07, 3.6548e-07],\n",
      "        [4.7843e-05, 1.0837e-02, 7.7653e-01, 1.9401e-01, 1.5212e-02, 1.3029e-03,\n",
      "         8.8517e-04, 5.9769e-04, 3.7564e-04, 2.0294e-04],\n",
      "        [3.6966e-05, 4.7952e-03, 2.9951e-01, 3.9883e-01, 2.4346e-01, 2.3901e-02,\n",
      "         1.1015e-02, 9.4218e-03, 5.7038e-03, 3.3294e-03],\n",
      "        [1.1658e-05, 2.9934e-04, 3.3536e-03, 8.6820e-02, 6.2915e-01, 1.6603e-01,\n",
      "         4.2450e-02, 3.3149e-02, 2.0599e-02, 1.8135e-02],\n",
      "        [1.8634e-05, 7.9408e-04, 5.9428e-03, 9.4962e-03, 7.1488e-02, 8.1347e-02,\n",
      "         1.0597e-01, 3.1745e-01, 2.6054e-01, 1.4695e-01],\n",
      "        [1.8059e-05, 1.7795e-03, 2.1151e-02, 5.7938e-03, 1.7356e-02, 2.1661e-02,\n",
      "         4.3011e-02, 3.3615e-01, 3.8865e-01, 1.6443e-01],\n",
      "        [1.8766e-05, 1.8608e-03, 1.2356e-02, 5.9665e-03, 1.4300e-02, 1.2959e-02,\n",
      "         1.6244e-02, 2.3886e-01, 4.2294e-01, 2.7450e-01],\n",
      "        [1.1867e-05, 3.9440e-04, 3.1817e-03, 3.3605e-03, 1.7776e-02, 1.2955e-02,\n",
      "         9.8807e-03, 1.6066e-01, 4.0969e-01, 3.8209e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: có một vài lần , ngôi trường đột_nhiên đóng_cửa khoảng\n",
      "Reference: from time to time , the school would suddenly\n",
      "Model: <SOS> there &apos;s a , , , , , ,\n",
      "Attention Weights: tensor([[9.9337e-01, 6.6286e-03, 5.5134e-06, 1.8703e-07, 1.3475e-08, 1.5221e-08,\n",
      "         6.8797e-09, 2.5404e-09, 2.3918e-09, 2.9709e-09],\n",
      "        [8.4417e-01, 1.4713e-01, 6.1620e-03, 1.2266e-03, 4.5442e-04, 4.9798e-04,\n",
      "         1.7552e-04, 9.1595e-05, 5.6034e-05, 4.1081e-05],\n",
      "        [3.3624e-01, 3.7761e-01, 1.7518e-01, 7.7727e-02, 1.1404e-02, 1.4204e-02,\n",
      "         4.1393e-03, 1.9284e-03, 9.8029e-04, 5.8746e-04],\n",
      "        [6.8931e-02, 9.3247e-02, 1.8175e-01, 3.7832e-01, 1.6455e-01, 7.3350e-02,\n",
      "         1.9510e-02, 1.0659e-02, 5.7865e-03, 3.8997e-03],\n",
      "        [1.8728e-03, 4.4743e-03, 5.7199e-02, 3.5096e-01, 3.4267e-01, 1.6443e-01,\n",
      "         3.6483e-02, 2.1520e-02, 1.2062e-02, 8.3328e-03],\n",
      "        [2.8686e-04, 7.4502e-04, 1.4627e-02, 1.6023e-01, 4.4741e-01, 2.7531e-01,\n",
      "         5.3847e-02, 2.0953e-02, 1.4175e-02, 1.2413e-02],\n",
      "        [2.7015e-04, 3.4104e-04, 2.0515e-03, 1.3635e-02, 2.6085e-01, 4.5053e-01,\n",
      "         1.6217e-01, 5.7814e-02, 2.9947e-02, 2.2397e-02],\n",
      "        [7.6869e-04, 6.2115e-04, 7.0712e-04, 1.8950e-03, 2.0896e-02, 2.9104e-01,\n",
      "         2.9412e-01, 2.3173e-01, 1.1347e-01, 4.4750e-02],\n",
      "        [5.9666e-04, 5.6606e-04, 1.0178e-03, 2.8515e-03, 2.9093e-02, 2.6761e-01,\n",
      "         2.0250e-01, 2.2923e-01, 1.7082e-01, 9.5723e-02]])\n",
      "\n",
      "Epoch: 0.91, Train Loss: 4.80, Val Loss: 4.82, Train BLEU: 6.57, Val BLEU: 5.78, Minutes Elapsed: 46.94\n",
      "Sampling from training predictions...\n",
      "Source: mc sẽ ứng_tấu lời bài_hát theo cái cách tương_tự với\n",
      "Reference: the mc would improvise lyrics in the same way\n",
      "Model: <SOS> why is is we us to the , ,\n",
      "Attention Weights: tensor([[9.9735e-01, 2.6424e-03, 1.1640e-05, 3.0079e-07, 1.0973e-08, 7.9468e-09,\n",
      "         3.9697e-09, 1.5465e-09, 1.4781e-09, 1.0348e-09],\n",
      "        [4.1755e-01, 5.8082e-01, 1.5566e-03, 4.9369e-05, 5.7405e-06, 6.0181e-06,\n",
      "         3.3258e-06, 1.7809e-06, 1.3519e-06, 8.0707e-07],\n",
      "        [4.0665e-02, 9.2936e-01, 2.7997e-02, 1.4413e-03, 1.3870e-04, 1.7257e-04,\n",
      "         9.9220e-05, 6.2915e-05, 3.5297e-05, 2.5074e-05],\n",
      "        [3.2924e-02, 8.6693e-01, 8.4143e-02, 1.1050e-02, 1.1928e-03, 1.6735e-03,\n",
      "         1.0066e-03, 5.9959e-04, 2.9315e-04, 1.8407e-04],\n",
      "        [3.8125e-03, 1.6155e-01, 4.4006e-01, 2.4436e-01, 3.9386e-02, 5.5820e-02,\n",
      "         2.9782e-02, 1.5041e-02, 6.0502e-03, 4.1293e-03],\n",
      "        [2.4223e-04, 8.6438e-03, 1.2387e-01, 5.3025e-01, 1.2608e-01, 1.1424e-01,\n",
      "         5.1051e-02, 3.1601e-02, 8.1469e-03, 5.8742e-03],\n",
      "        [5.3431e-05, 7.5506e-04, 1.7908e-02, 2.8212e-01, 2.3062e-01, 2.4210e-01,\n",
      "         1.2730e-01, 6.7470e-02, 1.7192e-02, 1.4477e-02],\n",
      "        [5.3487e-05, 2.6545e-04, 5.8569e-03, 7.2574e-02, 1.7282e-01, 2.8906e-01,\n",
      "         2.3328e-01, 1.5483e-01, 3.9689e-02, 3.1572e-02],\n",
      "        [2.1381e-05, 2.9699e-04, 1.4707e-03, 1.2084e-02, 7.3036e-02, 2.5321e-01,\n",
      "         3.2869e-01, 2.1241e-01, 6.4069e-02, 5.4718e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: vì_vậy , để thực_hiện các bước đầu_tiên hướng tới việc\n",
      "Reference: so , taking the first steps towards this today\n",
      "Model: <SOS> so , let &apos;s to of of the the\n",
      "Attention Weights: tensor([[4.2910e-01, 4.2286e-01, 1.4751e-01, 5.2844e-04, 6.0180e-06, 9.1284e-08,\n",
      "         4.5832e-09, 2.6207e-09, 1.2636e-09, 7.2904e-10],\n",
      "        [1.4927e-02, 5.3231e-02, 9.0244e-01, 2.9236e-02, 1.5333e-04, 5.2968e-06,\n",
      "         1.2324e-06, 4.8925e-07, 2.4967e-07, 1.4399e-07],\n",
      "        [5.7257e-03, 2.8226e-02, 5.5523e-01, 3.9539e-01, 1.2916e-02, 1.6464e-03,\n",
      "         5.0974e-04, 1.9540e-04, 1.0917e-04, 5.5008e-05],\n",
      "        [2.5893e-04, 8.5855e-04, 4.9009e-02, 9.0314e-01, 3.8782e-02, 5.3423e-03,\n",
      "         1.4704e-03, 6.0803e-04, 3.4138e-04, 1.8659e-04],\n",
      "        [2.1486e-04, 4.2255e-04, 1.1778e-02, 8.5454e-01, 1.0413e-01, 1.9248e-02,\n",
      "         5.1973e-03, 2.6325e-03, 1.1568e-03, 6.8413e-04],\n",
      "        [2.4469e-04, 2.6120e-04, 2.6522e-03, 2.9504e-01, 3.2218e-01, 2.5268e-01,\n",
      "         8.3391e-02, 2.5819e-02, 1.1531e-02, 6.2018e-03],\n",
      "        [4.1946e-04, 5.8886e-04, 1.5097e-03, 4.9200e-02, 1.7550e-01, 4.0531e-01,\n",
      "         1.9221e-01, 1.1232e-01, 3.7968e-02, 2.4970e-02],\n",
      "        [3.7577e-05, 3.9580e-05, 8.7535e-05, 1.8938e-03, 3.6324e-02, 2.3629e-01,\n",
      "         3.6618e-01, 2.4703e-01, 6.6177e-02, 4.5947e-02],\n",
      "        [5.3111e-06, 3.6334e-06, 1.4383e-05, 2.8325e-04, 9.6003e-03, 9.8938e-02,\n",
      "         3.2706e-01, 3.6783e-01, 1.2609e-01, 7.0173e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.96, Train Loss: 4.75, Val Loss: 4.77, Train BLEU: 6.25, Val BLEU: 6.46, Minutes Elapsed: 49.44\n",
      "Sampling from training predictions...\n",
      "Source: mỗi năm , hơn 15,000 nhà khoa_học đến san francisco\n",
      "Reference: over 15,000 scientists go to san francisco every year\n",
      "Model: <SOS> in , , , the the the the the\n",
      "Attention Weights: tensor([[9.8588e-01, 1.4111e-02, 6.5252e-06, 6.6925e-07, 1.1221e-07, 1.4465e-08,\n",
      "         2.2575e-09, 3.1163e-10, 3.6602e-11, 2.6399e-11],\n",
      "        [1.4993e-01, 8.0387e-01, 4.1067e-02, 4.8447e-03, 2.3519e-04, 4.9416e-05,\n",
      "         7.6786e-06, 1.5967e-06, 6.2728e-07, 3.4883e-07],\n",
      "        [6.7231e-02, 4.2793e-01, 3.2322e-01, 1.7048e-01, 7.6160e-03, 2.2068e-03,\n",
      "         9.9771e-04, 2.4453e-04, 5.3955e-05, 2.4467e-05],\n",
      "        [2.1846e-03, 1.4539e-02, 1.1063e-01, 7.6497e-01, 5.1155e-02, 2.7809e-02,\n",
      "         1.6209e-02, 6.5778e-03, 3.6344e-03, 2.2896e-03],\n",
      "        [5.5788e-03, 1.4292e-02, 3.5141e-02, 2.7634e-01, 1.5362e-02, 7.9827e-02,\n",
      "         2.1676e-01, 2.0439e-01, 9.6036e-02, 5.6276e-02],\n",
      "        [2.0820e-03, 1.8337e-03, 1.0865e-03, 1.1557e-02, 7.8365e-03, 5.1794e-02,\n",
      "         2.2036e-01, 4.4388e-01, 1.6301e-01, 9.6562e-02],\n",
      "        [9.9932e-04, 1.1426e-03, 4.4226e-04, 1.3564e-03, 1.2602e-03, 5.9787e-03,\n",
      "         4.1585e-02, 2.1635e-01, 4.0679e-01, 3.2409e-01],\n",
      "        [2.8853e-03, 3.7323e-03, 1.3345e-03, 1.0333e-03, 3.8779e-04, 1.7255e-03,\n",
      "         1.8845e-02, 1.4721e-01, 3.5656e-01, 4.6628e-01],\n",
      "        [6.9224e-03, 8.8290e-03, 3.5033e-03, 1.0398e-02, 3.6058e-03, 1.1006e-02,\n",
      "         2.5937e-02, 8.6409e-02, 1.8883e-01, 6.5456e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: có mấy người đàn_ông , họ giúp tôi dỡ đồ\n",
      "Reference: these are the guys , they helped me <UNK>\n",
      "Model: <SOS> there are people people , they i to to\n",
      "Attention Weights: tensor([[9.9482e-01, 5.1658e-03, 1.1965e-05, 6.7733e-08, 5.5881e-09, 1.1484e-08,\n",
      "         8.0561e-10, 5.3355e-10, 1.1766e-10, 1.4883e-10],\n",
      "        [4.7134e-01, 4.7574e-01, 5.1398e-02, 8.7723e-04, 1.6508e-04, 3.7636e-04,\n",
      "         5.9546e-05, 2.0821e-05, 1.6514e-05, 9.3682e-06],\n",
      "        [1.9807e-01, 4.0582e-01, 3.5801e-01, 2.8364e-02, 2.3327e-03, 5.3377e-03,\n",
      "         1.0634e-03, 4.8915e-04, 3.1494e-04, 1.9316e-04],\n",
      "        [3.7691e-03, 5.5992e-02, 3.8998e-01, 3.5942e-01, 1.2261e-01, 4.5747e-02,\n",
      "         1.6284e-02, 1.2135e-03, 3.1471e-03, 1.8402e-03],\n",
      "        [7.9704e-04, 3.0614e-03, 8.3469e-02, 2.5530e-01, 4.3375e-01, 1.5489e-01,\n",
      "         4.9431e-02, 4.5604e-03, 8.2261e-03, 6.5206e-03],\n",
      "        [1.3657e-03, 3.0091e-03, 1.2053e-02, 2.0012e-02, 4.4333e-01, 4.4290e-01,\n",
      "         5.9107e-02, 7.7677e-03, 5.3712e-03, 5.0853e-03],\n",
      "        [6.0295e-04, 1.3493e-03, 7.8803e-03, 1.3664e-02, 6.5885e-02, 5.4717e-01,\n",
      "         2.3616e-01, 4.3449e-02, 5.0746e-02, 3.3089e-02],\n",
      "        [5.8860e-03, 1.5587e-02, 2.8437e-02, 7.9661e-03, 1.7128e-02, 3.1482e-01,\n",
      "         2.5117e-01, 1.6606e-01, 1.3840e-01, 5.4547e-02],\n",
      "        [1.9715e-04, 5.0114e-04, 1.5369e-03, 4.7502e-03, 2.1425e-02, 3.5620e-02,\n",
      "         1.6387e-01, 5.4197e-02, 5.1741e-01, 2.0049e-01]])\n",
      "\n",
      "Epoch: 1.00, Train Loss: 4.76, Val Loss: 4.77, Train BLEU: 6.35, Val BLEU: 6.31, Minutes Elapsed: 51.54\n",
      "Sampling from training predictions...\n",
      "Source: và chúng_tôi còn làm_cho tế_bào nhảy_múa . <EOS> <PAD> <PAD>\n",
      "Reference: and we make cells dance . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> and we we to to the <EOS> . .\n",
      "Attention Weights: tensor([[0.0118, 0.2267, 0.7600, 0.0016, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.3614, 0.5832, 0.0550, 0.0003, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0211, 0.9154, 0.0601, 0.0029, 0.0002, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0006, 0.0095, 0.5248, 0.4278, 0.0347, 0.0025, 0.0002, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0011, 0.0114, 0.3672, 0.5086, 0.1037, 0.0048, 0.0029, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0004, 0.0060, 0.0515, 0.4120, 0.4654, 0.0368, 0.0278, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0003, 0.0027, 0.0172, 0.1866, 0.6682, 0.0573, 0.0676, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0008, 0.0014, 0.0090, 0.0243, 0.1333, 0.5417, 0.1268, 0.1628, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0008, 0.0114, 0.3081, 0.1802, 0.2036, 0.2323, 0.0302, 0.0335, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: rất dễ gây thêm hư_hại cho những hình_ảnh đã hư_hại\n",
      "Reference: it &apos;s very easy to do more damage to\n",
      "Model: <SOS> it &apos;s just to to to to to to\n",
      "Attention Weights: tensor([[9.6685e-01, 3.3063e-02, 8.4787e-05, 1.3863e-06, 1.4185e-07, 1.6867e-08,\n",
      "         7.5451e-09, 3.6388e-09, 3.1733e-09, 3.1702e-09],\n",
      "        [2.3205e-01, 7.4443e-01, 2.3046e-02, 4.3308e-04, 2.3216e-05, 7.6282e-06,\n",
      "         4.8412e-06, 2.1546e-06, 1.3404e-06, 1.1934e-06],\n",
      "        [1.5378e-01, 6.8282e-01, 1.4871e-01, 1.3556e-02, 6.5357e-04, 2.0060e-04,\n",
      "         1.3260e-04, 6.8389e-05, 3.6905e-05, 3.4883e-05],\n",
      "        [2.1567e-03, 3.3511e-02, 3.8705e-01, 4.4460e-01, 9.1262e-02, 1.9573e-02,\n",
      "         1.2086e-02, 5.7576e-03, 2.1674e-03, 1.8313e-03],\n",
      "        [6.3276e-04, 1.2240e-02, 2.2821e-01, 5.5732e-01, 1.2289e-01, 3.4259e-02,\n",
      "         2.1666e-02, 1.2219e-02, 5.6301e-03, 4.9288e-03],\n",
      "        [1.8918e-04, 5.7402e-03, 4.2296e-02, 4.6524e-01, 2.8274e-01, 1.1070e-01,\n",
      "         4.6911e-02, 2.2601e-02, 1.2827e-02, 1.0749e-02],\n",
      "        [3.5652e-05, 3.1136e-04, 3.6411e-03, 1.0058e-01, 2.8990e-01, 2.8491e-01,\n",
      "         1.9699e-01, 8.1688e-02, 2.5969e-02, 1.5969e-02],\n",
      "        [3.2254e-05, 2.4920e-04, 2.5608e-03, 6.5563e-02, 2.6736e-01, 2.7199e-01,\n",
      "         2.3071e-01, 1.0805e-01, 3.3045e-02, 2.0439e-02],\n",
      "        [2.6352e-05, 1.4207e-04, 9.2141e-04, 1.8717e-02, 1.2309e-01, 2.3010e-01,\n",
      "         3.1026e-01, 2.0594e-01, 7.1373e-02, 3.9424e-02]])\n",
      "\n",
      "Epoch: 1.05, Train Loss: 4.24, Val Loss: 4.72, Train BLEU: 7.15, Val BLEU: 6.64, Minutes Elapsed: 54.02\n",
      "Sampling from training predictions...\n",
      "Source: các nhà khoa_học phải được thắt_chặt hoàn_toàn vào ghế để\n",
      "Reference: and the scientists have to be completely harnessed in\n",
      "Model: <SOS> the are are are be be the to to\n",
      "Attention Weights: tensor([[7.5804e-01, 2.2678e-01, 1.5124e-02, 5.5297e-05, 6.4610e-07, 3.3080e-08,\n",
      "         5.4969e-09, 3.1527e-09, 1.2652e-09, 1.0217e-09],\n",
      "        [8.9382e-03, 2.1997e-02, 7.1955e-01, 2.3913e-01, 9.6953e-03, 3.1750e-04,\n",
      "         2.4608e-04, 6.8765e-05, 3.4050e-05, 2.4932e-05],\n",
      "        [7.1799e-04, 1.6611e-03, 1.0714e-01, 7.7090e-01, 1.1495e-01, 2.3335e-03,\n",
      "         1.3850e-03, 4.3143e-04, 2.3793e-04, 2.4613e-04],\n",
      "        [4.8936e-04, 1.2587e-03, 5.9155e-02, 7.1359e-01, 2.1626e-01, 5.4869e-03,\n",
      "         2.5344e-03, 5.1527e-04, 3.3929e-04, 3.7821e-04],\n",
      "        [4.8473e-04, 1.3313e-03, 6.9800e-02, 7.3617e-01, 1.7413e-01, 9.4982e-03,\n",
      "         5.3043e-03, 1.5668e-03, 9.2390e-04, 7.9637e-04],\n",
      "        [1.5476e-05, 2.8862e-05, 1.7329e-03, 9.2812e-02, 6.7944e-01, 8.7953e-02,\n",
      "         1.0783e-01, 1.9032e-02, 6.9057e-03, 4.2523e-03],\n",
      "        [5.6344e-06, 1.1212e-05, 1.1237e-04, 5.5376e-03, 2.2438e-01, 1.9616e-01,\n",
      "         4.0845e-01, 1.2081e-01, 2.8880e-02, 1.5658e-02],\n",
      "        [4.4074e-06, 7.8223e-06, 4.6886e-05, 1.0838e-03, 4.9819e-02, 1.3764e-01,\n",
      "         5.1639e-01, 2.0111e-01, 6.2464e-02, 3.1426e-02],\n",
      "        [5.2330e-06, 5.1668e-06, 3.1467e-05, 4.5821e-04, 1.2257e-02, 9.3902e-02,\n",
      "         4.2643e-01, 2.9000e-01, 1.0864e-01, 6.8257e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tom <UNK> : vậy max , bằng cách lấy tất_cả\n",
      "Reference: so max , by taking all these samples of\n",
      "Model: <SOS> kevin : : : , , , , ,\n",
      "Attention Weights: tensor([[6.2480e-01, 3.7149e-01, 3.4983e-03, 2.0658e-04, 2.1662e-06, 2.5029e-08,\n",
      "         1.4182e-08, 4.3614e-09, 1.8160e-09, 5.3020e-10],\n",
      "        [3.9372e-02, 9.0789e-01, 4.3214e-02, 9.4714e-03, 4.9435e-05, 1.4155e-06,\n",
      "         3.9297e-07, 1.0132e-07, 5.4832e-08, 4.1330e-08],\n",
      "        [1.1963e-03, 6.1754e-02, 8.6535e-02, 8.4455e-01, 4.8191e-03, 7.5076e-04,\n",
      "         3.0375e-04, 5.2019e-05, 2.2028e-05, 1.3356e-05],\n",
      "        [2.5794e-04, 5.4794e-03, 2.1721e-02, 9.0447e-01, 4.9693e-02, 8.1873e-03,\n",
      "         7.3814e-03, 1.6674e-03, 7.7498e-04, 3.6999e-04],\n",
      "        [9.5072e-05, 5.4312e-04, 4.7591e-03, 6.9313e-01, 1.8870e-01, 4.6610e-02,\n",
      "         4.8751e-02, 1.0284e-02, 4.5639e-03, 2.5648e-03],\n",
      "        [9.6624e-05, 4.4918e-04, 8.9857e-04, 2.0437e-01, 2.1727e-01, 1.0631e-01,\n",
      "         3.6571e-01, 6.7332e-02, 2.6551e-02, 1.1015e-02],\n",
      "        [1.6766e-05, 8.5610e-05, 4.5442e-04, 1.3366e-01, 1.3233e-01, 2.2911e-01,\n",
      "         3.8325e-01, 6.6885e-02, 3.3233e-02, 2.0978e-02],\n",
      "        [1.4236e-05, 6.0189e-05, 2.9536e-04, 5.2644e-02, 5.7992e-02, 2.1901e-01,\n",
      "         4.9813e-01, 8.1189e-02, 5.2983e-02, 3.7677e-02],\n",
      "        [1.6788e-05, 3.4420e-05, 1.0004e-04, 1.1126e-02, 2.0892e-02, 1.0472e-01,\n",
      "         5.1723e-01, 1.6109e-01, 1.1106e-01, 7.3731e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1.10, Train Loss: 4.30, Val Loss: 4.70, Train BLEU: 8.01, Val BLEU: 6.91, Minutes Elapsed: 56.50\n",
      "Sampling from training predictions...\n",
      "Source: các y_tá trong khoa tôi nằm cho_rằng phương_pháp đúng nhất_là\n",
      "Reference: the nurses in my department thought that the right\n",
      "Model: <SOS> the the of the i to the the the\n",
      "Attention Weights: tensor([[9.8736e-01, 1.2618e-02, 1.8840e-05, 2.5236e-07, 1.1189e-08, 2.9358e-09,\n",
      "         7.7180e-10, 4.4290e-10, 1.8872e-10, 1.3633e-10],\n",
      "        [1.9128e-02, 4.1586e-01, 5.5552e-01, 9.3644e-03, 4.7395e-05, 2.9309e-05,\n",
      "         2.7927e-05, 1.2231e-05, 9.3556e-06, 4.6997e-06],\n",
      "        [1.7137e-03, 3.5822e-02, 6.3576e-01, 3.1135e-01, 9.7485e-03, 2.7231e-03,\n",
      "         1.5844e-03, 5.6992e-04, 4.8744e-04, 2.4497e-04],\n",
      "        [7.2295e-04, 1.5491e-02, 3.0655e-01, 5.3118e-01, 1.0433e-01, 2.0615e-02,\n",
      "         1.0584e-02, 4.7899e-03, 3.8278e-03, 1.9107e-03],\n",
      "        [1.7412e-04, 1.4151e-03, 1.6225e-02, 1.4010e-01, 1.9688e-01, 2.9279e-01,\n",
      "         1.8432e-01, 7.6746e-02, 5.4701e-02, 3.6643e-02],\n",
      "        [3.7446e-05, 7.7781e-04, 3.2917e-03, 3.0952e-02, 1.2688e-01, 2.7288e-01,\n",
      "         3.1324e-01, 1.4751e-01, 7.9371e-02, 2.5070e-02],\n",
      "        [4.9140e-06, 7.6487e-05, 6.9272e-04, 3.8491e-03, 2.3065e-02, 1.3889e-01,\n",
      "         3.4775e-01, 2.3942e-01, 1.7863e-01, 6.7615e-02],\n",
      "        [6.5232e-06, 3.1971e-05, 2.5247e-04, 6.7365e-04, 2.5727e-03, 6.0837e-02,\n",
      "         2.9114e-01, 2.5218e-01, 2.7113e-01, 1.2116e-01],\n",
      "        [1.0212e-05, 4.4910e-05, 3.1828e-04, 6.4408e-04, 1.5896e-03, 3.5276e-02,\n",
      "         1.9919e-01, 2.1756e-01, 3.2638e-01, 2.1899e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tất_cả đều có_thể với những thông_tin này . <EOS> <PAD>\n",
      "Reference: all this is possible with this information . <EOS>\n",
      "Model: <SOS> all all can all of these . . <EOS>\n",
      "Attention Weights: tensor([[0.8055, 0.1920, 0.0025, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1137, 0.7656, 0.1178, 0.0027, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0411, 0.4256, 0.4018, 0.1094, 0.0204, 0.0015, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0088, 0.0686, 0.2178, 0.2528, 0.3701, 0.0753, 0.0045, 0.0013, 0.0007,\n",
      "         0.0000],\n",
      "        [0.0016, 0.0140, 0.0628, 0.1154, 0.5619, 0.2133, 0.0181, 0.0079, 0.0050,\n",
      "         0.0000],\n",
      "        [0.0005, 0.0042, 0.0332, 0.0854, 0.4809, 0.2923, 0.0567, 0.0278, 0.0190,\n",
      "         0.0000],\n",
      "        [0.0004, 0.0022, 0.0057, 0.0171, 0.1844, 0.3924, 0.2110, 0.1019, 0.0850,\n",
      "         0.0000],\n",
      "        [0.0016, 0.0088, 0.0195, 0.0157, 0.0716, 0.1711, 0.3432, 0.2025, 0.1661,\n",
      "         0.0000],\n",
      "        [0.0024, 0.0121, 0.0225, 0.0168, 0.0698, 0.1792, 0.2669, 0.2380, 0.1923,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 1.14, Train Loss: 4.33, Val Loss: 4.72, Train BLEU: 7.35, Val BLEU: 6.61, Minutes Elapsed: 58.99\n",
      "Sampling from training predictions...\n",
      "Source: và chúng_tôi nghĩ có_thể có 2 lực đang diễn ra\n",
      "Reference: and we thought maybe what is happening is that\n",
      "Model: <SOS> and we think that can have are two two\n",
      "Attention Weights: tensor([[3.5118e-03, 1.9497e-01, 8.0085e-01, 6.2859e-04, 3.9818e-05, 7.7364e-08,\n",
      "         6.4604e-09, 2.3386e-09, 3.1495e-10, 3.4287e-10],\n",
      "        [3.1322e-02, 9.4934e-01, 1.9314e-02, 2.4636e-05, 1.2771e-06, 9.2863e-08,\n",
      "         2.4596e-08, 1.5999e-08, 7.1036e-09, 7.8971e-09],\n",
      "        [2.4267e-05, 5.8916e-03, 9.9164e-01, 1.8504e-03, 4.4115e-04, 7.3731e-05,\n",
      "         2.6971e-05, 2.7937e-05, 9.7838e-06, 9.2136e-06],\n",
      "        [2.4688e-05, 1.5996e-03, 9.6948e-01, 2.4923e-02, 3.3510e-03, 3.4489e-04,\n",
      "         9.0109e-05, 1.1694e-04, 3.3093e-05, 3.1925e-05],\n",
      "        [8.4159e-05, 6.8362e-04, 2.6617e-01, 4.1361e-01, 2.4509e-01, 5.3248e-02,\n",
      "         8.9519e-03, 6.8188e-03, 2.7234e-03, 2.6244e-03],\n",
      "        [9.0940e-06, 4.7489e-04, 1.4053e-01, 3.8944e-01, 3.6454e-01, 6.3292e-02,\n",
      "         1.4897e-02, 1.6975e-02, 5.0704e-03, 4.7735e-03],\n",
      "        [7.0726e-06, 2.0204e-04, 2.1946e-02, 1.8934e-01, 3.5727e-01, 1.3193e-01,\n",
      "         9.4235e-02, 1.3445e-01, 3.6865e-02, 3.3760e-02],\n",
      "        [7.1297e-06, 2.7876e-04, 1.5898e-02, 1.5520e-01, 2.4557e-01, 9.6388e-02,\n",
      "         1.0238e-01, 2.2382e-01, 7.5754e-02, 8.4709e-02],\n",
      "        [2.5232e-06, 2.8973e-05, 7.2351e-04, 8.5912e-03, 6.9487e-02, 1.4680e-01,\n",
      "         1.8788e-01, 2.7746e-01, 1.5601e-01, 1.5301e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: cô cũng đã có bản_sao của bức ảnh . <EOS>\n",
      "Reference: she also had <UNK> . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> she she have the the . . the .\n",
      "Attention Weights: tensor([[9.5273e-01, 4.7100e-02, 1.7372e-04, 9.6093e-07, 1.4488e-08, 2.4205e-10,\n",
      "         4.6323e-11, 4.0318e-12, 1.0305e-12, 1.6785e-12],\n",
      "        [1.9918e-02, 6.5618e-01, 2.8177e-01, 3.3301e-02, 8.6344e-03, 1.2090e-04,\n",
      "         6.2103e-05, 9.1781e-06, 1.8029e-06, 1.3436e-06],\n",
      "        [9.7704e-03, 3.0247e-01, 2.6194e-01, 1.8703e-01, 2.2679e-01, 7.8618e-03,\n",
      "         3.7472e-03, 3.0384e-04, 5.1829e-05, 3.2869e-05],\n",
      "        [3.4620e-04, 6.3056e-03, 2.7279e-02, 1.1311e-01, 5.4239e-01, 1.4969e-01,\n",
      "         1.5223e-01, 7.8424e-03, 5.3612e-04, 2.6629e-04],\n",
      "        [6.6558e-04, 1.0493e-02, 3.7780e-02, 1.0700e-01, 3.7103e-01, 1.4697e-01,\n",
      "         2.6644e-01, 5.3698e-02, 3.9144e-03, 2.0011e-03],\n",
      "        [9.5701e-05, 6.7999e-04, 3.8582e-03, 2.8911e-02, 1.3364e-01, 1.6542e-01,\n",
      "         4.1240e-01, 2.2979e-01, 1.7217e-02, 7.9840e-03],\n",
      "        [2.6672e-04, 1.5533e-03, 2.8898e-03, 1.6340e-02, 3.8579e-02, 8.8850e-02,\n",
      "         3.2807e-01, 3.3467e-01, 1.2028e-01, 6.8502e-02],\n",
      "        [5.2776e-03, 6.4942e-02, 4.7006e-02, 1.4570e-01, 1.6961e-01, 7.6968e-02,\n",
      "         2.7446e-01, 1.2880e-01, 5.1469e-02, 3.5764e-02],\n",
      "        [3.5863e-04, 2.5082e-03, 3.7960e-03, 1.9927e-02, 7.0035e-02, 1.1115e-01,\n",
      "         3.6390e-01, 2.7180e-01, 9.7801e-02, 5.8727e-02]])\n",
      "\n",
      "Epoch: 1.19, Train Loss: 4.30, Val Loss: 4.66, Train BLEU: 6.83, Val BLEU: 6.48, Minutes Elapsed: 61.47\n",
      "Sampling from training predictions...\n",
      "Source: tôi bị chứng trầm_cảm , và trong một thời_gian dài\n",
      "Reference: i suffer from depression , and for a long\n",
      "Model: <SOS> i was been and , and i in ,\n",
      "Attention Weights: tensor([[2.1052e-01, 7.8054e-01, 8.9082e-03, 2.5329e-05, 4.5541e-07, 1.2525e-08,\n",
      "         7.6495e-09, 5.4919e-09, 2.0066e-09, 1.1018e-09],\n",
      "        [1.4369e-02, 7.9717e-01, 1.8706e-01, 1.3155e-03, 3.9393e-05, 8.4342e-06,\n",
      "         2.2604e-05, 8.2803e-06, 4.4916e-06, 3.0166e-06],\n",
      "        [1.5351e-03, 2.0512e-01, 7.4018e-01, 5.1157e-02, 1.6470e-03, 8.4736e-05,\n",
      "         1.3036e-04, 7.8514e-05, 4.0311e-05, 2.4957e-05],\n",
      "        [4.2301e-05, 1.5600e-03, 1.5615e-01, 5.9056e-01, 2.3930e-01, 8.4858e-03,\n",
      "         2.7582e-03, 4.0411e-04, 4.4812e-04, 2.8598e-04],\n",
      "        [2.1178e-05, 7.2132e-04, 2.9255e-02, 2.2404e-01, 5.9209e-01, 9.7197e-02,\n",
      "         3.9038e-02, 4.6778e-03, 6.5313e-03, 6.4210e-03],\n",
      "        [1.4548e-04, 7.4404e-04, 7.1982e-03, 5.6809e-02, 7.5543e-01, 1.3401e-01,\n",
      "         2.8600e-02, 3.3646e-03, 5.2998e-03, 8.4066e-03],\n",
      "        [1.2885e-03, 2.7696e-03, 2.1477e-02, 3.8818e-02, 1.4702e-01, 2.6030e-01,\n",
      "         3.7935e-01, 6.9907e-02, 3.6911e-02, 4.2165e-02],\n",
      "        [1.0670e-04, 3.0549e-03, 1.8858e-02, 1.9766e-02, 7.9187e-02, 1.2118e-01,\n",
      "         4.5450e-01, 1.7503e-01, 6.5119e-02, 6.3207e-02],\n",
      "        [6.8304e-05, 2.3737e-03, 1.9385e-02, 2.6353e-02, 7.9753e-02, 1.3011e-01,\n",
      "         3.8419e-01, 1.6032e-01, 1.0443e-01, 9.3017e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: từ khi còn nhỏ , tôi đã từng làm_việc ở\n",
      "Reference: since i was a small boy , i used\n",
      "Model: <SOS> since , i , , , , i i\n",
      "Attention Weights: tensor([[9.9241e-01, 5.7489e-03, 1.7402e-03, 9.3431e-05, 2.5268e-06, 2.3701e-07,\n",
      "         1.6748e-07, 5.2838e-08, 7.4922e-09, 4.1349e-09],\n",
      "        [2.1146e-01, 2.3790e-01, 3.9035e-01, 1.4861e-01, 7.5929e-03, 1.4981e-03,\n",
      "         1.7145e-03, 6.0791e-04, 1.8702e-04, 7.7585e-05],\n",
      "        [2.9621e-02, 2.0716e-01, 4.6865e-01, 2.4463e-01, 2.3262e-02, 9.0385e-03,\n",
      "         1.1098e-02, 4.4149e-03, 1.6361e-03, 4.8645e-04],\n",
      "        [3.4009e-03, 3.7126e-02, 2.6506e-01, 4.2725e-01, 1.1655e-01, 4.8626e-02,\n",
      "         6.4670e-02, 2.2983e-02, 1.0722e-02, 3.6055e-03],\n",
      "        [2.4546e-04, 2.0885e-03, 3.4109e-02, 2.9279e-01, 2.1780e-01, 6.1782e-02,\n",
      "         1.8066e-01, 1.0176e-01, 7.0692e-02, 3.8073e-02],\n",
      "        [6.2335e-05, 1.1431e-03, 1.4380e-02, 1.2418e-01, 6.3828e-01, 1.2626e-01,\n",
      "         5.9529e-02, 9.0660e-03, 1.1605e-02, 1.5497e-02],\n",
      "        [3.3580e-05, 1.6825e-03, 8.0925e-03, 3.3101e-02, 6.1069e-01, 3.0853e-01,\n",
      "         2.8755e-02, 2.4676e-03, 2.1143e-03, 4.5353e-03],\n",
      "        [3.3777e-05, 1.5565e-03, 4.8952e-03, 1.7642e-02, 5.1016e-01, 4.1524e-01,\n",
      "         4.0161e-02, 3.8556e-03, 2.3061e-03, 4.1450e-03],\n",
      "        [2.1544e-05, 9.3103e-05, 6.2172e-04, 2.3691e-03, 8.3324e-02, 3.2625e-01,\n",
      "         4.9131e-01, 6.2347e-02, 1.7441e-02, 1.6224e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1.24, Train Loss: 4.27, Val Loss: 4.62, Train BLEU: 7.74, Val BLEU: 7.21, Minutes Elapsed: 63.96\n",
      "Sampling from training predictions...\n",
      "Source: có nhiều người gian_lận bằng cách ăn_gian 1 chút .\n",
      "Reference: we got a lot of people cheating by stealing\n",
      "Model: <SOS> there are a lot of to to a a\n",
      "Attention Weights: tensor([[9.9753e-01, 2.4645e-03, 6.7569e-06, 6.9229e-07, 1.7728e-07, 4.8593e-08,\n",
      "         3.3199e-08, 3.4480e-08, 4.4511e-09, 2.2872e-09],\n",
      "        [7.7899e-01, 2.1578e-01, 3.6990e-03, 8.7233e-04, 3.4968e-04, 1.9937e-04,\n",
      "         5.0909e-05, 3.5658e-05, 1.6750e-05, 4.8464e-06],\n",
      "        [3.3137e-01, 4.1990e-01, 1.6121e-01, 3.6649e-02, 2.7369e-02, 1.5832e-02,\n",
      "         3.5815e-03, 2.5474e-03, 1.2555e-03, 2.9356e-04],\n",
      "        [6.7801e-03, 1.9315e-01, 4.9293e-01, 1.9334e-01, 7.0405e-02, 3.4921e-02,\n",
      "         4.4094e-03, 2.3225e-03, 1.4521e-03, 2.8487e-04],\n",
      "        [1.9622e-03, 2.3254e-02, 3.0631e-01, 3.8798e-01, 1.6119e-01, 8.9722e-02,\n",
      "         1.4693e-02, 8.8048e-03, 4.8251e-03, 1.2603e-03],\n",
      "        [3.7954e-04, 2.8622e-03, 6.6420e-02, 2.4225e-01, 3.4187e-01, 2.3228e-01,\n",
      "         5.2706e-02, 3.7025e-02, 1.8402e-02, 5.8122e-03],\n",
      "        [3.0191e-05, 2.0618e-04, 2.3384e-03, 1.3649e-02, 1.8216e-01, 2.2706e-01,\n",
      "         1.7586e-01, 2.6040e-01, 1.2348e-01, 1.4812e-02],\n",
      "        [5.2187e-05, 2.0386e-04, 9.5496e-04, 4.2851e-03, 6.1540e-02, 7.5134e-02,\n",
      "         1.0608e-01, 2.8717e-01, 3.7227e-01, 9.2310e-02],\n",
      "        [6.4698e-05, 3.8836e-04, 2.7168e-03, 6.0540e-03, 3.4107e-02, 7.4476e-02,\n",
      "         1.3227e-01, 2.1805e-01, 4.0123e-01, 1.3064e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: động_cơ đốt trong không bền_vững . <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: the internal combustion engine is not sustainable . <EOS>\n",
      "Model: <SOS> the the is is not <EOS> . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9881, 0.0117, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2345, 0.5694, 0.1912, 0.0046, 0.0003, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0374, 0.0683, 0.5044, 0.3612, 0.0262, 0.0017, 0.0009, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0034, 0.0101, 0.2461, 0.6955, 0.0384, 0.0043, 0.0023, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0017, 0.0058, 0.1492, 0.6611, 0.1558, 0.0163, 0.0101, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0022, 0.0072, 0.0542, 0.3578, 0.4389, 0.0750, 0.0648, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0041, 0.0118, 0.0421, 0.2844, 0.3079, 0.1640, 0.1856, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0024, 0.0107, 0.0352, 0.2064, 0.2023, 0.2323, 0.3107, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0049, 0.0211, 0.0523, 0.2510, 0.2127, 0.1858, 0.2722, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 1.29, Train Loss: 4.26, Val Loss: 4.60, Train BLEU: 7.82, Val BLEU: 6.80, Minutes Elapsed: 66.43\n",
      "Sampling from training predictions...\n",
      "Source: sau_đó họ xé nó đi . không có bất_kỳ gian_lận\n",
      "Reference: then they shredded it . no cheating whatsoever .\n",
      "Model: <SOS> then they they it . . &apos;s . .\n",
      "Attention Weights: tensor([[9.9759e-01, 2.0871e-03, 3.2172e-04, 1.8874e-06, 3.5142e-08, 7.3009e-10,\n",
      "         5.6187e-11, 1.8596e-11, 4.3845e-12, 1.1990e-12],\n",
      "        [8.2022e-01, 1.2513e-01, 5.4459e-02, 1.8683e-04, 6.1383e-06, 4.0080e-07,\n",
      "         2.7462e-07, 5.3358e-08, 2.0648e-08, 9.2709e-09],\n",
      "        [4.6618e-04, 1.7857e-02, 9.5535e-01, 2.5117e-02, 1.0501e-03, 3.7232e-05,\n",
      "         7.8704e-05, 2.5858e-05, 1.1266e-05, 3.6954e-06],\n",
      "        [3.1420e-04, 3.9324e-03, 7.2472e-01, 2.4771e-01, 2.1966e-02, 4.4182e-04,\n",
      "         5.8914e-04, 2.0147e-04, 1.0755e-04, 2.1895e-05],\n",
      "        [2.9718e-04, 3.3370e-04, 1.0567e-01, 3.3804e-01, 5.1279e-01, 2.3085e-02,\n",
      "         1.0572e-02, 4.3533e-03, 3.1460e-03, 1.7182e-03],\n",
      "        [4.2039e-04, 2.3557e-04, 7.1221e-03, 1.1537e-02, 4.9514e-02, 1.1962e-01,\n",
      "         6.0050e-01, 1.4529e-01, 3.6874e-02, 2.8882e-02],\n",
      "        [1.9255e-04, 6.5402e-05, 1.8209e-03, 3.4924e-03, 9.6290e-03, 4.9318e-02,\n",
      "         6.4030e-01, 2.2391e-01, 4.6727e-02, 2.4551e-02],\n",
      "        [1.5450e-04, 3.3491e-04, 1.0647e-02, 8.0090e-03, 8.2394e-03, 2.6827e-02,\n",
      "         4.0982e-01, 3.1676e-01, 1.5331e-01, 6.5910e-02],\n",
      "        [8.2491e-05, 2.1642e-05, 4.4482e-04, 1.2323e-03, 4.7027e-03, 2.4040e-02,\n",
      "         4.2273e-01, 2.4656e-01, 1.2892e-01, 1.7126e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: nhiếp_ảnh là niềm đam_mê của tôi kể từ khi tôi\n",
      "Reference: photography has been my passion ever since i was\n",
      "Model: <SOS> my is my my my of i i i\n",
      "Attention Weights: tensor([[9.9706e-01, 2.9340e-03, 5.9420e-06, 6.0583e-07, 6.9226e-08, 9.1156e-09,\n",
      "         4.3430e-09, 2.7580e-09, 5.6818e-10, 2.7707e-10],\n",
      "        [5.6568e-01, 4.0484e-01, 2.7725e-02, 1.4660e-03, 1.2270e-04, 8.0832e-05,\n",
      "         4.6912e-05, 2.1524e-05, 1.0494e-05, 6.7641e-06],\n",
      "        [2.1586e-01, 3.3058e-01, 3.5033e-01, 7.7275e-02, 6.5373e-03, 1.1111e-02,\n",
      "         6.7519e-03, 7.9982e-04, 4.7764e-04, 2.7820e-04],\n",
      "        [4.6860e-03, 1.9143e-02, 5.0937e-01, 3.3563e-01, 4.8264e-02, 3.6108e-02,\n",
      "         3.9949e-02, 4.3151e-03, 1.6900e-03, 8.4104e-04],\n",
      "        [3.6143e-04, 6.4393e-03, 1.1566e-01, 3.1843e-01, 1.8310e-01, 1.0276e-01,\n",
      "         2.2122e-01, 3.6647e-02, 1.1760e-02, 3.6161e-03],\n",
      "        [5.4534e-05, 3.5000e-04, 9.3199e-03, 1.1473e-01, 1.2973e-01, 9.3693e-02,\n",
      "         3.8130e-01, 1.7143e-01, 8.4919e-02, 1.4472e-02],\n",
      "        [7.3070e-05, 1.7728e-04, 1.5299e-03, 1.2832e-02, 2.2722e-02, 3.8333e-02,\n",
      "         2.7081e-01, 2.6133e-01, 3.2354e-01, 6.8654e-02],\n",
      "        [1.2575e-04, 1.4455e-04, 1.0896e-03, 3.8000e-03, 7.3038e-03, 1.4422e-02,\n",
      "         1.4473e-01, 2.7095e-01, 3.3908e-01, 2.1835e-01],\n",
      "        [2.4884e-04, 2.2028e-04, 1.8851e-03, 4.6808e-03, 7.5507e-03, 1.2390e-02,\n",
      "         1.4095e-01, 2.8949e-01, 3.1483e-01, 2.2775e-01]])\n",
      "\n",
      "Epoch: 1.34, Train Loss: 4.25, Val Loss: 4.56, Train BLEU: 7.63, Val BLEU: 7.02, Minutes Elapsed: 68.92\n",
      "Sampling from training predictions...\n",
      "Source: tất_cả mọi người sẽ hụt_hẫng . bạn bước vào cuộc_chơi\n",
      "Reference: everybody is thrown off . you go in for\n",
      "Model: <SOS> all all be . . you you at the\n",
      "Attention Weights: tensor([[6.9263e-01, 3.0613e-01, 1.1106e-03, 1.3015e-04, 4.5218e-06, 1.2389e-07,\n",
      "         8.8289e-09, 3.8596e-09, 7.3666e-10, 2.9279e-10],\n",
      "        [3.7402e-02, 3.0056e-01, 2.8860e-01, 3.5566e-01, 1.7489e-02, 2.1487e-04,\n",
      "         4.6517e-05, 1.8288e-05, 3.3810e-06, 3.0572e-06],\n",
      "        [5.2363e-03, 4.7210e-02, 8.1298e-02, 7.3018e-01, 1.3152e-01, 2.8656e-03,\n",
      "         8.4228e-04, 6.2461e-04, 1.4974e-04, 7.5202e-05],\n",
      "        [1.7441e-04, 4.7835e-04, 4.4551e-03, 1.3804e-01, 7.9355e-01, 4.6997e-02,\n",
      "         8.8458e-03, 5.6359e-03, 1.1445e-03, 6.8381e-04],\n",
      "        [2.5625e-04, 5.5664e-04, 3.1458e-03, 8.5587e-02, 4.6449e-01, 2.9335e-01,\n",
      "         1.2477e-01, 2.1698e-02, 3.2630e-03, 2.8851e-03],\n",
      "        [2.5235e-04, 4.0304e-04, 6.6665e-04, 3.5435e-02, 3.4390e-02, 1.4075e-01,\n",
      "         6.4493e-01, 1.2348e-01, 1.2018e-02, 7.6712e-03],\n",
      "        [8.5918e-05, 1.2651e-04, 2.1752e-04, 5.2687e-03, 5.8773e-03, 3.5523e-02,\n",
      "         6.5468e-01, 2.5140e-01, 2.9110e-02, 1.7715e-02],\n",
      "        [5.2882e-05, 2.3663e-04, 8.7480e-04, 3.0584e-02, 2.7153e-02, 6.6123e-03,\n",
      "         1.4519e-01, 5.3780e-01, 1.6942e-01, 8.2077e-02],\n",
      "        [1.1959e-04, 1.5564e-04, 2.5690e-04, 2.5670e-03, 1.7631e-02, 1.8332e-02,\n",
      "         1.1611e-01, 3.3123e-01, 2.4438e-01, 2.6922e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: chúng_tôi có những nhóm tình_nguyện viên trợ_giúp cho enterprise <UNK>\n",
      "Reference: we have groups of volunteers supporting the enterprise facilitator\n",
      "Model: <SOS> we have these <UNK> <UNK> for for <UNK> of\n",
      "Attention Weights: tensor([[1.5591e-01, 8.4275e-01, 1.3302e-03, 8.9994e-06, 4.9182e-07, 1.1421e-07,\n",
      "         4.3294e-08, 1.1009e-08, 6.7036e-09, 7.7267e-09],\n",
      "        [1.4154e-01, 7.0373e-01, 1.5188e-01, 2.3185e-03, 3.7103e-04, 8.0451e-05,\n",
      "         5.1344e-05, 1.7878e-05, 6.8352e-06, 3.4829e-06],\n",
      "        [4.7500e-03, 1.1441e-01, 8.0481e-01, 5.9781e-02, 1.2303e-02, 2.6332e-03,\n",
      "         8.7293e-04, 2.9399e-04, 9.2180e-05, 5.0576e-05],\n",
      "        [2.9439e-04, 5.2465e-03, 1.5698e-01, 3.7923e-01, 3.3381e-01, 7.2104e-02,\n",
      "         4.3787e-02, 6.6103e-03, 1.4241e-03, 5.1858e-04],\n",
      "        [4.6141e-05, 2.4169e-03, 1.2065e-02, 5.4275e-02, 2.9262e-01, 2.5323e-01,\n",
      "         2.9056e-01, 8.1928e-02, 9.9018e-03, 2.9543e-03],\n",
      "        [1.2014e-05, 2.7241e-04, 1.2423e-03, 4.3706e-03, 2.9962e-02, 1.0785e-01,\n",
      "         3.3935e-01, 3.2041e-01, 1.3500e-01, 6.1527e-02],\n",
      "        [7.0457e-05, 1.0757e-03, 1.4904e-03, 2.9826e-03, 1.2471e-02, 6.0402e-02,\n",
      "         2.3247e-01, 4.7555e-01, 1.1366e-01, 9.9830e-02],\n",
      "        [3.6952e-05, 4.1718e-04, 2.1984e-03, 7.0767e-03, 1.9349e-02, 3.6905e-02,\n",
      "         1.1833e-01, 2.3032e-01, 1.9679e-01, 3.8858e-01],\n",
      "        [3.1451e-04, 6.1169e-03, 8.3190e-03, 1.8569e-02, 4.2907e-02, 7.0764e-02,\n",
      "         1.4181e-01, 2.1224e-01, 1.0421e-01, 3.9475e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1.38, Train Loss: 4.23, Val Loss: 4.55, Train BLEU: 8.35, Val BLEU: 7.44, Minutes Elapsed: 71.45\n",
      "Sampling from training predictions...\n",
      "Source: trong một nhà_thờ gothic , thứ âm_nhạc này mới là\n",
      "Reference: in a gothic cathedral , this kind of music\n",
      "Model: <SOS> in a case , , this &apos;s a is\n",
      "Attention Weights: tensor([[9.9246e-01, 7.5304e-03, 1.2980e-05, 3.3938e-07, 3.3615e-08, 6.3925e-08,\n",
      "         2.2595e-08, 2.3220e-09, 8.6738e-10, 3.2716e-10],\n",
      "        [1.1081e-01, 8.2901e-01, 5.7319e-02, 2.2568e-03, 2.2392e-04, 2.6416e-04,\n",
      "         9.3137e-05, 1.2633e-05, 9.4162e-06, 6.0636e-06],\n",
      "        [3.9411e-02, 2.7474e-01, 5.1925e-01, 1.3256e-01, 1.7520e-02, 1.0001e-02,\n",
      "         4.8925e-03, 6.4295e-04, 5.9097e-04, 3.8058e-04],\n",
      "        [2.8091e-03, 9.7362e-02, 2.8865e-01, 2.7775e-01, 2.6386e-01, 5.2843e-02,\n",
      "         1.0882e-02, 1.8745e-03, 2.4697e-03, 1.5007e-03],\n",
      "        [6.1006e-04, 1.8533e-02, 6.2398e-02, 9.5504e-02, 5.4192e-01, 2.4512e-01,\n",
      "         2.4269e-02, 2.9416e-03, 5.2248e-03, 3.4794e-03],\n",
      "        [1.2776e-04, 2.6734e-03, 1.1608e-02, 2.4596e-02, 1.4244e-01, 6.0631e-01,\n",
      "         1.7362e-01, 1.1179e-02, 1.7022e-02, 1.0414e-02],\n",
      "        [1.1197e-04, 3.1642e-04, 1.7584e-03, 5.1757e-03, 3.1109e-02, 2.9935e-01,\n",
      "         4.9429e-01, 4.8653e-02, 8.0473e-02, 3.8760e-02],\n",
      "        [2.4019e-03, 4.0558e-03, 7.4069e-03, 1.2836e-02, 6.9809e-03, 5.9820e-02,\n",
      "         2.9810e-01, 1.6784e-01, 2.2870e-01, 2.1186e-01],\n",
      "        [7.6632e-05, 1.9708e-04, 2.2930e-03, 9.7876e-03, 1.7166e-02, 6.4001e-02,\n",
      "         1.1052e-01, 8.4840e-02, 2.4337e-01, 4.6775e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: em không nhớ liệu em có xoáy thanh kẹo sô\n",
      "Reference: he doesn &apos;t remember if he stole my chocolate\n",
      "Model: <SOS> you don &apos;t know you you have a a\n",
      "Attention Weights: tensor([[6.8026e-01, 3.1776e-01, 1.9485e-03, 2.2723e-05, 2.6856e-06, 1.0519e-06,\n",
      "         1.4181e-07, 3.2265e-08, 2.5794e-08, 1.8398e-08],\n",
      "        [6.7097e-03, 8.7149e-01, 1.1803e-01, 2.7033e-03, 6.7349e-04, 2.2786e-04,\n",
      "         9.6367e-05, 3.0025e-05, 1.8902e-05, 1.2798e-05],\n",
      "        [1.3356e-02, 8.0104e-01, 1.4134e-01, 3.2957e-02, 6.4486e-03, 2.7709e-03,\n",
      "         1.0683e-03, 4.4530e-04, 3.3915e-04, 2.3133e-04],\n",
      "        [8.6950e-04, 1.4872e-01, 4.8467e-01, 2.6306e-01, 6.6815e-02, 2.2686e-02,\n",
      "         7.9716e-03, 2.6879e-03, 1.5851e-03, 9.3913e-04],\n",
      "        [5.9785e-05, 7.2050e-02, 2.2537e-01, 2.5069e-01, 2.1003e-01, 1.5993e-01,\n",
      "         5.7081e-02, 1.5606e-02, 6.4605e-03, 2.7235e-03],\n",
      "        [4.8525e-06, 4.4397e-04, 4.4387e-02, 4.6131e-01, 2.7318e-01, 8.8980e-02,\n",
      "         7.4315e-02, 3.9176e-02, 1.2553e-02, 5.6473e-03],\n",
      "        [2.4460e-06, 1.0196e-03, 2.4044e-03, 2.1600e-02, 3.9978e-01, 3.1764e-01,\n",
      "         6.9863e-02, 8.3868e-02, 6.8288e-02, 3.5537e-02],\n",
      "        [8.4493e-06, 3.7759e-03, 4.7377e-03, 1.0273e-02, 1.0017e-01, 3.9147e-01,\n",
      "         1.4315e-01, 1.2118e-01, 1.5461e-01, 7.0627e-02],\n",
      "        [6.8211e-07, 6.8669e-05, 1.9604e-03, 1.1875e-02, 4.8834e-02, 6.7516e-02,\n",
      "         1.2694e-01, 2.6755e-01, 2.7696e-01, 1.9830e-01]])\n",
      "\n",
      "Epoch: 1.43, Train Loss: 4.22, Val Loss: 4.50, Train BLEU: 8.07, Val BLEU: 7.29, Minutes Elapsed: 73.93\n",
      "Sampling from training predictions...\n",
      "Source: sau_đây là bài biểu_diễn cuối_cùng của tôi , nhưng trước\n",
      "Reference: and i &apos;m going to leave you with one\n",
      "Model: <SOS> and , is my my my my , ,\n",
      "Attention Weights: tensor([[9.9505e-01, 4.9457e-03, 2.0897e-06, 1.3223e-08, 1.8390e-09, 1.0535e-10,\n",
      "         3.8045e-11, 4.9278e-12, 3.7297e-12, 2.8076e-12],\n",
      "        [3.0394e-01, 6.6240e-01, 3.1562e-02, 1.7304e-03, 3.3698e-04, 1.5379e-05,\n",
      "         9.0992e-06, 4.2386e-06, 3.3623e-06, 2.3769e-06],\n",
      "        [2.4610e-02, 4.4503e-01, 3.0567e-01, 1.8703e-01, 3.0567e-02, 1.7049e-03,\n",
      "         2.8770e-03, 9.2351e-04, 8.5000e-04, 7.3746e-04],\n",
      "        [8.2859e-03, 1.6258e-01, 2.7406e-01, 4.3053e-01, 1.0367e-01, 5.2553e-03,\n",
      "         6.3511e-03, 2.4328e-03, 3.7222e-03, 3.1092e-03],\n",
      "        [2.0637e-05, 7.3441e-04, 1.2020e-02, 2.6548e-01, 6.7965e-01, 1.9683e-02,\n",
      "         1.2471e-02, 6.0607e-03, 2.5958e-03, 1.2916e-03],\n",
      "        [4.4441e-05, 2.4215e-03, 2.7718e-02, 1.1287e-01, 6.7184e-01, 6.1909e-02,\n",
      "         5.2202e-02, 3.8688e-02, 2.3411e-02, 8.8997e-03],\n",
      "        [2.4021e-05, 4.6309e-04, 7.1347e-03, 1.4848e-01, 5.7302e-01, 6.3396e-02,\n",
      "         7.5027e-02, 5.7315e-02, 4.7298e-02, 2.7835e-02],\n",
      "        [1.9256e-05, 1.6341e-04, 1.7266e-03, 2.0278e-02, 2.6894e-01, 8.4030e-02,\n",
      "         9.3112e-02, 2.4845e-01, 2.0122e-01, 8.2059e-02],\n",
      "        [1.3822e-05, 9.2225e-05, 3.8585e-04, 2.8797e-03, 4.6406e-02, 3.0198e-02,\n",
      "         4.5238e-02, 3.3317e-01, 3.9998e-01, 1.4163e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: sau sáu tháng tại nhật bản , 1.100 tình_nguyện viên\n",
      "Reference: after six months in japan , 1,100 volunteers had\n",
      "Model: <SOS> after the the , , , , the ,\n",
      "Attention Weights: tensor([[9.4538e-01, 5.4469e-02, 1.5251e-04, 2.3276e-07, 4.2861e-09, 2.5355e-10,\n",
      "         1.7992e-11, 5.7547e-12, 5.8394e-12, 2.9642e-12],\n",
      "        [5.9471e-02, 9.0239e-01, 3.7433e-02, 6.5304e-04, 4.5146e-05, 6.4803e-06,\n",
      "         9.4040e-07, 3.5598e-07, 2.0165e-07, 9.5641e-08],\n",
      "        [2.9216e-03, 2.9556e-01, 6.4179e-01, 4.8937e-02, 9.2618e-03, 1.2778e-03,\n",
      "         1.5369e-04, 5.2600e-05, 3.2045e-05, 1.8175e-05],\n",
      "        [1.2632e-03, 1.2641e-01, 6.2496e-01, 1.8147e-01, 5.1442e-02, 1.1526e-02,\n",
      "         2.0769e-03, 4.1518e-04, 2.6909e-04, 1.7389e-04],\n",
      "        [1.7472e-04, 2.7977e-03, 3.6412e-02, 1.0061e-01, 2.1788e-01, 3.4487e-01,\n",
      "         2.2443e-01, 3.4721e-02, 2.4984e-02, 1.3111e-02],\n",
      "        [2.6714e-05, 2.2316e-04, 3.4027e-03, 1.1511e-02, 3.9358e-02, 1.3994e-01,\n",
      "         4.0125e-01, 2.0719e-01, 1.3507e-01, 6.2026e-02],\n",
      "        [1.5406e-04, 6.2779e-04, 2.3032e-03, 3.1571e-03, 6.3432e-03, 3.3531e-02,\n",
      "         3.3388e-01, 1.6429e-01, 3.0658e-01, 1.4913e-01],\n",
      "        [5.5461e-05, 1.8916e-04, 1.8631e-03, 2.2352e-03, 2.6651e-03, 7.8184e-03,\n",
      "         6.1184e-02, 8.8791e-02, 4.8431e-01, 3.5089e-01],\n",
      "        [5.7145e-05, 8.8556e-04, 1.9315e-02, 7.7002e-03, 7.7439e-03, 6.6225e-03,\n",
      "         1.8173e-02, 7.4183e-02, 3.6402e-01, 5.0130e-01]])\n",
      "\n",
      "Epoch: 1.48, Train Loss: 4.19, Val Loss: 4.48, Train BLEU: 7.82, Val BLEU: 7.05, Minutes Elapsed: 76.42\n",
      "Sampling from training predictions...\n",
      "Source: đó là sự thích_ứng . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: it &apos;s adaptive . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> that &apos;s a . <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.4632, 0.5339, 0.0029, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0737, 0.6288, 0.2396, 0.0562, 0.0014, 0.0003, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0485, 0.2639, 0.3284, 0.3444, 0.0123, 0.0025, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0028, 0.0271, 0.1013, 0.7690, 0.0737, 0.0262, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0035, 0.0121, 0.0829, 0.5038, 0.2215, 0.1763, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0325, 0.0675, 0.1060, 0.1932, 0.1467, 0.4540, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0526, 0.1166, 0.1306, 0.2898, 0.1146, 0.2957, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0069, 0.0166, 0.0463, 0.1448, 0.1310, 0.6545, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0334, 0.0792, 0.1063, 0.1888, 0.1846, 0.4076, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tuy_nhiên , từng chút từng chút một , sự hưng_phấn\n",
      "Reference: however , bit by bit , the euphoria of\n",
      "Model: <SOS> but , , , a , , a ,\n",
      "Attention Weights: tensor([[9.9877e-01, 1.2014e-03, 2.9635e-05, 5.6136e-07, 6.6764e-08, 3.7984e-09,\n",
      "         7.1967e-10, 1.1488e-10, 1.6866e-10, 9.6490e-11],\n",
      "        [3.3875e-01, 4.9994e-01, 1.5852e-01, 2.3197e-03, 3.2883e-04, 9.7105e-05,\n",
      "         1.6616e-05, 7.8810e-06, 8.4848e-06, 6.4554e-06],\n",
      "        [4.8505e-02, 4.1766e-01, 5.0305e-01, 2.4229e-02, 4.3633e-03, 1.3386e-03,\n",
      "         2.9184e-04, 1.6324e-04, 2.2026e-04, 1.7421e-04],\n",
      "        [4.3399e-03, 6.2277e-02, 7.4741e-01, 1.4549e-01, 2.3282e-02, 1.3057e-02,\n",
      "         1.3677e-03, 8.1079e-04, 9.9367e-04, 9.7779e-04],\n",
      "        [1.6996e-03, 6.4169e-03, 1.3691e-01, 3.6236e-01, 2.7575e-01, 1.8084e-01,\n",
      "         1.8577e-02, 6.2995e-03, 4.4621e-03, 6.6757e-03],\n",
      "        [2.5467e-04, 9.9465e-04, 3.5154e-02, 1.4719e-01, 2.2554e-01, 3.7051e-01,\n",
      "         8.8990e-02, 5.8498e-02, 3.0916e-02, 4.1956e-02],\n",
      "        [2.7468e-04, 1.8803e-03, 1.0238e-02, 4.1369e-02, 1.0202e-01, 1.7169e-01,\n",
      "         1.1653e-01, 2.2835e-01, 1.5393e-01, 1.7372e-01],\n",
      "        [1.0028e-04, 3.2865e-04, 4.4567e-03, 1.5118e-02, 4.3056e-02, 1.0662e-01,\n",
      "         6.7517e-02, 1.6174e-01, 2.4923e-01, 3.5183e-01],\n",
      "        [1.7870e-04, 8.2768e-04, 1.2976e-02, 6.0270e-02, 1.4498e-01, 1.5421e-01,\n",
      "         3.3361e-02, 6.8881e-02, 1.6169e-01, 3.6262e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1.53, Train Loss: 4.21, Val Loss: 4.50, Train BLEU: 8.43, Val BLEU: 7.93, Minutes Elapsed: 78.94\n",
      "Sampling from training predictions...\n",
      "Source: và tất_cả những chất tự rửa <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: and it could be things that need to be\n",
      "Model: <SOS> and all all all all of . . <EOS>\n",
      "Attention Weights: tensor([[0.0685, 0.9087, 0.0227, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0419, 0.9440, 0.0139, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0009, 0.1090, 0.7273, 0.1576, 0.0048, 0.0004, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0023, 0.0368, 0.5346, 0.3521, 0.0674, 0.0062, 0.0006, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0021, 0.0097, 0.2099, 0.2374, 0.4646, 0.0716, 0.0047, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0019, 0.0053, 0.0370, 0.0629, 0.5281, 0.3280, 0.0368, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0103, 0.0083, 0.0304, 0.0647, 0.4705, 0.3328, 0.0830, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0038, 0.0074, 0.0211, 0.0365, 0.1718, 0.4434, 0.3160, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0023, 0.0097, 0.0257, 0.0517, 0.1218, 0.3575, 0.4313, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: sau cuộc nói_chuyện , tôi thấy thật kinh_khủng và thực_sự\n",
      "Reference: after we finished talking , i felt so horrible\n",
      "Model: <SOS> after the first , , i i , and\n",
      "Attention Weights: tensor([[7.6714e-01, 2.3269e-01, 1.6948e-04, 1.3961e-07, 4.5539e-09, 9.3886e-09,\n",
      "         1.6218e-09, 3.4103e-10, 4.0821e-11, 4.1472e-11],\n",
      "        [1.6744e-02, 9.0791e-01, 7.5063e-02, 2.6270e-04, 1.1145e-05, 8.9760e-06,\n",
      "         2.5347e-06, 1.4191e-06, 1.4690e-07, 1.6929e-07],\n",
      "        [6.4008e-03, 6.9938e-01, 2.8996e-01, 2.5695e-03, 4.4048e-04, 8.3310e-04,\n",
      "         2.7271e-04, 1.1776e-04, 1.0422e-05, 1.3050e-05],\n",
      "        [1.0539e-02, 2.8675e-01, 4.5396e-01, 1.5083e-01, 3.3946e-02, 4.2612e-02,\n",
      "         1.5527e-02, 4.3484e-03, 6.4971e-04, 8.3115e-04],\n",
      "        [2.2130e-04, 2.9882e-03, 4.8217e-02, 2.8026e-01, 5.7269e-02, 3.5790e-01,\n",
      "         1.4906e-01, 8.2336e-02, 1.0133e-02, 1.1624e-02],\n",
      "        [4.0749e-05, 6.8476e-04, 5.2477e-03, 1.4077e-01, 2.8241e-01, 4.1377e-01,\n",
      "         7.5438e-02, 4.6451e-02, 1.4360e-02, 2.0815e-02],\n",
      "        [1.0725e-05, 3.4744e-04, 1.8191e-03, 2.1388e-02, 9.2859e-02, 6.1857e-01,\n",
      "         1.8135e-01, 6.2403e-02, 7.5449e-03, 1.3702e-02],\n",
      "        [6.0175e-05, 1.7488e-03, 5.9472e-03, 3.1814e-03, 1.0869e-02, 5.0252e-01,\n",
      "         3.8466e-01, 6.9572e-02, 7.8081e-03, 1.3630e-02],\n",
      "        [1.1714e-05, 1.1008e-04, 4.1582e-04, 1.0779e-03, 5.3792e-04, 1.6265e-02,\n",
      "         1.2801e-01, 6.8127e-01, 9.4974e-02, 7.7324e-02]])\n",
      "\n",
      "Epoch: 1.58, Train Loss: 4.17, Val Loss: 4.44, Train BLEU: 8.50, Val BLEU: 8.09, Minutes Elapsed: 81.37\n",
      "Sampling from training predictions...\n",
      "Source: các nhà khoa_học phải được thắt_chặt hoàn_toàn vào ghế để\n",
      "Reference: and the scientists have to be completely harnessed in\n",
      "Model: <SOS> the are have are have to to to to\n",
      "Attention Weights: tensor([[1.2793e-01, 7.3552e-01, 1.3444e-01, 2.1010e-03, 3.0074e-06, 3.9562e-08,\n",
      "         4.1878e-09, 7.2578e-10, 4.4754e-10, 2.9471e-10],\n",
      "        [2.4687e-03, 6.4650e-03, 4.2816e-01, 5.3718e-01, 2.5218e-02, 3.3898e-04,\n",
      "         1.2292e-04, 2.1118e-05, 1.3402e-05, 8.8074e-06],\n",
      "        [1.3171e-03, 2.1667e-03, 4.5983e-02, 6.7012e-01, 2.5158e-01, 1.8538e-02,\n",
      "         8.0664e-03, 1.1388e-03, 6.6271e-04, 4.2789e-04],\n",
      "        [1.5516e-03, 2.4726e-03, 5.5436e-02, 6.6341e-01, 2.4664e-01, 1.8940e-02,\n",
      "         9.6903e-03, 1.0187e-03, 5.4484e-04, 3.0182e-04],\n",
      "        [1.0738e-03, 1.3493e-03, 5.7737e-02, 6.8609e-01, 2.1793e-01, 2.1817e-02,\n",
      "         1.1646e-02, 1.4073e-03, 6.1537e-04, 3.3328e-04],\n",
      "        [1.0405e-04, 1.5952e-04, 2.5539e-03, 7.7092e-02, 4.5432e-01, 1.3215e-01,\n",
      "         2.8314e-01, 3.8756e-02, 9.1994e-03, 2.5258e-03],\n",
      "        [3.0253e-05, 7.5645e-05, 3.1556e-04, 3.5703e-03, 6.7084e-02, 1.0872e-01,\n",
      "         6.6258e-01, 1.0779e-01, 3.6004e-02, 1.3829e-02],\n",
      "        [7.7640e-06, 3.1242e-05, 9.2374e-05, 1.0293e-03, 3.0224e-02, 9.0445e-02,\n",
      "         5.7542e-01, 2.1321e-01, 6.0473e-02, 2.9069e-02],\n",
      "        [3.3029e-06, 1.7740e-05, 4.1423e-05, 2.7654e-04, 6.3231e-03, 3.9674e-02,\n",
      "         3.2705e-01, 3.9729e-01, 1.4816e-01, 8.1167e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: cũng giống_như <UNK> triệu người mĩ khác , tôi sống\n",
      "Reference: just like <UNK> million other americans , i live\n",
      "Model: <SOS> it &apos;s to million , i i i have\n",
      "Attention Weights: tensor([[9.9613e-01, 3.8321e-03, 3.1865e-05, 4.4001e-06, 1.1822e-07, 1.1221e-08,\n",
      "         2.5442e-09, 2.3526e-10, 1.4676e-10, 1.4374e-10],\n",
      "        [3.1109e-01, 5.5365e-01, 1.0995e-01, 2.4470e-02, 7.2818e-04, 5.9162e-05,\n",
      "         3.3098e-05, 6.1212e-06, 3.1234e-06, 6.3307e-06],\n",
      "        [1.0509e-01, 3.4922e-01, 2.8769e-01, 2.1066e-01, 4.0994e-02, 3.8527e-03,\n",
      "         1.8466e-03, 3.6081e-04, 7.1583e-05, 2.1414e-04],\n",
      "        [9.4885e-04, 5.1632e-03, 3.2546e-02, 4.9959e-01, 3.6904e-01, 5.7219e-02,\n",
      "         3.0040e-02, 4.1804e-03, 4.4192e-04, 8.2790e-04],\n",
      "        [1.1133e-04, 5.5848e-04, 3.6787e-03, 1.8720e-01, 4.7475e-01, 1.5846e-01,\n",
      "         1.2063e-01, 4.4935e-02, 4.7214e-03, 4.9530e-03],\n",
      "        [1.3577e-05, 6.6922e-05, 1.7926e-04, 2.8047e-03, 9.4260e-03, 1.2542e-02,\n",
      "         2.5757e-02, 2.7001e-01, 4.1586e-01, 2.6334e-01],\n",
      "        [1.4214e-05, 8.3604e-05, 1.9766e-04, 4.8922e-03, 1.2475e-02, 1.4104e-02,\n",
      "         1.9926e-02, 1.4204e-01, 3.3115e-01, 4.7512e-01],\n",
      "        [1.9749e-05, 1.6262e-04, 3.3042e-04, 5.4538e-03, 1.4049e-02, 1.4634e-02,\n",
      "         2.1604e-02, 9.0199e-02, 1.8713e-01, 6.6641e-01],\n",
      "        [1.2890e-04, 3.7387e-04, 4.8321e-04, 1.6031e-02, 2.7256e-02, 2.9538e-02,\n",
      "         3.8177e-02, 7.0710e-02, 6.7937e-02, 7.4936e-01]])\n",
      "\n",
      "Epoch: 1.62, Train Loss: 4.14, Val Loss: 4.41, Train BLEU: 8.94, Val BLEU: 8.61, Minutes Elapsed: 83.86\n",
      "Sampling from training predictions...\n",
      "Source: và , như bạn biết , là cha_mẹ , nhất_là\n",
      "Reference: and , you know , as a parent ,\n",
      "Model: <SOS> and , you know , the is , ,\n",
      "Attention Weights: tensor([[4.3240e-04, 6.4305e-01, 3.4939e-01, 6.9954e-03, 1.3009e-04, 1.4685e-07,\n",
      "         2.5710e-09, 2.3818e-10, 5.5113e-11, 5.5267e-11],\n",
      "        [1.4811e-04, 8.4371e-01, 1.5405e-01, 2.0793e-03, 8.9786e-06, 6.9039e-08,\n",
      "         9.1274e-09, 1.6924e-09, 4.2671e-10, 5.3528e-10],\n",
      "        [6.0919e-05, 3.4673e-02, 7.9717e-01, 1.4739e-01, 1.9476e-02, 8.1446e-04,\n",
      "         2.6304e-04, 1.0340e-04, 2.5812e-05, 2.6887e-05],\n",
      "        [9.6280e-06, 1.7349e-03, 1.2264e-01, 3.7902e-01, 4.5884e-01, 2.7222e-02,\n",
      "         6.8009e-03, 2.7891e-03, 4.5263e-04, 4.9646e-04],\n",
      "        [1.5615e-05, 1.3784e-03, 3.0159e-02, 1.5658e-01, 7.4469e-01, 4.8810e-02,\n",
      "         1.0555e-02, 6.7926e-03, 5.5499e-04, 4.6646e-04],\n",
      "        [1.3587e-05, 1.9987e-04, 5.1381e-03, 3.8099e-03, 1.2437e-02, 2.7130e-01,\n",
      "         5.0241e-01, 1.3031e-01, 4.1110e-02, 3.3271e-02],\n",
      "        [4.4919e-06, 7.7996e-04, 3.3645e-03, 2.5153e-03, 1.3673e-03, 1.9072e-02,\n",
      "         3.6573e-01, 3.8591e-01, 1.0642e-01, 1.1484e-01],\n",
      "        [8.8508e-06, 5.6057e-04, 2.0778e-03, 1.6150e-03, 7.8798e-03, 1.3575e-02,\n",
      "         8.6113e-02, 4.5360e-01, 1.6586e-01, 2.6871e-01],\n",
      "        [4.0576e-06, 1.6226e-04, 5.4976e-04, 5.2942e-04, 1.2727e-03, 1.0048e-02,\n",
      "         8.0614e-02, 2.1370e-01, 2.5943e-01, 4.3369e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: xã_hội của chúng_tôi cần một cuộc đối_thoại cấp quốc_gia và\n",
      "Reference: our society needs national dialogue and <UNK> more than\n",
      "Model: <SOS> our society is a a a a and and\n",
      "Attention Weights: tensor([[9.9961e-01, 3.8460e-04, 8.4878e-06, 3.1524e-07, 9.1988e-09, 2.4656e-10,\n",
      "         6.1830e-11, 4.4514e-11, 3.7049e-11, 7.3830e-12],\n",
      "        [9.4599e-01, 3.4181e-02, 1.4850e-02, 4.7793e-03, 1.7648e-04, 1.8965e-05,\n",
      "         4.6301e-06, 1.9232e-06, 1.0769e-06, 3.3446e-07],\n",
      "        [1.5085e-02, 4.4969e-02, 2.0340e-01, 6.9951e-01, 2.8803e-02, 6.5099e-03,\n",
      "         9.7501e-04, 4.8478e-04, 2.0781e-04, 5.2967e-05],\n",
      "        [4.2788e-03, 1.4741e-02, 1.6035e-01, 6.6233e-01, 1.0050e-01, 4.8558e-02,\n",
      "         6.4816e-03, 1.9187e-03, 6.7409e-04, 1.6627e-04],\n",
      "        [1.1467e-03, 1.6749e-03, 5.8563e-03, 9.3303e-02, 2.1561e-01, 4.7950e-01,\n",
      "         1.4285e-01, 4.5300e-02, 1.3209e-02, 1.5616e-03],\n",
      "        [5.9031e-04, 5.8833e-04, 6.5358e-04, 1.7162e-02, 7.9174e-02, 5.8323e-01,\n",
      "         2.3115e-01, 6.0018e-02, 2.4476e-02, 2.9590e-03],\n",
      "        [1.8914e-04, 2.8841e-04, 2.5669e-04, 4.2533e-03, 1.1318e-02, 1.4836e-01,\n",
      "         2.9090e-01, 3.5694e-01, 1.5197e-01, 3.5513e-02],\n",
      "        [1.1778e-04, 2.8313e-04, 4.4147e-04, 5.4172e-03, 6.7028e-03, 2.4156e-02,\n",
      "         7.8772e-02, 3.0733e-01, 3.9773e-01, 1.7905e-01],\n",
      "        [1.8090e-04, 5.2134e-04, 1.3562e-03, 1.4696e-02, 1.3408e-02, 3.3186e-02,\n",
      "         7.0872e-02, 3.0191e-01, 3.1360e-01, 2.5027e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1.67, Train Loss: 4.15, Val Loss: 4.42, Train BLEU: 7.99, Val BLEU: 7.68, Minutes Elapsed: 86.34\n",
      "Sampling from training predictions...\n",
      "Source: nhưng những người nói tiếng hà_lan ở đây sẽ hiểu\n",
      "Reference: but the dutch people here will understand what i\n",
      "Model: <SOS> but the people who who that that tell that\n",
      "Attention Weights: tensor([[3.5187e-01, 6.4658e-01, 1.5486e-03, 6.3253e-06, 1.1753e-06, 1.1070e-07,\n",
      "         1.8927e-08, 1.6163e-09, 3.6284e-10, 1.3968e-10],\n",
      "        [3.1978e-02, 9.4976e-01, 1.8050e-02, 1.5088e-04, 5.8687e-05, 4.0548e-06,\n",
      "         1.0061e-06, 1.7221e-07, 7.9906e-08, 2.8851e-08],\n",
      "        [7.1293e-03, 5.6471e-01, 2.4747e-01, 1.1081e-01, 6.5762e-02, 3.2464e-03,\n",
      "         5.1343e-04, 1.8358e-04, 1.0599e-04, 7.8634e-05],\n",
      "        [1.5622e-03, 1.9503e-02, 6.1382e-02, 2.9504e-01, 4.5061e-01, 1.3752e-01,\n",
      "         2.6695e-02, 3.4390e-03, 2.2486e-03, 1.9975e-03],\n",
      "        [4.4020e-04, 3.8931e-03, 2.4445e-02, 2.7492e-01, 3.6356e-01, 1.6174e-01,\n",
      "         1.2872e-01, 2.5618e-02, 1.1986e-02, 4.6793e-03],\n",
      "        [2.5122e-05, 1.4130e-04, 9.5046e-04, 3.2684e-02, 1.4232e-01, 1.3759e-01,\n",
      "         4.2859e-01, 1.9742e-01, 4.4302e-02, 1.5972e-02],\n",
      "        [1.9817e-05, 4.5554e-05, 1.8678e-04, 2.0113e-03, 7.5133e-02, 9.9731e-02,\n",
      "         2.3982e-01, 2.9155e-01, 2.1515e-01, 7.6366e-02],\n",
      "        [7.5919e-06, 3.2412e-05, 8.5769e-05, 3.9698e-04, 9.3935e-03, 2.8503e-02,\n",
      "         1.2181e-01, 1.9131e-01, 3.5880e-01, 2.8966e-01],\n",
      "        [1.6095e-05, 2.6209e-05, 1.2789e-04, 5.0928e-04, 1.4530e-02, 2.9076e-02,\n",
      "         1.0589e-01, 8.2661e-02, 1.9148e-01, 5.7568e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: chúng_tôi đã có được một chiến_thắng trong tay . <EOS>\n",
      "Reference: we had a victory on our hands . <EOS>\n",
      "Model: <SOS> we &apos;ve a a in . . . <EOS>\n",
      "Attention Weights: tensor([[1.0122e-01, 8.6072e-01, 3.7674e-02, 3.6704e-04, 2.2482e-05, 1.9757e-07,\n",
      "         6.1716e-08, 1.0215e-08, 5.1884e-09, 6.1658e-09],\n",
      "        [4.5168e-02, 5.1318e-01, 2.7685e-01, 1.6038e-01, 4.0889e-03, 2.7505e-04,\n",
      "         3.9629e-05, 7.8562e-06, 3.7898e-06, 2.3827e-06],\n",
      "        [6.6676e-03, 1.0740e-01, 2.4597e-01, 5.8417e-01, 4.8428e-02, 6.6135e-03,\n",
      "         5.6371e-04, 1.1319e-04, 4.6920e-05, 2.6275e-05],\n",
      "        [4.6044e-04, 2.3027e-03, 1.0497e-02, 4.9417e-01, 2.5100e-01, 2.0722e-01,\n",
      "         3.1449e-02, 2.5344e-03, 2.1950e-04, 1.4336e-04],\n",
      "        [7.1991e-05, 7.2201e-04, 3.9455e-03, 1.2089e-01, 8.8997e-02, 5.6872e-01,\n",
      "         1.8341e-01, 2.9605e-02, 2.2945e-03, 1.3480e-03],\n",
      "        [4.4950e-05, 5.2108e-04, 2.1093e-03, 1.3684e-02, 2.2330e-02, 2.2314e-01,\n",
      "         4.8461e-01, 2.3517e-01, 1.2670e-02, 5.7238e-03],\n",
      "        [1.7947e-05, 6.2909e-05, 2.9023e-04, 2.7542e-03, 1.3543e-02, 7.4471e-02,\n",
      "         4.7417e-01, 3.8931e-01, 3.3472e-02, 1.1909e-02],\n",
      "        [1.0379e-04, 1.8279e-03, 2.9646e-03, 1.4920e-02, 1.1899e-02, 3.0666e-02,\n",
      "         2.9030e-01, 4.8697e-01, 1.1727e-01, 4.3080e-02],\n",
      "        [1.6103e-04, 1.3446e-03, 2.6388e-03, 1.2969e-02, 1.1530e-02, 2.0063e-02,\n",
      "         1.8993e-01, 5.0655e-01, 1.7398e-01, 8.0826e-02]])\n",
      "\n",
      "Epoch: 1.72, Train Loss: 4.14, Val Loss: 4.38, Train BLEU: 8.12, Val BLEU: 8.40, Minutes Elapsed: 88.82\n",
      "Sampling from training predictions...\n",
      "Source: đây là căn phòng mà bach viết một_số bản_nhạc .\n",
      "Reference: this is the room that bach wrote some of\n",
      "Model: <SOS> this is a picture of the a . .\n",
      "Attention Weights: tensor([[9.8293e-01, 1.7031e-02, 3.3970e-05, 6.0899e-07, 3.3666e-08, 4.6024e-09,\n",
      "         2.2676e-09, 3.1086e-09, 4.7427e-10, 1.6221e-10],\n",
      "        [9.7664e-02, 8.8699e-01, 1.2131e-02, 2.7030e-03, 2.7707e-04, 1.7973e-04,\n",
      "         2.9018e-05, 1.9945e-05, 5.9364e-06, 1.7574e-06],\n",
      "        [4.4970e-02, 7.4749e-01, 1.0746e-01, 7.6198e-02, 1.3435e-02, 7.3191e-03,\n",
      "         2.0121e-03, 6.9219e-04, 3.3953e-04, 7.4331e-05],\n",
      "        [1.0429e-02, 3.8041e-01, 1.4900e-01, 3.4223e-01, 4.8820e-02, 4.2354e-02,\n",
      "         1.6550e-02, 7.8778e-03, 2.0228e-03, 3.0652e-04],\n",
      "        [4.0987e-03, 1.9021e-01, 4.4123e-02, 2.4584e-01, 4.0226e-01, 3.8301e-02,\n",
      "         4.1984e-02, 2.2981e-02, 8.2870e-03, 1.9148e-03],\n",
      "        [2.3921e-04, 6.0853e-03, 4.2525e-03, 8.7261e-02, 6.6213e-01, 8.8964e-02,\n",
      "         7.7107e-02, 4.3542e-02, 2.1866e-02, 8.5540e-03],\n",
      "        [9.9475e-05, 6.7589e-04, 2.8482e-04, 8.7415e-03, 8.4507e-02, 1.2866e-01,\n",
      "         3.0215e-01, 3.8424e-01, 7.9570e-02, 1.1065e-02],\n",
      "        [3.0133e-04, 3.5808e-03, 2.0253e-04, 9.9327e-03, 4.6150e-02, 1.2494e-01,\n",
      "         3.3634e-01, 3.0178e-01, 1.6066e-01, 1.6112e-02],\n",
      "        [5.3248e-04, 3.9133e-03, 5.4819e-04, 7.2792e-03, 4.5038e-02, 4.7887e-02,\n",
      "         1.4577e-01, 3.5482e-01, 2.9172e-01, 1.0249e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi đã từng ghét sư_tử , nhưng bây_giờ bởi_vì phát_minh\n",
      "Reference: i used to hate lions , but now because\n",
      "Model: <SOS> i was been , , but but the the\n",
      "Attention Weights: tensor([[3.7544e-02, 9.4319e-01, 1.9228e-02, 3.5460e-05, 5.3815e-07, 7.8132e-08,\n",
      "         4.2072e-08, 1.7541e-08, 5.4512e-09, 2.9837e-09],\n",
      "        [3.1393e-02, 3.6520e-01, 5.9523e-01, 7.7378e-03, 7.0487e-05, 1.0802e-04,\n",
      "         1.3302e-04, 7.3887e-05, 4.3909e-05, 1.8798e-05],\n",
      "        [3.9518e-03, 9.5824e-02, 8.1097e-01, 8.7572e-02, 4.3931e-04, 3.2897e-04,\n",
      "         2.6898e-04, 3.2315e-04, 2.3612e-04, 8.2938e-05],\n",
      "        [2.7541e-04, 1.3787e-03, 7.0467e-02, 8.4967e-01, 3.1537e-02, 3.1110e-02,\n",
      "         9.5088e-03, 2.0123e-03, 2.5947e-03, 1.4447e-03],\n",
      "        [1.1299e-03, 4.4925e-03, 2.4020e-02, 5.0208e-01, 1.1197e-01, 1.7814e-01,\n",
      "         1.2249e-01, 2.3244e-02, 2.4351e-02, 8.0895e-03],\n",
      "        [1.9914e-03, 3.1493e-03, 6.4219e-03, 1.7157e-01, 9.6368e-02, 3.3876e-01,\n",
      "         2.7187e-01, 5.1752e-02, 4.2702e-02, 1.5407e-02],\n",
      "        [3.7245e-03, 1.5127e-03, 4.0962e-03, 1.2093e-02, 2.3950e-02, 1.8300e-01,\n",
      "         4.0792e-01, 1.8890e-01, 1.3349e-01, 4.1318e-02],\n",
      "        [3.6665e-03, 8.4815e-04, 1.2465e-03, 1.7735e-03, 4.2819e-03, 4.2662e-02,\n",
      "         2.2998e-01, 2.2432e-01, 3.8215e-01, 1.0907e-01],\n",
      "        [4.7018e-05, 7.7771e-04, 1.9389e-03, 1.9081e-03, 1.6987e-03, 1.1740e-02,\n",
      "         6.8358e-02, 1.6880e-01, 5.2402e-01, 2.2070e-01]])\n",
      "\n",
      "Epoch: 1.77, Train Loss: 4.15, Val Loss: 4.37, Train BLEU: 8.35, Val BLEU: 8.49, Minutes Elapsed: 91.31\n",
      "Sampling from training predictions...\n",
      "Source: nếu chẳng_may bạn phải dành nhiều thời_gian ở bệnh_viện ,\n",
      "Reference: and if you spend a lot of time in\n",
      "Model: <SOS> if you you you to a of the time\n",
      "Attention Weights: tensor([[9.3343e-02, 9.0291e-01, 3.3204e-03, 4.2619e-04, 1.0550e-06, 8.6548e-08,\n",
      "         1.1560e-08, 1.8662e-09, 8.7324e-10, 1.5014e-10],\n",
      "        [7.6439e-03, 9.7261e-01, 1.7983e-02, 1.7045e-03, 3.4668e-05, 1.1967e-05,\n",
      "         5.1221e-06, 1.4068e-06, 5.3791e-07, 1.6469e-07],\n",
      "        [2.2465e-03, 8.4517e-01, 9.2413e-02, 5.8748e-02, 9.6055e-04, 2.7932e-04,\n",
      "         1.0469e-04, 4.2743e-05, 2.6703e-05, 5.2555e-06],\n",
      "        [1.2790e-03, 3.0021e-01, 2.0170e-01, 4.4508e-01, 4.1810e-02, 7.2730e-03,\n",
      "         1.6020e-03, 6.1263e-04, 3.0917e-04, 1.2135e-04],\n",
      "        [3.9614e-04, 1.1199e-01, 4.4867e-02, 6.9958e-01, 1.0470e-01, 3.1273e-02,\n",
      "         5.4918e-03, 1.1782e-03, 4.1090e-04, 1.1395e-04],\n",
      "        [1.2553e-05, 6.8291e-04, 1.4107e-03, 1.8464e-01, 4.2071e-01, 2.6851e-01,\n",
      "         1.0583e-01, 1.3756e-02, 4.0490e-03, 4.0388e-04],\n",
      "        [1.2773e-06, 3.0823e-05, 2.2952e-04, 6.3705e-03, 1.3387e-01, 4.3816e-01,\n",
      "         2.9981e-01, 9.4749e-02, 2.4777e-02, 2.0028e-03],\n",
      "        [1.6356e-06, 1.3319e-05, 1.4434e-04, 8.3001e-04, 5.4835e-03, 6.6305e-02,\n",
      "         2.7583e-01, 4.4741e-01, 1.7986e-01, 2.4116e-02],\n",
      "        [1.7967e-06, 2.1494e-05, 7.0076e-05, 1.4714e-03, 8.4430e-03, 1.0148e-01,\n",
      "         3.0267e-01, 2.9370e-01, 2.4920e-01, 4.2944e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: và nếu bạn sử_dụng điện_thoại_di_động , thì đây chính là\n",
      "Reference: and if you use your mobile phone , where\n",
      "Model: <SOS> and if you &apos;re the , , , this\n",
      "Attention Weights: tensor([[3.3705e-02, 4.2525e-01, 4.1963e-01, 1.2097e-01, 4.4640e-04, 2.6924e-06,\n",
      "         1.1624e-07, 2.0341e-08, 5.6408e-09, 2.0941e-09],\n",
      "        [9.0461e-03, 8.8767e-01, 9.7866e-02, 5.4064e-03, 1.4320e-05, 2.9738e-07,\n",
      "         5.5956e-08, 3.7292e-08, 1.2252e-08, 4.9127e-09],\n",
      "        [1.8115e-04, 2.5931e-02, 8.2899e-01, 1.4292e-01, 1.8441e-03, 6.2692e-05,\n",
      "         3.5042e-05, 1.1639e-05, 1.0424e-05, 5.1077e-06],\n",
      "        [6.9552e-05, 3.1637e-03, 1.9148e-01, 7.8270e-01, 2.1401e-02, 4.4021e-04,\n",
      "         3.1026e-04, 1.6957e-04, 1.5521e-04, 1.0690e-04],\n",
      "        [2.7307e-04, 1.5312e-03, 4.1686e-02, 8.5655e-01, 9.8100e-02, 1.1764e-03,\n",
      "         2.8111e-04, 1.0154e-04, 1.7847e-04, 1.2653e-04],\n",
      "        [1.6948e-04, 9.6362e-04, 1.9185e-03, 1.2122e-01, 8.3043e-01, 3.9598e-02,\n",
      "         4.7832e-03, 4.0787e-04, 2.7461e-04, 2.3708e-04],\n",
      "        [2.1334e-04, 4.9387e-04, 1.2567e-03, 1.5377e-02, 2.6426e-01, 4.4382e-01,\n",
      "         2.4394e-01, 2.0366e-02, 5.4114e-03, 4.8687e-03],\n",
      "        [2.8743e-04, 7.2022e-04, 1.0178e-03, 4.7131e-03, 3.7391e-02, 2.2275e-01,\n",
      "         5.2297e-01, 1.6216e-01, 2.9986e-02, 1.8009e-02],\n",
      "        [9.1847e-05, 4.5906e-04, 1.2553e-03, 8.8303e-03, 1.6693e-02, 4.3804e-02,\n",
      "         3.7326e-01, 3.3386e-01, 1.6099e-01, 6.0762e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1.82, Train Loss: 4.13, Val Loss: 4.35, Train BLEU: 8.96, Val BLEU: 8.57, Minutes Elapsed: 93.85\n",
      "Sampling from training predictions...\n",
      "Source: vì_thế không có nhiều khả_năng bị phát_hiện <EOS> <PAD> <PAD>\n",
      "Reference: so it wasn &apos;t so much about the probability\n",
      "Model: <SOS> so there &apos;s no a a . . .\n",
      "Attention Weights: tensor([[0.9232, 0.0767, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0963, 0.8794, 0.0218, 0.0022, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1395, 0.7199, 0.0779, 0.0432, 0.0127, 0.0050, 0.0015, 0.0003, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0612, 0.5210, 0.0950, 0.1794, 0.0912, 0.0367, 0.0139, 0.0016, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0006, 0.0200, 0.1042, 0.5573, 0.2480, 0.0456, 0.0235, 0.0008, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0034, 0.0173, 0.3338, 0.4936, 0.0940, 0.0556, 0.0021, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0033, 0.0175, 0.2703, 0.4768, 0.1473, 0.0797, 0.0050, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0005, 0.0091, 0.0161, 0.0833, 0.2788, 0.4349, 0.1652, 0.0122, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0011, 0.0155, 0.0099, 0.0275, 0.1238, 0.5403, 0.2575, 0.0244, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: những cô gái này đã rất may_mắn . <EOS> <PAD>\n",
      "Reference: these girls were so lucky . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> these guys have been . . <EOS> <EOS> .\n",
      "Attention Weights: tensor([[0.9917, 0.0081, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.8189, 0.0563, 0.1176, 0.0042, 0.0022, 0.0006, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0203, 0.0259, 0.1032, 0.1540, 0.4755, 0.1902, 0.0274, 0.0024, 0.0012,\n",
      "         0.0000],\n",
      "        [0.0049, 0.0056, 0.0214, 0.0372, 0.2258, 0.5236, 0.1728, 0.0067, 0.0019,\n",
      "         0.0000],\n",
      "        [0.0016, 0.0008, 0.0092, 0.0331, 0.1764, 0.5304, 0.2395, 0.0065, 0.0026,\n",
      "         0.0000],\n",
      "        [0.0006, 0.0007, 0.0031, 0.0129, 0.1499, 0.4020, 0.3874, 0.0281, 0.0154,\n",
      "         0.0000],\n",
      "        [0.0006, 0.0009, 0.0028, 0.0093, 0.1350, 0.3547, 0.3791, 0.0707, 0.0469,\n",
      "         0.0000],\n",
      "        [0.0086, 0.0100, 0.0166, 0.0277, 0.1589, 0.2844, 0.2404, 0.1148, 0.1386,\n",
      "         0.0000],\n",
      "        [0.0293, 0.0168, 0.0709, 0.0856, 0.2527, 0.2852, 0.1297, 0.0798, 0.0500,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 1.86, Train Loss: 4.12, Val Loss: 4.34, Train BLEU: 8.44, Val BLEU: 8.61, Minutes Elapsed: 96.33\n",
      "Sampling from training predictions...\n",
      "Source: cái mà chúng_tôi không nhìn thấy trước được là sự\n",
      "Reference: what we could not have foreseen was the measurable\n",
      "Model: <SOS> what we don &apos;t see is is the .\n",
      "Attention Weights: tensor([[9.8173e-01, 1.8237e-02, 2.8586e-05, 4.5711e-06, 7.0715e-08, 1.2928e-09,\n",
      "         2.0323e-10, 2.0520e-11, 3.5784e-12, 2.6548e-12],\n",
      "        [1.2995e-01, 5.9267e-01, 1.5742e-01, 1.1363e-01, 6.0640e-03, 2.2969e-04,\n",
      "         3.0575e-05, 8.8994e-06, 2.2524e-06, 1.3492e-06],\n",
      "        [5.1588e-02, 1.3127e-01, 7.9665e-02, 6.0696e-01, 1.1557e-01, 1.3459e-02,\n",
      "         1.1009e-03, 2.2730e-04, 8.0915e-05, 8.1307e-05],\n",
      "        [1.4651e-02, 3.9708e-02, 4.7582e-02, 5.1227e-01, 3.2284e-01, 4.7353e-02,\n",
      "         1.2702e-02, 1.7827e-03, 5.8987e-04, 5.2231e-04],\n",
      "        [2.9320e-04, 5.9967e-04, 6.7522e-04, 5.0196e-03, 3.1222e-01, 5.5971e-01,\n",
      "         1.1061e-01, 9.0068e-03, 1.0849e-03, 7.7838e-04],\n",
      "        [1.0910e-04, 2.0603e-04, 1.5102e-04, 8.0224e-04, 1.6820e-02, 2.3461e-01,\n",
      "         5.4618e-01, 1.4287e-01, 2.8879e-02, 2.9379e-02],\n",
      "        [1.4985e-05, 2.1848e-05, 1.9783e-05, 3.3981e-04, 2.1989e-03, 2.8794e-02,\n",
      "         3.5355e-01, 2.2110e-01, 1.3630e-01, 2.5766e-01],\n",
      "        [3.6432e-05, 4.0549e-05, 2.0710e-05, 2.0606e-04, 9.0870e-04, 9.8716e-03,\n",
      "         1.4843e-01, 1.3112e-01, 2.1650e-01, 4.9287e-01],\n",
      "        [6.5870e-04, 1.0907e-03, 4.5261e-04, 1.4893e-03, 7.7601e-03, 1.5932e-02,\n",
      "         4.6554e-02, 1.4701e-01, 2.5108e-01, 5.2797e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: đó là môt sự_cố cá_biệt , và anh ta sẽ\n",
      "Reference: it was an isolated incident , and he was\n",
      "Model: <SOS> it &apos;s the to , , and he &apos;ll\n",
      "Attention Weights: tensor([[7.3989e-01, 2.5754e-01, 2.5578e-03, 1.6807e-05, 5.2600e-07, 1.2669e-08,\n",
      "         1.7403e-09, 5.5285e-10, 1.6578e-10, 5.3199e-10],\n",
      "        [3.6881e-02, 3.4003e-01, 5.9620e-01, 2.5203e-02, 1.4152e-03, 1.3777e-04,\n",
      "         2.6327e-05, 4.0097e-05, 2.1597e-05, 4.9960e-05],\n",
      "        [4.1904e-02, 1.5808e-01, 5.1294e-01, 2.3721e-01, 4.6811e-02, 1.3850e-03,\n",
      "         1.8407e-04, 4.8673e-04, 2.1132e-04, 7.9361e-04],\n",
      "        [3.2446e-04, 1.8549e-03, 2.5878e-01, 5.0870e-01, 2.1432e-01, 1.4741e-02,\n",
      "         8.9294e-04, 2.0918e-04, 5.4490e-05, 1.1953e-04],\n",
      "        [2.8491e-04, 4.9076e-03, 7.9390e-02, 4.3495e-01, 3.6256e-01, 1.0641e-01,\n",
      "         8.7133e-03, 1.6580e-03, 4.1001e-04, 7.2295e-04],\n",
      "        [1.1377e-04, 1.6404e-03, 1.4487e-02, 1.0104e-01, 2.3761e-01, 4.9910e-01,\n",
      "         1.1443e-01, 2.3219e-02, 3.9979e-03, 4.3577e-03],\n",
      "        [1.1073e-04, 3.1018e-04, 1.7967e-03, 6.1030e-03, 2.7944e-02, 4.3214e-01,\n",
      "         3.2196e-01, 1.4740e-01, 2.6309e-02, 3.5931e-02],\n",
      "        [2.3432e-03, 2.9787e-03, 1.0120e-02, 1.1534e-02, 1.7412e-02, 1.7521e-01,\n",
      "         2.5505e-01, 3.0943e-01, 6.3063e-02, 1.5286e-01],\n",
      "        [1.3484e-04, 9.9690e-04, 4.3268e-03, 4.4144e-03, 4.6340e-03, 5.8828e-03,\n",
      "         9.9224e-03, 7.3846e-02, 8.7939e-02, 8.0790e-01]])\n",
      "\n",
      "Epoch: 1.91, Train Loss: 4.11, Val Loss: 4.32, Train BLEU: 8.74, Val BLEU: 8.42, Minutes Elapsed: 98.83\n",
      "Sampling from training predictions...\n",
      "Source: thế_nhưng niềm vui_thích , niềm đam_mê và hạnh_phúc vẫn tồn_tại\n",
      "Reference: but the pleasure and the passion and the joy\n",
      "Model: <SOS> but the the , , , , and and\n",
      "Attention Weights: tensor([[6.8041e-01, 3.1904e-01, 5.5249e-04, 1.8655e-06, 1.0634e-06, 1.0148e-07,\n",
      "         1.0310e-08, 3.5730e-09, 1.1688e-09, 6.2924e-10],\n",
      "        [2.7105e-02, 9.4050e-01, 3.2010e-02, 1.8084e-04, 1.6656e-04, 2.2360e-05,\n",
      "         3.2410e-06, 4.5465e-06, 1.7412e-06, 1.5482e-06],\n",
      "        [2.7750e-02, 7.1988e-01, 2.1944e-01, 1.5962e-02, 1.4789e-02, 1.5190e-03,\n",
      "         1.8310e-04, 2.9830e-04, 1.0194e-04, 7.8561e-05],\n",
      "        [3.5955e-02, 2.5436e-01, 3.2168e-01, 2.1157e-01, 1.3870e-01, 2.8911e-02,\n",
      "         2.1124e-03, 4.2439e-03, 1.3453e-03, 1.1260e-03],\n",
      "        [7.6781e-03, 6.2150e-02, 1.4488e-01, 4.0337e-01, 3.4021e-01, 3.1225e-02,\n",
      "         4.2144e-03, 3.7841e-03, 1.5985e-03, 8.8736e-04],\n",
      "        [1.2586e-04, 4.5147e-03, 6.1379e-02, 2.3373e-01, 5.4405e-01, 1.1907e-01,\n",
      "         1.3072e-02, 1.5461e-02, 5.1209e-03, 3.4737e-03],\n",
      "        [1.0267e-04, 1.3259e-03, 5.2927e-03, 8.0598e-02, 5.2281e-01, 2.0435e-01,\n",
      "         8.0533e-02, 7.2600e-02, 2.1679e-02, 1.0707e-02],\n",
      "        [2.5457e-04, 1.2984e-03, 4.8153e-03, 8.9186e-02, 5.2676e-01, 1.8831e-01,\n",
      "         9.2744e-02, 5.8854e-02, 2.7759e-02, 1.0015e-02],\n",
      "        [5.4903e-05, 4.4525e-04, 1.5297e-03, 1.2279e-02, 3.1014e-01, 2.8886e-01,\n",
      "         1.0733e-01, 2.0012e-01, 5.3319e-02, 2.5924e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: bạn không_thể tưởng_tượng được hoa hướng_dương tuyệt_vời như thế_nào và\n",
      "Reference: you just couldn &apos;t imagine how amazing a sunflower\n",
      "Model: <SOS> you can &apos;t the see the the the ,\n",
      "Attention Weights: tensor([[8.8648e-01, 1.1273e-01, 7.8614e-04, 4.4582e-06, 2.5424e-07, 6.0033e-08,\n",
      "         2.2094e-08, 5.3436e-09, 2.3679e-09, 6.1438e-10],\n",
      "        [2.4296e-02, 9.5745e-01, 1.7968e-02, 2.2486e-04, 3.9619e-05, 9.4386e-06,\n",
      "         5.6503e-06, 3.1464e-06, 2.4677e-06, 7.4692e-07],\n",
      "        [2.7632e-02, 8.6229e-01, 1.0118e-01, 7.4511e-03, 1.1998e-03, 1.1490e-04,\n",
      "         6.4495e-05, 3.1676e-05, 2.5274e-05, 5.6802e-06],\n",
      "        [1.1313e-03, 1.3362e-01, 4.7349e-01, 3.1694e-01, 6.8677e-02, 4.0633e-03,\n",
      "         1.2047e-03, 5.1178e-04, 3.3658e-04, 3.3327e-05],\n",
      "        [9.3189e-04, 1.6598e-01, 3.3463e-01, 2.5777e-01, 1.8801e-01, 3.9262e-02,\n",
      "         1.0013e-02, 1.9628e-03, 1.2758e-03, 1.5315e-04],\n",
      "        [1.1075e-04, 1.2015e-02, 3.3018e-01, 2.9505e-01, 2.6805e-01, 6.6843e-02,\n",
      "         2.3598e-02, 2.8084e-03, 1.1902e-03, 1.4815e-04],\n",
      "        [1.3330e-04, 8.4062e-03, 1.5974e-01, 1.7570e-01, 3.5253e-01, 1.8453e-01,\n",
      "         9.0999e-02, 1.9579e-02, 7.5990e-03, 7.7925e-04],\n",
      "        [1.2123e-04, 7.3322e-03, 5.8585e-03, 6.5743e-02, 1.3882e-01, 3.3440e-01,\n",
      "         2.9064e-01, 9.9361e-02, 5.1135e-02, 6.5848e-03],\n",
      "        [6.7246e-04, 1.3898e-01, 4.4955e-02, 1.0043e-01, 1.1674e-01, 2.2072e-01,\n",
      "         1.7738e-01, 9.3552e-02, 8.9008e-02, 1.7569e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1.96, Train Loss: 4.08, Val Loss: 4.30, Train BLEU: 8.94, Val BLEU: 8.94, Minutes Elapsed: 101.32\n",
      "Sampling from training predictions...\n",
      "Source: bởi vì thế_giới tôi tin là một thế_giới mà việc\n",
      "Reference: because the world i believe in is one where\n",
      "Model: <SOS> because i i i i is is is a\n",
      "Attention Weights: tensor([[8.7983e-01, 1.1903e-01, 1.1344e-03, 8.5548e-07, 7.2552e-07, 1.2347e-08,\n",
      "         2.1199e-09, 9.3767e-11, 1.1547e-11, 7.5392e-12],\n",
      "        [2.3824e-02, 9.7641e-02, 8.6268e-01, 9.3207e-03, 6.4536e-03, 5.2847e-05,\n",
      "         1.8224e-05, 5.9557e-06, 8.4638e-07, 7.5639e-07],\n",
      "        [1.5143e-01, 2.1769e-01, 4.9811e-01, 1.8305e-02, 1.1003e-01, 3.3405e-03,\n",
      "         6.6875e-04, 2.5599e-04, 8.8468e-05, 7.4790e-05],\n",
      "        [1.6031e-01, 1.0748e-01, 1.9089e-01, 2.0564e-02, 4.8914e-01, 2.7120e-02,\n",
      "         3.1214e-03, 7.3698e-04, 3.4115e-04, 2.9119e-04],\n",
      "        [2.1800e-02, 7.0764e-02, 1.9014e-01, 1.6460e-01, 5.1494e-01, 2.5022e-02,\n",
      "         6.3416e-03, 3.3862e-03, 1.6233e-03, 1.3787e-03],\n",
      "        [8.8154e-04, 2.8146e-03, 1.2356e-02, 1.6127e-02, 8.5204e-01, 8.0387e-02,\n",
      "         2.3901e-02, 6.5564e-03, 2.5670e-03, 2.3723e-03],\n",
      "        [4.8038e-04, 1.0609e-03, 7.2562e-03, 1.1617e-03, 1.1385e-01, 2.8302e-01,\n",
      "         4.0233e-01, 1.1963e-01, 3.7321e-02, 3.3892e-02],\n",
      "        [1.5834e-03, 2.2612e-03, 5.0869e-03, 1.2951e-03, 1.4244e-01, 1.8535e-01,\n",
      "         3.0982e-01, 2.1198e-01, 8.1631e-02, 5.8553e-02],\n",
      "        [3.5967e-03, 1.1075e-02, 1.5836e-02, 3.8306e-03, 1.0917e-01, 8.8304e-02,\n",
      "         1.6916e-01, 2.9001e-01, 1.9109e-01, 1.1793e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: vì_vậy vài năm qua , tôi đang cố_gắng nhiều cách\n",
      "Reference: so over the past few years , i &apos;ve\n",
      "Model: <SOS> so couple years years years , , i was\n",
      "Attention Weights: tensor([[9.1188e-01, 8.8078e-02, 4.3003e-05, 9.2223e-08, 4.5196e-11, 6.3356e-12,\n",
      "         1.0964e-11, 4.3876e-12, 1.2004e-12, 2.8192e-13],\n",
      "        [1.5639e-02, 9.5981e-01, 2.2267e-02, 2.2678e-03, 8.1618e-06, 2.0072e-06,\n",
      "         6.8663e-06, 1.4626e-06, 4.2366e-07, 1.5831e-07],\n",
      "        [3.2901e-02, 3.9634e-01, 4.2583e-01, 1.3492e-01, 1.9182e-03, 1.1471e-03,\n",
      "         4.7192e-03, 1.4530e-03, 5.1131e-04, 2.6739e-04],\n",
      "        [9.1300e-02, 3.2806e-01, 3.7885e-01, 1.7466e-01, 6.6485e-03, 2.1676e-03,\n",
      "         1.1009e-02, 5.3309e-03, 1.4017e-03, 5.7052e-04],\n",
      "        [9.1081e-03, 1.7164e-01, 3.6783e-01, 3.4879e-01, 4.8206e-02, 1.7058e-02,\n",
      "         2.4738e-02, 7.7491e-03, 3.1532e-03, 1.7292e-03],\n",
      "        [3.1320e-03, 5.8390e-02, 3.2997e-01, 4.2795e-01, 8.5390e-02, 5.1197e-02,\n",
      "         3.3688e-02, 5.0388e-03, 2.9021e-03, 2.3471e-03],\n",
      "        [5.3546e-04, 4.7114e-03, 1.8037e-02, 5.8286e-02, 7.6915e-02, 1.0990e-01,\n",
      "         6.3438e-01, 6.9871e-02, 1.6816e-02, 1.0546e-02],\n",
      "        [7.2352e-05, 1.0375e-03, 1.2686e-03, 1.6564e-02, 1.0377e-01, 2.8097e-01,\n",
      "         5.2694e-01, 3.6740e-02, 1.7380e-02, 1.5254e-02],\n",
      "        [1.6908e-05, 1.6097e-04, 2.2586e-04, 2.5220e-03, 1.2736e-02, 6.6247e-02,\n",
      "         8.3003e-01, 6.4063e-02, 1.4294e-02, 9.7029e-03]])\n",
      "\n",
      "Epoch: 2.00, Train Loss: 4.09, Val Loss: 4.33, Train BLEU: 9.22, Val BLEU: 8.59, Minutes Elapsed: 103.45\n",
      "Sampling from training predictions...\n",
      "Source: ngay bây_giờ - — trước_khi chúng_ta bắt_đầu - - điều\n",
      "Reference: now — — before we get started -- this\n",
      "Model: <SOS> now now the we we we -- -- --\n",
      "Attention Weights: tensor([[7.9164e-01, 2.0832e-01, 3.5492e-05, 5.8990e-06, 1.0837e-06, 3.9251e-09,\n",
      "         6.6915e-09, 3.9371e-10, 3.5264e-10, 6.4670e-10],\n",
      "        [3.3942e-02, 9.1643e-01, 2.2838e-02, 1.9509e-02, 7.1024e-03, 6.8756e-05,\n",
      "         6.6508e-05, 9.8605e-06, 1.1569e-05, 2.6391e-05],\n",
      "        [1.0726e-02, 2.1406e-01, 1.1529e-01, 4.6271e-01, 1.8702e-01, 3.7321e-03,\n",
      "         3.8408e-03, 6.0958e-04, 5.9596e-04, 1.4196e-03],\n",
      "        [5.2129e-04, 4.7399e-03, 3.3182e-02, 4.3579e-01, 4.9722e-01, 1.2905e-02,\n",
      "         1.0468e-02, 9.7862e-04, 1.0312e-03, 3.1700e-03],\n",
      "        [1.9979e-04, 8.9039e-04, 8.5857e-03, 2.8869e-01, 6.0230e-01, 3.6172e-02,\n",
      "         5.0791e-02, 2.7763e-03, 2.2505e-03, 7.3457e-03],\n",
      "        [1.8300e-04, 7.1264e-04, 5.5620e-03, 2.7366e-01, 5.2297e-01, 5.3983e-02,\n",
      "         1.2463e-01, 4.0719e-03, 2.8840e-03, 1.1342e-02],\n",
      "        [6.2388e-05, 2.6196e-04, 2.0376e-03, 1.8719e-01, 5.2406e-01, 1.0474e-01,\n",
      "         1.4409e-01, 9.0361e-03, 7.5466e-03, 2.0978e-02],\n",
      "        [4.2600e-05, 1.1765e-04, 4.2468e-04, 2.7020e-02, 3.7452e-01, 2.6372e-02,\n",
      "         3.8851e-01, 6.4601e-02, 5.1750e-02, 6.6646e-02],\n",
      "        [1.0062e-04, 4.6093e-04, 1.1376e-03, 3.7767e-02, 3.7570e-01, 5.6498e-02,\n",
      "         2.7875e-01, 7.7102e-02, 6.9554e-02, 1.0292e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi có thể kết_thúc câu_chuyện tình_yêu điên_rồ của tôi bằng\n",
      "Reference: i was able to end my own crazy love\n",
      "Model: <SOS> i i have to my my my story of\n",
      "Attention Weights: tensor([[4.1290e-02, 9.2907e-01, 2.9560e-02, 8.2829e-05, 6.5810e-07, 1.6975e-07,\n",
      "         6.0265e-08, 6.0243e-09, 4.5275e-09, 4.1987e-09],\n",
      "        [3.3311e-02, 5.5896e-01, 3.8294e-01, 2.4068e-02, 4.8388e-04, 1.2455e-04,\n",
      "         6.8241e-05, 1.0949e-05, 8.4434e-06, 2.6751e-05],\n",
      "        [4.8302e-03, 1.7254e-01, 6.4148e-01, 1.7478e-01, 5.2710e-03, 5.5951e-04,\n",
      "         2.3623e-04, 5.3251e-05, 5.5114e-05, 1.9677e-04],\n",
      "        [6.2727e-05, 1.5422e-03, 1.9441e-02, 4.9218e-01, 4.4878e-01, 3.1319e-02,\n",
      "         5.4180e-03, 4.1554e-04, 1.7240e-04, 6.6660e-04],\n",
      "        [6.3812e-05, 2.1282e-04, 2.5332e-03, 1.4100e-01, 6.3510e-01, 1.6446e-01,\n",
      "         4.4068e-02, 7.1945e-03, 1.9588e-03, 3.4129e-03],\n",
      "        [2.1818e-05, 7.2768e-05, 7.3535e-04, 4.1657e-02, 4.6959e-01, 3.6149e-01,\n",
      "         1.1478e-01, 5.5762e-03, 1.6989e-03, 4.3793e-03],\n",
      "        [1.4857e-05, 4.0334e-05, 3.2234e-04, 1.8159e-02, 3.2779e-01, 4.3731e-01,\n",
      "         1.9067e-01, 1.3235e-02, 3.0735e-03, 9.3810e-03],\n",
      "        [9.1258e-06, 2.5661e-05, 1.5072e-04, 4.7009e-03, 9.8212e-02, 5.6638e-01,\n",
      "         2.6812e-01, 1.9449e-02, 8.1087e-03, 3.4848e-02],\n",
      "        [1.2535e-05, 4.2542e-05, 1.4615e-04, 2.7752e-03, 1.8130e-02, 2.9538e-01,\n",
      "         3.5472e-01, 7.7838e-02, 4.3606e-02, 2.0735e-01]])\n",
      "\n",
      "Epoch: 2.05, Train Loss: 3.51, Val Loss: 4.31, Train BLEU: 10.60, Val BLEU: 8.52, Minutes Elapsed: 105.94\n",
      "Sampling from training predictions...\n",
      "Source: tất_cả mọi người sẽ hụt_hẫng . bạn bước vào cuộc_chơi\n",
      "Reference: everybody is thrown off . you go in for\n",
      "Model: <SOS> everybody everybody be . . you &apos;re to to\n",
      "Attention Weights: tensor([[2.0443e-01, 7.8514e-01, 1.0357e-02, 6.5129e-05, 1.1147e-06, 1.5232e-08,\n",
      "         1.2454e-09, 4.1216e-10, 8.7137e-11, 2.3357e-11],\n",
      "        [4.0885e-02, 4.4262e-01, 3.3825e-01, 1.6606e-01, 1.1798e-02, 2.6332e-04,\n",
      "         6.6299e-05, 4.6878e-05, 8.1735e-06, 4.3225e-06],\n",
      "        [6.5049e-03, 1.4969e-02, 3.2183e-02, 7.5668e-01, 1.7891e-01, 9.2054e-03,\n",
      "         7.0541e-04, 5.7117e-04, 2.0233e-04, 6.8685e-05],\n",
      "        [3.1951e-04, 3.8990e-04, 1.6091e-03, 3.9167e-02, 6.0947e-01, 2.5685e-01,\n",
      "         4.5200e-02, 3.7077e-02, 6.5712e-03, 3.3418e-03],\n",
      "        [3.4594e-04, 4.2620e-04, 1.2497e-03, 2.3105e-02, 6.6019e-02, 3.2590e-01,\n",
      "         4.5381e-01, 1.1356e-01, 1.1060e-02, 4.5304e-03],\n",
      "        [1.7244e-04, 1.9355e-04, 4.9244e-04, 8.1443e-03, 4.9714e-03, 4.9451e-02,\n",
      "         7.5216e-01, 1.6471e-01, 1.4573e-02, 5.1302e-03],\n",
      "        [6.6928e-05, 1.2243e-04, 1.8150e-04, 3.9805e-03, 3.1264e-03, 4.7192e-02,\n",
      "         5.5396e-01, 3.3434e-01, 4.3532e-02, 1.3505e-02],\n",
      "        [5.0138e-05, 1.6703e-04, 4.4922e-04, 2.7768e-02, 1.4171e-02, 1.1716e-02,\n",
      "         4.7980e-02, 5.4296e-01, 2.7978e-01, 7.4959e-02],\n",
      "        [1.1456e-04, 9.8233e-05, 1.3031e-04, 6.8194e-04, 1.2941e-02, 3.4762e-02,\n",
      "         4.5321e-02, 1.8939e-01, 3.9771e-01, 3.1885e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: vậy_nên cái mà tôi làm trong năm đầu_tiên tại <UNK>\n",
      "Reference: and so what i did in <UNK> that first\n",
      "Model: <SOS> so i i i i in in year the\n",
      "Attention Weights: tensor([[9.1665e-01, 8.3008e-02, 3.4226e-04, 1.5870e-06, 2.0504e-07, 1.5027e-09,\n",
      "         1.5444e-10, 6.5581e-11, 1.9826e-11, 4.9771e-12],\n",
      "        [1.3557e-01, 2.5297e-01, 6.0174e-01, 8.1395e-03, 1.3631e-03, 1.5930e-04,\n",
      "         3.4961e-05, 1.6322e-05, 1.0370e-06, 5.2625e-07],\n",
      "        [1.1228e-01, 1.2117e-01, 4.2105e-01, 1.1654e-01, 1.8208e-01, 3.9746e-02,\n",
      "         5.2836e-03, 1.4672e-03, 2.6438e-04, 1.0907e-04],\n",
      "        [6.4737e-02, 5.7974e-02, 2.5197e-01, 1.1644e-01, 4.0020e-01, 9.3004e-02,\n",
      "         1.2235e-02, 2.8152e-03, 4.3109e-04, 1.9529e-04],\n",
      "        [3.1898e-02, 2.4882e-02, 1.3991e-01, 6.3037e-02, 5.6503e-01, 1.3121e-01,\n",
      "         3.1575e-02, 1.1070e-02, 1.0516e-03, 3.4066e-04],\n",
      "        [1.8821e-02, 1.8258e-02, 9.3784e-02, 4.3721e-02, 5.5555e-01, 1.8588e-01,\n",
      "         5.1591e-02, 2.8456e-02, 3.2634e-03, 6.7272e-04],\n",
      "        [4.7024e-05, 5.6240e-05, 1.8055e-04, 3.0525e-04, 1.2976e-02, 3.3506e-01,\n",
      "         3.3413e-01, 2.9731e-01, 1.6605e-02, 3.3381e-03],\n",
      "        [1.2734e-04, 2.0877e-04, 4.7638e-04, 8.4438e-04, 2.1893e-02, 2.2266e-01,\n",
      "         3.2925e-01, 3.5804e-01, 5.5987e-02, 1.0511e-02],\n",
      "        [2.5749e-04, 6.7536e-04, 1.4805e-03, 3.8765e-03, 2.7866e-02, 5.9986e-02,\n",
      "         2.6878e-01, 2.8657e-01, 2.7272e-01, 7.7787e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2.10, Train Loss: 3.61, Val Loss: 4.28, Train BLEU: 10.79, Val BLEU: 9.21, Minutes Elapsed: 108.43\n",
      "Sampling from training predictions...\n",
      "Source: kết_quả là những người cố_gắng nhớ_lại 10 điều răn của\n",
      "Reference: turns out the people who tried to recall the\n",
      "Model: <SOS> the are people people who 10 10 10 10\n",
      "Attention Weights: tensor([[9.9927e-01, 7.1704e-04, 1.0885e-05, 2.0150e-07, 7.6906e-08, 9.8971e-09,\n",
      "         5.4110e-09, 2.2745e-09, 1.0331e-09, 1.0144e-10],\n",
      "        [8.2166e-01, 1.2305e-01, 5.2363e-02, 2.0791e-03, 6.1041e-04, 1.4597e-04,\n",
      "         4.0641e-05, 2.7161e-05, 2.1190e-05, 4.7732e-06],\n",
      "        [2.2023e-01, 2.3282e-01, 2.4439e-01, 1.9548e-01, 8.8535e-02, 1.4241e-02,\n",
      "         2.8312e-03, 9.4311e-04, 4.0631e-04, 1.1082e-04],\n",
      "        [2.9575e-03, 2.8453e-02, 1.6360e-01, 3.6283e-01, 2.2379e-01, 1.7928e-01,\n",
      "         1.8752e-02, 1.3081e-02, 6.0057e-03, 1.2627e-03],\n",
      "        [1.5417e-04, 4.1528e-03, 2.0579e-02, 7.4359e-02, 3.3326e-01, 4.1122e-01,\n",
      "         9.2146e-02, 4.3218e-02, 1.7224e-02, 3.6826e-03],\n",
      "        [1.3463e-04, 5.9327e-03, 8.5949e-03, 9.8439e-02, 5.2477e-01, 2.0526e-01,\n",
      "         6.8828e-02, 5.6848e-02, 2.2900e-02, 8.2848e-03],\n",
      "        [3.9109e-05, 1.2558e-04, 1.0863e-03, 4.8011e-03, 6.9852e-02, 1.5563e-01,\n",
      "         1.3250e-01, 3.4405e-01, 2.4112e-01, 5.0809e-02],\n",
      "        [5.1160e-05, 2.2818e-04, 2.0614e-03, 9.2258e-03, 9.6469e-02, 2.1451e-01,\n",
      "         1.2667e-01, 2.8784e-01, 2.1876e-01, 4.4183e-02],\n",
      "        [2.7102e-05, 6.9180e-05, 5.7234e-04, 3.5334e-03, 2.5221e-02, 1.5545e-01,\n",
      "         8.5964e-02, 3.2577e-01, 3.3124e-01, 7.2152e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: không nghi_ngờ rằng con_cái của_ông ấy sẽ được giáo_dục ,\n",
      "Reference: there was no question that his children would receive\n",
      "Model: <SOS> no the the that that the are to been\n",
      "Attention Weights: tensor([[7.7487e-01, 2.2358e-01, 1.2807e-03, 2.6199e-04, 1.0604e-05, 8.7096e-07,\n",
      "         4.5004e-07, 1.9758e-07, 4.6776e-08, 1.5181e-08],\n",
      "        [7.3898e-02, 8.0977e-01, 8.1451e-02, 3.1733e-02, 2.0042e-03, 4.1450e-04,\n",
      "         4.8011e-04, 1.6783e-04, 5.3642e-05, 2.5912e-05],\n",
      "        [1.4449e-01, 2.2178e-01, 3.5919e-01, 2.3487e-01, 2.6388e-02, 4.7444e-03,\n",
      "         5.4638e-03, 2.4035e-03, 5.0635e-04, 1.6069e-04],\n",
      "        [6.5379e-03, 2.2064e-01, 4.4415e-01, 2.7763e-01, 4.2221e-02, 4.3830e-03,\n",
      "         2.3598e-03, 1.2356e-03, 6.5213e-04, 1.8930e-04],\n",
      "        [3.3621e-03, 4.2989e-02, 3.2941e-01, 5.0426e-01, 9.4619e-02, 1.3830e-02,\n",
      "         6.8042e-03, 2.6082e-03, 1.4274e-03, 6.9687e-04],\n",
      "        [2.3301e-04, 6.3360e-04, 4.3629e-02, 4.6660e-01, 3.2643e-01, 9.2390e-02,\n",
      "         5.6330e-02, 8.2464e-03, 2.9972e-03, 2.5028e-03],\n",
      "        [3.0687e-04, 4.2131e-04, 3.8407e-03, 1.2940e-01, 2.4052e-01, 1.1221e-01,\n",
      "         3.3702e-01, 1.2876e-01, 3.6973e-02, 1.0549e-02],\n",
      "        [5.6817e-04, 4.9761e-04, 3.6598e-03, 3.9056e-02, 7.0377e-02, 4.9147e-02,\n",
      "         3.5866e-01, 3.3359e-01, 1.0111e-01, 4.3341e-02],\n",
      "        [3.0584e-05, 4.6075e-05, 1.1374e-03, 8.9479e-03, 3.2628e-02, 3.3308e-02,\n",
      "         2.7380e-01, 3.0635e-01, 1.5331e-01, 1.9044e-01]])\n",
      "\n",
      "Epoch: 2.14, Train Loss: 3.63, Val Loss: 4.31, Train BLEU: 10.13, Val BLEU: 8.85, Minutes Elapsed: 110.99\n",
      "Sampling from training predictions...\n",
      "Source: có_phải chúng_ta sáng_tạo nên mọi thứ với một địa_điểm ,\n",
      "Reference: do we all make things with a venue ,\n",
      "Model: <SOS> we we make to everything a a , ,\n",
      "Attention Weights: tensor([[9.9960e-01, 2.3337e-04, 1.6232e-04, 5.1178e-07, 5.4788e-08, 5.1567e-09,\n",
      "         5.3829e-10, 2.5334e-10, 1.6686e-11, 3.0271e-12],\n",
      "        [8.1835e-01, 1.6562e-01, 1.5881e-02, 8.9277e-05, 3.5976e-05, 1.2137e-05,\n",
      "         3.6776e-06, 1.3340e-06, 6.0664e-07, 3.6569e-07],\n",
      "        [1.9458e-01, 9.3918e-02, 6.6182e-01, 4.3130e-02, 5.6377e-03, 6.1204e-04,\n",
      "         1.8465e-04, 6.2595e-05, 3.8369e-05, 1.6770e-05],\n",
      "        [3.5030e-03, 1.7697e-03, 3.0235e-01, 3.4604e-01, 2.7632e-01, 4.8607e-02,\n",
      "         1.7674e-02, 2.7915e-03, 8.2849e-04, 1.2039e-04],\n",
      "        [1.3374e-04, 7.5752e-05, 4.2315e-03, 1.2074e-01, 4.3755e-01, 2.6168e-01,\n",
      "         1.4378e-01, 1.7668e-02, 1.1798e-02, 2.3357e-03],\n",
      "        [9.4024e-05, 3.5711e-05, 1.7534e-03, 8.7565e-03, 1.4916e-01, 2.3816e-01,\n",
      "         2.3003e-01, 1.7811e-01, 1.5439e-01, 3.9504e-02],\n",
      "        [3.2309e-05, 1.2926e-05, 1.8832e-04, 1.5301e-03, 2.7261e-02, 7.9954e-02,\n",
      "         1.6408e-01, 1.8346e-01, 3.0849e-01, 2.3499e-01],\n",
      "        [1.1526e-04, 5.1143e-05, 1.6496e-03, 3.0914e-03, 1.2779e-02, 5.3503e-02,\n",
      "         1.0556e-01, 2.4998e-01, 2.6182e-01, 3.1145e-01],\n",
      "        [2.6368e-04, 1.8306e-04, 9.9272e-04, 4.5336e-03, 1.9328e-02, 3.1018e-02,\n",
      "         4.2819e-02, 7.9512e-02, 2.0106e-01, 6.2029e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi sẽ không nói với bạn những thiệt_hại mà số\n",
      "Reference: i &apos;m not going to tell you the damage\n",
      "Model: <SOS> i &apos;m not going to tell you the that\n",
      "Attention Weights: tensor([[1.6748e-01, 8.0722e-01, 2.5242e-02, 4.7260e-05, 4.4146e-06, 4.8408e-07,\n",
      "         1.2543e-07, 3.2912e-08, 1.4232e-08, 1.3537e-08],\n",
      "        [2.6184e-02, 9.0288e-01, 7.0617e-02, 2.2287e-04, 5.6162e-05, 1.7831e-05,\n",
      "         1.0420e-05, 4.6075e-06, 3.1937e-06, 2.7286e-06],\n",
      "        [1.1406e-02, 5.2803e-01, 4.5258e-01, 6.3683e-03, 1.0580e-03, 2.0572e-04,\n",
      "         1.5963e-04, 8.6131e-05, 5.5539e-05, 4.9719e-05],\n",
      "        [8.4758e-04, 1.2494e-01, 2.9149e-01, 4.4395e-01, 1.2093e-01, 7.3108e-03,\n",
      "         6.0596e-03, 2.3874e-03, 1.0786e-03, 1.0043e-03],\n",
      "        [1.5529e-03, 3.7088e-02, 2.0503e-01, 4.3146e-01, 2.9063e-01, 1.2560e-02,\n",
      "         8.7451e-03, 7.4148e-03, 2.6057e-03, 2.9089e-03],\n",
      "        [3.6044e-05, 1.8777e-03, 5.7545e-02, 2.1046e-01, 5.1272e-01, 1.1533e-01,\n",
      "         5.1627e-02, 2.7315e-02, 1.2125e-02, 1.0955e-02],\n",
      "        [6.0555e-06, 3.8729e-04, 9.4308e-03, 8.7595e-02, 5.8277e-01, 1.5446e-01,\n",
      "         8.9069e-02, 5.3955e-02, 1.1733e-02, 1.0598e-02],\n",
      "        [5.8922e-06, 1.4469e-04, 2.4002e-03, 1.1856e-02, 1.0630e-01, 1.2404e-01,\n",
      "         2.9926e-01, 3.2884e-01, 6.9609e-02, 5.7545e-02],\n",
      "        [6.1666e-06, 4.4185e-04, 3.2033e-03, 2.0773e-03, 1.6232e-02, 7.3382e-02,\n",
      "         2.4015e-01, 3.8037e-01, 1.5807e-01, 1.2607e-01]])\n",
      "\n",
      "Epoch: 2.19, Train Loss: 3.64, Val Loss: 4.28, Train BLEU: 10.15, Val BLEU: 8.74, Minutes Elapsed: 113.47\n",
      "Sampling from training predictions...\n",
      "Source: vâng , hãy giơ tay lên và cong cơ cánh_tay\n",
      "Reference: so put your arms back up and flex your\n",
      "Model: <SOS> well , &apos;s the and and the the and\n",
      "Attention Weights: tensor([[9.8812e-01, 1.1344e-02, 3.5577e-04, 1.7623e-04, 1.3691e-06, 1.1745e-07,\n",
      "         2.3150e-09, 1.6952e-09, 3.8483e-10, 1.4984e-10],\n",
      "        [9.3849e-03, 4.2184e-02, 6.1892e-01, 3.2434e-01, 4.5168e-03, 5.1793e-04,\n",
      "         5.8446e-05, 4.2076e-05, 2.3589e-05, 1.4825e-05],\n",
      "        [6.4009e-03, 1.3635e-02, 2.0098e-01, 5.2726e-01, 1.5990e-01, 7.4769e-02,\n",
      "         7.4662e-03, 5.9933e-03, 2.2608e-03, 1.3374e-03],\n",
      "        [2.9029e-03, 2.7930e-03, 2.0578e-02, 2.9800e-01, 2.8968e-01, 3.3336e-01,\n",
      "         2.0348e-02, 1.9980e-02, 8.4784e-03, 3.8780e-03],\n",
      "        [6.7182e-04, 6.0502e-04, 2.1766e-03, 4.1544e-02, 3.5842e-01, 4.3744e-01,\n",
      "         8.9562e-02, 3.4864e-02, 2.4493e-02, 1.0217e-02],\n",
      "        [3.3977e-04, 3.1699e-04, 7.4333e-04, 1.1951e-02, 1.2341e-01, 4.2552e-01,\n",
      "         2.1353e-01, 4.2900e-02, 1.0901e-01, 7.2285e-02],\n",
      "        [7.4284e-05, 2.8608e-05, 5.5191e-05, 1.3325e-03, 1.2825e-02, 8.3037e-02,\n",
      "         1.7442e-01, 1.7567e-01, 3.3679e-01, 2.1578e-01],\n",
      "        [6.9154e-05, 1.6302e-05, 1.8112e-05, 4.7471e-04, 7.1035e-03, 6.4521e-02,\n",
      "         1.4384e-01, 1.3779e-01, 3.1004e-01, 3.3613e-01],\n",
      "        [8.2190e-05, 1.6322e-05, 1.1893e-05, 3.5977e-04, 6.6791e-03, 5.7781e-02,\n",
      "         1.4167e-01, 1.0768e-01, 2.9520e-01, 3.9052e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: những thông_tin thuần sơ_cấp . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: raw data . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> the are . <EOS> . . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.8883, 0.1113, 0.0005, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0522, 0.7482, 0.1828, 0.0164, 0.0003, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0513, 0.1323, 0.4579, 0.3412, 0.0145, 0.0028, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0096, 0.0367, 0.1870, 0.5529, 0.1052, 0.1085, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0167, 0.0449, 0.1433, 0.3138, 0.1226, 0.3587, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1097, 0.1568, 0.2828, 0.2279, 0.0941, 0.1288, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0422, 0.1113, 0.2966, 0.2822, 0.0996, 0.1680, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0175, 0.0641, 0.1995, 0.3145, 0.0841, 0.3204, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0421, 0.1002, 0.2093, 0.2746, 0.1125, 0.2613, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2.24, Train Loss: 3.66, Val Loss: 4.27, Train BLEU: 10.22, Val BLEU: 8.72, Minutes Elapsed: 115.97\n",
      "Sampling from training predictions...\n",
      "Source: chúng_ta thấy dễ chấp_nhận vô_cùng khi bất_kỳ bộ_phận cơ_thể bị\n",
      "Reference: we are so , so , so accepting of\n",
      "Model: <SOS> we can &apos;t to to the &apos;s can can\n",
      "Attention Weights: tensor([[1.9507e-02, 9.7842e-01, 2.0684e-03, 2.7370e-06, 8.9812e-08, 3.2099e-09,\n",
      "         5.7885e-09, 2.9980e-09, 4.4966e-10, 1.3902e-10],\n",
      "        [1.8690e-03, 9.7864e-01, 1.9133e-02, 3.0625e-04, 3.3744e-05, 5.0163e-06,\n",
      "         7.0352e-06, 2.8505e-06, 9.9806e-07, 9.8681e-07],\n",
      "        [1.8294e-03, 5.7893e-01, 3.9804e-01, 1.9213e-02, 1.7489e-03, 8.7740e-05,\n",
      "         8.0776e-05, 4.8223e-05, 1.1376e-05, 1.3135e-05],\n",
      "        [8.6692e-05, 1.2889e-01, 6.5332e-01, 1.7870e-01, 3.4519e-02, 2.5958e-03,\n",
      "         1.1780e-03, 4.4693e-04, 9.7631e-05, 1.6080e-04],\n",
      "        [1.1529e-04, 1.3157e-02, 3.0675e-01, 4.2834e-01, 2.1330e-01, 2.7785e-02,\n",
      "         6.2871e-03, 2.5931e-03, 6.8663e-04, 9.7958e-04],\n",
      "        [3.5339e-06, 4.1543e-04, 3.3852e-02, 1.6261e-01, 4.8818e-01, 2.4519e-01,\n",
      "         4.8492e-02, 1.4692e-02, 2.2265e-03, 4.3311e-03],\n",
      "        [2.9738e-05, 9.3249e-03, 1.6989e-01, 1.2797e-01, 2.3017e-01, 6.6540e-02,\n",
      "         2.7886e-01, 9.1392e-02, 1.2585e-02, 1.3229e-02],\n",
      "        [1.4971e-05, 6.2039e-03, 7.6304e-02, 2.5952e-02, 7.5992e-02, 4.8638e-02,\n",
      "         3.7333e-01, 2.5850e-01, 6.0259e-02, 7.4806e-02],\n",
      "        [3.6094e-05, 1.7332e-02, 9.8229e-02, 2.2852e-02, 4.0307e-02, 3.4897e-02,\n",
      "         3.0883e-01, 2.5128e-01, 8.8822e-02, 1.3741e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tương_đương với 20 lần công_viên trung_tâm , <EOS> <PAD> <PAD>\n",
      "Reference: that &apos;s 20 central parks . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> the technology 20 20 technology technology <EOS> . .\n",
      "Attention Weights: tensor([[0.9984, 0.0016, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.8974, 0.0845, 0.0132, 0.0041, 0.0007, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2485, 0.3791, 0.1482, 0.1914, 0.0276, 0.0045, 0.0005, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0638, 0.0494, 0.2660, 0.3807, 0.1690, 0.0645, 0.0056, 0.0011, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0091, 0.0215, 0.1946, 0.4365, 0.2544, 0.0698, 0.0118, 0.0022, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0003, 0.0044, 0.1626, 0.3416, 0.3167, 0.1568, 0.0176, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0003, 0.0011, 0.0189, 0.1600, 0.3247, 0.4190, 0.0760, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0004, 0.0009, 0.0055, 0.0224, 0.1178, 0.2591, 0.3993, 0.1946, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0038, 0.0071, 0.0123, 0.0516, 0.1772, 0.2466, 0.2458, 0.2556, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 2.29, Train Loss: 3.69, Val Loss: 4.28, Train BLEU: 10.20, Val BLEU: 9.02, Minutes Elapsed: 118.48\n",
      "Sampling from training predictions...\n",
      "Source: tại pittsburgh có 2 trường đại_học lớn carnegie mellon và\n",
      "Reference: and at pittsburgh there are two big universities ,\n",
      "Model: <SOS> so film is two there two two in charles\n",
      "Attention Weights: tensor([[3.1286e-01, 6.8660e-01, 5.4670e-04, 1.3336e-07, 2.0518e-08, 1.0500e-09,\n",
      "         8.5826e-11, 6.9084e-11, 8.8032e-11, 3.1433e-11],\n",
      "        [5.9939e-03, 9.3549e-01, 5.7771e-02, 5.8758e-04, 1.3368e-04, 1.5753e-05,\n",
      "         3.2796e-06, 2.2935e-06, 1.3627e-06, 3.4665e-07],\n",
      "        [7.5159e-03, 1.0935e-01, 8.6513e-01, 1.3213e-02, 4.0347e-03, 4.9198e-04,\n",
      "         1.7505e-04, 5.6188e-05, 2.8470e-05, 1.2755e-05],\n",
      "        [6.7708e-03, 1.1753e-01, 8.3480e-01, 2.6441e-02, 1.1147e-02, 2.3621e-03,\n",
      "         5.7156e-04, 2.6147e-04, 8.8179e-05, 2.3045e-05],\n",
      "        [1.9293e-03, 3.1131e-02, 9.1293e-01, 2.9646e-02, 1.7222e-02, 4.9272e-03,\n",
      "         1.3596e-03, 5.7712e-04, 2.3281e-04, 4.7782e-05],\n",
      "        [6.1009e-05, 1.0466e-03, 4.0594e-01, 2.1178e-01, 2.3851e-01, 9.4477e-02,\n",
      "         3.2312e-02, 1.0419e-02, 4.3045e-03, 1.1393e-03],\n",
      "        [9.0387e-06, 8.9763e-05, 1.0717e-01, 1.4392e-01, 4.5988e-01, 1.8596e-01,\n",
      "         5.0237e-02, 3.5961e-02, 1.4570e-02, 2.1932e-03],\n",
      "        [2.3661e-06, 8.7504e-06, 3.3556e-03, 1.0872e-02, 2.0463e-01, 3.2670e-01,\n",
      "         2.5712e-01, 1.2091e-01, 6.7004e-02, 9.4015e-03],\n",
      "        [3.1976e-06, 9.1575e-06, 2.5216e-03, 2.7210e-03, 2.2580e-02, 9.1336e-02,\n",
      "         3.6679e-01, 2.9266e-01, 1.8262e-01, 3.8754e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi nhận ra rằng đó là một khoảng khắc có\n",
      "Reference: i realized that this was a symbolic moment in\n",
      "Model: <SOS> i i that that was a part of .\n",
      "Attention Weights: tensor([[1.0279e-01, 8.7564e-01, 2.0455e-02, 1.0530e-03, 5.3542e-05, 2.7631e-06,\n",
      "         5.5390e-07, 1.2161e-07, 3.8899e-08, 1.4924e-08],\n",
      "        [7.7746e-03, 9.7544e-01, 1.4880e-02, 1.8400e-03, 3.9176e-05, 1.7661e-05,\n",
      "         5.1534e-06, 2.8787e-06, 7.8525e-07, 1.6961e-07],\n",
      "        [9.8054e-03, 2.2826e-01, 2.3468e-01, 5.0532e-01, 1.6917e-02, 3.1052e-03,\n",
      "         1.0545e-03, 5.9687e-04, 2.1373e-04, 5.4395e-05],\n",
      "        [2.9223e-04, 6.2422e-03, 4.7945e-02, 5.9415e-01, 1.9618e-01, 1.0220e-01,\n",
      "         3.1242e-02, 1.4366e-02, 5.5320e-03, 1.8508e-03],\n",
      "        [7.0101e-05, 2.8165e-03, 1.0279e-02, 9.4243e-02, 1.2575e-01, 4.6602e-01,\n",
      "         1.6682e-01, 1.0734e-01, 2.1496e-02, 5.1574e-03],\n",
      "        [6.3473e-05, 2.5637e-03, 8.0304e-03, 6.0557e-02, 6.3704e-02, 3.1464e-01,\n",
      "         1.8958e-01, 3.0462e-01, 4.9973e-02, 6.2685e-03],\n",
      "        [1.5566e-05, 3.2806e-04, 1.4956e-03, 1.8413e-02, 2.9251e-02, 9.4291e-02,\n",
      "         1.2454e-01, 4.5117e-01, 2.3707e-01, 4.3426e-02],\n",
      "        [3.3040e-05, 2.5719e-04, 1.1903e-03, 8.6424e-03, 1.8464e-02, 3.6294e-02,\n",
      "         9.5493e-02, 2.3484e-01, 4.6966e-01, 1.3513e-01],\n",
      "        [7.2036e-05, 2.0139e-04, 1.2113e-03, 5.2475e-03, 1.1719e-02, 1.9063e-02,\n",
      "         3.5800e-02, 1.3082e-01, 5.0444e-01, 2.9143e-01]])\n",
      "\n",
      "Epoch: 2.34, Train Loss: 3.71, Val Loss: 4.27, Train BLEU: 9.64, Val BLEU: 8.92, Minutes Elapsed: 120.94\n",
      "Sampling from training predictions...\n",
      "Source: chúng_tôi chạy những mô_hình khổng_lồ trên siêu máy_tính ; đây\n",
      "Reference: we run enormous models on supercomputers ; this is\n",
      "Model: <SOS> we we these these of the ; ; &apos;re\n",
      "Attention Weights: tensor([[3.4674e-01, 6.5241e-01, 8.3990e-04, 1.3026e-05, 3.1667e-07, 2.2860e-08,\n",
      "         7.1169e-09, 4.0695e-09, 2.6123e-10, 1.2461e-09],\n",
      "        [1.2387e-02, 9.5995e-01, 2.6817e-02, 7.7626e-04, 6.1671e-05, 4.2281e-06,\n",
      "         1.4251e-06, 4.6073e-07, 4.3144e-08, 4.1240e-08],\n",
      "        [1.3380e-02, 3.8528e-01, 5.1185e-01, 8.3769e-02, 5.1851e-03, 4.1072e-04,\n",
      "         9.5679e-05, 3.1151e-05, 2.8554e-06, 1.7368e-06],\n",
      "        [8.8460e-04, 5.0438e-03, 1.6317e-01, 5.2135e-01, 2.3293e-01, 5.4862e-02,\n",
      "         1.3156e-02, 7.4533e-03, 6.9086e-04, 4.5533e-04],\n",
      "        [5.3801e-05, 1.6341e-03, 8.8303e-03, 2.2719e-01, 3.7165e-01, 3.2307e-01,\n",
      "         4.9227e-02, 1.2427e-02, 3.1548e-03, 2.7662e-03],\n",
      "        [7.8310e-06, 1.4552e-04, 5.1716e-04, 8.0801e-03, 6.1171e-02, 3.8551e-01,\n",
      "         3.7957e-01, 1.2152e-01, 2.6685e-02, 1.6783e-02],\n",
      "        [1.2930e-05, 2.2261e-04, 3.4978e-04, 5.8469e-03, 3.2876e-02, 1.6890e-01,\n",
      "         4.0279e-01, 2.0163e-01, 5.1045e-02, 1.3633e-01],\n",
      "        [3.9790e-05, 6.5644e-04, 6.9784e-04, 4.5141e-03, 1.0839e-02, 9.5994e-02,\n",
      "         3.0244e-01, 1.9466e-01, 8.5181e-02, 3.0498e-01],\n",
      "        [1.4960e-04, 7.9145e-04, 1.1621e-03, 9.3251e-03, 2.3357e-02, 6.2354e-02,\n",
      "         1.1604e-01, 8.9507e-02, 9.0669e-02, 6.0664e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: điều mà bạn nên làm là đấu_tranh cho sự tự_chủ\n",
      "Reference: but you have to fight for your <UNK> today\n",
      "Model: <SOS> what what you to is is the is for\n",
      "Attention Weights: tensor([[9.9498e-01, 4.7942e-03, 2.2502e-04, 3.8255e-06, 1.6831e-07, 1.8778e-09,\n",
      "         1.7842e-10, 5.7575e-11, 2.0782e-11, 9.3451e-12],\n",
      "        [1.4931e-01, 5.7784e-01, 2.5190e-01, 2.0442e-02, 4.0627e-04, 5.7685e-05,\n",
      "         3.3046e-05, 7.5984e-06, 3.1602e-06, 3.6356e-06],\n",
      "        [5.9415e-02, 1.2116e-01, 3.2209e-01, 4.7454e-01, 1.8044e-02, 2.7284e-03,\n",
      "         1.3720e-03, 3.4030e-04, 1.7207e-04, 1.4254e-04],\n",
      "        [1.5129e-02, 3.4535e-02, 2.1772e-01, 5.7579e-01, 1.2799e-01, 2.0690e-02,\n",
      "         6.0548e-03, 1.3837e-03, 4.3513e-04, 2.8034e-04],\n",
      "        [1.9185e-04, 2.4470e-04, 1.1320e-03, 6.3464e-02, 2.8277e-01, 4.5297e-01,\n",
      "         1.4583e-01, 3.4830e-02, 1.0493e-02, 8.0764e-03],\n",
      "        [2.0620e-05, 3.3009e-05, 1.0174e-04, 1.2219e-02, 1.0126e-01, 5.5163e-01,\n",
      "         2.7688e-01, 3.4403e-02, 1.3303e-02, 1.0149e-02],\n",
      "        [7.0677e-06, 9.5541e-06, 3.9849e-05, 3.0136e-03, 3.5547e-02, 3.7268e-01,\n",
      "         4.4786e-01, 8.4758e-02, 3.0608e-02, 2.5485e-02],\n",
      "        [1.4467e-05, 1.1128e-05, 3.4286e-05, 6.1873e-04, 5.3693e-03, 1.7234e-01,\n",
      "         4.6842e-01, 1.8304e-01, 9.0851e-02, 7.9303e-02],\n",
      "        [2.7362e-05, 1.5140e-04, 1.2695e-04, 4.1155e-04, 2.4827e-03, 2.5479e-02,\n",
      "         1.6740e-01, 3.9876e-01, 2.1712e-01, 1.8804e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2.38, Train Loss: 3.66, Val Loss: 4.23, Train BLEU: 10.49, Val BLEU: 9.33, Minutes Elapsed: 123.41\n",
      "Sampling from training predictions...\n",
      "Source: christopher decharms quét não_bộ theo thời_gian thực <EOS> <PAD> <PAD>\n",
      "Reference: christopher decharms : a look inside the brain in\n",
      "Model: <SOS> christopher wolfram : the to of world world world\n",
      "Attention Weights: tensor([[0.9998, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.5286, 0.4634, 0.0079, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0701, 0.2549, 0.6599, 0.0137, 0.0008, 0.0004, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0025, 0.4985, 0.4403, 0.0380, 0.0143, 0.0058, 0.0006, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0005, 0.0631, 0.5575, 0.2529, 0.0972, 0.0275, 0.0013, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0008, 0.0028, 0.0769, 0.4141, 0.2408, 0.1978, 0.0640, 0.0028, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0001, 0.0032, 0.0487, 0.2170, 0.4194, 0.3018, 0.0099, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0001, 0.0019, 0.0133, 0.1183, 0.4269, 0.4129, 0.0267, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0005, 0.0005, 0.0054, 0.0136, 0.0635, 0.3220, 0.5009, 0.0936, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: và các bạn có bao_giờ tự_hỏi chính mình \" nếu\n",
      "Reference: and if you ever are wondering , &quot; if\n",
      "Model: <SOS> and you you have the question to &quot; if\n",
      "Attention Weights: tensor([[1.4427e-04, 9.5245e-03, 2.2146e-02, 8.4966e-01, 1.1118e-01, 7.1662e-03,\n",
      "         1.7417e-04, 8.2440e-06, 2.1694e-07, 7.4816e-09],\n",
      "        [2.3045e-03, 7.4876e-01, 2.2528e-01, 1.8420e-02, 4.9232e-03, 2.9507e-04,\n",
      "         1.6153e-05, 1.0103e-06, 1.8576e-07, 6.4675e-08],\n",
      "        [1.0356e-04, 2.2960e-02, 9.9977e-02, 1.6552e-01, 6.3428e-01, 7.3720e-02,\n",
      "         2.8518e-03, 5.2306e-04, 5.0348e-05, 1.7688e-05],\n",
      "        [2.9996e-05, 2.8618e-03, 2.6196e-02, 7.7908e-02, 5.8151e-01, 2.8660e-01,\n",
      "         1.9685e-02, 4.9057e-03, 2.5141e-04, 5.6835e-05],\n",
      "        [1.3588e-05, 9.4696e-04, 1.6669e-02, 1.0291e-01, 5.2017e-01, 2.9879e-01,\n",
      "         4.4900e-02, 1.4870e-02, 5.8228e-04, 1.4035e-04],\n",
      "        [2.8254e-07, 1.3348e-05, 1.1779e-04, 2.2419e-03, 4.8609e-02, 5.7799e-01,\n",
      "         2.4645e-01, 1.1502e-01, 7.6593e-03, 1.9008e-03],\n",
      "        [8.7017e-08, 2.0297e-06, 9.2902e-05, 6.5654e-04, 2.9384e-03, 9.0899e-02,\n",
      "         2.6521e-01, 4.4770e-01, 1.2335e-01, 6.9155e-02],\n",
      "        [8.1679e-07, 8.1580e-06, 1.3310e-04, 3.2331e-04, 1.8721e-03, 1.7348e-02,\n",
      "         1.4204e-01, 2.2291e-01, 3.2359e-01, 2.9177e-01],\n",
      "        [2.1634e-06, 2.3812e-05, 2.2001e-04, 7.6055e-04, 2.5742e-03, 1.0819e-02,\n",
      "         8.0184e-02, 1.4931e-01, 3.4198e-01, 4.1413e-01]])\n",
      "\n",
      "Epoch: 2.43, Train Loss: 3.68, Val Loss: 4.21, Train BLEU: 10.12, Val BLEU: 9.31, Minutes Elapsed: 125.91\n",
      "Sampling from training predictions...\n",
      "Source: trong 4 phút , chuyên_gia hoá_học khí_quyển rachel pike giới_thiệu\n",
      "Reference: in 4 minutes , atmospheric chemist rachel pike provides\n",
      "Model: <SOS> in four four , the <UNK> shares shares the\n",
      "Attention Weights: tensor([[9.9791e-01, 1.9230e-03, 1.6399e-04, 6.9482e-07, 3.5799e-07, 2.2945e-08,\n",
      "         7.0628e-09, 2.2579e-09, 4.0930e-09, 3.0128e-09],\n",
      "        [2.2334e-01, 2.9324e-01, 4.5577e-01, 1.6529e-02, 6.2850e-03, 2.1828e-03,\n",
      "         1.4218e-03, 6.7509e-04, 3.3884e-04, 2.2331e-04],\n",
      "        [5.0893e-02, 1.4580e-01, 6.1581e-01, 1.3801e-01, 2.1134e-02, 1.4616e-02,\n",
      "         7.3700e-03, 3.9559e-03, 1.7339e-03, 6.7133e-04],\n",
      "        [1.0957e-03, 4.2243e-02, 1.2055e-01, 5.9716e-01, 1.3177e-01, 5.8684e-02,\n",
      "         2.4035e-02, 1.7357e-02, 4.5810e-03, 2.5221e-03],\n",
      "        [6.8071e-04, 3.7888e-02, 1.2072e-01, 4.0737e-01, 2.2488e-01, 1.1140e-01,\n",
      "         5.5239e-02, 2.9060e-02, 8.9811e-03, 3.7694e-03],\n",
      "        [4.0417e-04, 8.3269e-04, 4.1284e-03, 3.7758e-02, 1.7720e-01, 2.7095e-01,\n",
      "         2.6156e-01, 1.3329e-01, 7.3706e-02, 4.0180e-02],\n",
      "        [5.0997e-04, 1.8038e-03, 4.5309e-03, 1.0531e-02, 5.5595e-02, 1.7079e-01,\n",
      "         3.3615e-01, 1.5212e-01, 8.5964e-02, 1.8200e-01],\n",
      "        [1.1912e-04, 3.9284e-04, 1.4536e-03, 8.6376e-03, 1.0687e-02, 4.6575e-02,\n",
      "         1.3092e-01, 1.5028e-01, 1.4272e-01, 5.0821e-01],\n",
      "        [2.7371e-04, 4.1168e-04, 3.2800e-03, 9.3013e-03, 1.0217e-02, 3.3722e-02,\n",
      "         1.0895e-01, 1.3205e-01, 1.4660e-01, 5.5519e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tất_cả những thông_tin này đều được lưu_trữ ít_nhất trong sáu\n",
      "Reference: all this information is stored for at least six\n",
      "Model: <SOS> all these these are the the the in of\n",
      "Attention Weights: tensor([[8.8741e-01, 9.8906e-02, 1.2853e-02, 8.1852e-04, 1.0313e-05, 1.0713e-06,\n",
      "         1.2818e-07, 9.2526e-09, 2.4319e-09, 1.7962e-09],\n",
      "        [1.0749e-02, 1.4125e-01, 8.4227e-01, 2.2844e-03, 2.8336e-03, 4.2811e-04,\n",
      "         1.4045e-04, 3.0532e-05, 9.4385e-06, 5.6516e-06],\n",
      "        [2.4628e-02, 2.2280e-01, 6.3941e-01, 3.4442e-02, 7.0353e-02, 7.3266e-03,\n",
      "         8.9121e-04, 9.6789e-05, 3.3167e-05, 2.3188e-05],\n",
      "        [1.3328e-03, 1.6627e-02, 1.3425e-01, 4.7161e-02, 5.5757e-01, 2.0179e-01,\n",
      "         3.6037e-02, 3.2926e-03, 1.0746e-03, 8.6419e-04],\n",
      "        [4.9975e-05, 2.2403e-04, 5.9011e-03, 7.1946e-03, 3.9478e-01, 4.0392e-01,\n",
      "         1.4461e-01, 2.9285e-02, 8.0123e-03, 6.0301e-03],\n",
      "        [4.0720e-05, 1.8561e-04, 2.4838e-03, 1.4982e-03, 4.0908e-02, 1.7395e-01,\n",
      "         4.2738e-01, 2.8094e-01, 3.7191e-02, 3.5431e-02],\n",
      "        [1.5319e-05, 4.0982e-05, 4.2488e-04, 5.7033e-04, 1.3315e-02, 8.3258e-02,\n",
      "         3.1030e-01, 2.3503e-01, 2.0983e-01, 1.4722e-01],\n",
      "        [1.8614e-05, 2.2630e-05, 2.0497e-04, 2.6457e-04, 2.2448e-03, 1.9407e-02,\n",
      "         9.5372e-02, 6.4142e-02, 2.7685e-01, 5.4147e-01],\n",
      "        [7.2709e-06, 1.1983e-05, 9.0676e-05, 1.0773e-04, 1.2962e-03, 1.0827e-02,\n",
      "         4.4994e-02, 3.4269e-02, 2.4132e-01, 6.6708e-01]])\n",
      "\n",
      "Epoch: 2.48, Train Loss: 3.66, Val Loss: 4.19, Train BLEU: 10.00, Val BLEU: 9.07, Minutes Elapsed: 128.41\n",
      "Sampling from training predictions...\n",
      "Source: video này được quay từ tuần trước . <EOS> <PAD>\n",
      "Reference: this short video is from last week . <EOS>\n",
      "Model: <SOS> this is is is from from . . <EOS>\n",
      "Attention Weights: tensor([[0.9998, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.9309, 0.0165, 0.0494, 0.0030, 0.0001, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0430, 0.0799, 0.7069, 0.1604, 0.0037, 0.0046, 0.0012, 0.0001, 0.0001,\n",
      "         0.0000],\n",
      "        [0.0027, 0.0179, 0.6064, 0.2945, 0.0198, 0.0444, 0.0133, 0.0006, 0.0003,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0035, 0.1906, 0.3889, 0.0791, 0.2366, 0.0945, 0.0044, 0.0022,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0003, 0.0164, 0.1155, 0.0622, 0.5074, 0.2888, 0.0059, 0.0035,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0001, 0.0025, 0.0190, 0.0223, 0.6049, 0.3228, 0.0197, 0.0087,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0001, 0.0015, 0.0073, 0.0125, 0.2542, 0.4761, 0.1544, 0.0939,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0004, 0.0034, 0.0087, 0.0057, 0.1367, 0.3860, 0.2086, 0.2505,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: việc người bắc triều_tiên phải che dấu danh_tính của mình\n",
      "Reference: it &apos;s tragic that north koreans have to hide\n",
      "Model: <SOS> people people the to to people the the their\n",
      "Attention Weights: tensor([[9.8435e-01, 1.5272e-02, 3.7174e-04, 3.0409e-06, 1.1717e-07, 7.1299e-09,\n",
      "         1.2189e-09, 3.5210e-10, 4.4871e-11, 3.6135e-11],\n",
      "        [1.9907e-02, 2.3292e-02, 8.2622e-01, 1.2601e-01, 3.9431e-03, 3.3807e-04,\n",
      "         1.6185e-04, 1.1900e-04, 6.2449e-06, 6.4538e-06],\n",
      "        [8.3813e-03, 1.5036e-02, 2.8648e-01, 4.9991e-01, 1.6590e-01, 1.4486e-02,\n",
      "         7.0993e-03, 2.0593e-03, 2.9840e-04, 3.5170e-04],\n",
      "        [2.2037e-03, 8.3043e-03, 1.7534e-01, 5.7989e-01, 1.3758e-01, 4.1975e-02,\n",
      "         3.4831e-02, 1.7401e-02, 1.1365e-03, 1.3411e-03],\n",
      "        [7.9518e-03, 2.2090e-02, 3.5459e-01, 4.7508e-01, 9.4808e-02, 1.8778e-02,\n",
      "         1.8045e-02, 6.2616e-03, 1.1632e-03, 1.2391e-03],\n",
      "        [6.8608e-06, 3.1145e-05, 4.6167e-03, 1.0198e-01, 5.3958e-01, 1.4782e-01,\n",
      "         1.2534e-01, 6.0184e-02, 7.9372e-03, 1.2496e-02],\n",
      "        [3.2782e-05, 1.3977e-04, 7.2968e-03, 3.2881e-02, 3.8436e-01, 2.1581e-01,\n",
      "         1.9803e-01, 1.1934e-01, 1.4311e-02, 2.7799e-02],\n",
      "        [8.3778e-06, 3.5816e-05, 1.1549e-03, 7.4958e-03, 1.2520e-01, 1.1845e-01,\n",
      "         2.4188e-01, 3.6420e-01, 4.0875e-02, 1.0071e-01],\n",
      "        [6.9982e-06, 1.1546e-05, 3.2925e-04, 3.5485e-03, 2.1245e-02, 4.9526e-02,\n",
      "         2.6094e-01, 5.3484e-01, 4.8532e-02, 8.1020e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2.53, Train Loss: 3.69, Val Loss: 4.23, Train BLEU: 10.49, Val BLEU: 9.48, Minutes Elapsed: 130.89\n",
      "Sampling from training predictions...\n",
      "Source: christopher decharms quét não_bộ theo thời_gian thực <EOS> <PAD> <PAD>\n",
      "Reference: christopher decharms : a look inside the brain in\n",
      "Model: <SOS> paul jurvetson : a for for time <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9992, 0.0008, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1910, 0.7808, 0.0280, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0500, 0.4129, 0.5235, 0.0122, 0.0010, 0.0003, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0008, 0.3090, 0.5319, 0.1148, 0.0339, 0.0091, 0.0005, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0002, 0.0277, 0.1715, 0.3614, 0.3512, 0.0865, 0.0015, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0009, 0.0127, 0.0831, 0.2242, 0.4403, 0.2346, 0.0039, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0002, 0.0035, 0.0225, 0.1664, 0.4039, 0.3925, 0.0110, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0002, 0.0029, 0.0094, 0.1134, 0.4379, 0.4159, 0.0202, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0005, 0.0053, 0.0110, 0.0712, 0.3397, 0.5125, 0.0593, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: nhưng_mà , tôi hãnh_diện đứng đây là một sinh_viên tốt_nghiệp\n",
      "Reference: instead , i stand here a proud graduate of\n",
      "Model: <SOS> but , i i to this this of a\n",
      "Attention Weights: tensor([[9.9607e-01, 3.8533e-03, 5.9085e-05, 1.3529e-05, 1.5367e-06, 7.8270e-09,\n",
      "         3.7879e-10, 5.0471e-10, 1.1346e-10, 1.9792e-10],\n",
      "        [5.1512e-01, 1.7451e-01, 2.8778e-01, 2.1584e-02, 9.4516e-04, 3.6809e-05,\n",
      "         1.0328e-05, 1.0885e-05, 3.8032e-06, 3.1907e-06],\n",
      "        [5.5623e-02, 1.0894e-01, 6.4236e-01, 1.8285e-01, 8.4744e-03, 7.7786e-04,\n",
      "         2.9537e-04, 3.4670e-04, 2.0088e-04, 1.2932e-04],\n",
      "        [1.3670e-02, 5.3460e-02, 2.6797e-01, 6.4070e-01, 2.0931e-02, 1.1586e-03,\n",
      "         6.9091e-04, 6.8232e-04, 5.0450e-04, 2.3115e-04],\n",
      "        [3.2491e-02, 3.3506e-02, 3.1352e-02, 7.6545e-01, 1.3188e-01, 2.7766e-03,\n",
      "         1.0102e-03, 7.1078e-04, 5.9894e-04, 2.2594e-04],\n",
      "        [5.1356e-04, 3.4970e-04, 1.6458e-03, 2.5415e-01, 6.5599e-01, 3.5356e-02,\n",
      "         1.2975e-02, 8.8239e-03, 2.2094e-02, 8.1064e-03],\n",
      "        [6.9369e-05, 2.3584e-04, 6.6045e-04, 5.1991e-02, 2.8114e-01, 2.6874e-01,\n",
      "         1.6309e-01, 7.6950e-02, 1.0407e-01, 5.3045e-02],\n",
      "        [1.5540e-05, 3.0296e-05, 2.6873e-05, 1.1354e-02, 6.1706e-02, 7.8267e-02,\n",
      "         2.3636e-01, 2.1026e-01, 3.1068e-01, 9.1296e-02],\n",
      "        [1.0945e-05, 1.6036e-04, 5.5726e-05, 1.9985e-04, 1.3977e-03, 1.2457e-02,\n",
      "         1.5614e-01, 1.4028e-01, 3.1587e-01, 3.7343e-01]])\n",
      "\n",
      "Epoch: 2.58, Train Loss: 3.67, Val Loss: 4.17, Train BLEU: 10.62, Val BLEU: 9.50, Minutes Elapsed: 133.38\n",
      "Sampling from training predictions...\n",
      "Source: và đó sự khôi_hài với tôi , bởi_vì trầm_cảm là\n",
      "Reference: and that &apos;s ironic to me , because depression\n",
      "Model: <SOS> and that was &apos;t me me , because because\n",
      "Attention Weights: tensor([[3.1160e-03, 9.5705e-01, 3.7556e-02, 2.2472e-03, 2.6231e-05, 2.5205e-07,\n",
      "         1.4714e-10, 1.0109e-10, 7.0430e-11, 1.5474e-11],\n",
      "        [8.6597e-03, 8.9876e-01, 7.6973e-02, 1.5377e-02, 2.3042e-04, 1.2197e-06,\n",
      "         9.2551e-08, 5.7288e-08, 1.6070e-08, 3.0350e-09],\n",
      "        [9.7404e-04, 8.0727e-02, 2.6412e-01, 5.9003e-01, 6.1992e-02, 8.9905e-04,\n",
      "         5.1240e-04, 5.3358e-04, 1.7242e-04, 3.7517e-05],\n",
      "        [2.5451e-03, 6.5051e-02, 9.2565e-02, 5.0373e-01, 3.0660e-01, 1.4292e-02,\n",
      "         1.0395e-02, 3.2563e-03, 1.2784e-03, 2.8039e-04],\n",
      "        [2.0871e-04, 2.4081e-03, 5.6098e-03, 1.1241e-01, 7.3025e-01, 5.6198e-02,\n",
      "         6.5320e-02, 2.2486e-02, 4.4584e-03, 6.5096e-04],\n",
      "        [2.0552e-04, 1.6448e-03, 5.3917e-03, 5.0766e-02, 3.6016e-01, 1.1149e-01,\n",
      "         2.8922e-01, 1.6911e-01, 1.0706e-02, 1.3056e-03],\n",
      "        [3.2097e-05, 3.0321e-04, 1.6768e-04, 1.0530e-03, 8.6388e-03, 6.7604e-03,\n",
      "         2.0354e-01, 6.9105e-01, 8.2982e-02, 5.4767e-03],\n",
      "        [8.1295e-05, 1.8435e-04, 9.7813e-05, 3.3383e-04, 2.2538e-03, 1.9732e-03,\n",
      "         1.1186e-01, 7.3752e-01, 1.3657e-01, 9.1244e-03],\n",
      "        [2.1645e-04, 1.1769e-03, 2.5387e-04, 9.4139e-04, 1.9721e-03, 6.4137e-04,\n",
      "         2.3735e-02, 5.4772e-01, 4.0985e-01, 1.3487e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: vì_vậy hôm_nay tôi muốn động_viên tất_cả mọi người hãy có_mặt\n",
      "Reference: so i want to encourage everyone today to get\n",
      "Model: <SOS> so i want to tell you all people you\n",
      "Attention Weights: tensor([[9.8956e-01, 1.0253e-02, 1.6761e-04, 2.0070e-05, 2.1248e-06, 2.8145e-08,\n",
      "         6.7424e-10, 1.0303e-10, 1.2888e-10, 1.4051e-10],\n",
      "        [1.3649e-02, 3.2104e-01, 6.2498e-01, 4.0180e-02, 1.3313e-04, 3.0183e-06,\n",
      "         1.2427e-06, 1.0208e-06, 1.6278e-06, 9.7740e-07],\n",
      "        [2.0458e-03, 1.2798e-02, 1.5166e-01, 8.1853e-01, 1.4023e-02, 3.2354e-04,\n",
      "         2.1696e-04, 1.5574e-04, 1.1554e-04, 1.2435e-04],\n",
      "        [5.2778e-03, 5.6054e-03, 2.5056e-02, 8.6321e-01, 9.6588e-02, 2.0432e-03,\n",
      "         1.0480e-03, 4.9853e-04, 3.3252e-04, 3.4054e-04],\n",
      "        [1.2997e-04, 3.3214e-04, 5.5465e-04, 7.6850e-03, 9.2979e-01, 3.9081e-02,\n",
      "         1.3116e-02, 4.4617e-03, 1.8754e-03, 2.9734e-03],\n",
      "        [1.5234e-04, 2.7897e-04, 3.3988e-04, 3.2590e-03, 4.4159e-01, 4.6530e-01,\n",
      "         7.1296e-02, 1.0915e-02, 2.2257e-03, 4.6384e-03],\n",
      "        [1.7520e-05, 7.6130e-05, 4.7994e-05, 7.4231e-04, 8.1719e-02, 3.6106e-01,\n",
      "         3.7500e-01, 1.2621e-01, 1.5530e-02, 3.9600e-02],\n",
      "        [4.6822e-06, 1.0127e-05, 7.5115e-06, 9.0537e-05, 2.8796e-03, 2.0298e-02,\n",
      "         1.7843e-01, 4.0077e-01, 1.0400e-01, 2.9351e-01],\n",
      "        [1.5957e-05, 2.0177e-05, 2.0967e-05, 1.9404e-04, 1.4066e-03, 4.1592e-03,\n",
      "         2.8291e-02, 2.0726e-01, 1.7232e-01, 5.8631e-01]])\n",
      "\n",
      "Epoch: 2.62, Train Loss: 3.64, Val Loss: 4.15, Train BLEU: 10.87, Val BLEU: 10.37, Minutes Elapsed: 135.86\n",
      "Sampling from training predictions...\n",
      "Source: nhưng có những dạng nâng cao . <EOS> <PAD> <PAD>\n",
      "Reference: but there are advanced configurations . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> but there are a . . <EOS> . .\n",
      "Attention Weights: tensor([[0.1216, 0.8781, 0.0003, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0150, 0.9824, 0.0022, 0.0002, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0719, 0.4138, 0.2516, 0.1912, 0.0581, 0.0123, 0.0007, 0.0004, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0211, 0.1100, 0.1362, 0.4021, 0.2710, 0.0513, 0.0067, 0.0017, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0031, 0.0159, 0.0546, 0.5123, 0.3146, 0.0883, 0.0095, 0.0017, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0016, 0.0178, 0.0327, 0.3138, 0.3758, 0.1897, 0.0536, 0.0149, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0031, 0.0077, 0.0050, 0.0478, 0.2423, 0.2500, 0.2569, 0.1872, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0182, 0.0614, 0.0169, 0.0494, 0.1404, 0.3049, 0.1389, 0.2699, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0443, 0.1126, 0.1180, 0.1956, 0.2985, 0.1050, 0.0546, 0.0714, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: một_số nơi tôi coi_như nhà mình . <EOS> <PAD> <PAD>\n",
      "Reference: some i even considered like my second home .\n",
      "Model: <SOS> some few my my my . . . <EOS>\n",
      "Attention Weights: tensor([[0.9994, 0.0006, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.8810, 0.1158, 0.0014, 0.0016, 0.0001, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.5064, 0.3547, 0.0362, 0.0937, 0.0063, 0.0021, 0.0005, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0687, 0.2960, 0.0979, 0.4915, 0.0339, 0.0104, 0.0012, 0.0003, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0147, 0.0435, 0.0199, 0.5978, 0.2329, 0.0782, 0.0084, 0.0046, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0026, 0.0044, 0.4286, 0.3243, 0.2062, 0.0246, 0.0089, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0010, 0.0040, 0.0120, 0.1499, 0.2873, 0.3818, 0.1184, 0.0456, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0018, 0.0068, 0.0123, 0.2208, 0.1347, 0.4314, 0.1438, 0.0486, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0025, 0.0188, 0.0168, 0.0723, 0.1448, 0.2111, 0.2658, 0.2681, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 2.67, Train Loss: 3.66, Val Loss: 4.18, Train BLEU: 9.52, Val BLEU: 9.17, Minutes Elapsed: 138.37\n",
      "Sampling from training predictions...\n",
      "Source: kích_cỡ của căn phòng_không to tới_mức này . <EOS> <PAD>\n",
      "Reference: and the size of the room is not that\n",
      "Model: <SOS> the size of of the is is this .\n",
      "Attention Weights: tensor([[0.9969, 0.0030, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.9371, 0.0592, 0.0020, 0.0016, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4721, 0.3347, 0.0922, 0.0894, 0.0097, 0.0014, 0.0002, 0.0002, 0.0001,\n",
      "         0.0000],\n",
      "        [0.4069, 0.3488, 0.0907, 0.1217, 0.0270, 0.0038, 0.0004, 0.0005, 0.0002,\n",
      "         0.0000],\n",
      "        [0.0659, 0.2741, 0.1393, 0.3982, 0.1028, 0.0163, 0.0010, 0.0018, 0.0006,\n",
      "         0.0000],\n",
      "        [0.0137, 0.0623, 0.0795, 0.5843, 0.2057, 0.0478, 0.0027, 0.0029, 0.0011,\n",
      "         0.0000],\n",
      "        [0.0036, 0.0184, 0.0389, 0.3791, 0.3045, 0.2234, 0.0139, 0.0137, 0.0046,\n",
      "         0.0000],\n",
      "        [0.0015, 0.0162, 0.0429, 0.4274, 0.3105, 0.1810, 0.0089, 0.0087, 0.0030,\n",
      "         0.0000],\n",
      "        [0.0035, 0.0190, 0.0527, 0.3972, 0.2091, 0.2914, 0.0190, 0.0061, 0.0021,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi tới đây không có ý_định truyền cảm_hứng cho bạn\n",
      "Reference: i am here today not at all to inspire\n",
      "Model: <SOS> i i there there a you you you you\n",
      "Attention Weights: tensor([[4.2289e-02, 9.3603e-01, 1.8497e-02, 3.1475e-03, 3.4858e-05, 1.8442e-06,\n",
      "         1.2313e-07, 1.2868e-07, 3.6001e-08, 1.2318e-08],\n",
      "        [5.9471e-03, 9.8043e-01, 8.6518e-03, 4.8443e-03, 5.8410e-05, 4.4434e-05,\n",
      "         1.2641e-05, 5.0091e-06, 2.0395e-06, 7.3505e-07],\n",
      "        [6.1990e-03, 2.5977e-01, 3.3239e-01, 3.8398e-01, 1.3381e-02, 3.7435e-03,\n",
      "         3.3345e-04, 1.4296e-04, 4.5252e-05, 2.0180e-05],\n",
      "        [7.8785e-04, 1.6039e-02, 1.1410e-01, 4.6694e-01, 1.6555e-01, 1.9011e-01,\n",
      "         3.2069e-02, 1.1544e-02, 2.0357e-03, 8.1396e-04],\n",
      "        [2.6939e-05, 6.7065e-04, 8.1136e-03, 1.1997e-01, 1.0276e-01, 3.7241e-01,\n",
      "         1.8145e-01, 1.4345e-01, 5.7112e-02, 1.4034e-02],\n",
      "        [3.8228e-05, 1.8143e-03, 4.0123e-03, 1.8684e-01, 8.4256e-02, 3.0174e-01,\n",
      "         1.9854e-01, 1.5957e-01, 5.2321e-02, 1.0875e-02],\n",
      "        [3.4014e-04, 7.6823e-03, 2.9952e-03, 5.8484e-02, 4.8675e-02, 1.4057e-01,\n",
      "         2.0272e-01, 3.1235e-01, 1.7306e-01, 5.3121e-02],\n",
      "        [2.3249e-05, 3.0977e-04, 8.9714e-04, 7.0528e-03, 2.0293e-02, 9.1918e-02,\n",
      "         1.7408e-01, 3.7966e-01, 2.5509e-01, 7.0682e-02],\n",
      "        [4.9075e-05, 2.8392e-04, 8.2458e-04, 8.3536e-03, 1.2902e-02, 4.9738e-02,\n",
      "         1.6208e-01, 3.8425e-01, 2.6476e-01, 1.1675e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2.72, Train Loss: 3.66, Val Loss: 4.16, Train BLEU: 10.18, Val BLEU: 9.75, Minutes Elapsed: 140.85\n",
      "Sampling from training predictions...\n",
      "Source: việc đọc và viết trình_tự dna đang trở_nên dễ_dàng hơn\n",
      "Reference: reading and writing dna code is getting easier and\n",
      "Model: <SOS> the and and the the are are by .\n",
      "Attention Weights: tensor([[9.7130e-01, 2.8701e-02, 2.1642e-06, 1.1233e-07, 1.4739e-08, 1.2283e-09,\n",
      "         1.3832e-10, 4.9727e-11, 2.1162e-11, 8.7944e-12],\n",
      "        [6.5687e-02, 9.2945e-01, 3.1540e-03, 1.4207e-03, 2.6146e-04, 2.1163e-05,\n",
      "         2.9533e-06, 1.8372e-06, 7.3040e-07, 3.2974e-07],\n",
      "        [1.1505e-01, 6.2021e-01, 7.2706e-02, 1.3768e-01, 4.3924e-02, 8.3797e-03,\n",
      "         1.0123e-03, 5.5133e-04, 3.2967e-04, 1.5472e-04],\n",
      "        [7.0630e-03, 6.9019e-02, 7.4822e-02, 4.3517e-01, 2.9337e-01, 9.4154e-02,\n",
      "         1.4754e-02, 6.0884e-03, 3.7349e-03, 1.8214e-03],\n",
      "        [1.3270e-03, 7.5426e-03, 6.2995e-03, 1.3493e-01, 3.5991e-01, 3.1771e-01,\n",
      "         1.0642e-01, 4.1770e-02, 1.7467e-02, 6.6221e-03],\n",
      "        [4.5146e-05, 1.3762e-04, 6.9350e-05, 7.9787e-03, 8.4475e-02, 2.0681e-01,\n",
      "         2.8476e-01, 1.8068e-01, 1.5257e-01, 8.2478e-02],\n",
      "        [5.0455e-05, 8.8347e-05, 3.4715e-05, 1.1438e-03, 8.7503e-03, 3.0542e-02,\n",
      "         1.2020e-01, 1.8374e-01, 4.0477e-01, 2.5067e-01],\n",
      "        [2.1347e-04, 6.6827e-04, 8.2721e-05, 1.2389e-03, 7.3177e-03, 1.7304e-02,\n",
      "         6.9231e-02, 1.5172e-01, 2.8880e-01, 4.6343e-01],\n",
      "        [1.2204e-04, 8.2651e-04, 2.7849e-04, 1.8389e-03, 7.2319e-03, 1.1365e-02,\n",
      "         4.6199e-02, 2.0397e-01, 2.1816e-01, 5.1000e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: không_phải đến thời_điểm ấy mà tôi mới nhận_ra những tấm\n",
      "Reference: now , it wasn &apos;t until this point that\n",
      "Model: <SOS> not &apos;s &apos;s &apos;s not that that i i\n",
      "Attention Weights: tensor([[9.7977e-01, 1.9306e-02, 9.0153e-04, 2.5194e-05, 1.2909e-06, 3.0680e-07,\n",
      "         1.5694e-07, 2.3631e-08, 1.2368e-08, 1.2853e-08],\n",
      "        [6.0380e-01, 2.2660e-01, 1.6037e-01, 5.4881e-03, 3.0201e-03, 2.8460e-04,\n",
      "         3.3632e-04, 6.7460e-05, 1.7941e-05, 1.4382e-05],\n",
      "        [4.7110e-01, 1.5898e-01, 2.2335e-01, 7.5642e-02, 4.7359e-02, 1.0553e-02,\n",
      "         1.0337e-02, 1.7273e-03, 5.1659e-04, 4.3728e-04],\n",
      "        [4.7060e-01, 1.1702e-01, 1.8670e-01, 7.2674e-02, 8.2095e-02, 2.3475e-02,\n",
      "         4.0590e-02, 4.8730e-03, 1.1747e-03, 7.8954e-04],\n",
      "        [5.8809e-01, 9.8529e-02, 1.6328e-01, 4.4615e-02, 4.9870e-02, 1.2877e-02,\n",
      "         3.4853e-02, 5.9277e-03, 1.2315e-03, 7.3020e-04],\n",
      "        [4.6317e-02, 6.0600e-02, 4.9834e-01, 1.8017e-01, 1.1111e-01, 2.7159e-02,\n",
      "         5.9881e-02, 1.3564e-02, 1.7360e-03, 1.1263e-03],\n",
      "        [7.2745e-03, 6.8752e-03, 2.0636e-01, 2.1657e-01, 2.5399e-01, 1.1113e-01,\n",
      "         1.5118e-01, 3.3867e-02, 7.8506e-03, 4.9090e-03],\n",
      "        [2.0610e-03, 1.8154e-03, 5.4171e-02, 1.2394e-01, 2.7634e-01, 1.3558e-01,\n",
      "         3.3530e-01, 5.2646e-02, 9.8679e-03, 8.2751e-03],\n",
      "        [1.4465e-03, 4.6141e-04, 5.2429e-03, 9.8380e-03, 7.2130e-02, 7.9300e-02,\n",
      "         5.9409e-01, 1.8690e-01, 3.2708e-02, 1.7877e-02]])\n",
      "\n",
      "Epoch: 2.77, Train Loss: 3.71, Val Loss: 4.21, Train BLEU: 9.93, Val BLEU: 9.68, Minutes Elapsed: 143.32\n",
      "Sampling from training predictions...\n",
      "Source: thực_sự khó_khăn khi tôi phải nói về sự trầm_cảm của\n",
      "Reference: it &apos;s hard for me to talk about ,\n",
      "Model: <SOS> it was really to when i i about about\n",
      "Attention Weights: tensor([[9.9568e-01, 4.2816e-03, 3.3104e-05, 5.5925e-07, 2.9061e-07, 3.2785e-09,\n",
      "         2.2541e-09, 1.5766e-09, 1.7251e-09, 3.6822e-10],\n",
      "        [5.3856e-01, 4.5482e-01, 6.2783e-03, 1.3060e-04, 1.8868e-04, 5.3306e-06,\n",
      "         4.4932e-06, 3.5405e-06, 4.1531e-06, 6.2862e-07],\n",
      "        [7.5131e-01, 2.2027e-01, 2.1178e-02, 1.2827e-03, 5.2685e-03, 3.5670e-04,\n",
      "         1.5614e-04, 7.9415e-05, 8.5538e-05, 1.9074e-05],\n",
      "        [2.4855e-01, 6.1068e-01, 9.3390e-02, 8.0274e-03, 2.4650e-02, 7.4129e-03,\n",
      "         3.7953e-03, 1.7408e-03, 1.6039e-03, 1.4922e-04],\n",
      "        [1.4550e-01, 3.9719e-01, 3.2337e-01, 4.1468e-02, 4.5151e-02, 1.8136e-02,\n",
      "         1.4113e-02, 7.4646e-03, 6.7075e-03, 9.0385e-04],\n",
      "        [2.4179e-03, 2.4924e-02, 1.6984e-01, 1.1763e-01, 4.5759e-01, 9.4788e-02,\n",
      "         6.5577e-02, 3.5114e-02, 2.7605e-02, 4.5050e-03],\n",
      "        [3.5007e-03, 2.1758e-02, 2.2501e-01, 1.9907e-01, 4.6231e-01, 4.6310e-02,\n",
      "         1.9333e-02, 1.0463e-02, 9.9864e-03, 2.2583e-03],\n",
      "        [3.8511e-05, 2.5685e-04, 8.4994e-03, 4.0971e-02, 5.9962e-01, 1.2387e-01,\n",
      "         1.1254e-01, 6.7282e-02, 4.1049e-02, 5.8683e-03],\n",
      "        [2.4407e-05, 1.6713e-04, 3.1346e-03, 5.7845e-03, 3.6681e-02, 1.0448e-01,\n",
      "         3.3407e-01, 2.9818e-01, 2.0015e-01, 1.7327e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: chúng_tôi sẽ cỗ vũ cháu trên con đường cháu đi\n",
      "Reference: we &apos;re going to cheer you on every step\n",
      "Model: <SOS> we &apos;re going to focus on the the street\n",
      "Attention Weights: tensor([[2.1772e-01, 7.8086e-01, 1.4118e-03, 7.2735e-06, 1.5506e-06, 5.8055e-08,\n",
      "         8.0249e-09, 1.0610e-08, 4.2539e-09, 7.3122e-09],\n",
      "        [1.3015e-02, 9.5987e-01, 2.7037e-02, 6.0014e-05, 1.4143e-05, 4.9945e-06,\n",
      "         1.0809e-06, 1.0620e-06, 4.5093e-07, 2.3326e-07],\n",
      "        [2.0309e-02, 4.0698e-01, 5.5323e-01, 1.7842e-02, 1.0999e-03, 3.1703e-04,\n",
      "         8.2934e-05, 7.9333e-05, 4.0786e-05, 1.9566e-05],\n",
      "        [1.1800e-03, 7.4653e-03, 5.0819e-01, 4.1173e-01, 5.4547e-02, 1.1377e-02,\n",
      "         1.4847e-03, 2.0617e-03, 1.0604e-03, 9.1227e-04],\n",
      "        [5.5568e-04, 2.1302e-03, 2.8169e-01, 4.5612e-01, 1.6304e-01, 6.1731e-02,\n",
      "         1.2546e-02, 1.1851e-02, 5.2620e-03, 5.0744e-03],\n",
      "        [1.9243e-03, 8.2535e-03, 1.9244e-01, 6.1590e-01, 1.4169e-01, 3.0256e-02,\n",
      "         2.8172e-03, 3.4652e-03, 1.8824e-03, 1.3685e-03],\n",
      "        [5.9322e-05, 1.7872e-04, 4.3358e-03, 1.8428e-01, 4.0910e-01, 3.6069e-01,\n",
      "         1.5877e-02, 1.2351e-02, 6.3306e-03, 6.7973e-03],\n",
      "        [1.1242e-05, 1.4259e-04, 5.1038e-04, 1.4168e-02, 2.3972e-01, 5.7069e-01,\n",
      "         7.6342e-02, 6.1836e-02, 2.0179e-02, 1.6399e-02],\n",
      "        [4.6067e-06, 1.7243e-05, 4.6019e-04, 1.3312e-02, 1.3780e-01, 4.6984e-01,\n",
      "         1.2992e-01, 1.4889e-01, 5.9928e-02, 3.9824e-02]])\n",
      "\n",
      "Epoch: 2.82, Train Loss: 3.64, Val Loss: 4.13, Train BLEU: 10.81, Val BLEU: 9.79, Minutes Elapsed: 145.78\n",
      "Sampling from training predictions...\n",
      "Source: và hoá_ra đó là tình_trạng chung thôi . chúng_ta mắc\n",
      "Reference: and it turns out it &apos;s a more general\n",
      "Model: <SOS> and it turns out the the the . .\n",
      "Attention Weights: tensor([[3.3268e-03, 9.9634e-01, 3.2033e-04, 1.3688e-05, 1.3958e-06, 2.0480e-08,\n",
      "         1.1251e-09, 2.1076e-10, 3.7889e-12, 1.7724e-11],\n",
      "        [5.3039e-03, 9.9367e-01, 9.7948e-04, 4.0885e-05, 9.3335e-06, 1.0440e-06,\n",
      "         2.4602e-07, 3.5197e-08, 7.5598e-09, 1.1605e-08],\n",
      "        [1.0753e-03, 8.8117e-01, 8.4796e-02, 2.2777e-02, 7.3119e-03, 2.1017e-03,\n",
      "         6.5992e-04, 3.2632e-05, 2.1937e-05, 5.4573e-05],\n",
      "        [2.1607e-03, 5.5363e-01, 1.8409e-01, 1.6798e-01, 5.5642e-02, 2.2624e-02,\n",
      "         1.2502e-02, 5.3955e-04, 2.0206e-04, 6.3740e-04],\n",
      "        [1.9540e-04, 7.8819e-03, 1.7767e-02, 1.9097e-01, 4.0750e-01, 2.0780e-01,\n",
      "         1.6397e-01, 2.1499e-03, 4.7511e-04, 1.2779e-03],\n",
      "        [9.1089e-06, 1.4119e-03, 7.3158e-03, 1.0586e-01, 3.4037e-01, 2.9423e-01,\n",
      "         2.3524e-01, 9.9915e-03, 1.6940e-03, 3.8735e-03],\n",
      "        [5.0375e-06, 7.9836e-04, 8.7047e-03, 8.8127e-02, 4.1789e-01, 2.8839e-01,\n",
      "         1.4816e-01, 2.6203e-02, 4.7953e-03, 1.6916e-02],\n",
      "        [1.7543e-06, 4.2969e-05, 3.4139e-04, 2.7957e-02, 3.4084e-01, 4.0378e-01,\n",
      "         1.6848e-01, 2.7597e-02, 3.5794e-03, 2.7384e-02],\n",
      "        [2.8255e-06, 5.3720e-05, 6.0913e-04, 1.1288e-02, 1.6763e-01, 2.8432e-01,\n",
      "         2.3031e-01, 1.9084e-01, 3.9786e-02, 7.5165e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: họ biết hình của họ sẽ được xem bởi những\n",
      "Reference: they knew their image would be seen by you\n",
      "Model: <SOS> they knew their their to to to to the\n",
      "Attention Weights: tensor([[9.1553e-01, 8.4230e-02, 2.3860e-04, 6.2408e-07, 3.8412e-08, 3.3782e-08,\n",
      "         7.6010e-09, 1.1217e-09, 8.2808e-10, 4.0379e-10],\n",
      "        [4.8636e-03, 9.6489e-01, 3.0090e-02, 1.3241e-04, 6.5308e-06, 1.2106e-05,\n",
      "         7.0541e-06, 2.0502e-06, 1.1974e-06, 5.1358e-07],\n",
      "        [3.4811e-03, 2.9827e-01, 6.8877e-01, 6.9107e-03, 1.0728e-03, 7.5843e-04,\n",
      "         4.8096e-04, 1.4436e-04, 8.9498e-05, 2.4795e-05],\n",
      "        [8.5078e-04, 3.9565e-02, 8.0331e-01, 9.7431e-02, 4.0012e-02, 7.8999e-03,\n",
      "         5.3579e-03, 2.1798e-03, 2.6292e-03, 7.6692e-04],\n",
      "        [6.7810e-05, 2.4328e-03, 2.0907e-02, 6.5321e-02, 1.8055e-01, 3.8702e-01,\n",
      "         1.8296e-01, 7.8005e-02, 6.2987e-02, 1.9755e-02],\n",
      "        [6.7419e-06, 1.1572e-04, 2.7559e-04, 2.5168e-03, 6.4671e-02, 3.5919e-01,\n",
      "         2.1928e-01, 1.5856e-01, 1.6013e-01, 3.5258e-02],\n",
      "        [2.6486e-05, 3.0001e-04, 2.3767e-03, 2.8557e-03, 7.3598e-03, 5.2929e-02,\n",
      "         1.3708e-01, 2.0393e-01, 4.6334e-01, 1.2981e-01],\n",
      "        [1.5342e-05, 3.3066e-05, 1.4111e-03, 8.6507e-04, 9.9702e-04, 2.0511e-03,\n",
      "         1.0739e-02, 1.1647e-01, 6.5673e-01, 2.1069e-01],\n",
      "        [4.2150e-05, 1.5617e-04, 7.3901e-04, 1.3219e-03, 2.6063e-03, 1.1075e-02,\n",
      "         2.1489e-02, 1.1173e-01, 5.4738e-01, 3.0346e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2.86, Train Loss: 3.63, Val Loss: 4.12, Train BLEU: 10.32, Val BLEU: 9.78, Minutes Elapsed: 148.26\n",
      "Sampling from training predictions...\n",
      "Source: nói_chung thi jimmy stewart đã cản_trở các đạo_luật trong toàn_bộ\n",
      "Reference: after all , jimmy stewart filibustered for two entire\n",
      "Model: <SOS> so shows shows stewart studies has in the entire\n",
      "Attention Weights: tensor([[9.9520e-01, 4.6144e-03, 1.5402e-04, 2.3869e-05, 2.6237e-06, 3.0048e-07,\n",
      "         6.2199e-08, 3.5175e-08, 1.7909e-08, 5.0645e-09],\n",
      "        [2.3679e-01, 6.6258e-01, 8.0380e-02, 1.9290e-02, 5.6827e-04, 2.8668e-04,\n",
      "         3.1384e-05, 5.8949e-05, 9.5251e-06, 3.1745e-06],\n",
      "        [7.5691e-02, 5.3665e-01, 2.5857e-01, 1.0068e-01, 1.7406e-02, 7.8123e-03,\n",
      "         9.0689e-04, 1.9210e-03, 2.7604e-04, 8.3791e-05],\n",
      "        [2.8211e-03, 1.0664e-01, 3.2594e-01, 3.1838e-01, 1.8572e-01, 4.4500e-02,\n",
      "         3.8978e-03, 9.5690e-03, 2.0702e-03, 4.5828e-04],\n",
      "        [2.6680e-04, 2.0738e-02, 1.6574e-01, 2.8540e-01, 3.8215e-01, 1.1983e-01,\n",
      "         7.2937e-03, 1.3689e-02, 4.1408e-03, 7.5375e-04],\n",
      "        [1.4019e-03, 2.2392e-02, 6.5784e-02, 1.0337e-01, 5.5378e-01, 2.1899e-01,\n",
      "         1.2172e-02, 1.8990e-02, 2.6249e-03, 4.9703e-04],\n",
      "        [1.0036e-06, 7.9496e-05, 3.3654e-03, 2.0948e-02, 4.4459e-02, 4.0426e-01,\n",
      "         1.5748e-01, 2.9413e-01, 5.3783e-02, 2.1496e-02],\n",
      "        [2.7888e-07, 1.5218e-05, 2.9013e-04, 1.6403e-03, 5.6224e-03, 1.0427e-01,\n",
      "         1.3194e-01, 4.5162e-01, 1.5773e-01, 1.4687e-01],\n",
      "        [6.5746e-07, 2.5529e-05, 2.4872e-04, 1.0117e-03, 6.9905e-03, 8.1425e-02,\n",
      "         9.1763e-02, 2.4395e-01, 1.9839e-01, 3.7620e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: quân_cảnh không giúp ngăn_chặn sự lây_lan của bệnh_tật . <EOS>\n",
      "Reference: mps do not help to prevent the spread of\n",
      "Model: <SOS> the doesn &apos;t the the the . . .\n",
      "Attention Weights: tensor([[9.9619e-01, 3.7701e-03, 3.5688e-05, 5.3672e-07, 3.5921e-08, 1.9238e-08,\n",
      "         3.1880e-09, 8.2505e-10, 7.9890e-11, 7.9889e-11],\n",
      "        [4.8745e-01, 3.1485e-01, 1.5038e-01, 4.2005e-02, 2.4651e-03, 1.7824e-03,\n",
      "         7.0953e-04, 2.9813e-04, 3.9894e-05, 1.9394e-05],\n",
      "        [8.1238e-02, 2.1205e-01, 2.4308e-01, 3.4306e-01, 6.6324e-02, 3.0332e-02,\n",
      "         1.1597e-02, 1.1301e-02, 7.2856e-04, 2.9442e-04],\n",
      "        [3.1598e-03, 9.1980e-03, 2.3093e-01, 4.7168e-01, 1.7203e-01, 6.9463e-02,\n",
      "         2.6708e-02, 1.6330e-02, 3.3359e-04, 1.6037e-04],\n",
      "        [2.8554e-04, 1.0709e-03, 2.0720e-02, 3.0399e-01, 1.9617e-01, 2.2575e-01,\n",
      "         1.2889e-01, 1.2052e-01, 1.6466e-03, 9.6681e-04],\n",
      "        [2.4503e-04, 1.3674e-03, 1.4618e-02, 1.2699e-01, 1.3857e-01, 3.6698e-01,\n",
      "         1.6616e-01, 1.7807e-01, 4.9481e-03, 2.0625e-03],\n",
      "        [7.3247e-05, 1.9921e-04, 1.5379e-03, 4.0918e-02, 1.0933e-01, 4.1192e-01,\n",
      "         1.7327e-01, 2.4730e-01, 1.0901e-02, 4.5552e-03],\n",
      "        [3.3966e-05, 1.0802e-04, 8.9646e-04, 2.0478e-02, 8.2474e-02, 3.5902e-01,\n",
      "         2.2374e-01, 2.7648e-01, 2.4831e-02, 1.1939e-02],\n",
      "        [1.7265e-04, 4.3494e-04, 1.3716e-03, 1.4795e-02, 5.4673e-02, 3.5996e-01,\n",
      "         1.5726e-01, 3.1913e-01, 5.6789e-02, 3.5422e-02]])\n",
      "\n",
      "Epoch: 2.91, Train Loss: 3.65, Val Loss: 4.13, Train BLEU: 10.15, Val BLEU: 9.41, Minutes Elapsed: 150.76\n",
      "Sampling from training predictions...\n",
      "Source: tất_nhiên họ có_thể <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: of course they would . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> of course can they . . course . <EOS>\n",
      "Attention Weights: tensor([[0.9998, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.9603, 0.0342, 0.0055, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.3287, 0.2071, 0.4354, 0.0289, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1296, 0.3696, 0.4537, 0.0470, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0678, 0.1078, 0.7431, 0.0813, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0314, 0.0282, 0.1077, 0.8327, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0402, 0.0343, 0.0591, 0.8663, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1299, 0.0898, 0.4799, 0.3004, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1970, 0.1372, 0.3623, 0.3034, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: xã_hội của chúng_tôi cần những sự đại_diện có phẩm_chất từ\n",
      "Reference: our society needs the qualitative representation of the feminine\n",
      "Model: <SOS> our society is to need of to the that\n",
      "Attention Weights: tensor([[9.9910e-01, 9.0095e-04, 3.5960e-06, 1.1598e-07, 8.8055e-10, 1.0415e-10,\n",
      "         5.7411e-11, 1.4246e-11, 8.4167e-12, 5.6134e-12],\n",
      "        [9.4908e-01, 4.8845e-02, 1.7246e-03, 3.3547e-04, 1.3246e-05, 1.5800e-06,\n",
      "         2.5670e-06, 4.8563e-07, 6.7845e-07, 1.1042e-07],\n",
      "        [5.8662e-02, 3.7563e-01, 9.3083e-02, 4.5222e-01, 1.6639e-02, 1.9485e-03,\n",
      "         1.0017e-03, 4.1099e-04, 3.2781e-04, 7.1418e-05],\n",
      "        [6.5897e-04, 5.7634e-03, 6.9234e-02, 7.2560e-01, 1.4719e-01, 2.1832e-02,\n",
      "         1.6676e-02, 8.3938e-03, 3.8252e-03, 8.2720e-04],\n",
      "        [1.0706e-03, 6.7608e-04, 3.7309e-03, 2.0969e-01, 4.3681e-01, 1.2628e-01,\n",
      "         1.7930e-01, 1.8765e-02, 2.1421e-02, 2.2622e-03],\n",
      "        [2.4130e-04, 1.8013e-04, 1.1920e-04, 1.1982e-02, 3.6760e-01, 2.0460e-01,\n",
      "         2.7046e-01, 5.7655e-02, 7.4684e-02, 1.2483e-02],\n",
      "        [4.0275e-05, 3.8224e-05, 3.2862e-05, 5.0942e-03, 4.2517e-02, 1.7476e-01,\n",
      "         3.3963e-01, 2.4379e-01, 1.6617e-01, 2.7922e-02],\n",
      "        [4.4566e-05, 7.7244e-05, 4.9694e-05, 9.6838e-04, 4.2121e-03, 1.4125e-02,\n",
      "         9.0893e-02, 3.1420e-01, 4.5691e-01, 1.1852e-01],\n",
      "        [5.3513e-04, 3.6224e-04, 1.1764e-04, 1.1616e-03, 8.1926e-03, 1.1793e-02,\n",
      "         6.2801e-02, 2.7808e-01, 4.7949e-01, 1.5747e-01]])\n",
      "\n",
      "Epoch: 2.96, Train Loss: 3.60, Val Loss: 4.11, Train BLEU: 10.66, Val BLEU: 9.76, Minutes Elapsed: 153.22\n",
      "Sampling from training predictions...\n",
      "Source: và thực_ra đó là một trải_nghiệm ở một buổi nhạc_kịch\n",
      "Reference: and well , that was an opera experience .\n",
      "Model: <SOS> and it was it &apos;s a a of a\n",
      "Attention Weights: tensor([[1.4509e-02, 9.7920e-01, 6.2747e-03, 1.8014e-05, 2.2413e-06, 2.9158e-07,\n",
      "         2.7491e-09, 7.3014e-10, 4.0331e-11, 5.0027e-11],\n",
      "        [1.6432e-02, 9.7143e-01, 1.1991e-02, 1.2110e-04, 1.7047e-05, 7.9310e-06,\n",
      "         3.0696e-07, 8.9622e-08, 2.0566e-08, 1.4351e-08],\n",
      "        [4.5261e-03, 7.0355e-01, 1.8543e-01, 6.4529e-02, 1.6857e-02, 2.4153e-02,\n",
      "         6.1313e-04, 1.3815e-04, 1.1919e-04, 8.8301e-05],\n",
      "        [3.5866e-03, 2.9598e-01, 1.3367e-01, 3.0391e-01, 1.3058e-01, 1.2240e-01,\n",
      "         7.0149e-03, 1.0885e-03, 1.1298e-03, 6.4241e-04],\n",
      "        [1.7892e-03, 3.9109e-01, 1.2406e-01, 2.4440e-01, 9.1079e-02, 1.3516e-01,\n",
      "         8.8571e-03, 1.5905e-03, 1.1854e-03, 7.9161e-04],\n",
      "        [2.4351e-03, 2.7299e-01, 1.4446e-01, 2.7078e-01, 1.0698e-01, 1.8747e-01,\n",
      "         1.0840e-02, 1.5386e-03, 1.4398e-03, 1.0560e-03],\n",
      "        [4.1805e-05, 4.7106e-03, 1.0222e-02, 7.1995e-02, 6.2638e-02, 8.0760e-01,\n",
      "         3.1881e-02, 4.5211e-03, 3.3104e-03, 3.0771e-03],\n",
      "        [1.2066e-05, 4.1824e-04, 7.6379e-04, 5.6059e-03, 1.9337e-02, 7.9435e-01,\n",
      "         1.2764e-01, 1.3434e-02, 2.4105e-02, 1.4336e-02],\n",
      "        [1.4070e-05, 3.9808e-04, 2.4483e-03, 8.0793e-03, 6.7558e-03, 4.9694e-02,\n",
      "         4.6644e-01, 1.0765e-01, 2.5618e-01, 1.0233e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: đó sẽ là các <UNK> , và họ đang thực_hiện\n",
      "Reference: it will be entrepreneurs , and they &apos;re doing\n",
      "Model: <SOS> they would be be , and they &apos;re the\n",
      "Attention Weights: tensor([[3.2194e-01, 6.7626e-01, 1.7717e-03, 2.7548e-05, 1.5987e-07, 5.8984e-09,\n",
      "         1.4485e-09, 6.2816e-11, 1.2922e-10, 3.6310e-11],\n",
      "        [1.5138e-02, 9.6135e-01, 2.1754e-02, 1.6887e-03, 5.5863e-05, 9.3042e-06,\n",
      "         3.7479e-06, 1.1343e-06, 2.4136e-06, 8.4944e-07],\n",
      "        [1.2240e-02, 7.1105e-01, 1.8404e-01, 8.5353e-02, 6.4265e-03, 2.9789e-04,\n",
      "         5.6751e-05, 9.3659e-05, 3.4297e-04, 1.0320e-04],\n",
      "        [6.9092e-05, 2.5817e-03, 8.1930e-02, 6.3491e-01, 2.6343e-01, 1.5722e-02,\n",
      "         6.8501e-04, 2.4464e-04, 2.1249e-04, 2.1255e-04],\n",
      "        [1.6055e-05, 4.2557e-04, 1.0917e-02, 2.8536e-01, 4.6442e-01, 1.7676e-01,\n",
      "         5.4715e-02, 2.2328e-03, 1.8594e-03, 3.2895e-03],\n",
      "        [2.4296e-05, 2.8785e-04, 6.0189e-04, 1.1278e-02, 7.1564e-02, 5.8059e-01,\n",
      "         2.9844e-01, 3.2440e-02, 3.3214e-03, 1.4516e-03],\n",
      "        [1.0319e-03, 1.2842e-03, 4.8661e-04, 9.5603e-03, 2.6270e-02, 1.7644e-01,\n",
      "         5.4644e-01, 1.3260e-01, 9.1194e-02, 1.4698e-02],\n",
      "        [2.3589e-05, 1.5111e-03, 1.0505e-03, 4.1204e-03, 3.1550e-03, 1.4806e-03,\n",
      "         1.1368e-02, 7.2909e-02, 7.7449e-01, 1.2989e-01],\n",
      "        [3.7077e-05, 3.2713e-03, 4.1420e-03, 1.1039e-02, 6.1132e-03, 3.3384e-03,\n",
      "         3.4397e-03, 1.6104e-02, 6.6494e-01, 2.8758e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3.00, Train Loss: 3.61, Val Loss: 4.16, Train BLEU: 11.05, Val BLEU: 9.42, Minutes Elapsed: 155.34\n",
      "Sampling from training predictions...\n",
      "Source: đây là mahler . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: this is mahler . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> this is the . <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.5876, 0.4121, 0.0003, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0471, 0.9313, 0.0211, 0.0005, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0163, 0.4517, 0.5122, 0.0177, 0.0021, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0107, 0.0231, 0.8448, 0.1096, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0413, 0.0485, 0.2642, 0.2774, 0.3685, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1980, 0.1553, 0.1867, 0.1140, 0.3460, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0813, 0.5528, 0.1351, 0.0833, 0.1475, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0101, 0.0350, 0.4462, 0.1910, 0.3178, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1401, 0.0439, 0.1205, 0.2272, 0.4682, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: ông ấy la lên : \" bọn taliban đã đi\n",
      "Reference: &quot; the taliban are gone ! &quot; my father\n",
      "Model: <SOS> he said said said , &quot; &quot; &quot; the\n",
      "Attention Weights: tensor([[9.5596e-01, 3.8642e-02, 5.1302e-03, 2.6355e-04, 1.6134e-06, 5.5897e-08,\n",
      "         4.5118e-08, 1.0121e-08, 5.6940e-09, 3.2326e-09],\n",
      "        [9.8364e-02, 1.3022e-01, 7.1282e-01, 5.3716e-02, 1.7269e-03, 9.1884e-04,\n",
      "         1.6904e-03, 3.6399e-04, 1.2576e-04, 5.6544e-05],\n",
      "        [2.3630e-02, 6.6430e-02, 6.5755e-01, 2.3947e-01, 1.0188e-02, 1.2963e-03,\n",
      "         9.7393e-04, 2.1410e-04, 1.5617e-04, 9.4734e-05],\n",
      "        [5.6326e-02, 1.3449e-01, 3.1509e-01, 4.5009e-01, 3.3812e-02, 5.5780e-03,\n",
      "         3.0716e-03, 8.4564e-04, 4.7860e-04, 2.2646e-04],\n",
      "        [2.2681e-02, 3.8422e-02, 1.9599e-01, 5.8798e-01, 1.1763e-01, 2.1026e-02,\n",
      "         1.2331e-02, 1.6880e-03, 1.6686e-03, 5.8904e-04],\n",
      "        [7.7794e-05, 5.4877e-04, 2.4411e-02, 1.6485e-01, 3.4267e-01, 2.8499e-01,\n",
      "         1.4924e-01, 2.5367e-02, 4.9980e-03, 2.8472e-03],\n",
      "        [8.3625e-05, 3.8895e-04, 1.0585e-02, 1.6048e-01, 2.3549e-01, 3.0370e-01,\n",
      "         2.4967e-01, 3.1514e-02, 4.9052e-03, 3.1919e-03],\n",
      "        [2.4165e-05, 6.5988e-05, 1.0165e-03, 1.0410e-02, 4.2751e-02, 1.9795e-01,\n",
      "         6.0123e-01, 1.2152e-01, 1.6163e-02, 8.8680e-03],\n",
      "        [1.3341e-05, 2.1502e-05, 3.6254e-04, 1.8536e-03, 2.9626e-03, 3.8967e-02,\n",
      "         4.0979e-01, 3.0959e-01, 1.6012e-01, 7.6326e-02]])\n",
      "\n",
      "Epoch: 3.05, Train Loss: 3.01, Val Loss: 4.13, Train BLEU: 14.24, Val BLEU: 9.92, Minutes Elapsed: 157.83\n",
      "Sampling from training predictions...\n",
      "Source: micrô giúp cho đặc_biệt là ca_sĩ cũng_như nhạc_công và nhạc_sĩ\n",
      "Reference: microphones enabled singers , in particular , and musicians\n",
      "Model: <SOS> microphones are shown the the and and and and\n",
      "Attention Weights: tensor([[7.8616e-01, 2.1327e-01, 5.1535e-04, 5.6400e-05, 6.2159e-07, 7.7554e-07,\n",
      "         4.1809e-08, 6.2225e-09, 1.8838e-09, 6.1159e-10],\n",
      "        [1.1566e-02, 9.5031e-01, 2.6419e-02, 1.1525e-02, 5.2794e-05, 1.2183e-04,\n",
      "         5.5134e-06, 3.2608e-06, 1.5599e-07, 1.4413e-07],\n",
      "        [3.9072e-03, 1.5295e-01, 2.9576e-01, 4.8394e-01, 4.1990e-02, 1.7023e-02,\n",
      "         3.2262e-03, 1.0901e-03, 6.4637e-05, 3.7524e-05],\n",
      "        [6.2551e-05, 9.3270e-04, 7.0105e-03, 2.6999e-01, 2.2247e-01, 3.7571e-01,\n",
      "         9.2558e-02, 3.0189e-02, 6.5493e-04, 4.1952e-04],\n",
      "        [2.0403e-05, 5.2381e-04, 1.2874e-03, 5.1559e-02, 8.3382e-02, 4.7776e-01,\n",
      "         2.4344e-01, 1.3735e-01, 2.4205e-03, 2.2524e-03],\n",
      "        [2.1554e-06, 2.9250e-05, 5.5998e-05, 3.1751e-03, 4.1247e-02, 3.0624e-01,\n",
      "         2.7558e-01, 3.2734e-01, 1.8055e-02, 2.8270e-02],\n",
      "        [4.6806e-04, 2.8313e-03, 2.7329e-03, 1.4066e-02, 8.5234e-02, 3.0912e-01,\n",
      "         2.0575e-01, 2.5164e-01, 5.4928e-02, 7.3233e-02],\n",
      "        [2.3474e-05, 5.1158e-04, 1.3070e-03, 3.6840e-03, 4.0573e-02, 8.9204e-02,\n",
      "         2.5747e-01, 3.1358e-01, 9.0942e-02, 2.0271e-01],\n",
      "        [7.0432e-06, 1.6726e-04, 4.1954e-04, 1.5400e-03, 7.7128e-03, 3.8639e-02,\n",
      "         1.5613e-01, 2.4767e-01, 1.9613e-01, 3.5159e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: max little : vâng . vâng . điều sẽ xảy_ra\n",
      "Reference: yeah . yeah . so what will happen is\n",
      "Model: <SOS> amy : yeah yeah yeah . &apos;s it .\n",
      "Attention Weights: tensor([[6.4790e-01, 2.8609e-01, 5.6925e-02, 9.0584e-03, 1.8812e-05, 2.9904e-06,\n",
      "         9.0763e-08, 3.1829e-08, 3.2158e-09, 1.2693e-09],\n",
      "        [7.4377e-03, 5.0673e-01, 4.2291e-01, 6.2713e-02, 2.0341e-04, 1.0661e-05,\n",
      "         4.9146e-07, 5.7254e-08, 1.1535e-08, 3.8873e-09],\n",
      "        [8.7403e-04, 2.4282e-02, 1.3957e-01, 8.3138e-01, 2.7983e-03, 1.0487e-03,\n",
      "         2.8768e-05, 1.1561e-05, 1.7582e-06, 6.5025e-07],\n",
      "        [3.6441e-03, 2.7430e-02, 6.8882e-02, 7.9257e-01, 7.2222e-02, 3.2160e-02,\n",
      "         1.6831e-03, 9.5233e-04, 3.1257e-04, 1.4323e-04],\n",
      "        [3.5186e-03, 1.0069e-02, 1.4961e-02, 2.1472e-01, 3.1049e-01, 3.7110e-01,\n",
      "         2.5315e-02, 4.1978e-02, 5.1760e-03, 2.6733e-03],\n",
      "        [2.3926e-04, 8.6719e-04, 1.0622e-03, 3.2852e-02, 1.1696e-01, 5.1354e-01,\n",
      "         1.4447e-01, 1.6318e-01, 1.9605e-02, 7.2301e-03],\n",
      "        [7.0954e-04, 1.4656e-03, 1.3721e-03, 6.5375e-03, 1.2431e-02, 2.4411e-01,\n",
      "         2.2460e-01, 4.0745e-01, 6.9178e-02, 3.2143e-02],\n",
      "        [8.0842e-04, 1.9308e-03, 1.1992e-03, 5.8813e-03, 1.0484e-02, 1.1920e-01,\n",
      "         2.3025e-01, 3.3694e-01, 1.7416e-01, 1.1915e-01],\n",
      "        [1.6624e-04, 5.0021e-04, 2.6167e-04, 1.6204e-03, 3.4351e-03, 4.5012e-02,\n",
      "         1.4969e-01, 4.0888e-01, 1.8151e-01, 2.0892e-01]])\n",
      "\n",
      "Epoch: 3.10, Train Loss: 3.14, Val Loss: 4.12, Train BLEU: 13.32, Val BLEU: 10.58, Minutes Elapsed: 160.30\n",
      "Sampling from training predictions...\n",
      "Source: đó là leni riefenstahl trong ngôi chùa nazi tao_nhã tạo\n",
      "Reference: it was leni riefenstahl in her elegant nazi propaganda\n",
      "Model: <SOS> it &apos;s leni in the the new . .\n",
      "Attention Weights: tensor([[8.1636e-01, 1.8318e-01, 3.9208e-04, 6.7759e-05, 3.3365e-06, 5.0450e-07,\n",
      "         6.1529e-08, 8.4751e-09, 1.1436e-08, 9.6067e-09],\n",
      "        [5.8140e-02, 7.2442e-01, 1.4691e-01, 6.5018e-02, 4.0264e-03, 1.1386e-03,\n",
      "         2.7209e-04, 1.8069e-05, 3.6418e-05, 1.8742e-05],\n",
      "        [1.9932e-02, 1.0275e-01, 4.6328e-01, 3.6116e-01, 3.7052e-02, 1.1850e-02,\n",
      "         3.4191e-03, 1.3989e-04, 2.8334e-04, 1.2947e-04],\n",
      "        [1.1277e-02, 6.5315e-03, 8.4415e-02, 3.3783e-01, 4.3878e-01, 7.9614e-02,\n",
      "         3.4889e-02, 2.4139e-03, 2.9233e-03, 1.3238e-03],\n",
      "        [7.7109e-04, 7.0053e-04, 8.0086e-03, 5.1126e-02, 3.0794e-01, 3.4711e-01,\n",
      "         2.5272e-01, 1.7102e-02, 1.0033e-02, 4.4896e-03],\n",
      "        [3.0755e-05, 2.5815e-05, 2.7324e-04, 3.7333e-03, 9.6451e-02, 4.2928e-01,\n",
      "         3.7651e-01, 3.2293e-02, 3.9429e-02, 2.1979e-02],\n",
      "        [2.5643e-05, 8.9507e-06, 1.3825e-05, 8.2864e-05, 4.0342e-03, 8.9302e-02,\n",
      "         1.3093e-01, 1.3531e-01, 3.9793e-01, 2.4236e-01],\n",
      "        [1.8712e-03, 1.2171e-04, 1.4045e-04, 5.7878e-04, 1.4439e-03, 3.3864e-02,\n",
      "         7.0592e-02, 1.5585e-01, 2.4108e-01, 4.9445e-01],\n",
      "        [1.8916e-04, 3.5887e-05, 9.4260e-05, 2.5531e-04, 1.2613e-03, 1.2774e-02,\n",
      "         2.5025e-02, 1.2238e-01, 2.7791e-01, 5.6007e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: và trên chiếc đĩa cd , cái tôi cần đã\n",
      "Reference: and on the c.d. , this was on .\n",
      "Model: <SOS> and in the , , i i i to\n",
      "Attention Weights: tensor([[2.4043e-03, 9.9725e-01, 3.4718e-04, 2.4710e-06, 7.3234e-08, 1.5476e-09,\n",
      "         3.4311e-10, 1.6029e-11, 1.1240e-11, 8.6517e-12],\n",
      "        [1.2221e-02, 9.7035e-01, 1.7105e-02, 2.7967e-04, 4.1425e-05, 1.6347e-06,\n",
      "         7.8990e-07, 5.0463e-08, 4.8235e-08, 1.7471e-08],\n",
      "        [1.9130e-03, 2.2535e-01, 6.8834e-01, 5.2647e-02, 3.0535e-02, 6.8492e-04,\n",
      "         2.7216e-04, 5.7228e-05, 1.3163e-04, 6.6176e-05],\n",
      "        [4.9040e-03, 2.4015e-01, 4.8574e-01, 1.0957e-01, 1.5003e-01, 5.7119e-03,\n",
      "         1.7258e-03, 2.3500e-04, 1.1853e-03, 7.4357e-04],\n",
      "        [3.5708e-03, 8.4000e-02, 6.3841e-02, 2.2158e-01, 2.5318e-01, 3.0347e-01,\n",
      "         5.7072e-02, 2.2080e-03, 6.0172e-03, 5.0667e-03],\n",
      "        [1.5393e-04, 5.2313e-03, 1.5146e-02, 5.0940e-02, 1.9867e-01, 4.4521e-01,\n",
      "         2.6780e-01, 5.9132e-03, 6.0585e-03, 4.8832e-03],\n",
      "        [2.0690e-05, 1.6422e-03, 4.6182e-03, 1.7247e-03, 2.7041e-02, 2.9157e-02,\n",
      "         8.3296e-01, 4.1772e-02, 5.0379e-02, 1.0685e-02],\n",
      "        [7.4765e-06, 1.0536e-03, 1.7373e-03, 4.7586e-04, 9.8861e-04, 5.1251e-04,\n",
      "         5.5063e-03, 2.6799e-02, 7.2105e-01, 2.4187e-01],\n",
      "        [2.2714e-06, 2.8093e-04, 1.3394e-03, 3.0413e-04, 2.6060e-03, 1.9041e-03,\n",
      "         1.2646e-02, 3.5350e-02, 7.2655e-01, 2.1901e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3.14, Train Loss: 3.17, Val Loss: 4.14, Train BLEU: 12.40, Val BLEU: 10.24, Minutes Elapsed: 162.78\n",
      "Sampling from training predictions...\n",
      "Source: chúng_tôi là tấm_gương của bé . <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: we were his mirror . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> we &apos;re the of . <EOS> <EOS> our <EOS>\n",
      "Attention Weights: tensor([[0.6491, 0.3504, 0.0005, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0993, 0.8799, 0.0206, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0363, 0.5129, 0.4371, 0.0113, 0.0018, 0.0006, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0007, 0.0065, 0.9390, 0.0474, 0.0028, 0.0026, 0.0009, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0017, 0.0385, 0.1441, 0.1712, 0.0589, 0.3421, 0.2435, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0004, 0.0045, 0.0233, 0.0220, 0.0533, 0.4133, 0.4832, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0623, 0.0563, 0.2624, 0.1014, 0.0615, 0.1375, 0.3185, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0206, 0.4136, 0.3163, 0.0577, 0.0300, 0.0794, 0.0825, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0032, 0.0680, 0.5727, 0.0913, 0.0326, 0.0881, 0.1443, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: có_một vần đề trong những cuộc_họp cộng_đồng . <EOS> <PAD>\n",
      "Reference: there is a problem with community meetings . <EOS>\n",
      "Model: <SOS> there &apos;s a billion of the the . <EOS>\n",
      "Attention Weights: tensor([[0.9910, 0.0086, 0.0003, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.7474, 0.2251, 0.0245, 0.0021, 0.0004, 0.0003, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4975, 0.3120, 0.1600, 0.0234, 0.0031, 0.0022, 0.0016, 0.0002, 0.0001,\n",
      "         0.0000],\n",
      "        [0.0224, 0.3370, 0.5329, 0.0829, 0.0139, 0.0082, 0.0024, 0.0002, 0.0001,\n",
      "         0.0000],\n",
      "        [0.0238, 0.0977, 0.4570, 0.3706, 0.0284, 0.0188, 0.0029, 0.0004, 0.0002,\n",
      "         0.0000],\n",
      "        [0.0033, 0.0138, 0.1949, 0.5233, 0.1437, 0.0936, 0.0227, 0.0031, 0.0015,\n",
      "         0.0000],\n",
      "        [0.0012, 0.0008, 0.0032, 0.0579, 0.2899, 0.4672, 0.1712, 0.0064, 0.0022,\n",
      "         0.0000],\n",
      "        [0.0010, 0.0013, 0.0046, 0.0413, 0.1829, 0.4336, 0.1589, 0.1001, 0.0763,\n",
      "         0.0000],\n",
      "        [0.0013, 0.0018, 0.0041, 0.0076, 0.1636, 0.2937, 0.2282, 0.1322, 0.1674,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 3.19, Train Loss: 3.20, Val Loss: 4.12, Train BLEU: 12.37, Val BLEU: 9.71, Minutes Elapsed: 165.26\n",
      "Sampling from training predictions...\n",
      "Source: chộp lấy ngón_tay cái đó ! <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: grab that thumb ! <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> so &apos;s that ! <EOS> <EOS> ! <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9543, 0.0440, 0.0017, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0299, 0.7612, 0.2016, 0.0067, 0.0004, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0303, 0.2423, 0.6431, 0.0731, 0.0087, 0.0022, 0.0003, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0042, 0.0235, 0.3031, 0.4536, 0.1374, 0.0703, 0.0080, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0027, 0.0078, 0.1134, 0.3006, 0.1647, 0.3457, 0.0651, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0068, 0.0092, 0.0468, 0.1647, 0.0867, 0.5038, 0.1821, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0193, 0.0188, 0.0455, 0.1123, 0.0687, 0.3372, 0.3981, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0236, 0.0374, 0.0580, 0.1245, 0.0584, 0.3615, 0.3366, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0278, 0.0334, 0.0873, 0.1473, 0.0566, 0.3754, 0.2722, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi tham_gia vào các lực_lượng trong và ngoài libya để\n",
      "Reference: i joined forces with many other <UNK> inside and\n",
      "Model: <SOS> i went in the the and and and and\n",
      "Attention Weights: tensor([[3.4844e-01, 6.4894e-01, 2.5733e-03, 3.1451e-05, 1.4306e-05, 2.3416e-06,\n",
      "         6.0621e-08, 1.1214e-07, 1.7134e-08, 2.2748e-08],\n",
      "        [5.0888e-03, 9.8947e-01, 5.0082e-03, 1.7950e-04, 2.1922e-04, 1.9867e-05,\n",
      "         2.9985e-06, 7.6874e-06, 2.9009e-06, 7.8292e-07],\n",
      "        [2.9423e-03, 5.4210e-01, 3.8035e-01, 5.3994e-02, 1.9282e-02, 1.0763e-03,\n",
      "         3.4600e-05, 1.5004e-04, 5.1830e-05, 1.9864e-05],\n",
      "        [1.0673e-04, 7.5508e-03, 1.7092e-01, 2.6656e-01, 5.1378e-01, 3.7337e-02,\n",
      "         1.2865e-03, 1.9302e-03, 4.0415e-04, 1.2639e-04],\n",
      "        [1.5422e-04, 1.6009e-03, 2.5986e-02, 1.8210e-01, 5.8628e-01, 1.7063e-01,\n",
      "         2.0553e-02, 1.0428e-02, 1.5921e-03, 6.7715e-04],\n",
      "        [2.2132e-05, 1.6625e-04, 5.0330e-03, 4.3079e-02, 1.3142e-01, 1.9966e-01,\n",
      "         2.9039e-01, 2.5009e-01, 6.2649e-02, 1.7487e-02],\n",
      "        [3.2726e-05, 1.3449e-04, 1.7959e-03, 6.1449e-03, 2.9187e-02, 1.3503e-01,\n",
      "         4.6387e-01, 2.3028e-01, 8.4756e-02, 4.8764e-02],\n",
      "        [9.3631e-05, 3.5493e-04, 1.6887e-03, 4.8184e-03, 2.4114e-02, 6.0737e-02,\n",
      "         2.5948e-01, 4.0114e-01, 1.4537e-01, 1.0220e-01],\n",
      "        [8.6026e-05, 4.7897e-04, 1.5890e-03, 3.5337e-03, 1.2026e-02, 3.7151e-02,\n",
      "         1.7853e-01, 3.6841e-01, 1.6399e-01, 2.3420e-01]])\n",
      "\n",
      "Epoch: 3.24, Train Loss: 3.22, Val Loss: 4.12, Train BLEU: 12.03, Val BLEU: 10.02, Minutes Elapsed: 167.74\n",
      "Sampling from training predictions...\n",
      "Source: chính vì lượng khí thải rất lớn , nó có\n",
      "Reference: and because it &apos;s so much stuff , it\n",
      "Model: <SOS> it &apos;s &apos;s &apos;s a very , , it\n",
      "Attention Weights: tensor([[9.9971e-01, 2.8619e-04, 6.2498e-06, 1.0915e-07, 1.6650e-08, 5.5574e-09,\n",
      "         7.8038e-10, 2.9568e-11, 3.6299e-11, 5.0546e-11],\n",
      "        [4.3837e-01, 4.2150e-01, 1.2111e-01, 1.6015e-02, 1.7592e-03, 9.2259e-04,\n",
      "         2.4168e-04, 3.2278e-05, 1.9992e-05, 3.1622e-05],\n",
      "        [1.9277e-01, 2.8704e-01, 3.0873e-01, 1.1665e-01, 4.8168e-02, 3.8425e-02,\n",
      "         6.4411e-03, 4.9291e-04, 3.6498e-04, 9.1546e-04],\n",
      "        [9.9930e-02, 2.2406e-01, 3.3339e-01, 1.8080e-01, 7.3391e-02, 6.7308e-02,\n",
      "         1.7046e-02, 8.9819e-04, 6.8529e-04, 2.4960e-03],\n",
      "        [9.3338e-02, 2.1381e-01, 2.8868e-01, 1.5812e-01, 1.0353e-01, 1.0469e-01,\n",
      "         3.0523e-02, 1.6373e-03, 8.2273e-04, 4.8555e-03],\n",
      "        [3.9283e-03, 5.4921e-02, 4.2975e-01, 2.2580e-01, 1.4057e-01, 1.0015e-01,\n",
      "         4.0820e-02, 2.7099e-03, 5.6601e-04, 7.7913e-04],\n",
      "        [4.3678e-04, 4.2734e-03, 1.2727e-01, 4.1007e-01, 1.9973e-01, 1.4069e-01,\n",
      "         1.0302e-01, 1.1758e-02, 1.2747e-03, 1.4745e-03],\n",
      "        [2.7792e-04, 2.8529e-03, 1.9364e-02, 1.0524e-01, 2.4386e-01, 2.0714e-01,\n",
      "         2.5479e-01, 1.3413e-01, 2.1098e-02, 1.1254e-02],\n",
      "        [2.5275e-04, 1.1741e-03, 3.4284e-03, 1.3601e-02, 9.1077e-02, 1.3341e-01,\n",
      "         1.7366e-01, 3.0439e-01, 2.0353e-01, 7.5476e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: và tôi lắp_đặt mọi thứ . <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: so i set up everything . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> and i love everything things . <EOS> was .\n",
      "Attention Weights: tensor([[0.0009, 0.0462, 0.8940, 0.0584, 0.0006, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0033, 0.7081, 0.2882, 0.0004, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0383, 0.9305, 0.0299, 0.0011, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0051, 0.4242, 0.4596, 0.1081, 0.0027, 0.0003, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0013, 0.0472, 0.5341, 0.3854, 0.0272, 0.0047, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0059, 0.0395, 0.1578, 0.1831, 0.2248, 0.3887, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0057, 0.0829, 0.2249, 0.3169, 0.0936, 0.2760, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0584, 0.1992, 0.1577, 0.1893, 0.1080, 0.2869, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0280, 0.3752, 0.3669, 0.0803, 0.0471, 0.1023, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 3.29, Train Loss: 3.25, Val Loss: 4.13, Train BLEU: 12.23, Val BLEU: 9.72, Minutes Elapsed: 170.23\n",
      "Sampling from training predictions...\n",
      "Source: tôi sẽ bị phạt bao_nhiêu tiền nếu bị phát_hiện ?\n",
      "Reference: and how much punishment would i get if i\n",
      "Model: <SOS> i i will i i i be to to\n",
      "Attention Weights: tensor([[7.2148e-02, 8.8710e-01, 4.0299e-02, 4.3262e-04, 1.6999e-05, 2.5231e-06,\n",
      "         3.0736e-08, 7.1874e-08, 2.9829e-08, 1.2029e-08],\n",
      "        [2.4209e-02, 9.3399e-01, 4.0352e-02, 1.3215e-03, 1.1421e-04, 9.7332e-06,\n",
      "         1.0991e-06, 1.6588e-06, 1.7253e-06, 1.7771e-07],\n",
      "        [9.8060e-03, 4.6501e-01, 4.3252e-01, 8.2990e-02, 8.8918e-03, 5.8488e-04,\n",
      "         2.8089e-05, 7.6875e-05, 8.5517e-05, 7.5311e-06],\n",
      "        [5.5346e-03, 2.9184e-01, 5.3565e-01, 1.3640e-01, 2.8634e-02, 1.6530e-03,\n",
      "         4.0901e-05, 1.1814e-04, 1.1974e-04, 9.2998e-06],\n",
      "        [3.9294e-03, 3.9448e-01, 4.5191e-01, 1.1687e-01, 2.9105e-02, 3.3654e-03,\n",
      "         7.6212e-05, 1.1804e-04, 1.3628e-04, 7.7919e-06],\n",
      "        [3.2232e-03, 4.4327e-01, 4.0934e-01, 1.0520e-01, 3.2194e-02, 6.0026e-03,\n",
      "         1.5430e-04, 3.2973e-04, 2.7650e-04, 1.2353e-05],\n",
      "        [1.0107e-03, 3.5597e-01, 2.0555e-01, 1.7952e-01, 1.8639e-01, 6.4990e-02,\n",
      "         1.8881e-03, 2.6691e-03, 1.8858e-03, 1.1948e-04],\n",
      "        [1.6803e-05, 1.7185e-03, 4.3093e-02, 2.3449e-01, 3.8905e-01, 2.9950e-01,\n",
      "         1.2857e-02, 9.1724e-03, 9.7153e-03, 3.8504e-04],\n",
      "        [1.4362e-05, 8.1863e-04, 1.5011e-02, 1.1237e-01, 3.6657e-01, 4.1425e-01,\n",
      "         3.8068e-02, 2.5862e-02, 2.6047e-02, 9.8222e-04]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: vậy là cháu đã có học_bổng này . vâng .\n",
      "Reference: so you got this scholarship . yep . <EOS>\n",
      "Model: <SOS> so there &apos;s this . . yes . <EOS>\n",
      "Attention Weights: tensor([[7.9032e-01, 2.0749e-01, 2.1710e-03, 9.8290e-06, 1.3231e-06, 6.5797e-08,\n",
      "         7.9524e-10, 1.8892e-10, 1.0524e-10, 8.5317e-12],\n",
      "        [1.5792e-02, 3.6035e-01, 5.9331e-01, 2.6110e-02, 3.5340e-03, 8.8376e-04,\n",
      "         4.3016e-06, 5.3035e-06, 5.2859e-06, 9.6450e-07],\n",
      "        [2.2574e-02, 2.0630e-01, 5.0625e-01, 1.0263e-01, 8.3013e-02, 7.8394e-02,\n",
      "         3.8630e-04, 1.4270e-04, 2.6719e-04, 3.6481e-05],\n",
      "        [5.1132e-03, 1.1061e-01, 2.5936e-01, 7.8125e-02, 5.2572e-02, 4.8668e-01,\n",
      "         5.0962e-03, 9.3355e-04, 1.2899e-03, 2.2369e-04],\n",
      "        [9.0585e-06, 4.0628e-05, 1.0569e-03, 6.3746e-03, 1.7450e-02, 9.5817e-01,\n",
      "         6.9403e-03, 6.0704e-03, 3.5270e-03, 3.6560e-04],\n",
      "        [1.8055e-05, 9.8301e-05, 8.7187e-04, 6.5292e-03, 1.6634e-02, 6.7130e-01,\n",
      "         2.2875e-02, 1.0205e-01, 1.7263e-01, 6.9906e-03],\n",
      "        [1.1646e-04, 4.3770e-04, 5.2863e-03, 7.0852e-03, 1.6032e-02, 2.1750e-02,\n",
      "         3.6440e-03, 7.3557e-02, 8.5290e-01, 1.9191e-02],\n",
      "        [1.0472e-04, 4.6119e-04, 3.0376e-03, 4.4881e-03, 2.6828e-02, 4.8298e-02,\n",
      "         4.2380e-03, 6.2050e-02, 8.0736e-01, 4.3129e-02],\n",
      "        [9.0893e-04, 5.6711e-03, 6.0310e-03, 1.3535e-02, 6.5480e-02, 8.6493e-02,\n",
      "         9.5420e-03, 5.4892e-02, 4.1471e-01, 3.4274e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3.34, Train Loss: 3.33, Val Loss: 4.16, Train BLEU: 11.27, Val BLEU: 9.74, Minutes Elapsed: 172.69\n",
      "Sampling from training predictions...\n",
      "Source: thành_viên của chúng_tôi thách_thức sự mô_tả nhị_phân về cách mà\n",
      "Reference: our members defy the binary description of how we\n",
      "Model: <SOS> our our is the new of of how of\n",
      "Attention Weights: tensor([[9.9970e-01, 2.8935e-04, 8.0672e-06, 7.4457e-07, 9.4453e-09, 1.9403e-09,\n",
      "         1.5943e-09, 1.5987e-10, 9.3961e-11, 3.1323e-11],\n",
      "        [9.9377e-01, 2.1391e-03, 1.3997e-03, 2.5939e-03, 5.6220e-05, 2.1401e-05,\n",
      "         1.2958e-05, 1.9585e-06, 1.2247e-06, 4.2867e-07],\n",
      "        [1.3747e-01, 5.1270e-02, 7.5132e-02, 6.3730e-01, 7.6839e-02, 1.3813e-02,\n",
      "         6.7762e-03, 9.4426e-04, 3.0939e-04, 1.4988e-04],\n",
      "        [3.8470e-03, 3.4209e-03, 2.9664e-02, 5.8591e-01, 2.2802e-01, 9.0567e-02,\n",
      "         4.0099e-02, 1.1793e-02, 4.3043e-03, 2.3760e-03],\n",
      "        [1.9504e-03, 1.4596e-04, 7.1201e-04, 3.8634e-02, 1.3690e-01, 3.5268e-01,\n",
      "         3.7945e-01, 6.3507e-02, 2.0292e-02, 5.7362e-03],\n",
      "        [7.3291e-05, 1.2055e-05, 1.0877e-04, 2.1701e-03, 1.1296e-02, 1.9655e-01,\n",
      "         3.6393e-01, 2.9675e-01, 9.7399e-02, 3.1700e-02],\n",
      "        [2.6796e-05, 4.2979e-05, 1.0166e-04, 1.3321e-03, 2.0903e-03, 2.9273e-02,\n",
      "         1.5166e-01, 3.6067e-01, 2.8854e-01, 1.6626e-01],\n",
      "        [1.2091e-04, 4.7773e-05, 8.5416e-05, 7.6517e-04, 1.3539e-03, 1.8101e-02,\n",
      "         6.0908e-02, 2.8733e-01, 4.2218e-01, 2.0910e-01],\n",
      "        [1.0257e-03, 4.4728e-04, 5.6440e-04, 4.9746e-03, 3.8701e-03, 1.8548e-02,\n",
      "         5.5700e-02, 1.5095e-01, 3.6458e-01, 3.9934e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: anh ta ngồi cạnh tôi trong đường_hầm thành_phố new york\n",
      "Reference: he sat next to me on the new york\n",
      "Model: <SOS> he he me in in the the new york\n",
      "Attention Weights: tensor([[6.2738e-01, 1.6531e-02, 3.5357e-01, 2.4971e-03, 1.6475e-05, 1.8312e-07,\n",
      "         2.6711e-08, 2.1189e-09, 3.2716e-10, 4.7650e-10],\n",
      "        [1.7034e-02, 4.5765e-03, 8.8532e-01, 9.2683e-02, 2.9758e-04, 6.7201e-05,\n",
      "         1.4204e-05, 4.4124e-06, 7.4150e-07, 4.4235e-07],\n",
      "        [3.4395e-03, 4.2363e-03, 3.3098e-01, 6.2140e-01, 3.3260e-02, 5.7468e-03,\n",
      "         5.7908e-04, 2.9546e-04, 3.6319e-05, 2.5943e-05],\n",
      "        [2.2266e-03, 1.6249e-03, 1.3203e-01, 5.5954e-01, 2.0456e-01, 7.7697e-02,\n",
      "         1.6659e-02, 4.2342e-03, 1.0312e-03, 3.9359e-04],\n",
      "        [5.4785e-04, 9.0029e-04, 5.9811e-02, 1.5143e-01, 2.1180e-01, 3.4949e-01,\n",
      "         1.4792e-01, 5.2546e-02, 1.6916e-02, 8.6348e-03],\n",
      "        [1.5768e-05, 8.0392e-05, 1.5880e-03, 3.3092e-03, 1.2611e-02, 1.9794e-01,\n",
      "         4.9356e-01, 2.0145e-01, 6.1720e-02, 2.7719e-02],\n",
      "        [6.5314e-06, 1.6793e-05, 7.7513e-05, 1.3868e-03, 1.5766e-03, 7.3697e-02,\n",
      "         4.6526e-01, 3.2301e-01, 1.0570e-01, 2.9268e-02],\n",
      "        [4.0534e-06, 1.3339e-05, 1.0855e-04, 1.0808e-03, 2.1436e-03, 1.1269e-01,\n",
      "         4.4469e-01, 3.2183e-01, 8.6039e-02, 3.1397e-02],\n",
      "        [1.2769e-04, 2.8690e-04, 5.4791e-04, 1.8398e-03, 1.2316e-03, 1.3815e-02,\n",
      "         1.2775e-01, 3.6818e-01, 3.0524e-01, 1.8098e-01]])\n",
      "\n",
      "Epoch: 3.38, Train Loss: 3.27, Val Loss: 4.12, Train BLEU: 12.11, Val BLEU: 10.14, Minutes Elapsed: 175.17\n",
      "Sampling from training predictions...\n",
      "Source: và tôi quay_lại để đo cái mà chúng_tôi gọi_là nửa\n",
      "Reference: and i came back to measure what we technically\n",
      "Model: <SOS> and i i back to the that we call\n",
      "Attention Weights: tensor([[9.0811e-04, 8.0621e-01, 1.8841e-01, 4.2307e-03, 2.3477e-04, 7.9679e-06,\n",
      "         1.8626e-07, 2.9337e-08, 9.9872e-08, 6.2532e-08],\n",
      "        [2.0533e-03, 5.7358e-01, 4.2350e-01, 7.9478e-04, 5.7297e-05, 8.5217e-06,\n",
      "         1.4689e-06, 1.5385e-07, 1.1375e-07, 5.4595e-08],\n",
      "        [3.1835e-05, 1.2359e-01, 8.6664e-01, 8.4475e-03, 1.1225e-03, 1.0887e-04,\n",
      "         2.4764e-05, 8.7291e-06, 1.9575e-05, 5.8047e-06],\n",
      "        [3.8300e-05, 3.9385e-02, 7.4705e-01, 1.7425e-01, 3.0428e-02, 6.5037e-03,\n",
      "         1.2852e-03, 3.0382e-04, 5.8341e-04, 1.7900e-04],\n",
      "        [1.5011e-05, 3.0199e-03, 2.8010e-02, 1.6468e-01, 4.7617e-01, 2.7585e-01,\n",
      "         3.9698e-02, 4.9963e-03, 4.5698e-03, 2.9867e-03],\n",
      "        [2.4986e-05, 6.1075e-03, 6.4267e-02, 1.2548e-01, 4.9249e-01, 2.1895e-01,\n",
      "         6.0868e-02, 1.3633e-02, 1.1072e-02, 7.1079e-03],\n",
      "        [6.4787e-07, 3.8955e-04, 5.5149e-03, 3.0784e-02, 4.0738e-01, 2.7254e-01,\n",
      "         2.0423e-01, 4.0873e-02, 2.5620e-02, 1.2669e-02],\n",
      "        [7.0454e-08, 3.6770e-05, 6.7512e-04, 7.4071e-03, 1.3662e-01, 1.4886e-01,\n",
      "         3.7329e-01, 1.3641e-01, 1.5348e-01, 4.3222e-02],\n",
      "        [1.7125e-07, 5.1692e-05, 1.0049e-03, 3.2780e-03, 2.2306e-02, 1.9236e-02,\n",
      "         8.1434e-02, 2.4292e-01, 5.2923e-01, 1.0054e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: gần đây , trong một chuyến đi , chúng_tôi đang\n",
      "Reference: recently , on one trip , we were walking\n",
      "Model: <SOS> so , , a , we we &apos;re been\n",
      "Attention Weights: tensor([[9.9492e-01, 5.0695e-03, 1.1647e-05, 1.3670e-07, 2.2182e-08, 1.5150e-09,\n",
      "         7.2236e-10, 6.3740e-12, 1.2309e-12, 5.6710e-12],\n",
      "        [6.8981e-01, 1.9497e-01, 9.6435e-02, 1.6500e-02, 1.5699e-03, 6.0455e-04,\n",
      "         7.4939e-05, 1.7881e-05, 3.2307e-06, 7.3534e-06],\n",
      "        [1.9308e-01, 9.7116e-02, 4.5319e-01, 2.1416e-01, 1.9524e-02, 1.8296e-02,\n",
      "         3.3972e-03, 6.9412e-04, 1.8202e-04, 3.6087e-04],\n",
      "        [1.6566e-03, 8.8502e-04, 2.3178e-02, 4.5949e-01, 3.1281e-01, 1.8293e-01,\n",
      "         1.2717e-02, 3.5362e-03, 6.0970e-04, 2.1827e-03],\n",
      "        [1.3625e-03, 2.3554e-04, 3.1195e-03, 1.5127e-02, 2.9612e-02, 8.4349e-01,\n",
      "         5.3185e-02, 2.5650e-02, 3.1818e-03, 2.5041e-02],\n",
      "        [1.3012e-03, 1.7093e-03, 8.0003e-03, 2.5758e-02, 3.4286e-02, 1.2055e-01,\n",
      "         1.4296e-01, 6.1348e-01, 2.8877e-02, 2.3077e-02],\n",
      "        [4.4135e-05, 3.6229e-05, 3.5880e-04, 1.6967e-03, 1.0158e-03, 3.9333e-03,\n",
      "         2.9289e-03, 9.3486e-02, 2.2724e-01, 6.6926e-01],\n",
      "        [3.7269e-05, 1.1392e-05, 4.5673e-05, 9.6778e-04, 9.6494e-04, 2.7871e-03,\n",
      "         1.2391e-03, 1.0728e-02, 1.4937e-02, 9.6828e-01],\n",
      "        [1.0700e-03, 1.6119e-04, 1.1485e-03, 1.2704e-02, 1.3275e-02, 2.9863e-02,\n",
      "         4.4942e-03, 6.6137e-03, 6.0239e-03, 9.2465e-01]])\n",
      "\n",
      "Epoch: 3.43, Train Loss: 3.30, Val Loss: 4.09, Train BLEU: 11.87, Val BLEU: 10.22, Minutes Elapsed: 177.63\n",
      "Sampling from training predictions...\n",
      "Source: tôi đã muốn tự_sát và nếu bạn nhìn cuộc_sống của\n",
      "Reference: i was suicidal , and if you were to\n",
      "Model: <SOS> i wanted to to and you you look to\n",
      "Attention Weights: tensor([[1.3965e-02, 7.2743e-01, 2.4678e-01, 1.1768e-02, 5.2481e-05, 1.4553e-06,\n",
      "         9.3318e-07, 2.9947e-06, 1.1785e-06, 1.3427e-07],\n",
      "        [2.8077e-03, 2.1731e-01, 7.7582e-01, 3.8225e-03, 1.1078e-04, 1.1333e-05,\n",
      "         1.5593e-05, 7.3706e-05, 2.0743e-05, 1.5472e-06],\n",
      "        [2.7035e-03, 1.0697e-01, 7.8177e-01, 1.0624e-01, 1.4147e-03, 1.4776e-04,\n",
      "         1.2181e-04, 4.4686e-04, 1.7765e-04, 1.6775e-05],\n",
      "        [3.4878e-04, 2.8841e-04, 1.1936e-01, 8.2259e-01, 3.8778e-02, 1.1390e-02,\n",
      "         5.6486e-04, 4.3165e-03, 2.1973e-03, 1.5943e-04],\n",
      "        [2.5065e-03, 6.6005e-04, 4.2016e-02, 6.0053e-01, 2.0732e-01, 1.0929e-01,\n",
      "         6.7444e-03, 2.1172e-02, 8.7835e-03, 9.6942e-04],\n",
      "        [3.4266e-04, 2.4365e-04, 5.3510e-03, 1.1314e-02, 9.3394e-02, 4.8086e-01,\n",
      "         1.4449e-01, 2.1303e-01, 4.2402e-02, 8.5728e-03],\n",
      "        [3.5144e-04, 5.1055e-03, 6.0502e-02, 1.3277e-02, 4.2798e-03, 9.0324e-03,\n",
      "         1.0978e-01, 6.7207e-01, 1.2053e-01, 5.0721e-03],\n",
      "        [1.9286e-04, 4.2305e-03, 3.1469e-01, 2.9504e-02, 3.6284e-03, 8.4046e-03,\n",
      "         3.8318e-02, 3.8780e-01, 2.0852e-01, 4.7053e-03],\n",
      "        [2.5202e-04, 2.0424e-03, 5.9166e-01, 4.9586e-02, 4.4867e-03, 1.0385e-02,\n",
      "         2.3746e-02, 1.6694e-01, 1.4713e-01, 3.7692e-03]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: nó xảy_ra mọi nơi . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: it &apos;s everywhere . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s everything . <EOS> &apos;s . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.7808, 0.2157, 0.0034, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0590, 0.9064, 0.0331, 0.0013, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0111, 0.4490, 0.4802, 0.0593, 0.0003, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0004, 0.0433, 0.5600, 0.3878, 0.0075, 0.0011, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0004, 0.0553, 0.4244, 0.4419, 0.0538, 0.0242, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0017, 0.0578, 0.2199, 0.2689, 0.2367, 0.2151, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0102, 0.3792, 0.3819, 0.1289, 0.0511, 0.0488, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0008, 0.0908, 0.5204, 0.1996, 0.0926, 0.0958, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0048, 0.0329, 0.0708, 0.1217, 0.1462, 0.6237, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3.48, Train Loss: 3.26, Val Loss: 4.07, Train BLEU: 11.87, Val BLEU: 10.25, Minutes Elapsed: 180.08\n",
      "Sampling from training predictions...\n",
      "Source: nhưng nếu ai đó từ 1 nhóm khác , những\n",
      "Reference: but if it &apos;s somebody from another group ,\n",
      "Model: <SOS> but if someone someone another another another , ,\n",
      "Attention Weights: tensor([[4.5360e-03, 2.6096e-02, 9.4295e-01, 2.6398e-02, 1.6352e-05, 4.5208e-07,\n",
      "         1.3654e-07, 6.9656e-08, 3.0586e-10, 3.5607e-10],\n",
      "        [4.6469e-03, 4.7917e-01, 5.1545e-01, 7.3155e-04, 1.8477e-06, 2.8528e-07,\n",
      "         7.5836e-08, 6.2566e-08, 2.6988e-09, 3.9150e-09],\n",
      "        [1.3070e-04, 1.5975e-02, 9.5939e-01, 2.3762e-02, 6.4692e-04, 5.9992e-05,\n",
      "         2.3649e-05, 1.1685e-05, 1.3692e-06, 2.3865e-06],\n",
      "        [5.2030e-04, 7.3308e-04, 4.1010e-01, 4.3755e-01, 1.1561e-01, 1.7827e-02,\n",
      "         1.3808e-02, 2.7063e-03, 3.3937e-04, 8.0887e-04],\n",
      "        [1.4866e-04, 8.9867e-05, 5.7119e-02, 2.1178e-01, 2.6268e-01, 2.6055e-01,\n",
      "         1.7513e-01, 3.0529e-02, 9.9777e-04, 9.6574e-04],\n",
      "        [1.9015e-05, 3.5074e-06, 1.4985e-03, 4.1067e-03, 2.1164e-02, 1.5488e-01,\n",
      "         6.2041e-01, 1.8188e-01, 9.9960e-03, 6.0390e-03],\n",
      "        [1.0780e-04, 2.2546e-05, 4.6721e-03, 2.6639e-03, 1.2212e-02, 1.2085e-01,\n",
      "         6.3776e-01, 1.4768e-01, 6.0093e-02, 1.3942e-02],\n",
      "        [6.1875e-06, 3.2807e-07, 6.7465e-05, 1.5792e-04, 2.5654e-03, 1.0331e-01,\n",
      "         7.1809e-01, 1.2658e-01, 3.3253e-02, 1.5974e-02],\n",
      "        [6.4136e-05, 1.9676e-05, 2.0960e-04, 4.2516e-04, 1.5101e-03, 4.7824e-02,\n",
      "         3.9983e-01, 8.7258e-02, 2.8893e-01, 1.7393e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi đang đập_tan sự im_lặng hôm_nay . <EOS> <PAD> <PAD>\n",
      "Reference: i &apos;m still breaking the silence today . <EOS>\n",
      "Model: <SOS> i &apos;m working today . . . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0042, 0.9899, 0.0054, 0.0004, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0083, 0.9078, 0.0832, 0.0006, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0147, 0.6472, 0.2921, 0.0368, 0.0089, 0.0002, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0008, 0.0065, 0.0769, 0.2446, 0.6468, 0.0222, 0.0016, 0.0006, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0012, 0.0024, 0.0127, 0.1306, 0.7500, 0.0847, 0.0113, 0.0071, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0052, 0.0095, 0.0117, 0.0875, 0.6154, 0.1897, 0.0543, 0.0267, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0115, 0.0468, 0.0063, 0.0466, 0.4278, 0.2529, 0.1045, 0.1037, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0072, 0.0160, 0.0037, 0.0263, 0.3842, 0.3265, 0.1398, 0.0962, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0085, 0.0066, 0.0015, 0.0120, 0.1879, 0.4774, 0.1211, 0.1849, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 3.53, Train Loss: 3.28, Val Loss: 4.09, Train BLEU: 12.90, Val BLEU: 10.42, Minutes Elapsed: 182.57\n",
      "Sampling from training predictions...\n",
      "Source: nó tồn_tại . nó ở đó , và bạn biết\n",
      "Reference: well , it is there . it is there\n",
      "Model: <SOS> it &apos;s &apos;s &apos;s . . it &apos;s ,\n",
      "Attention Weights: tensor([[6.6933e-01, 3.2960e-01, 1.0331e-03, 3.4076e-05, 2.0401e-06, 5.7792e-07,\n",
      "         8.8985e-09, 3.3503e-09, 4.6891e-09, 1.7671e-09],\n",
      "        [3.3751e-02, 9.4473e-01, 2.0412e-02, 8.1385e-04, 2.3993e-04, 3.7727e-05,\n",
      "         1.1019e-05, 1.9474e-06, 3.0852e-06, 3.4086e-06],\n",
      "        [5.3989e-02, 7.6524e-01, 1.7011e-01, 7.6001e-03, 2.4350e-03, 4.9871e-04,\n",
      "         8.0383e-05, 6.7119e-06, 8.7060e-06, 2.9186e-05],\n",
      "        [9.0697e-02, 4.7794e-01, 3.4593e-01, 7.7203e-02, 6.1626e-03, 1.1354e-03,\n",
      "         6.7704e-04, 1.3558e-04, 5.0149e-05, 6.9519e-05],\n",
      "        [4.5401e-02, 6.2965e-01, 1.5279e-01, 1.0603e-01, 5.1995e-02, 1.1090e-02,\n",
      "         1.7706e-03, 2.3484e-04, 3.0788e-04, 7.3368e-04],\n",
      "        [7.1309e-04, 2.9145e-02, 3.7781e-01, 4.1701e-01, 1.0574e-01, 3.1684e-02,\n",
      "         3.3844e-02, 3.4541e-03, 1.6306e-04, 4.2425e-04],\n",
      "        [4.1731e-04, 1.2623e-03, 1.6554e-02, 3.5417e-01, 2.3820e-01, 1.1152e-01,\n",
      "         1.8605e-01, 8.6883e-02, 3.3421e-03, 1.6044e-03],\n",
      "        [1.4665e-04, 7.5436e-04, 2.0055e-03, 1.7923e-01, 5.4764e-01, 6.5306e-02,\n",
      "         9.5174e-02, 7.2976e-02, 2.8430e-02, 8.3312e-03],\n",
      "        [9.4269e-04, 8.5284e-03, 2.4240e-03, 1.6200e-02, 4.2189e-01, 2.5157e-01,\n",
      "         1.0130e-01, 2.0657e-02, 6.1602e-02, 1.1489e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi cảm_giác như thật dễ để nắm bắt_được theo ngày\n",
      "Reference: i feel like it &apos;s easy to get caught\n",
      "Model: <SOS> i feel like to be be to be the\n",
      "Attention Weights: tensor([[4.6320e-01, 5.1804e-01, 1.7088e-02, 1.6028e-03, 6.4195e-05, 3.6130e-06,\n",
      "         2.6640e-07, 2.3254e-07, 1.4679e-07, 5.2819e-08],\n",
      "        [8.7867e-03, 9.8130e-01, 8.0264e-03, 1.2153e-03, 5.4084e-04, 6.8947e-05,\n",
      "         2.4683e-05, 2.2423e-05, 7.5600e-06, 3.4582e-06],\n",
      "        [9.6456e-03, 5.9320e-01, 2.2882e-01, 1.0424e-01, 5.7392e-02, 5.2627e-03,\n",
      "         9.4954e-04, 3.9464e-04, 6.6751e-05, 2.1688e-05],\n",
      "        [2.3566e-03, 1.1392e-01, 1.5089e-01, 1.9554e-01, 3.9995e-01, 1.0993e-01,\n",
      "         1.3921e-02, 1.0124e-02, 2.3658e-03, 1.0006e-03],\n",
      "        [1.5832e-04, 5.8650e-03, 1.3856e-02, 6.6545e-02, 2.5485e-01, 3.0744e-01,\n",
      "         2.0600e-01, 1.1608e-01, 2.0727e-02, 8.4855e-03],\n",
      "        [8.8425e-06, 6.6503e-04, 4.0365e-03, 2.4432e-02, 1.2009e-01, 7.9309e-02,\n",
      "         1.9810e-01, 4.8391e-01, 6.5725e-02, 2.3728e-02],\n",
      "        [4.9047e-06, 4.3464e-05, 3.8863e-04, 1.3893e-03, 9.2295e-03, 1.0476e-02,\n",
      "         1.0575e-01, 6.5722e-01, 1.6611e-01, 4.9389e-02],\n",
      "        [5.5007e-06, 2.7314e-05, 4.1918e-04, 9.0325e-04, 3.9597e-03, 6.1239e-03,\n",
      "         6.2616e-02, 5.9654e-01, 2.0786e-01, 1.2155e-01],\n",
      "        [7.2613e-06, 1.5166e-05, 9.7286e-05, 3.5949e-04, 2.5038e-03, 4.1817e-03,\n",
      "         6.9321e-02, 5.1490e-01, 2.1819e-01, 1.9043e-01]])\n",
      "\n",
      "Epoch: 3.58, Train Loss: 3.29, Val Loss: 4.07, Train BLEU: 12.32, Val BLEU: 10.41, Minutes Elapsed: 185.04\n",
      "Sampling from training predictions...\n",
      "Source: có rất nhiều nguy_cơ liên_quan mà họ nói đến trong\n",
      "Reference: there were a lot of risks involved that they\n",
      "Model: <SOS> there are many lot of that that they they\n",
      "Attention Weights: tensor([[9.7373e-01, 2.6059e-02, 1.9345e-04, 1.3186e-05, 5.3122e-06, 1.1633e-07,\n",
      "         6.1741e-09, 5.0401e-09, 3.0599e-09, 2.5741e-09],\n",
      "        [6.3717e-01, 3.2733e-01, 1.9972e-02, 1.1215e-02, 4.0092e-03, 1.9016e-04,\n",
      "         5.7349e-05, 3.2637e-05, 1.2974e-05, 1.3852e-05],\n",
      "        [2.5862e-01, 3.9280e-01, 2.0000e-01, 8.9679e-02, 4.0963e-02, 6.6199e-03,\n",
      "         3.7944e-03, 4.8618e-03, 1.9024e-03, 7.6291e-04],\n",
      "        [5.1200e-03, 8.5134e-02, 3.9017e-01, 3.8955e-01, 1.1882e-01, 8.1922e-03,\n",
      "         1.5994e-03, 7.9287e-04, 4.4370e-04, 1.8466e-04],\n",
      "        [2.0359e-04, 1.1768e-03, 3.6417e-02, 6.6988e-01, 2.2999e-01, 4.8602e-02,\n",
      "         6.3277e-03, 3.9903e-03, 2.2791e-03, 1.1289e-03],\n",
      "        [2.1615e-04, 4.8150e-04, 1.0200e-02, 4.2907e-01, 3.9181e-01, 1.4648e-01,\n",
      "         8.6392e-03, 7.7371e-03, 2.5971e-03, 2.7680e-03],\n",
      "        [7.0180e-04, 5.5065e-04, 1.0728e-02, 3.6320e-01, 4.2567e-01, 1.3868e-01,\n",
      "         2.9066e-02, 2.4318e-02, 4.0878e-03, 3.0024e-03],\n",
      "        [5.7429e-05, 4.7920e-05, 6.4300e-04, 6.9138e-02, 2.5554e-01, 4.4234e-01,\n",
      "         1.0207e-01, 9.0541e-02, 2.2521e-02, 1.7092e-02],\n",
      "        [3.7435e-05, 7.8904e-05, 2.2416e-04, 4.0121e-03, 3.5868e-02, 6.9391e-02,\n",
      "         2.0170e-01, 4.6697e-01, 1.5092e-01, 7.0797e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: và chúng_ta có tiếp_tục hỏi , tại_sao cô ấy không\n",
      "Reference: and still we ask , why doesn &apos;t she\n",
      "Model: <SOS> and we have have to , why why understand\n",
      "Attention Weights: tensor([[3.7662e-03, 1.0174e-02, 5.3783e-01, 4.3238e-01, 1.5839e-02, 3.2164e-06,\n",
      "         3.0452e-06, 2.9449e-06, 7.0999e-07, 5.4633e-07],\n",
      "        [5.2405e-02, 8.4209e-01, 9.9683e-02, 5.6783e-03, 1.4231e-04, 1.7119e-06,\n",
      "         1.4718e-06, 5.8841e-07, 1.3583e-07, 5.7237e-08],\n",
      "        [6.3210e-05, 2.9807e-03, 2.5504e-01, 7.3170e-01, 9.5660e-03, 2.3266e-04,\n",
      "         2.1380e-04, 1.1472e-04, 6.9523e-05, 2.6783e-05],\n",
      "        [5.7312e-05, 1.1921e-03, 9.0123e-02, 7.5445e-01, 1.4675e-01, 4.7880e-03,\n",
      "         9.3768e-04, 7.3568e-04, 6.8694e-04, 2.8376e-04],\n",
      "        [3.5014e-04, 5.4843e-03, 2.2298e-01, 5.5133e-01, 2.1215e-01, 5.5206e-03,\n",
      "         1.1499e-03, 5.0831e-04, 3.4385e-04, 1.8958e-04],\n",
      "        [3.5616e-05, 5.5713e-05, 1.3775e-03, 1.3547e-01, 7.2548e-01, 1.2565e-01,\n",
      "         7.7656e-03, 2.0198e-03, 1.3062e-03, 8.4564e-04],\n",
      "        [1.9630e-05, 1.3219e-04, 3.1355e-03, 1.9755e-02, 1.1425e-01, 5.1355e-01,\n",
      "         2.9322e-01, 3.5915e-02, 1.1217e-02, 8.7948e-03],\n",
      "        [2.6462e-05, 7.0115e-05, 2.4321e-03, 6.6275e-03, 3.9709e-03, 1.9437e-02,\n",
      "         4.8561e-01, 3.2090e-01, 1.0349e-01, 5.7441e-02],\n",
      "        [1.3877e-06, 3.5111e-06, 1.2520e-04, 9.1767e-04, 1.1958e-03, 1.3459e-02,\n",
      "         2.1327e-01, 2.6449e-01, 3.3281e-01, 1.7372e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3.62, Train Loss: 3.26, Val Loss: 4.06, Train BLEU: 13.10, Val BLEU: 11.44, Minutes Elapsed: 187.52\n",
      "Sampling from training predictions...\n",
      "Source: khoảnh_khắc mọi người nghĩ về việc cố_gắng nhớ_lại 10 điều\n",
      "Reference: the moment people thought about trying to recall the\n",
      "Model: <SOS> the people of people about about people think about\n",
      "Attention Weights: tensor([[9.9444e-01, 5.4658e-03, 6.7319e-05, 2.1997e-05, 2.5148e-07, 1.1028e-07,\n",
      "         5.1002e-08, 1.1155e-08, 7.0003e-09, 3.8755e-09],\n",
      "        [7.2046e-01, 2.5054e-01, 1.8309e-02, 1.0287e-02, 2.1749e-04, 7.9852e-05,\n",
      "         7.8293e-05, 1.7691e-05, 2.4840e-06, 5.0199e-06],\n",
      "        [2.6248e-01, 3.2500e-01, 1.0337e-01, 2.6533e-01, 3.3394e-02, 6.7708e-03,\n",
      "         2.5249e-03, 8.6241e-04, 1.6626e-04, 9.7177e-05],\n",
      "        [1.8414e-02, 2.2511e-01, 1.7997e-01, 5.1845e-01, 3.7577e-02, 9.9504e-03,\n",
      "         6.5853e-03, 3.1983e-03, 4.6985e-04, 2.7343e-04],\n",
      "        [2.1467e-02, 4.2414e-02, 8.1698e-02, 5.9284e-01, 1.0312e-01, 6.1014e-02,\n",
      "         7.9910e-02, 1.3612e-02, 2.1795e-03, 1.7420e-03],\n",
      "        [1.8063e-04, 4.4734e-04, 5.4694e-03, 7.4804e-02, 2.8111e-01, 3.0076e-01,\n",
      "         2.5903e-01, 6.6182e-02, 5.8859e-03, 6.1318e-03],\n",
      "        [6.0256e-05, 7.4370e-05, 2.9714e-04, 9.2775e-03, 5.0654e-02, 1.9141e-01,\n",
      "         4.9904e-01, 1.6893e-01, 3.6647e-02, 4.3611e-02],\n",
      "        [1.0980e-05, 1.7915e-04, 1.4162e-04, 2.8174e-03, 1.6826e-02, 1.4087e-01,\n",
      "         2.9081e-01, 9.1585e-02, 7.2808e-02, 3.8395e-01],\n",
      "        [4.4406e-06, 7.8553e-06, 2.5538e-05, 9.6856e-04, 1.2411e-02, 9.7112e-02,\n",
      "         3.6235e-01, 1.7251e-01, 5.4201e-02, 3.0041e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: bởi_lẽ tôi muốn cho mọi người thấy sự <UNK> dữ_liệu\n",
      "Reference: because i want to show the people what does\n",
      "Model: <SOS> because i want to show people the that data\n",
      "Attention Weights: tensor([[9.9937e-01, 5.5084e-04, 8.2783e-05, 8.4510e-07, 4.7620e-08, 3.5369e-10,\n",
      "         3.8509e-10, 2.3693e-11, 2.5782e-12, 1.7141e-11],\n",
      "        [1.9901e-01, 5.3986e-01, 2.6048e-01, 6.2324e-04, 1.5863e-05, 2.4786e-06,\n",
      "         3.5340e-06, 6.8947e-07, 3.9789e-07, 4.6812e-07],\n",
      "        [3.3921e-03, 7.6305e-03, 9.7594e-01, 1.1504e-02, 1.1768e-03, 1.5102e-04,\n",
      "         1.5344e-04, 2.7347e-05, 1.4148e-05, 7.6176e-06],\n",
      "        [2.0753e-02, 8.6498e-03, 7.0608e-01, 2.0462e-01, 5.3625e-02, 3.8833e-03,\n",
      "         1.7958e-03, 3.3748e-04, 1.9985e-04, 5.4454e-05],\n",
      "        [2.1931e-03, 8.8343e-04, 1.8150e-02, 4.9704e-01, 3.6042e-01, 7.6343e-02,\n",
      "         3.8810e-02, 3.9467e-03, 1.2725e-03, 9.4086e-04],\n",
      "        [9.7344e-04, 6.6562e-04, 2.6759e-03, 1.7021e-01, 3.6153e-01, 1.4274e-01,\n",
      "         2.8400e-01, 2.5775e-02, 6.9209e-03, 4.5061e-03],\n",
      "        [1.8996e-04, 8.7444e-05, 2.6088e-04, 1.1402e-02, 8.8675e-02, 1.2316e-01,\n",
      "         5.5823e-01, 1.1910e-01, 6.5700e-02, 3.3192e-02],\n",
      "        [1.8971e-05, 6.0186e-06, 2.3426e-05, 1.4694e-04, 1.3291e-03, 6.8232e-03,\n",
      "         7.8231e-02, 7.7238e-02, 1.3752e-01, 6.9866e-01],\n",
      "        [5.1095e-05, 7.3880e-05, 4.8868e-05, 1.1324e-04, 5.7924e-04, 9.3884e-04,\n",
      "         2.6294e-02, 3.3924e-02, 8.1199e-02, 8.5678e-01]])\n",
      "\n",
      "Epoch: 3.67, Train Loss: 3.31, Val Loss: 4.10, Train BLEU: 11.02, Val BLEU: 9.90, Minutes Elapsed: 190.01\n",
      "Sampling from training predictions...\n",
      "Source: như bạn có_thể tưởng_tượng tôi căm_ghét cái khoảnh_khắc bóc toạc\n",
      "Reference: and as you can imagine , i hated that\n",
      "Model: <SOS> as you can can imagine my i i a\n",
      "Attention Weights: tensor([[9.4245e-01, 5.5274e-02, 2.2741e-03, 2.1301e-06, 4.7885e-08, 6.5700e-09,\n",
      "         2.3318e-09, 8.3421e-10, 5.8245e-10, 1.8364e-10],\n",
      "        [1.5046e-01, 7.2639e-01, 1.0969e-01, 1.3284e-02, 1.2075e-04, 4.4286e-05,\n",
      "         6.9303e-06, 4.7191e-06, 1.2000e-06, 7.5105e-07],\n",
      "        [2.4490e-02, 2.6031e-01, 3.5075e-01, 3.5551e-01, 5.7353e-03, 2.7629e-03,\n",
      "         2.1984e-04, 1.6946e-04, 3.4016e-05, 2.1897e-05],\n",
      "        [6.0228e-03, 7.3094e-02, 1.3289e-01, 7.7179e-01, 7.9567e-03, 7.7746e-03,\n",
      "         2.1889e-04, 2.2546e-04, 2.1012e-05, 1.1983e-05],\n",
      "        [8.0977e-03, 1.0981e-01, 1.5289e-01, 7.0449e-01, 1.4035e-02, 9.9919e-03,\n",
      "         3.1838e-04, 3.1583e-04, 3.6967e-05, 1.6616e-05],\n",
      "        [3.8689e-03, 2.1707e-02, 1.1062e-02, 7.4145e-01, 1.5216e-01, 6.6005e-02,\n",
      "         2.3388e-03, 1.1134e-03, 2.2296e-04, 6.7369e-05],\n",
      "        [2.7725e-03, 6.4623e-03, 1.1426e-02, 2.1160e-01, 3.4852e-01, 3.5471e-01,\n",
      "         3.5778e-02, 2.1864e-02, 4.7915e-03, 2.0681e-03],\n",
      "        [1.2806e-04, 5.9676e-04, 5.0853e-03, 2.0870e-02, 1.0795e-01, 3.9051e-01,\n",
      "         2.2062e-01, 1.7130e-01, 5.4269e-02, 2.8686e-02],\n",
      "        [1.5376e-03, 3.9225e-03, 4.9626e-02, 1.8121e-01, 4.0078e-02, 2.7622e-01,\n",
      "         1.3698e-01, 2.6965e-01, 2.8996e-02, 1.1789e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: cảm_ơn các bạn . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: thank you . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> thank you . <EOS> . . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0046, 0.0023, 0.0134, 0.1353, 0.8444, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0550, 0.0360, 0.0282, 0.7733, 0.1075, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0537, 0.0727, 0.1860, 0.5611, 0.1266, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0746, 0.0527, 0.1206, 0.3957, 0.3564, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0483, 0.0286, 0.0824, 0.3537, 0.4870, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1414, 0.0649, 0.1628, 0.4597, 0.1712, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0440, 0.0244, 0.1380, 0.5699, 0.2237, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0220, 0.0215, 0.0698, 0.4843, 0.4024, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0172, 0.0278, 0.0818, 0.5429, 0.3303, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 3.72, Train Loss: 3.30, Val Loss: 4.07, Train BLEU: 12.17, Val BLEU: 10.52, Minutes Elapsed: 192.47\n",
      "Sampling from training predictions...\n",
      "Source: và nó còn xảy ra ở đâu nữa ? <EOS>\n",
      "Reference: and does it happen anywhere else ? <EOS> <PAD>\n",
      "Model: <SOS> and where does it ? ? <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[3.5633e-02, 6.7667e-01, 2.8620e-01, 1.3585e-03, 1.3530e-04, 3.3225e-06,\n",
      "         3.5248e-07, 5.8268e-08, 7.9854e-09, 3.9857e-11],\n",
      "        [5.8197e-03, 9.5890e-01, 3.4441e-02, 7.8974e-04, 4.4673e-05, 4.8982e-06,\n",
      "         1.3631e-06, 2.9538e-07, 1.1765e-07, 1.5420e-08],\n",
      "        [3.2647e-04, 1.4794e-01, 6.8958e-01, 1.4650e-01, 1.1946e-02, 2.6826e-03,\n",
      "         7.1782e-04, 2.0527e-04, 8.2880e-05, 1.9391e-05],\n",
      "        [1.1845e-03, 1.1005e-01, 5.2692e-01, 2.7068e-01, 5.5957e-02, 2.5388e-02,\n",
      "         6.8569e-03, 2.1849e-03, 6.1617e-04, 1.5615e-04],\n",
      "        [6.0516e-04, 3.2784e-02, 1.7215e-01, 2.8096e-01, 1.3572e-01, 2.1775e-01,\n",
      "         1.2072e-01, 2.8553e-02, 8.9594e-03, 1.7856e-03],\n",
      "        [2.8132e-04, 2.3301e-03, 1.2317e-02, 7.7795e-02, 1.0371e-01, 3.1925e-01,\n",
      "         3.3247e-01, 1.1041e-01, 2.7893e-02, 1.3539e-02],\n",
      "        [5.1786e-05, 3.7484e-04, 2.7842e-03, 1.8206e-02, 2.0289e-02, 1.7681e-01,\n",
      "         3.8685e-01, 2.1209e-01, 1.0435e-01, 7.8199e-02],\n",
      "        [2.7200e-04, 3.2900e-03, 8.2597e-03, 2.4326e-02, 2.3913e-02, 1.3049e-01,\n",
      "         3.0646e-01, 1.6840e-01, 1.8022e-01, 1.5437e-01],\n",
      "        [2.6302e-04, 1.3951e-02, 2.1895e-02, 2.9105e-02, 3.1762e-02, 8.8986e-02,\n",
      "         1.9475e-01, 9.3297e-02, 1.8508e-01, 3.4090e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi muốn đưa nô_lệ ra ánh_sáng . <EOS> <PAD> <PAD>\n",
      "Reference: i want to shine a light on slavery .\n",
      "Model: <SOS> i want to take a a . <EOS> .\n",
      "Attention Weights: tensor([[0.1360, 0.8592, 0.0048, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0020, 0.9943, 0.0036, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0055, 0.8869, 0.1039, 0.0028, 0.0005, 0.0003, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0009, 0.0311, 0.8351, 0.1043, 0.0158, 0.0123, 0.0004, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0006, 0.0492, 0.4717, 0.2604, 0.2160, 0.0015, 0.0006, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0007, 0.0872, 0.1915, 0.7105, 0.0077, 0.0025, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0004, 0.0066, 0.0879, 0.8724, 0.0185, 0.0141, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0008, 0.0006, 0.0028, 0.0208, 0.2209, 0.5304, 0.1191, 0.1046, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0005, 0.0020, 0.0047, 0.0440, 0.1761, 0.6598, 0.0590, 0.0539, 0.0000,\n",
      "         0.0000]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3.77, Train Loss: 3.39, Val Loss: 4.16, Train BLEU: 11.12, Val BLEU: 9.91, Minutes Elapsed: 194.92\n",
      "Sampling from training predictions...\n",
      "Source: điều mà tôi thích nhất_là , ai đó có_thể tải\n",
      "Reference: the one i liked the best is , someone\n",
      "Model: <SOS> what i i i really , , , ,\n",
      "Attention Weights: tensor([[9.9803e-01, 1.9448e-03, 1.3226e-05, 7.8179e-06, 1.2379e-08, 1.4644e-10,\n",
      "         1.5717e-10, 4.0060e-11, 2.1072e-11, 1.6080e-12],\n",
      "        [1.2158e-01, 7.0505e-01, 9.6263e-02, 7.6783e-02, 3.1605e-04, 3.5363e-06,\n",
      "         6.4562e-06, 2.7178e-06, 2.2065e-06, 4.5834e-07],\n",
      "        [8.1048e-03, 7.7347e-02, 7.3031e-02, 8.3595e-01, 5.2570e-03, 8.4401e-05,\n",
      "         7.2403e-05, 4.4926e-05, 5.6120e-05, 4.7273e-05],\n",
      "        [6.8284e-03, 6.2730e-02, 7.0521e-02, 8.3924e-01, 1.9329e-02, 5.7561e-04,\n",
      "         4.4945e-04, 9.6082e-05, 1.4087e-04, 8.5345e-05],\n",
      "        [2.3990e-03, 3.2259e-02, 5.0945e-02, 8.8707e-01, 2.2829e-02, 1.5026e-03,\n",
      "         2.2416e-03, 3.3507e-04, 2.7670e-04, 1.3856e-04],\n",
      "        [1.6453e-03, 1.6227e-03, 3.5912e-03, 6.8516e-01, 2.2991e-01, 3.2715e-02,\n",
      "         4.0228e-02, 2.0385e-03, 1.6557e-03, 1.4391e-03],\n",
      "        [9.3670e-05, 1.2447e-04, 4.3128e-04, 3.1595e-02, 1.1412e-01, 1.0269e-01,\n",
      "         7.0513e-01, 3.2355e-02, 7.6849e-03, 5.7723e-03],\n",
      "        [1.0328e-04, 5.2847e-04, 1.1921e-03, 1.2515e-02, 2.1564e-02, 1.1274e-01,\n",
      "         8.2143e-01, 2.3587e-02, 4.5178e-03, 1.8204e-03],\n",
      "        [2.9764e-05, 2.0602e-04, 2.0897e-04, 6.1761e-03, 2.9967e-02, 6.2929e-02,\n",
      "         7.9460e-01, 8.6863e-02, 1.5716e-02, 3.3059e-03]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: điều tôi không bao_giờ lại có nửa , mãi_mãi là\n",
      "Reference: what i will never have again , ever ,\n",
      "Model: <SOS> i i never never forget that , the was\n",
      "Attention Weights: tensor([[9.9974e-01, 1.6550e-04, 8.6392e-05, 4.3618e-06, 5.7209e-08, 2.7478e-09,\n",
      "         2.0986e-10, 3.2682e-12, 4.2966e-12, 7.5210e-13],\n",
      "        [8.6611e-01, 3.5046e-02, 9.0612e-02, 8.1759e-03, 5.2932e-05, 3.4164e-06,\n",
      "         2.0428e-06, 3.3349e-07, 7.9494e-07, 4.0142e-07],\n",
      "        [6.9176e-02, 2.0731e-02, 3.8137e-01, 4.9712e-01, 3.0122e-02, 1.1490e-03,\n",
      "         2.6943e-04, 1.6317e-05, 2.1481e-05, 2.0067e-05],\n",
      "        [2.5375e-01, 2.7551e-02, 2.2004e-01, 4.3027e-01, 6.4191e-02, 3.4362e-03,\n",
      "         6.1836e-04, 4.3321e-05, 5.7270e-05, 4.2237e-05],\n",
      "        [5.4895e-02, 4.6953e-03, 5.5764e-03, 4.0649e-01, 4.1230e-01, 8.6454e-02,\n",
      "         2.9116e-02, 2.1869e-04, 1.5449e-04, 9.0958e-05],\n",
      "        [6.2437e-03, 8.6569e-04, 1.0195e-03, 7.2276e-02, 6.6112e-01, 1.5206e-01,\n",
      "         1.0333e-01, 1.6023e-03, 1.0960e-03, 3.8077e-04],\n",
      "        [1.0252e-03, 1.6727e-04, 3.2348e-04, 1.5476e-02, 4.1162e-01, 2.7629e-01,\n",
      "         2.7641e-01, 6.7521e-03, 1.0685e-02, 1.2459e-03],\n",
      "        [2.7862e-04, 7.0306e-05, 1.1260e-04, 2.8286e-03, 1.9262e-01, 3.5344e-01,\n",
      "         4.0844e-01, 2.0945e-02, 1.8375e-02, 2.8782e-03],\n",
      "        [1.9053e-04, 1.8753e-05, 5.0474e-05, 1.5365e-03, 1.2355e-01, 2.9378e-01,\n",
      "         4.4379e-01, 4.0919e-02, 8.5237e-02, 1.0927e-02]])\n",
      "\n",
      "Epoch: 3.82, Train Loss: 3.27, Val Loss: 4.06, Train BLEU: 12.32, Val BLEU: 10.62, Minutes Elapsed: 197.42\n",
      "Sampling from training predictions...\n",
      "Source: xin cảm_ơn . cảm_ơn . tạm_biệt . <EOS> <PAD> <PAD>\n",
      "Reference: thank you . thank you . bye . <EOS>\n",
      "Model: <SOS> thank you . thank you . <EOS> you <EOS>\n",
      "Attention Weights: tensor([[0.0017, 0.4029, 0.5901, 0.0053, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0053, 0.8203, 0.1598, 0.0136, 0.0006, 0.0003, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0227, 0.4049, 0.4279, 0.1248, 0.0102, 0.0069, 0.0020, 0.0006, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0020, 0.0637, 0.3654, 0.5028, 0.0300, 0.0309, 0.0039, 0.0012, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0013, 0.2398, 0.0676, 0.5207, 0.0753, 0.0844, 0.0082, 0.0027, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0035, 0.1647, 0.0456, 0.2864, 0.1457, 0.2821, 0.0569, 0.0151, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0010, 0.0509, 0.0456, 0.2786, 0.2227, 0.3325, 0.0561, 0.0126, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0013, 0.1651, 0.0186, 0.1625, 0.1061, 0.5089, 0.0268, 0.0109, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0038, 0.1585, 0.0273, 0.0406, 0.1223, 0.4884, 0.1385, 0.0206, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: cảm_ơn bạn . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: thank you . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> thank you . <EOS> you . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0092, 0.0107, 0.2354, 0.7447, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0559, 0.1985, 0.6676, 0.0780, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0961, 0.2468, 0.5822, 0.0750, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1862, 0.1363, 0.4827, 0.1949, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0771, 0.3030, 0.4063, 0.2136, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0896, 0.2118, 0.5849, 0.1137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0814, 0.2193, 0.6253, 0.0740, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0775, 0.2630, 0.5249, 0.1345, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0680, 0.1932, 0.6460, 0.0928, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 3.86, Train Loss: 3.26, Val Loss: 4.04, Train BLEU: 12.25, Val BLEU: 10.58, Minutes Elapsed: 199.88\n",
      "Sampling from training predictions...\n",
      "Source: đa_phần âm_nhạc mà chúng_ta biết ngày_nay có cội_nguồn từ tây\n",
      "Reference: most of the popular music that we know now\n",
      "Model: <SOS> most of we we that we we know that\n",
      "Attention Weights: tensor([[9.8123e-01, 1.8357e-02, 4.1078e-04, 5.2934e-06, 1.2453e-06, 2.7532e-07,\n",
      "         3.4817e-08, 1.1778e-08, 5.9375e-09, 2.9077e-09],\n",
      "        [3.3776e-01, 5.8641e-01, 7.1128e-02, 1.8080e-03, 2.5489e-03, 1.8944e-04,\n",
      "         3.7837e-05, 8.6390e-05, 1.6473e-05, 1.1909e-05],\n",
      "        [5.0007e-01, 2.7681e-01, 9.4900e-02, 2.5479e-02, 9.7436e-02, 4.1598e-03,\n",
      "         4.8602e-04, 5.1700e-04, 9.5980e-05, 4.5825e-05],\n",
      "        [8.3721e-02, 2.6536e-01, 2.7522e-01, 8.7301e-02, 2.6531e-01, 1.6654e-02,\n",
      "         3.0785e-03, 2.6626e-03, 3.5110e-04, 3.3451e-04],\n",
      "        [2.1792e-02, 1.3688e-01, 3.8437e-01, 2.0109e-01, 2.4468e-01, 8.7512e-03,\n",
      "         1.3166e-03, 8.8087e-04, 1.4665e-04, 1.0149e-04],\n",
      "        [1.1570e-02, 1.4484e-01, 2.9073e-01, 2.5197e-01, 2.8780e-01, 9.6596e-03,\n",
      "         2.0953e-03, 1.0136e-03, 1.8069e-04, 1.4187e-04],\n",
      "        [5.5484e-03, 5.6551e-02, 1.0036e-01, 1.8244e-01, 6.3090e-01, 1.3805e-02,\n",
      "         5.1678e-03, 4.2290e-03, 5.3529e-04, 4.6533e-04],\n",
      "        [2.7011e-03, 1.0221e-02, 2.7765e-02, 1.0352e-01, 6.9424e-01, 9.9615e-02,\n",
      "         3.4246e-02, 2.2419e-02, 2.6563e-03, 2.6211e-03],\n",
      "        [3.1685e-03, 1.2594e-02, 2.5273e-02, 6.1242e-02, 6.4728e-01, 1.5438e-01,\n",
      "         4.5976e-02, 4.3815e-02, 3.7561e-03, 2.5093e-03]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi thực_sự tin , nếu ta coi người khác như\n",
      "Reference: i truly believe , if we can see one\n",
      "Model: <SOS> i really believe , if we were somebody like\n",
      "Attention Weights: tensor([[3.5252e-01, 5.1191e-01, 1.3555e-01, 2.5382e-05, 3.9688e-06, 1.0713e-07,\n",
      "         1.9843e-07, 7.6441e-08, 6.8394e-08, 1.1752e-08],\n",
      "        [9.0667e-04, 9.8464e-01, 1.4406e-02, 3.3447e-05, 3.2607e-06, 6.7837e-07,\n",
      "         4.0657e-06, 2.8792e-06, 1.1522e-06, 1.9723e-07],\n",
      "        [1.5046e-03, 3.3953e-01, 6.3657e-01, 1.8673e-02, 3.8683e-04, 1.4132e-04,\n",
      "         2.3635e-03, 5.1741e-04, 2.7839e-04, 3.3529e-05],\n",
      "        [8.7623e-03, 5.7156e-02, 2.9236e-01, 4.2020e-01, 1.8461e-01, 4.5060e-03,\n",
      "         1.3223e-02, 1.2329e-02, 4.5840e-03, 2.2702e-03],\n",
      "        [1.8088e-03, 4.1970e-03, 3.0000e-02, 2.7700e-01, 5.7094e-01, 3.5560e-02,\n",
      "         2.6272e-02, 2.6969e-02, 1.7037e-02, 1.0216e-02],\n",
      "        [1.9117e-04, 9.3013e-04, 8.8525e-04, 9.3181e-03, 1.3288e-01, 1.1784e-01,\n",
      "         2.6679e-01, 3.5716e-01, 1.0243e-01, 1.1563e-02],\n",
      "        [4.4754e-05, 5.2702e-03, 2.1924e-03, 1.2689e-03, 1.0252e-02, 1.5752e-02,\n",
      "         3.7277e-01, 3.1872e-01, 2.3822e-01, 3.5510e-02],\n",
      "        [3.1798e-05, 2.0822e-03, 3.1386e-03, 1.3782e-03, 2.1641e-03, 5.3744e-03,\n",
      "         3.1088e-01, 2.0334e-01, 2.5723e-01, 2.1438e-01],\n",
      "        [2.2734e-06, 3.0341e-05, 1.9461e-04, 6.3852e-04, 2.5049e-03, 1.9307e-04,\n",
      "         1.6069e-02, 1.8843e-01, 3.8712e-01, 4.0482e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3.91, Train Loss: 3.27, Val Loss: 4.06, Train BLEU: 11.17, Val BLEU: 10.05, Minutes Elapsed: 202.36\n",
      "Sampling from training predictions...\n",
      "Source: vậy sao không phải là công_nghệ sinh_học cá_nhân ? <EOS>\n",
      "Reference: why not personal biotech ? <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> why is &apos;t not ? <EOS> <EOS> ? <EOS>\n",
      "Attention Weights: tensor([[5.7399e-02, 9.4144e-01, 9.8817e-04, 1.6757e-04, 3.8075e-07, 4.1766e-08,\n",
      "         3.6289e-09, 4.0583e-09, 6.5813e-10, 9.7099e-11],\n",
      "        [7.2855e-03, 9.5977e-01, 2.9534e-02, 3.3374e-03, 4.3283e-05, 2.0257e-05,\n",
      "         7.7355e-06, 2.8549e-06, 3.0430e-07, 1.4766e-07],\n",
      "        [2.2023e-02, 7.5776e-01, 1.7165e-01, 3.5873e-02, 5.7831e-03, 4.6219e-03,\n",
      "         1.5850e-03, 6.3768e-04, 4.5520e-05, 2.5379e-05],\n",
      "        [4.5307e-03, 2.2038e-01, 2.2779e-01, 1.9602e-01, 1.0562e-01, 1.7093e-01,\n",
      "         4.7269e-02, 2.6210e-02, 7.6159e-04, 4.8739e-04],\n",
      "        [3.3065e-04, 1.6881e-02, 2.9742e-02, 8.0996e-02, 9.0614e-02, 3.9036e-01,\n",
      "         2.5582e-01, 1.3164e-01, 2.3667e-03, 1.2580e-03],\n",
      "        [8.7787e-05, 7.9595e-03, 3.2893e-02, 6.3853e-03, 1.6940e-02, 2.1242e-01,\n",
      "         4.0004e-01, 2.5191e-01, 4.7323e-02, 2.4032e-02],\n",
      "        [3.1173e-04, 1.4473e-02, 2.2144e-02, 1.6752e-02, 3.1503e-02, 1.2551e-01,\n",
      "         3.5138e-01, 2.4663e-01, 4.2772e-02, 1.4853e-01],\n",
      "        [1.1471e-03, 1.6876e-01, 1.6309e-01, 3.4539e-02, 6.2638e-02, 1.9351e-01,\n",
      "         1.5306e-01, 8.7188e-02, 4.4023e-02, 9.2045e-02],\n",
      "        [5.8269e-04, 4.7882e-02, 1.8486e-02, 7.1521e-03, 2.0552e-02, 2.1700e-01,\n",
      "         4.8271e-01, 1.2814e-01, 3.4429e-02, 4.3060e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: chúng thật_sự là những gã gom rác tự_nhiên . <EOS>\n",
      "Reference: they &apos;re our natural garbage collectors . <EOS> <PAD>\n",
      "Model: <SOS> they are really really of . <EOS> <EOS> course\n",
      "Attention Weights: tensor([[9.7911e-01, 2.0693e-02, 1.9800e-04, 2.2039e-06, 2.3327e-07, 7.6132e-08,\n",
      "         1.5615e-08, 1.1411e-08, 6.5373e-10, 3.3361e-10],\n",
      "        [6.0278e-02, 9.1813e-01, 1.8106e-02, 2.3748e-03, 5.8155e-04, 3.0839e-04,\n",
      "         1.3362e-04, 7.1043e-05, 9.2100e-06, 6.1997e-06],\n",
      "        [3.0240e-02, 7.5271e-01, 9.8495e-02, 5.8116e-02, 3.9870e-02, 1.1889e-02,\n",
      "         6.3908e-03, 2.1113e-03, 1.2448e-04, 5.0326e-05],\n",
      "        [1.1330e-04, 1.2486e-02, 7.6627e-02, 2.8948e-01, 3.7375e-01, 1.5011e-01,\n",
      "         5.0699e-02, 4.6268e-02, 3.6092e-04, 1.0664e-04],\n",
      "        [1.2585e-04, 4.6319e-03, 2.1089e-02, 1.7224e-01, 4.5197e-01, 2.1614e-01,\n",
      "         5.9280e-02, 7.1393e-02, 2.2991e-03, 8.3330e-04],\n",
      "        [1.3141e-05, 1.0186e-04, 1.8327e-03, 1.9522e-02, 2.5801e-01, 2.3194e-01,\n",
      "         1.8760e-01, 2.3620e-01, 4.6001e-02, 1.8779e-02],\n",
      "        [5.5894e-05, 2.1705e-04, 1.5253e-03, 2.4576e-03, 3.6730e-02, 6.0436e-02,\n",
      "         2.5777e-01, 2.8194e-01, 2.2839e-01, 1.3048e-01],\n",
      "        [1.6214e-03, 1.7782e-03, 4.6984e-03, 6.6246e-03, 1.8159e-02, 2.5742e-02,\n",
      "         9.1679e-02, 1.9960e-01, 2.0651e-01, 4.4359e-01],\n",
      "        [5.6148e-03, 1.1757e-02, 1.0716e-02, 1.7650e-02, 2.4359e-02, 2.7314e-02,\n",
      "         1.0713e-01, 2.2873e-01, 1.5017e-01, 4.1656e-01]])\n",
      "\n",
      "Epoch: 3.96, Train Loss: 3.22, Val Loss: 4.05, Train BLEU: 11.81, Val BLEU: 10.56, Minutes Elapsed: 204.86\n",
      "Sampling from training predictions...\n",
      "Source: nhưng ở đâu , trong thế_giới già nhanh_chóng già_cỗi và\n",
      "Reference: but where , in our increasingly secular and fragmented\n",
      "Model: <SOS> but in , in the world , , ,\n",
      "Attention Weights: tensor([[9.8625e-03, 9.5717e-01, 3.2894e-02, 6.9638e-05, 3.8742e-06, 4.5866e-08,\n",
      "         1.4670e-09, 3.8480e-10, 2.1646e-10, 1.5029e-11],\n",
      "        [1.0361e-02, 8.9940e-01, 8.9471e-02, 7.1011e-04, 4.8574e-05, 4.5325e-06,\n",
      "         2.6175e-07, 9.2288e-08, 5.5968e-08, 5.1521e-09],\n",
      "        [6.3596e-03, 5.7817e-02, 1.7534e-01, 2.6328e-01, 3.5030e-01, 1.1768e-01,\n",
      "         2.0819e-02, 6.3463e-03, 1.8627e-03, 2.0342e-04],\n",
      "        [1.9120e-03, 6.4188e-03, 3.8862e-02, 1.3203e-01, 4.5423e-01, 2.5326e-01,\n",
      "         7.7107e-02, 2.9965e-02, 5.6621e-03, 5.4449e-04],\n",
      "        [5.4072e-04, 1.4013e-03, 8.9940e-03, 3.3892e-02, 2.3193e-01, 4.4364e-01,\n",
      "         1.6572e-01, 9.2171e-02, 2.0018e-02, 1.6998e-03],\n",
      "        [5.4194e-04, 1.5878e-03, 4.4324e-03, 8.5731e-03, 7.3754e-02, 5.4203e-01,\n",
      "         1.8403e-01, 1.5103e-01, 3.0901e-02, 3.1120e-03],\n",
      "        [1.0963e-04, 1.4460e-03, 7.8763e-03, 4.3755e-02, 4.3057e-02, 2.5512e-01,\n",
      "         3.6828e-01, 1.9739e-01, 6.3490e-02, 1.9467e-02],\n",
      "        [7.4680e-06, 1.0402e-04, 5.6840e-04, 2.0465e-03, 3.3459e-03, 1.1095e-01,\n",
      "         2.2819e-01, 3.3231e-01, 2.1099e-01, 1.1149e-01],\n",
      "        [4.5234e-06, 1.7574e-05, 4.7814e-05, 2.1121e-04, 9.5869e-04, 4.0558e-02,\n",
      "         9.9956e-02, 3.3549e-01, 2.6550e-01, 2.5726e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi đã rất sợ . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: and i was scared . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> i was was very disconcerted <EOS> was . <EOS>\n",
      "Attention Weights: tensor([[0.0050, 0.6015, 0.3861, 0.0073, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0020, 0.1692, 0.8233, 0.0055, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0014, 0.1785, 0.5798, 0.2234, 0.0157, 0.0010, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0066, 0.3465, 0.4873, 0.1443, 0.0143, 0.0009, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0035, 0.0087, 0.2102, 0.4757, 0.2382, 0.0637, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0038, 0.0142, 0.0502, 0.3539, 0.1800, 0.3979, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0126, 0.0706, 0.2598, 0.1574, 0.0827, 0.4169, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0109, 0.2675, 0.6063, 0.0652, 0.0160, 0.0342, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0115, 0.1429, 0.1516, 0.2148, 0.1167, 0.3624, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 4.00, Train Loss: 3.20, Val Loss: 4.11, Train BLEU: 12.87, Val BLEU: 10.09, Minutes Elapsed: 206.92\n",
      "Sampling from training predictions...\n",
      "Source: họ viết nên ca_khúc mà giờ người_ta gọi là nhạc\n",
      "Reference: they wrote what is now called arena rock ,\n",
      "Model: <SOS> they wrote the the the that call called call\n",
      "Attention Weights: tensor([[9.7242e-01, 2.7418e-02, 1.4369e-04, 1.4743e-05, 6.8313e-07, 8.1085e-08,\n",
      "         1.0736e-08, 1.0770e-08, 2.1318e-09, 2.2264e-09],\n",
      "        [2.2161e-03, 9.8993e-01, 7.0876e-03, 7.4576e-04, 8.2571e-06, 9.0908e-06,\n",
      "         2.3541e-06, 3.3810e-06, 4.7217e-07, 3.3648e-07],\n",
      "        [5.5268e-03, 1.8915e-01, 7.5576e-01, 3.9483e-02, 6.4770e-03, 2.9923e-03,\n",
      "         2.4372e-04, 2.5307e-04, 8.7796e-05, 3.0800e-05],\n",
      "        [3.0454e-04, 2.3543e-02, 5.7508e-01, 3.7319e-01, 1.1892e-02, 1.0137e-02,\n",
      "         4.0469e-03, 1.0664e-03, 4.6967e-04, 2.7351e-04],\n",
      "        [1.1887e-04, 1.7174e-02, 2.2459e-01, 3.6718e-01, 1.1511e-01, 1.7809e-01,\n",
      "         7.2159e-02, 1.8592e-02, 4.3062e-03, 2.6790e-03],\n",
      "        [2.0411e-04, 3.6138e-02, 7.4613e-02, 3.1829e-01, 9.8514e-02, 2.3684e-01,\n",
      "         1.3700e-01, 8.5443e-02, 8.0957e-03, 4.8681e-03],\n",
      "        [1.1903e-05, 3.8656e-03, 3.3384e-02, 1.6797e-01, 9.8957e-02, 3.1025e-01,\n",
      "         2.2783e-01, 1.3607e-01, 1.0792e-02, 1.0872e-02],\n",
      "        [3.7915e-05, 9.8664e-03, 2.2161e-02, 1.4461e-01, 1.1360e-01, 2.6657e-01,\n",
      "         1.9905e-01, 2.1268e-01, 2.0191e-02, 1.1228e-02],\n",
      "        [3.0582e-06, 2.8993e-04, 4.9155e-03, 5.0618e-02, 1.0796e-01, 2.2767e-01,\n",
      "         2.2266e-01, 3.2598e-01, 3.4358e-02, 2.5550e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: bấy_giờ , <UNK> không trở_về nhà vào một ngày và\n",
      "Reference: now , <UNK> did not come home one day\n",
      "Model: <SOS> now , the &apos;s not sit on the a\n",
      "Attention Weights: tensor([[9.9968e-01, 3.0730e-04, 7.8804e-06, 7.1023e-07, 2.0156e-08, 2.1860e-10,\n",
      "         5.4595e-11, 4.2119e-11, 1.3762e-11, 2.4154e-12],\n",
      "        [4.9955e-01, 3.9544e-01, 8.8334e-02, 1.5137e-02, 1.2692e-03, 1.5398e-04,\n",
      "         6.3254e-05, 3.9556e-05, 1.3616e-05, 5.8667e-06],\n",
      "        [1.1227e-01, 1.2405e-01, 4.5645e-01, 2.5515e-01, 4.5545e-02, 4.0685e-03,\n",
      "         1.3756e-03, 6.6140e-04, 3.5274e-04, 7.7004e-05],\n",
      "        [3.6208e-02, 2.8194e-02, 3.1285e-01, 5.1161e-01, 8.3119e-02, 1.9954e-02,\n",
      "         5.3266e-03, 1.9996e-03, 6.2387e-04, 1.1262e-04],\n",
      "        [1.7529e-02, 1.8312e-02, 2.2690e-01, 5.0521e-01, 1.5746e-01, 5.4966e-02,\n",
      "         1.3973e-02, 4.1598e-03, 1.3679e-03, 1.2820e-04],\n",
      "        [7.5023e-04, 2.8177e-04, 1.9334e-02, 2.3605e-01, 3.0741e-01, 2.3870e-01,\n",
      "         1.1985e-01, 5.7302e-02, 1.8783e-02, 1.5339e-03],\n",
      "        [1.7085e-04, 4.2419e-05, 1.2139e-03, 6.4899e-03, 2.4197e-01, 4.5290e-01,\n",
      "         1.6114e-01, 8.8870e-02, 4.6399e-02, 8.0471e-04],\n",
      "        [2.5845e-04, 3.5870e-05, 2.2841e-03, 8.1820e-03, 5.7468e-02, 2.5908e-01,\n",
      "         1.7664e-01, 2.1970e-01, 2.6567e-01, 1.0683e-02],\n",
      "        [6.7176e-04, 6.0194e-05, 1.6780e-03, 1.1375e-02, 4.8147e-02, 1.8289e-01,\n",
      "         1.6850e-01, 1.9668e-01, 3.6855e-01, 2.1441e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4.05, Train Loss: 2.64, Val Loss: 4.07, Train BLEU: 16.78, Val BLEU: 10.47, Minutes Elapsed: 209.43\n",
      "Sampling from training predictions...\n",
      "Source: nhưng trong những cuộn_phim là mục_đích và ý_nghĩa <EOS> <PAD>\n",
      "Reference: but within the reels lie purpose and meaning .\n",
      "Model: <SOS> but in the reels is the and and .\n",
      "Attention Weights: tensor([[0.0473, 0.9523, 0.0003, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0040, 0.9931, 0.0024, 0.0005, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0062, 0.0894, 0.4418, 0.4505, 0.0038, 0.0076, 0.0003, 0.0004, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0231, 0.1033, 0.2721, 0.4178, 0.0569, 0.1157, 0.0044, 0.0068, 0.0001,\n",
      "         0.0000],\n",
      "        [0.0004, 0.0007, 0.0100, 0.0585, 0.6222, 0.2756, 0.0196, 0.0124, 0.0005,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0003, 0.0034, 0.0464, 0.3180, 0.5228, 0.0485, 0.0583, 0.0022,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0004, 0.0061, 0.0339, 0.1630, 0.5100, 0.0997, 0.1846, 0.0021,\n",
      "         0.0000],\n",
      "        [0.0006, 0.0013, 0.0023, 0.0082, 0.1100, 0.2741, 0.1361, 0.4513, 0.0162,\n",
      "         0.0000],\n",
      "        [0.0054, 0.0053, 0.0015, 0.0047, 0.0617, 0.2025, 0.1000, 0.5768, 0.0421,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: bất_cứ ai khoẻ_mạnh hoặc mắc bệnh parkinson có_thể gọi tới\n",
      "Reference: anyone healthy or with parkinson &apos;s can call in\n",
      "Model: <SOS> anyone of the or to , , to to\n",
      "Attention Weights: tensor([[2.7674e-01, 7.2183e-01, 1.4342e-03, 5.1610e-06, 8.2521e-08, 2.9463e-09,\n",
      "         2.3426e-09, 7.9105e-10, 2.9337e-10, 7.2639e-11],\n",
      "        [1.5148e-02, 2.9855e-01, 6.5895e-01, 2.5095e-02, 1.9917e-03, 1.5842e-04,\n",
      "         6.4375e-05, 1.4308e-05, 1.4524e-05, 4.1682e-06],\n",
      "        [2.3189e-02, 6.0014e-02, 6.5464e-01, 1.8530e-01, 6.7972e-02, 5.6772e-03,\n",
      "         2.1042e-03, 4.8780e-04, 5.1486e-04, 1.0105e-04],\n",
      "        [2.1782e-03, 6.8099e-04, 1.8659e-01, 4.1731e-01, 2.1060e-01, 1.1184e-01,\n",
      "         6.1840e-02, 5.2475e-03, 3.2284e-03, 4.7766e-04],\n",
      "        [9.9548e-04, 6.6265e-05, 9.4419e-04, 2.0168e-02, 1.8137e-01, 3.6614e-01,\n",
      "         2.1513e-01, 1.6953e-01, 3.7308e-02, 8.3509e-03],\n",
      "        [3.2673e-04, 6.4114e-05, 1.9152e-04, 4.2707e-03, 4.7216e-02, 3.4856e-01,\n",
      "         1.8555e-01, 2.7957e-01, 1.1348e-01, 2.0769e-02],\n",
      "        [3.6697e-04, 2.0046e-04, 1.3036e-04, 1.0949e-03, 9.1382e-03, 2.0713e-01,\n",
      "         1.0334e-01, 4.0325e-01, 2.2846e-01, 4.6890e-02],\n",
      "        [1.0621e-05, 2.3520e-05, 1.0754e-04, 2.6505e-04, 7.6584e-04, 1.1313e-02,\n",
      "         2.0944e-02, 2.0484e-01, 5.2401e-01, 2.3773e-01],\n",
      "        [1.4703e-06, 1.5127e-06, 2.2035e-05, 2.8885e-04, 1.1410e-03, 1.5086e-02,\n",
      "         3.1817e-02, 2.2988e-01, 3.2063e-01, 4.0114e-01]])\n",
      "\n",
      "Epoch: 4.10, Train Loss: 2.77, Val Loss: 4.07, Train BLEU: 16.10, Val BLEU: 10.67, Minutes Elapsed: 211.92\n",
      "Sampling from training predictions...\n",
      "Source: chúng không hoang_dã hay tập_trung quá nhiều vào bản_thân .\n",
      "Reference: they are neither feral nor myopically self-absorbed . <EOS>\n",
      "Model: <SOS> they &apos;re &apos;t feral or myopically self-absorbed . .\n",
      "Attention Weights: tensor([[9.8424e-01, 1.5392e-02, 3.2219e-04, 4.2156e-05, 2.9919e-07, 1.5595e-08,\n",
      "         4.1974e-09, 5.5900e-10, 3.0548e-10, 1.3323e-10],\n",
      "        [3.0168e-02, 7.5837e-01, 2.0255e-01, 8.1436e-03, 6.9892e-04, 3.8682e-05,\n",
      "         2.5865e-05, 5.1280e-06, 5.8522e-06, 1.7213e-06],\n",
      "        [3.4660e-02, 4.4629e-01, 3.2572e-01, 1.7346e-01, 1.7766e-02, 1.1384e-03,\n",
      "         5.2972e-04, 2.1614e-04, 1.8501e-04, 3.4644e-05],\n",
      "        [7.4774e-03, 3.9143e-03, 6.2796e-01, 3.0892e-01, 4.4037e-02, 5.5230e-03,\n",
      "         1.5776e-03, 1.9449e-04, 3.7202e-04, 2.0408e-05],\n",
      "        [5.0906e-03, 3.4127e-03, 7.0164e-02, 3.2799e-01, 5.2405e-01, 4.9486e-02,\n",
      "         1.0953e-02, 4.5120e-03, 4.0334e-03, 3.0890e-04],\n",
      "        [1.1588e-04, 7.5062e-04, 3.4801e-03, 2.5174e-02, 5.1991e-01, 2.1412e-01,\n",
      "         1.4682e-01, 4.6396e-02, 4.0912e-02, 2.3222e-03],\n",
      "        [8.0783e-05, 7.7254e-05, 4.1558e-04, 3.3504e-03, 1.9748e-02, 9.0604e-02,\n",
      "         2.9869e-01, 2.1592e-01, 3.4485e-01, 2.6266e-02],\n",
      "        [6.9127e-06, 2.3799e-05, 7.8325e-05, 1.2571e-03, 2.9588e-02, 1.1987e-01,\n",
      "         2.8421e-01, 2.1748e-01, 2.9734e-01, 5.0149e-02],\n",
      "        [3.9737e-05, 1.6030e-05, 9.9149e-05, 9.5187e-04, 9.4300e-03, 5.5189e-02,\n",
      "         2.5077e-01, 2.1307e-01, 3.8575e-01, 8.4677e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: làm thế_nào chúng_ta chia_sẻ nhiều hơn những kí_ức của chúng_ta\n",
      "Reference: how can we share more of our memories of\n",
      "Model: <SOS> how do we spending more lot than that that\n",
      "Attention Weights: tensor([[9.9713e-01, 2.7766e-03, 8.9854e-05, 3.8285e-06, 1.3772e-06, 8.4658e-08,\n",
      "         3.9290e-09, 3.4131e-09, 1.6328e-10, 4.7647e-11],\n",
      "        [4.3209e-01, 4.3711e-01, 8.9653e-02, 3.6370e-02, 3.9423e-03, 6.6557e-04,\n",
      "         1.0052e-04, 4.5991e-05, 1.5041e-05, 8.6018e-06],\n",
      "        [1.8365e-01, 2.0744e-01, 2.2761e-01, 3.5944e-01, 1.7886e-02, 2.8007e-03,\n",
      "         7.2260e-04, 3.0198e-04, 8.1485e-05, 5.6372e-05],\n",
      "        [5.1813e-02, 4.3643e-02, 2.5166e-02, 7.8828e-01, 8.0173e-02, 8.3766e-03,\n",
      "         1.6407e-03, 6.4635e-04, 1.8965e-04, 7.4412e-05],\n",
      "        [1.9610e-04, 9.4619e-04, 4.4179e-04, 3.1395e-02, 5.9940e-01, 3.1958e-01,\n",
      "         3.3808e-02, 1.3083e-02, 9.1154e-04, 2.4413e-04],\n",
      "        [1.4566e-04, 7.2033e-04, 2.0747e-04, 7.2344e-02, 4.3449e-01, 2.9742e-01,\n",
      "         1.2215e-01, 6.7594e-02, 4.0108e-03, 9.1901e-04],\n",
      "        [3.5852e-05, 1.1496e-04, 6.1020e-05, 2.6050e-03, 1.0889e-02, 1.0262e-01,\n",
      "         2.1622e-01, 6.0054e-01, 4.0017e-02, 2.6902e-02],\n",
      "        [2.5124e-05, 1.0427e-04, 2.8987e-05, 1.1120e-03, 2.8343e-03, 2.5013e-02,\n",
      "         1.2495e-01, 6.5265e-01, 1.1226e-01, 8.1028e-02],\n",
      "        [3.7371e-04, 8.7575e-04, 2.1370e-04, 2.6795e-03, 4.1630e-03, 3.4837e-02,\n",
      "         1.2694e-01, 5.4326e-01, 1.3287e-01, 1.5378e-01]])\n",
      "\n",
      "Epoch: 4.14, Train Loss: 2.81, Val Loss: 4.09, Train BLEU: 15.47, Val BLEU: 10.79, Minutes Elapsed: 214.39\n",
      "Sampling from training predictions...\n",
      "Source: tôi có_một khối đá xỉ ở đây một_nửa đã được\n",
      "Reference: what i have here is a cinder block that\n",
      "Model: <SOS> i have have a big a cinder here here\n",
      "Attention Weights: tensor([[8.1265e-01, 1.8692e-01, 4.2315e-04, 7.9041e-06, 3.9406e-06, 5.9843e-07,\n",
      "         4.2829e-08, 1.8143e-08, 5.4554e-09, 3.8192e-09],\n",
      "        [4.2533e-02, 9.4864e-01, 8.1081e-03, 1.7830e-04, 4.9004e-04, 2.7092e-05,\n",
      "         8.4567e-06, 1.0195e-05, 2.7837e-06, 4.3443e-06],\n",
      "        [2.1815e-02, 8.1780e-01, 1.4320e-01, 1.0292e-02, 6.2749e-03, 3.7115e-04,\n",
      "         3.4677e-05, 1.0588e-04, 4.6509e-05, 6.0302e-05],\n",
      "        [6.0514e-02, 7.3361e-01, 1.6245e-01, 2.2828e-02, 1.7176e-02, 1.8306e-03,\n",
      "         2.7097e-04, 7.4643e-04, 2.6907e-04, 2.9842e-04],\n",
      "        [3.8865e-05, 9.5045e-03, 4.2023e-01, 2.6564e-01, 2.8750e-01, 1.2423e-02,\n",
      "         1.4695e-03, 2.5352e-03, 2.9406e-04, 3.7362e-04],\n",
      "        [1.7719e-04, 1.2241e-02, 2.9861e-01, 3.7258e-01, 2.1618e-01, 8.5489e-02,\n",
      "         6.0533e-03, 4.9483e-03, 2.4321e-03, 1.2914e-03],\n",
      "        [4.0656e-05, 3.5511e-03, 3.8417e-02, 1.5419e-01, 1.7757e-01, 5.0614e-01,\n",
      "         5.3896e-02, 3.9286e-02, 1.7730e-02, 9.1746e-03],\n",
      "        [5.2154e-05, 3.6144e-04, 2.6823e-03, 7.4647e-02, 8.6521e-02, 6.5540e-01,\n",
      "         9.8424e-02, 5.8731e-02, 1.4462e-02, 8.7199e-03],\n",
      "        [7.7438e-05, 2.2786e-04, 8.2346e-04, 1.4385e-02, 4.1689e-02, 6.7521e-01,\n",
      "         1.1601e-01, 1.0584e-01, 2.9247e-02, 1.6490e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi rất may_mắn được nuôi dạy trong một gia_đình rất\n",
      "Reference: i was very lucky to grow up in a\n",
      "Model: <SOS> i was fortunate fortunate to be a a a\n",
      "Attention Weights: tensor([[6.9893e-01, 3.0084e-01, 2.2667e-04, 8.3057e-06, 2.5906e-07, 5.7808e-08,\n",
      "         8.7266e-09, 6.1671e-09, 1.8467e-09, 1.3079e-09],\n",
      "        [2.7342e-02, 9.6772e-01, 4.6143e-03, 2.6020e-04, 5.2355e-05, 5.1397e-06,\n",
      "         3.7867e-06, 3.0525e-06, 1.9850e-06, 8.0134e-07],\n",
      "        [1.0753e-02, 7.2625e-01, 2.5139e-01, 1.0648e-02, 6.7260e-04, 2.0178e-04,\n",
      "         4.2059e-05, 2.0465e-05, 1.2273e-05, 7.4903e-06],\n",
      "        [3.1710e-04, 4.8157e-02, 6.9700e-01, 1.9626e-01, 3.6599e-02, 1.8819e-02,\n",
      "         1.7218e-03, 4.5173e-04, 4.8371e-04, 1.8843e-04],\n",
      "        [4.8835e-04, 3.3586e-03, 1.7265e-01, 4.8159e-01, 1.0201e-01, 2.0858e-01,\n",
      "         2.1289e-02, 4.9615e-03, 3.2231e-03, 1.8522e-03],\n",
      "        [3.9126e-05, 2.9631e-04, 1.9919e-02, 2.6509e-01, 1.1509e-01, 4.6018e-01,\n",
      "         1.0959e-01, 1.1506e-02, 1.1025e-02, 7.2603e-03],\n",
      "        [9.0507e-07, 1.0082e-05, 7.3513e-04, 1.0246e-01, 1.0160e-01, 3.7700e-01,\n",
      "         3.2018e-01, 5.6585e-02, 2.3873e-02, 1.7557e-02],\n",
      "        [2.8517e-06, 6.3489e-06, 4.4515e-04, 3.3761e-02, 1.1614e-01, 4.2361e-01,\n",
      "         2.3982e-01, 8.2858e-02, 6.4176e-02, 3.9173e-02],\n",
      "        [1.8731e-06, 3.1856e-06, 9.1520e-05, 1.6017e-02, 2.4992e-02, 6.1618e-02,\n",
      "         3.6740e-01, 2.3653e-01, 1.5967e-01, 1.3368e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4.19, Train Loss: 2.87, Val Loss: 4.08, Train BLEU: 15.02, Val BLEU: 10.58, Minutes Elapsed: 216.88\n",
      "Sampling from training predictions...\n",
      "Source: nhạc_sống , và nhạc thu âm . <EOS> <PAD> <PAD>\n",
      "Reference: there &apos;s live music , and there &apos;s recorded\n",
      "Model: <SOS> clearly , and , and and you &apos;s the\n",
      "Attention Weights: tensor([[0.9966, 0.0034, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.8001, 0.1963, 0.0032, 0.0004, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0963, 0.1299, 0.6422, 0.1202, 0.0108, 0.0005, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1335, 0.1230, 0.2002, 0.4166, 0.1123, 0.0124, 0.0014, 0.0005, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0994, 0.4209, 0.3029, 0.1528, 0.0207, 0.0022, 0.0007, 0.0003, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0098, 0.0492, 0.2383, 0.6152, 0.0763, 0.0082, 0.0017, 0.0013, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0048, 0.0037, 0.0306, 0.7572, 0.1822, 0.0136, 0.0040, 0.0039, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0067, 0.0063, 0.0045, 0.2250, 0.6713, 0.0805, 0.0042, 0.0013, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0198, 0.0061, 0.0022, 0.1222, 0.6445, 0.1848, 0.0177, 0.0028, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi có di_sản ở vùng nam_trung . <EOS> <PAD> <PAD>\n",
      "Reference: see , i have a legacy in south central\n",
      "Model: <SOS> i have i i in in in the .\n",
      "Attention Weights: tensor([[0.1069, 0.8897, 0.0031, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0704, 0.6536, 0.2727, 0.0025, 0.0004, 0.0003, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0119, 0.1168, 0.8324, 0.0309, 0.0051, 0.0030, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0827, 0.2273, 0.5261, 0.1079, 0.0366, 0.0190, 0.0003, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0589, 0.2641, 0.4698, 0.1321, 0.0452, 0.0292, 0.0005, 0.0002, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0009, 0.1417, 0.4343, 0.2651, 0.1535, 0.0036, 0.0006, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0002, 0.0166, 0.2213, 0.5059, 0.2473, 0.0067, 0.0019, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0001, 0.0009, 0.0277, 0.6998, 0.2479, 0.0132, 0.0104, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0001, 0.0007, 0.0121, 0.4163, 0.5148, 0.0402, 0.0156, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 4.24, Train Loss: 2.90, Val Loss: 4.07, Train BLEU: 14.25, Val BLEU: 10.29, Minutes Elapsed: 219.32\n",
      "Sampling from training predictions...\n",
      "Source: những loài chim khác , như loài tanager , cũng\n",
      "Reference: other birds , like this tanager , have adapted\n",
      "Model: <SOS> other birds birds like like tanager , the <UNK>\n",
      "Attention Weights: tensor([[3.5183e-01, 6.1759e-01, 2.9820e-02, 7.5532e-04, 3.0637e-06, 3.5148e-07,\n",
      "         9.0483e-08, 5.0303e-08, 4.0991e-09, 4.7281e-09],\n",
      "        [4.3648e-02, 2.8910e-01, 4.5356e-01, 1.9512e-01, 1.6330e-02, 1.2908e-03,\n",
      "         4.9542e-04, 3.3385e-04, 8.0789e-05, 3.7947e-05],\n",
      "        [8.6776e-03, 5.9156e-02, 4.3465e-01, 1.8725e-01, 2.7083e-01, 2.7959e-02,\n",
      "         7.3945e-03, 3.0909e-03, 6.4088e-04, 3.5311e-04],\n",
      "        [2.9317e-04, 2.5789e-03, 2.7259e-02, 9.4909e-02, 5.6607e-01, 1.9976e-01,\n",
      "         7.7442e-02, 2.4277e-02, 4.8554e-03, 2.5574e-03],\n",
      "        [5.5250e-05, 2.7708e-04, 1.4187e-03, 1.0062e-02, 7.5254e-02, 2.5671e-01,\n",
      "         4.8805e-01, 1.4082e-01, 1.0177e-02, 1.7169e-02],\n",
      "        [7.4721e-05, 1.9877e-03, 3.2351e-03, 2.5714e-03, 8.8998e-03, 7.6037e-02,\n",
      "         3.5854e-01, 2.7363e-01, 1.3289e-01, 1.4214e-01],\n",
      "        [1.5571e-05, 3.7742e-04, 6.2732e-04, 5.0441e-04, 4.5678e-03, 3.1097e-02,\n",
      "         1.2658e-01, 1.4868e-01, 2.9357e-01, 3.9398e-01],\n",
      "        [1.1550e-06, 3.8798e-05, 1.3127e-04, 1.2782e-04, 7.2915e-03, 1.7218e-01,\n",
      "         2.4248e-01, 1.5382e-01, 1.1502e-01, 3.0890e-01],\n",
      "        [8.9291e-06, 1.0838e-04, 4.0147e-04, 5.6414e-04, 1.8077e-03, 2.1353e-02,\n",
      "         2.2215e-01, 1.4505e-01, 1.0646e-01, 5.0210e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi chắc rằng bạn trong số những người đang nghe\n",
      "Reference: i promise you there are several people listening to\n",
      "Model: <SOS> i i sure you of you of who are\n",
      "Attention Weights: tensor([[1.2871e-02, 9.7283e-01, 1.4151e-02, 1.4523e-04, 4.3770e-06, 2.0654e-07,\n",
      "         1.2742e-07, 7.3189e-08, 1.2672e-07, 4.6694e-08],\n",
      "        [2.8048e-03, 9.8310e-01, 1.3953e-02, 7.0760e-05, 5.3873e-05, 5.7889e-06,\n",
      "         3.6178e-06, 1.1505e-06, 1.4892e-06, 1.0366e-06],\n",
      "        [3.4504e-03, 4.7013e-01, 4.9234e-01, 2.5623e-02, 7.6997e-03, 4.1721e-04,\n",
      "         1.6550e-04, 7.8662e-05, 5.2887e-05, 3.5266e-05],\n",
      "        [2.3915e-03, 6.7375e-02, 4.8392e-01, 2.6699e-01, 1.2786e-01, 2.7622e-02,\n",
      "         1.4190e-02, 5.4081e-03, 2.5340e-03, 1.7042e-03],\n",
      "        [7.8427e-05, 3.9086e-03, 2.3340e-02, 1.7425e-01, 5.2009e-01, 1.4809e-01,\n",
      "         7.5930e-02, 3.0621e-02, 1.3610e-02, 1.0082e-02],\n",
      "        [1.1803e-06, 2.2740e-05, 1.1840e-03, 2.7807e-02, 2.7625e-01, 4.5689e-01,\n",
      "         1.8484e-01, 3.8156e-02, 6.2043e-03, 8.6336e-03],\n",
      "        [1.9815e-06, 1.8652e-04, 1.4984e-03, 6.5342e-03, 3.1431e-01, 2.9457e-01,\n",
      "         1.9510e-01, 9.7251e-02, 4.5563e-02, 4.4986e-02],\n",
      "        [2.6370e-06, 4.0385e-05, 1.1253e-03, 1.2859e-03, 4.1694e-02, 9.1014e-02,\n",
      "         1.5940e-01, 2.6412e-01, 1.5911e-01, 2.8220e-01],\n",
      "        [2.2587e-05, 1.2355e-04, 3.3234e-03, 8.6207e-04, 5.5098e-03, 5.5501e-03,\n",
      "         4.1473e-02, 1.3167e-01, 3.9475e-01, 4.1671e-01]])\n",
      "\n",
      "Epoch: 4.29, Train Loss: 2.92, Val Loss: 4.09, Train BLEU: 15.18, Val BLEU: 10.17, Minutes Elapsed: 221.79\n",
      "Sampling from training predictions...\n",
      "Source: ta đều hiểu đau_đớn ở trong lòng ra_sao , và\n",
      "Reference: we all know what it is to have pain\n",
      "Model: <SOS> we &apos;re understand in in in in in ,\n",
      "Attention Weights: tensor([[3.5242e-03, 9.9375e-01, 2.7071e-03, 1.4869e-05, 1.3549e-07, 8.0031e-09,\n",
      "         1.6888e-09, 4.3640e-10, 1.8414e-10, 4.2188e-11],\n",
      "        [3.2850e-04, 8.2825e-01, 1.7074e-01, 6.5528e-04, 1.7161e-05, 2.9699e-06,\n",
      "         1.0611e-06, 5.8884e-07, 1.1647e-07, 4.9204e-08],\n",
      "        [1.4492e-03, 3.7044e-01, 5.2879e-01, 9.6925e-02, 2.2220e-03, 1.1534e-04,\n",
      "         3.1432e-05, 2.2616e-05, 2.5149e-06, 7.1648e-07],\n",
      "        [3.4683e-05, 1.7880e-03, 2.2401e-01, 7.1601e-01, 4.8376e-02, 7.6452e-03,\n",
      "         1.3458e-03, 7.2152e-04, 6.4029e-05, 4.7437e-06],\n",
      "        [1.9856e-05, 2.2807e-03, 1.2338e-01, 3.8886e-01, 1.9773e-01, 1.6980e-01,\n",
      "         8.2224e-02, 3.2276e-02, 3.1287e-03, 3.0779e-04],\n",
      "        [1.9037e-05, 2.9609e-03, 1.0244e-01, 2.3963e-01, 1.6601e-01, 1.4997e-01,\n",
      "         2.1955e-01, 1.0688e-01, 1.1670e-02, 8.6279e-04],\n",
      "        [3.4768e-05, 9.4773e-03, 1.5543e-01, 2.5346e-01, 1.6409e-01, 1.4847e-01,\n",
      "         1.5064e-01, 9.1762e-02, 2.4841e-02, 1.8039e-03],\n",
      "        [2.8088e-06, 6.4777e-05, 9.7253e-03, 3.2767e-02, 9.3608e-02, 1.5417e-01,\n",
      "         3.0896e-01, 2.5047e-01, 1.3331e-01, 1.6922e-02],\n",
      "        [6.2390e-06, 6.1145e-05, 2.5194e-03, 1.1936e-02, 3.7367e-02, 1.5259e-01,\n",
      "         4.3144e-01, 2.0687e-01, 1.0890e-01, 4.8316e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: anh ta kể với tôi về hai thứ . <EOS>\n",
      "Reference: he told me two things . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> he he me me two two <EOS> . two\n",
      "Attention Weights: tensor([[9.2276e-01, 2.3534e-02, 5.3554e-02, 1.4828e-04, 8.0833e-07, 7.8861e-08,\n",
      "         5.8621e-08, 6.4446e-09, 3.5614e-10, 2.0021e-10],\n",
      "        [2.4487e-03, 1.9868e-03, 9.9140e-01, 4.1147e-03, 1.6076e-05, 3.0633e-05,\n",
      "         1.3817e-06, 5.3688e-07, 4.0976e-08, 2.0613e-08],\n",
      "        [8.8164e-03, 1.5760e-02, 7.3246e-01, 2.2629e-01, 1.1235e-02, 5.0784e-03,\n",
      "         2.7394e-04, 7.6944e-05, 7.1881e-06, 3.8710e-06],\n",
      "        [6.4781e-04, 2.9441e-04, 6.7795e-02, 5.4361e-01, 2.2037e-01, 1.1754e-01,\n",
      "         3.3900e-02, 1.5372e-02, 3.2115e-04, 1.4791e-04],\n",
      "        [1.0455e-04, 4.8233e-05, 2.2580e-03, 3.6731e-02, 1.1602e-01, 3.7752e-01,\n",
      "         3.2005e-01, 1.4089e-01, 4.4644e-03, 1.9152e-03],\n",
      "        [1.0132e-05, 6.7062e-06, 3.8791e-04, 2.2245e-02, 3.9188e-02, 2.9938e-01,\n",
      "         3.8936e-01, 2.2469e-01, 1.7474e-02, 7.2516e-03],\n",
      "        [2.6054e-05, 1.0485e-05, 1.9887e-04, 2.3011e-03, 2.9676e-03, 7.6312e-02,\n",
      "         1.5379e-01, 3.9019e-01, 2.4024e-01, 1.3397e-01],\n",
      "        [1.8048e-04, 1.1742e-04, 1.6835e-03, 6.0908e-03, 4.8383e-03, 9.4754e-02,\n",
      "         2.5248e-01, 3.3628e-01, 1.1072e-01, 1.9286e-01],\n",
      "        [1.1066e-02, 3.4608e-03, 7.6401e-02, 5.6604e-02, 1.4160e-02, 3.1284e-01,\n",
      "         1.2146e-01, 1.5222e-01, 1.0605e-01, 1.4574e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4.38, Train Loss: 2.95, Val Loss: 4.08, Train BLEU: 13.90, Val BLEU: 10.48, Minutes Elapsed: 226.71\n",
      "Sampling from training predictions...\n",
      "Source: 6000 bản nhận_xét mỗi tuần ở từng trường ganh_đua cho\n",
      "Reference: six thousand reviews each school week vying for the\n",
      "Model: <SOS> she thousand of years vying in vying the the\n",
      "Attention Weights: tensor([[2.7927e-01, 7.1925e-01, 1.4230e-03, 5.8868e-05, 1.5158e-06, 2.7393e-07,\n",
      "         1.3238e-07, 2.3005e-08, 1.2593e-08, 1.5425e-08],\n",
      "        [3.1847e-02, 9.0611e-01, 6.0811e-02, 9.8918e-04, 2.1178e-04, 1.7987e-05,\n",
      "         5.3529e-06, 3.2240e-06, 3.3343e-06, 1.2877e-06],\n",
      "        [5.8392e-03, 6.6843e-01, 3.1344e-01, 1.0904e-02, 1.1190e-03, 1.3701e-04,\n",
      "         5.2547e-05, 3.7923e-05, 2.6167e-05, 1.4437e-05],\n",
      "        [5.3056e-03, 4.7611e-01, 2.6013e-01, 1.3321e-01, 9.8269e-02, 1.4565e-02,\n",
      "         2.6002e-03, 5.1887e-03, 2.9415e-03, 1.6896e-03],\n",
      "        [4.2230e-04, 2.7211e-02, 5.7625e-02, 2.5585e-01, 2.9565e-01, 2.3836e-01,\n",
      "         2.8527e-02, 4.0504e-02, 1.7381e-02, 3.8473e-02],\n",
      "        [3.8891e-05, 1.5747e-03, 6.7225e-03, 8.3234e-02, 1.9138e-01, 3.9839e-01,\n",
      "         9.8043e-02, 9.8532e-02, 6.1665e-02, 6.0423e-02],\n",
      "        [4.3586e-05, 6.9758e-04, 1.0334e-03, 9.9135e-03, 4.1292e-02, 2.5547e-01,\n",
      "         1.2937e-01, 2.5329e-01, 9.6805e-02, 2.1207e-01],\n",
      "        [5.6876e-05, 1.6453e-03, 4.4304e-03, 1.8901e-02, 2.7474e-02, 2.6361e-01,\n",
      "         2.4747e-01, 2.1858e-01, 8.8064e-02, 1.2977e-01],\n",
      "        [2.1995e-04, 3.2097e-03, 5.9943e-03, 2.1462e-02, 1.8754e-02, 1.7501e-01,\n",
      "         2.6831e-01, 2.7518e-01, 1.0192e-01, 1.2995e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: hàng năm , có vô_số người bắc triều_tiên bị bắt\n",
      "Reference: every year , countless north koreans are caught in\n",
      "Model: <SOS> in , , there was the the the by\n",
      "Attention Weights: tensor([[9.9623e-01, 3.7385e-03, 2.7243e-05, 1.7808e-06, 3.1417e-08, 5.1983e-10,\n",
      "         1.8581e-10, 8.1438e-11, 8.3179e-12, 3.0396e-12],\n",
      "        [8.4121e-01, 1.2055e-01, 3.7607e-02, 3.6772e-04, 1.2750e-04, 7.6748e-05,\n",
      "         4.9834e-05, 7.0488e-06, 8.0860e-07, 3.0552e-07],\n",
      "        [2.5765e-01, 9.8567e-02, 3.7362e-01, 1.6055e-01, 4.6706e-02, 3.0274e-02,\n",
      "         2.6625e-02, 4.9833e-03, 8.5961e-04, 1.6986e-04],\n",
      "        [6.9779e-03, 3.4336e-03, 7.8630e-02, 6.1980e-01, 1.7493e-01, 5.5158e-02,\n",
      "         4.5583e-02, 1.1330e-02, 3.0800e-03, 1.0765e-03],\n",
      "        [2.2266e-03, 4.7016e-04, 4.3381e-03, 2.1932e-01, 2.9524e-01, 1.2646e-01,\n",
      "         1.9778e-01, 1.1394e-01, 2.9182e-02, 1.1043e-02],\n",
      "        [1.6717e-03, 3.0099e-04, 1.0413e-03, 1.4902e-02, 1.7786e-01, 2.0415e-01,\n",
      "         4.3624e-01, 1.2634e-01, 3.1631e-02, 5.8618e-03],\n",
      "        [9.1061e-06, 1.9409e-05, 1.2857e-04, 1.6208e-03, 7.7004e-03, 2.9777e-02,\n",
      "         3.0104e-01, 2.1399e-01, 3.3565e-01, 1.1006e-01],\n",
      "        [2.0373e-05, 3.6020e-05, 5.6432e-04, 5.9565e-03, 7.5639e-03, 1.0254e-02,\n",
      "         3.8958e-02, 4.8375e-02, 3.7773e-01, 5.1055e-01],\n",
      "        [2.3834e-04, 4.8812e-04, 1.2259e-04, 2.2244e-04, 5.1118e-04, 2.6931e-03,\n",
      "         5.0230e-02, 1.4749e-01, 4.1417e-01, 3.8384e-01]])\n",
      "\n",
      "Epoch: 4.43, Train Loss: 3.00, Val Loss: 4.05, Train BLEU: 13.73, Val BLEU: 11.14, Minutes Elapsed: 229.18\n",
      "Sampling from training predictions...\n",
      "Source: và nó sẽ hỏng cả nếu đặt vào địa_điểm như\n",
      "Reference: and it would be a mess in a context\n",
      "Model: <SOS> and it would going the to to the to\n",
      "Attention Weights: tensor([[6.0783e-02, 9.0921e-01, 2.8391e-02, 1.5554e-03, 5.6445e-05, 1.2394e-06,\n",
      "         9.8842e-07, 1.2742e-07, 7.4686e-08, 7.6236e-09],\n",
      "        [2.0351e-02, 9.6257e-01, 1.6611e-02, 4.4577e-04, 2.1845e-05, 1.2076e-06,\n",
      "         1.2779e-06, 2.5797e-07, 1.2420e-07, 3.2105e-08],\n",
      "        [1.5701e-04, 1.4539e-01, 6.4776e-01, 2.0044e-01, 5.9086e-03, 1.1397e-04,\n",
      "         1.3146e-04, 7.5145e-05, 1.7337e-05, 4.6133e-06],\n",
      "        [2.8246e-04, 2.1390e-02, 3.0068e-01, 5.9187e-01, 8.1503e-02, 2.3972e-03,\n",
      "         1.0973e-03, 6.2837e-04, 1.2426e-04, 3.1794e-05],\n",
      "        [1.3425e-04, 7.9469e-04, 1.5289e-02, 3.8714e-01, 4.7897e-01, 7.2511e-02,\n",
      "         2.7970e-02, 1.2916e-02, 3.9358e-03, 3.3683e-04],\n",
      "        [1.1320e-04, 3.4357e-04, 4.3623e-03, 2.5411e-01, 3.3247e-01, 1.2962e-01,\n",
      "         1.6305e-01, 8.0553e-02, 3.1134e-02, 4.2516e-03],\n",
      "        [2.7011e-05, 2.1592e-04, 3.5163e-03, 3.3806e-02, 1.5894e-01, 1.9321e-01,\n",
      "         2.8092e-01, 1.7077e-01, 1.1638e-01, 4.2213e-02],\n",
      "        [8.8084e-06, 7.5153e-05, 1.4983e-03, 7.8246e-03, 8.6862e-02, 2.7942e-01,\n",
      "         2.2881e-01, 1.8400e-01, 1.4458e-01, 6.6920e-02],\n",
      "        [9.7728e-07, 9.1875e-06, 5.0293e-04, 2.1927e-03, 5.1640e-03, 2.8058e-02,\n",
      "         2.1362e-01, 3.5170e-01, 2.9751e-01, 1.0124e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: điều đó sẽ thực_sự miễn một chuyến đi đến phòng_khám\n",
      "Reference: now , that would actually save on a difficult\n",
      "Model: <SOS> that would would would would a a a to\n",
      "Attention Weights: tensor([[9.7822e-01, 2.1187e-02, 5.8217e-04, 5.7277e-06, 2.5302e-09, 6.1256e-10,\n",
      "         5.8621e-11, 8.8834e-11, 1.1249e-11, 3.5972e-12],\n",
      "        [2.8193e-01, 1.1907e-01, 4.6058e-01, 1.3705e-01, 1.2872e-03, 4.8942e-05,\n",
      "         2.4474e-05, 3.5282e-06, 2.8860e-06, 3.6391e-06],\n",
      "        [1.5479e-02, 4.0448e-03, 2.1237e-01, 6.9941e-01, 6.4796e-02, 2.1469e-03,\n",
      "         1.4505e-03, 1.6659e-04, 9.7718e-05, 3.9879e-05],\n",
      "        [2.6087e-02, 1.1503e-02, 2.8329e-01, 5.5837e-01, 1.1357e-01, 4.4413e-03,\n",
      "         2.3156e-03, 2.6187e-04, 1.1244e-04, 4.6898e-05],\n",
      "        [2.6282e-02, 1.2053e-02, 2.9162e-01, 5.3203e-01, 1.2641e-01, 6.9769e-03,\n",
      "         3.8212e-03, 5.0601e-04, 2.1506e-04, 8.0024e-05],\n",
      "        [4.1056e-03, 6.5589e-04, 4.1997e-02, 4.8370e-01, 3.6072e-01, 6.5259e-02,\n",
      "         3.0122e-02, 9.6001e-03, 2.8472e-03, 9.9426e-04],\n",
      "        [1.3698e-04, 3.1285e-05, 1.8005e-03, 1.8611e-01, 4.4621e-01, 1.5204e-01,\n",
      "         9.3092e-02, 8.7395e-02, 2.4605e-02, 8.5813e-03],\n",
      "        [4.4875e-06, 1.1758e-06, 6.3408e-04, 3.0775e-02, 1.1896e-01, 1.2798e-01,\n",
      "         3.4899e-01, 2.0022e-01, 1.1365e-01, 5.8775e-02],\n",
      "        [8.5850e-06, 4.7183e-06, 1.1354e-04, 7.6730e-04, 6.4435e-03, 3.8827e-02,\n",
      "         1.9359e-01, 1.3777e-01, 2.7243e-01, 3.5005e-01]])\n",
      "\n",
      "Epoch: 4.48, Train Loss: 2.96, Val Loss: 4.04, Train BLEU: 13.39, Val BLEU: 10.80, Minutes Elapsed: 231.63\n",
      "Sampling from training predictions...\n",
      "Source: nhưng điều thực_sự thú_vị là_vì cô ấy nói , \"\n",
      "Reference: but it was actually more interesting than that ,\n",
      "Model: <SOS> but the really interesting interesting that she she said\n",
      "Attention Weights: tensor([[5.2012e-03, 9.5301e-01, 4.1662e-02, 1.2551e-04, 2.1132e-07, 2.0602e-08,\n",
      "         2.0146e-09, 6.5231e-11, 1.4089e-11, 7.1027e-12],\n",
      "        [2.5064e-03, 8.8295e-01, 1.1309e-01, 1.4190e-03, 2.9718e-05, 2.2438e-06,\n",
      "         3.3312e-07, 1.1557e-08, 3.0589e-09, 2.7577e-09],\n",
      "        [1.7662e-03, 1.4173e-01, 7.4212e-01, 1.0463e-01, 9.1796e-03, 4.2574e-04,\n",
      "         1.3211e-04, 1.7707e-05, 1.1160e-06, 7.4482e-07],\n",
      "        [1.9797e-02, 4.8850e-02, 3.1808e-01, 4.2259e-01, 1.2958e-01, 3.4734e-02,\n",
      "         2.0587e-02, 5.3593e-03, 3.5798e-04, 6.9113e-05],\n",
      "        [9.3968e-03, 3.0476e-02, 1.5250e-01, 4.8300e-01, 2.0525e-01, 6.3474e-02,\n",
      "         4.4304e-02, 1.0518e-02, 8.7697e-04, 1.9872e-04],\n",
      "        [6.0624e-03, 4.4356e-02, 1.7267e-01, 2.5725e-01, 2.9309e-01, 1.3763e-01,\n",
      "         7.1043e-02, 1.3042e-02, 2.9932e-03, 1.8615e-03],\n",
      "        [1.6014e-04, 1.8929e-03, 2.7318e-02, 1.5629e-01, 5.4140e-01, 1.1058e-01,\n",
      "         9.1149e-02, 5.4783e-02, 1.0597e-02, 5.8263e-03],\n",
      "        [5.2158e-05, 7.2396e-04, 7.6744e-03, 7.0587e-02, 4.8082e-01, 1.1895e-01,\n",
      "         9.5149e-02, 1.4183e-01, 5.6034e-02, 2.8178e-02],\n",
      "        [7.7121e-06, 8.1129e-05, 1.5392e-03, 9.8586e-03, 8.4197e-02, 1.0189e-01,\n",
      "         1.0275e-01, 2.1741e-01, 1.9014e-01, 2.9213e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: một sự ước_lượng dè_dặt cho chúng_tôi biết có hơn 27\n",
      "Reference: a conservative estimate tells us there are more than\n",
      "Model: <SOS> a of of us we that about 27 27\n",
      "Attention Weights: tensor([[3.7902e-01, 4.0761e-01, 2.1227e-01, 1.0702e-03, 2.8056e-05, 8.6997e-07,\n",
      "         2.6899e-07, 1.9695e-08, 1.6112e-08, 7.3418e-09],\n",
      "        [1.5441e-03, 8.1552e-03, 9.4712e-01, 3.8843e-02, 4.0595e-03, 1.5564e-04,\n",
      "         6.8544e-05, 2.3408e-05, 1.6055e-05, 1.3396e-05],\n",
      "        [2.5788e-02, 3.6258e-02, 5.1061e-01, 2.8588e-01, 1.3094e-01, 6.5074e-03,\n",
      "         2.6978e-03, 7.5441e-04, 3.7043e-04, 1.9132e-04],\n",
      "        [1.6789e-04, 3.1303e-04, 3.1822e-02, 3.6685e-01, 5.3594e-01, 4.5236e-02,\n",
      "         1.6423e-02, 2.1199e-03, 7.8618e-04, 3.4123e-04],\n",
      "        [5.0783e-06, 1.2643e-05, 7.5387e-04, 3.9094e-03, 9.8820e-02, 1.6998e-01,\n",
      "         6.0951e-01, 7.6402e-02, 3.2465e-02, 8.1365e-03],\n",
      "        [1.0482e-05, 1.9653e-05, 1.3434e-04, 5.7077e-04, 7.5500e-03, 5.6931e-02,\n",
      "         4.7173e-01, 1.9966e-01, 2.2928e-01, 3.4114e-02],\n",
      "        [9.6071e-07, 2.2039e-06, 4.5469e-05, 1.5720e-04, 4.5319e-04, 2.2290e-03,\n",
      "         2.2008e-02, 1.3699e-01, 4.3628e-01, 4.0183e-01],\n",
      "        [1.0273e-06, 1.5649e-06, 1.5401e-05, 5.9407e-05, 2.6903e-04, 4.9846e-04,\n",
      "         3.6692e-03, 1.9714e-02, 1.8383e-01, 7.9194e-01],\n",
      "        [7.2308e-06, 8.2531e-06, 3.9924e-05, 2.1423e-04, 1.6099e-03, 1.4726e-03,\n",
      "         1.0744e-02, 5.5695e-02, 2.7514e-01, 6.5507e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4.53, Train Loss: 2.96, Val Loss: 4.05, Train BLEU: 14.83, Val BLEU: 11.06, Minutes Elapsed: 234.15\n",
      "Sampling from training predictions...\n",
      "Source: hai thứ này kết_hợp với_nhau mang đến một thứ âm_nhạc\n",
      "Reference: so those two things combined meant that a different\n",
      "Model: <SOS> these two things things combined bring together a is\n",
      "Attention Weights: tensor([[9.9676e-01, 3.2085e-03, 3.0489e-05, 2.2386e-07, 6.7354e-08, 3.1004e-08,\n",
      "         2.0146e-08, 4.2303e-09, 7.1572e-10, 2.4398e-10],\n",
      "        [6.0867e-01, 3.8423e-01, 4.0690e-03, 2.3397e-03, 5.4694e-04, 1.0975e-04,\n",
      "         1.8465e-05, 7.2926e-06, 1.0435e-05, 4.3334e-06],\n",
      "        [2.7404e-01, 4.0273e-01, 1.0598e-01, 1.5125e-01, 5.3354e-02, 1.0311e-02,\n",
      "         1.5132e-03, 4.5186e-04, 2.7263e-04, 9.4806e-05],\n",
      "        [2.3662e-01, 3.3620e-01, 9.5355e-02, 2.1890e-01, 9.2062e-02, 1.8554e-02,\n",
      "         1.6777e-03, 3.3349e-04, 2.4820e-04, 6.1483e-05],\n",
      "        [4.3466e-03, 2.5207e-02, 8.7653e-02, 3.4536e-01, 3.6749e-01, 1.4136e-01,\n",
      "         2.0979e-02, 4.5875e-03, 2.2394e-03, 7.7890e-04],\n",
      "        [1.0552e-04, 3.1557e-04, 3.2089e-03, 3.4192e-02, 1.8653e-01, 4.6753e-01,\n",
      "         2.2450e-01, 6.1543e-02, 1.6220e-02, 5.8458e-03],\n",
      "        [7.4782e-04, 4.4334e-03, 3.4079e-03, 4.7829e-02, 1.9205e-01, 2.1372e-01,\n",
      "         1.8458e-01, 1.9581e-01, 1.2028e-01, 3.7143e-02],\n",
      "        [3.6719e-05, 7.5930e-05, 2.3138e-04, 1.3569e-03, 7.7581e-03, 5.9267e-02,\n",
      "         1.2544e-01, 1.6014e-01, 4.1640e-01, 2.2929e-01],\n",
      "        [2.7994e-04, 3.3994e-04, 3.2941e-04, 3.5769e-03, 9.9332e-03, 5.1258e-02,\n",
      "         7.8105e-02, 1.1330e-01, 4.4331e-01, 2.9957e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: trước_tiên , bạn phải mang đến cho họ sự bảo_mật\n",
      "Reference: first , you have to offer them <UNK> .\n",
      "Model: <SOS> first , all have to give them a <EOS>\n",
      "Attention Weights: tensor([[9.9999e-01, 2.3973e-06, 6.0702e-08, 2.7994e-06, 3.7871e-08, 2.2198e-09,\n",
      "         1.4584e-10, 4.7655e-12, 3.2014e-12, 1.9313e-12],\n",
      "        [9.7722e-01, 2.0275e-02, 1.1557e-03, 1.2368e-03, 8.4617e-05, 1.6855e-05,\n",
      "         5.4566e-06, 1.2362e-06, 6.7170e-07, 3.8128e-07],\n",
      "        [5.0421e-01, 1.0378e-01, 1.4194e-01, 1.6673e-01, 6.3442e-02, 1.3858e-02,\n",
      "         4.2710e-03, 9.2847e-04, 5.6360e-04, 2.7766e-04],\n",
      "        [2.6714e-03, 3.8877e-02, 2.1423e-01, 6.3142e-01, 6.6267e-02, 2.3872e-02,\n",
      "         1.4023e-02, 4.1065e-03, 2.6245e-03, 1.9136e-03],\n",
      "        [4.2980e-03, 3.0011e-03, 4.2457e-03, 3.9538e-01, 5.3556e-01, 3.6223e-02,\n",
      "         1.5434e-02, 2.8571e-03, 2.0173e-03, 9.8470e-04],\n",
      "        [5.4831e-04, 1.6507e-04, 7.6141e-04, 4.2180e-03, 4.5299e-01, 3.6594e-01,\n",
      "         1.3188e-01, 2.5228e-02, 1.1882e-02, 6.3901e-03],\n",
      "        [1.5318e-05, 2.1052e-05, 4.8965e-05, 3.2526e-04, 1.1011e-01, 2.3717e-01,\n",
      "         3.2710e-01, 1.5010e-01, 1.1794e-01, 5.7162e-02],\n",
      "        [2.1672e-05, 8.3184e-06, 2.2167e-05, 2.7844e-05, 4.4258e-03, 2.7166e-02,\n",
      "         2.1739e-01, 1.8859e-01, 2.5292e-01, 3.0942e-01],\n",
      "        [1.6638e-05, 1.4735e-05, 5.7900e-06, 6.0539e-06, 1.0013e-03, 5.2900e-03,\n",
      "         3.1328e-02, 3.4295e-02, 1.7245e-01, 7.5560e-01]])\n",
      "\n",
      "Epoch: 4.58, Train Loss: 2.98, Val Loss: 4.03, Train BLEU: 14.84, Val BLEU: 11.13, Minutes Elapsed: 236.62\n",
      "Sampling from training predictions...\n",
      "Source: bạn có_thể phân_tích ngũ_cốc của bạn để tìm thực_phẩm biến_đổi\n",
      "Reference: you can analyze your breakfast cereal for gmo &apos;s\n",
      "Model: <SOS> you can spray your power of to the to\n",
      "Attention Weights: tensor([[8.7490e-01, 1.2366e-01, 1.2413e-03, 1.9382e-04, 3.1116e-06, 4.7959e-07,\n",
      "         6.5268e-08, 9.8940e-09, 5.9951e-09, 3.2192e-09],\n",
      "        [5.6290e-02, 8.2542e-01, 1.1549e-01, 2.4751e-03, 9.0813e-05, 3.7727e-05,\n",
      "         1.0284e-04, 7.4713e-05, 1.5284e-05, 4.9088e-06],\n",
      "        [1.6621e-03, 3.7506e-02, 9.4582e-01, 1.4339e-02, 1.1933e-04, 9.0959e-05,\n",
      "         1.9647e-04, 2.0593e-04, 4.8037e-05, 1.5011e-05],\n",
      "        [4.8680e-04, 2.9915e-03, 6.7730e-02, 9.1353e-01, 7.1231e-03, 3.6887e-03,\n",
      "         1.7434e-03, 1.6856e-03, 6.0164e-04, 4.1445e-04],\n",
      "        [1.1421e-04, 1.6644e-04, 2.5219e-02, 9.1132e-01, 4.0942e-02, 1.2672e-02,\n",
      "         3.7614e-03, 3.0877e-03, 1.3598e-03, 1.3544e-03],\n",
      "        [1.1566e-04, 3.7205e-04, 2.0655e-03, 1.3232e-01, 2.1875e-01, 1.5923e-01,\n",
      "         3.3349e-01, 1.1838e-01, 2.3563e-02, 1.1718e-02],\n",
      "        [5.5903e-06, 2.4859e-05, 1.0325e-03, 2.3711e-02, 6.6872e-02, 1.4692e-01,\n",
      "         2.9693e-01, 3.5728e-01, 6.3180e-02, 4.4041e-02],\n",
      "        [8.6860e-07, 6.4090e-06, 2.3501e-04, 3.5362e-03, 4.7994e-03, 2.0509e-02,\n",
      "         4.8592e-02, 4.4592e-01, 3.1239e-01, 1.6401e-01],\n",
      "        [4.6901e-05, 9.9766e-05, 2.9485e-04, 1.1491e-02, 1.4064e-02, 1.2534e-02,\n",
      "         2.9954e-02, 1.9868e-01, 3.0634e-01, 4.2650e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: chúng_tôi đã giúp khởi_động 40,000 công_việc làm_ăn . <EOS> <PAD>\n",
      "Reference: we have helped to start 40,000 businesses . <EOS>\n",
      "Model: <SOS> we we the . do . <EOS> do <EOS>\n",
      "Attention Weights: tensor([[0.0410, 0.8206, 0.1343, 0.0040, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0078, 0.1775, 0.8038, 0.0107, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0024, 0.0320, 0.7915, 0.1708, 0.0025, 0.0006, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0007, 0.0004, 0.0760, 0.7917, 0.0822, 0.0466, 0.0022, 0.0003, 0.0001,\n",
      "         0.0000],\n",
      "        [0.0012, 0.0023, 0.0456, 0.0972, 0.1301, 0.6770, 0.0278, 0.0139, 0.0048,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0003, 0.0065, 0.0600, 0.0941, 0.7775, 0.0531, 0.0059, 0.0024,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0001, 0.0027, 0.0362, 0.0811, 0.7883, 0.0724, 0.0136, 0.0056,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0002, 0.0027, 0.0091, 0.0146, 0.8870, 0.0687, 0.0129, 0.0048,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0012, 0.0371, 0.0755, 0.0359, 0.4235, 0.3287, 0.0815, 0.0164,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 4.62, Train Loss: 2.96, Val Loss: 4.04, Train BLEU: 14.82, Val BLEU: 11.50, Minutes Elapsed: 239.09\n",
      "Sampling from training predictions...\n",
      "Source: mà là xây nên một thế_giới để dạy nhau cách\n",
      "Reference: it &apos;s in building a world where we teach\n",
      "Model: <SOS> it &apos;s a a way to to to ways\n",
      "Attention Weights: tensor([[9.0939e-01, 8.9520e-02, 1.0858e-03, 1.4356e-06, 8.1165e-08, 2.2225e-08,\n",
      "         1.8497e-09, 1.2601e-09, 4.8939e-10, 4.3855e-11],\n",
      "        [4.5753e-02, 3.3190e-01, 6.1425e-01, 6.6892e-03, 8.3466e-04, 4.6074e-04,\n",
      "         6.4169e-05, 3.7091e-05, 7.8782e-06, 1.5487e-06],\n",
      "        [5.4202e-02, 1.3490e-01, 6.3176e-01, 1.5375e-01, 1.3178e-02, 1.0224e-02,\n",
      "         9.4809e-04, 7.6714e-04, 1.7207e-04, 9.5876e-05],\n",
      "        [2.3047e-04, 2.1703e-03, 1.7956e-01, 4.6832e-01, 2.0502e-01, 1.3780e-01,\n",
      "         2.8631e-03, 2.5443e-03, 9.0210e-04, 5.9721e-04],\n",
      "        [1.4312e-04, 1.5179e-03, 8.0634e-02, 1.6919e-01, 1.5420e-01, 5.0730e-01,\n",
      "         5.4219e-02, 2.3938e-02, 4.6619e-03, 4.1868e-03],\n",
      "        [6.6656e-04, 1.7042e-03, 1.3084e-02, 6.9007e-02, 4.4733e-02, 6.0726e-01,\n",
      "         1.3539e-01, 1.0744e-01, 8.6971e-03, 1.2012e-02],\n",
      "        [4.8596e-06, 1.1530e-05, 7.6021e-04, 4.4961e-03, 3.0671e-02, 3.4919e-01,\n",
      "         1.0858e-01, 3.7577e-01, 5.4634e-02, 7.5877e-02],\n",
      "        [4.4471e-06, 1.1812e-05, 4.6608e-04, 2.9582e-03, 2.1503e-03, 7.1436e-02,\n",
      "         2.3122e-01, 5.0910e-01, 3.8238e-02, 1.4442e-01],\n",
      "        [1.4088e-06, 4.9829e-06, 1.3899e-04, 1.5140e-03, 3.0164e-03, 2.6313e-02,\n",
      "         2.0645e-02, 5.4476e-01, 7.1786e-02, 3.3182e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: chúng_tôi đã rất sợ , nhưng dù vậy , chúng_tôi\n",
      "Reference: we were scared , but still , school was\n",
      "Model: <SOS> we &apos;ve very , but we , we we\n",
      "Attention Weights: tensor([[1.8745e-02, 6.9934e-01, 2.8080e-01, 1.1155e-03, 1.1613e-06, 8.2545e-08,\n",
      "         3.7286e-08, 4.8871e-09, 2.7851e-10, 1.1015e-09],\n",
      "        [5.1957e-03, 1.5401e-01, 8.3824e-01, 2.5505e-03, 5.4282e-06, 6.0435e-07,\n",
      "         1.6359e-06, 4.9559e-07, 6.4510e-08, 6.9777e-08],\n",
      "        [6.2266e-04, 5.6776e-02, 7.7605e-01, 1.6296e-01, 2.9830e-03, 9.9183e-05,\n",
      "         2.8286e-04, 2.1407e-04, 7.8127e-06, 2.8048e-06],\n",
      "        [7.0475e-04, 1.6766e-04, 1.0794e-02, 4.9349e-01, 4.6118e-01, 2.8768e-02,\n",
      "         3.5200e-03, 1.0925e-03, 2.6337e-04, 1.8771e-05],\n",
      "        [4.6736e-03, 6.3574e-04, 3.9795e-03, 1.2385e-01, 3.9195e-01, 4.4186e-01,\n",
      "         2.5173e-02, 5.4596e-03, 1.7790e-03, 6.4626e-04],\n",
      "        [5.8053e-03, 9.4745e-04, 1.3654e-02, 1.7370e-02, 8.7556e-02, 6.0154e-01,\n",
      "         2.1597e-01, 4.0971e-02, 1.2261e-02, 3.9269e-03],\n",
      "        [1.2050e-03, 1.2202e-02, 3.7090e-02, 7.0118e-03, 4.8975e-03, 3.7215e-02,\n",
      "         5.1682e-01, 2.8547e-01, 6.8632e-02, 2.9461e-02],\n",
      "        [1.5140e-04, 1.5784e-03, 3.6083e-02, 9.7157e-03, 2.1150e-03, 1.0733e-02,\n",
      "         2.6053e-01, 3.5542e-01, 2.6543e-01, 5.8243e-02],\n",
      "        [3.0240e-04, 2.7943e-03, 7.4280e-03, 1.7386e-03, 1.4277e-03, 4.4032e-03,\n",
      "         5.1649e-02, 8.8111e-02, 3.0647e-01, 5.3568e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4.67, Train Loss: 3.03, Val Loss: 4.08, Train BLEU: 13.23, Val BLEU: 10.11, Minutes Elapsed: 241.60\n",
      "Sampling from training predictions...\n",
      "Source: ông ấy có_thể , một_cách rất sáng_tạo , thay_đổi gam\n",
      "Reference: he can , very innovatively , actually change keys\n",
      "Model: <SOS> he he , , innovatively , , , the\n",
      "Attention Weights: tensor([[7.8062e-01, 2.1334e-01, 6.0256e-03, 1.2555e-05, 1.2154e-06, 3.0567e-07,\n",
      "         4.0929e-08, 1.0268e-10, 8.6968e-11, 4.7874e-11],\n",
      "        [6.7219e-02, 7.2379e-01, 1.9505e-01, 8.5668e-03, 3.3210e-03, 1.8370e-03,\n",
      "         1.9859e-04, 6.5274e-06, 6.5539e-06, 4.5294e-06],\n",
      "        [6.7386e-03, 1.4876e-01, 2.2000e-01, 4.3914e-01, 6.7538e-02, 9.0098e-02,\n",
      "         2.4454e-02, 2.0245e-03, 7.0578e-04, 5.4155e-04],\n",
      "        [3.8743e-04, 7.7464e-03, 1.0781e-02, 2.6236e-01, 5.5106e-01, 1.4316e-01,\n",
      "         2.2092e-02, 1.8151e-03, 4.8264e-04, 1.1992e-04],\n",
      "        [2.7058e-04, 1.8394e-03, 1.3650e-03, 7.0538e-02, 6.9051e-01, 1.7781e-01,\n",
      "         5.1757e-02, 3.0898e-03, 2.4270e-03, 3.9763e-04],\n",
      "        [1.5062e-03, 8.3264e-03, 4.2368e-03, 5.5642e-02, 1.5941e-01, 3.5945e-01,\n",
      "         3.6928e-01, 2.9580e-02, 7.1230e-03, 5.4510e-03],\n",
      "        [2.9470e-05, 1.1559e-04, 5.9163e-05, 2.0294e-03, 4.0889e-02, 1.1131e-01,\n",
      "         2.2734e-01, 4.0028e-01, 1.7018e-01, 4.7762e-02],\n",
      "        [2.9316e-05, 6.7894e-05, 1.1790e-05, 1.1457e-04, 1.3650e-02, 1.1820e-02,\n",
      "         1.2228e-02, 3.3634e-02, 8.1290e-01, 1.1555e-01],\n",
      "        [4.7562e-05, 2.3163e-04, 7.0953e-05, 2.8982e-04, 1.2032e-02, 3.6137e-02,\n",
      "         2.0697e-02, 1.5096e-02, 2.6697e-01, 6.4842e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: nhờ phát_minh này , tôi đã may_mắn nhận được học_bổng\n",
      "Reference: because of this invention , i was lucky to\n",
      "Model: <SOS> so this this , , i was understood to\n",
      "Attention Weights: tensor([[6.6967e-01, 3.3005e-01, 2.7229e-04, 3.5289e-07, 3.7219e-08, 1.5352e-07,\n",
      "         1.2560e-08, 7.8817e-09, 7.4602e-10, 1.8868e-10],\n",
      "        [3.6992e-02, 9.5883e-01, 2.5284e-03, 1.5109e-03, 4.0641e-05, 6.4287e-05,\n",
      "         1.9115e-05, 8.9803e-06, 7.3233e-07, 4.0917e-07],\n",
      "        [9.2517e-02, 6.6397e-01, 4.7191e-02, 1.5808e-01, 9.6929e-03, 1.6495e-02,\n",
      "         7.6678e-03, 3.8205e-03, 3.6527e-04, 1.9374e-04],\n",
      "        [7.3653e-02, 4.9322e-01, 9.7573e-02, 2.2453e-01, 2.1683e-02, 4.6399e-02,\n",
      "         3.4680e-02, 6.4096e-03, 1.1630e-03, 6.8836e-04],\n",
      "        [5.4895e-03, 5.1608e-02, 3.7110e-02, 6.2985e-01, 1.9234e-01, 6.0085e-02,\n",
      "         1.9343e-02, 3.3897e-03, 4.4595e-04, 3.3529e-04],\n",
      "        [9.6817e-04, 2.3203e-02, 5.5616e-03, 3.3444e-01, 4.2676e-01, 1.2975e-01,\n",
      "         7.1446e-02, 6.5102e-03, 9.4335e-04, 4.1519e-04],\n",
      "        [1.0480e-03, 2.1008e-02, 4.9033e-04, 3.4830e-02, 8.1510e-02, 2.0190e-01,\n",
      "         4.8629e-01, 1.6080e-01, 9.0103e-03, 3.1125e-03],\n",
      "        [6.8506e-05, 2.5504e-03, 1.2881e-04, 2.2689e-03, 4.0555e-03, 8.0374e-02,\n",
      "         5.6021e-01, 2.3219e-01, 6.2445e-02, 5.5703e-02],\n",
      "        [3.5668e-04, 4.1191e-03, 7.9113e-05, 2.2125e-03, 2.9581e-03, 2.8365e-03,\n",
      "         1.0429e-01, 5.3202e-01, 5.6660e-02, 2.9446e-01]])\n",
      "\n",
      "Epoch: 4.72, Train Loss: 3.02, Val Loss: 4.05, Train BLEU: 14.07, Val BLEU: 11.11, Minutes Elapsed: 244.13\n",
      "Sampling from training predictions...\n",
      "Source: mc sẽ ứng_tấu lời bài_hát theo cái cách tương_tự với\n",
      "Reference: the mc would improvise lyrics in the same way\n",
      "Model: <SOS> the mc would be the song the way to\n",
      "Attention Weights: tensor([[9.9970e-01, 2.9935e-04, 4.8838e-07, 3.3592e-07, 3.1192e-08, 9.6127e-10,\n",
      "         3.2780e-10, 7.3740e-11, 2.1465e-11, 3.2720e-11],\n",
      "        [7.4372e-01, 2.3491e-01, 1.7815e-02, 2.9355e-03, 4.6562e-04, 8.5110e-05,\n",
      "         3.9513e-05, 1.1801e-05, 8.1833e-06, 4.9896e-06],\n",
      "        [3.5633e-02, 7.2874e-01, 1.2726e-01, 7.6798e-02, 2.7007e-02, 3.4463e-03,\n",
      "         6.7513e-04, 2.7637e-04, 1.0407e-04, 5.8909e-05],\n",
      "        [3.8810e-03, 2.7302e-01, 4.1699e-01, 2.6400e-01, 3.7055e-02, 3.1869e-03,\n",
      "         9.9338e-04, 4.6731e-04, 2.7996e-04, 1.2568e-04],\n",
      "        [5.0298e-03, 4.6707e-02, 3.1457e-01, 4.4584e-01, 1.7619e-01, 6.6748e-03,\n",
      "         2.8830e-03, 1.2140e-03, 7.0738e-04, 1.8757e-04],\n",
      "        [3.3250e-04, 1.4171e-03, 5.0719e-02, 1.9286e-01, 6.1243e-01, 9.0470e-02,\n",
      "         2.8897e-02, 1.3542e-02, 7.6276e-03, 1.6970e-03],\n",
      "        [2.1590e-04, 2.3081e-04, 4.2003e-03, 9.1240e-03, 8.0451e-02, 2.5600e-01,\n",
      "         3.1595e-01, 1.4199e-01, 1.3843e-01, 5.3406e-02],\n",
      "        [3.0788e-04, 1.1926e-04, 4.2562e-04, 3.1408e-03, 5.8544e-03, 1.9657e-02,\n",
      "         1.6775e-01, 2.6023e-01, 3.1669e-01, 2.2583e-01],\n",
      "        [1.5863e-04, 8.6025e-04, 2.7510e-03, 5.0571e-03, 8.0034e-03, 1.7030e-02,\n",
      "         5.3982e-02, 9.6029e-02, 2.0263e-01, 6.1350e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: lí_do là chúng đang bị đầu_độc , chúng bị đầu_độc\n",
      "Reference: the reason is that they &apos;re getting poisoned ,\n",
      "Model: <SOS> the reason is they they &apos;re looking , ,\n",
      "Attention Weights: tensor([[9.9979e-01, 1.9534e-04, 1.2717e-05, 5.4342e-07, 7.5167e-08, 2.0052e-08,\n",
      "         9.5737e-11, 4.3019e-10, 3.0962e-10, 1.2331e-10],\n",
      "        [9.8646e-01, 1.1555e-02, 1.5265e-03, 3.2026e-04, 8.2386e-05, 3.3830e-05,\n",
      "         5.2022e-06, 6.4697e-06, 3.8458e-06, 1.6299e-06],\n",
      "        [1.6851e-01, 5.8788e-01, 1.5401e-01, 4.4587e-02, 3.2742e-02, 9.8552e-03,\n",
      "         4.8196e-04, 6.0739e-04, 9.4529e-04, 3.8214e-04],\n",
      "        [2.7336e-02, 6.5618e-01, 1.6474e-01, 7.3574e-02, 5.2680e-02, 1.6877e-02,\n",
      "         2.3993e-03, 2.8361e-03, 2.3217e-03, 1.0553e-03],\n",
      "        [4.7079e-03, 4.8370e-02, 1.3620e-01, 4.9750e-01, 2.3915e-01, 5.3074e-02,\n",
      "         3.0540e-03, 5.5466e-03, 8.8082e-03, 3.5938e-03],\n",
      "        [4.7326e-04, 7.1671e-03, 7.1105e-02, 3.6031e-01, 3.4483e-01, 1.6051e-01,\n",
      "         9.7047e-03, 8.6256e-03, 3.1679e-02, 5.5930e-03],\n",
      "        [2.1558e-04, 1.8704e-03, 9.3886e-03, 4.9150e-01, 2.7109e-01, 1.0737e-01,\n",
      "         1.0514e-02, 4.2677e-03, 7.5356e-02, 2.8427e-02],\n",
      "        [6.4691e-06, 1.0661e-04, 1.2708e-04, 1.9403e-03, 7.2772e-02, 8.3677e-01,\n",
      "         6.2140e-02, 1.7371e-03, 5.6031e-03, 1.8801e-02],\n",
      "        [3.0404e-05, 2.3669e-04, 8.8634e-04, 2.5684e-03, 4.1728e-02, 2.4430e-01,\n",
      "         3.1080e-01, 2.2793e-01, 1.1395e-01, 5.7569e-02]])\n",
      "\n",
      "Epoch: 4.77, Train Loss: 3.11, Val Loss: 4.15, Train BLEU: 12.84, Val BLEU: 10.28, Minutes Elapsed: 246.61\n",
      "Sampling from training predictions...\n",
      "Source: có giai_đoạn chúng_tôi còn mang cả máy_bay theo . <EOS>\n",
      "Reference: and on part of that field campaign we even\n",
      "Model: <SOS> there have we time we we got we we\n",
      "Attention Weights: tensor([[9.8365e-01, 1.6090e-02, 2.3531e-04, 2.5357e-05, 2.2749e-07, 6.9080e-08,\n",
      "         1.3165e-08, 3.0707e-09, 4.3713e-10, 3.4205e-10],\n",
      "        [2.9157e-01, 6.9697e-01, 7.1006e-03, 3.6696e-03, 5.1776e-04, 1.1573e-04,\n",
      "         4.7863e-05, 4.0353e-06, 1.5056e-06, 8.4502e-07],\n",
      "        [2.9134e-01, 4.6915e-01, 4.1404e-02, 1.7530e-01, 2.0075e-02, 1.9743e-03,\n",
      "         6.4366e-04, 6.9367e-05, 2.9067e-05, 1.5794e-05],\n",
      "        [2.1783e-01, 5.3172e-01, 4.1784e-02, 1.8754e-01, 1.8200e-02, 1.9668e-03,\n",
      "         8.2346e-04, 7.9231e-05, 3.4507e-05, 2.1116e-05],\n",
      "        [2.7064e-01, 2.7006e-01, 2.5976e-01, 1.8315e-01, 1.4306e-02, 1.3820e-03,\n",
      "         5.6638e-04, 9.7438e-05, 2.7567e-05, 1.4065e-05],\n",
      "        [1.4706e-01, 2.2251e-01, 5.1584e-02, 5.0130e-01, 7.2602e-02, 3.0511e-03,\n",
      "         1.6968e-03, 1.3539e-04, 4.3143e-05, 2.2227e-05],\n",
      "        [4.3371e-02, 5.6759e-02, 1.5023e-01, 6.8349e-01, 6.3434e-02, 1.6603e-03,\n",
      "         7.6356e-04, 1.8168e-04, 6.9858e-05, 3.9687e-05],\n",
      "        [7.6452e-02, 3.2355e-01, 3.0948e-02, 4.4039e-01, 1.2359e-01, 3.3684e-03,\n",
      "         1.5666e-03, 9.4785e-05, 2.4631e-05, 1.3836e-05],\n",
      "        [3.6805e-02, 1.3184e-01, 3.0733e-02, 5.4900e-01, 2.3371e-01, 1.0726e-02,\n",
      "         6.5214e-03, 4.8786e-04, 1.1178e-04, 5.4478e-05]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: rồi chỉ vào dấu chân mờ_mờ này và nói ,\n",
      "Reference: then he pointed toward this barely visible <UNK> ,\n",
      "Model: <SOS> then then the on this top of and and\n",
      "Attention Weights: tensor([[9.9746e-01, 2.5439e-03, 9.6927e-07, 5.2700e-09, 8.5284e-11, 9.5255e-12,\n",
      "         2.9700e-12, 9.3286e-14, 3.0231e-14, 2.0560e-15],\n",
      "        [4.6381e-01, 5.1359e-01, 1.6880e-02, 4.9343e-03, 6.7291e-04, 1.0122e-04,\n",
      "         6.0055e-06, 9.6573e-07, 9.3866e-07, 2.2005e-07],\n",
      "        [1.5993e-01, 5.6339e-01, 8.6007e-02, 1.6498e-01, 2.3316e-02, 2.2448e-03,\n",
      "         7.8414e-05, 2.1326e-05, 3.2895e-05, 5.0815e-06],\n",
      "        [6.2855e-02, 3.3307e-01, 1.1282e-01, 3.6798e-01, 1.0541e-01, 1.7118e-02,\n",
      "         5.0614e-04, 1.4601e-04, 8.2938e-05, 1.2357e-05],\n",
      "        [5.1025e-03, 8.8684e-03, 4.6904e-02, 5.6653e-01, 2.8525e-01, 7.8713e-02,\n",
      "         6.7275e-03, 1.3737e-03, 4.6966e-04, 7.1372e-05],\n",
      "        [6.7198e-04, 1.3190e-03, 6.6109e-03, 4.1739e-01, 3.8121e-01, 1.6849e-01,\n",
      "         1.5188e-02, 6.5188e-03, 2.2801e-03, 3.1782e-04],\n",
      "        [1.0415e-03, 2.1944e-04, 1.0527e-03, 1.0762e-01, 4.7592e-01, 2.6579e-01,\n",
      "         3.9702e-02, 7.1551e-02, 3.2937e-02, 4.1675e-03],\n",
      "        [1.1711e-04, 2.8691e-05, 3.3745e-04, 7.6286e-03, 1.2830e-01, 2.3911e-01,\n",
      "         7.4820e-02, 2.2405e-01, 3.0480e-01, 2.0810e-02],\n",
      "        [1.0904e-04, 6.1719e-05, 4.1519e-04, 7.8785e-03, 1.5780e-01, 2.9627e-01,\n",
      "         6.7161e-02, 2.2265e-01, 2.3147e-01, 1.6181e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4.82, Train Loss: 2.98, Val Loss: 4.04, Train BLEU: 14.47, Val BLEU: 10.94, Minutes Elapsed: 249.10\n",
      "Sampling from training predictions...\n",
      "Source: các y_tá trong khoa tôi nằm cho_rằng phương_pháp đúng nhất_là\n",
      "Reference: the nurses in my department thought that the right\n",
      "Model: <SOS> nurses nurses in i i i i was was\n",
      "Attention Weights: tensor([[2.0825e-01, 7.8420e-01, 7.1564e-03, 3.9509e-04, 7.9396e-07, 1.7142e-07,\n",
      "         1.9746e-08, 1.3176e-08, 4.1608e-09, 1.4275e-09],\n",
      "        [3.5744e-02, 5.3961e-01, 2.8990e-01, 1.3430e-01, 1.4641e-04, 1.7000e-04,\n",
      "         8.5001e-05, 2.3615e-05, 1.9014e-05, 9.1204e-06],\n",
      "        [1.2116e-02, 2.1435e-02, 2.7413e-01, 6.5579e-01, 2.3876e-02, 7.1646e-03,\n",
      "         3.8991e-03, 6.7718e-04, 8.0236e-04, 1.1523e-04],\n",
      "        [1.9434e-03, 1.1737e-02, 2.0945e-01, 7.4404e-01, 2.3116e-02, 5.9397e-03,\n",
      "         2.3565e-03, 5.6828e-04, 6.2789e-04, 2.1973e-04],\n",
      "        [6.4448e-04, 3.5641e-03, 7.3048e-03, 5.0955e-01, 1.0830e-01, 2.2312e-01,\n",
      "         7.5705e-02, 3.3339e-02, 2.7642e-02, 1.0831e-02],\n",
      "        [5.3552e-05, 3.3220e-04, 1.3464e-03, 1.8891e-01, 2.5778e-01, 3.1525e-01,\n",
      "         1.5922e-01, 3.1146e-02, 4.0508e-02, 5.4566e-03],\n",
      "        [4.7461e-06, 5.1292e-05, 2.2730e-04, 1.6355e-02, 8.6930e-02, 3.2537e-01,\n",
      "         3.2669e-01, 9.1919e-02, 1.3468e-01, 1.7780e-02],\n",
      "        [9.4239e-05, 4.0906e-04, 1.6724e-04, 4.3635e-03, 1.6893e-02, 3.0471e-01,\n",
      "         3.3421e-01, 1.4944e-01, 1.3518e-01, 5.4532e-02],\n",
      "        [1.5185e-04, 9.7688e-04, 2.1630e-04, 2.8862e-03, 8.2405e-03, 1.7874e-01,\n",
      "         2.8721e-01, 2.0373e-01, 1.9422e-01, 1.2363e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: nó là vật_liệu gây ồn , nếu chúng_ta làm những\n",
      "Reference: it &apos;s a noisy material , and if we\n",
      "Model: <SOS> it &apos;s a , , , if we do\n",
      "Attention Weights: tensor([[5.5568e-01, 4.4350e-01, 7.0482e-04, 9.9838e-05, 1.6423e-05, 1.3202e-08,\n",
      "         5.6991e-09, 3.3679e-10, 3.9094e-09, 5.2388e-10],\n",
      "        [7.8458e-02, 7.5931e-01, 1.5921e-01, 2.6609e-03, 2.7050e-04, 2.5341e-05,\n",
      "         1.4267e-05, 8.0362e-06, 3.8611e-05, 4.1950e-06],\n",
      "        [9.1421e-02, 4.8956e-01, 3.5481e-01, 4.9951e-02, 1.2821e-02, 6.0584e-04,\n",
      "         1.3149e-04, 5.6868e-05, 5.0508e-04, 1.3329e-04],\n",
      "        [2.5952e-04, 8.3851e-03, 5.1266e-01, 3.2907e-01, 1.4557e-01, 3.7733e-03,\n",
      "         1.2052e-04, 8.9580e-06, 4.6272e-05, 1.1486e-04],\n",
      "        [1.2847e-04, 4.6229e-03, 3.5183e-01, 2.7400e-01, 2.6081e-01, 1.0056e-01,\n",
      "         6.4168e-03, 8.1928e-05, 1.1772e-03, 3.8092e-04],\n",
      "        [1.3042e-04, 2.1704e-03, 3.5049e-02, 1.4284e-01, 1.0753e-01, 5.8684e-01,\n",
      "         1.0910e-01, 9.0091e-04, 1.3621e-02, 1.8046e-03],\n",
      "        [6.2526e-05, 1.1815e-04, 2.6900e-03, 3.6055e-03, 7.0900e-03, 4.2393e-01,\n",
      "         5.1417e-01, 1.7686e-02, 2.8267e-02, 2.3843e-03],\n",
      "        [5.8530e-04, 1.8509e-03, 4.2113e-02, 8.5060e-03, 9.3007e-03, 9.2630e-02,\n",
      "         2.4281e-01, 1.3630e-01, 4.5444e-01, 1.1459e-02],\n",
      "        [3.6578e-04, 3.1697e-03, 1.1691e-02, 3.1903e-03, 1.0815e-03, 4.0691e-03,\n",
      "         7.7064e-03, 5.3677e-02, 8.4671e-01, 6.8337e-02]])\n",
      "\n",
      "Epoch: 4.86, Train Loss: 2.97, Val Loss: 4.02, Train BLEU: 14.21, Val BLEU: 10.92, Minutes Elapsed: 251.62\n",
      "Sampling from training predictions...\n",
      "Source: được làm vào năm 1939 , bộ phim có tuổi_già\n",
      "Reference: made in 1939 , the film is older than\n",
      "Model: <SOS> in was 1939 , , was was was in\n",
      "Attention Weights: tensor([[9.9346e-01, 5.8770e-03, 6.2905e-04, 2.6655e-05, 6.7798e-06, 6.5176e-08,\n",
      "         1.9325e-08, 3.8480e-09, 9.5979e-10, 8.7885e-10],\n",
      "        [6.6464e-01, 1.8749e-01, 1.1800e-01, 2.8558e-02, 1.0558e-03, 1.9794e-04,\n",
      "         2.4333e-05, 2.1241e-05, 5.0228e-06, 4.2177e-06],\n",
      "        [2.6036e-01, 1.8926e-01, 3.5558e-01, 1.5881e-01, 1.9747e-02, 1.2716e-02,\n",
      "         1.3746e-03, 1.7660e-03, 2.9005e-04, 9.9411e-05],\n",
      "        [1.9914e-02, 1.5045e-02, 4.3796e-01, 2.7919e-01, 2.4321e-02, 1.8316e-01,\n",
      "         2.0129e-02, 1.7269e-02, 1.5902e-03, 1.4270e-03],\n",
      "        [4.5376e-03, 3.7058e-03, 1.1734e-01, 7.5623e-02, 1.2417e-02, 3.9813e-01,\n",
      "         3.2592e-01, 4.6718e-02, 9.7276e-03, 5.8749e-03],\n",
      "        [2.0750e-05, 2.9378e-05, 4.1590e-04, 2.6100e-03, 8.0178e-04, 9.6620e-02,\n",
      "         3.7890e-01, 3.3667e-01, 1.3120e-01, 5.2741e-02],\n",
      "        [2.6865e-03, 8.4951e-03, 5.3697e-03, 3.0440e-03, 1.3473e-03, 1.0496e-02,\n",
      "         6.3253e-02, 3.3422e-01, 2.6847e-01, 3.0261e-01],\n",
      "        [5.1013e-04, 5.1266e-03, 1.9926e-02, 8.8677e-03, 3.4592e-03, 4.5218e-02,\n",
      "         5.6482e-02, 1.3157e-01, 3.7369e-01, 3.5514e-01],\n",
      "        [5.5807e-05, 2.5275e-04, 8.9300e-04, 9.4787e-04, 9.8722e-04, 7.5107e-03,\n",
      "         1.9829e-02, 7.6914e-02, 3.4813e-01, 5.4448e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: có_một thế_hệ doanh_nhân mới những người đang kiệt_quệ vì sự\n",
      "Reference: there is a new generation of entrepreneurs who are\n",
      "Model: <SOS> there &apos;s a group that who who who who\n",
      "Attention Weights: tensor([[9.9941e-01, 4.2832e-04, 1.6135e-04, 2.2240e-06, 6.8166e-08, 4.3484e-08,\n",
      "         6.7351e-09, 4.1184e-09, 2.9876e-09, 9.3275e-10],\n",
      "        [8.4811e-01, 7.3193e-02, 7.6358e-02, 1.6418e-03, 3.9493e-04, 1.4563e-04,\n",
      "         8.8976e-05, 5.3583e-05, 8.7170e-06, 8.7215e-06],\n",
      "        [7.1538e-01, 1.7405e-01, 9.8997e-02, 8.5151e-03, 1.6611e-03, 5.1482e-04,\n",
      "         5.0273e-04, 2.9611e-04, 4.5112e-05, 3.6575e-05],\n",
      "        [4.6681e-02, 2.3004e-01, 7.1146e-01, 9.7089e-03, 9.2580e-04, 5.1808e-04,\n",
      "         1.9951e-04, 3.3399e-04, 9.1871e-05, 4.1309e-05],\n",
      "        [2.3810e-01, 3.4235e-01, 2.4074e-01, 1.6626e-01, 1.8468e-03, 2.8855e-03,\n",
      "         4.8409e-03, 2.2537e-03, 6.0531e-04, 1.1537e-04],\n",
      "        [2.9036e-02, 8.8844e-02, 3.1213e-01, 5.0389e-01, 1.0945e-02, 1.2584e-02,\n",
      "         2.3584e-02, 1.4828e-02, 2.8688e-03, 1.2838e-03],\n",
      "        [1.9290e-03, 7.4033e-03, 1.6701e-01, 5.0046e-01, 4.2493e-02, 4.0450e-02,\n",
      "         1.8559e-01, 4.0344e-02, 9.6403e-03, 4.6781e-03],\n",
      "        [5.6467e-04, 1.7750e-03, 4.7556e-02, 1.9499e-01, 4.9392e-02, 8.0379e-02,\n",
      "         3.2740e-01, 2.0061e-01, 6.3113e-02, 3.4215e-02],\n",
      "        [2.6797e-04, 5.0545e-04, 3.0930e-03, 7.1224e-02, 3.4197e-02, 8.8855e-02,\n",
      "         4.6749e-01, 2.3735e-01, 7.3984e-02, 2.3040e-02]])\n",
      "\n",
      "Epoch: 4.91, Train Loss: 2.96, Val Loss: 4.04, Train BLEU: 13.13, Val BLEU: 10.28, Minutes Elapsed: 254.16\n",
      "Sampling from training predictions...\n",
      "Source: ta đều biết rằng khi suy_nghĩ , ta đã tạo\n",
      "Reference: we all know that as we form thoughts ,\n",
      "Model: <SOS> we all know that when when we thinking ,\n",
      "Attention Weights: tensor([[4.7024e-03, 9.9451e-01, 7.7348e-04, 1.1061e-05, 4.8213e-07, 1.6547e-07,\n",
      "         3.4704e-10, 1.4298e-10, 1.4519e-09, 7.3453e-10],\n",
      "        [5.9376e-04, 9.7583e-01, 2.2782e-02, 7.3571e-04, 2.6480e-05, 2.5338e-05,\n",
      "         2.8233e-07, 6.0898e-08, 1.5833e-06, 6.9087e-07],\n",
      "        [1.8710e-03, 5.0821e-01, 3.4964e-01, 1.2828e-01, 8.4895e-03, 3.3290e-03,\n",
      "         1.5029e-05, 9.7268e-06, 8.5158e-05, 6.8899e-05],\n",
      "        [1.8321e-04, 6.6463e-03, 4.7885e-02, 5.6535e-01, 2.7708e-01, 1.0041e-01,\n",
      "         9.7937e-04, 3.3468e-04, 6.7429e-04, 4.6000e-04],\n",
      "        [3.6940e-04, 2.9681e-03, 1.3326e-02, 1.2283e-01, 6.7253e-01, 1.8019e-01,\n",
      "         2.2660e-03, 2.1644e-03, 2.3608e-03, 9.9302e-04],\n",
      "        [1.6793e-05, 6.9750e-04, 1.7482e-03, 2.5347e-02, 2.3562e-01, 6.7004e-01,\n",
      "         7.7570e-03, 1.2217e-02, 4.0171e-02, 6.3826e-03],\n",
      "        [8.2462e-06, 6.3706e-04, 2.0068e-03, 5.8020e-03, 6.5251e-02, 5.8155e-01,\n",
      "         4.5908e-02, 3.8459e-02, 1.9829e-01, 6.2087e-02],\n",
      "        [6.8603e-05, 2.6998e-03, 1.2717e-02, 1.1415e-02, 7.2392e-02, 6.1492e-01,\n",
      "         9.3601e-02, 6.3490e-02, 8.2933e-02, 4.5766e-02],\n",
      "        [3.1734e-05, 3.8034e-05, 2.7810e-04, 4.0103e-03, 9.4002e-02, 5.5066e-01,\n",
      "         1.6596e-01, 5.0607e-02, 2.5450e-02, 1.0897e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi có được những thứ miễn_phí đó là nhờ vào\n",
      "Reference: and i got these free things because of how\n",
      "Model: <SOS> i i have the that that i i was\n",
      "Attention Weights: tensor([[1.9973e-02, 8.5719e-01, 1.2211e-01, 6.2233e-04, 1.0317e-04, 7.2836e-06,\n",
      "         9.1877e-07, 7.0827e-08, 9.6033e-09, 4.3659e-08],\n",
      "        [1.2333e-03, 5.1369e-02, 8.9831e-01, 4.4100e-02, 3.6101e-03, 1.3519e-03,\n",
      "         1.0440e-05, 6.1923e-06, 3.0229e-06, 1.7562e-06],\n",
      "        [2.1426e-03, 5.1870e-02, 5.0932e-01, 3.9721e-01, 2.8090e-02, 1.0347e-02,\n",
      "         7.7524e-04, 1.7183e-04, 4.4801e-05, 3.1391e-05],\n",
      "        [1.6028e-03, 2.5571e-02, 3.8537e-01, 4.3534e-01, 1.2181e-01, 2.7979e-02,\n",
      "         1.8308e-03, 3.3468e-04, 1.1037e-04, 5.9551e-05],\n",
      "        [1.2571e-04, 3.2140e-04, 3.4898e-02, 1.1106e-01, 1.8448e-01, 6.5920e-01,\n",
      "         5.8836e-03, 2.7508e-03, 8.0235e-04, 4.7842e-04],\n",
      "        [2.6543e-04, 3.2432e-03, 3.6359e-02, 3.3570e-02, 2.7106e-01, 6.1418e-01,\n",
      "         1.7528e-02, 8.2373e-03, 4.9537e-03, 1.0597e-02],\n",
      "        [1.4548e-04, 9.5634e-04, 4.1228e-03, 2.8159e-03, 6.0862e-02, 4.9353e-01,\n",
      "         1.6701e-01, 1.3247e-01, 1.8337e-02, 1.1975e-01],\n",
      "        [7.1108e-05, 5.0211e-04, 1.4293e-03, 2.0610e-03, 6.6948e-03, 5.3670e-02,\n",
      "         6.7987e-02, 2.0948e-01, 1.4337e-01, 5.1474e-01],\n",
      "        [1.0210e-04, 3.7666e-04, 1.0443e-03, 2.2703e-03, 7.8053e-03, 5.3014e-02,\n",
      "         2.3277e-02, 1.8288e-01, 2.8776e-01, 4.4147e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4.96, Train Loss: 2.92, Val Loss: 4.04, Train BLEU: 14.10, Val BLEU: 10.44, Minutes Elapsed: 256.69\n",
      "Sampling from training predictions...\n",
      "Source: không không không . nó chỉ dài bốn phút thôi\n",
      "Reference: no , no , no . it &apos;s four\n",
      "Model: <SOS> it &apos;s it &apos;s it &apos;s just &apos;s only\n",
      "Attention Weights: tensor([[8.7285e-01, 1.2111e-01, 5.8996e-03, 1.3011e-04, 2.7930e-06, 1.7206e-06,\n",
      "         1.2498e-07, 7.0813e-08, 3.0059e-08, 5.1313e-09],\n",
      "        [2.7676e-01, 2.3060e-01, 2.6433e-01, 2.1242e-01, 1.0646e-02, 3.0926e-03,\n",
      "         4.9455e-04, 6.7154e-04, 6.1355e-04, 3.6912e-04],\n",
      "        [2.9468e-01, 2.1773e-01, 2.9203e-01, 1.1967e-01, 3.9442e-02, 2.3809e-02,\n",
      "         6.3120e-03, 2.8897e-03, 2.2613e-03, 1.1815e-03],\n",
      "        [5.9468e-02, 1.1466e-01, 2.2946e-01, 2.4602e-01, 2.2494e-01, 7.4848e-02,\n",
      "         2.1215e-02, 1.2099e-02, 9.8595e-03, 7.4343e-03],\n",
      "        [3.5059e-02, 8.0325e-02, 1.5396e-01, 7.4823e-02, 9.9592e-02, 2.5464e-01,\n",
      "         1.5334e-01, 8.5539e-02, 4.6906e-02, 1.5808e-02],\n",
      "        [3.3512e-03, 1.1355e-02, 1.8240e-02, 8.2201e-02, 2.5606e-01, 2.3025e-01,\n",
      "         1.8818e-01, 1.3233e-01, 5.4231e-02, 2.3807e-02],\n",
      "        [3.1318e-02, 6.2010e-02, 1.5432e-01, 4.4493e-02, 3.6401e-02, 2.9309e-01,\n",
      "         2.1832e-01, 1.1215e-01, 3.5250e-02, 1.2648e-02],\n",
      "        [2.5975e-03, 1.5707e-02, 1.9626e-02, 3.2505e-02, 7.8311e-02, 2.7407e-01,\n",
      "         2.9285e-01, 1.8862e-01, 6.1466e-02, 3.4251e-02],\n",
      "        [2.1400e-02, 4.4734e-02, 9.4622e-02, 3.4429e-02, 2.5289e-02, 2.7790e-01,\n",
      "         3.1719e-01, 1.2300e-01, 4.3951e-02, 1.7492e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: trong những thập_kỉ vừa_qua , chúng_ta đã định_nghĩa sắc_đẹp không\n",
      "Reference: well , for the past few centuries we have\n",
      "Model: <SOS> in the the past past decade , , we\n",
      "Attention Weights: tensor([[9.0042e-01, 6.0793e-02, 3.8461e-02, 3.2152e-04, 8.9457e-07, 5.6033e-08,\n",
      "         7.0624e-08, 1.2265e-07, 9.2288e-09, 1.2161e-09],\n",
      "        [6.5204e-03, 2.7246e-01, 6.7636e-01, 4.4152e-02, 3.0102e-04, 1.5858e-05,\n",
      "         4.9394e-05, 1.2762e-04, 9.4240e-06, 3.6614e-06],\n",
      "        [1.7230e-02, 1.1956e-01, 6.5280e-01, 2.0123e-01, 5.2329e-03, 2.6795e-04,\n",
      "         6.9394e-04, 2.3850e-03, 5.0154e-04, 1.1008e-04],\n",
      "        [2.0457e-02, 1.5036e-01, 5.4767e-01, 2.3346e-01, 2.5051e-02, 1.3030e-03,\n",
      "         4.1633e-03, 1.3583e-02, 3.3116e-03, 6.3090e-04],\n",
      "        [3.2519e-02, 1.7232e-01, 5.2145e-01, 2.0122e-01, 1.9519e-02, 1.8692e-03,\n",
      "         9.9455e-03, 3.1643e-02, 7.4919e-03, 2.0168e-03],\n",
      "        [2.6234e-03, 4.3979e-02, 1.9584e-01, 2.0770e-01, 3.5542e-01, 2.8901e-02,\n",
      "         5.5141e-02, 7.8844e-02, 2.5698e-02, 5.8544e-03],\n",
      "        [4.7730e-04, 4.8771e-03, 7.0723e-02, 3.9540e-01, 3.2275e-01, 4.1358e-02,\n",
      "         7.5235e-02, 6.4932e-02, 1.9383e-02, 4.8652e-03],\n",
      "        [2.2283e-04, 1.3049e-03, 2.0215e-02, 1.7241e-02, 9.5636e-02, 1.1845e-01,\n",
      "         5.7830e-01, 1.0791e-01, 4.2495e-02, 1.8224e-02],\n",
      "        [5.4049e-05, 5.1746e-04, 4.8429e-03, 2.2029e-02, 1.4647e-01, 2.2841e-01,\n",
      "         4.8452e-01, 8.4621e-02, 2.1640e-02, 6.9003e-03]])\n",
      "\n",
      "Epoch: 5.00, Train Loss: 2.86, Val Loss: 4.10, Train BLEU: 15.10, Val BLEU: 10.15, Minutes Elapsed: 258.81\n",
      "Sampling from training predictions...\n",
      "Source: vì_vậy tôi bỏ việc_làm của tôi là làm y_tá .\n",
      "Reference: so i quit my day job as a nurse\n",
      "Model: <SOS> so i i my my job a a nurse\n",
      "Attention Weights: tensor([[9.9921e-01, 6.9710e-04, 9.3272e-05, 1.6350e-06, 1.1774e-08, 2.9761e-10,\n",
      "         7.4038e-11, 1.6765e-11, 1.3625e-11, 5.8600e-13],\n",
      "        [2.2291e-01, 5.0699e-01, 2.6668e-01, 3.3221e-03, 8.8980e-05, 3.7745e-06,\n",
      "         1.4359e-06, 4.2489e-07, 4.2702e-07, 2.4529e-08],\n",
      "        [4.2563e-02, 8.1147e-03, 8.2241e-01, 1.2188e-01, 3.4755e-03, 5.8745e-04,\n",
      "         5.8958e-04, 2.7552e-04, 8.5543e-05, 1.9313e-05],\n",
      "        [3.4600e-01, 3.3930e-03, 3.8140e-01, 2.1596e-01, 4.6661e-02, 2.5279e-03,\n",
      "         2.8807e-03, 8.5168e-04, 2.9395e-04, 2.3475e-05],\n",
      "        [1.8385e-02, 1.3340e-03, 6.8117e-02, 8.2524e-01, 6.8106e-02, 9.6615e-03,\n",
      "         3.8696e-03, 1.8691e-03, 3.2695e-03, 1.4494e-04],\n",
      "        [3.1759e-03, 6.7681e-04, 9.9153e-03, 3.2999e-01, 3.6016e-01, 8.6532e-02,\n",
      "         8.0720e-02, 4.9225e-02, 7.6836e-02, 2.7712e-03],\n",
      "        [6.9316e-05, 5.6104e-05, 6.1960e-04, 5.2592e-02, 6.8154e-02, 1.0798e-01,\n",
      "         2.6553e-01, 2.7084e-01, 2.0924e-01, 2.4927e-02],\n",
      "        [1.1673e-04, 8.1049e-05, 7.5349e-04, 1.3627e-02, 1.8113e-02, 2.1721e-02,\n",
      "         1.4247e-01, 1.6788e-01, 6.0776e-01, 2.7470e-02],\n",
      "        [2.2178e-04, 1.8828e-04, 6.4627e-04, 4.1162e-03, 1.1368e-02, 1.7403e-02,\n",
      "         1.1922e-01, 1.7428e-01, 6.3833e-01, 3.4229e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: cháu không biết là thật_là thú_vị biết_bao khi nghe câu_chuyện\n",
      "Reference: you have no idea how exciting it is to\n",
      "Model: <SOS> it is &apos;t idea what the is when when\n",
      "Attention Weights: tensor([[9.8878e-01, 1.1198e-02, 2.3890e-05, 3.0291e-07, 1.3591e-08, 1.9452e-09,\n",
      "         4.4678e-10, 3.9202e-11, 4.5011e-11, 1.5068e-11],\n",
      "        [6.8420e-01, 2.6707e-01, 4.2680e-02, 5.2461e-03, 5.8682e-04, 1.4973e-04,\n",
      "         5.1857e-05, 4.0344e-06, 3.8715e-06, 3.6466e-06],\n",
      "        [4.0438e-01, 3.6323e-01, 1.6512e-01, 5.1350e-02, 1.1096e-02, 3.1928e-03,\n",
      "         1.3139e-03, 1.4056e-04, 1.0354e-04, 6.9790e-05],\n",
      "        [2.5460e-02, 1.1262e-01, 5.4951e-01, 2.4840e-01, 4.4665e-02, 1.0759e-02,\n",
      "         7.3493e-03, 7.5238e-04, 3.1972e-04, 1.6710e-04],\n",
      "        [1.7178e-02, 3.9229e-02, 1.6694e-01, 5.5070e-01, 1.1745e-01, 5.4032e-02,\n",
      "         4.0845e-02, 1.1771e-02, 1.1255e-03, 7.3151e-04],\n",
      "        [1.0606e-03, 1.0122e-02, 1.7025e-02, 4.1706e-01, 2.9525e-01, 8.6072e-02,\n",
      "         1.2056e-01, 3.8842e-02, 1.0082e-02, 3.9208e-03],\n",
      "        [6.1361e-05, 7.1503e-04, 6.8139e-04, 2.3811e-01, 2.6576e-01, 1.8286e-01,\n",
      "         1.7793e-01, 1.0492e-01, 2.1989e-02, 6.9827e-03],\n",
      "        [1.8215e-04, 3.7733e-03, 1.3138e-03, 1.4812e-01, 2.0601e-01, 1.9783e-01,\n",
      "         2.8204e-01, 9.0113e-02, 5.4143e-02, 1.6483e-02],\n",
      "        [2.5350e-05, 8.9307e-05, 9.7291e-05, 6.2048e-03, 6.3213e-02, 9.0991e-02,\n",
      "         2.2163e-01, 3.6249e-01, 1.7224e-01, 8.3022e-02]])\n",
      "\n",
      "Epoch: 5.05, Train Loss: 2.37, Val Loss: 4.06, Train BLEU: 20.42, Val BLEU: 10.80, Minutes Elapsed: 261.33\n",
      "Sampling from training predictions...\n",
      "Source: nó là trò_chơi duy_nhất trên thế_giới mà tôi biết sẽ\n",
      "Reference: it &apos;s the only game in the world that\n",
      "Model: <SOS> it &apos;s the only game in the world i\n",
      "Attention Weights: tensor([[3.2023e-01, 6.7765e-01, 2.0535e-03, 6.1909e-05, 8.0560e-06, 1.7291e-07,\n",
      "         1.8732e-08, 2.0820e-09, 2.9461e-09, 9.2530e-10],\n",
      "        [2.4675e-02, 6.8529e-01, 2.6973e-01, 1.9951e-02, 2.7345e-04, 5.3545e-05,\n",
      "         1.0475e-05, 2.9890e-06, 5.9032e-06, 5.8758e-06],\n",
      "        [4.6876e-02, 2.7708e-01, 4.5900e-01, 2.1159e-01, 4.3302e-03, 7.5325e-04,\n",
      "         1.7196e-04, 3.8724e-05, 1.0703e-04, 5.1374e-05],\n",
      "        [2.9187e-05, 5.5703e-04, 1.5997e-01, 8.1515e-01, 2.1822e-02, 1.9729e-03,\n",
      "         4.1946e-04, 2.2632e-05, 3.1877e-05, 2.8515e-05],\n",
      "        [4.5041e-05, 1.5259e-03, 4.8423e-01, 3.0137e-01, 1.9504e-01, 1.5130e-02,\n",
      "         2.1171e-03, 1.6977e-04, 2.5854e-04, 1.1142e-04],\n",
      "        [2.5100e-04, 1.3356e-02, 1.9388e-01, 1.2115e-01, 5.8319e-01, 3.7876e-02,\n",
      "         4.2302e-02, 5.0728e-03, 2.2573e-03, 6.6466e-04],\n",
      "        [1.3970e-05, 1.4784e-04, 3.4204e-02, 6.0646e-02, 4.7124e-01, 2.7067e-01,\n",
      "         1.1714e-01, 2.0053e-02, 2.0402e-02, 5.4916e-03],\n",
      "        [4.0953e-06, 3.2228e-05, 2.8784e-03, 3.1387e-03, 1.5621e-01, 6.1954e-01,\n",
      "         1.1577e-01, 3.2031e-02, 5.1833e-02, 1.8559e-02],\n",
      "        [4.3727e-04, 7.1035e-04, 2.3834e-03, 4.9764e-04, 7.0238e-02, 1.8932e-01,\n",
      "         4.0279e-01, 1.9434e-01, 1.1763e-01, 2.1655e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: chúng_tôi đã giúp khởi_động 40,000 công_việc làm_ăn . <EOS> <PAD>\n",
      "Reference: we have helped to start 40,000 businesses . <EOS>\n",
      "Model: <SOS> we we the insects do . the work <EOS>\n",
      "Attention Weights: tensor([[0.0155, 0.8616, 0.1197, 0.0031, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0033, 0.0147, 0.9478, 0.0340, 0.0001, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0016, 0.0224, 0.5958, 0.3739, 0.0048, 0.0013, 0.0002, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0018, 0.0008, 0.0334, 0.6931, 0.1499, 0.1161, 0.0046, 0.0002, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0012, 0.0049, 0.0277, 0.0473, 0.1145, 0.7333, 0.0622, 0.0066, 0.0024,\n",
      "         0.0000],\n",
      "        [0.0006, 0.0018, 0.0036, 0.0090, 0.0404, 0.7816, 0.1431, 0.0165, 0.0034,\n",
      "         0.0000],\n",
      "        [0.0004, 0.0003, 0.0006, 0.0098, 0.0328, 0.8427, 0.0702, 0.0325, 0.0109,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0006, 0.0008, 0.0025, 0.0160, 0.8118, 0.1166, 0.0361, 0.0155,\n",
      "         0.0000],\n",
      "        [0.0005, 0.0031, 0.0430, 0.0180, 0.0109, 0.2932, 0.4078, 0.1594, 0.0642,\n",
      "         0.0000]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5.10, Train Loss: 2.51, Val Loss: 4.07, Train BLEU: 18.33, Val BLEU: 10.85, Minutes Elapsed: 263.86\n",
      "Sampling from training predictions...\n",
      "Source: không không không . nó chỉ dài bốn phút thôi\n",
      "Reference: no , no , no . it &apos;s four\n",
      "Model: <SOS> no &apos;s it &apos;s it &apos;s just &apos;s only\n",
      "Attention Weights: tensor([[9.5538e-01, 4.3385e-02, 1.2225e-03, 1.5675e-05, 8.5837e-08, 1.0356e-07,\n",
      "         7.6353e-09, 6.0648e-09, 3.1392e-09, 8.7430e-10],\n",
      "        [5.5175e-01, 3.0145e-01, 1.1782e-01, 2.6933e-02, 1.2949e-03, 4.1146e-04,\n",
      "         7.9073e-05, 7.6705e-05, 1.0045e-04, 8.0127e-05],\n",
      "        [4.0306e-01, 2.5159e-01, 2.9031e-01, 4.7420e-02, 4.5261e-03, 1.4183e-03,\n",
      "         5.9570e-04, 3.3858e-04, 4.1480e-04, 3.2593e-04],\n",
      "        [1.0375e-01, 1.8416e-01, 4.2805e-01, 1.9701e-01, 6.2916e-02, 1.0542e-02,\n",
      "         3.8979e-03, 2.8349e-03, 3.1692e-03, 3.6784e-03],\n",
      "        [1.2799e-01, 1.9908e-01, 3.6062e-01, 9.3566e-02, 6.8655e-02, 7.9078e-02,\n",
      "         3.7774e-02, 1.4344e-02, 1.2249e-02, 6.6517e-03],\n",
      "        [7.0436e-03, 2.1273e-02, 3.7952e-02, 1.3377e-01, 3.3477e-01, 2.4926e-01,\n",
      "         1.0312e-01, 5.1289e-02, 3.5233e-02, 2.6294e-02],\n",
      "        [1.8824e-02, 4.2329e-02, 7.2534e-02, 7.7741e-03, 2.3715e-02, 3.8712e-01,\n",
      "         2.5498e-01, 9.8418e-02, 6.0528e-02, 3.3775e-02],\n",
      "        [4.6430e-04, 1.8919e-03, 4.3267e-03, 3.6230e-03, 3.1902e-02, 3.0268e-01,\n",
      "         3.0197e-01, 1.5954e-01, 1.0356e-01, 9.0039e-02],\n",
      "        [4.8047e-02, 6.2101e-02, 7.9600e-02, 1.8682e-02, 1.3617e-02, 2.6788e-01,\n",
      "         3.0779e-01, 8.9905e-02, 7.1555e-02, 4.0823e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi đã dàng hết sự_nghiệp làm_việc cho những công_ty trong\n",
      "Reference: i &apos;ve spent most of my career working for\n",
      "Model: <SOS> i &apos;ve been been career to to for the\n",
      "Attention Weights: tensor([[2.7051e-02, 7.1845e-01, 2.5390e-01, 5.4305e-04, 4.2286e-05, 9.3562e-06,\n",
      "         1.2399e-06, 1.2924e-08, 1.5899e-08, 3.6482e-08],\n",
      "        [1.5209e-03, 1.6997e-02, 9.6320e-01, 1.7895e-02, 3.7198e-04, 1.5230e-05,\n",
      "         2.5405e-06, 7.3236e-07, 5.0878e-07, 2.6371e-07],\n",
      "        [3.8505e-04, 3.3822e-02, 4.3168e-01, 4.1298e-01, 1.1607e-01, 4.3375e-03,\n",
      "         4.5165e-04, 1.5247e-04, 1.0297e-04, 1.9107e-05],\n",
      "        [2.0307e-04, 3.2846e-04, 2.1384e-02, 3.1878e-01, 5.4365e-01, 9.2048e-02,\n",
      "         1.3268e-02, 5.0993e-03, 4.2318e-03, 1.0028e-03],\n",
      "        [4.6078e-05, 1.1535e-04, 2.2765e-02, 4.1585e-01, 4.6482e-01, 8.0714e-02,\n",
      "         8.4165e-03, 3.0485e-03, 3.6945e-03, 5.2971e-04],\n",
      "        [7.3597e-05, 2.8195e-04, 1.7552e-03, 4.4963e-02, 1.3414e-01, 4.8785e-01,\n",
      "         2.8168e-01, 1.1593e-02, 2.1504e-02, 1.6161e-02],\n",
      "        [7.9491e-05, 5.0321e-05, 2.8198e-04, 3.1522e-03, 2.7627e-02, 2.0249e-01,\n",
      "         2.6716e-01, 1.4523e-01, 2.9895e-01, 5.4984e-02],\n",
      "        [9.6317e-05, 3.8042e-05, 5.5905e-05, 2.3709e-04, 7.4592e-03, 1.0431e-01,\n",
      "         2.9772e-01, 1.4002e-01, 2.4776e-01, 2.0231e-01],\n",
      "        [1.7307e-06, 7.0188e-07, 4.6381e-06, 2.6710e-05, 7.0615e-04, 9.2569e-03,\n",
      "         4.4694e-02, 1.2759e-01, 3.9730e-01, 4.2041e-01]])\n",
      "\n",
      "Epoch: 5.14, Train Loss: 2.56, Val Loss: 4.08, Train BLEU: 17.90, Val BLEU: 11.54, Minutes Elapsed: 266.37\n",
      "Sampling from training predictions...\n",
      "Source: có những dòng trông như thế_này khi bàn về biến_đổi\n",
      "Reference: headlines that look like this when they have to\n",
      "Model: <SOS> there are places like when when the age about\n",
      "Attention Weights: tensor([[9.9888e-01, 4.4421e-04, 5.6689e-04, 1.0836e-04, 1.4464e-06, 3.8247e-07,\n",
      "         1.1115e-08, 6.4702e-09, 7.8514e-10, 1.2468e-09],\n",
      "        [6.1101e-01, 5.0340e-02, 2.5814e-01, 7.4871e-02, 2.1981e-03, 3.1824e-03,\n",
      "         1.5009e-04, 6.7391e-05, 2.3031e-05, 1.6235e-05],\n",
      "        [1.6896e-01, 2.3095e-01, 3.8240e-01, 1.8379e-01, 1.3122e-02, 1.9623e-02,\n",
      "         6.0880e-04, 3.2214e-04, 1.6062e-04, 7.0261e-05],\n",
      "        [1.1995e-02, 5.1027e-03, 3.2929e-02, 9.8902e-02, 1.1371e-01, 4.8721e-01,\n",
      "         1.9136e-01, 4.2125e-02, 9.1359e-03, 7.5328e-03],\n",
      "        [7.6277e-03, 1.5729e-03, 6.6863e-03, 2.5267e-02, 2.1574e-02, 3.9615e-01,\n",
      "         2.1720e-01, 1.9121e-01, 7.3555e-02, 5.9153e-02],\n",
      "        [2.0360e-04, 2.1875e-04, 7.5971e-04, 3.3234e-03, 2.0340e-02, 2.2389e-01,\n",
      "         2.7519e-01, 2.4112e-01, 1.1351e-01, 1.2144e-01],\n",
      "        [5.5584e-04, 2.0587e-04, 1.2436e-03, 2.2377e-03, 2.1379e-03, 3.8633e-02,\n",
      "         7.6701e-02, 3.9026e-01, 2.4346e-01, 2.4456e-01],\n",
      "        [9.8400e-05, 1.2088e-04, 2.8573e-03, 4.6887e-03, 3.5369e-03, 1.5923e-02,\n",
      "         5.2015e-02, 1.9677e-01, 1.5219e-01, 5.7181e-01],\n",
      "        [1.0892e-02, 1.4155e-03, 1.0794e-02, 1.5115e-02, 5.2688e-03, 6.4198e-02,\n",
      "         1.4842e-01, 4.4402e-01, 1.4716e-01, 1.5272e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi tin_tưởng rằng các bạn sẽ nhìn_thấy ngày_càng nhiều người\n",
      "Reference: i &apos;m confident that you will see more and\n",
      "Model: <SOS> i &apos;m sure you &apos;ll &apos;ll see a people\n",
      "Attention Weights: tensor([[2.4634e-01, 5.9448e-01, 1.5865e-01, 4.3371e-04, 5.6098e-05, 2.5658e-05,\n",
      "         3.2202e-06, 9.9478e-07, 3.3420e-07, 3.6281e-08],\n",
      "        [1.1639e-02, 9.7361e-01, 1.4072e-02, 3.7580e-04, 1.6253e-04, 9.2859e-05,\n",
      "         4.0214e-05, 2.0115e-06, 1.2660e-06, 2.7953e-07],\n",
      "        [6.6371e-03, 5.2700e-01, 4.4789e-01, 9.4383e-03, 4.2602e-03, 3.5743e-03,\n",
      "         1.0616e-03, 1.1257e-04, 2.5818e-05, 6.1547e-06],\n",
      "        [2.8619e-03, 3.1908e-02, 5.4992e-02, 1.1668e-01, 3.3091e-01, 3.0356e-01,\n",
      "         1.3863e-01, 1.6021e-02, 3.4495e-03, 9.8417e-04],\n",
      "        [4.3844e-04, 4.3702e-03, 3.4491e-02, 2.3443e-01, 3.3637e-01, 1.8494e-01,\n",
      "         1.6291e-01, 3.0071e-02, 8.6199e-03, 3.3711e-03],\n",
      "        [4.0048e-06, 4.6999e-04, 1.1995e-03, 8.7275e-03, 9.3125e-02, 3.3413e-01,\n",
      "         4.9962e-01, 5.4318e-02, 6.8271e-03, 1.5759e-03],\n",
      "        [2.3372e-05, 8.5925e-04, 2.2758e-03, 3.2754e-03, 3.9375e-02, 3.0388e-01,\n",
      "         5.6306e-01, 6.9718e-02, 1.4287e-02, 3.2405e-03],\n",
      "        [3.0661e-07, 1.2981e-05, 6.3246e-05, 2.2881e-04, 1.6494e-03, 4.8780e-03,\n",
      "         1.3304e-01, 5.6868e-01, 2.4939e-01, 4.2056e-02],\n",
      "        [4.8056e-07, 3.3685e-05, 1.2776e-04, 2.2827e-04, 2.3008e-03, 8.4190e-03,\n",
      "         1.1642e-01, 4.8261e-01, 3.3246e-01, 5.7400e-02]])\n",
      "\n",
      "Epoch: 5.19, Train Loss: 2.60, Val Loss: 4.08, Train BLEU: 17.25, Val BLEU: 10.62, Minutes Elapsed: 268.95\n",
      "Sampling from training predictions...\n",
      "Source: bạn có_thể bị các bạch_cầu tấn_công trong động_mạch . <EOS>\n",
      "Reference: you could be attacked by white blood cells in\n",
      "Model: <SOS> you can be be in the in in the\n",
      "Attention Weights: tensor([[4.1324e-01, 5.8304e-01, 3.6992e-03, 1.0167e-05, 8.7377e-06, 1.1941e-06,\n",
      "         7.3979e-08, 3.7569e-09, 1.2841e-09, 5.7192e-10],\n",
      "        [2.4496e-02, 4.5542e-01, 5.1622e-01, 2.4792e-03, 9.7983e-04, 3.3261e-04,\n",
      "         5.7400e-05, 1.4091e-05, 1.2142e-06, 5.2635e-07],\n",
      "        [2.3667e-03, 6.7857e-02, 9.0298e-01, 1.9183e-02, 5.5845e-03, 1.8066e-03,\n",
      "         1.7700e-04, 3.9254e-05, 4.4165e-06, 2.1164e-06],\n",
      "        [7.0719e-04, 3.0128e-03, 5.0293e-01, 2.3393e-01, 1.5525e-01, 9.7504e-02,\n",
      "         5.0973e-03, 1.5319e-03, 3.2222e-05, 1.2076e-05],\n",
      "        [1.2079e-04, 5.6796e-04, 4.6586e-02, 2.0108e-01, 2.5654e-01, 4.5492e-01,\n",
      "         3.0496e-02, 9.2206e-03, 3.4232e-04, 1.3472e-04],\n",
      "        [8.8964e-04, 1.3825e-03, 2.2188e-02, 7.2655e-02, 4.1126e-01, 3.8677e-01,\n",
      "         7.5054e-02, 2.7671e-02, 1.4542e-03, 6.7762e-04],\n",
      "        [3.5213e-05, 2.2711e-04, 9.8689e-04, 1.2453e-02, 1.3655e-01, 5.1866e-01,\n",
      "         1.8073e-01, 1.4429e-01, 4.4173e-03, 1.6431e-03],\n",
      "        [1.9362e-04, 2.6583e-04, 1.4612e-03, 1.1783e-03, 3.1995e-02, 2.0680e-01,\n",
      "         4.3380e-01, 2.6470e-01, 3.3193e-02, 2.6407e-02],\n",
      "        [2.2125e-04, 8.5148e-04, 9.3170e-04, 1.0071e-03, 1.1134e-02, 4.5432e-02,\n",
      "         2.0154e-01, 7.0104e-01, 1.9705e-02, 1.8131e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: và tôi ở đây ngày hôm_nay . <EOS> <PAD> <PAD>\n",
      "Reference: and here i am today . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> and i &apos;m here here today <EOS> . .\n",
      "Attention Weights: tensor([[0.0006, 0.2522, 0.7434, 0.0036, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0039, 0.9837, 0.0123, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0775, 0.8996, 0.0154, 0.0062, 0.0011, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0505, 0.8979, 0.0354, 0.0131, 0.0026, 0.0003, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0003, 0.1630, 0.5845, 0.1225, 0.0700, 0.0474, 0.0102, 0.0020, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0003, 0.0021, 0.0188, 0.3592, 0.5232, 0.0689, 0.0274, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0002, 0.0012, 0.0099, 0.1054, 0.4922, 0.1911, 0.2000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0007, 0.0026, 0.0081, 0.1064, 0.3550, 0.2281, 0.2988, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0603, 0.2798, 0.0378, 0.0910, 0.1410, 0.1180, 0.2718, 0.0000,\n",
      "         0.0000]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5.24, Train Loss: 2.65, Val Loss: 4.06, Train BLEU: 16.45, Val BLEU: 10.46, Minutes Elapsed: 271.47\n",
      "Sampling from training predictions...\n",
      "Source: bạn đã lầm . vì_thế tôi đã ngồi ở cạnh\n",
      "Reference: you would be wrong . so i sat there\n",
      "Model: <SOS> you &apos;ve . . . so i sat sitting\n",
      "Attention Weights: tensor([[3.0080e-01, 4.9313e-01, 2.0569e-01, 3.7649e-04, 5.0679e-06, 8.1996e-08,\n",
      "         1.0309e-07, 1.8670e-07, 5.9418e-08, 5.2502e-09],\n",
      "        [1.6276e-02, 2.4710e-01, 7.2628e-01, 9.2943e-03, 7.0124e-04, 1.5518e-05,\n",
      "         7.7007e-05, 2.2317e-04, 2.9428e-05, 3.4212e-06],\n",
      "        [2.0848e-02, 1.9210e-01, 7.0769e-01, 7.4813e-02, 2.6674e-03, 1.1385e-04,\n",
      "         2.8379e-04, 1.3104e-03, 1.7203e-04, 9.1339e-06],\n",
      "        [7.4984e-04, 4.7822e-03, 6.9324e-02, 7.4067e-01, 1.7301e-01, 3.7239e-03,\n",
      "         1.7579e-03, 4.9715e-03, 7.7620e-04, 2.3202e-04],\n",
      "        [9.4536e-04, 3.0237e-03, 5.8936e-03, 2.4084e-01, 7.0556e-01, 2.0143e-02,\n",
      "         7.3609e-03, 1.1569e-02, 2.9265e-03, 1.7359e-03],\n",
      "        [2.9657e-03, 4.0856e-03, 2.8152e-03, 1.2912e-01, 8.0927e-01, 2.4271e-02,\n",
      "         1.3253e-02, 1.0257e-02, 2.3197e-03, 1.6427e-03],\n",
      "        [1.9863e-03, 1.8694e-03, 1.5422e-03, 2.3647e-02, 2.6878e-01, 1.7577e-01,\n",
      "         3.0462e-01, 1.9497e-01, 1.8583e-02, 8.2345e-03],\n",
      "        [1.4652e-03, 5.6553e-03, 3.4188e-02, 9.8170e-03, 6.4863e-02, 6.9844e-02,\n",
      "         2.9490e-01, 4.9613e-01, 2.1042e-02, 2.0862e-03],\n",
      "        [1.4800e-04, 9.4540e-04, 1.7989e-02, 1.1972e-02, 8.5415e-03, 7.6496e-03,\n",
      "         1.3634e-01, 7.0124e-01, 1.1114e-01, 4.0351e-03]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: hai đứa con_trai nhỏ , giờ không còn nhỏ nữa\n",
      "Reference: her two little boys , not so little anymore\n",
      "Model: <SOS> two thousand , , , it &apos;t little little\n",
      "Attention Weights: tensor([[9.9833e-01, 1.5268e-03, 1.3050e-04, 8.2626e-06, 8.8680e-08, 2.4316e-08,\n",
      "         1.3500e-08, 1.2433e-09, 1.5205e-10, 7.4008e-11],\n",
      "        [3.7241e-01, 2.0157e-01, 3.8893e-01, 3.5000e-02, 9.8778e-04, 3.6045e-04,\n",
      "         5.8294e-04, 9.2473e-05, 5.2414e-05, 1.5252e-05],\n",
      "        [4.0085e-02, 1.6042e-01, 4.3797e-01, 1.2001e-01, 1.5633e-01, 5.3075e-02,\n",
      "         2.1921e-02, 8.1199e-03, 1.2768e-03, 7.8595e-04],\n",
      "        [3.3788e-03, 1.9394e-02, 4.2833e-01, 1.0607e-01, 2.7390e-01, 1.0855e-01,\n",
      "         3.2805e-02, 1.5578e-02, 4.9858e-03, 7.0117e-03],\n",
      "        [7.0199e-04, 4.1254e-03, 1.2448e-01, 3.4275e-02, 2.6646e-01, 4.8576e-01,\n",
      "         6.6412e-02, 8.9045e-03, 2.1603e-03, 6.7297e-03],\n",
      "        [1.3673e-04, 4.0720e-04, 1.4017e-02, 8.2828e-03, 1.5725e-01, 7.5593e-01,\n",
      "         4.4605e-02, 7.5230e-03, 1.7712e-03, 1.0072e-02],\n",
      "        [1.1325e-03, 1.6782e-03, 2.1302e-02, 1.7582e-02, 6.2563e-02, 5.1286e-01,\n",
      "         2.5764e-01, 8.2268e-02, 2.1660e-02, 2.1311e-02],\n",
      "        [9.3988e-04, 1.5205e-03, 4.1490e-03, 1.4643e-03, 2.1295e-02, 8.8910e-02,\n",
      "         4.5572e-01, 2.5696e-01, 8.5257e-02, 8.3785e-02],\n",
      "        [5.2382e-04, 7.4166e-04, 1.3181e-02, 3.7713e-03, 2.3673e-02, 7.0092e-02,\n",
      "         1.5140e-01, 3.1539e-01, 1.6023e-01, 2.6100e-01]])\n",
      "\n",
      "Epoch: 5.29, Train Loss: 2.67, Val Loss: 4.10, Train BLEU: 16.45, Val BLEU: 10.46, Minutes Elapsed: 274.02\n",
      "Sampling from training predictions...\n",
      "Source: tôi có_thể có một sự_nghiệp hoàn_hảo trong các ngành khoa_học_chính\n",
      "Reference: i could have a perfectly good career in mainstream\n",
      "Model: <SOS> i can have a conference conference in in the\n",
      "Attention Weights: tensor([[5.4129e-01, 4.5215e-01, 6.5036e-03, 5.1361e-05, 5.3317e-06, 8.7480e-07,\n",
      "         1.2049e-07, 7.0368e-09, 4.2077e-09, 3.7812e-09],\n",
      "        [3.4947e-02, 9.4578e-01, 1.9138e-02, 9.3335e-05, 3.2498e-05, 7.9531e-06,\n",
      "         1.7321e-06, 6.7496e-07, 1.0027e-06, 7.6570e-07],\n",
      "        [1.8183e-02, 3.8247e-01, 5.6649e-01, 2.1209e-02, 9.8112e-03, 1.6637e-03,\n",
      "         9.0575e-05, 2.1226e-05, 3.4755e-05, 2.8914e-05],\n",
      "        [2.3129e-04, 1.6128e-03, 2.5025e-01, 4.2702e-01, 1.7547e-01, 1.4365e-01,\n",
      "         1.4321e-03, 7.6638e-05, 1.1485e-04, 1.4399e-04],\n",
      "        [1.3411e-05, 1.5005e-04, 2.1979e-03, 2.1694e-02, 6.0555e-01, 3.5623e-01,\n",
      "         1.1932e-02, 6.1599e-04, 5.5905e-04, 1.0618e-03],\n",
      "        [6.4288e-05, 5.5036e-04, 5.5858e-04, 1.4598e-02, 8.2533e-01, 1.2441e-01,\n",
      "         3.0689e-02, 6.2123e-04, 1.7831e-03, 1.3917e-03],\n",
      "        [2.8080e-04, 3.5332e-03, 8.4655e-04, 4.3417e-03, 3.6985e-01, 1.3537e-01,\n",
      "         3.0912e-01, 5.9673e-02, 8.1031e-02, 3.5958e-02],\n",
      "        [1.6355e-04, 4.0198e-04, 1.7581e-04, 1.2857e-03, 8.1549e-02, 7.6281e-02,\n",
      "         4.4327e-01, 1.1162e-01, 1.2786e-01, 1.5739e-01],\n",
      "        [1.3308e-05, 1.1678e-05, 6.4648e-05, 2.8472e-04, 1.3633e-02, 1.3103e-02,\n",
      "         9.9894e-02, 1.4936e-01, 3.5297e-01, 3.7066e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: một_số nơi tôi coi_như nhà mình . <EOS> <PAD> <PAD>\n",
      "Reference: some i even considered like my second home .\n",
      "Model: <SOS> some of my forced my . . . .\n",
      "Attention Weights: tensor([[0.9931, 0.0069, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2556, 0.7165, 0.0115, 0.0150, 0.0013, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.3340, 0.3909, 0.0733, 0.1707, 0.0272, 0.0039, 0.0002, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0073, 0.1726, 0.0630, 0.5638, 0.1665, 0.0255, 0.0009, 0.0002, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0009, 0.0073, 0.0013, 0.5606, 0.3407, 0.0855, 0.0030, 0.0006, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0004, 0.0026, 0.0008, 0.4213, 0.3754, 0.1434, 0.0373, 0.0187, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0005, 0.0062, 0.0063, 0.2111, 0.2278, 0.1459, 0.1534, 0.2488, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0033, 0.0129, 0.0108, 0.2769, 0.2693, 0.1227, 0.1420, 0.1621, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0007, 0.0131, 0.0115, 0.1096, 0.2437, 0.1145, 0.1540, 0.3527, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 5.34, Train Loss: 2.70, Val Loss: 4.08, Train BLEU: 15.87, Val BLEU: 10.30, Minutes Elapsed: 276.56\n",
      "Sampling from training predictions...\n",
      "Source: đây là hội_trường carnegie . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: this is carnegie hall . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> this is the square . <EOS> . . <EOS>\n",
      "Attention Weights: tensor([[0.8248, 0.1750, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0224, 0.8405, 0.1355, 0.0016, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0185, 0.2452, 0.6836, 0.0509, 0.0016, 0.0003, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0022, 0.0114, 0.8102, 0.1707, 0.0049, 0.0006, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0004, 0.0014, 0.5826, 0.2207, 0.1477, 0.0472, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0004, 0.0079, 0.0140, 0.0982, 0.8792, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0474, 0.0811, 0.1666, 0.0443, 0.1117, 0.5489, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0265, 0.2140, 0.6844, 0.0170, 0.0208, 0.0373, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0037, 0.0083, 0.5484, 0.1032, 0.0445, 0.2919, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: những gì cậu_bé nhớ được , là em bị bắt\n",
      "Reference: for as long as he can recall , he\n",
      "Model: <SOS> what he he he , was , , he\n",
      "Attention Weights: tensor([[7.3478e-02, 9.1244e-01, 1.0517e-02, 3.5513e-03, 1.3804e-05, 6.3444e-08,\n",
      "         3.6641e-09, 2.4272e-10, 1.8593e-10, 2.9972e-11],\n",
      "        [1.5844e-02, 7.8036e-02, 3.1641e-01, 5.8310e-01, 6.4041e-03, 1.6146e-04,\n",
      "         1.4903e-05, 7.5787e-06, 1.7662e-05, 1.9331e-06],\n",
      "        [4.4802e-03, 8.3219e-03, 4.6906e-02, 8.5279e-01, 8.0611e-02, 2.7960e-03,\n",
      "         1.2895e-03, 3.1381e-04, 2.2708e-03, 2.1647e-04],\n",
      "        [6.0548e-04, 5.2681e-03, 5.5133e-02, 4.3806e-01, 4.3330e-01, 4.9677e-02,\n",
      "         9.3310e-03, 1.4033e-03, 5.5616e-03, 1.6589e-03],\n",
      "        [3.9472e-04, 2.5719e-03, 4.6897e-02, 3.9674e-01, 4.9045e-01, 4.5857e-02,\n",
      "         8.8598e-03, 8.8771e-04, 5.1801e-03, 2.1544e-03],\n",
      "        [1.2604e-04, 5.2655e-04, 1.8337e-02, 2.4652e-01, 4.7280e-01, 1.4607e-01,\n",
      "         8.5504e-02, 6.1018e-03, 1.8746e-02, 5.2801e-03],\n",
      "        [2.0834e-04, 8.5139e-04, 2.3029e-02, 2.9448e-01, 3.7562e-01, 1.0426e-01,\n",
      "         1.4906e-01, 7.3120e-03, 3.4694e-02, 1.0494e-02],\n",
      "        [1.6062e-05, 4.6680e-05, 6.9049e-04, 2.7234e-02, 5.6640e-02, 2.6077e-01,\n",
      "         5.2488e-01, 4.5091e-02, 5.2261e-02, 3.2369e-02],\n",
      "        [2.5265e-05, 2.6563e-05, 4.2047e-04, 1.4847e-02, 1.3920e-02, 9.9468e-02,\n",
      "         4.5828e-01, 6.9117e-02, 2.9159e-01, 5.2302e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5.38, Train Loss: 2.71, Val Loss: 4.09, Train BLEU: 15.99, Val BLEU: 10.93, Minutes Elapsed: 279.10\n",
      "Sampling from training predictions...\n",
      "Source: những bộ phim này mang đến_nỗi đau quá lớn đến\n",
      "Reference: these films held what was too hurtful to say\n",
      "Model: <SOS> these films video a a a to to <EOS>\n",
      "Attention Weights: tensor([[5.6370e-01, 3.0345e-01, 1.3255e-01, 2.8136e-04, 1.7470e-05, 7.2426e-07,\n",
      "         3.0158e-08, 1.1826e-08, 5.0773e-09, 1.6487e-09],\n",
      "        [4.8360e-02, 1.3870e-01, 8.0773e-01, 3.7304e-03, 1.2153e-03, 1.8747e-04,\n",
      "         2.9017e-05, 3.0460e-05, 1.1273e-05, 4.2437e-06],\n",
      "        [1.8886e-02, 8.2556e-02, 2.0658e-01, 3.1283e-01, 3.1446e-01, 3.7561e-02,\n",
      "         8.5195e-03, 1.3443e-02, 3.3446e-03, 1.8196e-03],\n",
      "        [3.5004e-04, 8.5941e-04, 1.2858e-02, 4.6569e-02, 3.7818e-01, 2.9114e-01,\n",
      "         6.1308e-02, 1.5185e-01, 4.6857e-02, 1.0023e-02],\n",
      "        [1.2471e-05, 6.2826e-05, 1.2379e-03, 2.4845e-03, 3.2278e-02, 2.4625e-01,\n",
      "         1.0082e-01, 3.3776e-01, 2.1107e-01, 6.8031e-02],\n",
      "        [2.0071e-06, 1.9244e-05, 3.0622e-05, 5.7664e-04, 4.7494e-03, 6.3097e-02,\n",
      "         8.0509e-02, 3.2703e-01, 3.3638e-01, 1.8760e-01],\n",
      "        [2.1961e-04, 2.7988e-04, 4.8288e-04, 4.3337e-04, 8.1556e-03, 4.7485e-02,\n",
      "         6.6416e-02, 3.6298e-01, 3.2525e-01, 1.8829e-01],\n",
      "        [6.8436e-05, 1.3908e-04, 7.8394e-05, 3.0298e-04, 1.9535e-03, 1.6286e-02,\n",
      "         3.8601e-02, 3.0124e-01, 3.9380e-01, 2.4752e-01],\n",
      "        [5.4608e-04, 4.7712e-04, 5.3950e-04, 1.8225e-04, 1.1168e-03, 1.5959e-02,\n",
      "         4.3075e-02, 3.0829e-01, 3.5439e-01, 2.7543e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: bạn có_thể thấy tất_cả điều đó . <EOS> <PAD> <PAD>\n",
      "Reference: you can see all of this . <EOS> <PAD>\n",
      "Model: <SOS> you can see all . . . <EOS> you\n",
      "Attention Weights: tensor([[0.8565, 0.1299, 0.0133, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0201, 0.4161, 0.5602, 0.0034, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0019, 0.0237, 0.9227, 0.0437, 0.0069, 0.0008, 0.0001, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0004, 0.0014, 0.2662, 0.4993, 0.2119, 0.0155, 0.0047, 0.0006, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0004, 0.0480, 0.2173, 0.5931, 0.0970, 0.0282, 0.0157, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0005, 0.0021, 0.0146, 0.0418, 0.3395, 0.1352, 0.2356, 0.2308, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0021, 0.0155, 0.0740, 0.0812, 0.1268, 0.0601, 0.2055, 0.4349, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0031, 0.0081, 0.0611, 0.0684, 0.0849, 0.0351, 0.1481, 0.5912, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0066, 0.0453, 0.1302, 0.0468, 0.0756, 0.0382, 0.1360, 0.5213, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 5.43, Train Loss: 2.76, Val Loss: 4.05, Train BLEU: 15.56, Val BLEU: 10.66, Minutes Elapsed: 281.66\n",
      "Sampling from training predictions...\n",
      "Source: nếu bạn có_một ngón_cái rảnh_rỗi , hãy vẫy nó lên\n",
      "Reference: if you have a free thumb , wave it\n",
      "Model: <SOS> if you have a guy thumb , it it\n",
      "Attention Weights: tensor([[5.4730e-01, 4.4751e-01, 5.1611e-03, 1.5038e-05, 6.3283e-06, 2.3585e-08,\n",
      "         7.9237e-09, 8.9586e-09, 4.9872e-10, 1.8501e-09],\n",
      "        [5.0099e-02, 9.2503e-01, 2.4769e-02, 6.1125e-05, 3.8356e-05, 1.6051e-06,\n",
      "         8.2395e-07, 1.4792e-06, 1.6294e-07, 1.2063e-07],\n",
      "        [3.4000e-03, 2.1333e-01, 7.7062e-01, 1.1503e-02, 9.9506e-04, 3.9138e-05,\n",
      "         1.8107e-05, 9.0716e-05, 4.2538e-06, 3.8396e-06],\n",
      "        [8.2858e-04, 1.2246e-01, 7.7934e-01, 8.2238e-02, 1.4404e-02, 8.9323e-05,\n",
      "         5.1012e-05, 5.1833e-04, 3.9120e-05, 3.3481e-05],\n",
      "        [3.2258e-05, 7.2923e-05, 3.0082e-03, 4.9109e-01, 5.0287e-01, 2.3237e-03,\n",
      "         7.1758e-05, 3.0884e-04, 7.4269e-05, 1.4803e-04],\n",
      "        [5.7670e-03, 2.0392e-03, 2.6195e-02, 5.8138e-01, 3.4099e-01, 3.9632e-02,\n",
      "         1.1198e-03, 1.7865e-03, 3.7919e-04, 7.1115e-04],\n",
      "        [7.1948e-03, 3.6806e-03, 2.1948e-02, 1.0091e-01, 2.6123e-01, 4.7645e-01,\n",
      "         6.6288e-02, 4.9803e-02, 6.2508e-03, 6.2358e-03],\n",
      "        [4.0394e-05, 3.8483e-05, 1.3433e-03, 4.0651e-03, 8.9682e-03, 3.3253e-02,\n",
      "         2.4864e-01, 4.6641e-01, 9.5291e-02, 1.4195e-01],\n",
      "        [1.0276e-04, 1.0320e-04, 1.3413e-03, 3.0027e-03, 1.7300e-02, 1.1767e-02,\n",
      "         2.0870e-01, 5.4258e-01, 7.3318e-02, 1.4179e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: nhưng một thứ sẽ mãi_mãi tồn_tại với con là thứ\n",
      "Reference: but the one thing that will always remain with\n",
      "Model: <SOS> but one thing thing is going exists to is\n",
      "Attention Weights: tensor([[1.0872e-01, 7.7051e-01, 1.1762e-01, 3.0998e-03, 4.1455e-05, 1.2869e-05,\n",
      "         4.4292e-07, 8.6828e-09, 2.8067e-08, 2.4719e-08],\n",
      "        [1.8379e-02, 9.3650e-01, 4.3746e-02, 1.3197e-03, 3.9611e-05, 9.4508e-06,\n",
      "         5.1301e-07, 1.6616e-07, 2.1270e-07, 9.1848e-08],\n",
      "        [5.9622e-03, 5.5698e-03, 9.1740e-01, 5.0757e-02, 1.6317e-02, 3.7889e-03,\n",
      "         1.5609e-04, 2.3101e-05, 1.2339e-05, 1.0759e-05],\n",
      "        [7.1157e-03, 1.2914e-02, 6.7032e-02, 2.4493e-01, 6.3186e-01, 2.8223e-02,\n",
      "         6.2982e-03, 1.1223e-03, 3.3824e-04, 1.6516e-04],\n",
      "        [2.6227e-03, 1.1584e-03, 5.4319e-02, 3.9856e-01, 4.0134e-01, 1.2237e-01,\n",
      "         1.4621e-02, 3.3528e-03, 1.1162e-03, 5.4420e-04],\n",
      "        [1.0852e-04, 5.7057e-05, 4.9313e-03, 1.4862e-01, 3.5978e-01, 4.3379e-01,\n",
      "         3.7904e-02, 1.0798e-02, 2.8643e-03, 1.1483e-03],\n",
      "        [1.7841e-04, 2.0353e-04, 1.3638e-03, 3.1272e-02, 3.3096e-01, 4.9990e-01,\n",
      "         9.3109e-02, 1.9426e-02, 1.7576e-02, 6.0132e-03],\n",
      "        [1.3481e-04, 3.5310e-04, 6.3893e-04, 5.0948e-02, 2.6799e-01, 4.6024e-01,\n",
      "         8.8511e-02, 4.3237e-02, 6.5132e-02, 2.2811e-02],\n",
      "        [1.2281e-05, 1.3969e-05, 9.4663e-06, 2.1756e-04, 6.0303e-02, 2.8157e-01,\n",
      "         3.4535e-01, 8.1729e-02, 1.3067e-01, 1.0012e-01]])\n",
      "\n",
      "Epoch: 5.48, Train Loss: 2.72, Val Loss: 4.04, Train BLEU: 16.01, Val BLEU: 10.66, Minutes Elapsed: 284.23\n",
      "Sampling from training predictions...\n",
      "Source: ah , người nào đã làm được điều đó thế\n",
      "Reference: ah , who did that ? eric you did\n",
      "Model: <SOS> ah , who did do do that <EOS> <EOS>\n",
      "Attention Weights: tensor([[9.9655e-01, 3.4516e-03, 4.5149e-07, 1.1665e-07, 2.9882e-08, 5.7826e-08,\n",
      "         8.1801e-08, 2.5749e-08, 3.1251e-09, 7.3721e-10],\n",
      "        [1.4456e-01, 8.5374e-01, 1.3584e-03, 1.8580e-04, 5.5943e-05, 6.8740e-05,\n",
      "         1.6924e-05, 8.9999e-06, 1.3053e-06, 4.1695e-07],\n",
      "        [1.3756e-02, 5.0128e-01, 4.2579e-01, 4.7593e-02, 5.5969e-03, 3.3531e-03,\n",
      "         1.2720e-03, 9.2430e-04, 2.6735e-04, 1.6558e-04],\n",
      "        [7.5029e-04, 1.1324e-02, 9.8474e-02, 6.6249e-01, 8.4841e-02, 9.2360e-02,\n",
      "         3.7287e-02, 9.7609e-03, 1.5627e-03, 1.1471e-03],\n",
      "        [4.8213e-05, 8.5501e-04, 3.7845e-03, 7.2404e-02, 2.0321e-01, 5.0788e-01,\n",
      "         1.8519e-01, 2.1812e-02, 2.9657e-03, 1.8621e-03],\n",
      "        [7.4683e-06, 9.8077e-05, 1.0583e-03, 5.1579e-02, 6.6326e-02, 3.6662e-01,\n",
      "         2.8968e-01, 1.4737e-01, 3.7376e-02, 3.9884e-02],\n",
      "        [2.2097e-05, 3.9635e-04, 6.4072e-04, 7.0519e-03, 1.7184e-02, 5.3985e-02,\n",
      "         1.0045e-01, 1.3625e-01, 1.5441e-01, 5.2962e-01],\n",
      "        [1.8296e-04, 1.7239e-03, 6.4394e-03, 3.2371e-02, 5.7719e-02, 5.1442e-02,\n",
      "         7.1862e-02, 6.1734e-02, 9.3526e-02, 6.2300e-01],\n",
      "        [9.5173e-04, 6.8676e-03, 1.4924e-02, 6.4019e-02, 1.2754e-01, 1.3710e-01,\n",
      "         1.5459e-01, 8.8268e-02, 6.6763e-02, 3.3898e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: hiện_nay ý_tưởng của tôi đã được sử_dụng trên khắp kenya\n",
      "Reference: and my idea is also being used now all\n",
      "Model: <SOS> now my idea was been in in in the\n",
      "Attention Weights: tensor([[9.9088e-01, 9.1097e-03, 5.4614e-06, 1.5959e-07, 1.9405e-08, 4.3079e-09,\n",
      "         1.1169e-09, 1.0606e-10, 2.6931e-11, 9.1342e-12],\n",
      "        [1.9534e-02, 9.7342e-01, 5.5505e-03, 8.7473e-04, 4.4755e-04, 1.0957e-04,\n",
      "         5.2882e-05, 6.8076e-06, 2.3499e-06, 1.5022e-06],\n",
      "        [7.9060e-02, 6.6999e-01, 1.9635e-02, 1.9753e-02, 1.0511e-01, 7.6713e-02,\n",
      "         2.5714e-02, 3.1163e-03, 7.4703e-04, 1.5633e-04],\n",
      "        [7.8598e-02, 4.8784e-01, 2.8283e-02, 2.2436e-02, 1.8973e-01, 1.2708e-01,\n",
      "         6.1140e-02, 4.1924e-03, 5.4307e-04, 1.4648e-04],\n",
      "        [2.3766e-03, 3.3151e-02, 1.5015e-02, 1.9237e-02, 2.4327e-01, 4.0448e-01,\n",
      "         2.5074e-01, 2.6792e-02, 3.5437e-03, 1.3976e-03],\n",
      "        [3.6553e-05, 5.9676e-03, 1.9685e-03, 1.0984e-03, 4.9880e-03, 5.3098e-02,\n",
      "         6.8659e-01, 2.2180e-01, 1.6897e-02, 7.5533e-03],\n",
      "        [2.4233e-06, 3.0001e-04, 2.0736e-04, 2.4127e-04, 2.7565e-04, 5.7970e-03,\n",
      "         1.1381e-01, 5.5914e-01, 2.2056e-01, 9.9664e-02],\n",
      "        [5.2691e-05, 5.5378e-04, 1.6690e-04, 2.1451e-04, 6.5720e-04, 4.0298e-03,\n",
      "         4.1423e-02, 2.2713e-01, 4.0840e-01, 3.1738e-01],\n",
      "        [3.0866e-04, 1.3822e-03, 1.5680e-04, 1.0094e-04, 3.8086e-04, 1.9601e-03,\n",
      "         1.5635e-02, 1.2026e-01, 4.8950e-01, 3.7031e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5.53, Train Loss: 2.72, Val Loss: 4.05, Train BLEU: 16.54, Val BLEU: 11.26, Minutes Elapsed: 286.79\n",
      "Sampling from training predictions...\n",
      "Source: khi chúng_tôi tạo 1 khoảng_cách lớn hơn khỏi gian_lận khỏi\n",
      "Reference: when we get bigger distance from cheating , from\n",
      "Model: <SOS> when we created a a , the , ,\n",
      "Attention Weights: tensor([[9.9901e-01, 6.6845e-05, 9.2107e-04, 2.5538e-06, 2.1986e-07, 1.2847e-07,\n",
      "         3.7684e-09, 1.9986e-10, 7.6673e-11, 1.4357e-10],\n",
      "        [5.9059e-02, 8.2831e-01, 1.1213e-01, 4.6205e-04, 3.6700e-05, 5.9595e-06,\n",
      "         2.8202e-06, 7.7345e-07, 2.5206e-07, 1.6588e-07],\n",
      "        [1.7805e-03, 1.9007e-02, 9.7117e-01, 7.1904e-03, 7.4704e-04, 6.8599e-05,\n",
      "         2.4829e-05, 1.0681e-05, 2.0858e-06, 6.9518e-07],\n",
      "        [3.2185e-03, 3.6250e-03, 6.2357e-01, 2.0522e-01, 1.2116e-01, 2.8801e-02,\n",
      "         1.1468e-02, 2.6657e-03, 1.9746e-04, 6.8826e-05],\n",
      "        [2.7662e-04, 9.8023e-05, 7.5940e-03, 3.3916e-02, 6.6127e-01, 2.2213e-01,\n",
      "         4.8276e-02, 2.0877e-02, 4.7184e-03, 8.4235e-04],\n",
      "        [6.4315e-04, 1.3536e-04, 3.6196e-04, 6.2678e-03, 2.5299e-01, 3.1442e-01,\n",
      "         2.4054e-01, 1.3867e-01, 3.6877e-02, 9.0883e-03],\n",
      "        [2.2498e-04, 2.5555e-05, 4.3625e-05, 2.5785e-04, 5.6569e-03, 3.8921e-03,\n",
      "         4.9064e-02, 3.5637e-01, 4.1165e-01, 1.7281e-01],\n",
      "        [2.6230e-04, 2.5381e-04, 6.7511e-04, 7.4381e-04, 4.8205e-03, 3.0743e-03,\n",
      "         1.6050e-02, 2.1117e-01, 4.3871e-01, 3.2424e-01],\n",
      "        [1.2833e-03, 4.9075e-04, 7.5035e-04, 1.0336e-03, 3.8737e-03, 4.5378e-03,\n",
      "         1.2361e-02, 5.8309e-02, 2.4982e-01, 6.6754e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: những tấm hình không phải là về bản_thân <UNK> .\n",
      "Reference: these images are not of issues . they are\n",
      "Model: <SOS> these aren are not <UNK> to . <EOS> &apos;re\n",
      "Attention Weights: tensor([[3.2712e-01, 3.2083e-01, 3.5010e-01, 1.6754e-03, 2.7114e-04, 8.9048e-07,\n",
      "         9.4080e-08, 2.8996e-08, 7.0217e-09, 1.3181e-09],\n",
      "        [7.6602e-03, 4.2972e-02, 4.4097e-01, 4.7942e-01, 2.4957e-02, 2.6805e-03,\n",
      "         8.8943e-04, 4.3543e-04, 1.3140e-05, 1.7439e-06],\n",
      "        [2.0285e-02, 5.5378e-02, 2.0089e-01, 5.7271e-01, 9.2089e-02, 2.7398e-02,\n",
      "         2.1929e-02, 8.5055e-03, 7.0405e-04, 1.0714e-04],\n",
      "        [6.8546e-03, 2.4147e-02, 1.0959e-01, 4.9499e-01, 8.7555e-02, 6.7733e-02,\n",
      "         9.0907e-02, 1.0894e-01, 8.9554e-03, 3.3682e-04],\n",
      "        [5.2446e-03, 6.9480e-03, 4.9293e-02, 1.1268e-01, 8.0839e-02, 1.1811e-01,\n",
      "         2.9424e-01, 2.8138e-01, 5.0138e-02, 1.1249e-03],\n",
      "        [9.9455e-05, 1.0007e-03, 1.4692e-02, 4.4070e-03, 1.5364e-02, 4.0366e-02,\n",
      "         2.1876e-01, 4.9573e-01, 1.7811e-01, 3.1471e-02],\n",
      "        [1.0068e-05, 6.3408e-05, 2.4829e-03, 2.8383e-03, 9.3400e-03, 2.1065e-02,\n",
      "         1.2757e-01, 6.1844e-01, 1.6572e-01, 5.2476e-02],\n",
      "        [1.0660e-05, 1.3567e-04, 2.8692e-03, 2.4974e-02, 2.6279e-03, 1.7529e-02,\n",
      "         5.5420e-02, 6.7128e-01, 8.9677e-02, 1.3548e-01],\n",
      "        [2.5110e-04, 4.7562e-04, 4.7591e-03, 1.3850e-02, 3.9434e-03, 5.6034e-03,\n",
      "         3.1958e-02, 6.7906e-01, 1.2596e-01, 1.3415e-01]])\n",
      "\n",
      "Epoch: 5.58, Train Loss: 2.74, Val Loss: 4.04, Train BLEU: 16.40, Val BLEU: 11.21, Minutes Elapsed: 289.33\n",
      "Sampling from training predictions...\n",
      "Source: chúng_ta hay có xu_hướng , như là một xã_hội ,\n",
      "Reference: and we have a tendency , as a society\n",
      "Model: <SOS> we tend tend , tendency , as a society\n",
      "Attention Weights: tensor([[3.8092e-01, 6.0328e-01, 1.5286e-02, 5.1534e-04, 2.1314e-06, 1.1128e-06,\n",
      "         1.2335e-06, 1.5005e-06, 6.2228e-08, 4.9735e-09],\n",
      "        [2.8823e-03, 9.2359e-01, 6.5873e-02, 7.5165e-03, 2.9786e-05, 2.3423e-05,\n",
      "         3.8522e-05, 3.7329e-05, 1.1134e-05, 1.4211e-06],\n",
      "        [6.9529e-03, 3.5286e-01, 3.0782e-01, 3.2517e-01, 3.7672e-03, 5.8975e-04,\n",
      "         1.2885e-03, 8.2496e-04, 6.9116e-04, 3.2226e-05],\n",
      "        [9.3729e-03, 2.8083e-01, 2.1080e-01, 4.9090e-01, 2.7452e-03, 8.5100e-04,\n",
      "         2.4261e-03, 1.0699e-03, 9.6908e-04, 3.8766e-05],\n",
      "        [3.5460e-04, 8.8585e-03, 2.4548e-01, 6.8843e-01, 3.2359e-02, 5.4670e-03,\n",
      "         1.0075e-02, 5.5163e-03, 3.0501e-03, 4.1216e-04],\n",
      "        [3.4414e-05, 7.0094e-04, 5.8089e-02, 3.0650e-01, 1.4828e-01, 1.8162e-01,\n",
      "         1.9147e-01, 7.4983e-02, 2.9691e-02, 8.6360e-03],\n",
      "        [2.6234e-04, 4.5809e-04, 3.3910e-03, 1.8297e-02, 9.1392e-02, 6.4561e-01,\n",
      "         1.5914e-01, 5.2234e-02, 1.4732e-02, 1.4482e-02],\n",
      "        [8.3186e-06, 2.0599e-04, 2.7757e-03, 1.5435e-02, 4.3594e-03, 2.1492e-02,\n",
      "         4.0222e-01, 5.0086e-01, 4.5524e-02, 7.1183e-03],\n",
      "        [9.7126e-06, 1.4927e-03, 3.5384e-03, 4.3288e-02, 5.4308e-03, 1.8907e-02,\n",
      "         1.8308e-01, 3.0174e-01, 3.8221e-01, 6.0309e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: cô bạn của tôi đã đi cùng tôi . <EOS>\n",
      "Reference: my friend got to come with me . <EOS>\n",
      "Model: <SOS> my friend is me to me me . <EOS>\n",
      "Attention Weights: tensor([[8.0446e-01, 1.9554e-01, 6.0987e-06, 2.8910e-07, 4.5231e-08, 2.0636e-08,\n",
      "         5.5810e-10, 1.1984e-10, 1.8542e-11, 2.9948e-12],\n",
      "        [2.1749e-02, 9.7315e-01, 4.9375e-03, 1.1620e-04, 3.3235e-05, 6.5200e-06,\n",
      "         3.7999e-06, 1.3120e-07, 1.4051e-07, 5.1926e-08],\n",
      "        [5.5865e-03, 6.6497e-02, 6.9108e-01, 1.3232e-01, 8.3965e-02, 1.6001e-02,\n",
      "         4.3790e-03, 7.7949e-05, 7.1722e-05, 2.5184e-05],\n",
      "        [1.3671e-03, 3.6251e-02, 2.9440e-01, 1.2772e-01, 3.1819e-01, 1.6449e-01,\n",
      "         5.4273e-02, 2.2002e-03, 8.3744e-04, 2.7485e-04],\n",
      "        [1.2212e-05, 1.4310e-03, 1.9485e-02, 2.6526e-02, 1.6018e-01, 3.5989e-01,\n",
      "         4.0506e-01, 1.6025e-02, 8.1045e-03, 3.2846e-03],\n",
      "        [1.7379e-06, 4.3023e-05, 9.9387e-04, 8.9402e-03, 3.5751e-02, 1.5821e-01,\n",
      "         6.8675e-01, 5.9275e-02, 3.0442e-02, 1.9595e-02],\n",
      "        [1.8283e-05, 1.5810e-04, 6.6276e-04, 4.1399e-03, 3.3300e-02, 9.4873e-02,\n",
      "         6.9697e-01, 4.6396e-02, 7.2897e-02, 5.0589e-02],\n",
      "        [2.1901e-05, 2.1845e-04, 6.4115e-04, 1.7715e-03, 1.0350e-02, 3.5867e-02,\n",
      "         6.7129e-01, 5.5994e-02, 1.3890e-01, 8.4949e-02],\n",
      "        [3.2020e-05, 1.7195e-04, 1.0287e-03, 2.1108e-03, 3.5531e-02, 6.1029e-02,\n",
      "         4.2975e-01, 7.4481e-02, 2.0848e-01, 1.8738e-01]])\n",
      "\n",
      "Epoch: 5.62, Train Loss: 2.74, Val Loss: 4.06, Train BLEU: 16.30, Val BLEU: 11.41, Minutes Elapsed: 291.87\n",
      "Sampling from training predictions...\n",
      "Source: tôi huýt_gió lúc đang đi xe_đạp , tôi huýt_gió ở\n",
      "Reference: i whistled on &#91; my &#93; bike . i\n",
      "Model: <SOS> i whistled on the bike &#93; , , i\n",
      "Attention Weights: tensor([[7.8646e-02, 9.1257e-01, 8.7585e-03, 2.2784e-05, 4.9848e-07, 4.8140e-08,\n",
      "         5.9123e-10, 1.8381e-09, 4.9583e-09, 1.3602e-09],\n",
      "        [6.0872e-04, 9.9312e-01, 6.0764e-03, 1.8503e-04, 6.6949e-06, 6.2481e-06,\n",
      "         2.6159e-07, 9.0378e-08, 4.6477e-07, 1.0346e-07],\n",
      "        [2.7748e-03, 3.9852e-01, 4.2408e-01, 1.6221e-01, 1.1936e-02, 4.1455e-04,\n",
      "         2.2898e-05, 3.8854e-06, 3.5880e-05, 9.0044e-06],\n",
      "        [1.0601e-03, 4.6906e-02, 3.6133e-01, 3.3065e-01, 1.3923e-01, 1.1844e-01,\n",
      "         1.5510e-03, 1.4580e-04, 3.9746e-04, 2.9163e-04],\n",
      "        [7.6633e-05, 9.4605e-04, 2.7975e-02, 2.5985e-01, 2.3356e-01, 4.4932e-01,\n",
      "         2.2062e-02, 1.4138e-03, 2.7160e-03, 2.0774e-03],\n",
      "        [1.1540e-03, 1.1768e-03, 5.4352e-02, 3.4571e-01, 1.4844e-01, 2.2323e-01,\n",
      "         1.5984e-01, 5.0214e-02, 1.1438e-02, 4.4485e-03],\n",
      "        [3.5708e-05, 5.7493e-06, 4.2971e-04, 1.8072e-02, 1.4841e-02, 1.7596e-01,\n",
      "         4.7418e-01, 1.8350e-01, 9.0065e-02, 4.2909e-02],\n",
      "        [2.1005e-05, 1.4297e-05, 2.1874e-04, 5.1525e-03, 4.7781e-03, 1.7147e-02,\n",
      "         2.8322e-01, 5.6154e-01, 1.0143e-01, 2.6477e-02],\n",
      "        [7.5288e-06, 1.5501e-05, 9.6560e-04, 4.8359e-03, 2.4646e-03, 1.0565e-02,\n",
      "         1.4380e-01, 2.2409e-01, 5.2335e-01, 8.9909e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: chúng_ta không đụng vào mỗi người xung_quanh , vì_vậy có\n",
      "Reference: we don &apos;t bump into every neighbor , so\n",
      "Model: <SOS> we don &apos;t choose to each other , there\n",
      "Attention Weights: tensor([[2.5430e-01, 6.9850e-01, 4.7106e-02, 9.0339e-05, 1.5127e-06, 4.1132e-08,\n",
      "         5.1133e-08, 2.7742e-09, 2.9955e-09, 1.1013e-09],\n",
      "        [3.1997e-03, 9.8448e-01, 1.2108e-02, 1.6388e-04, 2.8089e-05, 9.1524e-06,\n",
      "         8.5282e-06, 4.3649e-07, 6.3821e-07, 3.0029e-07],\n",
      "        [3.6841e-03, 8.4392e-01, 1.4489e-01, 6.3260e-03, 8.1091e-04, 2.5210e-04,\n",
      "         1.0173e-04, 4.3677e-06, 1.3627e-06, 1.5090e-06],\n",
      "        [1.8097e-04, 2.7808e-03, 9.2547e-01, 6.3086e-02, 7.3570e-03, 8.7966e-04,\n",
      "         2.2129e-04, 1.4849e-05, 5.8239e-06, 3.1166e-06],\n",
      "        [1.6732e-04, 5.4129e-03, 1.2121e-01, 2.7259e-01, 4.8615e-01, 9.4978e-02,\n",
      "         1.8487e-02, 7.2519e-04, 1.7678e-04, 9.4876e-05],\n",
      "        [1.9062e-04, 8.4281e-04, 6.6688e-03, 7.6914e-02, 6.7482e-01, 1.2836e-01,\n",
      "         9.7509e-02, 1.1124e-02, 2.7811e-03, 7.9222e-04],\n",
      "        [2.9757e-05, 1.3957e-04, 1.9118e-04, 1.3399e-02, 6.4326e-01, 1.5731e-01,\n",
      "         9.4211e-02, 7.4124e-02, 1.6228e-02, 1.1093e-03],\n",
      "        [9.4064e-06, 3.3666e-04, 1.7429e-05, 2.0068e-03, 4.2977e-02, 8.9637e-02,\n",
      "         1.4476e-01, 5.7197e-01, 1.4499e-01, 3.2949e-03],\n",
      "        [1.5942e-06, 5.3129e-05, 5.5407e-05, 1.4930e-03, 4.2493e-02, 1.0834e-01,\n",
      "         2.1866e-01, 3.3556e-01, 2.8785e-01, 5.4938e-03]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5.67, Train Loss: 2.81, Val Loss: 4.09, Train BLEU: 14.90, Val BLEU: 10.40, Minutes Elapsed: 294.41\n",
      "Sampling from training predictions...\n",
      "Source: tôi đến louisburg ở miền bắc carolina , phí đông_nam\n",
      "Reference: so i went to louisburg , north carolina ,\n",
      "Model: <SOS> i went went to louisburg to north carolina ,\n",
      "Attention Weights: tensor([[9.8358e-01, 1.6406e-02, 1.3588e-05, 2.5784e-07, 1.2824e-08, 8.5553e-09,\n",
      "         3.4604e-09, 2.9120e-10, 1.6674e-09, 1.6160e-09],\n",
      "        [1.4322e-01, 8.4494e-01, 1.1581e-02, 1.5435e-04, 3.7426e-05, 3.7988e-05,\n",
      "         2.3508e-05, 1.3170e-06, 7.2865e-06, 1.6612e-06],\n",
      "        [3.1314e-02, 7.4332e-01, 2.1859e-01, 4.7721e-03, 5.5662e-04, 1.0454e-03,\n",
      "         3.7513e-04, 4.6761e-06, 1.7813e-05, 6.8483e-06],\n",
      "        [1.4262e-01, 6.2729e-01, 2.1275e-01, 1.0409e-02, 2.4029e-03, 3.1911e-03,\n",
      "         1.2666e-03, 1.7130e-05, 3.1754e-05, 1.7808e-05],\n",
      "        [1.8259e-04, 6.0877e-03, 8.2529e-01, 9.6587e-02, 3.0456e-02, 2.0298e-02,\n",
      "         2.0452e-02, 2.9706e-04, 3.0846e-04, 4.4929e-05],\n",
      "        [2.4537e-04, 1.2510e-03, 1.5586e-01, 4.0112e-01, 1.0356e-01, 1.5359e-01,\n",
      "         1.7794e-01, 3.5977e-03, 2.2838e-03, 5.6110e-04],\n",
      "        [1.7696e-05, 8.0160e-05, 6.1841e-02, 1.2363e-01, 1.1826e-01, 3.2746e-01,\n",
      "         3.5403e-01, 8.7506e-03, 5.4785e-03, 4.5302e-04],\n",
      "        [5.2918e-06, 3.0621e-06, 1.1182e-04, 7.4482e-03, 8.1538e-02, 2.7466e-01,\n",
      "         3.8404e-01, 1.2491e-01, 1.2172e-01, 5.5595e-03],\n",
      "        [1.8279e-05, 1.1899e-04, 4.1791e-04, 8.9093e-03, 4.5642e-02, 7.0289e-02,\n",
      "         6.1412e-02, 1.5446e-01, 5.5226e-01, 1.0647e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: để họ có_thể nhanh_chóng thoát ra khỏi đó , tôi\n",
      "Reference: they had to get out quickly , so i\n",
      "Model: <SOS> to order them to able to out , ,\n",
      "Attention Weights: tensor([[9.9950e-01, 4.6876e-04, 2.6968e-05, 4.9920e-06, 2.0051e-06, 3.6540e-07,\n",
      "         5.9678e-08, 3.2617e-09, 1.7672e-11, 1.3940e-10],\n",
      "        [6.8723e-01, 2.8432e-01, 1.9607e-02, 8.2715e-03, 4.2073e-04, 4.6125e-05,\n",
      "         8.8929e-05, 1.1488e-05, 2.8284e-06, 5.5309e-07],\n",
      "        [3.0727e-01, 5.6597e-01, 7.3804e-02, 4.7726e-02, 4.1516e-03, 3.6691e-04,\n",
      "         5.9060e-04, 8.2155e-05, 2.3634e-05, 5.5739e-06],\n",
      "        [5.4048e-03, 3.8264e-02, 5.9634e-02, 6.5395e-01, 2.0902e-01, 1.9121e-02,\n",
      "         1.3348e-02, 9.9122e-04, 2.1928e-04, 4.8250e-05],\n",
      "        [1.9372e-03, 6.4355e-03, 1.4477e-02, 1.8212e-01, 4.7936e-01, 1.4906e-01,\n",
      "         1.5541e-01, 9.7468e-03, 1.2927e-03, 1.6090e-04],\n",
      "        [5.0396e-04, 6.4665e-03, 9.4644e-03, 1.1369e-01, 5.0340e-01, 1.2871e-01,\n",
      "         2.1824e-01, 1.6185e-02, 2.8391e-03, 4.9959e-04],\n",
      "        [1.4228e-05, 1.5872e-04, 1.3131e-03, 2.2771e-02, 1.2527e-01, 1.4167e-01,\n",
      "         5.4925e-01, 1.1096e-01, 4.6181e-02, 2.4192e-03],\n",
      "        [7.9926e-06, 4.7044e-04, 3.6823e-03, 2.1232e-02, 9.0376e-02, 5.9004e-02,\n",
      "         5.8794e-01, 1.2670e-01, 1.0493e-01, 5.6647e-03],\n",
      "        [4.1602e-05, 3.3249e-04, 2.8415e-03, 9.2855e-03, 1.1463e-02, 1.8645e-02,\n",
      "         3.0509e-01, 1.0863e-01, 4.4982e-01, 9.3847e-02]])\n",
      "\n",
      "Epoch: 5.72, Train Loss: 2.79, Val Loss: 4.08, Train BLEU: 15.88, Val BLEU: 10.58, Minutes Elapsed: 296.96\n",
      "Sampling from training predictions...\n",
      "Source: tôi đã sợ rằng mọi người sẽ nhìn_thấy tôi với\n",
      "Reference: i was afraid that people would see me for\n",
      "Model: <SOS> i &apos;m that that people would me me with\n",
      "Attention Weights: tensor([[3.4056e-02, 1.9633e-01, 7.3083e-01, 3.6070e-02, 2.6269e-03, 3.3772e-05,\n",
      "         4.9280e-05, 1.9575e-06, 2.6677e-07, 3.9599e-07],\n",
      "        [1.8822e-03, 1.6483e-02, 9.2562e-01, 5.5009e-02, 5.5191e-04, 1.0698e-04,\n",
      "         1.9841e-04, 1.4597e-04, 2.2789e-06, 3.2214e-06],\n",
      "        [1.4747e-03, 8.5999e-03, 4.5459e-01, 4.7543e-01, 3.7535e-02, 4.2636e-03,\n",
      "         1.1289e-02, 6.4282e-03, 1.9431e-04, 1.9382e-04],\n",
      "        [2.7358e-04, 3.8121e-04, 1.3580e-02, 2.0802e-01, 3.6680e-01, 5.9981e-02,\n",
      "         2.1646e-01, 1.2261e-01, 7.7135e-03, 4.1761e-03],\n",
      "        [1.0536e-03, 1.2793e-03, 2.2151e-02, 1.4174e-01, 3.5076e-01, 1.1114e-01,\n",
      "         1.8735e-01, 1.3038e-01, 2.5366e-02, 2.8782e-02],\n",
      "        [1.3564e-05, 9.6319e-05, 2.7024e-04, 1.6222e-03, 6.8711e-03, 9.0054e-03,\n",
      "         1.5568e-01, 4.8633e-01, 1.0182e-01, 2.3829e-01],\n",
      "        [1.5683e-04, 8.0892e-04, 8.3921e-03, 8.2992e-03, 4.2148e-03, 4.1048e-03,\n",
      "         1.8043e-01, 5.2845e-01, 1.1416e-01, 1.5099e-01],\n",
      "        [6.3975e-06, 5.5888e-06, 4.3612e-05, 2.0914e-03, 1.4367e-03, 1.8227e-03,\n",
      "         3.3929e-03, 1.1122e-01, 4.7149e-01, 4.0849e-01],\n",
      "        [2.1620e-05, 4.5074e-06, 2.3926e-05, 7.8911e-04, 9.4556e-04, 1.0778e-03,\n",
      "         3.3861e-03, 3.0656e-02, 1.9068e-01, 7.7242e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: khi người dân làng này đòi tự_do , những <UNK>\n",
      "Reference: when these villagers claimed their freedom , the <UNK>\n",
      "Model: <SOS> when this <UNK> this freedom freedom , the <UNK>\n",
      "Attention Weights: tensor([[9.1265e-01, 8.6765e-02, 4.4055e-04, 1.4366e-04, 3.5724e-06, 1.0284e-07,\n",
      "         4.4749e-09, 1.1220e-10, 2.0328e-11, 1.7754e-11],\n",
      "        [1.8537e-02, 8.0227e-01, 1.1675e-01, 6.1610e-02, 4.5268e-04, 2.5486e-04,\n",
      "         1.1726e-04, 3.1612e-06, 1.7600e-06, 1.3003e-06],\n",
      "        [7.2810e-04, 3.2332e-02, 1.9912e-01, 7.5367e-01, 5.4312e-03, 7.8782e-03,\n",
      "         7.7672e-04, 2.8521e-05, 1.8870e-05, 1.0755e-05],\n",
      "        [9.8774e-04, 5.8916e-03, 9.2922e-02, 6.9625e-01, 1.2633e-01, 6.9045e-02,\n",
      "         8.3826e-03, 1.0483e-04, 3.4589e-05, 5.4001e-05],\n",
      "        [2.8066e-04, 2.2277e-03, 2.0327e-02, 7.6987e-02, 6.6841e-02, 2.3703e-01,\n",
      "         5.3001e-01, 4.7476e-02, 1.1018e-02, 7.8045e-03],\n",
      "        [1.2778e-05, 5.4548e-05, 1.2511e-03, 3.4297e-02, 1.4106e-02, 2.7153e-01,\n",
      "         5.3529e-01, 8.6553e-02, 4.2143e-02, 1.4771e-02],\n",
      "        [1.3287e-05, 2.0075e-05, 5.9767e-05, 4.4973e-04, 5.7480e-04, 6.8916e-03,\n",
      "         4.9660e-02, 1.7539e-01, 6.8728e-01, 7.9661e-02],\n",
      "        [2.6322e-06, 7.0191e-07, 2.8626e-06, 5.9892e-05, 1.0777e-04, 1.2321e-03,\n",
      "         4.4253e-03, 2.2571e-01, 6.4618e-01, 1.2228e-01],\n",
      "        [1.7908e-06, 2.7034e-06, 2.9409e-05, 1.0402e-03, 3.8478e-04, 2.3155e-03,\n",
      "         5.9259e-03, 9.8781e-02, 5.8805e-01, 3.0347e-01]])\n",
      "\n",
      "Epoch: 5.77, Train Loss: 2.78, Val Loss: 4.09, Train BLEU: 15.23, Val BLEU: 10.48, Minutes Elapsed: 299.53\n",
      "Sampling from training predictions...\n",
      "Source: mọi người nhảy_múa , hò_hét , uống rượu . <EOS>\n",
      "Reference: people are dancing , shouting and drinking . <EOS>\n",
      "Model: <SOS> people torajans , , shouting , drinking . <EOS>\n",
      "Attention Weights: tensor([[9.1771e-01, 6.9019e-02, 1.3230e-02, 3.2952e-05, 4.4330e-06, 3.1876e-09,\n",
      "         7.3042e-10, 4.4859e-11, 5.0989e-12, 1.3978e-12],\n",
      "        [7.9076e-04, 2.2314e-03, 8.8670e-01, 7.6422e-02, 3.3436e-02, 3.2998e-04,\n",
      "         6.8966e-05, 1.4230e-05, 1.7420e-06, 5.0169e-07],\n",
      "        [2.8707e-03, 1.4647e-02, 1.1207e-01, 6.9639e-01, 1.5785e-01, 1.4074e-02,\n",
      "         1.8610e-03, 2.2184e-04, 9.7077e-06, 1.5149e-06],\n",
      "        [4.8246e-03, 8.4053e-03, 8.9266e-02, 2.2054e-01, 6.5462e-01, 1.4072e-02,\n",
      "         7.6051e-03, 6.2553e-04, 3.0254e-05, 8.2227e-06],\n",
      "        [7.3125e-03, 6.5693e-03, 1.0839e-01, 2.5783e-01, 5.8615e-01, 1.9851e-02,\n",
      "         1.2870e-02, 9.3550e-04, 7.0560e-05, 2.6060e-05],\n",
      "        [9.7184e-04, 6.6210e-04, 1.2696e-02, 5.4478e-02, 6.1641e-01, 1.3932e-01,\n",
      "         1.6428e-01, 1.0527e-02, 4.6777e-04, 1.8939e-04],\n",
      "        [9.7432e-05, 8.5169e-05, 6.0174e-04, 1.9208e-03, 1.8103e-02, 4.5091e-02,\n",
      "         7.6771e-01, 1.4540e-01, 1.7207e-02, 3.7864e-03],\n",
      "        [3.1667e-05, 3.3488e-05, 1.5985e-04, 3.0442e-04, 6.5506e-03, 8.6137e-03,\n",
      "         6.9425e-01, 2.0449e-01, 6.6007e-02, 1.9553e-02],\n",
      "        [3.4132e-04, 1.2279e-04, 1.4678e-03, 1.9434e-03, 5.5868e-03, 1.3014e-02,\n",
      "         4.7795e-01, 2.5975e-01, 1.6402e-01, 7.5807e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: liệu họ có_thể lưu lại toàn_bộ thông_tin của chúng_ta không\n",
      "Reference: can they really store all this information about us\n",
      "Model: <SOS> can they get their their entire their of us\n",
      "Attention Weights: tensor([[9.9818e-01, 1.8133e-03, 3.6783e-06, 1.5235e-06, 5.9033e-09, 8.6489e-11,\n",
      "         4.1404e-12, 5.6088e-13, 2.8445e-14, 9.2958e-14],\n",
      "        [3.6776e-01, 5.6766e-01, 6.1838e-02, 2.6468e-03, 8.1746e-05, 4.1136e-06,\n",
      "         1.6548e-06, 1.5956e-07, 2.9063e-08, 1.1540e-07],\n",
      "        [6.6389e-02, 7.4189e-02, 3.4792e-01, 5.0558e-01, 5.3686e-03, 3.5712e-04,\n",
      "         1.3851e-04, 1.3045e-05, 7.2814e-06, 3.3018e-05],\n",
      "        [8.3531e-04, 2.6329e-04, 3.1260e-03, 7.0670e-01, 2.6983e-01, 1.8122e-02,\n",
      "         1.0239e-03, 2.0435e-05, 1.2972e-05, 6.0239e-05],\n",
      "        [1.2673e-03, 1.3361e-03, 3.4886e-03, 2.0754e-01, 2.5025e-01, 3.3686e-01,\n",
      "         1.9401e-01, 3.3314e-03, 1.1390e-03, 7.7697e-04],\n",
      "        [3.7167e-04, 3.7261e-04, 5.5733e-04, 1.3679e-02, 1.4303e-01, 5.8030e-01,\n",
      "         2.5347e-01, 4.2068e-03, 1.8084e-03, 2.2065e-03],\n",
      "        [3.1348e-06, 8.3677e-06, 5.6636e-05, 3.9858e-04, 4.9133e-03, 3.9318e-01,\n",
      "         5.0169e-01, 3.0898e-02, 4.7842e-02, 2.1012e-02],\n",
      "        [3.6464e-06, 1.2664e-05, 5.4013e-05, 3.6625e-04, 3.2154e-03, 2.4709e-01,\n",
      "         4.6487e-01, 7.9742e-02, 1.2887e-01, 7.5778e-02],\n",
      "        [2.3684e-05, 4.9627e-05, 1.7463e-04, 4.6496e-04, 2.3080e-03, 8.0652e-02,\n",
      "         3.0229e-01, 1.3179e-01, 1.7689e-01, 3.0535e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5.82, Train Loss: 2.75, Val Loss: 4.05, Train BLEU: 16.27, Val BLEU: 10.84, Minutes Elapsed: 302.08\n",
      "Sampling from training predictions...\n",
      "Source: và một loại_hình nhạc mới ra_đời . <EOS> <PAD> <PAD>\n",
      "Reference: and another new form of music was born .\n",
      "Model: <SOS> and a new of of came came . .\n",
      "Attention Weights: tensor([[0.0059, 0.9915, 0.0026, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0016, 0.8622, 0.1325, 0.0036, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0342, 0.8197, 0.0939, 0.0317, 0.0196, 0.0005, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0005, 0.0517, 0.5151, 0.2182, 0.0746, 0.1123, 0.0246, 0.0031, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0011, 0.0038, 0.0415, 0.0851, 0.5434, 0.2177, 0.1074, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0028, 0.0029, 0.0590, 0.1388, 0.7443, 0.0380, 0.0142, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0161, 0.0084, 0.1044, 0.1964, 0.6166, 0.0434, 0.0145, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0005, 0.0438, 0.0078, 0.0731, 0.2476, 0.5033, 0.0936, 0.0304, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0047, 0.0009, 0.0267, 0.2055, 0.4200, 0.1543, 0.1878, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: trong đêm_tối lạnh_lẽo <UNK> . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: in the cold , windy night . <EOS> <PAD>\n",
      "Model: <SOS> in the <UNK> of , <UNK> . <EOS> is\n",
      "Attention Weights: tensor([[0.9647, 0.0346, 0.0007, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0401, 0.7078, 0.2397, 0.0123, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0474, 0.2058, 0.5326, 0.2064, 0.0069, 0.0009, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0014, 0.0844, 0.5802, 0.2592, 0.0695, 0.0053, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0009, 0.0282, 0.5307, 0.3581, 0.0741, 0.0080, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0083, 0.4392, 0.1621, 0.1778, 0.2125, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0133, 0.2038, 0.6189, 0.1006, 0.0322, 0.0312, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0047, 0.0210, 0.2831, 0.2177, 0.0924, 0.3811, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0206, 0.0632, 0.2720, 0.2272, 0.1059, 0.3111, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 5.86, Train Loss: 2.73, Val Loss: 4.05, Train BLEU: 16.11, Val BLEU: 11.06, Minutes Elapsed: 304.65\n",
      "Sampling from training predictions...\n",
      "Source: nhà_văn , thomas frank , nói rằng có_lẽ đó là\n",
      "Reference: the writer , thomas frank , says that this\n",
      "Model: <SOS> writer writer writer thomas frank , , that that\n",
      "Attention Weights: tensor([[9.9486e-01, 4.3818e-03, 6.0375e-04, 1.5804e-04, 7.0039e-08, 2.6516e-09,\n",
      "         9.2150e-10, 1.2619e-09, 1.2628e-10, 2.0497e-11],\n",
      "        [3.9706e-01, 2.3650e-01, 3.1064e-01, 5.5717e-02, 7.5754e-05, 7.5670e-06,\n",
      "         3.3056e-06, 1.9855e-06, 2.0027e-07, 6.5125e-08],\n",
      "        [1.4829e-03, 3.9871e-02, 7.7165e-01, 1.8528e-01, 1.4373e-03, 2.1249e-04,\n",
      "         3.7098e-05, 2.3460e-05, 3.9190e-06, 1.3031e-06],\n",
      "        [1.3437e-04, 2.2979e-02, 8.3881e-01, 1.3049e-01, 6.8321e-03, 5.6962e-04,\n",
      "         1.0959e-04, 6.3303e-05, 7.1740e-06, 3.5168e-06],\n",
      "        [4.4171e-04, 3.8406e-03, 3.0364e-01, 6.8359e-01, 6.6261e-03, 1.0548e-03,\n",
      "         3.8200e-04, 3.8378e-04, 2.6071e-05, 1.2827e-05],\n",
      "        [1.4602e-04, 1.1705e-03, 2.0130e-01, 4.5993e-01, 2.8466e-01, 4.0448e-02,\n",
      "         6.4687e-03, 5.1625e-03, 4.1357e-04, 2.9619e-04],\n",
      "        [2.1760e-06, 7.2106e-05, 1.0171e-02, 1.6037e-02, 1.2352e-01, 6.2231e-01,\n",
      "         1.4820e-01, 7.1898e-02, 4.4777e-03, 3.3090e-03],\n",
      "        [4.6972e-06, 5.0701e-05, 4.2940e-03, 9.4373e-03, 6.2841e-02, 4.1035e-01,\n",
      "         2.3570e-01, 2.5539e-01, 1.2908e-02, 9.0259e-03],\n",
      "        [6.5004e-06, 2.1985e-05, 7.1077e-04, 6.5278e-03, 7.0721e-03, 8.6960e-02,\n",
      "         1.8485e-01, 6.4647e-01, 4.7427e-02, 1.9950e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: một ngày , cơn ác_mộng đó đã thành sự_thật ,\n",
      "Reference: one day , my worst nightmare came true ,\n",
      "Model: <SOS> one day , the the came to , ,\n",
      "Attention Weights: tensor([[9.9864e-01, 1.3639e-03, 8.4360e-07, 1.5364e-07, 3.0730e-09, 1.2027e-09,\n",
      "         6.6363e-11, 8.2627e-12, 4.7084e-12, 6.7759e-13],\n",
      "        [1.9711e-01, 6.9867e-01, 6.4163e-02, 3.2556e-02, 5.4876e-03, 4.7135e-04,\n",
      "         4.6094e-04, 4.4869e-04, 5.9174e-04, 3.7269e-05],\n",
      "        [4.9848e-02, 3.0652e-01, 4.1302e-01, 1.6026e-01, 3.6673e-02, 3.8713e-03,\n",
      "         1.4159e-02, 1.2666e-02, 2.7593e-03, 2.1530e-04],\n",
      "        [1.6686e-03, 6.6680e-03, 1.6390e-01, 7.4192e-01, 6.6434e-02, 3.1545e-03,\n",
      "         7.1114e-03, 5.6675e-03, 2.5381e-03, 9.3691e-04],\n",
      "        [5.7814e-04, 9.8344e-04, 9.2281e-03, 3.4219e-01, 6.0387e-01, 1.0567e-02,\n",
      "         1.6031e-02, 1.1641e-02, 4.5194e-03, 3.9121e-04],\n",
      "        [5.9179e-04, 1.4910e-03, 7.7381e-03, 5.8314e-02, 2.1486e-01, 1.3332e-01,\n",
      "         3.6485e-01, 1.7623e-01, 3.9669e-02, 2.9403e-03],\n",
      "        [1.4085e-05, 2.0358e-05, 9.2176e-04, 2.8122e-03, 1.8380e-02, 1.0927e-02,\n",
      "         1.6204e-01, 4.9265e-01, 2.6024e-01, 5.1985e-02],\n",
      "        [1.4447e-04, 1.2484e-05, 1.1664e-04, 8.2164e-04, 6.4070e-03, 6.1897e-03,\n",
      "         3.5381e-02, 1.0433e-01, 3.9828e-01, 4.4832e-01],\n",
      "        [1.1164e-03, 1.2452e-04, 3.3623e-04, 4.1257e-03, 3.0211e-03, 5.7150e-03,\n",
      "         7.5385e-02, 1.0184e-01, 2.2494e-01, 5.8339e-01]])\n",
      "\n",
      "Epoch: 5.91, Train Loss: 2.70, Val Loss: 4.06, Train BLEU: 15.43, Val BLEU: 10.21, Minutes Elapsed: 307.23\n",
      "Sampling from training predictions...\n",
      "Source: nó chỉ_cần tuân_thủ những quy_tắc an_toàn . <EOS> <PAD> <PAD>\n",
      "Reference: it just has to follow safety guidelines . <EOS>\n",
      "Model: <SOS> it &apos;s the the safety safety rules . <EOS>\n",
      "Attention Weights: tensor([[0.8937, 0.1062, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0138, 0.9796, 0.0065, 0.0001, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0281, 0.5815, 0.3087, 0.0377, 0.0376, 0.0062, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0011, 0.0072, 0.3268, 0.2452, 0.3333, 0.0848, 0.0015, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0054, 0.0811, 0.2213, 0.4927, 0.1728, 0.0233, 0.0033, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0055, 0.1540, 0.1248, 0.5446, 0.1167, 0.0473, 0.0070, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0021, 0.0508, 0.0643, 0.5869, 0.1745, 0.1047, 0.0166, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0011, 0.0076, 0.0149, 0.2377, 0.1269, 0.3581, 0.2536, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0011, 0.0054, 0.0026, 0.0146, 0.1117, 0.1738, 0.2675, 0.4232, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi rất muốn từ_bỏ chuyện học , nhưng bố tôi\n",
      "Reference: i would want to quit , but my father\n",
      "Model: <SOS> i i love to make a words , ,\n",
      "Attention Weights: tensor([[3.5868e-02, 9.6332e-01, 8.0478e-04, 2.6882e-06, 2.0657e-07, 3.6139e-07,\n",
      "         2.8166e-09, 2.9647e-09, 1.1877e-09, 5.2938e-10],\n",
      "        [1.1909e-02, 9.4248e-01, 4.5310e-02, 2.2158e-04, 5.1731e-05, 1.0513e-05,\n",
      "         1.1743e-06, 2.6725e-06, 1.0239e-05, 1.1697e-06],\n",
      "        [3.8454e-03, 6.3960e-01, 3.3919e-01, 1.3800e-02, 2.7719e-03, 6.7329e-04,\n",
      "         3.5194e-05, 2.2171e-05, 4.9736e-05, 9.2924e-06],\n",
      "        [5.4844e-04, 5.5809e-02, 6.6800e-01, 1.8121e-01, 5.8955e-02, 3.3698e-02,\n",
      "         1.1516e-03, 3.5877e-04, 1.8950e-04, 7.4945e-05],\n",
      "        [1.8432e-04, 6.0820e-03, 4.9627e-01, 1.2734e-01, 1.7844e-01, 1.8260e-01,\n",
      "         5.9611e-03, 2.2684e-03, 7.2247e-04, 1.3789e-04],\n",
      "        [1.3383e-05, 1.6121e-04, 2.9337e-02, 7.2771e-02, 5.3199e-01, 3.3592e-01,\n",
      "         2.4957e-02, 3.8442e-03, 9.1170e-04, 9.9307e-05],\n",
      "        [9.3151e-06, 1.6890e-05, 4.3220e-04, 5.1491e-03, 2.6936e-01, 5.8993e-01,\n",
      "         1.1362e-01, 1.9500e-02, 1.8370e-03, 1.4378e-04],\n",
      "        [9.3018e-06, 1.9582e-05, 3.7483e-04, 2.9239e-03, 3.3236e-01, 2.0126e-01,\n",
      "         2.7305e-01, 1.7391e-01, 1.5571e-02, 5.1181e-04],\n",
      "        [3.5492e-04, 7.1129e-03, 2.7555e-02, 8.7680e-03, 5.6579e-02, 3.0523e-02,\n",
      "         1.0448e-01, 3.2923e-01, 4.0073e-01, 3.4663e-02]])\n",
      "\n",
      "Epoch: 5.96, Train Loss: 2.67, Val Loss: 4.07, Train BLEU: 16.37, Val BLEU: 10.47, Minutes Elapsed: 309.85\n",
      "Sampling from training predictions...\n",
      "Source: không_sao , bởi_vì bạn đã học được một kỹ_năng mới\n",
      "Reference: that &apos;s okay , because you learned a new\n",
      "Model: <SOS> no , , , because you &apos;ve learned a\n",
      "Attention Weights: tensor([[9.9995e-01, 3.9046e-05, 7.0083e-06, 2.5234e-08, 1.6166e-08, 1.2290e-09,\n",
      "         1.8724e-10, 1.8989e-10, 2.5408e-11, 1.8127e-11],\n",
      "        [8.6932e-01, 6.3098e-02, 6.3839e-02, 2.8053e-03, 5.2793e-04, 3.1564e-04,\n",
      "         6.8602e-05, 2.0389e-05, 6.9278e-06, 2.5101e-06],\n",
      "        [2.8149e-01, 2.7579e-01, 3.9029e-01, 1.7615e-02, 1.5142e-02, 1.6220e-02,\n",
      "         2.5381e-03, 5.9410e-04, 2.2233e-04, 9.3121e-05],\n",
      "        [3.7338e-02, 7.2198e-02, 7.8306e-01, 4.6240e-02, 3.0179e-02, 2.5849e-02,\n",
      "         3.5636e-03, 7.6291e-04, 5.0385e-04, 3.0719e-04],\n",
      "        [5.0652e-03, 9.0371e-02, 8.6710e-01, 2.1069e-02, 5.5116e-03, 9.1932e-03,\n",
      "         1.2660e-03, 1.2468e-04, 1.0737e-04, 1.9260e-04],\n",
      "        [8.1537e-03, 2.3106e-03, 4.2678e-01, 2.5387e-01, 1.4676e-01, 1.4137e-01,\n",
      "         1.4838e-02, 4.1634e-03, 1.1990e-03, 5.5466e-04],\n",
      "        [1.1023e-02, 1.8659e-03, 1.1292e-01, 8.1646e-02, 2.3676e-01, 4.2440e-01,\n",
      "         1.1326e-01, 1.1952e-02, 4.8531e-03, 1.3132e-03],\n",
      "        [3.2191e-03, 1.1985e-03, 3.0142e-02, 2.8591e-02, 2.1609e-01, 3.6677e-01,\n",
      "         3.1612e-01, 2.0923e-02, 1.3387e-02, 3.5607e-03],\n",
      "        [1.7266e-03, 8.6088e-04, 1.2452e-02, 1.8811e-03, 3.7509e-03, 9.0619e-02,\n",
      "         1.8592e-01, 1.0492e-01, 3.9756e-01, 2.0031e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: bạn không cần phải thiết_kế cả một hệ_thống bệnh_viện hoàn_toàn\n",
      "Reference: you don &apos;t have to design a whole new\n",
      "Model: <SOS> you don &apos;t have to have a a specialized\n",
      "Attention Weights: tensor([[9.7710e-01, 2.2844e-02, 5.1489e-05, 8.7909e-06, 8.0837e-08, 2.4935e-08,\n",
      "         2.6238e-09, 2.6602e-10, 1.6897e-10, 8.7246e-11],\n",
      "        [5.1177e-02, 9.3540e-01, 1.3138e-02, 2.2727e-04, 3.8220e-05, 8.8133e-06,\n",
      "         2.2126e-06, 2.2578e-06, 2.7898e-06, 1.4512e-06],\n",
      "        [6.6915e-02, 8.7366e-01, 5.2741e-02, 5.8202e-03, 6.9112e-04, 9.3866e-05,\n",
      "         3.2287e-05, 1.5669e-05, 1.7960e-05, 1.3402e-05],\n",
      "        [5.3202e-03, 5.2795e-02, 7.1670e-01, 2.0275e-01, 2.1393e-02, 7.5751e-04,\n",
      "         8.6766e-05, 8.8298e-05, 5.5451e-05, 5.5413e-05],\n",
      "        [1.9119e-04, 5.1968e-03, 6.9887e-02, 6.7658e-01, 2.2125e-01, 2.1913e-02,\n",
      "         1.5493e-03, 1.3361e-03, 1.3667e-03, 7.2452e-04],\n",
      "        [1.5898e-05, 1.5847e-03, 1.5337e-02, 4.1741e-01, 5.1053e-01, 4.4354e-02,\n",
      "         1.6331e-03, 3.6623e-03, 2.6727e-03, 2.7949e-03],\n",
      "        [4.4467e-06, 3.2376e-04, 1.6959e-03, 2.2498e-01, 3.4393e-01, 3.2250e-01,\n",
      "         3.1468e-02, 3.1872e-02, 2.1693e-02, 2.1532e-02],\n",
      "        [4.1293e-06, 2.6908e-05, 1.3920e-04, 7.7315e-03, 4.0754e-01, 2.5508e-01,\n",
      "         4.9798e-02, 5.3452e-02, 9.9739e-02, 1.2649e-01],\n",
      "        [1.9709e-05, 5.2083e-05, 5.0209e-05, 1.1013e-03, 2.6166e-02, 1.1539e-01,\n",
      "         8.1273e-02, 2.4496e-01, 3.9695e-01, 1.3404e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6.00, Train Loss: 2.53, Val Loss: 4.08, Train BLEU: 18.51, Val BLEU: 10.75, Minutes Elapsed: 312.01\n",
      "Sampling from training predictions...\n",
      "Source: và , như bạn biết , là cha_mẹ , nhất_là\n",
      "Reference: and , you know , as a parent ,\n",
      "Model: <SOS> and , you you , the is parent ,\n",
      "Attention Weights: tensor([[1.5353e-03, 4.2206e-01, 5.7288e-01, 3.2312e-03, 2.9606e-04, 5.1145e-07,\n",
      "         2.5469e-08, 2.4051e-09, 7.2875e-11, 1.1498e-10],\n",
      "        [7.5240e-04, 5.5845e-01, 4.3451e-01, 6.1249e-03, 1.6248e-04, 3.8746e-07,\n",
      "         3.5298e-08, 5.8173e-09, 3.7587e-10, 6.9099e-10],\n",
      "        [1.5822e-05, 4.5768e-03, 6.9817e-01, 2.6698e-01, 2.9434e-02, 4.5294e-04,\n",
      "         3.3110e-04, 3.1755e-05, 5.4443e-06, 6.8659e-06],\n",
      "        [1.7023e-05, 5.6592e-04, 6.4702e-02, 3.0663e-01, 5.8765e-01, 1.9849e-02,\n",
      "         1.7778e-02, 2.3651e-03, 2.0570e-04, 2.3735e-04],\n",
      "        [2.4017e-05, 4.1677e-04, 1.2408e-02, 7.0450e-02, 7.0373e-01, 1.2505e-01,\n",
      "         6.5907e-02, 2.0396e-02, 1.0625e-03, 5.5337e-04],\n",
      "        [6.1469e-05, 2.6682e-04, 2.3972e-03, 1.5262e-03, 3.1357e-03, 7.5311e-02,\n",
      "         7.0623e-01, 1.8801e-01, 1.0055e-02, 1.3005e-02],\n",
      "        [9.6944e-06, 3.8905e-04, 2.0846e-03, 3.0101e-03, 3.3935e-03, 3.8997e-02,\n",
      "         7.0354e-01, 1.8564e-01, 2.6076e-02, 3.6861e-02],\n",
      "        [7.9204e-06, 6.0992e-05, 2.9279e-04, 6.2005e-04, 1.1723e-02, 2.0255e-02,\n",
      "         1.0977e-01, 4.7279e-01, 2.7955e-01, 1.0493e-01],\n",
      "        [1.6906e-04, 5.1449e-03, 2.0297e-03, 3.7417e-04, 5.2962e-03, 2.0018e-02,\n",
      "         1.4097e-01, 1.0021e-01, 6.3024e-01, 9.5548e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: và bắt_đầu học để chuẩn_bị cho kì thi đại_học .\n",
      "Reference: i started studying for the university entrance exam .\n",
      "Model: <SOS> and the to to to to to to the\n",
      "Attention Weights: tensor([[8.5254e-04, 9.9693e-01, 2.2186e-03, 1.5396e-06, 3.2557e-09, 1.2788e-10,\n",
      "         3.1987e-12, 6.0382e-13, 2.3513e-12, 4.8604e-13],\n",
      "        [1.5651e-03, 7.1882e-01, 2.7890e-01, 6.9330e-04, 2.2147e-05, 6.2702e-07,\n",
      "         8.3101e-08, 6.7507e-08, 2.5426e-08, 3.3913e-09],\n",
      "        [1.9448e-04, 5.4545e-01, 3.9072e-01, 5.4692e-02, 8.5588e-03, 2.6360e-04,\n",
      "         6.4213e-05, 3.2594e-05, 2.2130e-05, 9.4143e-07],\n",
      "        [6.3485e-06, 1.7282e-03, 1.0411e-02, 2.4398e-02, 6.6774e-01, 1.2464e-01,\n",
      "         8.2580e-02, 5.9202e-02, 2.8992e-02, 3.0633e-04],\n",
      "        [3.4795e-04, 6.5181e-03, 2.2936e-02, 1.6220e-02, 3.9551e-01, 1.7028e-01,\n",
      "         2.0580e-01, 1.1710e-01, 6.4562e-02, 7.2525e-04],\n",
      "        [5.0893e-06, 1.3617e-04, 1.8843e-04, 4.2290e-04, 4.3797e-02, 6.3643e-02,\n",
      "         2.8097e-01, 2.3370e-01, 3.7164e-01, 5.4927e-03],\n",
      "        [1.7296e-05, 1.8352e-04, 1.0758e-04, 8.6360e-04, 1.4920e-02, 4.8782e-02,\n",
      "         2.7408e-01, 3.1165e-01, 3.2909e-01, 2.0304e-02],\n",
      "        [8.1529e-06, 3.3717e-04, 1.8335e-04, 9.4393e-04, 6.8528e-03, 2.4576e-02,\n",
      "         2.0939e-01, 2.8722e-01, 4.4133e-01, 2.9165e-02],\n",
      "        [5.3089e-05, 7.4713e-04, 3.1100e-04, 5.4282e-04, 5.5641e-02, 3.5955e-02,\n",
      "         1.2551e-01, 2.0095e-01, 5.5332e-01, 2.6970e-02]])\n",
      "\n",
      "Epoch: 6.05, Train Loss: 2.15, Val Loss: 4.09, Train BLEU: 23.33, Val BLEU: 10.93, Minutes Elapsed: 314.58\n",
      "Sampling from training predictions...\n",
      "Source: rồi , thế nên hầu_hết mọi người đều quen_thuộc với\n",
      "Reference: okay , so most people are familiar with traditional\n",
      "Model: <SOS> then , so most people people familiar with with\n",
      "Attention Weights: tensor([[9.7222e-01, 2.3259e-02, 3.6219e-03, 8.4621e-04, 5.3428e-05, 1.8804e-06,\n",
      "         4.9704e-08, 1.1392e-08, 1.7437e-09, 7.4080e-10],\n",
      "        [3.6687e-01, 3.8195e-01, 1.7480e-01, 5.1720e-02, 2.4220e-02, 3.5822e-04,\n",
      "         6.0284e-05, 1.6741e-05, 5.5844e-06, 1.9506e-06],\n",
      "        [4.6774e-03, 2.9657e-02, 5.3729e-01, 2.5445e-01, 1.5646e-01, 9.4318e-03,\n",
      "         6.0530e-03, 1.5434e-03, 3.0930e-04, 1.2071e-04],\n",
      "        [9.1675e-05, 3.5975e-04, 1.2222e-02, 1.1673e-01, 7.4315e-01, 7.1531e-02,\n",
      "         2.8569e-02, 2.1039e-02, 5.1698e-03, 1.1380e-03],\n",
      "        [1.6649e-05, 5.0568e-04, 1.7281e-03, 3.9327e-02, 1.7030e-01, 1.0985e-01,\n",
      "         8.5994e-02, 3.0074e-01, 2.5720e-01, 3.4343e-02],\n",
      "        [8.4733e-06, 8.0059e-05, 1.5749e-04, 5.7995e-03, 3.8610e-02, 5.1792e-02,\n",
      "         5.1171e-02, 3.6337e-01, 4.5391e-01, 3.5103e-02],\n",
      "        [3.5317e-06, 8.5963e-06, 3.1847e-05, 3.8005e-04, 7.2277e-03, 1.8629e-02,\n",
      "         3.0741e-02, 2.9649e-01, 4.5360e-01, 1.9289e-01],\n",
      "        [6.3799e-06, 1.1909e-06, 1.3682e-06, 2.0135e-05, 1.8768e-03, 2.1321e-03,\n",
      "         3.4076e-03, 1.0348e-01, 4.9356e-01, 3.9551e-01],\n",
      "        [9.8743e-05, 6.3765e-05, 2.6971e-05, 7.3854e-05, 7.3548e-03, 6.3036e-03,\n",
      "         1.0539e-02, 5.6474e-02, 3.5597e-01, 5.6309e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: toàn_bộ ý tưởng_là thế_mà . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: that &apos;s the whole idea . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> the whole all . . . <EOS> . .\n",
      "Attention Weights: tensor([[0.9831, 0.0115, 0.0054, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2918, 0.2725, 0.4329, 0.0026, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0619, 0.1371, 0.7598, 0.0353, 0.0051, 0.0009, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0392, 0.0915, 0.6868, 0.1247, 0.0478, 0.0100, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0136, 0.0314, 0.5948, 0.1073, 0.1359, 0.1170, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0075, 0.1101, 0.3996, 0.1303, 0.1900, 0.1625, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0092, 0.0207, 0.3219, 0.1276, 0.1529, 0.3678, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0178, 0.0140, 0.2089, 0.0822, 0.0817, 0.5955, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2091, 0.1094, 0.3747, 0.0893, 0.0902, 0.1273, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 6.10, Train Loss: 2.29, Val Loss: 4.09, Train BLEU: 21.13, Val BLEU: 11.42, Minutes Elapsed: 317.13\n",
      "Sampling from training predictions...\n",
      "Source: nếu bạn có_một ngón_cái rảnh_rỗi , hãy vẫy nó lên\n",
      "Reference: if you have a free thumb , wave it\n",
      "Model: <SOS> if you have a thumb thumb , it it\n",
      "Attention Weights: tensor([[2.3484e-01, 7.5914e-01, 5.9728e-03, 4.5935e-05, 2.0219e-06, 1.2502e-08,\n",
      "         2.0661e-08, 2.6208e-08, 5.3973e-10, 1.5314e-09],\n",
      "        [4.6777e-02, 8.9138e-01, 6.1544e-02, 2.4069e-04, 4.2780e-05, 2.1356e-06,\n",
      "         2.7240e-06, 5.6452e-06, 5.3594e-07, 3.5426e-07],\n",
      "        [5.7630e-03, 1.3986e-01, 8.2754e-01, 2.4134e-02, 2.1700e-03, 6.4760e-05,\n",
      "         3.8335e-05, 3.7425e-04, 2.4899e-05, 2.4997e-05],\n",
      "        [8.2973e-04, 8.5024e-02, 5.8811e-01, 2.9976e-01, 2.4452e-02, 1.9251e-04,\n",
      "         1.1609e-04, 1.2933e-03, 1.0906e-04, 1.1455e-04],\n",
      "        [1.5268e-04, 1.0991e-04, 2.0562e-03, 5.5210e-01, 4.4330e-01, 1.6287e-03,\n",
      "         5.4449e-05, 4.5357e-04, 4.3005e-05, 9.8387e-05],\n",
      "        [4.4949e-02, 4.9150e-03, 5.8710e-02, 7.1351e-01, 1.3275e-01, 2.3887e-02,\n",
      "         2.0294e-03, 1.6597e-02, 9.6213e-04, 1.6974e-03],\n",
      "        [2.3069e-02, 1.4532e-02, 3.5025e-02, 1.4205e-01, 2.0167e-01, 2.2978e-01,\n",
      "         7.7173e-02, 2.2826e-01, 1.6722e-02, 3.1717e-02],\n",
      "        [4.5903e-05, 1.0850e-05, 3.8577e-04, 3.4823e-03, 5.4993e-03, 1.8889e-02,\n",
      "         5.7874e-02, 7.5295e-01, 5.6050e-02, 1.0481e-01],\n",
      "        [3.8276e-04, 2.1490e-04, 2.5838e-03, 1.9754e-03, 4.2030e-03, 5.4010e-03,\n",
      "         7.4161e-02, 7.0838e-01, 7.3928e-02, 1.2877e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: anh ta cần chúng để cảm_thấy được bảo_vệ . <EOS>\n",
      "Reference: he needed them to feel protected . <EOS> <PAD>\n",
      "Model: <SOS> he need to to to feel for <EOS> <EOS>\n",
      "Attention Weights: tensor([[9.6722e-01, 2.8620e-02, 4.0982e-03, 6.4164e-05, 4.7149e-08, 2.3916e-09,\n",
      "         1.4800e-10, 3.9098e-11, 5.2834e-12, 3.9640e-12],\n",
      "        [1.4975e-03, 1.0326e-03, 9.9579e-01, 1.5955e-03, 8.1949e-05, 1.3934e-06,\n",
      "         1.2802e-07, 3.0087e-08, 2.0883e-09, 1.2558e-09],\n",
      "        [3.3919e-03, 7.5994e-03, 7.9869e-01, 1.8365e-01, 6.1708e-03, 3.6881e-04,\n",
      "         1.0201e-04, 2.4277e-05, 1.0669e-06, 4.7819e-07],\n",
      "        [2.2310e-03, 1.2269e-03, 5.1199e-01, 2.8809e-01, 1.7394e-01, 1.6383e-02,\n",
      "         3.2733e-03, 2.6059e-03, 1.9018e-04, 7.2504e-05],\n",
      "        [4.1250e-04, 1.8000e-04, 8.2965e-02, 1.2753e-01, 4.5699e-01, 2.8920e-01,\n",
      "         2.4816e-02, 1.6196e-02, 1.1817e-03, 5.3344e-04],\n",
      "        [3.3123e-05, 1.8651e-05, 1.1455e-02, 3.4430e-02, 9.2620e-02, 6.5208e-01,\n",
      "         1.1882e-01, 8.8656e-02, 1.3816e-03, 5.0291e-04],\n",
      "        [3.6288e-05, 8.0778e-06, 2.7196e-04, 3.1230e-03, 2.1233e-02, 1.1893e-01,\n",
      "         2.6039e-01, 5.6779e-01, 2.1575e-02, 6.6436e-03],\n",
      "        [4.6530e-05, 2.3844e-05, 6.5851e-04, 2.4364e-03, 1.9882e-02, 1.9275e-01,\n",
      "         2.9842e-01, 4.0325e-01, 5.7157e-02, 2.5379e-02],\n",
      "        [2.8575e-03, 3.2718e-03, 1.2557e-02, 5.2270e-03, 4.7494e-03, 8.3347e-02,\n",
      "         2.0903e-01, 4.8158e-01, 1.0319e-01, 9.4182e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6.14, Train Loss: 2.31, Val Loss: 4.09, Train BLEU: 21.24, Val BLEU: 11.39, Minutes Elapsed: 319.68\n",
      "Sampling from training predictions...\n",
      "Source: một mặt , chúng_ta luôn muốn tự soi bản_thân trong\n",
      "Reference: at one hand , we all want to look\n",
      "Model: <SOS> one night , we we want want to be\n",
      "Attention Weights: tensor([[6.3138e-01, 3.6859e-01, 2.9917e-05, 6.9369e-07, 6.6423e-07, 4.7072e-08,\n",
      "         1.5326e-09, 2.1106e-10, 1.6859e-10, 4.0094e-11],\n",
      "        [9.3238e-02, 8.0409e-01, 8.4100e-02, 1.7204e-03, 1.6697e-02, 1.1408e-04,\n",
      "         1.6958e-05, 1.3570e-05, 9.4232e-06, 2.4718e-06],\n",
      "        [1.4501e-01, 1.3791e-01, 5.8661e-01, 3.9750e-02, 8.3356e-02, 6.3623e-03,\n",
      "         7.6559e-04, 1.3322e-04, 8.2867e-05, 2.5117e-05],\n",
      "        [1.3216e-02, 7.2446e-02, 4.5679e-01, 2.4371e-01, 1.9986e-01, 1.2227e-02,\n",
      "         1.1548e-03, 3.2383e-04, 2.0170e-04, 6.0266e-05],\n",
      "        [2.3372e-03, 4.2326e-03, 3.4628e-02, 1.7093e-01, 7.6818e-01, 1.6038e-02,\n",
      "         2.0121e-03, 9.1211e-04, 6.2080e-04, 1.1318e-04],\n",
      "        [4.2248e-04, 6.7161e-04, 1.0113e-03, 1.2687e-02, 9.6950e-01, 1.3670e-02,\n",
      "         1.2325e-03, 2.9683e-04, 4.3967e-04, 7.3650e-05],\n",
      "        [6.0443e-04, 6.1075e-04, 3.5982e-03, 3.5942e-03, 8.4828e-01, 1.2006e-01,\n",
      "         1.7701e-02, 3.1481e-03, 2.0897e-03, 3.0979e-04],\n",
      "        [1.8277e-04, 4.4743e-04, 4.1562e-04, 2.0581e-04, 2.1389e-02, 4.7412e-01,\n",
      "         3.4606e-01, 6.9793e-02, 8.4021e-02, 3.3665e-03],\n",
      "        [5.3447e-06, 1.2797e-05, 9.0837e-06, 8.4415e-05, 6.6781e-03, 1.0871e-01,\n",
      "         3.7354e-01, 2.3435e-01, 2.5699e-01, 1.9626e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: và đó là một bóng_đèn nhỏ từ cây đèn pin\n",
      "Reference: and that &apos;s a small torch from a broken\n",
      "Model: <SOS> and it &apos;s a little app from &apos;s game\n",
      "Attention Weights: tensor([[1.4608e-02, 9.8110e-01, 3.6965e-03, 5.8680e-04, 3.7261e-06, 5.1723e-07,\n",
      "         7.0914e-09, 1.2252e-09, 5.7704e-11, 6.4287e-12],\n",
      "        [1.0744e-02, 9.8013e-01, 3.0735e-03, 5.9823e-03, 6.2267e-05, 5.1007e-06,\n",
      "         5.5598e-07, 1.4936e-07, 1.0625e-08, 2.5627e-09],\n",
      "        [4.4701e-04, 1.3063e-01, 2.5315e-01, 3.3829e-01, 2.1792e-01, 5.5887e-02,\n",
      "         2.3584e-03, 1.1706e-03, 1.1083e-04, 3.4124e-05],\n",
      "        [1.5628e-04, 1.5749e-02, 8.5847e-02, 1.6688e-01, 3.7125e-01, 3.5204e-01,\n",
      "         4.9752e-03, 2.5091e-03, 4.8437e-04, 1.0416e-04],\n",
      "        [3.9829e-05, 2.6410e-04, 1.0632e-02, 2.3198e-02, 3.6262e-01, 5.6535e-01,\n",
      "         2.2869e-02, 1.3771e-02, 9.9572e-04, 2.6351e-04],\n",
      "        [3.2720e-05, 1.5448e-04, 1.9582e-03, 3.1816e-02, 4.5884e-01, 1.5068e-01,\n",
      "         1.4548e-01, 1.7957e-01, 2.6913e-02, 4.5492e-03],\n",
      "        [3.8870e-05, 4.9826e-04, 1.0899e-03, 4.2383e-03, 1.9090e-02, 1.9156e-02,\n",
      "         2.0235e-01, 6.4405e-01, 9.0042e-02, 1.9441e-02],\n",
      "        [2.9665e-06, 1.3990e-05, 6.2094e-05, 1.7784e-04, 3.4069e-03, 6.8941e-03,\n",
      "         5.4028e-02, 4.3348e-01, 3.0186e-01, 2.0008e-01],\n",
      "        [3.0574e-06, 2.0090e-05, 7.0947e-05, 4.1783e-04, 6.9073e-03, 3.6989e-03,\n",
      "         1.6695e-02, 2.7347e-01, 4.9265e-01, 2.0606e-01]])\n",
      "\n",
      "Epoch: 6.19, Train Loss: 2.37, Val Loss: 4.10, Train BLEU: 19.92, Val BLEU: 10.86, Minutes Elapsed: 322.21\n",
      "Sampling from training predictions...\n",
      "Source: nên bé sinh ra được đủ cân_nặng . <EOS> <PAD>\n",
      "Reference: so he got the right weight at birth .\n",
      "Model: <SOS> so , was born to . . <EOS> .\n",
      "Attention Weights: tensor([[0.9993, 0.0006, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1712, 0.0281, 0.7926, 0.0068, 0.0012, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0130, 0.0042, 0.6591, 0.1847, 0.1305, 0.0073, 0.0012, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0075, 0.0046, 0.2483, 0.2985, 0.3517, 0.0681, 0.0210, 0.0002, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0010, 0.0006, 0.0015, 0.0185, 0.1626, 0.2355, 0.5778, 0.0021, 0.0005,\n",
      "         0.0000],\n",
      "        [0.0004, 0.0003, 0.0014, 0.0356, 0.0960, 0.2835, 0.5154, 0.0405, 0.0268,\n",
      "         0.0000],\n",
      "        [0.0009, 0.0002, 0.0018, 0.0312, 0.1072, 0.0994, 0.4950, 0.1378, 0.1265,\n",
      "         0.0000],\n",
      "        [0.0051, 0.0022, 0.0048, 0.0110, 0.0394, 0.0762, 0.3883, 0.1103, 0.3628,\n",
      "         0.0000],\n",
      "        [0.0532, 0.0316, 0.0075, 0.0157, 0.0491, 0.0982, 0.2498, 0.0855, 0.4094,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: bảo_trợ , tôi đối xử với tất_cả mọi người từ\n",
      "Reference: patronizing , i treat everybody from another culture as\n",
      "Model: <SOS> so i i &apos;m by by all of from\n",
      "Attention Weights: tensor([[9.9547e-01, 4.2433e-03, 1.4592e-04, 1.1731e-04, 1.9382e-05, 3.3796e-06,\n",
      "         4.1190e-08, 4.4246e-09, 2.5693e-09, 9.6071e-10],\n",
      "        [1.0907e-01, 5.1520e-02, 8.1851e-01, 1.6423e-02, 3.7725e-03, 4.9763e-04,\n",
      "         1.4294e-04, 2.1950e-05, 2.1423e-05, 1.8356e-05],\n",
      "        [4.7107e-02, 1.2039e-01, 2.5644e-01, 4.1166e-01, 1.5539e-01, 7.7704e-03,\n",
      "         5.3197e-04, 3.4795e-04, 2.3585e-04, 1.2698e-04],\n",
      "        [6.7173e-04, 1.6252e-03, 2.1509e-01, 2.4286e-01, 3.9181e-01, 1.3183e-01,\n",
      "         1.1288e-02, 2.5710e-03, 1.2891e-03, 9.6371e-04],\n",
      "        [1.1256e-03, 2.9165e-03, 6.7789e-03, 9.5061e-02, 6.8527e-01, 1.8587e-01,\n",
      "         1.5113e-02, 4.0459e-03, 2.2885e-03, 1.5356e-03],\n",
      "        [4.2811e-04, 2.0158e-04, 3.3481e-04, 7.8780e-03, 1.8853e-01, 5.2852e-01,\n",
      "         2.2231e-01, 4.1324e-02, 8.7478e-03, 1.7195e-03],\n",
      "        [3.2138e-04, 1.3670e-04, 1.6483e-03, 1.4679e-03, 5.4023e-02, 2.4600e-01,\n",
      "         4.9963e-01, 1.5448e-01, 2.9340e-02, 1.2955e-02],\n",
      "        [2.8902e-05, 1.8979e-05, 2.6593e-04, 4.4793e-04, 2.6346e-02, 7.4113e-02,\n",
      "         2.6065e-01, 3.2847e-01, 1.8624e-01, 1.2342e-01],\n",
      "        [7.6582e-06, 2.5730e-05, 6.8626e-05, 1.0436e-04, 4.7644e-03, 8.7547e-03,\n",
      "         9.4711e-02, 2.6671e-01, 2.6565e-01, 3.5920e-01]])\n",
      "\n",
      "Epoch: 6.24, Train Loss: 2.41, Val Loss: 4.09, Train BLEU: 19.17, Val BLEU: 10.62, Minutes Elapsed: 324.76\n",
      "Sampling from training predictions...\n",
      "Source: kevin breel : những thú_nhận của một nghệ_sĩ hài bị\n",
      "Reference: kevin breel : confessions of a depressed comic <EOS>\n",
      "Model: <SOS> kevin breel : confessions of a <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[9.8689e-01, 1.1890e-02, 1.2180e-03, 6.6082e-07, 8.0968e-07, 1.0507e-08,\n",
      "         1.7087e-10, 1.1779e-10, 7.3663e-11, 3.6940e-12],\n",
      "        [5.1479e-02, 8.1424e-01, 1.3400e-01, 1.9696e-04, 8.6878e-05, 2.9053e-06,\n",
      "         3.1192e-08, 1.0014e-08, 7.9789e-09, 1.0043e-09],\n",
      "        [5.3569e-04, 9.2823e-03, 9.8723e-01, 9.3310e-04, 8.7744e-04, 1.1317e-03,\n",
      "         7.3976e-06, 2.1497e-06, 4.1270e-07, 6.0386e-08],\n",
      "        [3.5670e-06, 2.2803e-05, 4.2699e-04, 5.8169e-01, 4.1204e-01, 4.7819e-03,\n",
      "         5.3342e-04, 2.8834e-04, 1.8046e-04, 2.9649e-05],\n",
      "        [8.3463e-06, 9.9375e-06, 1.2682e-04, 5.6080e-02, 8.6481e-01, 3.3996e-02,\n",
      "         2.0460e-02, 1.2134e-02, 1.0181e-02, 2.1954e-03],\n",
      "        [5.1448e-07, 8.1899e-07, 4.9650e-05, 2.0562e-03, 4.6370e-02, 2.3917e-01,\n",
      "         3.2923e-01, 1.8128e-01, 1.2287e-01, 7.8981e-02],\n",
      "        [3.4443e-08, 7.7814e-08, 2.5832e-06, 1.2426e-04, 2.5223e-03, 9.7084e-03,\n",
      "         8.5252e-02, 2.4892e-01, 3.6862e-01, 2.8485e-01],\n",
      "        [3.0789e-07, 6.7287e-07, 3.1689e-05, 1.5718e-03, 6.2813e-03, 2.3358e-02,\n",
      "         9.2083e-02, 1.4709e-01, 3.0289e-01, 4.2669e-01],\n",
      "        [2.5536e-06, 4.5912e-06, 5.7204e-05, 1.9645e-03, 4.7693e-03, 2.0184e-02,\n",
      "         1.0649e-01, 1.9193e-01, 2.6614e-01, 4.0846e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: không phải ai cũng có cơ_hội để làm điều này\n",
      "Reference: not everybody gets to do that . <EOS> <PAD>\n",
      "Model: <SOS> not one had to chance chance chance do do\n",
      "Attention Weights: tensor([[2.9033e-01, 6.4018e-01, 5.6720e-02, 1.2326e-02, 3.8814e-04, 3.9880e-05,\n",
      "         4.9043e-06, 5.1239e-06, 5.5794e-07, 8.1113e-08],\n",
      "        [1.3977e-01, 2.3718e-01, 2.4980e-01, 3.1378e-01, 2.6654e-02, 2.8399e-02,\n",
      "         2.3926e-03, 1.6238e-03, 3.4147e-04, 6.5964e-05],\n",
      "        [1.7079e-01, 1.4121e-01, 1.6130e-01, 2.5506e-01, 1.2064e-01, 1.2991e-01,\n",
      "         1.4736e-02, 4.5990e-03, 1.5635e-03, 1.9612e-04],\n",
      "        [4.3623e-02, 5.8919e-02, 1.1856e-01, 4.0402e-01, 1.7538e-01, 1.5489e-01,\n",
      "         3.2507e-02, 1.0396e-02, 1.5477e-03, 1.6026e-04],\n",
      "        [1.9843e-04, 2.2847e-03, 1.6871e-02, 3.2123e-01, 2.8900e-01, 2.5958e-01,\n",
      "         4.1338e-02, 3.7259e-02, 2.8244e-02, 3.9922e-03],\n",
      "        [1.7582e-05, 1.5237e-04, 2.1599e-02, 1.8926e-01, 7.0208e-02, 5.1237e-01,\n",
      "         4.9642e-02, 6.3143e-02, 7.9759e-02, 1.3840e-02],\n",
      "        [3.6696e-05, 1.8849e-04, 2.1284e-02, 1.4163e-01, 6.0698e-02, 5.0961e-01,\n",
      "         4.2908e-02, 8.8747e-02, 1.0917e-01, 2.5729e-02],\n",
      "        [4.1698e-05, 8.1778e-05, 8.1170e-03, 6.3114e-02, 6.6356e-02, 1.4147e-01,\n",
      "         6.7109e-02, 2.6082e-01, 3.5644e-01, 3.6447e-02],\n",
      "        [2.0558e-04, 4.6994e-04, 2.1922e-03, 2.7269e-02, 8.2971e-02, 4.0120e-02,\n",
      "         9.7624e-02, 3.7543e-01, 3.3532e-01, 3.8394e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6.29, Train Loss: 2.43, Val Loss: 4.10, Train BLEU: 18.68, Val BLEU: 10.59, Minutes Elapsed: 327.31\n",
      "Sampling from training predictions...\n",
      "Source: bạn có_thể phân_tích ngũ_cốc của bạn để tìm thực_phẩm biến_đổi\n",
      "Reference: you can analyze your breakfast cereal for gmo &apos;s\n",
      "Model: <SOS> you can analyze your power of to gmo of\n",
      "Attention Weights: tensor([[4.8265e-01, 5.0856e-01, 8.4264e-03, 3.6557e-04, 5.2394e-07, 7.5753e-08,\n",
      "         1.4779e-08, 1.5852e-09, 1.7029e-09, 4.0751e-10],\n",
      "        [4.6809e-03, 4.1327e-01, 5.7512e-01, 6.8924e-03, 2.6059e-05, 5.8723e-06,\n",
      "         6.5147e-06, 4.7571e-06, 1.3645e-06, 3.2529e-07],\n",
      "        [1.2179e-03, 4.0599e-02, 9.1559e-01, 4.2058e-02, 3.9986e-04, 6.1083e-05,\n",
      "         3.0364e-05, 3.1529e-05, 6.6799e-06, 1.5845e-06],\n",
      "        [1.0029e-04, 1.8309e-03, 9.3015e-02, 9.0003e-01, 4.0289e-03, 6.0575e-04,\n",
      "         1.3420e-04, 1.2921e-04, 6.1368e-05, 6.0799e-05],\n",
      "        [3.4591e-04, 1.5080e-03, 1.5420e-01, 8.2757e-01, 1.0193e-02, 2.5740e-03,\n",
      "         9.8589e-04, 1.6025e-03, 7.2349e-04, 2.9644e-04],\n",
      "        [1.5474e-04, 5.0859e-03, 1.9910e-02, 5.5436e-01, 4.8462e-02, 6.1366e-02,\n",
      "         1.3403e-01, 1.4874e-01, 2.2557e-02, 5.3390e-03],\n",
      "        [2.1496e-06, 1.2641e-04, 1.3749e-03, 1.9628e-02, 9.3116e-03, 5.5061e-02,\n",
      "         2.5862e-01, 5.3564e-01, 9.6162e-02, 2.4072e-02],\n",
      "        [6.1589e-07, 3.5984e-05, 2.7988e-04, 2.9380e-03, 1.8221e-03, 1.0558e-02,\n",
      "         9.8555e-02, 6.0637e-01, 2.0563e-01, 7.3816e-02],\n",
      "        [8.9507e-06, 8.9179e-05, 2.1398e-04, 6.2906e-03, 5.7372e-04, 7.7817e-04,\n",
      "         1.1070e-02, 2.0480e-01, 4.4620e-01, 3.2998e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: chúng_tôi không có bất_cứ cơ_sở_hạ_tầng nào . <EOS> <PAD> <PAD>\n",
      "Reference: we have zero infrastructure . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> we didn no have . <EOS> <EOS> no <EOS>\n",
      "Attention Weights: tensor([[0.1182, 0.8776, 0.0042, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0435, 0.9257, 0.0305, 0.0002, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0206, 0.8942, 0.0718, 0.0116, 0.0015, 0.0002, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0067, 0.0509, 0.5994, 0.2876, 0.0499, 0.0053, 0.0001, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0012, 0.0117, 0.2011, 0.6485, 0.1337, 0.0029, 0.0009, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0016, 0.0046, 0.0271, 0.5870, 0.2365, 0.0724, 0.0708, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0269, 0.1785, 0.1539, 0.0808, 0.1528, 0.0943, 0.0945, 0.2182, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0109, 0.4348, 0.1598, 0.0684, 0.1705, 0.0332, 0.0553, 0.0671, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0133, 0.0319, 0.0173, 0.1340, 0.5991, 0.0919, 0.0550, 0.0574, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 6.34, Train Loss: 2.48, Val Loss: 4.10, Train BLEU: 18.16, Val BLEU: 10.23, Minutes Elapsed: 329.86\n",
      "Sampling from training predictions...\n",
      "Source: chúng_ta nói chúng_ta rất buồn và nói chúng_ta rất làm\n",
      "Reference: we say we &apos;re sad and we say we\n",
      "Model: <SOS> we say we need sad to we say we\n",
      "Attention Weights: tensor([[6.2541e-02, 9.3313e-01, 2.9126e-03, 1.4129e-03, 6.0246e-06, 3.1293e-07,\n",
      "         7.3691e-08, 1.3833e-08, 1.0404e-07, 4.4500e-09],\n",
      "        [2.2152e-03, 9.9219e-01, 3.5322e-03, 1.9632e-03, 8.2625e-05, 6.1556e-06,\n",
      "         7.4842e-06, 5.2026e-07, 4.5287e-06, 6.3194e-07],\n",
      "        [3.5988e-03, 5.0298e-01, 2.0732e-01, 2.5865e-01, 2.7035e-02, 2.9328e-04,\n",
      "         6.5871e-05, 7.8596e-06, 4.1461e-05, 5.6567e-06],\n",
      "        [1.1850e-04, 4.0813e-02, 2.0127e-01, 6.1026e-01, 1.4260e-01, 2.5460e-03,\n",
      "         1.5292e-03, 1.3470e-04, 5.3296e-04, 2.0218e-04],\n",
      "        [3.6849e-05, 4.5596e-02, 2.5889e-02, 2.5278e-01, 6.4722e-01, 6.3035e-03,\n",
      "         1.6560e-02, 5.0022e-04, 4.0708e-03, 1.0467e-03],\n",
      "        [2.8577e-05, 1.1069e-03, 9.4028e-03, 2.2398e-01, 6.8405e-01, 5.7681e-02,\n",
      "         2.0288e-02, 7.6619e-04, 1.9501e-03, 7.4646e-04],\n",
      "        [9.9471e-05, 3.5236e-03, 6.0155e-02, 1.1188e-01, 2.9030e-01, 3.7084e-01,\n",
      "         1.5034e-01, 7.7912e-03, 3.0131e-03, 2.0519e-03],\n",
      "        [5.3395e-05, 2.3145e-03, 1.0375e-02, 1.6928e-02, 5.2226e-02, 2.0902e-01,\n",
      "         6.4403e-01, 2.5391e-02, 3.4547e-02, 5.1150e-03],\n",
      "        [1.0366e-06, 5.9404e-04, 2.9770e-03, 1.4189e-02, 7.6974e-02, 3.5369e-02,\n",
      "         4.7883e-01, 3.8998e-02, 3.1187e-01, 4.0207e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: những hiệu_ứng âm_thanh này có_thể thực_sự khó phát_hiện , trong\n",
      "Reference: so these vocal effects can actually be quite subtle\n",
      "Model: <SOS> these these these can are be be , ,\n",
      "Attention Weights: tensor([[8.2336e-01, 1.6906e-01, 7.5728e-03, 4.3886e-06, 1.1078e-07, 1.3860e-08,\n",
      "         7.8285e-10, 2.4116e-10, 1.6261e-11, 3.2281e-11],\n",
      "        [9.0338e-03, 3.3463e-01, 6.5482e-01, 1.1311e-03, 2.7358e-04, 8.9561e-05,\n",
      "         1.4061e-05, 3.3738e-06, 3.3523e-07, 3.0271e-07],\n",
      "        [5.7997e-02, 2.1568e-01, 3.9039e-01, 2.1476e-01, 9.0497e-02, 2.7352e-02,\n",
      "         2.9620e-03, 2.8857e-04, 4.1851e-05, 3.8846e-05],\n",
      "        [9.8241e-02, 3.3492e-01, 4.0353e-01, 8.1832e-02, 5.6392e-02, 2.1781e-02,\n",
      "         2.9824e-03, 2.5183e-04, 4.0860e-05, 3.5038e-05],\n",
      "        [2.0616e-04, 3.8179e-03, 5.1787e-02, 1.3728e-01, 2.6889e-01, 4.2268e-01,\n",
      "         9.6647e-02, 1.6243e-02, 1.5951e-03, 8.5073e-04],\n",
      "        [6.6458e-06, 2.8977e-04, 3.4101e-03, 5.5878e-03, 5.6097e-02, 6.3488e-01,\n",
      "         2.0856e-01, 8.0052e-02, 9.0404e-03, 2.0702e-03],\n",
      "        [4.8279e-06, 9.3125e-05, 2.3316e-03, 4.0962e-04, 1.2062e-02, 2.1510e-01,\n",
      "         3.4759e-01, 3.4908e-01, 6.1477e-02, 1.1860e-02],\n",
      "        [4.5255e-06, 4.4858e-05, 5.8730e-04, 1.2037e-04, 1.6985e-03, 2.9843e-02,\n",
      "         3.5697e-01, 4.9564e-01, 8.9717e-02, 2.5375e-02],\n",
      "        [6.6136e-06, 8.3104e-05, 5.4384e-04, 2.2047e-04, 1.0264e-03, 1.2667e-02,\n",
      "         2.8890e-01, 4.2219e-01, 1.5503e-01, 1.1934e-01]])\n",
      "\n",
      "Epoch: 6.38, Train Loss: 2.51, Val Loss: 4.12, Train BLEU: 17.49, Val BLEU: 10.52, Minutes Elapsed: 332.40\n",
      "Sampling from training predictions...\n",
      "Source: nói theo cách khác , nó giống với âm_nhạc tây\n",
      "Reference: in other ways , it &apos;s more like the\n",
      "Model: <SOS> in other words , it &apos;s like like way\n",
      "Attention Weights: tensor([[7.9603e-01, 1.4281e-01, 2.1045e-02, 4.0119e-02, 1.8938e-06, 1.8988e-07,\n",
      "         5.8487e-08, 2.3099e-08, 2.8663e-09, 9.4607e-10],\n",
      "        [6.0845e-02, 4.2874e-01, 2.2813e-01, 2.5823e-01, 2.3225e-02, 3.7370e-04,\n",
      "         3.6052e-04, 2.7883e-05, 5.2615e-05, 1.6324e-05],\n",
      "        [1.0768e-01, 2.4112e-01, 3.4958e-01, 2.1009e-01, 7.5313e-02, 9.0705e-03,\n",
      "         5.8685e-03, 6.7084e-04, 5.1235e-04, 8.3607e-05],\n",
      "        [2.8942e-03, 4.8049e-03, 5.5706e-02, 3.9039e-02, 8.5399e-01, 3.7451e-02,\n",
      "         3.7906e-03, 8.4565e-04, 1.0602e-03, 4.1532e-04],\n",
      "        [1.0169e-03, 2.3509e-03, 1.3944e-02, 1.2799e-02, 5.0616e-01, 3.8350e-01,\n",
      "         5.1434e-02, 9.5451e-03, 1.1867e-02, 7.3879e-03],\n",
      "        [9.1347e-05, 3.0864e-04, 2.2214e-03, 1.1360e-03, 2.5676e-03, 4.3954e-02,\n",
      "         8.5875e-01, 6.7384e-02, 2.0568e-02, 3.0139e-03],\n",
      "        [9.2958e-04, 1.9404e-03, 1.4790e-02, 6.0055e-03, 2.7144e-03, 3.3963e-02,\n",
      "         6.5636e-01, 1.3682e-01, 1.1062e-01, 3.5862e-02],\n",
      "        [1.4836e-04, 2.4434e-03, 2.8652e-02, 3.9551e-02, 9.8622e-03, 6.3659e-03,\n",
      "         3.5415e-01, 1.8231e-01, 3.0383e-01, 7.2684e-02],\n",
      "        [8.9046e-04, 4.4500e-03, 2.8684e-02, 4.6305e-02, 6.6076e-02, 1.6554e-02,\n",
      "         9.6204e-02, 1.2411e-01, 3.4887e-01, 2.6786e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: đây không_phải nói người mẹ không quan_trọng trong thành_công_của chúng_ta\n",
      "Reference: it &apos;s not to say that our mothers aren\n",
      "Model: <SOS> this is not about our the the not not\n",
      "Attention Weights: tensor([[9.8016e-01, 1.9819e-02, 2.3738e-05, 9.5900e-07, 1.0462e-07, 6.6237e-09,\n",
      "         8.2629e-10, 3.0884e-11, 9.2812e-12, 1.5018e-12],\n",
      "        [2.5813e-02, 9.6697e-01, 6.0539e-03, 6.5108e-04, 4.1399e-04, 5.7571e-05,\n",
      "         3.9913e-05, 1.7966e-06, 1.2490e-06, 1.6886e-07],\n",
      "        [1.8748e-02, 9.3965e-01, 3.5204e-02, 3.5033e-03, 1.8457e-03, 7.5837e-04,\n",
      "         2.6471e-04, 1.8004e-05, 4.3404e-06, 8.6674e-07],\n",
      "        [2.3019e-03, 6.1010e-02, 7.6292e-01, 1.2190e-01, 2.9376e-02, 7.4253e-03,\n",
      "         1.4438e-02, 5.1399e-04, 9.7813e-05, 1.4279e-05],\n",
      "        [3.1327e-04, 2.4925e-02, 1.7275e-01, 5.1886e-01, 1.2864e-01, 5.3545e-02,\n",
      "         8.6390e-02, 1.0152e-02, 3.7370e-03, 6.8738e-04],\n",
      "        [5.2872e-05, 1.2377e-02, 5.8544e-02, 4.7468e-01, 1.9734e-01, 1.5077e-01,\n",
      "         9.3474e-02, 8.6399e-03, 3.5685e-03, 5.4900e-04],\n",
      "        [8.3659e-06, 1.3508e-02, 4.6478e-02, 3.2352e-01, 2.2379e-01, 2.1749e-01,\n",
      "         1.4599e-01, 2.1352e-02, 7.4189e-03, 4.4363e-04],\n",
      "        [5.0774e-04, 3.4170e-01, 1.9580e-01, 7.0997e-02, 8.3464e-02, 2.1522e-01,\n",
      "         7.8261e-02, 1.1831e-02, 2.0844e-03, 1.2939e-04],\n",
      "        [8.5486e-05, 5.0059e-02, 2.4354e-01, 1.0810e-01, 8.5623e-02, 2.8986e-01,\n",
      "         1.7182e-01, 3.8820e-02, 1.0524e-02, 1.5715e-03]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6.43, Train Loss: 2.56, Val Loss: 4.08, Train BLEU: 16.93, Val BLEU: 10.81, Minutes Elapsed: 335.00\n",
      "Sampling from training predictions...\n",
      "Source: và được thôi nếu chúng_ta nhớ tom hanks hơn nhà\n",
      "Reference: and it &apos;s okay if we remember tom hanks\n",
      "Model: <SOS> and what if be if we remember tom hanks\n",
      "Attention Weights: tensor([[4.1674e-05, 9.9983e-01, 1.3074e-04, 3.3771e-08, 1.0450e-09, 3.0428e-10,\n",
      "         1.7028e-11, 1.4641e-11, 2.8083e-11, 2.4340e-12],\n",
      "        [1.0968e-03, 9.4811e-01, 5.0379e-02, 3.8642e-04, 2.8533e-05, 1.8169e-06,\n",
      "         1.5442e-07, 5.8558e-08, 1.9855e-08, 1.6740e-09],\n",
      "        [1.5848e-04, 1.7256e-01, 7.5634e-01, 5.2375e-02, 1.2881e-02, 4.6669e-03,\n",
      "         9.4668e-04, 4.8934e-05, 1.4724e-05, 1.9426e-06],\n",
      "        [1.8904e-03, 5.5696e-01, 1.7186e-01, 1.1378e-01, 5.1082e-02, 6.8957e-02,\n",
      "         3.3117e-02, 1.4323e-03, 8.3943e-04, 8.2834e-05],\n",
      "        [1.5756e-04, 2.2809e-02, 1.3401e-01, 1.0242e-01, 8.9355e-02, 2.6122e-01,\n",
      "         3.6948e-01, 1.5433e-02, 4.5734e-03, 5.4165e-04],\n",
      "        [4.7179e-04, 4.2272e-02, 1.2090e-01, 3.4732e-01, 2.6477e-01, 1.0295e-01,\n",
      "         1.0260e-01, 1.4564e-02, 3.5324e-03, 6.2063e-04],\n",
      "        [2.7117e-06, 9.6898e-04, 2.0695e-03, 1.3990e-02, 1.1217e-01, 5.9646e-01,\n",
      "         1.4767e-01, 8.4200e-02, 3.9824e-02, 2.6397e-03],\n",
      "        [5.8502e-06, 1.2980e-04, 4.2711e-04, 6.6628e-04, 2.0565e-03, 1.1698e-01,\n",
      "         5.2968e-01, 1.2717e-01, 2.1585e-01, 7.0388e-03],\n",
      "        [1.0748e-04, 6.5285e-04, 1.4421e-03, 2.8298e-03, 5.7108e-04, 1.2064e-02,\n",
      "         3.0028e-01, 2.8746e-01, 3.2943e-01, 6.5161e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: bên_kia địa_cầu , cho_dù ở thời_đại nào , nhu_cầu cơ_bản\n",
      "Reference: across the globe , throughout the ages , our\n",
      "Model: <SOS> the the , , , in , , ,\n",
      "Attention Weights: tensor([[9.4190e-01, 5.7999e-02, 8.8559e-05, 7.4523e-06, 5.3839e-07, 2.6099e-07,\n",
      "         3.9291e-08, 1.7259e-10, 3.0394e-10, 1.1434e-09],\n",
      "        [1.0237e-02, 7.6606e-01, 2.1798e-01, 5.3306e-03, 2.0750e-04, 1.4319e-04,\n",
      "         3.6542e-05, 3.9091e-06, 1.3251e-06, 1.3394e-06],\n",
      "        [1.5609e-02, 1.7021e-01, 6.9185e-01, 1.1093e-01, 6.6985e-03, 3.0192e-03,\n",
      "         1.5062e-03, 1.4250e-04, 2.9817e-05, 1.6694e-05],\n",
      "        [3.3305e-04, 2.5306e-03, 4.8986e-02, 6.7268e-01, 2.1224e-01, 4.1973e-02,\n",
      "         1.7694e-02, 2.1327e-03, 8.8299e-04, 5.4854e-04],\n",
      "        [4.9272e-04, 7.3406e-03, 9.1263e-02, 6.7238e-01, 1.8583e-01, 2.7387e-02,\n",
      "         1.2282e-02, 1.4115e-03, 9.0351e-04, 7.0368e-04],\n",
      "        [1.5537e-04, 1.7004e-03, 7.9055e-03, 2.1470e-01, 4.9757e-01, 2.0132e-01,\n",
      "         5.9273e-02, 5.3348e-03, 6.4924e-03, 5.5528e-03],\n",
      "        [3.3426e-05, 7.6300e-04, 2.1669e-03, 1.0340e-02, 1.5713e-01, 3.0891e-01,\n",
      "         1.9627e-01, 1.7587e-01, 1.1772e-01, 3.0789e-02],\n",
      "        [2.7599e-06, 4.1436e-05, 3.5800e-04, 7.7100e-04, 1.8098e-02, 6.6521e-02,\n",
      "         4.4576e-02, 2.9151e-01, 4.1877e-01, 1.5935e-01],\n",
      "        [2.9765e-05, 5.7761e-05, 1.0903e-02, 1.9700e-02, 5.7083e-02, 3.6076e-02,\n",
      "         8.3699e-02, 3.7882e-01, 3.4619e-01, 6.7441e-02]])\n",
      "\n",
      "Epoch: 6.48, Train Loss: 2.53, Val Loss: 4.07, Train BLEU: 17.53, Val BLEU: 10.59, Minutes Elapsed: 337.57\n",
      "Sampling from training predictions...\n",
      "Source: video này được quay từ tuần trước . <EOS> <PAD>\n",
      "Reference: this short video is from last week . <EOS>\n",
      "Model: <SOS> this video is from from week week week <EOS>\n",
      "Attention Weights: tensor([[0.9975, 0.0025, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.9438, 0.0391, 0.0163, 0.0006, 0.0000, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0142, 0.1531, 0.6449, 0.1652, 0.0079, 0.0109, 0.0038, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0013, 0.0071, 0.6306, 0.2654, 0.0290, 0.0462, 0.0200, 0.0004, 0.0001,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0008, 0.2766, 0.2711, 0.0563, 0.2859, 0.1074, 0.0014, 0.0004,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0001, 0.0084, 0.0279, 0.0510, 0.6530, 0.2544, 0.0038, 0.0014,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0000, 0.0010, 0.0059, 0.0438, 0.5788, 0.3595, 0.0087, 0.0022,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0003, 0.0028, 0.0187, 0.3732, 0.5036, 0.0633, 0.0380,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0002, 0.0007, 0.0022, 0.0773, 0.2548, 0.2102, 0.4546,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: anh ta đã làm điều đặt biệt này lúc ban_đầu\n",
      "Reference: he did this especially at the beginning by <UNK>\n",
      "Model: <SOS> he did this this thing the last of the\n",
      "Attention Weights: tensor([[5.4243e-01, 2.4228e-02, 4.0133e-01, 1.5595e-02, 1.6113e-02, 2.9565e-04,\n",
      "         8.5059e-06, 5.3331e-07, 1.3033e-07, 1.0623e-08],\n",
      "        [2.2393e-02, 5.6918e-03, 1.6938e-01, 5.8271e-01, 2.1805e-01, 1.1927e-03,\n",
      "         5.7770e-04, 5.3855e-06, 1.1434e-06, 1.5874e-07],\n",
      "        [1.2445e-03, 1.2097e-03, 3.3602e-02, 3.4283e-01, 4.9238e-01, 6.6154e-02,\n",
      "         6.0486e-02, 1.6037e-03, 4.5839e-04, 3.3486e-05],\n",
      "        [9.8197e-05, 2.0978e-04, 7.1074e-04, 2.0280e-03, 1.4015e-01, 1.7910e-01,\n",
      "         6.1564e-01, 3.3372e-02, 2.5293e-02, 3.3979e-03],\n",
      "        [3.5740e-04, 7.6193e-04, 6.8682e-04, 1.5006e-03, 4.1040e-02, 1.1315e-01,\n",
      "         5.0863e-01, 1.0386e-01, 2.1137e-01, 1.8647e-02],\n",
      "        [3.8155e-05, 1.5051e-05, 4.5836e-05, 6.7336e-05, 5.0587e-04, 2.1460e-03,\n",
      "         4.9496e-02, 3.6033e-02, 6.7967e-01, 2.3198e-01],\n",
      "        [1.5637e-05, 1.5665e-05, 4.5682e-05, 6.9237e-05, 2.4546e-04, 1.0501e-03,\n",
      "         5.6064e-03, 4.8062e-03, 4.6374e-01, 5.2441e-01],\n",
      "        [3.9584e-04, 4.1753e-04, 6.7420e-04, 6.7054e-04, 1.4776e-03, 5.0901e-03,\n",
      "         1.6819e-02, 4.0915e-02, 5.5711e-01, 3.7643e-01],\n",
      "        [5.1253e-04, 3.3973e-04, 6.5380e-04, 9.6245e-04, 1.1976e-03, 4.3992e-03,\n",
      "         6.0939e-03, 2.6004e-02, 5.9284e-01, 3.6700e-01]])\n",
      "\n",
      "Epoch: 6.53, Train Loss: 2.50, Val Loss: 4.08, Train BLEU: 18.48, Val BLEU: 11.23, Minutes Elapsed: 340.14\n",
      "Sampling from training predictions...\n",
      "Source: bây_giờ chúng_ta sẽ chọn lấy mức bình_thường , và tôi\n",
      "Reference: so we &apos;ll stick with the normal one for\n",
      "Model: <SOS> now we &apos;re going the a , , and\n",
      "Attention Weights: tensor([[9.9980e-01, 6.0581e-05, 1.1579e-04, 2.2072e-05, 3.3194e-06, 1.2619e-07,\n",
      "         1.3369e-08, 8.4844e-11, 1.1443e-11, 6.1299e-11],\n",
      "        [7.6364e-01, 5.5094e-02, 1.6520e-01, 1.5840e-02, 1.8899e-04, 3.4395e-05,\n",
      "         8.1038e-06, 9.1436e-07, 3.6714e-07, 1.8134e-06],\n",
      "        [6.5931e-03, 4.1019e-03, 3.2003e-01, 6.5680e-01, 1.1147e-02, 1.2647e-03,\n",
      "         6.3064e-05, 2.9498e-06, 5.9489e-07, 2.0786e-06],\n",
      "        [2.4172e-03, 7.6836e-04, 2.0865e-01, 7.4243e-01, 4.0498e-02, 5.0017e-03,\n",
      "         2.2046e-04, 1.0814e-05, 6.6345e-07, 3.7061e-06],\n",
      "        [2.1229e-04, 1.7175e-05, 3.8281e-04, 6.1732e-02, 5.7264e-01, 3.3714e-01,\n",
      "         2.7791e-02, 7.2250e-05, 2.0041e-06, 4.2506e-06],\n",
      "        [7.3427e-05, 5.0326e-06, 2.5962e-05, 2.6401e-03, 1.1348e-01, 5.4671e-01,\n",
      "         3.2603e-01, 1.0806e-02, 1.5124e-04, 7.9408e-05],\n",
      "        [6.9122e-05, 9.3329e-07, 3.4937e-05, 1.8091e-04, 1.0915e-02, 2.4809e-01,\n",
      "         6.0236e-01, 1.3498e-01, 2.0751e-03, 1.2934e-03],\n",
      "        [1.5284e-04, 2.2720e-06, 6.6838e-05, 3.9259e-04, 2.3298e-03, 1.7160e-02,\n",
      "         7.0634e-02, 8.3015e-01, 6.2497e-02, 1.6610e-02],\n",
      "        [5.8603e-04, 2.0634e-05, 3.5730e-04, 2.7306e-03, 2.3122e-03, 2.6668e-02,\n",
      "         1.1372e-01, 7.9619e-01, 5.2926e-02, 4.4892e-03]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: trong đêm_tối lạnh_lẽo <UNK> . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: in the cold , windy night . <EOS> <PAD>\n",
      "Model: <SOS> in &apos;s <UNK> of of <UNK> . <EOS> .\n",
      "Attention Weights: tensor([[0.9977, 0.0023, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1682, 0.6786, 0.1516, 0.0016, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1121, 0.3375, 0.4956, 0.0526, 0.0019, 0.0002, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0131, 0.1482, 0.7667, 0.0645, 0.0068, 0.0007, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0080, 0.0413, 0.7340, 0.1977, 0.0159, 0.0031, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0010, 0.0209, 0.5084, 0.2250, 0.1342, 0.1105, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0522, 0.1781, 0.5752, 0.1312, 0.0248, 0.0385, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0037, 0.0358, 0.2002, 0.2690, 0.1338, 0.3576, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0081, 0.0380, 0.1834, 0.1675, 0.1155, 0.4874, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6.58, Train Loss: 2.55, Val Loss: 4.08, Train BLEU: 17.95, Val BLEU: 11.29, Minutes Elapsed: 342.72\n",
      "Sampling from training predictions...\n",
      "Source: có những trường_đoạn nhất_định trong bản_nhạc - - bản_nhạc có\n",
      "Reference: there &apos;s certain sections of the song -- the\n",
      "Model: <SOS> there are certain certain of in -- -- --\n",
      "Attention Weights: tensor([[9.8460e-01, 4.4081e-03, 9.2987e-03, 1.6313e-03, 5.5062e-05, 9.2657e-06,\n",
      "         2.1087e-07, 2.1246e-07, 7.9115e-07, 3.7634e-08],\n",
      "        [5.6525e-01, 6.3102e-02, 2.4436e-01, 1.0825e-01, 1.4619e-02, 2.9722e-03,\n",
      "         1.5952e-04, 1.7012e-04, 9.5403e-04, 1.7371e-04],\n",
      "        [2.9485e-02, 1.3990e-01, 5.8717e-01, 1.5970e-01, 5.9776e-02, 1.7466e-02,\n",
      "         2.0905e-03, 7.1063e-04, 2.6664e-03, 1.0422e-03],\n",
      "        [9.2681e-04, 3.2568e-02, 4.6355e-01, 3.5316e-01, 1.1940e-01, 2.6970e-02,\n",
      "         1.9047e-03, 8.1728e-04, 6.4294e-04, 5.6152e-05],\n",
      "        [1.8232e-03, 1.7429e-02, 4.8971e-01, 1.0490e-01, 3.3194e-01, 2.7841e-02,\n",
      "         1.3906e-02, 5.1675e-03, 6.5829e-03, 7.0445e-04],\n",
      "        [3.4488e-04, 8.2960e-05, 6.8629e-03, 1.0561e-02, 5.6773e-01, 2.1980e-01,\n",
      "         1.1464e-01, 4.5407e-02, 3.1433e-02, 3.1414e-03],\n",
      "        [1.2212e-04, 5.5508e-05, 2.9692e-03, 5.1173e-03, 1.1560e-01, 3.6690e-01,\n",
      "         3.8095e-02, 6.1128e-02, 3.9737e-01, 1.2644e-02],\n",
      "        [3.4398e-05, 4.8981e-06, 4.9099e-05, 1.4419e-04, 2.6788e-02, 2.4253e-02,\n",
      "         1.4019e-01, 3.0295e-01, 4.5025e-01, 5.5337e-02],\n",
      "        [4.7327e-05, 5.6341e-06, 8.4748e-05, 5.5246e-04, 2.8452e-02, 9.4987e-02,\n",
      "         1.3238e-01, 1.9826e-01, 5.0543e-01, 3.9797e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: vì_vậy hôm_nay tôi muốn động_viên tất_cả mọi người hãy có_mặt\n",
      "Reference: so i want to encourage everyone today to get\n",
      "Model: <SOS> so today i to encourage all all to let\n",
      "Attention Weights: tensor([[9.9469e-01, 5.2958e-03, 5.3024e-06, 3.2908e-06, 7.6030e-07, 8.2962e-08,\n",
      "         5.7839e-10, 3.3482e-11, 1.7921e-11, 3.9889e-11],\n",
      "        [9.4771e-02, 6.1190e-01, 2.6607e-01, 2.7154e-02, 1.0097e-04, 3.2960e-06,\n",
      "         4.3357e-07, 4.9038e-07, 1.4077e-06, 4.8104e-07],\n",
      "        [3.1624e-03, 2.8184e-02, 1.3676e-01, 8.1463e-01, 1.6963e-02, 7.0357e-05,\n",
      "         3.7339e-05, 5.7410e-05, 8.1118e-05, 4.7782e-05],\n",
      "        [5.6155e-03, 1.4265e-02, 3.3650e-02, 8.8646e-01, 5.8993e-02, 3.8819e-04,\n",
      "         2.4098e-04, 1.6528e-04, 7.8779e-05, 1.4488e-04],\n",
      "        [8.6921e-05, 1.9930e-04, 2.7385e-04, 1.1449e-02, 9.4696e-01, 2.2370e-02,\n",
      "         9.7283e-03, 5.3391e-03, 1.6763e-03, 1.9226e-03],\n",
      "        [1.7640e-04, 1.7089e-04, 3.8729e-04, 5.3929e-03, 3.7388e-01, 4.1326e-01,\n",
      "         1.8014e-01, 2.1813e-02, 2.5576e-03, 2.2196e-03],\n",
      "        [2.5012e-05, 5.1908e-05, 3.7219e-04, 3.2878e-03, 1.0937e-01, 3.3802e-01,\n",
      "         3.9232e-01, 1.3152e-01, 7.9611e-03, 1.7075e-02],\n",
      "        [1.1330e-06, 1.7089e-06, 2.0173e-05, 9.7119e-04, 9.4886e-03, 6.3448e-02,\n",
      "         3.9225e-01, 3.6691e-01, 5.2200e-02, 1.1470e-01],\n",
      "        [6.7715e-07, 2.2468e-06, 4.1530e-06, 1.3307e-04, 2.0227e-04, 2.4954e-03,\n",
      "         5.5439e-02, 1.8390e-01, 2.4265e-01, 5.1517e-01]])\n",
      "\n",
      "Epoch: 6.62, Train Loss: 2.53, Val Loss: 4.09, Train BLEU: 18.37, Val BLEU: 11.75, Minutes Elapsed: 345.29\n",
      "Sampling from training predictions...\n",
      "Source: cũng gần vào thời_kỳ này , tôi nghĩ nó được\n",
      "Reference: it &apos;s around the same time , i think\n",
      "Model: <SOS> using in down this this time , i think\n",
      "Attention Weights: tensor([[9.9884e-01, 1.1594e-03, 8.5142e-07, 1.2301e-08, 4.5146e-10, 3.4147e-13,\n",
      "         2.7771e-13, 2.5336e-12, 1.4902e-13, 3.0060e-14],\n",
      "        [6.3007e-01, 3.4783e-01, 2.0823e-02, 1.2566e-03, 1.3547e-05, 2.3103e-06,\n",
      "         1.2864e-07, 3.4398e-06, 6.2586e-07, 4.3661e-07],\n",
      "        [3.3561e-01, 2.5232e-01, 3.1745e-01, 8.7602e-02, 3.9004e-03, 2.4183e-03,\n",
      "         9.1630e-05, 4.7940e-04, 6.8505e-05, 6.7635e-05],\n",
      "        [2.6101e-01, 2.2029e-01, 2.4568e-01, 2.5388e-01, 1.2843e-02, 3.6045e-03,\n",
      "         1.1878e-04, 8.7605e-04, 5.3031e-04, 1.1599e-03],\n",
      "        [6.5001e-02, 1.1181e-01, 3.4281e-01, 3.9509e-01, 6.1114e-02, 1.9399e-02,\n",
      "         4.0265e-04, 7.5487e-04, 8.3046e-04, 2.7772e-03],\n",
      "        [7.7249e-03, 6.4686e-03, 1.5443e-01, 6.8344e-01, 7.0854e-02, 7.2302e-02,\n",
      "         9.0686e-04, 8.4420e-04, 1.3494e-03, 1.6792e-03],\n",
      "        [1.7994e-03, 3.0115e-03, 9.9684e-02, 3.5459e-01, 8.4535e-02, 4.3223e-01,\n",
      "         1.4674e-02, 2.8591e-03, 3.1327e-03, 3.4890e-03],\n",
      "        [7.1953e-05, 5.0456e-04, 1.9090e-02, 2.3111e-01, 7.9463e-02, 5.3388e-01,\n",
      "         8.8223e-02, 2.9481e-02, 8.3567e-03, 9.8155e-03],\n",
      "        [3.2445e-04, 2.2466e-03, 6.9030e-03, 1.0256e-01, 1.2699e-02, 2.4713e-02,\n",
      "         1.8274e-02, 6.3787e-01, 1.2863e-01, 6.5784e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: nếu không , bé gái trong hình sẽ không còn\n",
      "Reference: otherwise , that little girl isn &apos;t going to\n",
      "Model: <SOS> if no , you in in in in to\n",
      "Attention Weights: tensor([[5.5932e-04, 9.9907e-01, 3.6084e-04, 6.3506e-07, 5.5697e-06, 4.8234e-07,\n",
      "         2.4014e-09, 3.0565e-10, 3.1703e-10, 1.9241e-11],\n",
      "        [4.5273e-03, 9.7688e-01, 1.8262e-02, 1.7777e-04, 1.1934e-04, 3.0802e-05,\n",
      "         5.2879e-07, 5.3983e-07, 1.1383e-07, 8.8768e-08],\n",
      "        [3.2984e-02, 4.1716e-01, 4.7936e-01, 3.3879e-02, 1.9093e-02, 1.6300e-02,\n",
      "         9.5976e-04, 1.9141e-04, 4.3677e-05, 2.4669e-05],\n",
      "        [7.6477e-03, 1.4847e-01, 2.4645e-01, 1.6360e-01, 2.0959e-01, 1.8813e-01,\n",
      "         2.9719e-02, 4.6036e-03, 1.1899e-03, 5.9564e-04],\n",
      "        [2.5535e-04, 2.2990e-02, 3.1231e-02, 2.0280e-02, 2.1528e-01, 6.3051e-01,\n",
      "         4.8446e-02, 1.9860e-02, 6.9983e-03, 4.1554e-03],\n",
      "        [2.7385e-05, 4.0429e-02, 7.0988e-02, 1.1340e-02, 6.5502e-02, 6.7189e-01,\n",
      "         9.4430e-02, 3.2152e-02, 7.5064e-03, 5.7362e-03],\n",
      "        [4.9669e-06, 7.3633e-04, 2.1960e-03, 2.1578e-03, 2.2718e-02, 4.4177e-01,\n",
      "         3.7775e-01, 9.6721e-02, 2.4228e-02, 3.1721e-02],\n",
      "        [3.7157e-07, 1.4624e-04, 6.4080e-04, 3.3582e-04, 2.9586e-03, 4.2556e-02,\n",
      "         3.3225e-01, 1.7292e-01, 1.4811e-01, 3.0008e-01],\n",
      "        [6.3120e-07, 1.3387e-05, 3.0576e-04, 6.7555e-05, 7.1789e-04, 8.9297e-03,\n",
      "         4.3947e-02, 8.2261e-02, 1.6161e-01, 7.0215e-01]])\n",
      "\n",
      "Epoch: 6.67, Train Loss: 2.60, Val Loss: 4.12, Train BLEU: 15.89, Val BLEU: 10.44, Minutes Elapsed: 347.85\n",
      "Sampling from training predictions...\n",
      "Source: đầu_tiên , chúng_tôi yêu_cầu 1 nửa số người tham_gia hồi_tưởng\n",
      "Reference: first , we asked half the people to recall\n",
      "Model: <SOS> so , we asked a a a of people\n",
      "Attention Weights: tensor([[9.9997e-01, 2.4395e-05, 3.2909e-06, 1.0443e-06, 9.3360e-10, 1.8473e-10,\n",
      "         3.4737e-11, 1.9358e-11, 1.7595e-11, 4.7908e-11],\n",
      "        [9.5769e-01, 2.9915e-02, 2.0580e-03, 1.0256e-02, 6.0990e-05, 1.2423e-05,\n",
      "         2.5384e-06, 1.1926e-06, 2.7544e-06, 2.0703e-06],\n",
      "        [1.2346e-01, 3.2363e-01, 8.7701e-02, 3.8105e-01, 5.3512e-02, 1.9587e-02,\n",
      "         5.6099e-03, 2.1492e-03, 2.6685e-03, 6.2481e-04],\n",
      "        [2.8562e-03, 1.5942e-02, 1.1845e-01, 8.4976e-01, 6.6669e-03, 3.5283e-03,\n",
      "         1.0743e-03, 6.3720e-04, 8.4255e-04, 2.3715e-04],\n",
      "        [1.2525e-03, 4.7502e-03, 1.0560e-02, 7.8108e-01, 1.4105e-01, 4.2711e-02,\n",
      "         1.0038e-02, 4.2383e-03, 3.1985e-03, 1.1209e-03],\n",
      "        [2.5938e-05, 4.3801e-05, 2.1177e-04, 1.3659e-02, 1.5719e-01, 6.9522e-01,\n",
      "         7.3092e-02, 2.7473e-02, 2.2981e-02, 1.0105e-02],\n",
      "        [4.4270e-06, 1.1856e-05, 1.0485e-04, 3.1783e-03, 1.1883e-01, 5.4129e-01,\n",
      "         1.9806e-01, 5.5908e-02, 5.2213e-02, 3.0397e-02],\n",
      "        [8.3027e-07, 4.1044e-06, 4.9962e-05, 7.8871e-04, 2.0784e-02, 3.3843e-01,\n",
      "         1.0443e-01, 1.1457e-01, 1.9652e-01, 2.2443e-01],\n",
      "        [9.7250e-07, 1.1253e-05, 8.3273e-06, 3.1735e-04, 3.3729e-03, 1.0213e-01,\n",
      "         9.8550e-02, 1.1284e-01, 4.1259e-01, 2.7018e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: vì_thế chúng_ta được dạy rằng \" sự khoan_dung của ta\n",
      "Reference: thus we are told that &quot; my mercy <UNK>\n",
      "Model: <SOS> so we we taught that &quot; our our of\n",
      "Attention Weights: tensor([[9.8494e-01, 9.3351e-05, 1.4759e-02, 1.9931e-04, 6.7078e-06, 4.9131e-08,\n",
      "         7.0630e-09, 4.2203e-08, 3.4533e-09, 6.5042e-10],\n",
      "        [4.3170e-02, 1.1105e-01, 8.4520e-01, 5.7208e-04, 2.0451e-06, 1.2797e-06,\n",
      "         2.4488e-06, 4.6489e-06, 2.2818e-07, 3.6866e-08],\n",
      "        [5.0001e-03, 1.7437e-02, 8.4851e-01, 1.2459e-01, 3.4545e-03, 1.6436e-04,\n",
      "         3.7606e-04, 4.6245e-04, 5.6025e-06, 2.9705e-06],\n",
      "        [9.8483e-04, 6.2687e-03, 6.5567e-01, 2.9383e-01, 3.2020e-02, 2.5834e-03,\n",
      "         2.1404e-03, 6.3988e-03, 8.6570e-05, 1.4564e-05],\n",
      "        [3.0254e-05, 5.4011e-05, 2.3212e-03, 3.8405e-01, 3.5175e-01, 2.2837e-01,\n",
      "         1.3792e-02, 1.8687e-02, 3.5946e-04, 5.7669e-04],\n",
      "        [7.5665e-05, 1.6418e-04, 1.2213e-03, 2.5676e-02, 1.1817e-01, 5.1426e-01,\n",
      "         2.4394e-01, 9.1205e-02, 3.3076e-03, 1.9768e-03],\n",
      "        [5.4193e-06, 9.5867e-06, 4.6178e-04, 1.4220e-03, 9.1818e-03, 1.5713e-01,\n",
      "         6.2729e-01, 1.9769e-01, 4.8952e-03, 1.9163e-03],\n",
      "        [1.8828e-06, 2.2884e-06, 1.7062e-05, 3.2016e-05, 7.3268e-04, 3.1380e-02,\n",
      "         3.4248e-01, 6.0844e-01, 9.4328e-03, 7.4770e-03],\n",
      "        [9.8529e-06, 1.1775e-05, 2.0326e-05, 8.2432e-05, 1.1018e-03, 4.8139e-03,\n",
      "         3.1691e-02, 9.0203e-01, 2.5985e-02, 3.4252e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6.72, Train Loss: 2.56, Val Loss: 4.10, Train BLEU: 16.87, Val BLEU: 11.36, Minutes Elapsed: 350.41\n",
      "Sampling from training predictions...\n",
      "Source: và tôi kẹp trong 1 khoảng thời_gian dài và ngắn\n",
      "Reference: and i would crunch it for long periods and\n",
      "Model: <SOS> and i was up a a a long long\n",
      "Attention Weights: tensor([[5.1812e-02, 6.9129e-01, 2.5659e-01, 3.1002e-04, 1.1696e-06, 4.0626e-07,\n",
      "         8.3147e-07, 2.5556e-08, 3.6119e-09, 1.9870e-09],\n",
      "        [1.5951e-02, 5.8064e-01, 4.0320e-01, 2.0385e-04, 5.2321e-06, 3.1780e-07,\n",
      "         3.3952e-07, 6.9451e-08, 1.6278e-08, 1.6609e-08],\n",
      "        [1.0922e-05, 6.4777e-03, 9.8714e-01, 6.0736e-03, 2.1652e-04, 5.8261e-05,\n",
      "         1.6095e-05, 6.0281e-06, 1.0948e-06, 3.0065e-06],\n",
      "        [6.6373e-05, 2.1828e-03, 7.7731e-01, 2.0658e-01, 1.0462e-02, 2.3835e-03,\n",
      "         7.8676e-04, 2.2493e-04, 3.1145e-06, 6.9428e-06],\n",
      "        [7.4973e-05, 1.7745e-04, 1.9144e-02, 2.6103e-01, 3.3577e-01, 2.1753e-01,\n",
      "         1.1087e-01, 5.3601e-02, 9.5782e-04, 8.4204e-04],\n",
      "        [5.6386e-05, 5.0015e-04, 5.0542e-02, 9.9702e-02, 1.5772e-01, 3.6953e-01,\n",
      "         2.0227e-01, 1.1569e-01, 2.0462e-03, 1.9412e-03],\n",
      "        [5.0970e-07, 1.4183e-05, 2.1371e-04, 4.3726e-04, 2.7854e-02, 2.4433e-01,\n",
      "         4.1004e-01, 2.9070e-01, 1.4210e-02, 1.2196e-02],\n",
      "        [9.1989e-07, 5.1861e-06, 4.1793e-04, 6.0967e-04, 1.3986e-02, 3.0490e-01,\n",
      "         3.5602e-01, 2.8578e-01, 2.4042e-02, 1.4240e-02],\n",
      "        [3.5106e-06, 3.2047e-05, 6.3644e-04, 3.6603e-04, 2.5429e-03, 8.8140e-02,\n",
      "         2.6076e-01, 4.3550e-01, 1.5337e-01, 5.8652e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: đó là lí_do tại_sao người da_trắng tại châu phi được\n",
      "Reference: that &apos;s why the white people in africa are\n",
      "Model: <SOS> that &apos;s why the people is in africa africa\n",
      "Attention Weights: tensor([[3.6738e-01, 6.1973e-01, 1.2796e-02, 8.4156e-05, 1.5276e-06, 4.6063e-07,\n",
      "         3.5650e-09, 1.6299e-10, 2.4995e-10, 2.5445e-10],\n",
      "        [9.3494e-03, 4.9621e-01, 4.5771e-01, 3.4672e-02, 1.4583e-03, 5.6266e-04,\n",
      "         3.1366e-05, 5.4528e-06, 3.3304e-06, 2.8602e-06],\n",
      "        [2.9759e-02, 1.9963e-01, 4.7814e-01, 2.7222e-01, 1.2587e-02, 6.6951e-03,\n",
      "         6.9911e-04, 1.8339e-04, 5.6690e-05, 2.4400e-05],\n",
      "        [4.5015e-04, 1.1717e-02, 7.3579e-02, 1.9276e-01, 5.8914e-01, 1.2227e-01,\n",
      "         7.2103e-03, 1.8042e-03, 6.4476e-04, 4.1268e-04],\n",
      "        [6.4017e-05, 1.8079e-03, 7.1087e-03, 4.5315e-02, 4.3712e-01, 4.8271e-01,\n",
      "         1.8262e-02, 5.2440e-03, 1.7661e-03, 6.0764e-04],\n",
      "        [1.8154e-04, 9.1758e-04, 1.1194e-03, 2.6082e-02, 1.6355e-01, 6.1813e-01,\n",
      "         1.2650e-01, 3.9124e-02, 1.7588e-02, 6.8122e-03],\n",
      "        [2.6465e-06, 4.1971e-05, 1.0466e-04, 1.1091e-03, 1.3483e-02, 4.4370e-01,\n",
      "         3.6181e-01, 1.0800e-01, 3.5266e-02, 3.6485e-02],\n",
      "        [1.8280e-06, 2.8167e-05, 6.5518e-05, 4.9741e-04, 8.1766e-03, 2.9068e-01,\n",
      "         2.9247e-01, 2.5492e-01, 7.4377e-02, 7.8781e-02],\n",
      "        [1.8619e-06, 1.4477e-05, 1.5041e-04, 2.9786e-04, 3.5118e-03, 5.1962e-02,\n",
      "         3.0186e-01, 2.2782e-01, 1.5485e-01, 2.5953e-01]])\n",
      "\n",
      "Epoch: 6.77, Train Loss: 2.54, Val Loss: 4.09, Train BLEU: 17.97, Val BLEU: 10.97, Minutes Elapsed: 352.98\n",
      "Sampling from training predictions...\n",
      "Source: ừ thì nó thả tôi ở những vực sâu nhưng\n",
      "Reference: because yeah , it &apos;s put me in the\n",
      "Model: <SOS> well it it it &apos;s me me in the\n",
      "Attention Weights: tensor([[9.8880e-01, 5.3688e-03, 5.8273e-03, 7.7443e-06, 2.5186e-08, 3.0823e-09,\n",
      "         2.2620e-11, 2.5292e-11, 5.2961e-12, 1.5611e-12],\n",
      "        [1.9930e-02, 6.3033e-02, 8.8620e-01, 3.0750e-02, 7.0589e-05, 1.1765e-05,\n",
      "         5.5958e-07, 6.4669e-07, 5.9719e-07, 2.2860e-07],\n",
      "        [2.3855e-02, 3.3085e-02, 5.3336e-01, 3.9184e-01, 1.3541e-02, 3.6593e-03,\n",
      "         1.7309e-04, 2.8022e-04, 1.8311e-04, 2.6049e-05],\n",
      "        [1.2201e-02, 3.8657e-03, 9.5678e-02, 8.0160e-01, 4.8113e-02, 3.6656e-02,\n",
      "         4.9107e-04, 7.6940e-04, 4.7704e-04, 1.4583e-04],\n",
      "        [1.9785e-03, 1.6202e-03, 3.7654e-02, 8.1001e-01, 8.5721e-02, 6.1298e-02,\n",
      "         5.9665e-04, 6.2231e-04, 3.9851e-04, 9.7420e-05],\n",
      "        [2.8158e-03, 2.4592e-03, 4.2956e-02, 8.3481e-01, 9.7691e-02, 1.8572e-02,\n",
      "         3.3306e-04, 1.8922e-04, 1.2974e-04, 4.8971e-05],\n",
      "        [9.9095e-04, 3.9513e-04, 6.5582e-03, 3.2240e-01, 3.4675e-01, 2.9801e-01,\n",
      "         1.2468e-02, 6.1393e-03, 5.7632e-03, 5.2484e-04],\n",
      "        [7.0533e-04, 7.7335e-04, 1.6576e-02, 3.1540e-01, 1.8076e-01, 4.4253e-01,\n",
      "         1.8560e-02, 1.2453e-02, 1.0951e-02, 1.2929e-03],\n",
      "        [2.7494e-05, 3.4007e-05, 1.1052e-03, 6.9459e-02, 7.5711e-02, 2.6787e-01,\n",
      "         1.8196e-01, 2.4974e-01, 1.4228e-01, 1.1814e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: dọn_dẹp trường_học , vệ_sinh nhà_cửa , sẵn_sàng cho việc đổi_mới\n",
      "Reference: we cleaned schools . we <UNK> and gutted homes\n",
      "Model: <SOS> it school , schools young schools , , to\n",
      "Attention Weights: tensor([[9.9896e-01, 1.0391e-03, 4.4405e-07, 4.3223e-08, 4.8025e-09, 1.3891e-11,\n",
      "         8.2721e-11, 1.6478e-11, 5.6886e-12, 3.5399e-12],\n",
      "        [1.5530e-01, 8.2508e-01, 1.7025e-02, 2.3298e-03, 2.3742e-04, 1.5242e-05,\n",
      "         1.2537e-05, 2.3488e-06, 1.9878e-06, 1.3228e-06],\n",
      "        [1.1563e-01, 6.7933e-01, 1.8155e-01, 1.5758e-02, 5.9798e-03, 1.0140e-03,\n",
      "         5.7307e-04, 8.8706e-05, 4.2893e-05, 2.8849e-05],\n",
      "        [1.1516e-02, 1.8529e-01, 4.2478e-01, 3.0395e-01, 5.1106e-02, 1.3091e-02,\n",
      "         6.9139e-03, 1.5610e-03, 1.1011e-03, 6.9629e-04],\n",
      "        [8.8434e-03, 1.3348e-02, 1.7555e-01, 7.0304e-01, 7.9432e-02, 6.7165e-03,\n",
      "         9.4554e-03, 2.0090e-03, 9.7749e-04, 6.3303e-04],\n",
      "        [6.9548e-05, 2.4634e-04, 1.7393e-02, 5.9628e-01, 2.4014e-01, 3.3803e-02,\n",
      "         9.6123e-02, 8.4708e-03, 4.6766e-03, 2.7972e-03],\n",
      "        [1.3520e-04, 7.9019e-04, 1.9215e-02, 1.6010e-01, 7.9029e-02, 2.2445e-01,\n",
      "         3.4703e-01, 1.2571e-01, 3.2671e-02, 1.0882e-02],\n",
      "        [2.0690e-05, 1.0065e-04, 8.6488e-03, 2.3229e-01, 1.0754e-01, 2.1813e-01,\n",
      "         2.8981e-01, 6.7615e-02, 4.2431e-02, 3.3421e-02],\n",
      "        [1.9947e-06, 4.5305e-06, 1.3458e-04, 2.5893e-02, 9.8414e-03, 5.3284e-02,\n",
      "         5.4498e-01, 1.5441e-01, 8.2523e-02, 1.2892e-01]])\n",
      "\n",
      "Epoch: 6.82, Train Loss: 2.60, Val Loss: 4.10, Train BLEU: 17.04, Val BLEU: 11.28, Minutes Elapsed: 355.56\n",
      "Sampling from training predictions...\n",
      "Source: còn rất nhiều chất có nước như bê_tông , sơn\n",
      "Reference: it &apos;s a lot of water-based materials like concrete\n",
      "Model: <SOS> there &apos;s a lot of water-based , people there\n",
      "Attention Weights: tensor([[9.2920e-01, 7.0537e-02, 2.5218e-04, 5.9456e-06, 1.0944e-06, 5.5031e-07,\n",
      "         2.0679e-09, 1.0053e-09, 6.8493e-11, 1.4113e-10],\n",
      "        [1.1073e-01, 2.4316e-01, 4.1847e-01, 1.9180e-01, 1.6057e-02, 1.8160e-02,\n",
      "         6.7894e-04, 7.8919e-04, 4.6611e-05, 1.0447e-04],\n",
      "        [1.3101e-01, 5.7229e-02, 1.8474e-01, 3.7099e-01, 7.9519e-02, 1.4817e-01,\n",
      "         9.1643e-03, 1.6603e-02, 1.7608e-03, 8.2570e-04],\n",
      "        [8.9800e-03, 5.5586e-02, 4.1839e-01, 2.0355e-01, 6.5367e-02, 2.3057e-01,\n",
      "         5.5752e-03, 1.1438e-02, 4.5966e-04, 8.4010e-05],\n",
      "        [2.1752e-04, 2.9529e-03, 2.0494e-01, 3.2317e-01, 5.7110e-02, 3.6340e-01,\n",
      "         7.4702e-03, 3.5737e-02, 2.8731e-03, 2.1331e-03],\n",
      "        [6.1988e-04, 1.1885e-03, 1.3817e-01, 4.2043e-01, 9.0566e-02, 2.2130e-01,\n",
      "         6.9876e-02, 5.1161e-02, 2.6388e-03, 4.0484e-03],\n",
      "        [2.7724e-05, 8.2118e-05, 9.6621e-03, 1.2846e-01, 1.9722e-01, 5.2669e-01,\n",
      "         1.9326e-02, 1.1052e-01, 5.1092e-03, 2.9051e-03],\n",
      "        [3.2948e-05, 3.5242e-05, 1.0506e-03, 5.6691e-02, 5.3331e-02, 2.7204e-01,\n",
      "         7.2762e-02, 2.9650e-01, 8.4621e-02, 1.6294e-01],\n",
      "        [3.9423e-03, 3.4665e-03, 9.6382e-03, 1.2132e-01, 1.6694e-01, 2.3175e-01,\n",
      "         2.5888e-02, 1.9477e-01, 6.8609e-02, 1.7367e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: nhưng tôi cũng là vui_mừng và vinh_dự lên đây tôi\n",
      "Reference: but i &apos;m also happy and honored to be\n",
      "Model: <SOS> but i also also happy and and &apos;m i\n",
      "Attention Weights: tensor([[1.2374e-02, 2.8180e-01, 7.0556e-01, 2.6797e-04, 3.8270e-06, 3.2923e-08,\n",
      "         7.9515e-07, 9.5329e-07, 2.0415e-08, 2.7557e-09],\n",
      "        [1.8304e-02, 4.9825e-01, 4.8254e-01, 7.4053e-04, 1.3425e-04, 2.5872e-06,\n",
      "         2.1046e-05, 1.1724e-05, 1.4068e-06, 5.1945e-07],\n",
      "        [3.7263e-04, 1.9336e-03, 9.1489e-01, 7.8113e-02, 4.4905e-03, 4.6923e-05,\n",
      "         1.0814e-04, 3.7442e-05, 4.5950e-06, 3.2367e-06],\n",
      "        [1.2704e-03, 1.2436e-03, 5.8901e-01, 2.6967e-01, 1.3633e-01, 4.1892e-04,\n",
      "         1.5729e-03, 4.4077e-04, 2.8504e-05, 1.3998e-05],\n",
      "        [4.1911e-05, 5.8321e-05, 1.4897e-03, 2.8867e-02, 9.1643e-01, 1.3309e-02,\n",
      "         3.1042e-02, 8.5851e-03, 1.4451e-04, 3.6839e-05],\n",
      "        [1.8171e-05, 8.1389e-05, 1.7262e-04, 8.5093e-03, 6.0451e-01, 1.2036e-01,\n",
      "         1.6025e-01, 1.0223e-01, 3.2304e-03, 6.3857e-04],\n",
      "        [6.6320e-06, 8.2128e-06, 1.6693e-05, 4.5451e-04, 5.5797e-02, 4.8369e-02,\n",
      "         2.9801e-01, 5.6559e-01, 2.5580e-02, 6.1723e-03],\n",
      "        [2.3866e-05, 7.4515e-06, 1.3747e-05, 1.2544e-04, 3.2297e-03, 4.3517e-03,\n",
      "         1.9176e-01, 3.2742e-01, 3.9939e-01, 7.3681e-02],\n",
      "        [5.5207e-06, 2.9439e-05, 1.9687e-04, 3.9839e-04, 3.0622e-03, 1.9357e-03,\n",
      "         2.8393e-02, 1.5688e-01, 5.0702e-01, 3.0208e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6.86, Train Loss: 2.49, Val Loss: 4.09, Train BLEU: 18.46, Val BLEU: 11.03, Minutes Elapsed: 358.15\n",
      "Sampling from training predictions...\n",
      "Source: tôi có một người cô là một người kể_chuyện tuyệt_vời\n",
      "Reference: i have an aunt who is a wonderful storyteller\n",
      "Model: <SOS> i i a person who a a storyteller storyteller\n",
      "Attention Weights: tensor([[1.6117e-01, 8.3089e-01, 7.8697e-03, 6.5135e-05, 6.7216e-06, 2.0053e-07,\n",
      "         1.1747e-08, 4.0275e-09, 1.1518e-09, 9.1969e-10],\n",
      "        [4.9835e-03, 8.3141e-01, 1.5867e-01, 4.1621e-03, 5.7440e-04, 1.7296e-04,\n",
      "         7.5997e-06, 7.6996e-06, 4.9107e-06, 1.8743e-06],\n",
      "        [4.8655e-03, 2.5996e-01, 5.6963e-01, 1.1969e-01, 3.2007e-02, 1.0958e-02,\n",
      "         1.8252e-03, 7.9872e-04, 1.7955e-04, 8.2424e-05],\n",
      "        [3.3258e-04, 1.7599e-03, 1.0371e-01, 6.2785e-01, 1.1373e-01, 5.8376e-02,\n",
      "         1.1274e-02, 4.2679e-02, 2.3941e-02, 1.6345e-02],\n",
      "        [9.6167e-04, 4.1730e-03, 1.6455e-01, 2.0161e-01, 1.2009e-01, 3.3523e-01,\n",
      "         3.2321e-02, 6.4628e-02, 4.2730e-02, 3.3715e-02],\n",
      "        [8.9548e-05, 4.4615e-04, 1.7100e-03, 9.3109e-03, 2.3267e-01, 4.6469e-01,\n",
      "         8.5868e-02, 6.9257e-02, 7.1507e-02, 6.4458e-02],\n",
      "        [5.6434e-06, 1.1665e-04, 5.7675e-04, 3.6323e-03, 4.6704e-02, 5.5404e-01,\n",
      "         8.3321e-02, 1.5919e-01, 8.3148e-02, 6.9260e-02],\n",
      "        [1.8430e-07, 1.1623e-05, 2.0152e-04, 4.9918e-03, 1.6479e-02, 2.3101e-01,\n",
      "         7.1247e-02, 1.5788e-01, 2.4302e-01, 2.7516e-01],\n",
      "        [2.0812e-06, 1.0620e-05, 3.9613e-04, 1.1904e-02, 1.2342e-02, 6.6979e-02,\n",
      "         2.8662e-02, 4.0414e-01, 3.8152e-01, 9.4045e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: cảm_ơn <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: thank you . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> thank you . <EOS> you <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0851, 0.9149, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.9320, 0.0680, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.8817, 0.1183, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.7393, 0.2607, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.8567, 0.1433, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.8198, 0.1802, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.9765, 0.0235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.8312, 0.1688, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.8535, 0.1465, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 6.91, Train Loss: 2.48, Val Loss: 4.12, Train BLEU: 17.31, Val BLEU: 10.12, Minutes Elapsed: 360.70\n",
      "Sampling from training predictions...\n",
      "Source: bạn chỉ thấy một đứa trẻ là một đội_trưởng của\n",
      "Reference: you &apos;d see a kid who was the captain\n",
      "Model: <SOS> you you see a child child a a of\n",
      "Attention Weights: tensor([[6.7825e-01, 3.1798e-01, 3.5798e-03, 1.5526e-04, 2.5475e-05, 2.8026e-06,\n",
      "         1.6634e-08, 6.2724e-08, 1.3702e-08, 5.3163e-10],\n",
      "        [1.1607e-02, 5.6058e-01, 4.2641e-01, 7.9236e-04, 4.0560e-04, 2.0025e-04,\n",
      "         2.5819e-06, 1.6895e-06, 3.9122e-06, 2.1937e-07],\n",
      "        [5.6630e-03, 1.4804e-01, 7.9622e-01, 2.5470e-02, 1.3376e-02, 1.0961e-02,\n",
      "         1.2125e-04, 5.1024e-05, 9.1749e-05, 6.7778e-06],\n",
      "        [8.8389e-05, 2.6443e-03, 1.7419e-01, 2.7257e-01, 3.0111e-01, 2.3653e-01,\n",
      "         5.6692e-03, 2.7250e-03, 4.0045e-03, 4.6671e-04],\n",
      "        [2.0882e-04, 3.9640e-03, 1.2934e-01, 1.2217e-01, 2.7944e-01, 4.2066e-01,\n",
      "         2.0990e-02, 7.2285e-03, 1.4785e-02, 1.2191e-03],\n",
      "        [2.2476e-04, 2.2288e-03, 1.9697e-02, 2.8937e-02, 2.5197e-01, 4.7068e-01,\n",
      "         6.7683e-02, 5.0247e-02, 9.9562e-02, 8.7699e-03],\n",
      "        [1.7433e-05, 3.1546e-05, 1.5078e-03, 2.9218e-03, 2.5887e-02, 2.4576e-01,\n",
      "         2.1709e-01, 2.2522e-01, 1.9819e-01, 8.3369e-02],\n",
      "        [6.3237e-07, 4.1023e-05, 4.1930e-04, 3.8391e-04, 3.0804e-03, 2.6240e-02,\n",
      "         6.9067e-02, 1.7911e-01, 6.2457e-01, 9.7087e-02],\n",
      "        [2.5235e-07, 8.0687e-06, 1.9373e-04, 6.8950e-04, 3.3345e-03, 2.4055e-02,\n",
      "         4.6594e-02, 1.5828e-01, 6.9762e-01, 6.9228e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tất_nhiên những người dân bản_địa <UNK> hứng_thú làm công_việc này\n",
      "Reference: and of course the local people had absolutely no\n",
      "Model: <SOS> of course course , people who of &apos;t with\n",
      "Attention Weights: tensor([[9.9961e-01, 3.8578e-04, 4.8813e-06, 2.5526e-07, 1.8030e-07, 7.4404e-09,\n",
      "         1.0682e-08, 1.8410e-09, 5.9869e-10, 4.6552e-10],\n",
      "        [8.6554e-01, 1.2512e-01, 5.1358e-03, 2.3137e-03, 1.6678e-03, 1.0950e-04,\n",
      "         5.0536e-05, 3.6521e-05, 2.5700e-05, 1.9557e-06],\n",
      "        [3.6630e-01, 3.4708e-01, 1.2731e-01, 9.2768e-02, 5.3855e-02, 7.2154e-03,\n",
      "         2.6837e-03, 1.8669e-03, 8.2096e-04, 8.9857e-05],\n",
      "        [1.6200e-01, 2.7211e-01, 1.0645e-01, 2.4609e-01, 1.7492e-01, 1.9968e-02,\n",
      "         8.9058e-03, 6.9903e-03, 2.2591e-03, 3.0861e-04],\n",
      "        [4.5675e-02, 4.3291e-01, 1.2167e-01, 1.4401e-01, 1.6970e-01, 2.6382e-02,\n",
      "         4.0105e-02, 1.4245e-02, 4.7024e-03, 5.9501e-04],\n",
      "        [6.4120e-04, 6.5512e-02, 2.6804e-02, 1.4766e-01, 3.3021e-01, 7.0962e-02,\n",
      "         2.0688e-01, 9.4497e-02, 5.2806e-02, 4.0206e-03],\n",
      "        [1.1541e-03, 1.5318e-02, 1.0965e-02, 9.3178e-02, 2.2368e-01, 5.8274e-02,\n",
      "         4.0456e-01, 1.5488e-01, 3.4341e-02, 3.6530e-03],\n",
      "        [9.5185e-05, 3.5695e-03, 3.2100e-03, 3.5195e-02, 1.2728e-01, 9.8280e-02,\n",
      "         4.4674e-01, 1.4859e-01, 1.2503e-01, 1.2022e-02],\n",
      "        [3.6388e-05, 3.1202e-03, 1.0421e-02, 6.7208e-02, 8.2186e-02, 1.0661e-01,\n",
      "         3.3363e-01, 7.0373e-02, 2.9923e-01, 2.7181e-02]])\n",
      "\n",
      "Epoch: 6.96, Train Loss: 2.42, Val Loss: 4.11, Train BLEU: 18.50, Val BLEU: 10.69, Minutes Elapsed: 363.25\n",
      "Sampling from training predictions...\n",
      "Source: video này được quay từ tuần trước . <EOS> <PAD>\n",
      "Reference: this short video is from last week . <EOS>\n",
      "Model: <SOS> this video is from from through week . <EOS>\n",
      "Attention Weights: tensor([[0.9883, 0.0116, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.9466, 0.0336, 0.0193, 0.0004, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0877, 0.0815, 0.7606, 0.0615, 0.0035, 0.0040, 0.0010, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0018, 0.0036, 0.5817, 0.3691, 0.0156, 0.0219, 0.0062, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0004, 0.0008, 0.3369, 0.4755, 0.0351, 0.1059, 0.0445, 0.0007, 0.0001,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0000, 0.0059, 0.0507, 0.0537, 0.6314, 0.2547, 0.0027, 0.0008,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0000, 0.0003, 0.0044, 0.0355, 0.5610, 0.3939, 0.0040, 0.0008,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0005, 0.0081, 0.0458, 0.4039, 0.4158, 0.1008, 0.0250,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0005, 0.0018, 0.0473, 0.2883, 0.2349, 0.4272,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: có một câu_chuyện rất vui mà tôi đọc được trên\n",
      "Reference: there &apos;s a lovely story that i read in\n",
      "Model: <SOS> there &apos;s a story story that i &apos;ve to\n",
      "Attention Weights: tensor([[9.7602e-01, 2.3715e-02, 8.7081e-05, 1.7911e-04, 9.4197e-07, 1.8256e-10,\n",
      "         2.8016e-11, 1.3047e-10, 2.5257e-11, 1.1468e-11],\n",
      "        [3.9544e-01, 4.0580e-01, 1.2537e-01, 6.4908e-02, 8.1812e-03, 1.8825e-04,\n",
      "         1.8723e-05, 6.2157e-05, 1.7779e-05, 1.0209e-05],\n",
      "        [1.5463e-01, 3.0419e-01, 2.3770e-01, 1.9799e-01, 9.8896e-02, 2.6025e-03,\n",
      "         5.8826e-04, 2.4889e-03, 6.9804e-04, 2.2115e-04],\n",
      "        [3.0106e-03, 7.6306e-03, 5.8293e-01, 1.6220e-01, 2.3213e-01, 1.0550e-02,\n",
      "         5.8474e-04, 5.5731e-04, 2.6722e-04, 1.3906e-04],\n",
      "        [1.6137e-03, 2.2232e-03, 4.3903e-01, 2.7016e-01, 2.4683e-01, 3.7158e-02,\n",
      "         8.8825e-04, 1.4061e-03, 4.5365e-04, 2.3224e-04],\n",
      "        [1.6926e-03, 5.8746e-04, 2.8360e-01, 1.0963e-01, 2.3517e-01, 3.3082e-01,\n",
      "         1.2413e-02, 2.1286e-02, 2.7341e-03, 2.0601e-03],\n",
      "        [1.8366e-04, 5.9221e-05, 7.3027e-03, 1.2379e-02, 9.1280e-02, 4.5304e-01,\n",
      "         1.3567e-01, 2.6968e-01, 1.9589e-02, 1.0817e-02],\n",
      "        [1.1599e-04, 2.2395e-04, 2.0027e-03, 2.7830e-03, 1.8434e-02, 2.3402e-01,\n",
      "         7.5170e-02, 5.7438e-01, 8.0469e-02, 1.2404e-02],\n",
      "        [1.1670e-04, 4.7209e-04, 3.5173e-03, 1.5068e-03, 2.5098e-03, 1.1367e-02,\n",
      "         2.3882e-02, 4.5420e-01, 3.7284e-01, 1.2959e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7.00, Train Loss: 2.25, Val Loss: 4.10, Train BLEU: 21.53, Val BLEU: 10.60, Minutes Elapsed: 365.39\n",
      "Sampling from training predictions...\n",
      "Source: và cũng loại công_nghệ đó - - được gọi_là mã_vạch\n",
      "Reference: and the same kind of technology -- it &apos;s\n",
      "Model: <SOS> and the same of of technology -- it &apos;s\n",
      "Attention Weights: tensor([[2.5541e-04, 9.9938e-01, 3.5389e-04, 6.3684e-06, 2.2837e-07, 1.6615e-10,\n",
      "         4.8111e-11, 6.4384e-11, 3.9239e-11, 5.2802e-12],\n",
      "        [9.7331e-05, 9.9796e-01, 1.2798e-03, 6.5764e-04, 2.8327e-06, 1.5086e-07,\n",
      "         5.3218e-08, 7.9364e-08, 2.0914e-08, 8.6861e-09],\n",
      "        [1.2930e-04, 1.0262e-01, 3.2422e-01, 5.6839e-01, 2.7552e-03, 9.1263e-04,\n",
      "         2.6266e-04, 5.5630e-04, 1.1500e-04, 3.7885e-05],\n",
      "        [1.2892e-03, 5.2179e-02, 1.8928e-01, 6.9874e-01, 4.1276e-02, 1.0390e-02,\n",
      "         3.3925e-03, 2.3042e-03, 7.9446e-04, 3.6070e-04],\n",
      "        [3.4870e-05, 6.4352e-03, 2.9215e-02, 7.2316e-01, 1.8855e-01, 3.3833e-02,\n",
      "         6.7144e-03, 1.0613e-02, 9.8823e-04, 4.5778e-04],\n",
      "        [1.1808e-06, 2.8989e-04, 4.1220e-03, 3.9840e-01, 1.4241e-01, 1.7517e-01,\n",
      "         7.0405e-02, 1.7941e-01, 2.2680e-02, 7.1040e-03],\n",
      "        [3.4917e-07, 6.1467e-05, 5.7904e-03, 9.5017e-02, 3.0251e-02, 1.1367e-01,\n",
      "         1.9335e-01, 3.8050e-01, 1.2156e-01, 5.9812e-02],\n",
      "        [1.5907e-06, 1.1439e-04, 5.9589e-04, 3.8035e-03, 7.9702e-03, 4.9327e-02,\n",
      "         1.4771e-01, 5.7536e-01, 1.4860e-01, 6.6522e-02],\n",
      "        [3.5799e-07, 1.6375e-05, 1.0368e-03, 3.9711e-03, 8.6386e-04, 1.9732e-02,\n",
      "         9.7967e-02, 4.4044e-01, 2.6789e-01, 1.6807e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: sáng nay , người tổ_chức buổi họp này đặt một\n",
      "Reference: this morning , the gentleman who opened this conference\n",
      "Model: <SOS> now , , the young boy a a a\n",
      "Attention Weights: tensor([[9.9944e-01, 5.4537e-04, 1.8643e-05, 3.8524e-07, 1.6151e-08, 1.2929e-09,\n",
      "         4.3022e-10, 3.5927e-11, 1.8709e-11, 1.0848e-12],\n",
      "        [4.9887e-01, 3.3310e-01, 1.4542e-01, 1.2923e-02, 7.7906e-03, 1.4500e-03,\n",
      "         3.9450e-04, 2.2070e-05, 3.0697e-05, 5.7340e-06],\n",
      "        [3.4198e-02, 4.7420e-02, 3.4846e-01, 3.5477e-01, 1.2170e-01, 7.1879e-02,\n",
      "         1.7099e-02, 1.4806e-03, 2.5653e-03, 4.3348e-04],\n",
      "        [3.7117e-03, 7.6436e-03, 8.5215e-02, 4.5224e-01, 1.7386e-01, 1.1247e-01,\n",
      "         1.2454e-01, 1.7021e-02, 1.8172e-02, 5.1208e-03],\n",
      "        [1.0365e-04, 2.2516e-04, 3.3838e-03, 6.6093e-02, 1.7292e-01, 1.7815e-01,\n",
      "         4.9581e-01, 3.1846e-02, 4.0027e-02, 1.1433e-02],\n",
      "        [8.8429e-04, 4.2573e-03, 5.8633e-03, 4.6250e-03, 1.5071e-01, 1.9009e-01,\n",
      "         1.0393e-01, 1.3480e-01, 3.2644e-01, 7.8404e-02],\n",
      "        [1.5281e-03, 3.0010e-03, 1.1347e-02, 5.1566e-03, 4.2046e-02, 1.4685e-01,\n",
      "         5.5778e-02, 1.2049e-01, 5.2585e-01, 8.7949e-02],\n",
      "        [7.6533e-07, 2.6075e-06, 2.9981e-05, 1.4579e-04, 4.2399e-03, 1.0380e-01,\n",
      "         3.8042e-01, 4.1930e-02, 2.3290e-01, 2.3653e-01],\n",
      "        [2.4029e-06, 2.6742e-06, 2.7745e-05, 8.2024e-05, 2.6207e-03, 6.1116e-02,\n",
      "         3.9943e-01, 4.7447e-02, 2.6889e-01, 2.2037e-01]])\n",
      "\n",
      "Epoch: 7.05, Train Loss: 1.99, Val Loss: 4.15, Train BLEU: 24.35, Val BLEU: 10.49, Minutes Elapsed: 367.95\n",
      "Sampling from training predictions...\n",
      "Source: một_số người chưa bao_giờ trải_qua cảm_giác trầm_cảm hay chưa thực_sự\n",
      "Reference: now , for someone who has never experienced depression\n",
      "Model: <SOS> people people people people people never experienced experienced the\n",
      "Attention Weights: tensor([[9.9670e-01, 3.1182e-03, 1.6897e-04, 1.3533e-05, 1.3066e-07, 5.3387e-08,\n",
      "         8.9768e-09, 2.6011e-09, 8.0389e-10, 5.9980e-10],\n",
      "        [3.9589e-02, 9.8592e-02, 3.5714e-01, 4.7805e-01, 2.3836e-02, 2.1194e-03,\n",
      "         5.9100e-04, 2.7781e-05, 3.4513e-05, 2.4989e-05],\n",
      "        [1.1627e-02, 2.6717e-02, 1.6816e-01, 5.4772e-01, 2.1177e-01, 2.5294e-02,\n",
      "         7.7909e-03, 3.6545e-04, 3.9107e-04, 1.6492e-04],\n",
      "        [7.5584e-03, 7.9015e-02, 1.5277e-01, 2.8413e-01, 4.0633e-01, 4.7057e-02,\n",
      "         2.1404e-02, 7.8513e-04, 6.9282e-04, 2.5961e-04],\n",
      "        [8.9812e-03, 7.2898e-02, 2.0508e-01, 2.5369e-01, 3.8815e-01, 4.7670e-02,\n",
      "         2.1491e-02, 9.0982e-04, 8.6104e-04, 2.7030e-04],\n",
      "        [1.2156e-03, 6.9487e-02, 2.8243e-01, 3.4924e-01, 2.6925e-01, 2.1689e-02,\n",
      "         5.8774e-03, 3.3630e-04, 4.0077e-04, 7.0791e-05],\n",
      "        [7.4514e-05, 9.1871e-04, 1.3745e-02, 9.6873e-02, 6.1430e-01, 1.6491e-01,\n",
      "         1.0179e-01, 3.3927e-03, 3.0058e-03, 1.0006e-03],\n",
      "        [1.7806e-05, 2.0612e-05, 8.1419e-04, 6.3255e-03, 2.9399e-01, 3.2206e-01,\n",
      "         3.4221e-01, 2.4458e-02, 7.4210e-03, 2.6751e-03],\n",
      "        [7.9322e-05, 2.0762e-05, 7.6464e-05, 3.5322e-03, 1.2100e-01, 5.6043e-01,\n",
      "         2.8216e-01, 1.8548e-02, 8.5626e-03, 5.5913e-03]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: ông ấy không bắt_đầu một_mình . <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: he wasn &apos;t alone when he started . <EOS>\n",
      "Model: <SOS> he didn &apos;t to to . . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.4777, 0.4905, 0.0316, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0007, 0.0089, 0.9551, 0.0348, 0.0004, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0011, 0.0162, 0.5928, 0.3679, 0.0215, 0.0003, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0015, 0.0304, 0.8327, 0.1334, 0.0017, 0.0002, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0006, 0.0064, 0.7112, 0.2167, 0.0573, 0.0078, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0007, 0.0062, 0.2717, 0.4484, 0.1658, 0.1071, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0003, 0.0190, 0.0972, 0.0891, 0.1541, 0.6401, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0017, 0.0110, 0.5197, 0.2873, 0.0449, 0.0188, 0.1166, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0003, 0.0132, 0.1286, 0.1558, 0.1118, 0.5899, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 7.10, Train Loss: 2.07, Val Loss: 4.13, Train BLEU: 22.99, Val BLEU: 11.59, Minutes Elapsed: 370.50\n",
      "Sampling from training predictions...\n",
      "Source: chúng_ta đang nhìn_thấy đây là 160 - 175 độ ,\n",
      "Reference: but what you &apos;re seeing here is 160 to\n",
      "Model: <SOS> what &apos;re we &apos;re seeing here is 160 you\n",
      "Attention Weights: tensor([[1.8723e-02, 9.4794e-01, 3.2630e-02, 7.0336e-04, 5.8070e-06, 7.5227e-07,\n",
      "         1.1702e-07, 1.6940e-08, 9.8021e-09, 4.0200e-10],\n",
      "        [7.6432e-03, 9.8371e-01, 8.6237e-03, 1.6557e-05, 7.7705e-07, 2.0839e-06,\n",
      "         1.5573e-07, 7.1719e-08, 8.4569e-08, 7.8609e-09],\n",
      "        [2.5450e-02, 4.7760e-01, 4.8372e-01, 1.1468e-02, 1.1715e-03, 3.6206e-04,\n",
      "         1.0745e-04, 7.6633e-05, 3.3135e-05, 2.8442e-06],\n",
      "        [3.3415e-02, 7.2870e-01, 2.3135e-01, 5.9663e-03, 3.2900e-04, 1.2901e-04,\n",
      "         5.3143e-05, 3.4496e-05, 2.2924e-05, 2.1309e-06],\n",
      "        [1.1723e-02, 6.7496e-01, 3.0014e-01, 1.2136e-02, 6.9482e-04, 1.7800e-04,\n",
      "         8.2226e-05, 4.9347e-05, 3.3809e-05, 3.1600e-06],\n",
      "        [1.4042e-04, 3.4060e-03, 4.3881e-01, 4.9043e-01, 5.3118e-02, 2.6256e-03,\n",
      "         3.3238e-03, 3.7641e-03, 4.2415e-03, 1.4150e-04],\n",
      "        [1.5666e-03, 6.0549e-03, 2.2186e-01, 4.1488e-01, 2.5924e-01, 1.3623e-02,\n",
      "         3.0671e-02, 2.4544e-02, 2.5784e-02, 1.7759e-03],\n",
      "        [1.6925e-04, 8.5667e-03, 1.6931e-02, 5.1726e-02, 3.2782e-01, 9.6034e-02,\n",
      "         1.7689e-01, 1.3663e-01, 1.7072e-01, 1.4506e-02],\n",
      "        [1.0362e-05, 3.5428e-04, 9.0024e-04, 2.6390e-03, 5.4064e-02, 1.7854e-02,\n",
      "         1.1562e-01, 1.4716e-01, 5.7959e-01, 8.1806e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: ngày khác chúng_tôi thức_dậy với tin_tức về vụ tàn_sát đại_sứ\n",
      "Reference: on another day we wake up to the news\n",
      "Model: <SOS> we we day we we to to the news\n",
      "Attention Weights: tensor([[9.9339e-01, 6.6138e-03, 4.1706e-07, 1.4265e-07, 3.7425e-10, 3.1923e-11,\n",
      "         1.2984e-12, 1.7932e-13, 1.3198e-13, 4.9364e-13],\n",
      "        [1.0792e-01, 8.8805e-01, 2.1933e-03, 1.8274e-03, 6.4271e-06, 1.9489e-06,\n",
      "         7.2258e-08, 6.5659e-08, 3.7430e-08, 2.8797e-08],\n",
      "        [1.5867e-01, 3.6115e-01, 2.1928e-02, 4.2236e-01, 3.3878e-02, 1.7692e-03,\n",
      "         1.8674e-04, 3.6802e-05, 8.2123e-06, 9.5070e-06],\n",
      "        [4.5289e-01, 1.8957e-01, 7.7795e-02, 2.4639e-01, 3.2280e-02, 8.0316e-04,\n",
      "         2.1073e-04, 5.5412e-05, 8.1248e-06, 4.5605e-06],\n",
      "        [7.5971e-03, 3.8937e-02, 1.0240e-01, 7.8940e-01, 5.8982e-02, 1.6979e-03,\n",
      "         4.2769e-04, 4.2640e-04, 9.7563e-05, 3.8305e-05],\n",
      "        [1.2463e-03, 1.1967e-02, 8.1344e-03, 7.9906e-01, 1.7171e-01, 6.7149e-03,\n",
      "         8.7552e-04, 1.9254e-04, 7.8008e-05, 2.4374e-05],\n",
      "        [2.5957e-04, 4.9869e-04, 3.8731e-04, 9.4577e-03, 4.3174e-01, 4.7754e-01,\n",
      "         6.4181e-02, 1.3342e-02, 1.6490e-03, 9.4270e-04],\n",
      "        [3.9961e-05, 5.7466e-05, 1.3546e-04, 2.2380e-03, 1.4963e-01, 4.7576e-01,\n",
      "         3.0249e-01, 6.4016e-02, 3.2392e-03, 2.3904e-03],\n",
      "        [1.4472e-04, 6.6078e-05, 1.0615e-04, 3.8715e-04, 2.4091e-02, 2.3642e-01,\n",
      "         3.1920e-01, 3.4875e-01, 3.2644e-02, 3.8184e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7.14, Train Loss: 2.11, Val Loss: 4.13, Train BLEU: 22.94, Val BLEU: 11.58, Minutes Elapsed: 373.05\n",
      "Sampling from training predictions...\n",
      "Source: đến cuối năm nay , chúng_ta sẽ có_thể giải trình_tự\n",
      "Reference: by the end of this year , we &apos;ll\n",
      "Model: <SOS> by the end of the year year we &apos;ll\n",
      "Attention Weights: tensor([[9.8709e-01, 1.2698e-02, 2.1355e-04, 8.1175e-07, 4.9371e-09, 1.5677e-10,\n",
      "         5.6616e-11, 1.0225e-11, 3.4565e-12, 2.0458e-12],\n",
      "        [2.1419e-01, 7.0088e-01, 7.9627e-02, 4.0932e-03, 1.1710e-03, 2.5499e-05,\n",
      "         1.4139e-05, 3.0989e-06, 6.5636e-07, 7.2708e-07],\n",
      "        [8.3408e-02, 6.4656e-01, 2.3394e-01, 1.8731e-02, 1.2293e-02, 3.2258e-03,\n",
      "         1.2978e-03, 3.1746e-04, 1.2870e-04, 1.0089e-04],\n",
      "        [1.8398e-01, 4.1979e-01, 2.8990e-01, 2.5300e-02, 6.7608e-02, 8.9137e-03,\n",
      "         2.9367e-03, 1.0099e-03, 3.2971e-04, 2.4190e-04],\n",
      "        [6.0681e-02, 5.2389e-01, 3.4318e-01, 2.3567e-02, 4.0313e-02, 3.8768e-03,\n",
      "         3.8456e-03, 4.6415e-04, 1.1120e-04, 7.5633e-05],\n",
      "        [2.1632e-03, 1.8378e-01, 5.2460e-01, 3.3602e-02, 1.2385e-01, 7.3829e-02,\n",
      "         4.1288e-02, 7.7410e-03, 5.5789e-03, 3.5693e-03],\n",
      "        [7.4669e-03, 1.1545e-01, 2.7896e-01, 7.5884e-02, 3.4129e-01, 1.1912e-01,\n",
      "         4.9341e-02, 9.1913e-03, 2.6715e-03, 6.2392e-04],\n",
      "        [2.4327e-04, 7.2567e-03, 7.1661e-02, 1.9286e-02, 1.6467e-01, 3.1388e-01,\n",
      "         3.9436e-01, 2.5129e-02, 2.7617e-03, 7.6009e-04],\n",
      "        [5.9167e-05, 5.0299e-04, 2.9642e-03, 2.1838e-03, 6.5108e-02, 1.8592e-01,\n",
      "         7.0669e-01, 2.3095e-02, 1.1933e-02, 1.5390e-03]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: đây là một trong sáu con sư_tử đã bị giết\n",
      "Reference: it &apos;s one of the six lions which were\n",
      "Model: <SOS> this &apos;s one of the kids that killed killed\n",
      "Attention Weights: tensor([[6.6801e-01, 3.3146e-01, 5.2231e-04, 2.0532e-06, 8.6158e-08, 1.7497e-09,\n",
      "         8.8616e-10, 1.9458e-11, 5.4056e-13, 5.2286e-14],\n",
      "        [1.8647e-02, 3.9463e-01, 5.7301e-01, 1.2411e-02, 1.0090e-03, 2.3271e-04,\n",
      "         1.9715e-05, 2.2375e-05, 1.2591e-05, 3.2562e-06],\n",
      "        [1.3811e-02, 2.1162e-01, 3.5528e-01, 3.7505e-01, 3.4721e-02, 7.1528e-03,\n",
      "         5.3492e-04, 1.0595e-03, 6.1578e-04, 1.5721e-04],\n",
      "        [2.0247e-04, 6.1907e-03, 2.0162e-02, 8.4311e-01, 9.3919e-02, 2.4773e-02,\n",
      "         1.9977e-03, 5.5953e-03, 3.0294e-03, 1.0191e-03],\n",
      "        [5.0197e-05, 1.4987e-03, 7.4042e-04, 2.8926e-01, 4.6048e-01, 9.8364e-02,\n",
      "         1.9178e-02, 8.5925e-02, 3.5443e-02, 9.0549e-03],\n",
      "        [3.7638e-05, 1.1917e-03, 4.4132e-04, 3.0962e-02, 1.0825e-01, 1.7763e-01,\n",
      "         1.9243e-02, 3.6444e-01, 2.4230e-01, 5.5503e-02],\n",
      "        [8.4373e-05, 4.3713e-03, 1.1126e-04, 4.0651e-03, 4.1588e-03, 1.8560e-02,\n",
      "         1.6590e-02, 3.6101e-01, 4.3353e-01, 1.5752e-01],\n",
      "        [1.1520e-05, 3.0775e-04, 1.3713e-05, 1.5520e-03, 7.9990e-04, 6.0305e-03,\n",
      "         1.0031e-02, 2.0701e-01, 5.4190e-01, 2.3234e-01],\n",
      "        [7.6017e-06, 1.4467e-04, 1.4055e-05, 4.4700e-04, 4.9458e-04, 4.1975e-03,\n",
      "         7.2219e-03, 2.2936e-01, 4.5003e-01, 3.0808e-01]])\n",
      "\n",
      "Epoch: 7.19, Train Loss: 2.19, Val Loss: 4.14, Train BLEU: 21.64, Val BLEU: 11.28, Minutes Elapsed: 375.62\n",
      "Sampling from training predictions...\n",
      "Source: và nói về kết_nối cơ_thể , các bạn biết tôi\n",
      "Reference: and speaking of physical connection , you guys know\n",
      "Model: <SOS> and speaking about the , , you know what\n",
      "Attention Weights: tensor([[4.9999e-03, 9.9197e-01, 2.4847e-03, 5.4392e-04, 2.1613e-06, 3.9661e-09,\n",
      "         8.2433e-10, 6.0411e-09, 6.6412e-10, 5.5707e-11],\n",
      "        [6.7452e-02, 8.0146e-01, 1.0444e-01, 2.6427e-02, 2.0993e-04, 2.1731e-06,\n",
      "         2.8516e-06, 3.1689e-06, 2.5076e-07, 4.4150e-08],\n",
      "        [3.9493e-04, 1.2250e-01, 8.3689e-01, 3.8529e-02, 1.3882e-03, 9.6389e-05,\n",
      "         5.5367e-05, 5.6681e-05, 7.3081e-05, 1.7351e-05],\n",
      "        [1.9911e-05, 2.2255e-02, 2.4508e-01, 6.6069e-01, 5.6195e-02, 8.3006e-03,\n",
      "         1.2945e-03, 1.8218e-03, 3.6381e-03, 7.0389e-04],\n",
      "        [6.2700e-07, 9.1371e-05, 2.7332e-03, 9.1742e-01, 4.6102e-02, 1.6100e-02,\n",
      "         7.2107e-03, 3.0426e-03, 5.8137e-03, 1.4854e-03],\n",
      "        [6.2628e-06, 6.5105e-04, 1.7419e-03, 5.6222e-02, 6.0567e-02, 3.9451e-01,\n",
      "         2.5415e-01, 1.8298e-01, 4.5648e-02, 3.5162e-03],\n",
      "        [8.6731e-08, 5.9112e-05, 1.3231e-04, 2.6020e-03, 3.9629e-03, 6.7832e-02,\n",
      "         4.4166e-01, 3.0723e-01, 1.6433e-01, 1.2196e-02],\n",
      "        [1.5620e-06, 9.1423e-04, 6.1516e-04, 6.3669e-03, 7.6768e-03, 1.6942e-02,\n",
      "         4.7673e-02, 2.0203e-01, 7.0104e-01, 1.6747e-02],\n",
      "        [1.1951e-07, 4.9368e-05, 4.0762e-04, 3.3532e-04, 3.4572e-04, 1.9114e-03,\n",
      "         6.6214e-03, 5.8921e-02, 9.0357e-01, 2.7838e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: vì_thế chúng_ta được dạy rằng \" sự khoan_dung của ta\n",
      "Reference: thus we are told that &quot; my mercy <UNK>\n",
      "Model: <SOS> so we we taught told &quot; our our .\n",
      "Attention Weights: tensor([[9.9212e-01, 5.4619e-05, 7.6704e-03, 1.4919e-04, 8.1017e-06, 5.4216e-08,\n",
      "         1.7109e-08, 3.1835e-09, 6.8957e-09, 1.2631e-10],\n",
      "        [8.8790e-03, 6.8006e-01, 3.1059e-01, 4.5344e-04, 6.4398e-06, 2.7145e-06,\n",
      "         3.5483e-06, 2.7541e-06, 1.7397e-07, 3.2165e-08],\n",
      "        [1.9631e-03, 1.9913e-02, 7.9938e-01, 1.7040e-01, 7.2823e-03, 7.3237e-05,\n",
      "         6.5280e-04, 3.1967e-04, 5.2538e-06, 4.6447e-06],\n",
      "        [9.0377e-05, 2.6392e-03, 6.6648e-01, 3.0524e-01, 1.8785e-02, 7.3101e-04,\n",
      "         2.1675e-03, 3.8287e-03, 3.1394e-05, 1.4203e-05],\n",
      "        [2.9127e-05, 2.5211e-04, 5.7552e-03, 4.2457e-01, 3.7285e-01, 1.3250e-01,\n",
      "         3.6561e-02, 2.6954e-02, 2.7802e-04, 2.4995e-04],\n",
      "        [3.7007e-05, 1.2967e-04, 3.2855e-04, 1.1235e-02, 7.6464e-02, 3.3225e-01,\n",
      "         4.6255e-01, 1.1058e-01, 3.2557e-03, 3.1601e-03],\n",
      "        [6.1748e-07, 9.6935e-07, 1.5777e-05, 1.1042e-04, 2.4350e-03, 9.2021e-02,\n",
      "         7.9695e-01, 9.4168e-02, 8.8416e-03, 5.4572e-03],\n",
      "        [3.6202e-06, 3.6432e-06, 5.1111e-06, 2.1268e-05, 2.5030e-04, 3.0262e-02,\n",
      "         5.4170e-01, 3.4776e-01, 2.6022e-02, 5.3972e-02],\n",
      "        [6.7294e-05, 3.0958e-05, 3.7218e-05, 1.5100e-04, 8.1466e-04, 6.5603e-03,\n",
      "         8.8818e-02, 6.0355e-01, 1.1012e-01, 1.8986e-01]])\n",
      "\n",
      "Epoch: 7.24, Train Loss: 2.23, Val Loss: 4.14, Train BLEU: 19.94, Val BLEU: 10.57, Minutes Elapsed: 378.17\n",
      "Sampling from training predictions...\n",
      "Source: chuyện gì sẽ xảy ra trong 1 tình_huống khi bạn\n",
      "Reference: what happens in a situation when you create something\n",
      "Model: <SOS> what happens happen in situation when you put a\n",
      "Attention Weights: tensor([[1.6987e-03, 1.6114e-02, 9.7282e-01, 9.1646e-03, 2.0293e-04, 2.5860e-06,\n",
      "         4.6085e-08, 1.0029e-08, 3.4959e-10, 1.1080e-11],\n",
      "        [2.2378e-03, 7.1997e-04, 8.8981e-01, 8.1426e-02, 2.1003e-02, 3.8980e-03,\n",
      "         4.2754e-04, 4.5747e-04, 1.5220e-05, 2.7302e-06],\n",
      "        [7.9974e-03, 2.0028e-03, 1.7789e-01, 2.5576e-01, 3.2470e-01, 2.0529e-01,\n",
      "         1.2780e-02, 1.1823e-02, 1.5319e-03, 2.3590e-04],\n",
      "        [3.4917e-04, 8.3330e-06, 3.0305e-03, 6.4288e-02, 1.1329e-01, 4.2076e-01,\n",
      "         1.9260e-01, 1.9228e-01, 1.1963e-02, 1.4314e-03],\n",
      "        [2.8195e-05, 2.8238e-07, 1.3472e-04, 4.4449e-03, 6.5205e-03, 3.5415e-02,\n",
      "         1.6703e-01, 7.6114e-01, 1.8954e-02, 6.3385e-03],\n",
      "        [2.6197e-07, 6.5534e-07, 1.8613e-04, 6.0772e-04, 2.9111e-03, 4.2234e-03,\n",
      "         7.1146e-02, 6.9018e-01, 2.1931e-01, 1.1440e-02],\n",
      "        [3.9284e-07, 2.8755e-07, 1.8437e-04, 3.4068e-04, 1.0291e-03, 1.0031e-03,\n",
      "         2.0604e-02, 4.9501e-01, 4.4972e-01, 3.2103e-02],\n",
      "        [1.3906e-05, 3.5743e-06, 1.0370e-03, 1.2946e-03, 6.7265e-04, 3.1225e-03,\n",
      "         3.7859e-02, 2.5045e-01, 1.5214e-01, 5.5341e-01],\n",
      "        [3.4331e-05, 1.1124e-05, 1.8822e-03, 7.6337e-03, 2.8896e-02, 7.1877e-02,\n",
      "         8.1614e-02, 2.3127e-01, 3.7436e-02, 5.3935e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi cũng đã từng tự_hỏi , thực_tế nó có hoạt_động\n",
      "Reference: and i also ask myself , does it really\n",
      "Model: <SOS> i also also to , , what it it\n",
      "Attention Weights: tensor([[2.8504e-03, 9.8191e-01, 1.1035e-02, 4.1212e-03, 8.3367e-05, 1.5065e-07,\n",
      "         4.4170e-07, 8.1545e-09, 5.8069e-09, 9.2988e-10],\n",
      "        [4.8881e-03, 8.1347e-01, 3.2123e-02, 1.4752e-01, 1.9062e-03, 1.1473e-05,\n",
      "         6.8471e-05, 1.0442e-06, 2.2514e-06, 6.8073e-07],\n",
      "        [6.3939e-04, 6.7861e-02, 1.0912e-01, 7.0574e-01, 1.1592e-01, 4.5638e-04,\n",
      "         1.6314e-04, 2.8458e-05, 4.4780e-05, 3.2857e-05],\n",
      "        [1.8583e-03, 1.2575e-01, 1.1115e-01, 6.1915e-01, 1.4111e-01, 5.8044e-04,\n",
      "         2.8426e-04, 2.5350e-05, 4.9655e-05, 3.4331e-05],\n",
      "        [1.1296e-04, 2.0984e-03, 2.1528e-02, 1.7373e-01, 7.4517e-01, 3.3368e-02,\n",
      "         2.2244e-02, 3.9532e-04, 5.2815e-04, 8.2816e-04],\n",
      "        [1.8082e-04, 1.7363e-03, 2.4667e-02, 1.5900e-01, 5.2572e-01, 6.5215e-02,\n",
      "         2.0413e-01, 1.1573e-02, 4.2722e-03, 3.4999e-03],\n",
      "        [6.6188e-06, 1.1943e-04, 4.1542e-04, 9.4575e-03, 4.1275e-02, 1.1439e-01,\n",
      "         7.4749e-01, 4.7517e-02, 2.9601e-02, 9.7262e-03],\n",
      "        [3.5490e-06, 2.4080e-05, 7.2194e-05, 4.4576e-03, 1.0588e-02, 7.5986e-02,\n",
      "         7.9930e-01, 6.0177e-02, 3.8991e-02, 1.0400e-02],\n",
      "        [1.4124e-06, 1.0345e-04, 3.1842e-04, 1.8194e-03, 2.5421e-03, 9.4074e-03,\n",
      "         3.8391e-01, 9.9734e-02, 3.0109e-01, 2.0107e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7.29, Train Loss: 2.29, Val Loss: 4.16, Train BLEU: 20.43, Val BLEU: 11.08, Minutes Elapsed: 380.71\n",
      "Sampling from training predictions...\n",
      "Source: bất_kể ở các hình_vẽ trong hang_động hay các cách dùng\n",
      "Reference: whether in cave paintings or the latest uses of\n",
      "Model: <SOS> because in the in the the in , ,\n",
      "Attention Weights: tensor([[9.9078e-01, 9.0406e-03, 2.5260e-05, 1.5334e-04, 7.7625e-07, 5.9662e-08,\n",
      "         3.1975e-09, 9.5160e-11, 1.1163e-10, 5.4263e-11],\n",
      "        [2.7277e-01, 4.5470e-01, 5.6701e-02, 1.6526e-01, 3.2517e-02, 1.6683e-02,\n",
      "         1.2352e-03, 7.4759e-05, 3.9677e-05, 2.3399e-05],\n",
      "        [1.7563e-01, 1.1552e-01, 9.8410e-02, 3.1927e-01, 1.8841e-01, 5.9024e-02,\n",
      "         4.0488e-02, 1.5284e-03, 1.0619e-03, 6.5560e-04],\n",
      "        [1.6404e-02, 3.7542e-02, 1.8753e-02, 1.4574e-01, 4.6105e-01, 2.2346e-01,\n",
      "         7.8822e-02, 7.4789e-03, 6.0853e-03, 4.6684e-03],\n",
      "        [2.9142e-06, 1.2171e-04, 9.4957e-04, 1.8719e-02, 9.4808e-02, 4.0336e-01,\n",
      "         3.4883e-01, 6.3080e-02, 3.9320e-02, 3.0816e-02],\n",
      "        [8.3257e-07, 9.0995e-06, 7.3620e-05, 2.9622e-03, 2.8833e-03, 3.4878e-02,\n",
      "         7.7446e-02, 5.4971e-01, 1.8390e-01, 1.4813e-01],\n",
      "        [6.3099e-06, 1.5258e-05, 3.1740e-05, 3.4386e-04, 8.6772e-04, 2.4223e-03,\n",
      "         2.2720e-02, 3.8780e-01, 2.1080e-01, 3.7499e-01],\n",
      "        [5.0579e-07, 2.2028e-05, 5.0056e-05, 6.9211e-04, 2.8364e-03, 2.1512e-02,\n",
      "         4.9714e-02, 8.7877e-02, 2.7560e-01, 5.6170e-01],\n",
      "        [1.2475e-06, 3.6075e-05, 4.7085e-05, 5.3453e-04, 2.0640e-03, 1.5207e-02,\n",
      "         3.8631e-02, 8.7756e-02, 4.4982e-01, 4.0590e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: đó là thời_điểm tuyệt_vọng nhất trong cuộc_đời tôi . <EOS>\n",
      "Reference: this was one of the lowest points in my\n",
      "Model: <SOS> it was the most in life life life life\n",
      "Attention Weights: tensor([[9.1596e-03, 9.8562e-01, 5.2199e-03, 5.0866e-06, 3.6644e-08, 9.8341e-10,\n",
      "         5.7904e-11, 1.1800e-12, 8.3083e-13, 9.2578e-14],\n",
      "        [1.6772e-02, 7.5890e-01, 2.0962e-01, 1.2760e-02, 1.8060e-03, 1.0043e-04,\n",
      "         3.9688e-05, 6.0040e-07, 5.0009e-07, 1.1664e-07],\n",
      "        [1.1474e-02, 1.6699e-01, 6.6441e-01, 1.2958e-01, 2.5693e-02, 1.2246e-03,\n",
      "         5.7856e-04, 3.5373e-05, 1.7648e-05, 3.5003e-06],\n",
      "        [4.1453e-05, 2.6939e-03, 4.0758e-01, 4.4658e-01, 1.2632e-01, 1.2446e-02,\n",
      "         4.2505e-03, 6.2012e-05, 1.1345e-05, 5.2310e-06],\n",
      "        [5.1157e-05, 1.2313e-03, 8.5811e-01, 1.3428e-01, 2.2803e-03, 2.9694e-03,\n",
      "         1.0340e-03, 2.1206e-05, 1.2298e-05, 6.4272e-06],\n",
      "        [3.2353e-06, 6.9685e-05, 2.9173e-02, 4.1451e-02, 4.2398e-02, 3.6450e-01,\n",
      "         5.0258e-01, 1.1344e-02, 6.2507e-03, 2.2288e-03],\n",
      "        [4.4313e-05, 1.5945e-03, 3.7540e-02, 1.2235e-02, 1.3268e-02, 5.9815e-01,\n",
      "         2.8570e-01, 2.0106e-02, 2.2837e-02, 8.5221e-03],\n",
      "        [8.2993e-06, 1.4624e-04, 4.6381e-03, 5.6205e-03, 1.2119e-02, 4.3936e-01,\n",
      "         3.8134e-01, 8.5308e-02, 5.4443e-02, 1.7020e-02],\n",
      "        [5.3152e-06, 1.0309e-04, 1.4641e-03, 1.6660e-03, 2.2885e-03, 1.3110e-01,\n",
      "         6.9711e-01, 6.4789e-02, 7.1451e-02, 3.0020e-02]])\n",
      "\n",
      "Epoch: 7.34, Train Loss: 2.29, Val Loss: 4.15, Train BLEU: 19.22, Val BLEU: 10.37, Minutes Elapsed: 383.26\n",
      "Sampling from training predictions...\n",
      "Source: chúng_ta không hoàn_hảo , và vậy_thì cũng bình_thường thôi .\n",
      "Reference: we &apos;re not perfect , and that &apos;s okay\n",
      "Model: <SOS> we &apos;re not perfect , and the &apos;re the\n",
      "Attention Weights: tensor([[7.9945e-01, 2.0001e-01, 5.3675e-04, 6.6769e-06, 5.8023e-08, 1.3049e-08,\n",
      "         3.0484e-09, 3.1838e-10, 7.5875e-11, 1.4153e-11],\n",
      "        [8.2862e-04, 9.9438e-01, 4.7774e-03, 7.3497e-06, 1.2048e-06, 1.0289e-06,\n",
      "         5.5142e-07, 2.6620e-07, 9.4150e-08, 1.4350e-08],\n",
      "        [1.3872e-02, 7.7632e-01, 2.0702e-01, 2.7003e-03, 2.2657e-05, 3.0558e-05,\n",
      "         1.5716e-05, 1.3473e-05, 3.8685e-06, 7.2304e-07],\n",
      "        [1.9610e-03, 4.1834e-02, 9.3714e-01, 1.8616e-02, 1.9706e-04, 1.5349e-04,\n",
      "         4.9191e-05, 3.9985e-05, 5.6977e-06, 5.1966e-07],\n",
      "        [2.5076e-03, 1.8103e-02, 3.0993e-01, 6.4619e-01, 1.8759e-02, 3.8187e-03,\n",
      "         3.1563e-04, 2.2445e-04, 1.0674e-04, 3.7743e-05],\n",
      "        [2.9935e-02, 3.4256e-02, 1.5211e-01, 5.0948e-01, 2.3126e-01, 3.8501e-02,\n",
      "         1.4949e-03, 1.4623e-03, 1.2821e-03, 2.1398e-04],\n",
      "        [6.4241e-03, 6.6800e-03, 7.8254e-03, 5.6223e-02, 3.7943e-01, 5.2067e-01,\n",
      "         1.2511e-02, 6.1011e-03, 3.4449e-03, 6.9171e-04],\n",
      "        [2.9073e-04, 1.7659e-03, 4.9011e-03, 2.6921e-03, 3.6734e-02, 3.8309e-01,\n",
      "         3.3275e-01, 1.7547e-01, 5.9543e-02, 2.7642e-03],\n",
      "        [5.3170e-05, 9.0596e-04, 2.4543e-03, 1.3086e-03, 2.7337e-03, 9.2271e-02,\n",
      "         5.4034e-01, 2.5378e-01, 1.0435e-01, 1.8044e-03]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: bà nghỉ_hưu 2 năm về trước để dùng nhà của\n",
      "Reference: she retired two years ago , only to turn\n",
      "Model: <SOS> she &apos;s two years ago to to my my\n",
      "Attention Weights: tensor([[9.2539e-01, 7.4606e-02, 3.9159e-06, 1.3771e-07, 2.6311e-09, 1.1688e-09,\n",
      "         4.1677e-11, 2.1529e-11, 3.4451e-11, 4.2082e-12],\n",
      "        [1.9741e-02, 9.4615e-01, 2.9971e-02, 3.7220e-03, 8.3069e-05, 2.7037e-04,\n",
      "         3.0371e-05, 2.5972e-05, 7.9314e-06, 7.4419e-07],\n",
      "        [2.8848e-02, 6.3405e-01, 2.8614e-01, 4.6371e-02, 3.1180e-03, 1.1406e-03,\n",
      "         1.4096e-04, 1.2887e-04, 5.5854e-05, 8.7588e-06],\n",
      "        [8.3002e-04, 4.3449e-02, 4.7252e-01, 4.4286e-01, 2.4845e-02, 1.4567e-02,\n",
      "         2.9838e-04, 2.6274e-04, 3.1291e-04, 4.8625e-05],\n",
      "        [1.7642e-04, 1.3887e-03, 3.5195e-02, 4.9127e-01, 2.2625e-01, 2.2065e-01,\n",
      "         1.8241e-02, 4.8558e-03, 1.5608e-03, 4.1481e-04],\n",
      "        [5.3561e-08, 4.1412e-06, 1.0417e-04, 1.4290e-02, 2.8398e-01, 4.5306e-01,\n",
      "         2.2100e-01, 2.0400e-02, 3.8211e-03, 3.3373e-03],\n",
      "        [1.0008e-08, 4.9647e-06, 2.8503e-05, 1.4065e-03, 2.1932e-02, 3.3067e-01,\n",
      "         3.1575e-01, 2.8212e-01, 3.6089e-02, 1.1998e-02],\n",
      "        [2.0445e-07, 1.2290e-04, 3.9130e-05, 4.1462e-04, 3.4742e-03, 5.7184e-02,\n",
      "         5.7750e-02, 5.0215e-01, 3.4687e-01, 3.1999e-02],\n",
      "        [9.9686e-05, 8.4891e-03, 1.9656e-03, 4.4182e-03, 1.6043e-02, 5.0566e-02,\n",
      "         1.4491e-01, 4.9458e-01, 2.1842e-01, 6.0507e-02]])\n",
      "\n",
      "Epoch: 7.38, Train Loss: 2.30, Val Loss: 4.16, Train BLEU: 19.40, Val BLEU: 10.66, Minutes Elapsed: 385.79\n",
      "Sampling from training predictions...\n",
      "Source: chúng_ta không hoàn_hảo , và vậy_thì cũng bình_thường thôi .\n",
      "Reference: we &apos;re not perfect , and that &apos;s okay\n",
      "Model: <SOS> we &apos;re not perfect , and the &apos;re the\n",
      "Attention Weights: tensor([[8.0929e-01, 1.8986e-01, 8.3696e-04, 9.4971e-06, 8.9928e-08, 2.4874e-08,\n",
      "         5.7006e-09, 5.6393e-10, 8.3886e-11, 2.8352e-11],\n",
      "        [1.4618e-03, 9.9336e-01, 5.1689e-03, 8.2829e-06, 1.8274e-06, 1.3540e-06,\n",
      "         6.9507e-07, 3.2704e-07, 8.0034e-08, 2.0803e-08],\n",
      "        [1.4674e-02, 8.7936e-01, 1.0439e-01, 1.4937e-03, 2.2079e-05, 2.6669e-05,\n",
      "         1.8400e-05, 1.2525e-05, 2.1613e-06, 5.6401e-07],\n",
      "        [5.5767e-03, 6.6118e-02, 9.2131e-01, 6.5284e-03, 1.8113e-04, 1.7644e-04,\n",
      "         5.6646e-05, 4.2658e-05, 6.3674e-06, 7.2313e-07],\n",
      "        [5.2598e-03, 2.5895e-02, 3.0403e-01, 6.4276e-01, 1.9820e-02, 1.5380e-03,\n",
      "         2.9700e-04, 2.8198e-04, 9.1952e-05, 2.8440e-05],\n",
      "        [4.3410e-02, 5.0540e-02, 7.0692e-02, 4.4676e-01, 3.5079e-01, 3.5326e-02,\n",
      "         1.2821e-03, 6.1702e-04, 4.4665e-04, 1.3209e-04],\n",
      "        [9.6028e-03, 1.0903e-02, 5.7222e-03, 3.8032e-02, 3.1518e-01, 5.9229e-01,\n",
      "         1.7349e-02, 6.6388e-03, 3.3092e-03, 9.6820e-04],\n",
      "        [8.7763e-04, 7.9176e-03, 7.2443e-03, 1.9714e-03, 1.8189e-02, 2.8184e-01,\n",
      "         3.9563e-01, 2.2535e-01, 5.5653e-02, 5.3332e-03],\n",
      "        [2.5368e-04, 5.0691e-03, 4.0715e-03, 7.4300e-04, 3.2259e-03, 6.8603e-02,\n",
      "         4.2158e-01, 3.7380e-01, 1.1637e-01, 6.2879e-03]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: và mảnh vườn , nó rất đẹp . <EOS> <PAD>\n",
      "Reference: and the garden , it was beautiful . <EOS>\n",
      "Model: <SOS> and the the is , was very beautiful <EOS>\n",
      "Attention Weights: tensor([[0.0022, 0.9974, 0.0004, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0037, 0.9815, 0.0147, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0002, 0.9052, 0.0923, 0.0020, 0.0002, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0012, 0.6206, 0.2358, 0.1149, 0.0114, 0.0122, 0.0038, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0116, 0.0897, 0.8668, 0.0141, 0.0134, 0.0041, 0.0002, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0197, 0.0714, 0.3351, 0.2667, 0.2595, 0.0422, 0.0040, 0.0013,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0017, 0.0022, 0.0022, 0.0271, 0.7094, 0.2475, 0.0080, 0.0019,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0020, 0.0098, 0.0283, 0.0121, 0.1259, 0.6675, 0.1074, 0.0469,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0042, 0.0425, 0.1438, 0.0324, 0.0293, 0.0852, 0.3340, 0.3283,\n",
      "         0.0000]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7.43, Train Loss: 2.39, Val Loss: 4.13, Train BLEU: 17.89, Val BLEU: 11.04, Minutes Elapsed: 388.34\n",
      "Sampling from training predictions...\n",
      "Source: đây là orchid lounge ở tootsie ở nashville . <EOS>\n",
      "Reference: this is tootsie &apos;s orchid lounge in nashville .\n",
      "Model: <SOS> this is the <UNK> in in in nashville .\n",
      "Attention Weights: tensor([[7.9596e-01, 2.0363e-01, 4.0990e-04, 8.6605e-06, 1.3773e-07, 1.4432e-08,\n",
      "         6.1821e-09, 4.7430e-09, 1.9567e-09, 4.5875e-10],\n",
      "        [2.9787e-03, 8.9042e-01, 9.6472e-02, 7.6963e-03, 1.7960e-03, 3.5450e-04,\n",
      "         2.6354e-04, 1.8363e-05, 1.3745e-06, 6.2636e-07],\n",
      "        [2.2715e-02, 3.8489e-01, 5.0453e-01, 6.4286e-02, 1.4971e-02, 6.3140e-03,\n",
      "         1.7667e-03, 4.7544e-04, 3.2331e-05, 1.3651e-05],\n",
      "        [1.4148e-03, 5.9791e-03, 3.0065e-01, 5.6460e-01, 8.1456e-02, 2.9712e-02,\n",
      "         1.4395e-02, 1.5860e-03, 1.6358e-04, 4.3542e-05],\n",
      "        [1.3850e-04, 1.5997e-03, 1.1404e-01, 1.4239e-01, 5.5670e-01, 5.9191e-02,\n",
      "         1.1846e-01, 6.4825e-03, 8.1730e-04, 1.8666e-04],\n",
      "        [8.3202e-07, 1.6506e-06, 4.1500e-04, 2.1629e-03, 1.2359e-01, 7.5560e-02,\n",
      "         6.2879e-01, 1.5118e-01, 1.6156e-02, 2.1358e-03],\n",
      "        [1.0995e-05, 1.6826e-06, 9.4856e-05, 1.2635e-03, 1.1394e-01, 3.2362e-02,\n",
      "         7.2565e-01, 1.1089e-01, 1.1587e-02, 4.1990e-03],\n",
      "        [2.0711e-05, 1.8696e-06, 5.6939e-05, 9.2702e-04, 2.5772e-02, 3.3072e-02,\n",
      "         3.5519e-01, 5.4660e-01, 2.6697e-02, 1.1665e-02],\n",
      "        [6.8151e-04, 3.9094e-05, 1.3940e-04, 9.2226e-04, 3.4620e-02, 2.8636e-02,\n",
      "         3.4131e-01, 4.9784e-01, 6.8430e-02, 2.7387e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: trước_tiên bạn được một hòn đá , rồi nhiều hơn\n",
      "Reference: first you get one stone , then several more\n",
      "Model: <SOS> so you you a a , whenever much than\n",
      "Attention Weights: tensor([[9.9996e-01, 3.7008e-05, 6.1417e-07, 3.1813e-09, 7.2338e-11, 4.8568e-11,\n",
      "         1.9075e-12, 1.0417e-11, 6.0205e-12, 2.6891e-12],\n",
      "        [9.8918e-01, 8.9080e-03, 1.9009e-03, 6.7569e-06, 4.7178e-06, 3.9928e-07,\n",
      "         8.3893e-08, 5.6836e-08, 3.7616e-08, 9.7346e-09],\n",
      "        [6.2916e-01, 1.3253e-01, 2.1003e-01, 1.9753e-02, 6.2770e-03, 1.8669e-03,\n",
      "         2.2959e-04, 7.7339e-05, 3.9225e-05, 4.2355e-05],\n",
      "        [2.6225e-03, 4.7086e-02, 8.5059e-01, 7.3783e-02, 2.1536e-02, 2.1476e-03,\n",
      "         1.5336e-03, 3.9847e-04, 1.2214e-04, 1.7695e-04],\n",
      "        [2.9183e-04, 3.5912e-04, 9.1629e-03, 5.2525e-02, 7.1216e-01, 1.8184e-01,\n",
      "         3.6456e-02, 4.4617e-03, 9.5377e-04, 1.7887e-03],\n",
      "        [8.0801e-03, 8.0605e-04, 1.7686e-03, 2.9900e-02, 4.4058e-01, 3.4964e-01,\n",
      "         1.0056e-01, 5.5456e-02, 4.8982e-03, 8.3145e-03],\n",
      "        [2.8780e-04, 1.4862e-04, 7.3258e-04, 2.9297e-03, 9.4130e-03, 2.1000e-02,\n",
      "         6.6426e-02, 8.0940e-01, 6.0660e-02, 2.9005e-02],\n",
      "        [1.7177e-03, 7.5869e-05, 3.0181e-04, 8.3537e-04, 8.0140e-03, 6.5021e-03,\n",
      "         2.8705e-02, 6.0036e-01, 2.7242e-01, 8.1070e-02],\n",
      "        [2.5892e-03, 7.1998e-05, 9.5291e-04, 3.1643e-03, 1.3284e-02, 4.3485e-03,\n",
      "         2.0540e-02, 8.9980e-02, 3.0472e-01, 5.6035e-01]])\n",
      "\n",
      "Epoch: 7.48, Train Loss: 2.32, Val Loss: 4.10, Train BLEU: 18.22, Val BLEU: 10.70, Minutes Elapsed: 390.88\n",
      "Sampling from training predictions...\n",
      "Source: nhưng tôi cũng để_ý rằng đôi_khi những sáng_tác mà tôi\n",
      "Reference: but i also noticed that sometimes the music that\n",
      "Model: <SOS> but i also argue that sometimes the the that\n",
      "Attention Weights: tensor([[3.4089e-01, 1.5055e-01, 5.0701e-01, 1.4639e-03, 9.6638e-05, 1.5206e-06,\n",
      "         3.3464e-08, 2.5789e-07, 2.5285e-08, 1.8682e-08],\n",
      "        [4.8387e-02, 4.9600e-01, 4.4773e-01, 7.8383e-03, 3.9527e-05, 4.9179e-06,\n",
      "         1.9681e-06, 1.2876e-06, 1.1102e-07, 8.9478e-08],\n",
      "        [1.3342e-03, 3.4971e-03, 6.4858e-01, 3.1922e-01, 2.6960e-02, 2.9482e-04,\n",
      "         5.5805e-05, 5.3491e-05, 3.2578e-06, 1.6517e-06],\n",
      "        [2.2261e-03, 1.6448e-03, 1.8240e-01, 4.6497e-01, 3.2292e-01, 1.7726e-02,\n",
      "         5.2401e-03, 2.7254e-03, 1.2554e-04, 2.2163e-05],\n",
      "        [2.0042e-04, 1.1690e-04, 5.1766e-04, 4.3494e-02, 8.2402e-01, 1.0545e-01,\n",
      "         1.3355e-02, 1.0809e-02, 1.8388e-03, 2.0231e-04],\n",
      "        [3.9176e-04, 2.4413e-04, 2.6714e-04, 1.0084e-02, 1.1683e-01, 6.6488e-01,\n",
      "         9.0458e-02, 1.0102e-01, 1.4159e-02, 1.6603e-03],\n",
      "        [6.2588e-06, 1.8008e-05, 1.6712e-05, 3.0756e-04, 4.7941e-03, 3.0869e-02,\n",
      "         1.2196e-01, 7.5407e-01, 7.7906e-02, 1.0051e-02],\n",
      "        [1.0830e-06, 5.7661e-06, 1.0052e-04, 3.0962e-03, 1.2830e-02, 5.1864e-02,\n",
      "         2.5010e-01, 4.6927e-01, 1.6332e-01, 4.9406e-02],\n",
      "        [2.9668e-07, 1.0937e-05, 5.6590e-06, 1.3094e-03, 2.4564e-02, 1.8476e-02,\n",
      "         1.8638e-01, 2.3579e-01, 3.0252e-01, 2.3094e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: nhưng thay vì thế , chúng_tôi giết chết mọi thứ\n",
      "Reference: instead , everything we touched we killed . <EOS>\n",
      "Model: <SOS> but instead , we we cutting everything everything everything\n",
      "Attention Weights: tensor([[1.9377e-03, 5.5595e-02, 9.0891e-01, 3.3522e-02, 1.3973e-05, 1.2670e-07,\n",
      "         1.2735e-06, 1.8025e-05, 4.5000e-06, 8.8574e-08],\n",
      "        [4.8440e-02, 2.8004e-01, 5.8868e-01, 8.0434e-02, 2.1689e-03, 1.5021e-04,\n",
      "         7.3190e-05, 1.0188e-05, 1.2141e-06, 3.8087e-07],\n",
      "        [1.6809e-03, 3.4765e-02, 3.4994e-01, 5.1831e-01, 8.5044e-02, 1.3861e-03,\n",
      "         8.4855e-03, 3.1911e-04, 5.1461e-05, 2.1083e-05],\n",
      "        [9.3567e-04, 1.9973e-03, 9.7266e-02, 1.1469e-01, 1.6499e-01, 2.9214e-02,\n",
      "         5.2539e-01, 6.1777e-02, 2.3925e-03, 1.3490e-03],\n",
      "        [4.4628e-05, 4.8838e-04, 1.2448e-02, 6.5514e-03, 1.4881e-02, 4.2342e-03,\n",
      "         8.0248e-01, 1.5598e-01, 2.4301e-03, 4.5911e-04],\n",
      "        [2.5985e-06, 2.1981e-05, 4.2386e-04, 1.0232e-03, 7.8806e-03, 9.4781e-03,\n",
      "         6.3284e-01, 3.2251e-01, 2.1912e-02, 3.9140e-03],\n",
      "        [8.0679e-06, 1.9803e-05, 1.4637e-03, 7.9416e-03, 8.5584e-03, 4.4021e-03,\n",
      "         1.8767e-02, 4.0193e-01, 4.3336e-01, 1.2355e-01],\n",
      "        [1.2098e-04, 6.7139e-05, 2.2322e-04, 2.6085e-03, 6.0407e-02, 1.5458e-02,\n",
      "         4.5083e-02, 2.9078e-01, 5.0376e-01, 8.1495e-02],\n",
      "        [1.9264e-05, 1.2791e-05, 1.1181e-04, 5.3183e-04, 1.8511e-02, 2.7171e-03,\n",
      "         4.1521e-02, 3.2726e-01, 4.4058e-01, 1.6874e-01]])\n",
      "\n",
      "Epoch: 7.53, Train Loss: 2.33, Val Loss: 4.13, Train BLEU: 19.09, Val BLEU: 11.03, Minutes Elapsed: 393.43\n",
      "Sampling from training predictions...\n",
      "Source: và , bạn biết đấy , không có nhiều nhiều\n",
      "Reference: and , you know , there &apos;s not much\n",
      "Model: <SOS> and , you know , there are no lot\n",
      "Attention Weights: tensor([[1.8371e-03, 7.5552e-01, 1.7362e-02, 2.1075e-01, 1.4385e-02, 6.7867e-05,\n",
      "         6.9112e-05, 2.6892e-06, 9.1863e-07, 4.1318e-07],\n",
      "        [8.7603e-04, 9.7484e-01, 2.3411e-02, 8.7284e-04, 2.8008e-06, 4.5078e-07,\n",
      "         9.4639e-07, 1.8000e-08, 3.3271e-09, 5.9423e-10],\n",
      "        [6.7504e-05, 2.1217e-02, 7.3013e-01, 2.4335e-01, 2.5925e-03, 1.3591e-03,\n",
      "         1.1887e-03, 8.1352e-05, 1.4839e-05, 1.9714e-06],\n",
      "        [6.1564e-05, 2.0335e-03, 7.2043e-02, 6.8656e-01, 1.7498e-01, 3.3587e-02,\n",
      "         2.6124e-02, 3.8369e-03, 7.0979e-04, 6.9925e-05],\n",
      "        [1.8933e-04, 1.8833e-03, 2.8006e-02, 3.6845e-01, 4.4999e-01, 1.0388e-01,\n",
      "         3.7519e-02, 7.5187e-03, 2.4367e-03, 1.3510e-04],\n",
      "        [6.5087e-06, 2.8537e-05, 3.5395e-03, 8.6393e-03, 9.8630e-03, 9.3518e-02,\n",
      "         7.1979e-01, 1.2725e-01, 3.0073e-02, 7.2937e-03],\n",
      "        [1.7905e-06, 1.4322e-04, 2.3766e-03, 1.1119e-02, 4.3918e-03, 2.5577e-02,\n",
      "         3.7117e-01, 4.6785e-01, 8.9949e-02, 2.7426e-02],\n",
      "        [6.1870e-06, 1.0164e-05, 1.5783e-04, 6.7680e-03, 1.9140e-02, 1.9763e-02,\n",
      "         4.4336e-01, 1.9554e-01, 2.3427e-01, 8.0990e-02],\n",
      "        [7.4381e-08, 2.2021e-06, 3.4860e-06, 4.4832e-03, 1.8497e-02, 2.1426e-02,\n",
      "         4.9654e-02, 5.7948e-02, 7.1713e-01, 1.3085e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: có thể hình_dung , thị_trấn đã bị tàn_phá . <EOS>\n",
      "Reference: as you can imagine , the town had been\n",
      "Model: <SOS> and can can , , the was was been\n",
      "Attention Weights: tensor([[9.3465e-01, 6.5056e-02, 2.9727e-04, 1.7198e-08, 6.8538e-09, 8.3054e-11,\n",
      "         1.2697e-11, 2.5303e-12, 3.7234e-13, 1.8117e-13],\n",
      "        [8.9207e-02, 8.0551e-01, 1.0388e-01, 8.2999e-04, 5.4458e-04, 1.3018e-05,\n",
      "         5.8347e-06, 1.4311e-06, 2.1752e-07, 1.0433e-07],\n",
      "        [8.0699e-03, 5.2537e-02, 9.3197e-01, 4.5752e-03, 1.4719e-03, 4.9590e-04,\n",
      "         8.2130e-04, 5.6319e-05, 4.2767e-06, 1.6914e-06],\n",
      "        [1.4024e-02, 4.7932e-02, 9.0446e-01, 2.4942e-02, 6.9154e-03, 9.2203e-04,\n",
      "         7.1947e-04, 7.1612e-05, 5.9970e-06, 1.3087e-06],\n",
      "        [5.8440e-04, 2.7316e-03, 2.5439e-01, 5.0928e-01, 2.2743e-01, 1.4320e-03,\n",
      "         2.6760e-03, 1.3403e-03, 9.1409e-05, 4.4258e-05],\n",
      "        [2.1044e-03, 2.0525e-03, 5.1047e-02, 1.7146e-01, 7.3579e-01, 1.7898e-02,\n",
      "         1.5068e-02, 4.0006e-03, 2.9239e-04, 2.9088e-04],\n",
      "        [1.7900e-03, 2.4914e-03, 7.7114e-03, 2.4180e-02, 8.7487e-01, 5.4267e-02,\n",
      "         2.9605e-02, 4.5925e-03, 2.3341e-04, 2.5979e-04],\n",
      "        [1.2402e-03, 1.5822e-03, 5.1359e-02, 3.5606e-03, 6.7196e-02, 2.0650e-01,\n",
      "         6.2532e-01, 4.0418e-02, 2.0302e-03, 7.8966e-04],\n",
      "        [6.8901e-05, 1.4883e-04, 1.0129e-02, 2.4767e-03, 6.5919e-02, 1.1673e-01,\n",
      "         6.7652e-01, 1.2248e-01, 4.5864e-03, 9.4160e-04]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7.58, Train Loss: 2.44, Val Loss: 4.17, Train BLEU: 18.47, Val BLEU: 11.10, Minutes Elapsed: 395.97\n",
      "Sampling from training predictions...\n",
      "Source: kích_cỡ của căn phòng_không to tới_mức này . <EOS> <PAD>\n",
      "Reference: and the size of the room is not that\n",
      "Model: <SOS> the size size of this is is this .\n",
      "Attention Weights: tensor([[0.9994, 0.0006, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.9231, 0.0654, 0.0071, 0.0042, 0.0001, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.3647, 0.4275, 0.1938, 0.0112, 0.0020, 0.0007, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.3857, 0.4641, 0.1211, 0.0259, 0.0027, 0.0005, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1931, 0.4370, 0.1837, 0.1729, 0.0105, 0.0026, 0.0001, 0.0002, 0.0001,\n",
      "         0.0000],\n",
      "        [0.0211, 0.0773, 0.1334, 0.6366, 0.0960, 0.0339, 0.0008, 0.0006, 0.0002,\n",
      "         0.0000],\n",
      "        [0.0089, 0.0513, 0.0414, 0.3020, 0.3822, 0.1758, 0.0211, 0.0124, 0.0049,\n",
      "         0.0000],\n",
      "        [0.0018, 0.0185, 0.0327, 0.3587, 0.2875, 0.2592, 0.0140, 0.0226, 0.0051,\n",
      "         0.0000],\n",
      "        [0.0012, 0.0014, 0.0087, 0.3763, 0.2320, 0.3404, 0.0274, 0.0101, 0.0025,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: bí_mật đó là , cây súng này được nạp sẵn\n",
      "Reference: my secret was that i had this gun loaded\n",
      "Model: <SOS> so that is this this this this really was\n",
      "Attention Weights: tensor([[9.9944e-01, 4.6105e-04, 9.5696e-05, 6.4234e-07, 8.4309e-07, 5.0481e-09,\n",
      "         4.8205e-10, 7.2833e-11, 2.9344e-11, 2.5399e-11],\n",
      "        [4.9996e-01, 3.5410e-01, 1.3221e-01, 8.5440e-03, 4.4057e-03, 7.7685e-04,\n",
      "         2.7407e-06, 1.2199e-06, 3.6509e-07, 5.2824e-07],\n",
      "        [3.1228e-02, 1.2769e-02, 1.8558e-01, 2.6930e-01, 3.8580e-01, 1.1135e-01,\n",
      "         1.5324e-03, 2.0420e-03, 2.4762e-04, 1.4358e-04],\n",
      "        [8.5847e-05, 3.2198e-04, 7.3968e-02, 2.4862e-01, 6.0754e-01, 6.3053e-02,\n",
      "         1.1941e-03, 3.5317e-03, 1.3193e-03, 3.6285e-04],\n",
      "        [1.1070e-05, 9.3162e-06, 1.0021e-03, 1.9156e-02, 5.8281e-01, 3.7999e-01,\n",
      "         4.0095e-03, 8.1405e-03, 3.4908e-03, 1.3765e-03],\n",
      "        [3.0342e-06, 5.4031e-06, 3.6022e-04, 3.9621e-02, 4.9369e-01, 4.1061e-01,\n",
      "         5.7379e-03, 2.1358e-02, 1.6813e-02, 1.1800e-02],\n",
      "        [2.0303e-06, 6.3249e-06, 9.2853e-04, 2.8010e-02, 3.6649e-01, 3.3952e-01,\n",
      "         2.9225e-02, 1.1765e-01, 9.1550e-02, 2.6616e-02],\n",
      "        [9.2291e-08, 5.1474e-07, 5.1930e-05, 3.6290e-03, 2.2277e-02, 1.8768e-01,\n",
      "         1.4707e-02, 1.9112e-01, 3.4109e-01, 2.3945e-01],\n",
      "        [3.9080e-07, 7.5406e-07, 3.1136e-05, 1.0658e-03, 1.1761e-02, 1.9100e-02,\n",
      "         3.3872e-03, 9.0425e-02, 2.0049e-01, 6.7374e-01]])\n",
      "\n",
      "Epoch: 7.62, Train Loss: 2.38, Val Loss: 4.14, Train BLEU: 19.39, Val BLEU: 11.60, Minutes Elapsed: 398.52\n",
      "Sampling from training predictions...\n",
      "Source: ý của tôi là hai thứ , niềm đam_mê ,\n",
      "Reference: i &apos;m saying the two , the passion ,\n",
      "Model: <SOS> i mean two two two , , , ,\n",
      "Attention Weights: tensor([[1.7721e-01, 2.8688e-02, 9.8732e-02, 6.9135e-01, 3.9942e-03, 2.5796e-05,\n",
      "         1.5038e-08, 1.4468e-08, 4.1449e-08, 3.6913e-10],\n",
      "        [1.1128e-01, 2.6445e-02, 2.0882e-01, 6.1668e-01, 3.5889e-02, 6.4238e-04,\n",
      "         3.4480e-05, 8.6251e-05, 1.2550e-04, 7.4952e-06],\n",
      "        [4.2292e-02, 2.0230e-02, 8.7339e-02, 5.6743e-01, 2.5789e-01, 2.1837e-02,\n",
      "         1.2462e-03, 1.2541e-03, 4.2826e-04, 4.8917e-05],\n",
      "        [5.6629e-04, 3.8194e-05, 1.5494e-03, 5.8725e-02, 4.6486e-01, 4.3389e-01,\n",
      "         1.2336e-02, 1.3800e-02, 1.3680e-02, 5.5667e-04],\n",
      "        [9.3961e-05, 9.6360e-06, 2.6992e-04, 1.2810e-02, 2.7087e-01, 4.8793e-01,\n",
      "         1.1735e-01, 7.5488e-02, 3.3049e-02, 2.1335e-03],\n",
      "        [1.2978e-04, 2.0067e-05, 4.1705e-04, 2.0972e-02, 9.0341e-02, 2.6961e-01,\n",
      "         1.6915e-01, 2.1144e-01, 2.2354e-01, 1.4378e-02],\n",
      "        [1.8403e-06, 1.4796e-06, 3.1455e-05, 3.8684e-04, 2.7749e-03, 1.3234e-02,\n",
      "         1.6484e-01, 5.7968e-01, 1.8431e-01, 5.4737e-02],\n",
      "        [5.6625e-06, 1.4805e-06, 1.2044e-04, 5.7136e-04, 4.5381e-04, 6.5116e-03,\n",
      "         6.5932e-02, 5.7144e-01, 3.1733e-01, 3.7630e-02],\n",
      "        [5.6487e-05, 3.6854e-06, 7.7135e-05, 1.2942e-03, 1.0993e-03, 2.7611e-03,\n",
      "         1.0238e-02, 1.7162e-02, 2.0869e-01, 7.5862e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi nhận ra rằng vấn_đề chính là giải_pháp . <EOS>\n",
      "Reference: so i figured that the problem is the solution\n",
      "Model: <SOS> i i realized that problem is is to .\n",
      "Attention Weights: tensor([[1.8760e-02, 8.8823e-01, 8.2247e-02, 5.5621e-03, 4.6889e-03, 5.0349e-04,\n",
      "         8.3696e-06, 1.8710e-06, 1.7506e-07, 5.8032e-09],\n",
      "        [2.5161e-03, 9.3286e-01, 4.9814e-02, 1.3678e-02, 8.8813e-04, 2.1148e-04,\n",
      "         1.8461e-05, 8.7280e-06, 2.0477e-07, 7.6948e-08],\n",
      "        [1.3437e-03, 2.4078e-01, 2.1002e-01, 3.8078e-01, 1.2248e-01, 3.2614e-02,\n",
      "         7.7823e-03, 4.0577e-03, 1.1777e-04, 1.6493e-05],\n",
      "        [6.5540e-03, 3.6099e-01, 1.7883e-01, 2.7138e-01, 1.3128e-01, 3.4313e-02,\n",
      "         1.1863e-02, 4.6045e-03, 1.6404e-04, 2.1977e-05],\n",
      "        [4.8002e-04, 5.2424e-03, 1.7227e-02, 1.8995e-01, 4.2940e-01, 1.4780e-01,\n",
      "         1.0222e-01, 1.0600e-01, 1.3801e-03, 2.9692e-04],\n",
      "        [6.0327e-05, 1.6808e-03, 3.4808e-03, 4.4062e-02, 1.6110e-01, 1.6085e-01,\n",
      "         2.1628e-01, 3.9961e-01, 1.1781e-02, 1.0849e-03],\n",
      "        [1.9952e-04, 2.3420e-03, 2.5785e-03, 9.1316e-03, 7.6348e-02, 7.6538e-02,\n",
      "         2.1878e-01, 5.7141e-01, 3.8441e-02, 4.2269e-03],\n",
      "        [3.8688e-04, 1.7182e-03, 1.3146e-03, 7.6982e-03, 1.2528e-02, 7.6957e-02,\n",
      "         4.6379e-01, 3.0766e-01, 8.2235e-02, 4.5709e-02],\n",
      "        [4.2116e-05, 5.2177e-04, 3.2708e-04, 2.7396e-03, 2.2846e-02, 2.3255e-02,\n",
      "         2.0801e-01, 6.1283e-01, 1.0003e-01, 2.9399e-02]])\n",
      "\n",
      "Epoch: 7.67, Train Loss: 2.43, Val Loss: 4.18, Train BLEU: 17.57, Val BLEU: 10.34, Minutes Elapsed: 401.06\n",
      "Sampling from training predictions...\n",
      "Source: mọi người bây_giờ trung_bình \" trả_lời đúng \" 7 câu\n",
      "Reference: people now solved seven questions on average . <EOS>\n",
      "Model: <SOS> people chinese , , &quot; &apos; &quot; seven <EOS>\n",
      "Attention Weights: tensor([[8.0815e-01, 1.3546e-01, 5.5289e-02, 1.0180e-03, 4.0695e-05, 4.0282e-05,\n",
      "         1.1694e-06, 2.1311e-08, 2.2291e-08, 4.6651e-09],\n",
      "        [5.8685e-05, 5.5420e-04, 7.2353e-01, 1.8928e-01, 2.9167e-02, 5.6420e-02,\n",
      "         8.8864e-04, 7.2883e-05, 2.4053e-05, 5.7059e-06],\n",
      "        [2.3109e-04, 1.6316e-03, 2.4696e-01, 2.1321e-01, 1.7503e-01, 2.8472e-01,\n",
      "         7.3006e-02, 3.8793e-03, 1.1214e-03, 2.1178e-04],\n",
      "        [9.5207e-06, 2.0262e-04, 3.6644e-03, 1.0283e-01, 1.2950e-01, 4.0659e-01,\n",
      "         2.3171e-01, 5.1077e-02, 6.9212e-02, 5.2135e-03],\n",
      "        [2.8869e-05, 1.2540e-04, 1.2999e-03, 1.5442e-02, 5.2444e-02, 2.9161e-01,\n",
      "         4.0628e-01, 6.1478e-02, 1.5117e-01, 2.0121e-02],\n",
      "        [3.2955e-07, 3.1974e-07, 8.0995e-06, 1.0041e-04, 5.7994e-03, 6.6456e-02,\n",
      "         2.4849e-01, 1.1988e-01, 4.0266e-01, 1.5660e-01],\n",
      "        [2.0729e-07, 1.0969e-07, 2.2424e-06, 5.6803e-05, 5.0435e-03, 5.2226e-02,\n",
      "         1.9016e-01, 1.3784e-01, 3.9563e-01, 2.1904e-01],\n",
      "        [3.7519e-07, 6.2508e-07, 9.1424e-06, 3.3136e-05, 4.3584e-03, 2.5951e-02,\n",
      "         8.7207e-02, 1.3513e-01, 3.3755e-01, 4.0976e-01],\n",
      "        [8.5627e-07, 1.3074e-06, 1.2735e-05, 2.8929e-04, 1.6054e-02, 5.7695e-02,\n",
      "         1.4680e-01, 1.1449e-01, 2.9626e-01, 3.6840e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: thật khó_tin , và chúng_tôi nói với những người zambia\n",
      "Reference: and we could not believe , and we were\n",
      "Model: <SOS> and , , and to to and we said\n",
      "Attention Weights: tensor([[9.9884e-01, 1.1634e-03, 8.9011e-08, 1.9333e-10, 5.8467e-11, 1.6264e-11,\n",
      "         3.2010e-12, 2.8175e-14, 2.0573e-14, 5.1054e-15],\n",
      "        [6.4471e-01, 3.4550e-01, 7.6117e-03, 5.0125e-04, 1.5315e-03, 9.7111e-05,\n",
      "         4.0532e-05, 4.4482e-06, 2.2352e-06, 1.6253e-06],\n",
      "        [4.3715e-01, 3.3624e-01, 1.2330e-01, 3.6942e-02, 4.8047e-02, 1.1860e-02,\n",
      "         5.0456e-03, 9.8888e-04, 3.0852e-04, 1.2456e-04],\n",
      "        [3.5542e-01, 1.2786e-01, 1.2796e-01, 1.0475e-01, 1.8604e-01, 6.1882e-02,\n",
      "         3.1248e-02, 3.4663e-03, 1.0682e-03, 3.1511e-04],\n",
      "        [7.0884e-02, 2.1887e-01, 2.2749e-02, 6.8528e-03, 6.0633e-03, 9.7858e-02,\n",
      "         5.0022e-01, 4.6142e-02, 1.7267e-02, 1.3101e-02],\n",
      "        [1.0611e-01, 2.9977e-01, 7.4417e-02, 2.0865e-02, 1.9312e-03, 6.5374e-02,\n",
      "         2.4736e-01, 1.1935e-01, 3.8947e-02, 2.5888e-02],\n",
      "        [7.5078e-03, 5.4627e-02, 5.6972e-02, 1.9975e-01, 7.1969e-03, 5.1752e-02,\n",
      "         2.9270e-01, 1.6953e-01, 9.2481e-02, 6.7485e-02],\n",
      "        [5.2776e-04, 9.0746e-04, 1.6110e-04, 3.1579e-03, 1.0397e-02, 2.0699e-01,\n",
      "         1.7120e-01, 2.0544e-01, 2.8456e-01, 1.1666e-01],\n",
      "        [3.7327e-03, 8.8955e-03, 4.6789e-04, 1.5495e-03, 4.5986e-03, 5.6890e-01,\n",
      "         2.7354e-01, 4.2270e-02, 6.1895e-02, 3.4146e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7.72, Train Loss: 2.36, Val Loss: 4.15, Train BLEU: 18.44, Val BLEU: 10.92, Minutes Elapsed: 403.67\n",
      "Sampling from training predictions...\n",
      "Source: vậy_thì rất nhỏ , nhưng rất hữu_dụng . <EOS> <PAD>\n",
      "Reference: so very small , but very useful . <EOS>\n",
      "Model: <SOS> so very small small but clear &apos;s . <EOS>\n",
      "Attention Weights: tensor([[0.8956, 0.0811, 0.0233, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0083, 0.6520, 0.3370, 0.0026, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0134, 0.1053, 0.6779, 0.1919, 0.0084, 0.0018, 0.0012, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0164, 0.1289, 0.5765, 0.2496, 0.0229, 0.0037, 0.0018, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0081, 0.0439, 0.3934, 0.5368, 0.0151, 0.0017, 0.0005, 0.0001,\n",
      "         0.0000],\n",
      "        [0.0004, 0.0113, 0.0745, 0.1430, 0.4944, 0.2037, 0.0508, 0.0173, 0.0047,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0056, 0.0218, 0.0039, 0.0181, 0.4132, 0.4894, 0.0377, 0.0102,\n",
      "         0.0000],\n",
      "        [0.0008, 0.0056, 0.0151, 0.0111, 0.0176, 0.0913, 0.6820, 0.1191, 0.0574,\n",
      "         0.0000],\n",
      "        [0.0008, 0.0109, 0.0425, 0.2020, 0.2575, 0.0575, 0.1426, 0.0872, 0.1991,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: cháu không biết là thật_là thú_vị biết_bao khi nghe câu_chuyện\n",
      "Reference: you have no idea how exciting it is to\n",
      "Model: <SOS> they don &apos;t know what the is actually when\n",
      "Attention Weights: tensor([[9.0453e-01, 9.5343e-02, 1.2267e-04, 1.7959e-06, 1.7283e-07, 1.4723e-07,\n",
      "         7.7546e-09, 6.1679e-09, 2.9636e-09, 2.1784e-10],\n",
      "        [2.2599e-01, 6.6589e-01, 9.8479e-02, 8.0428e-03, 1.0543e-03, 4.8608e-04,\n",
      "         4.5542e-05, 7.8726e-06, 3.5860e-06, 1.9169e-06],\n",
      "        [3.9879e-01, 3.1791e-01, 2.1309e-01, 5.3355e-02, 1.0357e-02, 5.0692e-03,\n",
      "         1.2093e-03, 1.5156e-04, 5.0671e-05, 1.7866e-05],\n",
      "        [3.2305e-03, 1.8846e-02, 4.7741e-01, 2.9843e-01, 1.1756e-01, 6.6883e-02,\n",
      "         1.5213e-02, 2.1416e-03, 1.5783e-04, 1.2431e-04],\n",
      "        [2.1736e-04, 2.4112e-03, 2.0319e-02, 3.8946e-01, 3.1297e-01, 1.7611e-01,\n",
      "         6.7823e-02, 2.9238e-02, 1.0582e-03, 3.8935e-04],\n",
      "        [3.4474e-04, 3.7550e-03, 2.6968e-03, 1.9291e-01, 4.7660e-01, 1.2277e-01,\n",
      "         9.2390e-02, 1.0003e-01, 6.2412e-03, 2.2669e-03],\n",
      "        [1.4488e-05, 1.9753e-04, 3.1122e-04, 2.2073e-01, 3.2774e-01, 1.5443e-01,\n",
      "         1.3023e-01, 1.5262e-01, 1.0875e-02, 2.8481e-03],\n",
      "        [9.3029e-05, 1.7245e-03, 3.5349e-03, 1.5736e-01, 3.0149e-01, 3.2488e-01,\n",
      "         8.8432e-02, 7.9771e-02, 3.4104e-02, 8.6111e-03],\n",
      "        [2.1752e-06, 1.5612e-05, 3.2138e-05, 7.0018e-03, 1.2680e-01, 9.1433e-02,\n",
      "         1.2211e-01, 4.2530e-01, 1.8026e-01, 4.7051e-02]])\n",
      "\n",
      "Epoch: 7.77, Train Loss: 2.35, Val Loss: 4.15, Train BLEU: 19.50, Val BLEU: 10.93, Minutes Elapsed: 406.22\n",
      "Sampling from training predictions...\n",
      "Source: chúng_tôi hack phần_cứng , phần_mềm , phần ướt , và\n",
      "Reference: we hack hardware , software , wetware , and\n",
      "Model: <SOS> we we hardware , software , , , and\n",
      "Attention Weights: tensor([[1.4565e-01, 8.1914e-01, 3.5209e-02, 5.4097e-06, 4.3815e-06, 2.7811e-09,\n",
      "         9.7802e-09, 1.1281e-09, 7.5493e-11, 8.0206e-11],\n",
      "        [7.0059e-04, 7.2325e-01, 2.7548e-01, 4.3299e-04, 1.3425e-04, 1.5732e-06,\n",
      "         1.1936e-06, 5.5161e-07, 2.3275e-08, 2.8436e-09],\n",
      "        [1.4007e-03, 1.0913e-01, 8.3880e-01, 4.3620e-02, 6.5961e-03, 2.5807e-04,\n",
      "         8.9210e-05, 1.0698e-04, 4.4538e-06, 3.8937e-07],\n",
      "        [4.3219e-04, 1.3811e-02, 3.8564e-01, 3.2794e-01, 2.6018e-01, 7.0638e-03,\n",
      "         2.1399e-03, 2.5668e-03, 1.9566e-04, 3.0020e-05],\n",
      "        [1.3416e-04, 6.0904e-03, 1.1241e-02, 3.2671e-01, 5.2446e-01, 7.8929e-02,\n",
      "         3.8106e-02, 1.0926e-02, 2.4782e-03, 9.3041e-04],\n",
      "        [2.2870e-05, 2.3205e-04, 1.8905e-03, 7.3680e-03, 1.6433e-01, 1.7013e-01,\n",
      "         4.4877e-01, 1.8213e-01, 1.2093e-02, 1.3041e-02],\n",
      "        [1.4103e-05, 6.9051e-04, 1.4109e-03, 2.0915e-03, 1.9193e-02, 7.1007e-02,\n",
      "         3.0966e-01, 4.4532e-01, 1.1895e-01, 3.1669e-02],\n",
      "        [3.7031e-05, 1.2191e-04, 4.0896e-04, 7.1808e-03, 2.9345e-02, 1.6535e-02,\n",
      "         3.6660e-01, 2.8235e-01, 1.7752e-01, 1.1990e-01],\n",
      "        [9.0863e-05, 2.6633e-03, 3.3214e-03, 3.8525e-03, 1.4402e-02, 3.5150e-02,\n",
      "         3.1183e-01, 4.3258e-01, 1.1432e-01, 8.1796e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: phần tệ nhất_là tròng cái <UNK> tay này qua đầu\n",
      "Reference: the worst part is putting this sweater over my\n",
      "Model: <SOS> the biggest part of the <UNK> <UNK> of my\n",
      "Attention Weights: tensor([[9.4567e-01, 5.2871e-02, 1.3994e-03, 6.1236e-05, 2.7330e-07, 2.4764e-08,\n",
      "         6.9801e-09, 5.5384e-09, 1.7003e-09, 7.6856e-10],\n",
      "        [1.0350e-01, 2.4747e-01, 5.9699e-01, 5.1057e-02, 8.6688e-04, 8.0707e-05,\n",
      "         9.8823e-06, 4.4613e-06, 6.0431e-06, 5.7553e-06],\n",
      "        [1.0199e-01, 5.4825e-01, 1.2845e-01, 2.1262e-01, 7.8656e-03, 6.1941e-04,\n",
      "         5.9997e-05, 7.2778e-05, 4.0303e-05, 2.0881e-05],\n",
      "        [4.1232e-04, 1.7401e-02, 1.6220e-01, 7.3957e-01, 7.7323e-02, 2.5146e-03,\n",
      "         3.3448e-04, 1.1957e-04, 7.6271e-05, 4.2677e-05],\n",
      "        [5.7261e-05, 1.4066e-03, 9.6859e-02, 7.1612e-01, 1.6242e-01, 1.8249e-02,\n",
      "         1.6734e-03, 8.9444e-04, 1.3305e-03, 9.8782e-04],\n",
      "        [1.0570e-04, 1.1017e-03, 2.6936e-02, 2.5491e-01, 1.9489e-01, 2.8281e-01,\n",
      "         9.4284e-02, 2.6199e-02, 8.3157e-02, 3.5610e-02],\n",
      "        [3.1975e-05, 7.0715e-04, 7.5133e-03, 9.0650e-02, 1.2331e-01, 1.4873e-01,\n",
      "         1.5668e-01, 1.0868e-01, 2.7711e-01, 8.6593e-02],\n",
      "        [1.4474e-05, 2.2990e-04, 7.0016e-04, 2.0673e-02, 6.5899e-02, 1.4706e-01,\n",
      "         2.1149e-01, 1.3624e-01, 2.4623e-01, 1.7147e-01],\n",
      "        [8.3388e-06, 8.3592e-05, 2.8563e-04, 4.8733e-03, 4.3417e-02, 1.7920e-01,\n",
      "         3.1431e-01, 1.3597e-01, 1.8022e-01, 1.4164e-01]])\n",
      "\n",
      "Epoch: 7.82, Train Loss: 2.40, Val Loss: 4.15, Train BLEU: 18.01, Val BLEU: 11.22, Minutes Elapsed: 408.77\n",
      "Sampling from training predictions...\n",
      "Source: đó là tính sợ nước . <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: it &apos;s that afraid of the water . <EOS>\n",
      "Model: <SOS> it &apos;s the faces water water water . .\n",
      "Attention Weights: tensor([[0.1437, 0.8456, 0.0099, 0.0007, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0268, 0.6895, 0.2698, 0.0115, 0.0021, 0.0002, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0045, 0.3148, 0.5319, 0.1241, 0.0243, 0.0004, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0028, 0.5207, 0.2714, 0.2032, 0.0015, 0.0003, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0009, 0.0216, 0.2142, 0.1602, 0.4601, 0.1114, 0.0316, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0012, 0.0143, 0.0757, 0.3993, 0.3866, 0.0746, 0.0483, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0034, 0.0362, 0.0825, 0.2397, 0.4823, 0.0750, 0.0810, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0375, 0.0820, 0.0552, 0.2535, 0.1729, 0.1587, 0.2402, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0096, 0.0593, 0.0601, 0.1420, 0.2548, 0.2436, 0.2306, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: thuốc này đã bị cấm sử_dụng trong ngành thú_y tại\n",
      "Reference: this drug has now been banned for veterinary use\n",
      "Model: <SOS> this has has been used used in the .\n",
      "Attention Weights: tensor([[9.9849e-01, 1.4531e-03, 4.9107e-05, 1.1808e-05, 1.2615e-07, 1.1039e-08,\n",
      "         3.7632e-10, 1.1350e-10, 3.8938e-11, 5.1627e-11],\n",
      "        [9.5639e-01, 7.8330e-03, 2.4263e-02, 1.0396e-02, 6.8121e-04, 4.0505e-04,\n",
      "         1.1232e-05, 1.1651e-05, 2.8388e-06, 1.6947e-06],\n",
      "        [2.5764e-03, 6.7937e-03, 3.1278e-01, 5.7599e-01, 7.5068e-02, 2.5966e-02,\n",
      "         5.1601e-04, 1.7943e-04, 5.9679e-05, 8.0433e-05],\n",
      "        [7.6968e-04, 7.6306e-04, 6.0704e-02, 5.3834e-01, 2.0113e-01, 1.8639e-01,\n",
      "         9.2825e-03, 1.7005e-03, 4.9384e-04, 4.2866e-04],\n",
      "        [6.9779e-05, 3.4492e-05, 6.1752e-04, 3.0265e-02, 1.2172e-01, 7.2339e-01,\n",
      "         9.9037e-02, 1.6642e-02, 5.2410e-03, 2.9778e-03],\n",
      "        [1.6530e-05, 1.6189e-05, 9.6281e-05, 1.9721e-03, 7.1223e-02, 5.5736e-01,\n",
      "         1.1508e-01, 1.8098e-01, 5.7980e-02, 1.5284e-02],\n",
      "        [4.3058e-05, 1.6934e-05, 6.8087e-05, 4.7571e-04, 4.2099e-02, 8.9988e-02,\n",
      "         9.3009e-02, 3.9120e-01, 2.5407e-01, 1.2903e-01],\n",
      "        [4.1989e-05, 4.0920e-05, 2.5085e-05, 1.7745e-04, 1.1700e-02, 3.0073e-02,\n",
      "         6.3463e-02, 3.1090e-01, 2.7444e-01, 3.0914e-01],\n",
      "        [1.3344e-03, 6.0413e-04, 9.8076e-04, 1.3622e-03, 2.1884e-02, 6.1818e-02,\n",
      "         3.9022e-02, 3.2930e-01, 2.4965e-01, 2.9404e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7.86, Train Loss: 2.31, Val Loss: 4.14, Train BLEU: 19.69, Val BLEU: 11.34, Minutes Elapsed: 411.32\n",
      "Sampling from training predictions...\n",
      "Source: việc đọc và viết trình_tự dna đang trở_nên dễ_dàng hơn\n",
      "Reference: reading and writing dna code is getting easier and\n",
      "Model: <SOS> reading and the the is is easy easier easy\n",
      "Attention Weights: tensor([[7.4526e-01, 2.5472e-01, 1.6997e-05, 4.5676e-06, 1.0869e-07, 3.6545e-09,\n",
      "         1.1035e-10, 1.4393e-11, 8.0443e-12, 2.5695e-12],\n",
      "        [1.2451e-02, 9.4673e-01, 1.7335e-02, 2.0581e-02, 2.6462e-03, 2.4176e-04,\n",
      "         1.0866e-05, 4.0239e-06, 1.1934e-06, 2.2174e-07],\n",
      "        [2.9017e-02, 1.2960e-01, 1.8130e-01, 5.0225e-01, 1.3374e-01, 2.0603e-02,\n",
      "         2.8271e-03, 4.2209e-04, 1.9791e-04, 3.9617e-05],\n",
      "        [7.2452e-05, 8.3493e-04, 5.1191e-03, 1.1009e-01, 7.6752e-01, 9.8151e-02,\n",
      "         1.3009e-02, 4.0925e-03, 8.9373e-04, 2.1298e-04],\n",
      "        [2.0901e-05, 1.7532e-04, 2.0948e-04, 5.1480e-02, 6.1648e-01, 1.3986e-01,\n",
      "         1.3181e-01, 3.8040e-02, 1.9340e-02, 2.5819e-03],\n",
      "        [4.8402e-07, 2.4520e-06, 2.2222e-05, 3.3721e-03, 7.9442e-02, 4.9121e-02,\n",
      "         3.3343e-01, 2.4597e-01, 2.5645e-01, 3.2188e-02],\n",
      "        [3.9843e-06, 1.1927e-05, 6.4350e-06, 2.2700e-04, 2.6278e-03, 2.7004e-03,\n",
      "         5.3856e-02, 1.4537e-01, 6.5881e-01, 1.3639e-01],\n",
      "        [1.1908e-05, 4.8165e-05, 9.1154e-06, 1.3726e-04, 4.4257e-03, 2.1842e-03,\n",
      "         2.9857e-02, 1.9800e-01, 4.7666e-01, 2.8867e-01],\n",
      "        [1.1113e-05, 1.9293e-05, 2.3529e-06, 1.4111e-04, 4.0242e-03, 1.7535e-03,\n",
      "         7.0681e-03, 1.5586e-01, 4.0437e-01, 4.2675e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: bạn có_thể thấy tất_cả điều đó . <EOS> <PAD> <PAD>\n",
      "Reference: you can see all of this . <EOS> <PAD>\n",
      "Model: <SOS> you can see all that . . <EOS> .\n",
      "Attention Weights: tensor([[0.7296, 0.2493, 0.0208, 0.0003, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0528, 0.3905, 0.5552, 0.0014, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0022, 0.0159, 0.9676, 0.0131, 0.0011, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0029, 0.0022, 0.4907, 0.3539, 0.1400, 0.0098, 0.0004, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0012, 0.0008, 0.1135, 0.2820, 0.5358, 0.0607, 0.0045, 0.0016, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0007, 0.0044, 0.0454, 0.3200, 0.1495, 0.3629, 0.1170, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0013, 0.0033, 0.0145, 0.0429, 0.1291, 0.1719, 0.3649, 0.2720, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0124, 0.0103, 0.1933, 0.1052, 0.1770, 0.1328, 0.1903, 0.1786, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0221, 0.0172, 0.0570, 0.0268, 0.0805, 0.0844, 0.2354, 0.4766, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 7.91, Train Loss: 2.26, Val Loss: 4.18, Train BLEU: 18.98, Val BLEU: 10.40, Minutes Elapsed: 413.89\n",
      "Sampling from training predictions...\n",
      "Source: bây_giờ bạn biết làm thế_nào để chơi nó rồi đấy\n",
      "Reference: now you know how to play it . you\n",
      "Model: <SOS> now you know how to play it . ,\n",
      "Attention Weights: tensor([[9.9978e-01, 2.1493e-04, 1.3933e-06, 6.9686e-07, 5.3197e-09, 3.3026e-10,\n",
      "         3.3127e-11, 2.2538e-12, 1.4721e-12, 1.9389e-13],\n",
      "        [4.8663e-01, 4.2935e-01, 8.3549e-02, 4.5342e-04, 1.5485e-05, 1.6592e-06,\n",
      "         1.4324e-06, 5.3017e-08, 2.9816e-08, 3.1722e-08],\n",
      "        [8.0419e-02, 4.6960e-02, 8.3630e-01, 3.4130e-02, 1.7254e-03, 1.9942e-04,\n",
      "         2.3774e-04, 1.8224e-05, 6.4923e-06, 5.0353e-06],\n",
      "        [7.5241e-02, 5.0955e-02, 7.0649e-01, 1.5540e-01, 9.3596e-03, 9.3014e-04,\n",
      "         1.5313e-03, 5.1568e-05, 2.6598e-05, 1.6610e-05],\n",
      "        [2.6059e-03, 3.0497e-03, 7.2033e-02, 3.4591e-01, 2.0462e-01, 2.9598e-01,\n",
      "         6.9895e-02, 3.3561e-03, 1.5530e-03, 1.0030e-03],\n",
      "        [2.2399e-04, 7.2032e-05, 5.4818e-03, 5.2284e-02, 5.3196e-02, 2.6263e-01,\n",
      "         5.6863e-01, 3.5146e-02, 1.5387e-02, 6.9460e-03],\n",
      "        [2.1008e-05, 6.5538e-06, 3.3932e-04, 2.8423e-03, 8.9245e-03, 3.6370e-02,\n",
      "         8.4369e-01, 6.8011e-02, 2.6545e-02, 1.3254e-02],\n",
      "        [7.0806e-05, 1.5190e-05, 9.4655e-06, 1.8736e-04, 2.8402e-03, 5.7689e-03,\n",
      "         4.8316e-02, 1.1504e-01, 6.3048e-01, 1.9727e-01],\n",
      "        [1.5268e-04, 1.5632e-05, 1.2530e-05, 8.4369e-05, 1.1530e-03, 3.2876e-03,\n",
      "         3.0148e-02, 4.2074e-02, 6.7822e-01, 2.4485e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: đây là một trong sáu con sư_tử đã bị giết\n",
      "Reference: it &apos;s one of the six lions which were\n",
      "Model: <SOS> this is one of my seal that that killed\n",
      "Attention Weights: tensor([[9.5344e-01, 4.6484e-02, 7.5126e-05, 2.6638e-07, 1.6764e-07, 1.1085e-09,\n",
      "         6.3995e-10, 1.9792e-12, 4.1546e-14, 3.6238e-15],\n",
      "        [1.4844e-02, 5.5130e-01, 4.0240e-01, 2.3467e-02, 6.9716e-03, 9.6235e-04,\n",
      "         3.1273e-05, 1.1107e-05, 7.3945e-06, 2.1170e-06],\n",
      "        [4.6407e-03, 4.2686e-01, 3.0193e-01, 2.1012e-01, 4.6166e-02, 9.4081e-03,\n",
      "         4.2467e-04, 2.3926e-04, 1.4993e-04, 5.4316e-05],\n",
      "        [1.0976e-04, 1.6177e-02, 3.2024e-02, 8.4250e-01, 7.8013e-02, 2.9575e-02,\n",
      "         9.9179e-04, 3.1669e-04, 2.3012e-04, 6.6977e-05],\n",
      "        [2.8171e-05, 3.6828e-03, 7.4425e-03, 6.5193e-01, 2.6554e-01, 6.1215e-02,\n",
      "         3.1508e-03, 5.5587e-03, 1.1824e-03, 2.7285e-04],\n",
      "        [6.9638e-06, 1.6123e-03, 1.1172e-03, 1.9499e-01, 3.2032e-01, 2.3759e-01,\n",
      "         4.2715e-02, 1.4339e-01, 5.0290e-02, 7.9744e-03],\n",
      "        [9.3140e-05, 1.6132e-02, 1.3040e-03, 8.5961e-02, 7.2519e-02, 1.1273e-01,\n",
      "         7.3117e-02, 2.8358e-01, 2.8703e-01, 6.7543e-02],\n",
      "        [1.0496e-05, 6.8970e-04, 7.1201e-05, 7.1858e-03, 3.4075e-03, 1.3469e-02,\n",
      "         1.0034e-02, 1.7101e-01, 6.1384e-01, 1.8028e-01],\n",
      "        [4.9785e-07, 6.8092e-05, 2.0846e-06, 7.7276e-04, 4.7114e-04, 4.1415e-03,\n",
      "         2.3920e-03, 6.1329e-02, 5.9212e-01, 3.3870e-01]])\n",
      "\n",
      "Epoch: 7.96, Train Loss: 2.20, Val Loss: 4.15, Train BLEU: 21.12, Val BLEU: 10.67, Minutes Elapsed: 416.44\n",
      "Sampling from training predictions...\n",
      "Source: nên chúng_tôi khá an_tâm . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: so we were pretty reassured by this . <EOS>\n",
      "Model: <SOS> so we &apos;re pretty reassured by <EOS> . <EOS>\n",
      "Attention Weights: tensor([[0.9997, 0.0000, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0367, 0.9421, 0.0213, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0060, 0.0091, 0.9811, 0.0038, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0018, 0.0040, 0.9420, 0.0520, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0002, 0.0696, 0.9149, 0.0143, 0.0009, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0007, 0.0261, 0.6896, 0.1663, 0.1174, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0002, 0.0069, 0.4928, 0.0919, 0.4082, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0018, 0.0053, 0.0552, 0.2474, 0.1391, 0.5512, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0211, 0.0306, 0.0764, 0.0537, 0.1558, 0.6624, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi đã có một_chút sợ_hãi . <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: that &apos;s a little bit scary . <EOS> <PAD>\n",
      "Model: <SOS> i had a i i . i <EOS> i\n",
      "Attention Weights: tensor([[0.0229, 0.7636, 0.2126, 0.0008, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0032, 0.3388, 0.6071, 0.0501, 0.0008, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0032, 0.1038, 0.1811, 0.6704, 0.0405, 0.0008, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0199, 0.1490, 0.0943, 0.5614, 0.1610, 0.0120, 0.0025, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0080, 0.2619, 0.0700, 0.4251, 0.1586, 0.0328, 0.0435, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0193, 0.1426, 0.1509, 0.1169, 0.2367, 0.1744, 0.1591, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0212, 0.2398, 0.1746, 0.1521, 0.1851, 0.0945, 0.1327, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0040, 0.4602, 0.2633, 0.1046, 0.0482, 0.0537, 0.0660, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0132, 0.1103, 0.3252, 0.1034, 0.0660, 0.0806, 0.3014, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 8.00, Train Loss: 2.01, Val Loss: 4.17, Train BLEU: 23.82, Val BLEU: 10.77, Minutes Elapsed: 418.58\n",
      "Sampling from training predictions...\n",
      "Source: và cảm_xúc cuối_cùng là tự_hào . <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: and the last emotion of pride . <EOS> <PAD>\n",
      "Model: <SOS> and the the emotion was pride . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0000, 0.9758, 0.0234, 0.0008, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0007, 0.9116, 0.0871, 0.0006, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0003, 0.6787, 0.2945, 0.0177, 0.0087, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0003, 0.7525, 0.1131, 0.0664, 0.0654, 0.0018, 0.0006, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0112, 0.0180, 0.2953, 0.6309, 0.0381, 0.0064, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0030, 0.0025, 0.1397, 0.6276, 0.1803, 0.0468, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0220, 0.0564, 0.0667, 0.0737, 0.1840, 0.5972, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0399, 0.0081, 0.0188, 0.0170, 0.1156, 0.8005, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0007, 0.3274, 0.3608, 0.0438, 0.0809, 0.0311, 0.1553, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi đã được lớn_lên ở một quốc_gia đã bị tiêu_huỷ\n",
      "Reference: i was raised in a country that has been\n",
      "Model: <SOS> i &apos;ve been in in a that the been\n",
      "Attention Weights: tensor([[1.1476e-02, 3.4921e-01, 5.5044e-01, 8.8735e-02, 1.3864e-04, 1.6857e-06,\n",
      "         1.3020e-07, 4.6002e-08, 7.3250e-09, 4.1784e-09],\n",
      "        [2.1218e-04, 3.3615e-03, 7.9561e-01, 2.0035e-01, 4.6141e-04, 4.3135e-06,\n",
      "         5.2163e-07, 7.5015e-08, 5.4868e-08, 8.8475e-08],\n",
      "        [1.2080e-03, 1.2697e-02, 3.7804e-01, 5.7658e-01, 2.9245e-02, 1.4562e-03,\n",
      "         5.7665e-04, 5.6858e-05, 1.0562e-04, 3.4468e-05],\n",
      "        [1.1668e-04, 1.1160e-04, 2.1145e-02, 6.2646e-01, 3.3151e-01, 1.3864e-02,\n",
      "         5.9964e-03, 3.5346e-04, 2.8855e-04, 1.6238e-04],\n",
      "        [4.7269e-04, 2.4083e-04, 1.6890e-02, 3.0948e-01, 4.6199e-01, 8.5500e-02,\n",
      "         1.0765e-01, 8.1151e-03, 6.3802e-03, 3.2735e-03],\n",
      "        [6.9090e-05, 6.4099e-05, 1.7920e-03, 1.2333e-02, 7.9450e-02, 2.3992e-01,\n",
      "         5.1895e-01, 7.1306e-02, 4.8733e-02, 2.7386e-02],\n",
      "        [1.0216e-05, 3.9107e-05, 4.0572e-04, 5.6032e-04, 8.1759e-03, 2.8044e-02,\n",
      "         3.1796e-01, 2.8002e-01, 2.5500e-01, 1.0979e-01],\n",
      "        [3.8295e-06, 6.1855e-06, 8.8194e-05, 2.7922e-04, 5.5089e-03, 1.3318e-02,\n",
      "         2.4313e-01, 2.4140e-01, 4.2674e-01, 6.9519e-02],\n",
      "        [7.0523e-07, 1.1323e-06, 7.5721e-05, 1.0405e-03, 1.1074e-02, 5.9355e-02,\n",
      "         1.8661e-01, 7.4961e-02, 1.7460e-01, 4.9227e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8.05, Train Loss: 1.72, Val Loss: 4.20, Train BLEU: 28.98, Val BLEU: 10.52, Minutes Elapsed: 421.14\n",
      "Sampling from training predictions...\n",
      "Source: như bạn có_thể tưởng_tượng tôi căm_ghét cái khoảnh_khắc bóc toạc\n",
      "Reference: and as you can imagine , i hated that\n",
      "Model: <SOS> so you you can imagine my i hated ,\n",
      "Attention Weights: tensor([[9.9647e-01, 3.2496e-03, 2.8186e-04, 1.1607e-06, 6.3978e-09, 6.8808e-10,\n",
      "         5.1935e-10, 1.5467e-10, 5.3125e-10, 1.6267e-10],\n",
      "        [3.3256e-01, 4.8723e-01, 1.5837e-01, 1.9857e-02, 1.7739e-03, 1.7883e-04,\n",
      "         2.2920e-05, 8.7949e-06, 2.9103e-06, 2.6959e-06],\n",
      "        [1.8356e-02, 2.2702e-01, 2.8864e-01, 4.2816e-01, 2.3139e-02, 1.3060e-02,\n",
      "         1.2059e-03, 3.3756e-04, 3.9886e-05, 3.3803e-05],\n",
      "        [2.6725e-03, 4.0002e-02, 1.4999e-01, 7.7321e-01, 1.5462e-02, 1.7773e-02,\n",
      "         4.9918e-04, 3.5042e-04, 2.6953e-05, 1.3486e-05],\n",
      "        [2.8758e-03, 3.9310e-02, 1.2469e-01, 7.6036e-01, 2.7435e-02, 4.3203e-02,\n",
      "         1.3550e-03, 7.1175e-04, 4.2528e-05, 1.4812e-05],\n",
      "        [3.0780e-04, 2.5614e-03, 5.1826e-03, 5.3926e-01, 2.6875e-01, 1.7791e-01,\n",
      "         4.4295e-03, 1.3679e-03, 1.7228e-04, 5.5853e-05],\n",
      "        [3.6877e-05, 9.3891e-04, 3.0507e-03, 5.6823e-02, 5.3560e-01, 3.2463e-01,\n",
      "         4.5928e-02, 2.5213e-02, 4.6445e-03, 3.1423e-03],\n",
      "        [3.9886e-06, 4.8228e-05, 1.0954e-03, 1.2357e-02, 8.6594e-02, 5.1730e-01,\n",
      "         1.5046e-01, 1.9697e-01, 2.3974e-02, 1.1201e-02],\n",
      "        [2.7478e-05, 4.6784e-04, 1.6916e-02, 1.1285e-01, 4.3122e-02, 2.9926e-01,\n",
      "         1.2609e-01, 3.0057e-01, 7.9464e-02, 2.1229e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: rồi tờ l. a. times nhận được tin , steve\n",
      "Reference: so l.a. times got <UNK> of it . steve\n",
      "Model: <SOS> and i was a the understood , , ,\n",
      "Attention Weights: tensor([[9.9953e-01, 3.8586e-04, 8.6072e-05, 1.3384e-06, 1.4905e-08, 6.2381e-10,\n",
      "         4.4414e-11, 1.2598e-11, 8.0971e-13, 1.3936e-12],\n",
      "        [4.5255e-01, 3.1554e-01, 2.3055e-01, 6.4121e-04, 5.7539e-04, 1.1881e-04,\n",
      "         1.3453e-05, 1.2550e-05, 2.5832e-07, 2.6479e-07],\n",
      "        [7.8646e-03, 6.7663e-02, 9.0982e-01, 1.2478e-03, 1.0850e-02, 1.4175e-03,\n",
      "         4.5766e-04, 6.0396e-04, 4.6999e-05, 3.2237e-05],\n",
      "        [6.0818e-03, 8.6344e-02, 7.4196e-01, 7.6458e-03, 1.0119e-01, 2.3507e-02,\n",
      "         1.6225e-02, 1.5629e-02, 8.1723e-04, 5.9967e-04],\n",
      "        [8.5116e-06, 4.6455e-04, 7.1574e-02, 1.6160e-03, 5.0053e-01, 2.5776e-01,\n",
      "         4.7727e-02, 1.0890e-01, 6.3774e-03, 5.0457e-03],\n",
      "        [3.2285e-07, 1.4349e-06, 2.5186e-04, 1.8658e-04, 1.0205e-02, 2.2724e-01,\n",
      "         1.1970e-01, 4.1641e-01, 1.5785e-01, 6.8143e-02],\n",
      "        [2.4906e-06, 4.4373e-06, 5.1327e-04, 1.1583e-04, 2.3672e-03, 1.5813e-02,\n",
      "         1.8574e-02, 1.0798e-01, 3.3100e-01, 5.2364e-01],\n",
      "        [2.8430e-07, 1.8727e-06, 1.2455e-04, 6.8407e-05, 1.1177e-03, 3.4959e-02,\n",
      "         7.3701e-03, 1.2576e-02, 4.1798e-02, 9.0198e-01],\n",
      "        [1.5669e-07, 2.6316e-06, 4.4076e-05, 1.1934e-04, 9.0330e-04, 9.8422e-03,\n",
      "         9.2923e-03, 2.3528e-02, 2.3298e-01, 7.2329e-01]])\n",
      "\n",
      "Epoch: 8.10, Train Loss: 1.91, Val Loss: 4.19, Train BLEU: 25.63, Val BLEU: 11.25, Minutes Elapsed: 423.69\n",
      "Sampling from training predictions...\n",
      "Source: vâng , bước ra khỏi phòng thì nghiệm có_vẻ như_là\n",
      "Reference: well , coming out of the research labs just\n",
      "Model: <SOS> well , when of of the labs of like\n",
      "Attention Weights: tensor([[9.9812e-01, 1.8674e-03, 1.2142e-05, 1.0861e-06, 1.0409e-08, 9.9653e-10,\n",
      "         6.3992e-11, 7.2770e-11, 2.0391e-12, 1.9359e-12],\n",
      "        [2.7710e-01, 6.5942e-01, 5.6633e-02, 5.8950e-03, 8.2106e-04, 4.9213e-05,\n",
      "         3.5877e-05, 4.5961e-05, 3.3131e-06, 1.5805e-06],\n",
      "        [4.2758e-03, 3.9182e-02, 8.7176e-01, 3.8670e-02, 3.8215e-02, 4.4677e-03,\n",
      "         8.8439e-04, 2.3740e-03, 1.4191e-04, 2.8353e-05],\n",
      "        [2.1626e-04, 7.7730e-04, 1.8243e-01, 1.5864e-01, 5.5177e-01, 5.5510e-02,\n",
      "         8.3670e-03, 4.0054e-02, 1.8312e-03, 3.9932e-04],\n",
      "        [3.7477e-04, 6.4260e-04, 3.9904e-02, 1.2856e-01, 4.0247e-01, 2.5078e-01,\n",
      "         6.1179e-02, 1.0033e-01, 1.3572e-02, 2.1898e-03],\n",
      "        [3.4306e-06, 6.6116e-06, 1.1965e-03, 2.9785e-03, 3.8127e-02, 1.2491e-01,\n",
      "         1.8147e-01, 5.7137e-01, 7.3122e-02, 6.8200e-03],\n",
      "        [1.2285e-06, 8.1819e-07, 3.9873e-04, 5.8881e-04, 1.6822e-02, 1.1228e-01,\n",
      "         4.9706e-02, 7.8399e-01, 3.2202e-02, 4.0118e-03],\n",
      "        [2.7083e-06, 3.4427e-06, 3.0932e-04, 4.0024e-04, 1.1590e-03, 1.4702e-03,\n",
      "         1.0277e-01, 2.9631e-01, 5.3429e-01, 6.3285e-02],\n",
      "        [8.3720e-06, 1.2636e-05, 5.4539e-04, 1.2469e-03, 2.8407e-03, 2.5482e-03,\n",
      "         1.2040e-01, 4.0794e-01, 4.2800e-01, 3.6455e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: khi lớn lên , em trở_nên càng khác_biệt , và\n",
      "Reference: and as he grew older , he grew more\n",
      "Model: <SOS> when i i grew older , i became to\n",
      "Attention Weights: tensor([[9.6838e-01, 3.1592e-02, 2.2558e-05, 1.1820e-06, 6.7230e-08, 8.8619e-09,\n",
      "         9.7344e-09, 1.8004e-09, 5.2965e-11, 1.2161e-11],\n",
      "        [3.9956e-03, 9.5823e-01, 3.5669e-02, 1.6560e-03, 1.3872e-04, 2.7867e-04,\n",
      "         2.5757e-05, 6.6667e-06, 8.4413e-07, 2.2957e-07],\n",
      "        [9.1428e-04, 5.1142e-01, 4.2994e-01, 2.7754e-02, 8.8670e-03, 1.8118e-02,\n",
      "         1.9414e-03, 9.7994e-04, 4.1892e-05, 2.3524e-05],\n",
      "        [1.4170e-03, 3.1181e-01, 5.5876e-01, 8.2937e-02, 9.5643e-03, 2.1773e-02,\n",
      "         9.7809e-03, 3.7981e-03, 1.0892e-04, 5.1042e-05],\n",
      "        [9.5657e-04, 1.4467e-01, 4.9423e-01, 2.0700e-01, 2.6727e-02, 8.3362e-02,\n",
      "         2.4149e-02, 1.8490e-02, 3.0735e-04, 1.1061e-04],\n",
      "        [3.6408e-05, 1.3318e-02, 1.6722e-01, 2.2970e-01, 5.9905e-02, 2.9761e-01,\n",
      "         1.4238e-01, 7.9215e-02, 7.7527e-03, 2.8551e-03],\n",
      "        [2.4028e-07, 2.1278e-04, 1.0133e-03, 5.9606e-03, 2.4132e-02, 7.9722e-01,\n",
      "         1.3039e-01, 2.5632e-02, 5.8117e-03, 9.6248e-03],\n",
      "        [4.6233e-08, 9.8333e-05, 2.6282e-04, 1.7422e-03, 8.1630e-03, 6.8194e-01,\n",
      "         2.4391e-01, 5.7918e-02, 3.1207e-03, 2.8428e-03],\n",
      "        [1.1885e-05, 1.0155e-03, 1.4537e-02, 3.3910e-03, 1.5464e-03, 2.5207e-01,\n",
      "         5.9849e-01, 1.1885e-01, 8.3068e-03, 1.7823e-03]])\n",
      "\n",
      "Epoch: 8.14, Train Loss: 1.93, Val Loss: 4.18, Train BLEU: 24.95, Val BLEU: 11.15, Minutes Elapsed: 426.26\n",
      "Sampling from training predictions...\n",
      "Source: bạn có_thể lập_trình cho hàng trăm cơ_bắp trong cánh_tay .\n",
      "Reference: you can program the hundreds of muscles in your\n",
      "Model: <SOS> you can be hundreds hundreds of muscles in your\n",
      "Attention Weights: tensor([[4.4270e-01, 5.5175e-01, 5.4784e-03, 4.9793e-05, 1.3065e-05, 4.2899e-06,\n",
      "         2.9858e-06, 9.3930e-08, 3.6924e-08, 9.4553e-10],\n",
      "        [5.7647e-02, 1.8667e-01, 7.3897e-01, 1.0179e-02, 4.9743e-03, 1.4394e-03,\n",
      "         4.6770e-05, 6.1402e-05, 9.3163e-06, 1.1307e-06],\n",
      "        [1.8652e-02, 4.4583e-02, 8.2695e-01, 7.7443e-02, 1.8867e-02, 1.3172e-02,\n",
      "         2.9403e-04, 3.2910e-05, 4.6185e-06, 7.6701e-07],\n",
      "        [7.6554e-04, 4.5896e-04, 3.0917e-01, 1.5763e-01, 4.4827e-01, 7.8614e-02,\n",
      "         4.3321e-03, 6.0278e-04, 1.3759e-04, 9.9957e-06],\n",
      "        [4.8705e-04, 1.9756e-04, 4.6429e-02, 2.2519e-02, 4.5111e-01, 4.4216e-01,\n",
      "         2.0150e-02, 1.0553e-02, 5.8546e-03, 5.4628e-04],\n",
      "        [1.0400e-04, 1.0177e-04, 1.3928e-03, 2.8091e-03, 1.8301e-01, 3.7056e-01,\n",
      "         1.4173e-01, 1.9890e-01, 9.4426e-02, 6.9628e-03],\n",
      "        [3.9471e-05, 8.8439e-05, 7.7940e-04, 2.0861e-03, 1.1623e-01, 3.5606e-01,\n",
      "         1.6231e-01, 1.5227e-01, 1.7910e-01, 3.1040e-02],\n",
      "        [2.6726e-06, 1.0238e-05, 1.2633e-04, 2.5501e-04, 4.1211e-03, 1.1440e-02,\n",
      "         3.6809e-02, 5.1295e-01, 3.9401e-01, 4.0278e-02],\n",
      "        [1.3671e-05, 2.6579e-05, 2.5325e-04, 3.6031e-04, 1.5255e-03, 6.5194e-03,\n",
      "         1.2657e-02, 4.3434e-01, 4.0828e-01, 1.3603e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: bạn phải đưa đến cho họ sự bảo_mật , riêng_tư\n",
      "Reference: you have to offer them <UNK> , privacy ,\n",
      "Model: <SOS> you have to to them them , , ,\n",
      "Attention Weights: tensor([[8.6865e-02, 9.1278e-01, 3.2909e-04, 2.4700e-05, 1.0208e-06, 3.8601e-08,\n",
      "         1.4363e-08, 2.9372e-09, 4.5711e-11, 3.1950e-10],\n",
      "        [1.5361e-03, 9.9029e-01, 7.6350e-03, 5.1023e-04, 2.5841e-05, 1.3548e-06,\n",
      "         5.9714e-07, 2.7371e-07, 1.1002e-08, 2.7274e-08],\n",
      "        [2.5345e-03, 7.0684e-01, 2.2309e-01, 6.0215e-02, 6.8639e-03, 3.3899e-04,\n",
      "         6.8633e-05, 4.5185e-05, 1.8526e-06, 2.4498e-06],\n",
      "        [6.2509e-04, 8.8158e-03, 3.2086e-01, 5.6128e-01, 7.1505e-02, 3.0441e-02,\n",
      "         3.7181e-03, 2.7140e-03, 2.0448e-05, 1.7303e-05],\n",
      "        [1.3280e-04, 3.2497e-03, 2.3559e-02, 3.3143e-01, 3.8057e-01, 1.8407e-01,\n",
      "         4.8365e-02, 2.8023e-02, 3.4268e-04, 2.5339e-04],\n",
      "        [6.3388e-05, 2.4980e-04, 2.3791e-03, 4.8642e-02, 2.6577e-01, 3.0816e-01,\n",
      "         2.3048e-01, 1.4232e-01, 1.3256e-03, 6.1489e-04],\n",
      "        [2.4550e-06, 1.4720e-05, 2.7652e-04, 2.7334e-03, 6.2480e-02, 7.1303e-02,\n",
      "         2.8578e-01, 5.2378e-01, 2.7465e-02, 2.6166e-02],\n",
      "        [3.7174e-06, 9.4758e-06, 8.4856e-05, 6.1052e-04, 9.8944e-03, 1.0827e-02,\n",
      "         7.9792e-02, 1.3244e-01, 2.5160e-01, 5.1473e-01],\n",
      "        [2.1460e-04, 2.7755e-04, 1.3142e-04, 5.7156e-04, 1.2032e-02, 2.2313e-03,\n",
      "         2.6480e-02, 4.0704e-02, 1.3212e-01, 7.8524e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8.19, Train Loss: 2.06, Val Loss: 4.20, Train BLEU: 22.59, Val BLEU: 10.86, Minutes Elapsed: 428.85\n",
      "Sampling from training predictions...\n",
      "Source: những ca_sĩ khác sau_đó còn tiến xa hơn . <EOS>\n",
      "Reference: other singers after him went even further . <EOS>\n",
      "Model: <SOS> the singers are later later . . . <EOS>\n",
      "Attention Weights: tensor([[6.8754e-01, 2.5947e-01, 4.0703e-02, 1.2226e-02, 4.7873e-05, 4.3033e-06,\n",
      "         7.1666e-07, 1.1204e-07, 3.3035e-09, 2.9650e-10],\n",
      "        [2.8247e-02, 3.7926e-01, 4.3676e-01, 1.5214e-01, 2.9044e-03, 5.6976e-04,\n",
      "         7.4615e-05, 3.0032e-05, 3.7263e-06, 1.5406e-06],\n",
      "        [2.6069e-03, 2.5170e-02, 5.6074e-02, 7.3946e-01, 1.2899e-01, 3.5211e-02,\n",
      "         5.2856e-03, 7.0175e-03, 1.6870e-04, 2.5242e-05],\n",
      "        [1.6650e-03, 1.6730e-02, 5.0185e-02, 7.0650e-01, 1.5253e-01, 4.5999e-02,\n",
      "         6.2152e-03, 1.9742e-02, 3.9112e-04, 4.4367e-05],\n",
      "        [8.8937e-04, 1.1512e-02, 1.8904e-02, 3.2372e-01, 2.7539e-01, 9.8134e-02,\n",
      "         6.2477e-02, 2.0487e-01, 3.2913e-03, 8.1463e-04],\n",
      "        [6.0485e-05, 1.5617e-03, 5.3460e-04, 4.3108e-02, 2.1293e-01, 2.2098e-01,\n",
      "         9.9434e-02, 3.6819e-01, 4.6864e-02, 6.3413e-03],\n",
      "        [8.7102e-05, 1.1961e-03, 4.0054e-04, 4.0611e-03, 1.9221e-02, 1.0549e-01,\n",
      "         3.3977e-01, 4.7985e-01, 3.7300e-02, 1.2634e-02],\n",
      "        [2.6185e-04, 2.4804e-03, 5.1133e-04, 3.1767e-03, 2.5648e-02, 8.0671e-02,\n",
      "         2.2444e-01, 5.3058e-01, 7.6018e-02, 5.6218e-02],\n",
      "        [5.6968e-04, 6.4149e-03, 4.1828e-04, 9.1455e-03, 3.2083e-02, 1.0312e-01,\n",
      "         1.9098e-01, 3.1281e-01, 1.7987e-01, 1.6459e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: đây là một trong những kế_hoạch của tôi . đây\n",
      "Reference: now this is one of my plans . this\n",
      "Model: <SOS> this is one one of my favorites . this\n",
      "Attention Weights: tensor([[9.2386e-01, 7.1243e-02, 4.8970e-03, 1.9040e-06, 1.7605e-08, 7.0886e-10,\n",
      "         3.1451e-11, 2.6415e-11, 4.6329e-12, 7.9776e-12],\n",
      "        [2.6533e-02, 5.8982e-01, 3.4752e-01, 3.1706e-02, 2.9683e-03, 1.4214e-03,\n",
      "         1.2862e-05, 7.2587e-06, 2.4491e-06, 3.1929e-06],\n",
      "        [2.8022e-02, 4.0849e-01, 2.7007e-01, 2.7282e-01, 1.2904e-02, 6.9704e-03,\n",
      "         4.4635e-04, 2.6699e-04, 1.0066e-05, 3.5004e-06],\n",
      "        [6.2587e-03, 3.2709e-01, 1.4652e-01, 4.8468e-01, 2.5156e-02, 9.3331e-03,\n",
      "         4.4917e-04, 4.9830e-04, 8.1884e-06, 4.6179e-06],\n",
      "        [4.2295e-05, 9.2569e-03, 1.3042e-02, 7.1490e-01, 1.5605e-01, 1.0276e-01,\n",
      "         1.8864e-03, 1.8711e-03, 1.2580e-04, 6.9245e-05],\n",
      "        [2.0308e-05, 2.9482e-03, 3.2461e-03, 6.8095e-01, 2.2636e-01, 7.8555e-02,\n",
      "         3.3834e-03, 3.5350e-03, 6.5902e-04, 3.4530e-04],\n",
      "        [3.9592e-06, 2.1556e-04, 1.5228e-04, 4.6208e-02, 5.5496e-02, 8.1656e-01,\n",
      "         3.1798e-02, 2.2630e-02, 9.7791e-03, 1.7158e-02],\n",
      "        [4.9774e-03, 3.5462e-02, 1.4740e-03, 4.9312e-02, 1.9296e-02, 2.4070e-02,\n",
      "         1.3154e-01, 3.1846e-02, 3.4372e-01, 3.5831e-01],\n",
      "        [5.9374e-06, 8.9849e-05, 9.3528e-05, 6.7204e-04, 1.2124e-04, 2.4267e-04,\n",
      "         4.3409e-04, 1.8479e-03, 2.3126e-01, 7.6523e-01]])\n",
      "\n",
      "Epoch: 8.24, Train Loss: 2.06, Val Loss: 4.19, Train BLEU: 22.22, Val BLEU: 11.28, Minutes Elapsed: 431.40\n",
      "Sampling from training predictions...\n",
      "Source: chúng_tôi phải bay với độ nghiêng đặc_biệt để thực_hiện các\n",
      "Reference: we have to fly at a special incline in\n",
      "Model: <SOS> we have to fly the the incline incline to\n",
      "Attention Weights: tensor([[8.8939e-03, 9.9021e-01, 8.5357e-04, 4.0842e-05, 2.4585e-06, 1.9675e-06,\n",
      "         4.2459e-07, 2.2549e-08, 6.4120e-09, 7.6663e-10],\n",
      "        [7.9690e-04, 9.9148e-01, 7.7000e-03, 1.0181e-05, 5.1553e-06, 3.6377e-06,\n",
      "         1.8318e-06, 2.1713e-07, 2.1154e-07, 6.6776e-08],\n",
      "        [2.2040e-03, 7.8934e-01, 2.0504e-01, 2.0930e-03, 7.5531e-04, 3.6331e-04,\n",
      "         1.7664e-04, 1.3598e-05, 9.4363e-06, 6.3863e-06],\n",
      "        [5.2296e-04, 1.0273e-02, 8.8651e-01, 4.9927e-02, 2.9532e-02, 1.3186e-02,\n",
      "         9.3550e-03, 2.7382e-04, 2.9626e-04, 1.2460e-04],\n",
      "        [3.3521e-05, 2.6773e-03, 1.6671e-01, 3.7883e-01, 2.4901e-01, 1.2237e-01,\n",
      "         7.5539e-02, 2.6581e-03, 1.5556e-03, 6.1796e-04],\n",
      "        [4.0273e-05, 8.8350e-05, 1.2357e-02, 6.2040e-02, 1.8857e-01, 2.9418e-01,\n",
      "         4.3267e-01, 7.2327e-03, 1.5888e-03, 1.2392e-03],\n",
      "        [2.3804e-06, 5.6552e-06, 9.5507e-04, 3.6116e-02, 1.6281e-01, 4.7888e-01,\n",
      "         2.9737e-01, 1.5121e-02, 7.5022e-03, 1.2386e-03],\n",
      "        [7.9359e-06, 1.2746e-04, 2.1181e-04, 1.1211e-02, 4.8717e-02, 4.2585e-01,\n",
      "         1.4449e-01, 2.2561e-01, 1.3368e-01, 1.0093e-02],\n",
      "        [4.4828e-07, 4.6474e-05, 6.0179e-05, 1.6031e-03, 1.2205e-02, 1.7603e-01,\n",
      "         9.8017e-02, 2.9112e-01, 3.9166e-01, 2.9248e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi đã không_tưởng được những gì xảy đến với cuộc_sống\n",
      "Reference: i had no idea what life was going to\n",
      "Model: <SOS> i didn &apos;t idea what to to to to\n",
      "Attention Weights: tensor([[3.9001e-03, 1.8805e-01, 8.0416e-01, 3.8664e-03, 1.6539e-05, 3.8620e-06,\n",
      "         1.5946e-06, 3.9067e-07, 4.9129e-08, 2.4059e-08],\n",
      "        [4.9043e-04, 1.1191e-02, 9.7730e-01, 1.0493e-02, 4.2209e-04, 2.3639e-05,\n",
      "         6.2396e-05, 9.8680e-06, 4.1484e-06, 1.2247e-06],\n",
      "        [1.2397e-03, 3.9416e-02, 7.3975e-01, 1.9487e-01, 2.2636e-02, 1.2641e-03,\n",
      "         5.6392e-04, 1.8785e-04, 4.4591e-05, 2.2536e-05],\n",
      "        [1.7757e-04, 3.9217e-04, 1.0054e-01, 6.5280e-01, 1.7885e-01, 3.8951e-02,\n",
      "         2.2617e-02, 4.8741e-03, 6.3856e-04, 1.5688e-04],\n",
      "        [4.5635e-05, 8.6090e-06, 2.4970e-03, 6.7990e-02, 1.6854e-01, 4.0668e-01,\n",
      "         2.4792e-01, 7.8544e-02, 2.2075e-02, 5.6943e-03],\n",
      "        [4.7372e-05, 5.9865e-05, 3.6230e-03, 6.8018e-03, 1.0153e-02, 1.3736e-01,\n",
      "         3.6736e-01, 1.6782e-01, 1.9487e-01, 1.1191e-01],\n",
      "        [6.3686e-06, 6.2304e-06, 5.6502e-03, 3.8256e-03, 7.4688e-03, 6.2997e-02,\n",
      "         2.0400e-01, 2.3072e-01, 2.6653e-01, 2.1880e-01],\n",
      "        [1.5911e-03, 1.3356e-04, 1.7008e-01, 1.6770e-02, 2.2316e-02, 5.6664e-02,\n",
      "         1.0774e-01, 2.4801e-01, 2.2087e-01, 1.5583e-01],\n",
      "        [8.9212e-05, 2.9049e-05, 6.3976e-03, 1.0528e-03, 1.4109e-03, 2.6955e-02,\n",
      "         2.9621e-02, 8.2526e-02, 2.2769e-01, 6.2423e-01]])\n",
      "\n",
      "Epoch: 8.29, Train Loss: 2.14, Val Loss: 4.24, Train BLEU: 21.54, Val BLEU: 10.87, Minutes Elapsed: 433.96\n",
      "Sampling from training predictions...\n",
      "Source: ngay_cả nếu có như_vậy , hay_là như thế_nào khác ,\n",
      "Reference: whether it &apos;s with this , whether it &apos;s\n",
      "Model: <SOS> even if there like , , , that &apos;s\n",
      "Attention Weights: tensor([[9.8144e-01, 3.3925e-04, 1.8164e-02, 5.2130e-05, 1.1925e-06, 6.3625e-07,\n",
      "         8.2170e-08, 2.7810e-08, 1.7382e-09, 4.1375e-13],\n",
      "        [1.8533e-02, 1.9492e-02, 9.6168e-01, 2.5089e-04, 2.7082e-05, 1.2998e-05,\n",
      "         2.5123e-06, 5.7749e-07, 1.3022e-07, 3.3782e-09],\n",
      "        [2.5632e-02, 1.8037e-02, 8.8656e-01, 4.8913e-02, 1.3554e-02, 7.0095e-03,\n",
      "         1.5118e-04, 6.0260e-05, 7.1976e-05, 7.6669e-06],\n",
      "        [3.3463e-03, 4.2311e-03, 9.1034e-01, 5.2635e-02, 1.6585e-02, 1.0821e-02,\n",
      "         9.5056e-04, 4.4597e-04, 5.9852e-04, 4.8093e-05],\n",
      "        [2.9688e-03, 4.5399e-03, 2.8744e-01, 2.2475e-01, 2.8548e-01, 1.7784e-01,\n",
      "         7.4902e-03, 2.8793e-03, 5.4414e-03, 1.1678e-03],\n",
      "        [3.7604e-03, 2.8692e-03, 1.7016e-01, 3.4833e-02, 3.1685e-01, 4.4359e-01,\n",
      "         8.0430e-03, 4.3210e-03, 1.2071e-02, 3.4933e-03],\n",
      "        [1.1916e-03, 2.4290e-03, 7.4714e-02, 8.4155e-03, 1.4631e-01, 7.0384e-01,\n",
      "         1.1932e-02, 1.7766e-02, 2.0773e-02, 1.2631e-02],\n",
      "        [1.0081e-03, 3.7365e-03, 3.8271e-01, 9.5290e-03, 7.9771e-02, 3.0638e-01,\n",
      "         4.1444e-02, 5.8529e-02, 9.6590e-02, 2.0299e-02],\n",
      "        [2.0991e-04, 3.1298e-04, 5.8190e-02, 3.2288e-03, 3.8730e-03, 3.1339e-02,\n",
      "         5.8638e-02, 2.0768e-01, 5.6795e-01, 6.8571e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: những phụ_nữ lớn_tuổi đôi_khi chưa_từng nhìn_thấy máy scan , nhưng\n",
      "Reference: the older ladies sometimes hadn &apos;t seen a scanner\n",
      "Model: <SOS> the babies who are at at the , ,\n",
      "Attention Weights: tensor([[2.4529e-01, 4.5136e-01, 3.0214e-01, 1.2047e-03, 8.8553e-06, 2.4464e-07,\n",
      "         1.2122e-08, 7.0034e-09, 4.7765e-09, 1.4334e-09],\n",
      "        [4.6940e-03, 6.4333e-02, 8.8465e-01, 3.7802e-02, 7.8242e-03, 6.1605e-04,\n",
      "         5.5608e-05, 1.2331e-05, 1.0019e-05, 4.0446e-06],\n",
      "        [2.0105e-04, 1.3361e-02, 3.3991e-01, 2.4927e-01, 3.4408e-01, 3.5489e-02,\n",
      "         1.6497e-02, 6.2746e-04, 4.8097e-04, 8.7169e-05],\n",
      "        [4.6109e-05, 1.5181e-03, 4.8330e-02, 1.7752e-01, 5.1193e-01, 1.5975e-01,\n",
      "         9.4394e-02, 3.9203e-03, 2.1227e-03, 4.7093e-04],\n",
      "        [5.1194e-06, 9.4767e-04, 2.3132e-02, 5.2973e-02, 4.2712e-01, 2.4850e-01,\n",
      "         1.8727e-01, 3.8014e-02, 1.7485e-02, 4.5571e-03],\n",
      "        [5.1834e-08, 1.7368e-05, 4.1047e-04, 9.1529e-03, 9.4975e-02, 2.1666e-01,\n",
      "         3.1364e-01, 1.4370e-01, 1.5533e-01, 6.6112e-02],\n",
      "        [9.8919e-08, 1.3994e-05, 1.0536e-04, 1.8658e-03, 1.2753e-01, 1.9434e-01,\n",
      "         2.8910e-01, 1.4797e-01, 1.1337e-01, 1.2570e-01],\n",
      "        [2.9399e-06, 5.8684e-05, 1.6528e-04, 1.5823e-03, 5.8748e-02, 1.5015e-01,\n",
      "         3.8342e-01, 2.7103e-01, 5.8326e-02, 7.6518e-02],\n",
      "        [9.6383e-07, 4.6948e-05, 5.4986e-05, 5.3845e-04, 2.1478e-02, 8.4978e-02,\n",
      "         1.9322e-01, 4.2198e-01, 7.1695e-02, 2.0600e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8.34, Train Loss: 2.13, Val Loss: 4.22, Train BLEU: 21.09, Val BLEU: 10.46, Minutes Elapsed: 436.50\n",
      "Sampling from training predictions...\n",
      "Source: chúng_tôi phải thay_đổi kế_hoạch của mình . <EOS> <PAD> <PAD>\n",
      "Reference: we needed to change our schedule . <EOS> <PAD>\n",
      "Model: <SOS> we have to change our schedule . <EOS> .\n",
      "Attention Weights: tensor([[0.0159, 0.9840, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0015, 0.9978, 0.0007, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0003, 0.9152, 0.0768, 0.0074, 0.0001, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0005, 0.0135, 0.7201, 0.2626, 0.0019, 0.0012, 0.0001, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0057, 0.1359, 0.6991, 0.0982, 0.0588, 0.0017, 0.0006, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0009, 0.0530, 0.8390, 0.0568, 0.0485, 0.0014, 0.0004, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0008, 0.0050, 0.0095, 0.0967, 0.1631, 0.5620, 0.1166, 0.0463, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0005, 0.0018, 0.0075, 0.0106, 0.1952, 0.4959, 0.2884, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0650, 0.0812, 0.0041, 0.0272, 0.0239, 0.1640, 0.2381, 0.3963, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: từ khi còn nhỏ , tôi đã từng làm_việc ở\n",
      "Reference: since i was a small boy , i used\n",
      "Model: <SOS> from , a a kid of , i was\n",
      "Attention Weights: tensor([[9.6627e-01, 2.2127e-02, 1.0970e-02, 6.3486e-04, 1.8380e-07, 1.7603e-08,\n",
      "         1.0290e-08, 2.8694e-07, 1.6833e-08, 6.4145e-09],\n",
      "        [1.3715e-01, 8.6332e-02, 3.8025e-01, 3.9400e-01, 2.0273e-03, 4.2919e-05,\n",
      "         4.2071e-05, 1.1853e-04, 2.6129e-05, 9.8846e-06],\n",
      "        [4.4049e-02, 6.1734e-02, 5.7273e-01, 2.7477e-01, 3.1566e-02, 2.0815e-03,\n",
      "         3.3175e-03, 7.3900e-03, 2.1174e-03, 2.5046e-04],\n",
      "        [8.4648e-03, 2.6465e-02, 3.8537e-01, 1.6635e-01, 2.4450e-01, 1.1263e-02,\n",
      "         1.7706e-02, 7.2748e-02, 6.0303e-02, 6.8268e-03],\n",
      "        [2.2775e-03, 3.7988e-03, 8.1323e-02, 7.0792e-02, 1.0998e-02, 1.7011e-03,\n",
      "         9.7268e-04, 6.0485e-02, 6.5669e-01, 1.1096e-01],\n",
      "        [1.8256e-02, 2.9249e-02, 5.0047e-01, 1.6102e-01, 5.6377e-02, 3.2845e-03,\n",
      "         1.7839e-03, 1.4607e-02, 1.4474e-01, 7.0206e-02],\n",
      "        [2.2911e-03, 1.8152e-02, 3.7907e-01, 1.3224e-01, 1.6448e-01, 2.8712e-02,\n",
      "         1.0385e-02, 3.1810e-02, 7.1960e-02, 1.6089e-01],\n",
      "        [4.9797e-04, 7.0018e-03, 1.9095e-01, 5.2294e-02, 2.1562e-01, 7.6760e-02,\n",
      "         8.3221e-02, 8.8882e-02, 7.5398e-02, 2.0937e-01],\n",
      "        [8.8646e-05, 3.0168e-04, 2.2601e-02, 3.6028e-02, 4.2377e-02, 3.0931e-02,\n",
      "         1.5492e-01, 3.4804e-01, 2.3856e-01, 1.2616e-01]])\n",
      "\n",
      "Epoch: 8.38, Train Loss: 2.12, Val Loss: 4.20, Train BLEU: 21.49, Val BLEU: 10.78, Minutes Elapsed: 439.09\n",
      "Sampling from training predictions...\n",
      "Source: bây_giờ , nếu chúng_ta nghĩ đến thị_trường chứng_khoán nghĩ đến\n",
      "Reference: now , if we think about this in terms\n",
      "Model: <SOS> now , if we think of the political ,\n",
      "Attention Weights: tensor([[9.9988e-01, 1.1805e-04, 1.6991e-07, 5.6571e-09, 6.1019e-09, 4.6010e-11,\n",
      "         3.7215e-11, 1.1319e-11, 9.9503e-12, 3.7847e-13],\n",
      "        [5.8530e-02, 1.6513e-01, 7.7326e-01, 2.6357e-03, 4.0833e-04, 2.9386e-05,\n",
      "         9.3932e-06, 1.8499e-06, 2.9582e-07, 1.1076e-07],\n",
      "        [8.2569e-03, 7.3837e-02, 8.1725e-01, 7.3210e-02, 2.2041e-02, 4.2702e-03,\n",
      "         7.4867e-04, 3.5100e-04, 2.6144e-05, 1.0222e-05],\n",
      "        [6.0747e-04, 2.0418e-03, 4.2334e-02, 3.1019e-01, 6.0565e-01, 1.9198e-02,\n",
      "         1.2925e-02, 6.6219e-03, 3.4707e-04, 8.3696e-05],\n",
      "        [1.8171e-03, 5.0622e-03, 2.9661e-02, 4.4023e-02, 8.5676e-01, 5.1909e-02,\n",
      "         7.3166e-03, 3.1275e-03, 2.6150e-04, 6.6619e-05],\n",
      "        [1.5357e-03, 3.4407e-03, 6.6490e-03, 2.3488e-02, 5.8614e-01, 3.0757e-01,\n",
      "         4.7712e-02, 2.1080e-02, 2.0204e-03, 3.5988e-04],\n",
      "        [1.8877e-04, 9.5363e-05, 4.9664e-04, 3.0384e-04, 1.1667e-02, 1.1402e-01,\n",
      "         7.2813e-01, 1.3827e-01, 5.8371e-03, 9.9195e-04],\n",
      "        [5.0669e-06, 1.6989e-05, 1.4455e-05, 8.1067e-05, 8.7439e-04, 1.8228e-02,\n",
      "         8.3678e-01, 1.3459e-01, 7.4629e-03, 1.9458e-03],\n",
      "        [1.7235e-05, 1.0415e-04, 2.2431e-05, 9.4132e-05, 3.8292e-04, 1.1232e-02,\n",
      "         6.7434e-01, 2.1973e-01, 7.5197e-02, 1.8874e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tiền_của con có_thể bị cướp mất . con có_thể bị\n",
      "Reference: your money can be stolen . you can be\n",
      "Model: <SOS> the can can be be . she could get\n",
      "Attention Weights: tensor([[9.8407e-01, 1.5868e-02, 6.3754e-05, 2.3735e-06, 3.5595e-07, 9.9074e-08,\n",
      "         6.4149e-09, 1.1163e-09, 1.0064e-09, 2.0851e-09],\n",
      "        [4.5547e-01, 4.1483e-01, 1.2434e-01, 3.8117e-03, 1.3753e-03, 1.5208e-04,\n",
      "         7.9671e-06, 4.2437e-06, 7.5860e-06, 1.6126e-06],\n",
      "        [3.0105e-02, 4.0709e-02, 3.5849e-01, 4.2668e-01, 1.1423e-01, 2.8109e-02,\n",
      "         7.3592e-04, 2.3757e-04, 3.2386e-04, 3.7516e-04],\n",
      "        [7.4095e-04, 1.3686e-02, 2.0415e-01, 6.1586e-01, 1.3327e-01, 3.1443e-02,\n",
      "         4.3371e-04, 4.8894e-05, 1.2185e-04, 2.4256e-04],\n",
      "        [1.3704e-03, 5.5098e-03, 2.8588e-02, 3.6217e-01, 4.8170e-01, 1.1125e-01,\n",
      "         6.3897e-03, 8.3083e-04, 6.4299e-04, 1.5497e-03],\n",
      "        [2.0562e-03, 9.9685e-04, 1.5245e-03, 4.2871e-02, 3.9494e-01, 4.3841e-01,\n",
      "         6.6909e-02, 2.9813e-02, 3.6769e-03, 1.8809e-02],\n",
      "        [5.5509e-04, 1.0446e-03, 4.5740e-03, 9.6259e-03, 3.3779e-02, 6.3281e-02,\n",
      "         2.3949e-01, 5.8983e-01, 3.5160e-02, 2.2660e-02],\n",
      "        [9.3077e-04, 7.4135e-04, 4.1732e-03, 6.6634e-03, 7.0166e-03, 7.2601e-03,\n",
      "         1.1807e-01, 5.3457e-01, 2.1076e-01, 1.0982e-01],\n",
      "        [1.0670e-03, 5.5356e-04, 4.0305e-03, 1.5136e-01, 4.6068e-02, 1.1219e-02,\n",
      "         2.1969e-02, 2.4222e-02, 1.6836e-01, 5.7115e-01]])\n",
      "\n",
      "Epoch: 8.43, Train Loss: 2.20, Val Loss: 4.18, Train BLEU: 20.93, Val BLEU: 11.12, Minutes Elapsed: 441.62\n",
      "Sampling from training predictions...\n",
      "Source: đây là phòng nghiên_cứu khói bụi euphore ở tây ban\n",
      "Reference: this is the euphore smog chamber in spain .\n",
      "Model: <SOS> this is a <UNK> that <UNK> sweden in .\n",
      "Attention Weights: tensor([[9.6617e-01, 3.3810e-02, 1.5027e-05, 6.6447e-07, 9.6337e-09, 1.4532e-10,\n",
      "         4.8829e-11, 2.7470e-11, 1.6159e-11, 2.7987e-12],\n",
      "        [1.0420e-02, 8.4902e-01, 1.3544e-01, 3.5884e-03, 1.4683e-03, 4.0943e-05,\n",
      "         9.8404e-06, 6.3500e-06, 1.7164e-06, 4.2774e-07],\n",
      "        [3.1895e-02, 3.1691e-01, 4.9560e-01, 8.9735e-02, 6.1382e-02, 3.5760e-03,\n",
      "         6.1330e-04, 1.4223e-04, 1.1396e-04, 3.1533e-05],\n",
      "        [1.6294e-04, 1.6330e-02, 1.9742e-01, 1.7991e-01, 5.8554e-01, 1.7165e-02,\n",
      "         1.8088e-03, 1.2388e-03, 3.1745e-04, 1.0473e-04],\n",
      "        [1.1132e-05, 1.6909e-02, 1.9381e-01, 4.8160e-01, 2.7641e-01, 2.6529e-02,\n",
      "         1.7535e-03, 2.1613e-03, 6.5162e-04, 1.6774e-04],\n",
      "        [3.3528e-06, 1.8945e-03, 4.1491e-02, 1.7364e-01, 6.5813e-01, 1.0812e-01,\n",
      "         8.2847e-03, 5.5521e-03, 1.6213e-03, 1.2605e-03],\n",
      "        [1.9402e-05, 3.6592e-03, 2.5534e-02, 4.1575e-01, 4.9076e-01, 4.4699e-02,\n",
      "         1.0715e-02, 6.3082e-03, 2.0495e-03, 5.0481e-04],\n",
      "        [4.1811e-07, 6.7526e-06, 5.5990e-04, 4.5914e-03, 1.7749e-02, 5.5328e-02,\n",
      "         5.2298e-02, 3.8549e-01, 3.2204e-01, 1.6194e-01],\n",
      "        [1.0978e-05, 1.4489e-05, 3.2550e-05, 4.6190e-04, 8.5986e-04, 7.6677e-03,\n",
      "         1.4803e-02, 2.9758e-01, 4.1598e-01, 2.6259e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: những chúng mang hai_nghĩa khác_biệt . <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: but they mean two different things . <EOS> <PAD>\n",
      "Model: <SOS> they they have different different . <EOS> <EOS> .\n",
      "Attention Weights: tensor([[0.9090, 0.0859, 0.0023, 0.0014, 0.0014, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1123, 0.4624, 0.2266, 0.1891, 0.0096, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0464, 0.0385, 0.1902, 0.6748, 0.0475, 0.0023, 0.0003, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1121, 0.1362, 0.1151, 0.5187, 0.1128, 0.0044, 0.0007, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0017, 0.0029, 0.0212, 0.5735, 0.3746, 0.0228, 0.0032, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0280, 0.0390, 0.0331, 0.4432, 0.4124, 0.0344, 0.0099, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0045, 0.0366, 0.0121, 0.1023, 0.4771, 0.1835, 0.1838, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0028, 0.0223, 0.0187, 0.0494, 0.1775, 0.1962, 0.5332, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0040, 0.0230, 0.0212, 0.1766, 0.1667, 0.1377, 0.4709, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8.48, Train Loss: 2.18, Val Loss: 4.17, Train BLEU: 19.76, Val BLEU: 11.03, Minutes Elapsed: 444.17\n",
      "Sampling from training predictions...\n",
      "Source: sau đó , chúng_tôi đã yêu_cầu mọi người_làm như_thế \"\n",
      "Reference: so , we got people to sign , &quot;\n",
      "Model: <SOS> and , we we people people &quot; the the\n",
      "Attention Weights: tensor([[7.2318e-02, 9.2754e-01, 1.4107e-04, 4.0384e-07, 8.8465e-07, 1.5420e-06,\n",
      "         3.1668e-06, 4.6828e-08, 7.3186e-10, 1.6714e-10],\n",
      "        [3.4680e-03, 8.6733e-01, 1.1946e-01, 6.9681e-03, 1.5004e-03, 1.2379e-03,\n",
      "         3.0792e-05, 4.5231e-06, 1.9554e-07, 9.3885e-08],\n",
      "        [8.4501e-03, 4.5276e-02, 2.0256e-01, 8.3758e-02, 1.7998e-01, 4.0221e-01,\n",
      "         6.2123e-02, 1.4766e-02, 7.2643e-04, 1.4624e-04],\n",
      "        [5.3084e-04, 5.7315e-03, 6.7145e-02, 1.3245e-02, 7.6758e-02, 6.2204e-01,\n",
      "         1.8140e-01, 3.2415e-02, 5.9615e-04, 1.3677e-04],\n",
      "        [2.1314e-04, 6.5299e-03, 8.3399e-02, 3.5020e-03, 7.0573e-02, 5.2627e-01,\n",
      "         2.6493e-01, 4.3038e-02, 1.3502e-03, 1.9332e-04],\n",
      "        [1.7080e-05, 2.9733e-04, 4.8095e-03, 5.2918e-04, 7.9812e-04, 3.4947e-02,\n",
      "         3.8436e-01, 5.0290e-01, 4.9465e-02, 2.1873e-02],\n",
      "        [4.7781e-05, 1.9622e-03, 4.4225e-03, 8.7391e-04, 2.0098e-04, 1.0415e-02,\n",
      "         7.2910e-02, 6.5665e-01, 1.7984e-01, 7.2673e-02],\n",
      "        [1.0891e-05, 7.9378e-04, 4.8647e-04, 1.8145e-04, 1.8346e-04, 2.3854e-03,\n",
      "         3.0446e-02, 1.5354e-01, 1.9915e-01, 6.1283e-01],\n",
      "        [8.2010e-05, 1.2400e-03, 7.0696e-04, 3.3273e-04, 6.6178e-05, 4.3338e-04,\n",
      "         5.7724e-03, 8.9435e-02, 1.8951e-01, 7.1242e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: làm_vườn là công_việc có tính trị_liệu nhất và thách_thức nhất\n",
      "Reference: gardening is the most therapeutic and <UNK> act you\n",
      "Model: <SOS> so is that most of of of most the\n",
      "Attention Weights: tensor([[9.9895e-01, 1.0119e-03, 3.3587e-05, 2.7446e-07, 7.8494e-08, 7.6283e-08,\n",
      "         1.8796e-08, 1.0155e-09, 8.8026e-10, 7.5588e-11],\n",
      "        [4.5793e-01, 4.4559e-01, 9.4074e-02, 1.0909e-03, 6.5258e-04, 5.9514e-04,\n",
      "         4.9037e-05, 1.8375e-06, 1.1244e-05, 2.5808e-06],\n",
      "        [3.5621e-01, 1.0356e-01, 4.1266e-01, 4.4644e-02, 4.3877e-02, 3.2595e-02,\n",
      "         5.7513e-03, 1.2327e-04, 4.6688e-04, 1.1836e-04],\n",
      "        [6.8748e-04, 2.8470e-02, 4.9839e-01, 8.9481e-02, 1.0771e-01, 1.4803e-01,\n",
      "         1.2148e-01, 1.2048e-03, 3.9709e-03, 5.7793e-04],\n",
      "        [5.3342e-05, 6.9520e-03, 1.2507e-01, 1.6067e-01, 2.9133e-01, 2.8101e-01,\n",
      "         1.0639e-01, 1.6063e-02, 1.1958e-02, 4.9499e-04],\n",
      "        [2.4496e-05, 2.5455e-03, 1.9111e-02, 8.4369e-02, 1.2131e-01, 3.0870e-01,\n",
      "         2.1558e-01, 1.8468e-01, 5.8234e-02, 5.4469e-03],\n",
      "        [3.4254e-05, 4.2795e-04, 6.3800e-03, 3.1275e-02, 5.2259e-02, 2.8202e-01,\n",
      "         1.8610e-01, 3.1795e-01, 1.1542e-01, 8.1343e-03],\n",
      "        [8.7303e-06, 4.8767e-05, 5.5057e-04, 2.5406e-03, 3.4650e-03, 6.8105e-03,\n",
      "         2.7582e-02, 3.5617e-01, 5.7750e-01, 2.5329e-02],\n",
      "        [4.5870e-04, 3.1607e-04, 4.7349e-03, 7.7475e-03, 1.9328e-02, 3.2478e-02,\n",
      "         3.3697e-02, 1.6955e-01, 6.5670e-01, 7.4988e-02]])\n",
      "\n",
      "Epoch: 8.53, Train Loss: 2.16, Val Loss: 4.20, Train BLEU: 21.05, Val BLEU: 11.40, Minutes Elapsed: 446.74\n",
      "Sampling from training predictions...\n",
      "Source: chúng_ta đang được phục_vụ một chế_độ \" ăn_kiêng \" mà\n",
      "Reference: we are increasingly offered a diet in which sensation\n",
      "Model: <SOS> we &apos;re playing to a diet , <EOS> ,\n",
      "Attention Weights: tensor([[3.8586e-01, 4.4206e-01, 1.7053e-01, 1.5320e-03, 2.3037e-05, 1.0967e-06,\n",
      "         2.0762e-08, 1.4518e-07, 2.6340e-09, 2.6880e-09],\n",
      "        [5.7014e-04, 9.2186e-01, 7.6680e-02, 8.8509e-04, 1.1580e-06, 3.4913e-07,\n",
      "         3.4472e-08, 1.1021e-07, 6.6437e-09, 4.4310e-09],\n",
      "        [6.6237e-03, 3.3212e-01, 3.7244e-01, 2.8501e-01, 2.6657e-03, 1.0704e-03,\n",
      "         2.4407e-05, 4.1115e-05, 3.0515e-06, 3.8436e-06],\n",
      "        [2.2981e-04, 5.3707e-03, 2.6499e-02, 7.3315e-01, 1.2433e-01, 1.0061e-01,\n",
      "         4.3034e-03, 5.3541e-03, 1.2623e-04, 2.6575e-05],\n",
      "        [3.6958e-04, 7.9475e-04, 2.3986e-03, 1.0543e-01, 8.6387e-02, 4.7874e-01,\n",
      "         1.0092e-01, 2.0615e-01, 1.3473e-02, 5.3366e-03],\n",
      "        [4.0184e-05, 3.3189e-04, 6.5413e-04, 3.0093e-03, 1.3961e-02, 1.7071e-01,\n",
      "         1.2833e-01, 4.5383e-01, 5.9660e-02, 1.6948e-01],\n",
      "        [2.5899e-06, 7.5413e-06, 2.9544e-05, 6.8298e-05, 1.8246e-03, 1.6645e-02,\n",
      "         1.4760e-01, 1.5928e-01, 2.6166e-01, 4.1289e-01],\n",
      "        [6.5643e-05, 5.0607e-05, 9.9131e-05, 1.6832e-04, 7.2057e-04, 4.0521e-03,\n",
      "         1.4124e-01, 1.4080e-01, 2.1384e-01, 4.9896e-01],\n",
      "        [5.5517e-04, 1.4368e-03, 1.0055e-03, 3.8516e-04, 3.0582e-03, 9.1357e-03,\n",
      "         2.7947e-02, 2.8332e-01, 2.6611e-01, 4.0704e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi đã bị sốc . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: i was so shocked . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> i was shocked . . <EOS> <EOS> . <EOS>\n",
      "Attention Weights: tensor([[0.0053, 0.1049, 0.8483, 0.0414, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0225, 0.0681, 0.8438, 0.0654, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0031, 0.0169, 0.4116, 0.5534, 0.0139, 0.0011, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0084, 0.0015, 0.1096, 0.7171, 0.0874, 0.0759, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0498, 0.0057, 0.0745, 0.4356, 0.0942, 0.3403, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0238, 0.0238, 0.2435, 0.1931, 0.0756, 0.4403, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4526, 0.1195, 0.1812, 0.0898, 0.0383, 0.1186, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0198, 0.0628, 0.4837, 0.3812, 0.0223, 0.0303, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2938, 0.0528, 0.1435, 0.3314, 0.0763, 0.1022, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 8.58, Train Loss: 2.27, Val Loss: 4.23, Train BLEU: 20.38, Val BLEU: 11.40, Minutes Elapsed: 449.32\n",
      "Sampling from training predictions...\n",
      "Source: bạn có_thể làm ra một loại pin nhiên_liệu sinh_học .\n",
      "Reference: you can make some sort of a biofuel cell\n",
      "Model: <SOS> you can make a kind of drug biofuel biofuel\n",
      "Attention Weights: tensor([[9.3450e-01, 6.2208e-02, 3.2456e-03, 4.1185e-05, 3.6695e-06, 1.3515e-07,\n",
      "         4.2551e-08, 3.7853e-08, 2.0268e-09, 1.0385e-10],\n",
      "        [6.3587e-02, 6.5837e-01, 2.6910e-01, 6.5738e-03, 1.3087e-03, 5.8795e-04,\n",
      "         2.7185e-04, 1.7805e-04, 2.4457e-05, 1.2394e-06],\n",
      "        [7.3896e-03, 3.5767e-02, 8.3206e-01, 9.4554e-02, 2.0799e-02, 6.1070e-03,\n",
      "         2.3986e-03, 7.9833e-04, 1.2596e-04, 5.1523e-06],\n",
      "        [1.3335e-03, 2.6944e-03, 1.9034e-01, 2.2638e-01, 3.1688e-01, 1.9138e-01,\n",
      "         4.6795e-02, 2.0415e-02, 3.7091e-03, 7.3318e-05],\n",
      "        [9.4220e-06, 3.9902e-05, 3.2824e-03, 2.9827e-02, 6.9707e-02, 4.3699e-01,\n",
      "         1.0770e-01, 3.0556e-01, 4.6318e-02, 5.6049e-04],\n",
      "        [2.3833e-05, 2.0878e-04, 4.8189e-03, 1.2751e-02, 1.0066e-02, 3.9008e-01,\n",
      "         2.5194e-01, 2.9907e-01, 2.6030e-02, 5.0181e-03],\n",
      "        [2.0070e-05, 4.6132e-04, 3.3104e-03, 1.6293e-03, 8.1069e-03, 1.8774e-01,\n",
      "         1.4745e-01, 4.5811e-01, 1.1297e-01, 8.0208e-02],\n",
      "        [4.6518e-04, 2.4117e-03, 4.5498e-02, 8.7649e-03, 1.4150e-02, 1.4029e-01,\n",
      "         1.2133e-01, 3.3142e-01, 1.0532e-01, 2.3035e-01],\n",
      "        [1.7337e-03, 2.9212e-03, 2.3540e-02, 6.3784e-03, 4.9164e-03, 7.6647e-02,\n",
      "         1.5457e-01, 3.1768e-01, 1.5520e-01, 2.5641e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: chứng_kiến những chuyện quá_sức như_thế thật nặng_nề . <EOS> <PAD>\n",
      "Reference: it &apos;s difficult to witness something so overwhelming .\n",
      "Model: <SOS> the of like like like like <EOS> &apos;s &apos;s\n",
      "Attention Weights: tensor([[0.9819, 0.0127, 0.0053, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.5866, 0.1567, 0.1802, 0.0734, 0.0009, 0.0017, 0.0006, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0687, 0.1148, 0.5024, 0.2851, 0.0095, 0.0136, 0.0053, 0.0005, 0.0002,\n",
      "         0.0000],\n",
      "        [0.0180, 0.1604, 0.2409, 0.4253, 0.0542, 0.0381, 0.0594, 0.0030, 0.0006,\n",
      "         0.0000],\n",
      "        [0.0059, 0.0247, 0.2308, 0.3632, 0.0874, 0.1219, 0.1389, 0.0182, 0.0090,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0030, 0.0111, 0.1276, 0.2295, 0.3052, 0.2146, 0.0829, 0.0258,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0006, 0.0068, 0.0799, 0.1557, 0.1941, 0.3222, 0.0874, 0.1532,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0009, 0.0041, 0.0124, 0.0395, 0.1816, 0.2651, 0.0942, 0.4019,\n",
      "         0.0000],\n",
      "        [0.0008, 0.0034, 0.0076, 0.0277, 0.0315, 0.1704, 0.3469, 0.1412, 0.2704,\n",
      "         0.0000]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8.62, Train Loss: 2.24, Val Loss: 4.22, Train BLEU: 21.61, Val BLEU: 11.37, Minutes Elapsed: 451.84\n",
      "Sampling from training predictions...\n",
      "Source: vậy_mà ngay bây_giờ , trầm_cảm là một vết cắt sâu\n",
      "Reference: but right now , depression is society &apos;s deep\n",
      "Model: <SOS> the now , now depression is a of .\n",
      "Attention Weights: tensor([[9.9967e-01, 2.6212e-04, 6.4487e-05, 1.0053e-08, 4.3990e-09, 1.2338e-10,\n",
      "         5.3386e-12, 7.6213e-13, 3.0630e-13, 4.4763e-13],\n",
      "        [7.3975e-02, 2.7830e-01, 6.4221e-01, 5.0216e-03, 4.7879e-04, 6.8428e-06,\n",
      "         3.8687e-07, 2.6898e-07, 1.3621e-07, 6.5977e-08],\n",
      "        [1.2116e-01, 1.8118e-01, 2.3182e-01, 1.9788e-01, 2.5681e-01, 6.5803e-03,\n",
      "         2.5885e-03, 1.1768e-03, 5.2951e-04, 2.7926e-04],\n",
      "        [3.8140e-02, 1.6666e-01, 2.9172e-01, 1.4285e-01, 3.3900e-01, 1.4832e-02,\n",
      "         3.1157e-03, 1.9155e-03, 1.1226e-03, 6.3790e-04],\n",
      "        [2.6109e-04, 5.9772e-03, 6.8072e-02, 7.6580e-02, 8.1353e-01, 2.0639e-02,\n",
      "         8.5689e-03, 2.5587e-03, 2.1477e-03, 1.6690e-03],\n",
      "        [1.6045e-04, 8.9112e-05, 2.7008e-03, 6.1582e-03, 6.3840e-01, 1.1237e-01,\n",
      "         7.2898e-02, 6.2006e-02, 6.5851e-02, 3.9371e-02],\n",
      "        [1.0492e-03, 3.9625e-04, 2.6375e-03, 6.0888e-03, 2.0634e-01, 3.4990e-01,\n",
      "         1.9976e-01, 9.1760e-02, 6.5205e-02, 7.6853e-02],\n",
      "        [3.4005e-05, 1.3731e-05, 4.3441e-04, 9.2762e-04, 6.1500e-03, 1.1027e-02,\n",
      "         4.8661e-02, 5.6005e-01, 2.0349e-01, 1.6921e-01],\n",
      "        [1.1878e-06, 1.2863e-04, 8.8972e-05, 1.4413e-04, 8.1407e-05, 2.4352e-03,\n",
      "         5.9975e-03, 1.7627e-01, 4.5808e-01, 3.5678e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: đó có nghĩa_là nó có_thể tự thực_hiện được . <EOS>\n",
      "Reference: that means they can be <UNK> . <EOS> <PAD>\n",
      "Model: <SOS> that means it can be . . <EOS> .\n",
      "Attention Weights: tensor([[2.8958e-01, 6.3475e-01, 7.5425e-02, 2.4003e-04, 3.4209e-06, 4.6151e-07,\n",
      "         5.2251e-08, 4.6851e-09, 2.9006e-09, 1.1319e-10],\n",
      "        [6.0876e-03, 6.5824e-02, 9.1735e-01, 7.0308e-03, 2.6080e-03, 7.3263e-04,\n",
      "         2.9002e-04, 6.3629e-05, 8.4976e-06, 2.2384e-06],\n",
      "        [3.1982e-03, 3.4199e-02, 6.6809e-01, 1.8563e-01, 4.4473e-02, 5.3294e-02,\n",
      "         8.6979e-03, 2.0916e-03, 2.6413e-04, 6.1258e-05],\n",
      "        [3.1143e-04, 6.0714e-03, 2.3657e-02, 1.6240e-01, 2.5207e-01, 3.3280e-01,\n",
      "         1.6144e-01, 5.6149e-02, 4.4145e-03, 6.8421e-04],\n",
      "        [6.1109e-06, 9.9725e-05, 2.7092e-03, 7.7935e-03, 1.1240e-01, 3.1470e-01,\n",
      "         2.3119e-01, 3.0483e-01, 2.0019e-02, 6.2456e-03],\n",
      "        [2.3321e-06, 5.7850e-05, 9.2755e-04, 1.0087e-03, 1.1798e-02, 1.3939e-01,\n",
      "         4.9900e-01, 2.5659e-01, 5.8751e-02, 3.2476e-02],\n",
      "        [3.1987e-06, 5.0224e-05, 5.8727e-04, 5.8551e-04, 3.1047e-03, 5.5480e-02,\n",
      "         2.2087e-01, 4.4246e-01, 1.0179e-01, 1.7507e-01],\n",
      "        [4.6149e-05, 2.2481e-04, 3.2261e-03, 1.2329e-03, 4.3846e-03, 4.3936e-02,\n",
      "         2.0781e-01, 1.4850e-01, 2.0304e-01, 3.8760e-01],\n",
      "        [2.8600e-04, 5.3773e-03, 3.8681e-02, 4.8340e-03, 1.5813e-02, 3.3543e-02,\n",
      "         1.4875e-01, 2.4970e-01, 1.5087e-01, 3.5214e-01]])\n",
      "\n",
      "Epoch: 8.67, Train Loss: 2.21, Val Loss: 4.23, Train BLEU: 20.04, Val BLEU: 10.55, Minutes Elapsed: 454.41\n",
      "Sampling from training predictions...\n",
      "Source: nhưng bây_giờ , chúng_ta có_một công_nghệ thực để làm_việc này\n",
      "Reference: but now , we have a real technology to\n",
      "Model: <SOS> but now , we have a technology technology to\n",
      "Attention Weights: tensor([[1.5875e-02, 9.8398e-01, 1.2278e-04, 2.6661e-06, 2.7455e-06, 1.2728e-05,\n",
      "         7.3775e-07, 1.7088e-07, 1.8864e-08, 1.4085e-08],\n",
      "        [1.2207e-03, 9.9671e-01, 1.6470e-03, 3.4574e-04, 7.7847e-05, 4.4088e-07,\n",
      "         2.2643e-07, 1.7307e-07, 2.0620e-07, 6.8697e-09],\n",
      "        [2.4352e-03, 3.1608e-02, 5.2327e-01, 3.3449e-01, 1.0191e-01, 5.0700e-03,\n",
      "         8.1442e-04, 1.9478e-04, 1.9428e-04, 5.2135e-06],\n",
      "        [2.6159e-04, 2.6651e-04, 1.9358e-02, 7.8906e-02, 7.7545e-01, 1.1841e-01,\n",
      "         4.9108e-03, 1.5876e-03, 7.9873e-04, 5.1196e-05],\n",
      "        [2.2603e-04, 4.4988e-04, 2.8760e-03, 1.2642e-02, 5.1846e-01, 4.3821e-01,\n",
      "         1.9787e-02, 2.9915e-03, 4.2069e-03, 1.4824e-04],\n",
      "        [6.1804e-04, 1.3453e-03, 3.5512e-03, 5.6917e-03, 3.6453e-01, 5.5686e-01,\n",
      "         6.0898e-02, 4.5843e-03, 1.8503e-03, 7.3218e-05],\n",
      "        [3.9795e-05, 8.5436e-05, 3.6861e-04, 1.9896e-04, 4.5391e-02, 7.3258e-01,\n",
      "         1.9333e-01, 1.5941e-02, 1.0953e-02, 1.1142e-03],\n",
      "        [5.2487e-06, 6.2655e-05, 5.4661e-04, 2.2384e-04, 3.6397e-02, 7.9731e-01,\n",
      "         8.6412e-02, 3.7912e-02, 3.2798e-02, 8.3300e-03],\n",
      "        [6.2880e-08, 5.3573e-06, 3.7425e-03, 7.5348e-04, 1.4631e-02, 3.9645e-02,\n",
      "         1.3066e-02, 9.1435e-02, 8.1638e-01, 2.0345e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: trong 5 năm sau đó , tôi đã ăn_mặc như\n",
      "Reference: so for the next five years , i dressed\n",
      "Model: <SOS> for the past past years years , i &apos;ve\n",
      "Attention Weights: tensor([[9.2351e-01, 7.2319e-02, 4.1045e-03, 6.4369e-05, 2.8824e-07, 1.3132e-09,\n",
      "         2.5279e-10, 1.2120e-09, 3.0144e-10, 4.1228e-10],\n",
      "        [2.6363e-01, 5.3267e-01, 1.9963e-01, 3.5953e-03, 4.3487e-04, 1.8914e-05,\n",
      "         2.8745e-06, 1.0216e-05, 3.0270e-06, 1.6103e-06],\n",
      "        [1.5085e-02, 1.3409e-01, 8.0162e-01, 4.1016e-02, 5.4251e-03, 1.7814e-03,\n",
      "         1.2404e-04, 6.1575e-04, 1.8749e-04, 6.3174e-05],\n",
      "        [6.2876e-02, 2.1294e-01, 6.4060e-01, 7.3850e-02, 5.9099e-03, 1.6763e-03,\n",
      "         1.8954e-04, 1.1364e-03, 7.1651e-04, 1.0588e-04],\n",
      "        [1.3853e-02, 3.1474e-01, 4.7102e-01, 1.6776e-01, 2.2022e-02, 8.7640e-03,\n",
      "         3.3915e-04, 9.8390e-04, 3.9032e-04, 1.2996e-04],\n",
      "        [9.1839e-03, 1.3208e-01, 5.0716e-01, 2.7716e-01, 5.0212e-02, 2.1756e-02,\n",
      "         5.9806e-04, 1.4741e-03, 2.6216e-04, 1.1540e-04],\n",
      "        [5.3262e-05, 3.4069e-03, 4.3078e-02, 3.8998e-01, 1.4638e-01, 3.0081e-01,\n",
      "         4.6167e-02, 5.9026e-02, 7.9703e-03, 3.1236e-03],\n",
      "        [2.3162e-05, 8.8892e-04, 2.2360e-02, 4.3568e-01, 6.6844e-02, 1.4837e-01,\n",
      "         1.4512e-01, 1.6267e-01, 1.3027e-02, 5.0225e-03],\n",
      "        [4.3497e-06, 5.3955e-05, 9.9754e-04, 1.3977e-02, 7.4460e-03, 7.7319e-02,\n",
      "         1.0183e-01, 6.5881e-01, 1.2428e-01, 1.5278e-02]])\n",
      "\n",
      "Epoch: 8.72, Train Loss: 2.19, Val Loss: 4.21, Train BLEU: 21.07, Val BLEU: 10.70, Minutes Elapsed: 456.98\n",
      "Sampling from training predictions...\n",
      "Source: được rồi , chuẩn_bị . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: okay , here it is . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> all , that . <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9628, 0.0369, 0.0004, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1305, 0.6050, 0.2412, 0.0229, 0.0004, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0185, 0.0288, 0.5535, 0.3768, 0.0195, 0.0030, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0019, 0.0024, 0.0629, 0.8794, 0.0479, 0.0054, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0018, 0.0023, 0.0455, 0.6110, 0.2458, 0.0936, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0350, 0.0566, 0.0639, 0.4364, 0.1487, 0.2593, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0112, 0.0868, 0.1158, 0.3364, 0.0914, 0.3585, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0318, 0.0723, 0.1593, 0.2190, 0.1330, 0.3845, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0369, 0.0364, 0.0838, 0.3213, 0.3222, 0.1994, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: ông giải_thích rất rõ rằng thể_hiện cảm_xúc là rất nguy_hiểm\n",
      "Reference: and he very clearly explained to me that emotional\n",
      "Model: <SOS> he <UNK> &apos;s a that that the feeling a\n",
      "Attention Weights: tensor([[9.9270e-01, 7.1106e-03, 1.8210e-04, 8.5013e-06, 1.8999e-08, 1.3348e-08,\n",
      "         1.9120e-09, 3.8732e-10, 3.7725e-10, 4.6619e-11],\n",
      "        [5.0046e-03, 9.7678e-01, 1.3992e-02, 2.0936e-03, 1.2439e-03, 8.0784e-04,\n",
      "         7.3181e-05, 5.5615e-06, 2.9390e-06, 8.0283e-07],\n",
      "        [1.3099e-02, 2.5144e-01, 4.3292e-01, 1.8947e-01, 7.7154e-02, 2.9082e-02,\n",
      "         6.0855e-03, 4.6308e-04, 1.7858e-04, 1.1523e-04],\n",
      "        [2.6339e-02, 4.9213e-01, 3.1186e-01, 1.0009e-01, 3.7008e-02, 2.8088e-02,\n",
      "         3.5252e-03, 5.2339e-04, 3.0444e-04, 1.3249e-04],\n",
      "        [5.7858e-03, 9.2653e-02, 2.6534e-01, 2.5634e-01, 1.4339e-01, 1.9071e-01,\n",
      "         3.5480e-02, 5.5808e-03, 3.3677e-03, 1.3529e-03],\n",
      "        [3.7137e-04, 9.8384e-03, 4.2841e-03, 1.1011e-01, 3.8167e-01, 3.9801e-01,\n",
      "         8.7550e-02, 2.7891e-03, 2.9519e-03, 2.4256e-03],\n",
      "        [1.7465e-05, 7.2475e-05, 3.8729e-04, 1.7882e-02, 3.5669e-02, 5.7562e-01,\n",
      "         2.9273e-01, 2.3514e-02, 2.9931e-02, 2.4175e-02],\n",
      "        [2.0024e-05, 4.0541e-05, 1.0884e-04, 1.6069e-03, 1.0718e-02, 3.1740e-01,\n",
      "         3.6590e-01, 9.8256e-02, 1.1301e-01, 9.2942e-02],\n",
      "        [1.4081e-06, 1.6991e-05, 1.3913e-04, 1.5190e-03, 9.7845e-03, 1.1189e-01,\n",
      "         1.2200e-01, 8.4788e-02, 2.5076e-01, 4.1910e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8.77, Train Loss: 2.19, Val Loss: 4.22, Train BLEU: 20.73, Val BLEU: 10.63, Minutes Elapsed: 459.56\n",
      "Sampling from training predictions...\n",
      "Source: vậy_nên tôi tự_hỏi bản_thân mình tôi có viết nhạc cho\n",
      "Reference: so i asked myself : do i write stuff\n",
      "Model: <SOS> so i asked myself myself myself have write write\n",
      "Attention Weights: tensor([[9.9850e-01, 3.4301e-04, 1.1502e-03, 5.5210e-06, 1.2446e-07, 4.2397e-10,\n",
      "         1.2387e-09, 1.4161e-10, 3.7753e-11, 2.8022e-11],\n",
      "        [4.5390e-01, 1.9382e-01, 3.4947e-01, 2.7800e-03, 4.1633e-05, 1.7413e-07,\n",
      "         1.4872e-07, 1.1719e-07, 2.4111e-08, 1.1462e-08],\n",
      "        [2.7739e-02, 4.9078e-02, 8.4543e-01, 7.6275e-02, 1.3340e-03, 5.4444e-05,\n",
      "         5.3373e-05, 2.9038e-05, 4.1715e-06, 2.4595e-06],\n",
      "        [2.4618e-02, 1.0070e-02, 5.2264e-01, 4.2791e-01, 1.3887e-02, 3.6586e-04,\n",
      "         3.5303e-04, 1.3526e-04, 1.2880e-05, 7.7562e-06],\n",
      "        [3.5989e-04, 5.6998e-04, 9.7884e-02, 7.1438e-01, 1.6206e-01, 1.8799e-02,\n",
      "         3.4911e-03, 1.2304e-03, 1.0824e-03, 1.4614e-04],\n",
      "        [1.2152e-05, 2.1809e-04, 1.5230e-02, 7.7986e-02, 3.1640e-01, 3.8763e-01,\n",
      "         1.0176e-01, 6.0935e-02, 3.3813e-02, 6.0145e-03],\n",
      "        [2.9977e-06, 6.3482e-06, 1.2298e-04, 3.2326e-03, 5.9647e-02, 1.0600e-01,\n",
      "         4.7753e-01, 2.1075e-01, 9.0382e-02, 5.2336e-02],\n",
      "        [1.3557e-04, 1.6920e-04, 1.5686e-02, 8.9844e-02, 1.1439e-01, 4.1330e-02,\n",
      "         2.0463e-01, 4.0620e-01, 9.9508e-02, 2.8113e-02],\n",
      "        [4.1143e-06, 5.5616e-06, 9.3146e-04, 6.7059e-03, 2.6887e-02, 9.4565e-02,\n",
      "         3.1099e-01, 3.1639e-01, 1.9882e-01, 4.4703e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: khi bạn bước ra khỏi căn phòng này , bạn\n",
      "Reference: when you walk out of this room , you\n",
      "Model: <SOS> when you walk out in this room , you\n",
      "Attention Weights: tensor([[9.5317e-01, 4.2432e-02, 4.3739e-03, 2.3794e-05, 1.0675e-06, 4.2600e-09,\n",
      "         2.5050e-10, 2.7374e-09, 3.3244e-11, 6.3503e-11],\n",
      "        [9.4718e-02, 7.2976e-01, 1.7399e-01, 1.3681e-03, 1.4179e-04, 7.6955e-06,\n",
      "         8.6993e-06, 1.5760e-06, 2.2901e-07, 5.3534e-07],\n",
      "        [2.0745e-03, 2.1498e-02, 9.4226e-01, 3.2770e-02, 1.3451e-03, 4.0940e-05,\n",
      "         1.2186e-05, 2.4870e-06, 3.2660e-07, 7.8696e-07],\n",
      "        [3.3632e-04, 1.9868e-03, 3.9108e-01, 5.4239e-01, 6.3313e-02, 6.2858e-04,\n",
      "         2.1689e-04, 4.6172e-05, 2.4489e-06, 1.0185e-06],\n",
      "        [4.0639e-04, 2.5047e-04, 9.5361e-03, 1.1042e-01, 5.4038e-01, 2.1327e-01,\n",
      "         1.2081e-01, 4.3067e-03, 5.1720e-04, 9.5964e-05],\n",
      "        [6.3171e-04, 1.8015e-04, 2.9909e-03, 1.4938e-02, 2.9938e-01, 2.5340e-01,\n",
      "         3.8575e-01, 2.8493e-02, 1.1696e-02, 2.5365e-03],\n",
      "        [3.3951e-04, 7.3145e-05, 6.4385e-03, 1.4553e-02, 1.5147e-01, 4.8766e-01,\n",
      "         2.6221e-01, 3.6047e-02, 3.3453e-02, 7.7549e-03],\n",
      "        [3.0569e-03, 1.5341e-04, 6.5545e-04, 1.8292e-03, 3.0774e-03, 2.3516e-02,\n",
      "         2.8082e-02, 1.1063e-01, 6.2007e-01, 2.0893e-01],\n",
      "        [3.6560e-05, 1.3750e-05, 1.2198e-04, 4.8397e-04, 9.8487e-04, 1.0886e-02,\n",
      "         3.1873e-02, 1.5686e-02, 2.8462e-01, 6.5530e-01]])\n",
      "\n",
      "Epoch: 8.82, Train Loss: 2.19, Val Loss: 4.21, Train BLEU: 20.90, Val BLEU: 11.35, Minutes Elapsed: 462.10\n",
      "Sampling from training predictions...\n",
      "Source: tôi không thấy bất_cứ ai gửi tin nhắn hoặc kiểm_tra\n",
      "Reference: i didn &apos;t see anybody sending text messages or\n",
      "Model: <SOS> i don &apos;t see anybody that or or or\n",
      "Attention Weights: tensor([[1.5794e-03, 8.6294e-01, 1.3248e-01, 2.2627e-03, 6.5208e-04, 7.8098e-05,\n",
      "         4.3572e-06, 6.0099e-07, 2.0596e-07, 8.0538e-08],\n",
      "        [3.6647e-04, 7.5385e-01, 2.4357e-01, 1.1410e-03, 5.2272e-04, 3.5301e-04,\n",
      "         1.6774e-04, 1.9008e-05, 5.8813e-06, 2.7653e-06],\n",
      "        [1.2617e-03, 6.2046e-01, 3.5832e-01, 1.1353e-02, 7.0145e-03, 1.1038e-03,\n",
      "         4.0223e-04, 5.5004e-05, 1.5587e-05, 9.7885e-06],\n",
      "        [2.9079e-04, 1.7427e-03, 9.5990e-01, 1.1412e-02, 9.7708e-03, 1.1874e-02,\n",
      "         4.7251e-03, 2.4529e-04, 2.8622e-05, 1.2021e-05],\n",
      "        [6.1701e-05, 1.9069e-04, 2.6628e-01, 1.1907e-01, 2.0008e-01, 1.9418e-01,\n",
      "         1.8149e-01, 3.1485e-02, 5.8846e-03, 1.2701e-03],\n",
      "        [1.3363e-06, 2.7454e-05, 1.8931e-02, 4.0094e-02, 3.1157e-02, 6.7404e-01,\n",
      "         1.6578e-01, 5.9746e-02, 7.7366e-03, 2.4849e-03],\n",
      "        [1.1371e-07, 9.6007e-07, 1.1370e-04, 6.7679e-04, 3.3525e-03, 8.3917e-02,\n",
      "         4.0033e-01, 4.0127e-01, 7.4543e-02, 3.5799e-02],\n",
      "        [3.1674e-08, 9.1531e-07, 1.0573e-04, 2.9311e-04, 5.1301e-04, 4.6652e-02,\n",
      "         2.1186e-01, 2.9325e-01, 2.9265e-01, 1.5468e-01],\n",
      "        [5.7097e-07, 3.2336e-06, 6.6032e-05, 1.7155e-04, 1.7311e-04, 9.5935e-03,\n",
      "         4.0649e-02, 6.9830e-02, 2.5499e-01, 6.2453e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: em chia_sẻ nó một_cách vô điều_kiện dù bất kể ra_sao\n",
      "Reference: he shares it unconditionally and he shares it regardless\n",
      "Model: <SOS> i shared shared how how how , , why\n",
      "Attention Weights: tensor([[8.9261e-01, 1.0696e-01, 4.3415e-04, 1.0148e-06, 4.3730e-08, 1.0209e-08,\n",
      "         1.0720e-08, 1.8848e-09, 2.1073e-10, 1.2940e-10],\n",
      "        [5.3924e-02, 9.4531e-01, 7.6083e-04, 8.7453e-06, 5.2804e-07, 2.4863e-07,\n",
      "         6.8240e-08, 3.5720e-08, 3.1773e-08, 3.4932e-08],\n",
      "        [1.7204e-02, 9.7073e-01, 1.0831e-02, 1.0299e-03, 1.2591e-04, 3.8883e-05,\n",
      "         1.9212e-05, 1.1096e-05, 4.1543e-06, 8.8075e-07],\n",
      "        [1.5799e-04, 7.0891e-02, 5.0508e-01, 2.7727e-01, 6.3237e-02, 5.2240e-02,\n",
      "         2.4988e-02, 4.7589e-03, 1.1064e-03, 2.7277e-04],\n",
      "        [2.0358e-05, 1.0807e-04, 1.3298e-02, 2.4127e-01, 1.7471e-01, 2.4592e-01,\n",
      "         2.4173e-01, 5.2553e-02, 2.0882e-02, 9.4979e-03],\n",
      "        [1.6631e-07, 1.4788e-05, 1.3300e-03, 1.3034e-01, 2.0547e-01, 2.2627e-01,\n",
      "         2.5484e-01, 8.5361e-02, 4.9038e-02, 4.7323e-02],\n",
      "        [2.1421e-07, 2.0835e-06, 2.1754e-04, 4.0982e-03, 4.8442e-02, 1.2763e-01,\n",
      "         1.1500e-01, 1.1459e-01, 2.2426e-01, 3.6576e-01],\n",
      "        [2.5809e-05, 1.7851e-04, 6.8406e-03, 2.0909e-02, 5.2007e-02, 7.5873e-02,\n",
      "         7.0366e-02, 3.4324e-02, 1.3418e-01, 6.0529e-01],\n",
      "        [5.6914e-06, 4.1178e-05, 1.3356e-03, 1.7533e-02, 4.6791e-02, 8.3591e-02,\n",
      "         1.4296e-01, 5.4115e-02, 1.0825e-01, 5.4538e-01]])\n",
      "\n",
      "Epoch: 8.86, Train Loss: 2.14, Val Loss: 4.20, Train BLEU: 22.16, Val BLEU: 11.48, Minutes Elapsed: 464.64\n",
      "Sampling from training predictions...\n",
      "Source: à , làm_việc với những sinh_vật an_toàn như chúng_tôi thường\n",
      "Reference: well , working with the safe organisms that we\n",
      "Model: <SOS> well , working with safe organisms that we we\n",
      "Attention Weights: tensor([[9.8314e-01, 1.6500e-02, 3.5830e-04, 6.4228e-06, 2.9254e-08, 7.8364e-08,\n",
      "         6.3806e-09, 1.0477e-09, 3.2560e-11, 4.6546e-10],\n",
      "        [8.4474e-02, 4.6086e-01, 4.3958e-01, 1.3999e-02, 5.5161e-04, 2.7483e-04,\n",
      "         1.7508e-04, 7.5147e-05, 4.3820e-06, 5.4228e-06],\n",
      "        [1.9394e-03, 1.1486e-02, 8.7798e-01, 8.9649e-02, 7.3761e-03, 7.1974e-03,\n",
      "         3.3375e-03, 7.3097e-04, 1.3116e-04, 1.6996e-04],\n",
      "        [3.8310e-04, 5.9719e-04, 4.3144e-01, 3.0855e-01, 8.6060e-02, 6.8502e-02,\n",
      "         1.0053e-01, 2.4264e-03, 2.0629e-04, 1.3017e-03],\n",
      "        [9.0028e-05, 1.7800e-04, 1.3141e-01, 1.0675e-01, 2.2959e-01, 2.4941e-01,\n",
      "         2.6454e-01, 1.5329e-02, 3.0937e-04, 2.3939e-03],\n",
      "        [1.4724e-07, 1.8575e-06, 1.3319e-02, 1.1663e-01, 8.7808e-02, 3.0484e-01,\n",
      "         4.0766e-01, 4.8258e-02, 4.5595e-03, 1.6926e-02],\n",
      "        [4.1954e-06, 2.4434e-05, 1.0096e-03, 5.7127e-03, 9.7807e-03, 9.9138e-02,\n",
      "         2.7631e-01, 3.0427e-01, 9.5782e-02, 2.0797e-01],\n",
      "        [9.4807e-06, 5.1444e-05, 5.7097e-03, 6.2727e-03, 1.0377e-02, 6.2905e-02,\n",
      "         3.0647e-01, 2.6580e-01, 1.5278e-01, 1.8962e-01],\n",
      "        [1.9527e-06, 6.4996e-06, 1.3790e-03, 2.6145e-03, 1.3953e-02, 6.4520e-02,\n",
      "         8.4790e-02, 1.6970e-01, 8.9774e-02, 5.7327e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: ngôi trường mới của tôi hiện đang bắt_đầu giúp_đỡ bằng\n",
      "Reference: my new school now is coming in and helping\n",
      "Model: <SOS> my school dream is started me on me ,\n",
      "Attention Weights: tensor([[9.4592e-01, 5.4002e-02, 7.3574e-05, 1.3431e-06, 2.8690e-08, 1.6215e-08,\n",
      "         8.9903e-09, 1.2969e-08, 4.0004e-10, 3.6373e-10],\n",
      "        [6.1554e-02, 8.8830e-01, 4.8376e-02, 1.4960e-03, 4.9846e-05, 1.5934e-04,\n",
      "         5.2654e-05, 5.8595e-06, 8.9652e-07, 5.8373e-07],\n",
      "        [2.5122e-01, 5.3321e-01, 1.2948e-01, 3.0110e-02, 1.5371e-02, 2.4590e-02,\n",
      "         9.5664e-03, 5.2243e-03, 9.0141e-04, 3.3377e-04],\n",
      "        [4.1216e-03, 5.0633e-02, 9.7200e-02, 4.5523e-02, 5.9255e-02, 5.1704e-01,\n",
      "         1.3993e-01, 7.3630e-02, 9.3575e-03, 3.3070e-03],\n",
      "        [6.1153e-04, 1.4160e-02, 1.0621e-01, 7.0935e-02, 5.8298e-02, 4.0193e-01,\n",
      "         1.7967e-01, 1.3837e-01, 1.6593e-02, 1.3232e-02],\n",
      "        [1.1803e-04, 4.1158e-03, 1.0664e-01, 2.2450e-02, 7.7793e-03, 1.7447e-01,\n",
      "         1.2598e-01, 3.0305e-01, 1.6154e-01, 9.3856e-02],\n",
      "        [5.7284e-04, 1.8927e-02, 1.0644e-01, 4.9874e-02, 7.1147e-03, 1.5480e-01,\n",
      "         1.1926e-01, 2.9100e-01, 1.7520e-01, 7.6819e-02],\n",
      "        [3.7710e-05, 6.5677e-04, 1.9034e-02, 6.6965e-03, 8.2076e-03, 4.8517e-02,\n",
      "         3.4744e-02, 4.5235e-01, 2.3568e-01, 1.9408e-01],\n",
      "        [3.9644e-06, 9.6453e-05, 4.5553e-04, 5.5155e-04, 2.9452e-03, 1.4772e-02,\n",
      "         2.0629e-02, 2.0627e-01, 3.6510e-01, 3.8917e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8.91, Train Loss: 2.09, Val Loss: 4.24, Train BLEU: 21.83, Val BLEU: 10.47, Minutes Elapsed: 467.18\n",
      "Sampling from training predictions...\n",
      "Source: khi bọn trẻ xem nhiều phim hơn , cuộc_sống của\n",
      "Reference: as they watch more films their lives got palpably\n",
      "Model: <SOS> when i i a , , their , life\n",
      "Attention Weights: tensor([[7.0254e-01, 2.9731e-01, 1.5002e-04, 4.2884e-07, 1.9770e-07, 9.3317e-09,\n",
      "         7.2473e-09, 1.4263e-10, 5.9353e-11, 2.0577e-11],\n",
      "        [2.3989e-03, 7.7393e-01, 2.2085e-01, 2.5061e-03, 2.0932e-04, 8.9535e-05,\n",
      "         1.4553e-05, 2.4833e-06, 6.7767e-06, 8.6696e-07],\n",
      "        [1.4928e-02, 3.3602e-01, 5.1947e-01, 1.1464e-01, 8.2323e-03, 5.3912e-03,\n",
      "         1.0900e-03, 9.0213e-05, 1.0087e-04, 3.7014e-05],\n",
      "        [3.8197e-03, 9.1956e-02, 6.6810e-01, 2.0751e-01, 1.1080e-02, 1.3437e-02,\n",
      "         3.8494e-03, 1.5697e-04, 5.0392e-05, 3.5420e-05],\n",
      "        [1.5495e-04, 6.3194e-03, 1.4980e-01, 2.0197e-01, 3.6877e-01, 2.2264e-01,\n",
      "         4.3506e-02, 3.0172e-03, 3.3832e-03, 4.4155e-04],\n",
      "        [4.9240e-05, 1.7720e-03, 1.4016e-02, 7.8469e-02, 2.3805e-01, 3.6159e-01,\n",
      "         1.2296e-01, 6.7910e-02, 1.0398e-01, 1.1212e-02],\n",
      "        [5.0156e-05, 8.3925e-04, 9.3102e-03, 1.7917e-02, 8.0596e-02, 1.4467e-01,\n",
      "         6.7132e-02, 1.5309e-01, 4.4238e-01, 8.4013e-02],\n",
      "        [5.5228e-06, 6.8283e-05, 7.5339e-04, 2.5298e-03, 1.2523e-02, 6.3483e-02,\n",
      "         1.7124e-02, 1.1631e-01, 6.3682e-01, 1.5038e-01],\n",
      "        [1.9374e-05, 2.5464e-05, 4.1775e-04, 1.5846e-02, 1.4756e-02, 1.0129e-01,\n",
      "         4.9865e-02, 3.2771e-01, 3.6694e-01, 1.2313e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: em không muốn chơi_đùa như các em_bé khác , và\n",
      "Reference: he didn &apos;t want to play like the other\n",
      "Model: <SOS> i don &apos;t want to be to as young\n",
      "Attention Weights: tensor([[9.2968e-01, 6.9855e-02, 4.5282e-04, 1.0154e-05, 7.7557e-08, 1.6317e-08,\n",
      "         1.9252e-08, 1.6509e-07, 5.1939e-10, 5.1220e-10],\n",
      "        [3.0152e-02, 9.4278e-01, 2.5816e-02, 1.2064e-03, 2.4513e-05, 4.8126e-06,\n",
      "         6.6236e-06, 5.8251e-06, 4.1958e-07, 2.3941e-07],\n",
      "        [4.9677e-02, 7.7137e-01, 1.6821e-01, 1.0227e-02, 3.5713e-04, 9.6361e-05,\n",
      "         3.2648e-05, 2.8797e-05, 1.4995e-06, 7.5020e-07],\n",
      "        [4.5503e-03, 2.8512e-02, 9.3017e-01, 3.5608e-02, 8.5154e-04, 1.1681e-04,\n",
      "         9.9394e-05, 8.4398e-05, 3.4617e-06, 7.1731e-07],\n",
      "        [4.3838e-04, 4.1483e-03, 2.9921e-01, 6.3100e-01, 4.5113e-02, 1.0063e-02,\n",
      "         3.9415e-03, 5.6997e-03, 3.6341e-04, 1.4908e-05],\n",
      "        [1.1284e-03, 3.5163e-03, 2.5735e-01, 6.0029e-01, 6.0619e-02, 4.1670e-02,\n",
      "         2.0624e-02, 1.2456e-02, 2.0071e-03, 3.4535e-04],\n",
      "        [4.0373e-06, 5.5001e-04, 1.0975e-01, 6.8278e-01, 1.3797e-01, 3.4301e-02,\n",
      "         1.1673e-02, 2.0696e-02, 2.1444e-03, 1.2723e-04],\n",
      "        [5.2040e-05, 3.6060e-04, 8.5448e-03, 1.8204e-01, 4.7334e-01, 1.4065e-01,\n",
      "         8.3233e-02, 9.6406e-02, 1.3420e-02, 1.9547e-03],\n",
      "        [1.1908e-05, 3.3423e-04, 2.2387e-03, 2.0340e-02, 2.0596e-01, 2.8890e-01,\n",
      "         3.8042e-01, 8.4241e-02, 1.2424e-02, 5.1298e-03]])\n",
      "\n",
      "Epoch: 8.96, Train Loss: 2.00, Val Loss: 4.21, Train BLEU: 23.73, Val BLEU: 10.54, Minutes Elapsed: 469.73\n",
      "Sampling from training predictions...\n",
      "Source: sáng_tạo : phải sáng_tạo để giải_quyết vấn_đề để nhóm tất_cả\n",
      "Reference: creativity : it took creativity to solve the problem\n",
      "Model: <SOS> creativity : we have to to solve out the\n",
      "Attention Weights: tensor([[9.9865e-01, 1.1613e-03, 1.8915e-04, 1.0235e-06, 9.3324e-09, 1.5253e-09,\n",
      "         1.8307e-08, 7.2031e-10, 7.2195e-11, 3.4227e-11],\n",
      "        [4.1752e-02, 4.2312e-01, 5.3432e-01, 7.7588e-04, 3.0263e-05, 3.4987e-06,\n",
      "         1.5983e-06, 1.6901e-07, 8.8934e-09, 9.1215e-09],\n",
      "        [7.1186e-04, 1.9141e-02, 9.7653e-01, 3.3967e-03, 1.9208e-04, 2.1984e-05,\n",
      "         2.7607e-06, 2.8799e-06, 8.4589e-07, 1.3137e-07],\n",
      "        [4.3182e-03, 4.8117e-03, 8.4005e-01, 1.3341e-01, 1.5566e-02, 1.5200e-03,\n",
      "         2.1842e-04, 5.8362e-05, 3.4916e-05, 8.6884e-06],\n",
      "        [1.6904e-03, 1.5260e-02, 1.2620e-01, 5.8183e-01, 1.8564e-01, 7.4683e-02,\n",
      "         1.1312e-02, 2.3166e-03, 8.6675e-04, 2.0466e-04],\n",
      "        [5.1324e-05, 3.0744e-03, 3.4023e-02, 2.2288e-01, 2.5156e-01, 4.3976e-01,\n",
      "         3.7352e-02, 8.1306e-03, 2.4094e-03, 7.6405e-04],\n",
      "        [1.3986e-07, 6.6650e-05, 3.7116e-04, 1.1483e-02, 1.1909e-01, 7.8712e-01,\n",
      "         4.4400e-02, 2.8289e-02, 8.1353e-03, 1.0420e-03],\n",
      "        [4.9727e-06, 4.4033e-06, 7.8631e-05, 1.9797e-04, 1.3983e-02, 2.0293e-01,\n",
      "         1.0591e-01, 7.1448e-02, 4.3180e-01, 1.7364e-01],\n",
      "        [1.4094e-05, 6.3375e-06, 2.9131e-05, 3.2756e-05, 2.7281e-03, 1.3294e-01,\n",
      "         1.8158e-01, 1.0745e-01, 2.9244e-01, 2.8278e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi gặp cậu_bé ở khu cứu_trợ mà tổ_chức giải_phóng nô_lệ\n",
      "Reference: i met him at a shelter where free the\n",
      "Model: <SOS> i met in in the center ward the york\n",
      "Attention Weights: tensor([[8.6623e-01, 1.3174e-01, 1.9242e-03, 1.0998e-04, 1.7281e-07, 4.6188e-08,\n",
      "         1.5807e-08, 3.0256e-09, 1.1700e-09, 6.0265e-10],\n",
      "        [2.9634e-03, 9.9389e-01, 2.8047e-03, 3.3591e-04, 2.8533e-06, 7.1257e-07,\n",
      "         1.7631e-08, 6.6261e-08, 3.2419e-08, 2.0411e-08],\n",
      "        [2.4465e-02, 5.3687e-01, 3.5691e-01, 7.8841e-02, 2.8000e-03, 7.2821e-05,\n",
      "         1.2414e-05, 1.0378e-05, 1.5174e-05, 3.9211e-06],\n",
      "        [2.2866e-03, 2.1952e-02, 3.0619e-01, 5.1563e-01, 1.0706e-01, 4.4956e-02,\n",
      "         9.3778e-04, 2.8338e-04, 3.0928e-04, 3.9225e-04],\n",
      "        [4.8695e-04, 8.9517e-04, 5.8220e-03, 4.1711e-02, 4.3226e-01, 4.2840e-01,\n",
      "         7.4397e-02, 9.8919e-03, 3.9127e-03, 2.2319e-03],\n",
      "        [6.4448e-06, 2.3912e-04, 5.4699e-03, 7.4328e-02, 3.9259e-01, 4.6604e-01,\n",
      "         4.2671e-02, 5.5286e-03, 7.6607e-03, 5.4641e-03],\n",
      "        [1.8998e-05, 1.7563e-04, 5.4366e-04, 6.5225e-03, 1.3540e-01, 2.8515e-01,\n",
      "         5.1980e-01, 2.9276e-02, 1.6956e-02, 6.1553e-03],\n",
      "        [1.7944e-05, 1.9994e-04, 4.0909e-04, 6.7728e-03, 9.2949e-02, 9.4413e-02,\n",
      "         7.4878e-01, 2.4589e-02, 2.5601e-02, 6.2723e-03],\n",
      "        [2.3751e-05, 9.3821e-05, 2.3754e-04, 7.2980e-03, 1.8994e-01, 3.3010e-01,\n",
      "         2.4388e-01, 1.1173e-01, 9.1022e-02, 2.5666e-02]])\n",
      "\n",
      "Epoch: 9.00, Train Loss: 1.80, Val Loss: 4.22, Train BLEU: 27.86, Val BLEU: 11.08, Minutes Elapsed: 471.88\n",
      "Sampling from training predictions...\n",
      "Source: thật_ra nó là một con_bọ cánh_cứng nhật_bản . <EOS> <PAD>\n",
      "Reference: it actually is a japanese beetle . <EOS> <PAD>\n",
      "Model: <SOS> it actually actually a human beetle . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9852, 0.0126, 0.0005, 0.0017, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.9673, 0.0204, 0.0106, 0.0015, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1116, 0.1334, 0.4879, 0.2212, 0.0311, 0.0123, 0.0025, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0104, 0.0024, 0.1024, 0.3668, 0.3164, 0.1545, 0.0467, 0.0003, 0.0001,\n",
      "         0.0000],\n",
      "        [0.0033, 0.0004, 0.0511, 0.0616, 0.4435, 0.2986, 0.1356, 0.0039, 0.0022,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0005, 0.0036, 0.5523, 0.4028, 0.0381, 0.0013, 0.0013,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0001, 0.0013, 0.0019, 0.1769, 0.3723, 0.3099, 0.0621, 0.0755,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0002, 0.0014, 0.0020, 0.0315, 0.0860, 0.2936, 0.3636, 0.2215,\n",
      "         0.0000],\n",
      "        [0.0103, 0.0005, 0.0038, 0.0099, 0.0280, 0.0588, 0.6048, 0.1143, 0.1696,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: nhưng bạn phải trông giữ nó . <EOS> <PAD> <PAD>\n",
      "Reference: but you have to maintain it . <EOS> <PAD>\n",
      "Model: <SOS> but you have to try rid . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0086, 0.5240, 0.4635, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0058, 0.5076, 0.4863, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0007, 0.0030, 0.9559, 0.0389, 0.0015, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0013, 0.0033, 0.6825, 0.2822, 0.0304, 0.0002, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0004, 0.0065, 0.7437, 0.2459, 0.0030, 0.0003, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0002, 0.0006, 0.0714, 0.9208, 0.0046, 0.0019, 0.0005, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0001, 0.0001, 0.0259, 0.8355, 0.0986, 0.0257, 0.0142, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0007, 0.0003, 0.0094, 0.1146, 0.0962, 0.3691, 0.4096, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0008, 0.0024, 0.0035, 0.0234, 0.1141, 0.0791, 0.3391, 0.4376, 0.0000,\n",
      "         0.0000]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9.05, Train Loss: 1.48, Val Loss: 4.26, Train BLEU: 33.53, Val BLEU: 10.61, Minutes Elapsed: 474.46\n",
      "Sampling from training predictions...\n",
      "Source: là con_người , chúng_ta chống_chọi và khổ_đau . chúng_ta rỉ\n",
      "Reference: we &apos;re people , and we struggle and we\n",
      "Model: <SOS> we &apos;s human , and we &apos;re and and\n",
      "Attention Weights: tensor([[9.9896e-01, 9.9546e-04, 3.9576e-05, 3.3573e-06, 2.9404e-07, 6.8915e-09,\n",
      "         4.9357e-09, 2.8918e-10, 1.0184e-09, 5.7119e-10],\n",
      "        [5.1945e-01, 3.8776e-01, 5.9646e-02, 2.0496e-02, 1.1098e-02, 6.3682e-04,\n",
      "         6.9360e-04, 3.4956e-05, 6.7162e-05, 1.1535e-04],\n",
      "        [7.4069e-02, 7.5514e-01, 4.5094e-02, 4.6987e-02, 7.4726e-02, 1.5851e-03,\n",
      "         1.9591e-03, 8.4245e-05, 7.6176e-05, 2.8039e-04],\n",
      "        [7.8554e-03, 7.1554e-02, 2.1948e-01, 1.9399e-01, 4.6256e-01, 1.6252e-02,\n",
      "         2.4782e-02, 2.2954e-03, 7.2076e-04, 5.0377e-04],\n",
      "        [2.1669e-03, 5.4160e-03, 3.3678e-01, 1.1944e-01, 1.6582e-01, 1.7074e-01,\n",
      "         1.5572e-01, 1.7300e-02, 2.3586e-02, 3.0390e-03],\n",
      "        [1.4778e-03, 1.4086e-03, 2.8349e-02, 1.5559e-01, 4.2566e-01, 1.0405e-01,\n",
      "         2.1197e-01, 9.3795e-03, 2.3102e-02, 3.9009e-02],\n",
      "        [3.4318e-05, 2.3722e-04, 1.5113e-03, 5.7469e-02, 5.4228e-01, 1.4818e-01,\n",
      "         2.0471e-01, 1.1557e-02, 1.0252e-02, 2.3772e-02],\n",
      "        [4.3424e-04, 7.9447e-04, 4.2163e-03, 2.1997e-02, 7.1782e-01, 8.8025e-02,\n",
      "         1.5172e-01, 6.1989e-03, 3.5769e-03, 5.2207e-03],\n",
      "        [6.7756e-04, 1.7910e-03, 2.5608e-03, 1.0511e-02, 1.2796e-01, 2.1254e-01,\n",
      "         5.7876e-01, 5.4066e-02, 6.7701e-03, 4.3600e-03]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: khi tôi chuẩn_bị cho buổi nói_chuyện này , tôi phát_hiện\n",
      "Reference: when i was researching this talk , i found\n",
      "Model: <SOS> when i i preparing to talk this , was\n",
      "Attention Weights: tensor([[9.9406e-01, 4.6345e-03, 1.2731e-03, 2.8672e-05, 9.0177e-08, 2.1978e-08,\n",
      "         6.1512e-09, 1.1307e-11, 5.8276e-11, 7.3886e-11],\n",
      "        [2.2505e-01, 7.3928e-01, 3.5533e-02, 7.8253e-05, 4.2097e-05, 1.4958e-05,\n",
      "         4.0894e-07, 2.9372e-08, 1.3614e-07, 3.4853e-07],\n",
      "        [2.6938e-02, 2.6818e-01, 6.8606e-01, 1.4439e-02, 3.9668e-03, 2.5883e-04,\n",
      "         1.0369e-05, 4.0144e-06, 7.7053e-06, 1.4352e-04],\n",
      "        [7.8944e-04, 1.5181e-03, 8.8764e-01, 8.4487e-02, 2.4804e-02, 6.7751e-04,\n",
      "         1.4079e-05, 2.8010e-06, 8.5279e-07, 6.5791e-05],\n",
      "        [1.0806e-05, 4.4808e-04, 9.3439e-02, 1.7818e-01, 6.3419e-01, 8.8989e-02,\n",
      "         3.2157e-03, 1.1231e-03, 9.2618e-05, 3.1119e-04],\n",
      "        [1.1154e-05, 2.9807e-04, 4.8627e-02, 1.8616e-01, 5.1980e-01, 2.2952e-01,\n",
      "         1.0607e-02, 3.2529e-03, 4.5601e-04, 1.2696e-03],\n",
      "        [2.2786e-06, 4.3174e-05, 5.9493e-04, 4.9643e-03, 2.2377e-01, 7.2687e-01,\n",
      "         2.3281e-02, 1.5600e-02, 1.9827e-03, 2.8890e-03],\n",
      "        [5.4263e-06, 3.0158e-06, 1.2263e-05, 5.7765e-04, 1.7004e-02, 4.9682e-01,\n",
      "         4.0783e-02, 2.6201e-01, 7.7169e-02, 1.0561e-01],\n",
      "        [5.7170e-06, 1.3882e-05, 2.7276e-05, 8.2198e-05, 3.0415e-03, 7.2183e-02,\n",
      "         8.5159e-03, 2.4658e-01, 2.9722e-01, 3.7233e-01]])\n",
      "\n",
      "Epoch: 9.10, Train Loss: 1.70, Val Loss: 4.25, Train BLEU: 28.43, Val BLEU: 11.54, Minutes Elapsed: 477.02\n",
      "Sampling from training predictions...\n",
      "Source: chúng_ta đang nhìn_thấy đây là 160 - 175 độ ,\n",
      "Reference: but what you &apos;re seeing here is 160 to\n",
      "Model: <SOS> what &apos;re we &apos;re seeing here is 160 --\n",
      "Attention Weights: tensor([[3.3373e-02, 9.3784e-01, 2.8093e-02, 6.8452e-04, 1.0809e-05, 3.5236e-07,\n",
      "         3.7287e-08, 2.0292e-09, 4.9241e-09, 4.0552e-10],\n",
      "        [1.4174e-02, 9.5608e-01, 2.9632e-02, 9.9198e-05, 6.4146e-06, 9.7655e-06,\n",
      "         2.7932e-07, 1.5706e-07, 2.3097e-07, 1.8895e-08],\n",
      "        [4.0391e-02, 3.6893e-01, 5.6702e-01, 2.1472e-02, 1.2122e-03, 7.7195e-04,\n",
      "         8.4344e-05, 8.7323e-05, 2.8884e-05, 1.8861e-06],\n",
      "        [4.4467e-02, 5.8825e-01, 3.5555e-01, 9.9512e-03, 8.3887e-04, 7.2572e-04,\n",
      "         9.7542e-05, 7.1938e-05, 5.0328e-05, 2.6555e-06],\n",
      "        [3.9189e-03, 7.0811e-01, 2.5799e-01, 2.8043e-02, 1.3050e-03, 3.6228e-04,\n",
      "         1.4181e-04, 7.6546e-05, 4.4684e-05, 1.7959e-06],\n",
      "        [4.2520e-04, 3.3573e-03, 3.1665e-01, 6.1160e-01, 5.9699e-02, 1.9592e-03,\n",
      "         2.5543e-03, 1.5052e-03, 2.1607e-03, 8.9525e-05],\n",
      "        [6.0805e-04, 2.9224e-03, 2.3887e-01, 3.0901e-01, 2.8700e-01, 6.6458e-02,\n",
      "         3.7189e-02, 2.3667e-02, 3.2440e-02, 1.8435e-03],\n",
      "        [2.8894e-05, 3.9556e-04, 3.5549e-03, 2.2670e-02, 2.5927e-01, 1.2717e-01,\n",
      "         2.3703e-01, 1.4254e-01, 1.8022e-01, 2.7116e-02],\n",
      "        [7.0723e-06, 2.4455e-04, 2.3834e-03, 9.4780e-03, 5.2440e-02, 2.2908e-02,\n",
      "         1.4651e-01, 1.8617e-01, 5.0472e-01, 7.5139e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tất_cả đều có_thể với những thông_tin này . <EOS> <PAD>\n",
      "Reference: all this is possible with this information . <EOS>\n",
      "Model: <SOS> all can could to to information . . <EOS>\n",
      "Attention Weights: tensor([[0.7569, 0.2418, 0.0013, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1738, 0.7421, 0.0754, 0.0076, 0.0004, 0.0006, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0559, 0.3023, 0.1284, 0.4967, 0.0118, 0.0045, 0.0002, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0071, 0.2316, 0.1169, 0.5960, 0.0168, 0.0306, 0.0008, 0.0003, 0.0001,\n",
      "         0.0000],\n",
      "        [0.0023, 0.0953, 0.0733, 0.2463, 0.1548, 0.4005, 0.0199, 0.0057, 0.0018,\n",
      "         0.0000],\n",
      "        [0.0061, 0.0845, 0.0236, 0.1887, 0.1712, 0.4833, 0.0269, 0.0124, 0.0033,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0002, 0.0005, 0.0206, 0.1201, 0.5966, 0.1478, 0.0941, 0.0200,\n",
      "         0.0000],\n",
      "        [0.0004, 0.0041, 0.0024, 0.0128, 0.0141, 0.1347, 0.2757, 0.4084, 0.1474,\n",
      "         0.0000],\n",
      "        [0.0075, 0.0150, 0.0103, 0.0045, 0.0119, 0.1032, 0.1008, 0.3704, 0.3764,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 9.14, Train Loss: 1.73, Val Loss: 4.26, Train BLEU: 28.77, Val BLEU: 11.35, Minutes Elapsed: 479.55\n",
      "Sampling from training predictions...\n",
      "Source: chuyện gì sẽ xay ra khi bạn làm những việc\n",
      "Reference: what happens when you do other things , like\n",
      "Model: <SOS> what happens when you do things things things you\n",
      "Attention Weights: tensor([[1.2383e-01, 3.0096e-02, 6.7843e-01, 1.1664e-01, 5.0230e-02, 7.7653e-04,\n",
      "         1.3997e-06, 1.1786e-06, 1.4131e-08, 7.1230e-08],\n",
      "        [6.3092e-02, 2.0369e-03, 2.8552e-01, 3.9877e-01, 2.0033e-01, 4.9350e-02,\n",
      "         5.8061e-04, 3.0864e-04, 1.5158e-05, 5.7946e-06],\n",
      "        [1.1795e-02, 1.6591e-03, 1.8179e-02, 2.0726e-01, 6.0114e-01, 1.4931e-01,\n",
      "         6.0831e-03, 3.8981e-03, 5.4481e-04, 1.3369e-04],\n",
      "        [4.2891e-04, 4.0299e-05, 2.9843e-03, 5.6327e-02, 1.5286e-01, 3.0401e-01,\n",
      "         4.1759e-01, 5.3060e-02, 7.6559e-03, 5.0490e-03],\n",
      "        [6.2241e-06, 2.1932e-06, 2.5540e-04, 6.1026e-04, 6.7075e-03, 1.0160e-01,\n",
      "         2.5773e-01, 5.3716e-01, 5.9473e-02, 3.6460e-02],\n",
      "        [5.3934e-06, 2.6874e-06, 3.5157e-04, 1.3170e-03, 7.3779e-03, 8.3775e-03,\n",
      "         9.6765e-02, 2.8894e-01, 4.7529e-01, 1.2158e-01],\n",
      "        [3.3854e-07, 1.0166e-07, 1.5553e-06, 8.1816e-05, 4.9302e-04, 7.9670e-03,\n",
      "         2.3317e-03, 1.3845e-02, 2.3417e-01, 7.4111e-01],\n",
      "        [1.2710e-06, 1.1636e-06, 1.0798e-04, 6.0997e-04, 3.2543e-02, 4.6193e-01,\n",
      "         6.0355e-02, 6.2749e-02, 9.2235e-03, 3.7248e-01],\n",
      "        [1.1973e-05, 2.0095e-05, 6.4453e-04, 7.0142e-04, 2.8794e-02, 6.8860e-01,\n",
      "         2.1608e-01, 3.8188e-02, 2.1359e-03, 2.4820e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: chúng_ta cần các bạn để thấu_hiểu bí_mật của bạo_lực gia_đình\n",
      "Reference: we need every one of you to understand the\n",
      "Model: <SOS> we need you to to understand to the the\n",
      "Attention Weights: tensor([[1.0331e-01, 8.9625e-01, 3.0292e-04, 1.0483e-04, 2.1650e-05, 1.2572e-06,\n",
      "         6.3147e-07, 6.9470e-08, 1.6251e-08, 2.0986e-09],\n",
      "        [6.6307e-03, 9.9218e-01, 8.3457e-04, 8.0989e-05, 1.4737e-04, 1.1181e-04,\n",
      "         1.4327e-05, 1.0264e-06, 1.2293e-06, 2.4963e-07],\n",
      "        [5.2607e-02, 7.8089e-01, 7.2872e-02, 4.8280e-02, 4.0158e-02, 3.5626e-03,\n",
      "         1.4506e-03, 7.6053e-05, 7.7163e-05, 2.6667e-05],\n",
      "        [8.3365e-03, 5.4656e-01, 1.6087e-01, 1.0860e-01, 1.3411e-01, 3.0716e-02,\n",
      "         9.2208e-03, 5.7525e-04, 6.5308e-04, 3.5859e-04],\n",
      "        [1.9406e-04, 2.0717e-02, 2.1244e-02, 3.8226e-02, 2.9646e-01, 5.0566e-01,\n",
      "         1.1015e-01, 3.4377e-03, 2.9922e-03, 9.2435e-04],\n",
      "        [3.6576e-05, 2.0442e-03, 1.1206e-02, 2.6970e-02, 1.4389e-01, 6.8093e-01,\n",
      "         1.1966e-01, 5.3231e-03, 8.0058e-03, 1.9313e-03],\n",
      "        [4.9591e-06, 1.9470e-03, 5.2334e-03, 1.3707e-02, 5.2376e-02, 6.7509e-01,\n",
      "         2.0702e-01, 2.0499e-02, 2.1932e-02, 2.1922e-03],\n",
      "        [5.9437e-06, 8.6088e-04, 1.2832e-03, 2.7858e-03, 4.9376e-02, 5.3430e-01,\n",
      "         1.8539e-01, 4.4531e-02, 1.4326e-01, 3.8209e-02],\n",
      "        [3.2431e-07, 4.0077e-05, 5.7465e-04, 2.9289e-03, 2.7861e-02, 3.7302e-01,\n",
      "         4.0883e-01, 5.9315e-02, 9.4600e-02, 3.2833e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9.19, Train Loss: 1.89, Val Loss: 4.26, Train BLEU: 25.33, Val BLEU: 10.82, Minutes Elapsed: 482.12\n",
      "Sampling from training predictions...\n",
      "Source: chúng_tôi làm_cho nhiều thứ phát_triển . <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: we make things grow . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> we make things things . . . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9293, 0.0705, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0099, 0.9843, 0.0057, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0031, 0.1119, 0.7657, 0.1094, 0.0097, 0.0003, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0023, 0.0019, 0.4531, 0.4623, 0.0714, 0.0072, 0.0019, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0021, 0.0717, 0.6737, 0.1996, 0.0423, 0.0102, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0002, 0.0060, 0.1819, 0.5312, 0.1113, 0.1692, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0006, 0.0007, 0.0137, 0.4532, 0.1008, 0.1361, 0.2949, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0038, 0.0174, 0.0387, 0.1950, 0.4882, 0.0704, 0.1864, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0041, 0.0068, 0.0244, 0.1824, 0.3464, 0.1130, 0.3230, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: khi đó tôi 22 tuổi , vừa tốt_nghiệp trường cao_đẳng\n",
      "Reference: i was 22 . i had just graduated from\n",
      "Model: <SOS> then was 22 years old , to years ,\n",
      "Attention Weights: tensor([[3.5322e-01, 6.4662e-01, 1.5083e-04, 1.4374e-05, 3.4664e-07, 2.6364e-10,\n",
      "         1.2855e-10, 9.7230e-12, 5.3006e-12, 8.2184e-13],\n",
      "        [8.7059e-03, 7.3739e-01, 2.4680e-01, 5.8478e-03, 1.2194e-03, 7.0673e-06,\n",
      "         1.8495e-05, 5.3802e-06, 8.1056e-07, 5.1390e-07],\n",
      "        [6.2527e-03, 8.8862e-02, 3.4356e-01, 3.6554e-01, 1.8939e-01, 2.1225e-03,\n",
      "         2.8276e-03, 9.8217e-04, 2.9874e-04, 1.6826e-04],\n",
      "        [4.0310e-05, 8.1109e-05, 3.0927e-04, 4.5339e-02, 9.1371e-01, 3.2192e-02,\n",
      "         3.9624e-03, 1.4926e-03, 1.6758e-03, 1.2002e-03],\n",
      "        [2.4827e-05, 9.9165e-05, 1.0540e-03, 2.7294e-02, 7.1482e-01, 1.1554e-01,\n",
      "         1.2358e-01, 8.0449e-03, 7.1656e-03, 2.3747e-03],\n",
      "        [1.2818e-05, 2.0915e-04, 2.6332e-04, 3.0528e-03, 2.6978e-01, 1.4403e-01,\n",
      "         2.5916e-01, 2.4347e-01, 6.3368e-02, 1.6654e-02],\n",
      "        [1.9167e-05, 2.2178e-04, 1.5117e-04, 1.4580e-03, 2.3537e-02, 2.2504e-02,\n",
      "         2.5183e-01, 4.9585e-01, 1.0217e-01, 1.0226e-01],\n",
      "        [3.3193e-06, 3.4071e-06, 1.7797e-05, 1.1854e-03, 1.3253e-01, 4.4848e-02,\n",
      "         1.1511e-01, 2.0653e-01, 3.0248e-01, 1.9730e-01],\n",
      "        [3.7297e-06, 9.3486e-06, 2.1747e-05, 1.7228e-03, 2.4165e-02, 1.6852e-01,\n",
      "         3.2727e-01, 1.0048e-01, 1.9655e-01, 1.8126e-01]])\n",
      "\n",
      "Epoch: 9.24, Train Loss: 1.91, Val Loss: 4.26, Train BLEU: 25.33, Val BLEU: 11.04, Minutes Elapsed: 484.67\n",
      "Sampling from training predictions...\n",
      "Source: phải thuê quân_đội và sát_hạch phi_cơ để điều_khiển máy_bay .\n",
      "Reference: we hire military and test pilots to do the\n",
      "Model: <SOS> it hire to and and and to to the\n",
      "Attention Weights: tensor([[7.9601e-01, 1.9790e-01, 6.0791e-03, 6.4457e-06, 1.2835e-07, 1.0147e-07,\n",
      "         4.7196e-08, 2.9672e-09, 1.9515e-10, 2.5736e-11],\n",
      "        [3.4407e-01, 4.9864e-01, 1.5467e-01, 9.5194e-04, 1.2335e-03, 1.8616e-04,\n",
      "         1.5116e-04, 8.2027e-05, 9.7553e-06, 1.9212e-06],\n",
      "        [3.8425e-02, 7.8782e-02, 8.3710e-01, 2.8354e-02, 1.3241e-02, 2.6422e-03,\n",
      "         8.3256e-04, 4.7977e-04, 1.2484e-04, 1.4430e-05],\n",
      "        [5.0811e-03, 2.4122e-01, 6.9618e-01, 2.6848e-02, 2.2204e-02, 7.5787e-03,\n",
      "         5.7877e-04, 2.6697e-04, 3.4376e-05, 7.9156e-06],\n",
      "        [3.4650e-03, 2.6130e-02, 2.9556e-01, 2.3948e-01, 2.3115e-01, 1.5368e-01,\n",
      "         4.1832e-02, 7.2582e-03, 1.0613e-03, 3.8299e-04],\n",
      "        [7.1996e-04, 2.6903e-03, 2.7166e-02, 1.3276e-01, 3.7140e-01, 3.4742e-01,\n",
      "         7.2874e-02, 3.9757e-02, 4.6163e-03, 5.9827e-04],\n",
      "        [2.5625e-05, 2.7278e-04, 1.9635e-03, 1.5890e-02, 1.7811e-01, 2.9526e-01,\n",
      "         2.3967e-01, 2.3461e-01, 3.2156e-02, 2.0417e-03],\n",
      "        [1.7664e-06, 7.8155e-05, 1.2079e-03, 3.5411e-03, 4.9600e-02, 7.8730e-02,\n",
      "         1.4774e-01, 6.0015e-01, 1.1094e-01, 8.0088e-03],\n",
      "        [2.3997e-06, 6.1480e-05, 1.4083e-03, 1.2675e-03, 1.4710e-02, 4.9245e-02,\n",
      "         4.5980e-02, 5.2796e-01, 3.2664e-01, 3.2723e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: chúng_ta đang ở giai_đoạn cuối_cùng của cuộc cách_mạng công_nghiệp đầu_tiên\n",
      "Reference: we are at the end of the first industrial\n",
      "Model: <SOS> we &apos;re at the beginning of the first revolution\n",
      "Attention Weights: tensor([[4.3050e-02, 6.6118e-01, 2.9536e-01, 3.7772e-04, 2.6459e-05, 6.1509e-06,\n",
      "         3.7822e-07, 1.1807e-07, 1.4288e-08, 4.5360e-09],\n",
      "        [3.4335e-03, 8.7594e-01, 1.1951e-01, 9.6255e-04, 1.0569e-04, 5.8085e-06,\n",
      "         1.9291e-05, 2.1990e-05, 4.6121e-06, 7.4336e-07],\n",
      "        [2.3727e-03, 2.9709e-01, 6.0747e-01, 8.5523e-02, 6.1611e-03, 4.5637e-04,\n",
      "         5.7626e-04, 2.2746e-04, 1.0697e-04, 1.8965e-05],\n",
      "        [5.9498e-06, 5.2331e-05, 1.0242e-02, 7.1511e-01, 2.3765e-01, 8.6416e-03,\n",
      "         1.5276e-02, 1.0556e-02, 1.8231e-03, 6.4206e-04],\n",
      "        [1.5632e-06, 6.3904e-06, 1.5065e-03, 4.0598e-01, 4.3700e-01, 2.9793e-02,\n",
      "         5.7772e-02, 5.4903e-02, 1.0870e-02, 2.1709e-03],\n",
      "        [1.1205e-05, 1.1644e-05, 3.7682e-04, 7.8443e-02, 1.3429e-01, 3.5533e-01,\n",
      "         1.9480e-01, 2.1172e-01, 2.3539e-02, 1.4717e-03],\n",
      "        [2.7728e-05, 1.0848e-05, 1.3119e-04, 5.3877e-03, 4.0553e-02, 1.0117e-01,\n",
      "         2.6028e-01, 5.1662e-01, 6.9664e-02, 6.1545e-03],\n",
      "        [1.6404e-06, 3.4531e-06, 3.2298e-05, 9.5909e-03, 7.9421e-02, 4.6789e-02,\n",
      "         1.2971e-01, 3.9748e-01, 2.6130e-01, 7.5672e-02],\n",
      "        [1.5116e-05, 2.2405e-05, 7.0573e-05, 9.2383e-03, 9.9340e-03, 4.1855e-02,\n",
      "         1.9223e-01, 5.5116e-01, 1.5999e-01, 3.5494e-02]])\n",
      "\n",
      "Epoch: 9.29, Train Loss: 1.97, Val Loss: 4.30, Train BLEU: 23.51, Val BLEU: 10.90, Minutes Elapsed: 487.20\n",
      "Sampling from training predictions...\n",
      "Source: là một nhà làm phim , điều đó làm_tôi lo_ngại\n",
      "Reference: as a filmmaker , it worried me . <EOS>\n",
      "Model: <SOS> as a filmmaker , it was kind . <EOS>\n",
      "Attention Weights: tensor([[9.9981e-01, 1.9180e-04, 5.8936e-07, 5.6801e-07, 2.0744e-08, 1.6895e-09,\n",
      "         6.8902e-10, 2.5238e-11, 5.8127e-12, 2.3050e-12],\n",
      "        [2.0173e-01, 2.2745e-01, 2.7174e-01, 1.9778e-01, 9.5267e-02, 1.8784e-03,\n",
      "         2.7477e-03, 5.6097e-04, 6.2463e-04, 2.2009e-04],\n",
      "        [1.4426e-01, 2.8442e-02, 2.3485e-01, 1.1617e-01, 4.4776e-01, 1.4449e-02,\n",
      "         3.2668e-03, 1.7459e-03, 4.5474e-03, 4.5071e-03],\n",
      "        [1.4023e-02, 2.2522e-03, 2.0572e-01, 2.5171e-01, 3.3513e-01, 1.4235e-01,\n",
      "         2.4652e-02, 6.6503e-03, 8.0815e-03, 9.4325e-03],\n",
      "        [1.1909e-03, 3.6264e-04, 3.9943e-02, 6.5166e-02, 7.3884e-02, 2.7669e-01,\n",
      "         5.0979e-01, 1.3062e-02, 1.4348e-02, 5.5670e-03],\n",
      "        [6.8470e-04, 2.6902e-04, 2.9019e-03, 1.0324e-02, 5.2348e-02, 2.8367e-02,\n",
      "         5.3495e-01, 1.2026e-01, 1.8016e-01, 6.9741e-02],\n",
      "        [5.8380e-03, 4.9461e-04, 1.3404e-03, 2.1273e-03, 1.2828e-02, 3.6214e-03,\n",
      "         8.8330e-03, 1.2111e-02, 3.4184e-01, 6.1097e-01],\n",
      "        [1.7849e-06, 6.7513e-06, 2.6428e-04, 5.7111e-04, 1.2405e-02, 1.3344e-02,\n",
      "         2.9060e-03, 5.1661e-04, 4.9709e-02, 9.2028e-01],\n",
      "        [6.2627e-05, 2.3263e-05, 1.1002e-04, 3.9466e-04, 4.0145e-03, 4.8864e-02,\n",
      "         4.1097e-01, 6.1597e-02, 3.7547e-01, 9.8501e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: người phiên_dịch của tôi kể_chuyện của họ . <EOS> <PAD>\n",
      "Reference: my interpreter told me their stories . <EOS> <PAD>\n",
      "Model: <SOS> my &apos;s is their story <EOS> <EOS> <EOS> .\n",
      "Attention Weights: tensor([[0.6147, 0.3848, 0.0004, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0044, 0.9428, 0.0356, 0.0121, 0.0051, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0223, 0.0623, 0.3964, 0.2319, 0.2524, 0.0304, 0.0027, 0.0011, 0.0003,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0003, 0.0064, 0.1864, 0.7008, 0.0554, 0.0329, 0.0135, 0.0042,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0001, 0.0005, 0.8943, 0.0183, 0.0257, 0.0433, 0.0178,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0002, 0.0003, 0.2905, 0.0366, 0.0248, 0.3282, 0.3195,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0007, 0.0084, 0.0038, 0.3974, 0.0710, 0.0518, 0.2207, 0.2462,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0008, 0.0006, 0.0311, 0.0042, 0.0151, 0.3859, 0.5624,\n",
      "         0.0000],\n",
      "        [0.0015, 0.0522, 0.0202, 0.0294, 0.5724, 0.0075, 0.0118, 0.0926, 0.2124,\n",
      "         0.0000]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9.34, Train Loss: 1.99, Val Loss: 4.30, Train BLEU: 23.37, Val BLEU: 10.08, Minutes Elapsed: 489.75\n",
      "Sampling from training predictions...\n",
      "Source: liệu họ không_thể nhìn thấy điều đó theo cách này\n",
      "Reference: would they not be able to see it this\n",
      "Model: <SOS> can they not see at at see this this\n",
      "Attention Weights: tensor([[9.9999e-01, 2.0729e-06, 8.8245e-06, 1.1178e-06, 3.0218e-08, 5.6783e-10,\n",
      "         3.3975e-09, 5.9908e-11, 1.9217e-12, 2.9399e-12],\n",
      "        [3.6364e-01, 1.0660e-01, 5.2906e-01, 4.7438e-04, 2.1575e-04, 8.3140e-06,\n",
      "         7.3751e-07, 8.5194e-07, 5.1870e-07, 5.8675e-08],\n",
      "        [2.8521e-02, 4.1761e-03, 9.4127e-01, 1.1651e-02, 1.3506e-02, 7.2646e-04,\n",
      "         7.3746e-05, 5.4711e-05, 2.1372e-05, 2.7892e-06],\n",
      "        [1.9451e-02, 1.5446e-03, 5.9468e-02, 4.2315e-01, 4.0312e-01, 8.2313e-02,\n",
      "         7.1229e-03, 2.5423e-03, 1.1993e-03, 8.8993e-05],\n",
      "        [1.8052e-03, 5.0609e-04, 1.5823e-03, 2.2335e-01, 2.3214e-01, 2.7532e-01,\n",
      "         6.4671e-02, 1.3261e-01, 6.6856e-02, 1.1511e-03],\n",
      "        [8.7926e-04, 3.2181e-04, 2.8720e-04, 2.6913e-02, 1.0668e-01, 2.7871e-01,\n",
      "         2.7698e-01, 1.9919e-01, 1.0392e-01, 6.1150e-03],\n",
      "        [6.7549e-04, 7.7845e-05, 1.7774e-04, 1.6941e-02, 1.2996e-01, 3.8785e-01,\n",
      "         2.1102e-01, 1.3037e-01, 1.1092e-01, 1.2009e-02],\n",
      "        [1.4264e-05, 1.1989e-05, 2.1497e-04, 1.0064e-02, 5.3081e-02, 3.9957e-01,\n",
      "         1.5573e-01, 1.9655e-01, 1.7214e-01, 1.2625e-02],\n",
      "        [9.3796e-06, 6.2625e-06, 4.3314e-05, 1.9186e-03, 2.9137e-02, 2.2952e-01,\n",
      "         1.8565e-01, 2.4658e-01, 2.7588e-01, 3.1246e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: một buổi sáng mà tôi không_thể nào quên được .\n",
      "Reference: a morning that i will never forget . <EOS>\n",
      "Model: <SOS> a was twist i can &apos;t be the .\n",
      "Attention Weights: tensor([[9.1275e-01, 3.2658e-02, 5.4586e-02, 3.5084e-06, 2.3983e-07, 6.7969e-08,\n",
      "         1.7119e-09, 1.2318e-10, 4.4728e-11, 3.5764e-11],\n",
      "        [4.3571e-03, 1.1495e-01, 8.6887e-01, 1.0143e-02, 2.6785e-04, 1.3780e-03,\n",
      "         1.9201e-05, 1.2156e-05, 2.7553e-06, 4.9448e-07],\n",
      "        [2.3739e-02, 4.4820e-01, 4.9614e-01, 2.1662e-02, 1.7360e-03, 7.3403e-03,\n",
      "         6.2063e-04, 5.1057e-04, 4.9345e-05, 3.6230e-06],\n",
      "        [2.7488e-03, 1.1526e-01, 1.0501e-01, 6.3950e-01, 3.9896e-02, 8.9854e-02,\n",
      "         3.1038e-03, 3.1695e-03, 1.3016e-03, 1.5115e-04],\n",
      "        [2.5440e-04, 4.1882e-03, 1.0540e-02, 6.6348e-02, 2.8557e-01, 5.5755e-01,\n",
      "         3.7909e-02, 3.2846e-02, 4.1550e-03, 6.4003e-04],\n",
      "        [2.4311e-04, 1.3404e-03, 1.6263e-03, 2.8479e-03, 1.5690e-02, 8.0755e-01,\n",
      "         1.0963e-01, 5.5292e-02, 5.4556e-03, 3.2193e-04],\n",
      "        [4.8745e-05, 9.4035e-04, 2.5269e-04, 7.9539e-04, 6.4779e-04, 4.0683e-02,\n",
      "         5.8012e-01, 3.4704e-01, 2.7085e-02, 2.3909e-03],\n",
      "        [2.5429e-05, 1.4763e-04, 1.9480e-04, 3.7700e-04, 2.4141e-04, 4.9652e-03,\n",
      "         1.0971e-01, 7.5041e-01, 1.1541e-01, 1.8522e-02],\n",
      "        [5.3341e-04, 5.3995e-03, 2.1264e-02, 2.7817e-03, 9.5350e-04, 4.8569e-03,\n",
      "         9.3657e-02, 5.0149e-01, 2.7144e-01, 9.7619e-02]])\n",
      "\n",
      "Epoch: 9.38, Train Loss: 1.98, Val Loss: 4.28, Train BLEU: 22.64, Val BLEU: 10.69, Minutes Elapsed: 492.30\n",
      "Sampling from training predictions...\n",
      "Source: có_phải đó là một mô_hình sáng_tạo ? <EOS> <PAD> <PAD>\n",
      "Reference: is that a kind of model for creativity ?\n",
      "Model: <SOS> is it a model of model ? <EOS> ?\n",
      "Attention Weights: tensor([[0.9997, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.6927, 0.0410, 0.0923, 0.1679, 0.0053, 0.0009, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2382, 0.0241, 0.1326, 0.3738, 0.1755, 0.0552, 0.0005, 0.0002, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0106, 0.0056, 0.0235, 0.0696, 0.5671, 0.3038, 0.0153, 0.0046, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0010, 0.0241, 0.0589, 0.0880, 0.6429, 0.0818, 0.0430, 0.0603, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0033, 0.0077, 0.0086, 0.2378, 0.2827, 0.1967, 0.2631, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0022, 0.0152, 0.0222, 0.0193, 0.4127, 0.1618, 0.1130, 0.2538, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0074, 0.0084, 0.0262, 0.0273, 0.1848, 0.1461, 0.1422, 0.4576, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0541, 0.0259, 0.1784, 0.1623, 0.2047, 0.2029, 0.0590, 0.1127, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: và tôi muốn chia_sẻ một_vài điều về cái mọi người\n",
      "Reference: and i &apos;d like to share a few things\n",
      "Model: <SOS> and i want like to share some couple about\n",
      "Attention Weights: tensor([[6.2848e-06, 1.0340e-03, 8.9520e-01, 1.0253e-01, 1.1293e-03, 9.7137e-05,\n",
      "         2.5041e-06, 6.7655e-07, 1.1773e-06, 1.5163e-06],\n",
      "        [2.5040e-03, 5.4134e-01, 4.5590e-01, 2.5087e-04, 1.0386e-06, 3.3411e-07,\n",
      "         7.6038e-08, 4.3739e-08, 4.7597e-08, 7.1789e-08],\n",
      "        [9.8397e-07, 1.2326e-02, 9.8251e-01, 4.9212e-03, 2.0170e-04, 1.8457e-05,\n",
      "         8.0235e-06, 3.3098e-06, 3.8792e-06, 4.5219e-06],\n",
      "        [1.0277e-05, 1.7608e-03, 9.3846e-01, 5.8595e-02, 1.0483e-03, 5.7419e-05,\n",
      "         2.7910e-05, 1.3427e-05, 1.3405e-05, 1.1723e-05],\n",
      "        [1.0527e-06, 1.0961e-04, 1.6834e-02, 9.3084e-01, 4.4612e-02, 4.0035e-03,\n",
      "         1.3139e-03, 8.7193e-04, 9.6098e-04, 4.5442e-04],\n",
      "        [3.7516e-06, 2.2302e-04, 8.8702e-03, 8.3862e-01, 1.1656e-01, 1.8264e-02,\n",
      "         8.1054e-03, 3.9932e-03, 3.8897e-03, 1.4727e-03],\n",
      "        [4.0562e-07, 7.4369e-05, 3.2929e-03, 1.0183e-01, 7.7428e-01, 9.5164e-02,\n",
      "         1.2801e-02, 7.1492e-03, 4.1412e-03, 1.2661e-03],\n",
      "        [5.0925e-08, 6.3142e-06, 1.3799e-04, 7.6491e-02, 6.1151e-01, 1.9430e-01,\n",
      "         5.8962e-02, 3.6844e-02, 1.6546e-02, 5.2089e-03],\n",
      "        [2.5682e-09, 1.0408e-06, 4.4743e-05, 1.0887e-02, 1.5052e-01, 2.6186e-01,\n",
      "         2.7536e-01, 1.3498e-01, 1.2707e-01, 3.9286e-02]])\n",
      "\n",
      "Epoch: 9.43, Train Loss: 2.04, Val Loss: 4.25, Train BLEU: 21.80, Val BLEU: 10.70, Minutes Elapsed: 494.88\n",
      "Sampling from training predictions...\n",
      "Source: thực_tế , thậm_chí khi chúng_tôi yêu_cầu những người tự cho_là\n",
      "Reference: in fact , even when we gave self-declared atheists\n",
      "Model: <SOS> in fact , as as we were self-declared atheists\n",
      "Attention Weights: tensor([[9.9985e-01, 1.1005e-04, 4.2436e-05, 1.4372e-08, 7.9736e-11, 2.5865e-10,\n",
      "         5.8429e-12, 7.2448e-12, 2.7611e-12, 3.9566e-13],\n",
      "        [9.5801e-01, 2.1811e-02, 2.0108e-02, 5.5651e-05, 1.6657e-06, 7.3236e-06,\n",
      "         1.3297e-06, 3.7115e-07, 1.7639e-07, 4.7005e-08],\n",
      "        [2.9663e-01, 2.3842e-01, 4.4843e-01, 1.1764e-02, 8.3519e-04, 1.9916e-03,\n",
      "         8.9179e-04, 7.4113e-04, 2.3523e-04, 6.0779e-05],\n",
      "        [4.9069e-03, 4.0529e-02, 9.1477e-01, 3.7108e-02, 7.0196e-04, 1.1089e-03,\n",
      "         4.1901e-04, 3.1912e-04, 1.0293e-04, 3.2923e-05],\n",
      "        [1.5575e-02, 2.1342e-02, 7.8847e-01, 1.0775e-01, 1.0135e-02, 4.9597e-02,\n",
      "         4.2328e-03, 1.8004e-03, 8.5857e-04, 2.4506e-04],\n",
      "        [2.5264e-03, 2.7970e-03, 1.8701e-01, 2.5471e-01, 6.5066e-02, 3.7714e-01,\n",
      "         5.8541e-02, 3.3831e-02, 1.4829e-02, 3.5587e-03],\n",
      "        [2.7398e-06, 2.2765e-05, 2.3650e-03, 7.1021e-03, 3.8000e-02, 8.7635e-01,\n",
      "         3.4052e-02, 2.0321e-02, 1.7399e-02, 4.3877e-03],\n",
      "        [1.4305e-05, 1.1516e-05, 1.0910e-04, 3.5820e-03, 9.6756e-03, 6.2967e-01,\n",
      "         8.9316e-02, 7.4351e-02, 1.7007e-01, 2.3199e-02],\n",
      "        [5.1162e-05, 7.5568e-06, 1.1084e-04, 1.0324e-04, 8.3513e-05, 5.6616e-03,\n",
      "         1.0950e-01, 5.9895e-01, 1.5074e-01, 1.3479e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: đờ_đẫn bởi sự đơn_điệu và kiệt_sức , họ câm_lặng làm_việc\n",
      "Reference: <UNK> by <UNK> and exhaustion , they work silently\n",
      "Model: <SOS> so and and , and , they do to\n",
      "Attention Weights: tensor([[9.8674e-01, 1.3180e-02, 7.4627e-05, 5.5771e-06, 7.9936e-08, 4.3288e-08,\n",
      "         9.0191e-10, 4.9058e-10, 2.0652e-09, 5.6593e-10],\n",
      "        [6.4914e-02, 6.0670e-01, 1.9065e-01, 1.3270e-01, 1.1690e-03, 3.7720e-03,\n",
      "         3.2124e-05, 4.8129e-06, 4.2992e-05, 1.0387e-05],\n",
      "        [2.6771e-02, 1.5400e-01, 4.6360e-01, 3.0745e-01, 2.9237e-02, 1.8704e-02,\n",
      "         1.7379e-04, 2.0140e-05, 3.4318e-05, 1.0759e-05],\n",
      "        [1.6568e-06, 1.2544e-04, 2.3117e-02, 2.7916e-01, 1.3316e-01, 5.5105e-01,\n",
      "         1.0501e-02, 1.0942e-03, 1.2697e-03, 5.1916e-04],\n",
      "        [1.2043e-06, 1.3399e-05, 4.2647e-03, 1.5008e-02, 1.5399e-01, 1.9752e-01,\n",
      "         5.5627e-01, 5.5063e-02, 1.5994e-02, 1.8728e-03],\n",
      "        [3.7941e-07, 7.3672e-06, 3.1158e-05, 1.4756e-04, 4.3433e-04, 1.1920e-02,\n",
      "         9.0738e-02, 1.2280e-01, 7.5916e-01, 1.4762e-02],\n",
      "        [1.5486e-06, 6.1590e-05, 1.6267e-04, 2.8569e-04, 1.0790e-04, 2.3944e-03,\n",
      "         1.7553e-02, 2.9792e-02, 8.0005e-01, 1.4960e-01],\n",
      "        [5.9981e-07, 4.9927e-06, 8.9578e-05, 5.4319e-04, 2.2173e-04, 1.4360e-03,\n",
      "         6.3632e-03, 8.4623e-03, 5.0628e-01, 4.7660e-01],\n",
      "        [1.3761e-05, 4.8578e-04, 2.0475e-03, 9.1428e-04, 1.4462e-04, 8.0204e-04,\n",
      "         2.2876e-03, 6.1517e-03, 6.7286e-01, 3.1430e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9.48, Train Loss: 2.04, Val Loss: 4.24, Train BLEU: 22.38, Val BLEU: 10.51, Minutes Elapsed: 497.44\n",
      "Sampling from training predictions...\n",
      "Source: nhạc_sống , và nhạc thu âm . <EOS> <PAD> <PAD>\n",
      "Reference: there &apos;s live music , and there &apos;s recorded\n",
      "Model: <SOS> clearly , and , and you you <UNK> .\n",
      "Attention Weights: tensor([[0.9999, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.9456, 0.0543, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2116, 0.2256, 0.3712, 0.1812, 0.0080, 0.0020, 0.0003, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.3799, 0.3560, 0.0907, 0.1054, 0.0612, 0.0051, 0.0015, 0.0003, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0383, 0.6799, 0.1792, 0.0866, 0.0117, 0.0015, 0.0022, 0.0005, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0127, 0.0351, 0.1332, 0.6457, 0.1513, 0.0090, 0.0082, 0.0047, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0192, 0.0086, 0.0118, 0.4611, 0.4410, 0.0318, 0.0186, 0.0079, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0049, 0.0083, 0.0002, 0.0496, 0.7294, 0.1694, 0.0315, 0.0067, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0026, 0.0209, 0.0006, 0.0620, 0.3315, 0.4100, 0.1308, 0.0416, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: và mảnh vườn , nó rất đẹp . <EOS> <PAD>\n",
      "Reference: and the garden , it was beautiful . <EOS>\n",
      "Model: <SOS> and the the , , was very . <EOS>\n",
      "Attention Weights: tensor([[0.0001, 0.9994, 0.0005, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0009, 0.9502, 0.0478, 0.0010, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.6492, 0.3096, 0.0358, 0.0018, 0.0023, 0.0011, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0003, 0.3014, 0.1835, 0.3855, 0.0187, 0.0794, 0.0306, 0.0004, 0.0002,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0042, 0.0371, 0.9069, 0.0336, 0.0129, 0.0047, 0.0005, 0.0001,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0178, 0.0969, 0.2497, 0.1236, 0.3916, 0.0698, 0.0388, 0.0119,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0005, 0.0014, 0.0020, 0.0177, 0.6097, 0.3493, 0.0124, 0.0069,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0016, 0.0213, 0.0241, 0.0026, 0.0597, 0.5134, 0.1816, 0.1957,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0018, 0.0187, 0.1069, 0.0108, 0.0111, 0.0610, 0.2962, 0.4934,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 9.53, Train Loss: 2.01, Val Loss: 4.27, Train BLEU: 22.96, Val BLEU: 11.19, Minutes Elapsed: 500.02\n",
      "Sampling from training predictions...\n",
      "Source: nhưng cuối_cùng thì mọi việc dường_như đã ổn . <EOS>\n",
      "Reference: but in the end everything seemed to be under\n",
      "Model: <SOS> but finally the end everything everything the . .\n",
      "Attention Weights: tensor([[2.1696e-01, 7.7461e-01, 4.1457e-03, 4.0993e-03, 1.4838e-04, 3.1139e-05,\n",
      "         9.5640e-07, 5.0303e-07, 7.1393e-08, 4.3432e-09],\n",
      "        [1.7057e-03, 9.9614e-01, 1.4059e-03, 5.9945e-04, 1.3145e-04, 1.1955e-05,\n",
      "         5.3634e-07, 6.2972e-07, 6.9413e-08, 7.5046e-09],\n",
      "        [1.6850e-02, 3.8698e-01, 5.6507e-02, 3.9488e-01, 9.6563e-02, 4.3720e-02,\n",
      "         3.5218e-03, 9.1700e-04, 5.4333e-05, 9.4582e-06],\n",
      "        [6.7926e-03, 1.4915e-02, 5.4544e-02, 3.7202e-01, 3.1907e-01, 2.0427e-01,\n",
      "         1.5499e-02, 1.0977e-02, 1.3989e-03, 5.1922e-04],\n",
      "        [4.7196e-04, 3.5538e-04, 2.8938e-02, 7.2865e-01, 1.4230e-01, 7.3929e-02,\n",
      "         1.5759e-02, 7.5498e-03, 1.5681e-03, 4.7857e-04],\n",
      "        [2.2740e-04, 7.6737e-04, 3.8698e-02, 7.7411e-01, 9.8249e-02, 6.2985e-02,\n",
      "         1.6592e-02, 6.9694e-03, 1.1092e-03, 2.8795e-04],\n",
      "        [3.7838e-05, 1.0491e-03, 2.4460e-03, 1.3699e-01, 2.9422e-01, 4.8210e-01,\n",
      "         3.1475e-02, 3.3529e-02, 1.2980e-02, 5.1706e-03],\n",
      "        [1.1606e-05, 2.3783e-04, 5.8770e-04, 2.5535e-02, 1.1363e-01, 4.8555e-01,\n",
      "         1.8572e-01, 1.4816e-01, 2.2273e-02, 1.8297e-02],\n",
      "        [7.0750e-06, 3.1003e-04, 4.2803e-04, 1.8247e-02, 3.6885e-02, 1.7078e-01,\n",
      "         1.4337e-01, 4.6769e-01, 5.2696e-02, 1.0958e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: chúng_tôi cần phát_triển một cuộc đàm_luận mang tính nữ không\n",
      "Reference: we need to develop a feminine discourse that not\n",
      "Model: <SOS> we needed to develop a new that that our\n",
      "Attention Weights: tensor([[3.6296e-02, 9.6179e-01, 1.9072e-03, 3.5228e-06, 3.9461e-07, 6.4974e-07,\n",
      "         1.4982e-08, 1.0547e-08, 1.4108e-08, 3.6856e-09],\n",
      "        [1.9171e-02, 9.7963e-01, 1.1975e-03, 3.0480e-06, 2.0104e-06, 6.2398e-07,\n",
      "         9.0549e-08, 7.3962e-08, 3.0122e-09, 3.7585e-09],\n",
      "        [6.8853e-03, 8.2864e-01, 1.5405e-01, 7.2437e-03, 2.3719e-03, 6.5449e-04,\n",
      "         7.1183e-05, 7.3504e-05, 3.6286e-06, 3.0522e-06],\n",
      "        [7.5216e-04, 1.3705e-02, 8.6678e-01, 4.6305e-02, 5.9396e-02, 1.1678e-02,\n",
      "         6.7515e-04, 6.2580e-04, 5.1179e-05, 2.9125e-05],\n",
      "        [5.5901e-05, 3.2408e-03, 1.5840e-01, 6.6706e-01, 1.2266e-01, 3.8274e-02,\n",
      "         6.2741e-03, 3.5499e-03, 4.1730e-04, 5.9527e-05],\n",
      "        [9.5004e-05, 2.4255e-04, 1.1923e-02, 6.7710e-02, 5.1786e-01, 3.3551e-01,\n",
      "         2.4029e-02, 3.9027e-02, 2.7140e-03, 8.9708e-04],\n",
      "        [4.8950e-05, 2.4073e-04, 1.8725e-03, 4.2171e-03, 2.0597e-01, 3.0263e-01,\n",
      "         4.1052e-01, 5.5471e-02, 1.1197e-02, 7.8364e-03],\n",
      "        [5.8461e-07, 6.2110e-05, 1.3062e-03, 4.8775e-03, 3.3011e-02, 1.3597e-01,\n",
      "         4.8326e-01, 2.6734e-01, 4.6062e-02, 2.8118e-02],\n",
      "        [1.3884e-06, 3.0636e-05, 1.8601e-04, 5.2352e-03, 7.1885e-03, 7.5659e-02,\n",
      "         1.3907e-01, 5.7608e-01, 1.1584e-01, 8.0716e-02]])\n",
      "\n",
      "Epoch: 9.58, Train Loss: 2.04, Val Loss: 4.29, Train BLEU: 22.55, Val BLEU: 11.05, Minutes Elapsed: 502.59\n",
      "Sampling from training predictions...\n",
      "Source: chị ấy khồng nghĩ tôi sẽ đi . <EOS> <PAD>\n",
      "Reference: she didn &apos;t expect me to go there .\n",
      "Model: <SOS> she didn &apos;t think me go . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.3063, 0.3500, 0.3420, 0.0018, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0046, 0.0248, 0.9326, 0.0377, 0.0000, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0034, 0.0032, 0.5938, 0.3734, 0.0093, 0.0160, 0.0007, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0005, 0.0005, 0.0701, 0.5101, 0.1192, 0.2438, 0.0534, 0.0020, 0.0004,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0058, 0.1382, 0.0505, 0.3284, 0.4562, 0.0189, 0.0019,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0008, 0.0127, 0.0684, 0.4624, 0.3639, 0.0669, 0.0250,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0006, 0.0076, 0.0178, 0.1417, 0.3444, 0.2281, 0.2598,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0011, 0.0062, 0.0186, 0.0752, 0.0387, 0.1994, 0.6607,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0043, 0.0243, 0.0410, 0.0731, 0.0422, 0.1289, 0.6862,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: và anh ta nói rằng anh ta cần những cây\n",
      "Reference: and he said that he needed those guns because\n",
      "Model: <SOS> and he said that he need to forms .\n",
      "Attention Weights: tensor([[3.9400e-02, 9.1508e-01, 3.2384e-02, 5.5562e-03, 7.4909e-03, 8.8750e-05,\n",
      "         2.1760e-07, 1.1106e-07, 2.5484e-08, 9.1640e-08],\n",
      "        [3.9562e-03, 9.6071e-01, 3.3471e-02, 1.7647e-03, 9.0491e-05, 5.0998e-06,\n",
      "         1.3147e-07, 1.0267e-07, 6.4429e-09, 4.7621e-09],\n",
      "        [1.8396e-06, 2.8960e-04, 1.1969e-03, 9.0015e-01, 9.4569e-02, 1.3204e-03,\n",
      "         5.1852e-04, 1.9229e-03, 2.0019e-05, 7.4664e-06],\n",
      "        [5.5465e-06, 7.5846e-05, 2.3584e-03, 3.0543e-01, 6.4828e-01, 3.5539e-02,\n",
      "         4.7153e-03, 2.6479e-03, 8.0455e-04, 1.4317e-04],\n",
      "        [1.0904e-05, 9.8881e-05, 4.6939e-04, 5.4765e-03, 5.4871e-02, 5.9553e-01,\n",
      "         1.5303e-01, 1.2532e-01, 5.5135e-02, 1.0059e-02],\n",
      "        [2.9576e-07, 3.1707e-06, 4.6287e-05, 1.0184e-02, 2.9618e-03, 9.2442e-03,\n",
      "         8.3975e-02, 8.8253e-01, 7.3639e-03, 3.6948e-03],\n",
      "        [2.3582e-07, 3.6575e-07, 2.0917e-06, 3.0953e-03, 3.3173e-03, 1.7466e-03,\n",
      "         1.2540e-02, 5.4966e-01, 3.0081e-01, 1.2883e-01],\n",
      "        [1.2299e-07, 1.9887e-06, 9.2271e-07, 1.7034e-04, 2.2598e-03, 2.6679e-03,\n",
      "         8.4526e-04, 6.5990e-02, 4.7651e-01, 4.5155e-01],\n",
      "        [8.1216e-06, 8.4853e-05, 2.8490e-05, 1.2618e-03, 9.6242e-03, 1.0485e-02,\n",
      "         3.3450e-03, 2.0086e-01, 3.8881e-01, 3.8548e-01]])\n",
      "\n",
      "Epoch: 9.62, Train Loss: 2.08, Val Loss: 4.30, Train BLEU: 22.76, Val BLEU: 11.40, Minutes Elapsed: 505.16\n",
      "Sampling from training predictions...\n",
      "Source: một_số băn_khoăn nặng_nề hơn , như_là cuộc_sống của mario sẽ\n",
      "Reference: some more tough , like , really , what\n",
      "Model: <SOS> some of the , like like the the the\n",
      "Attention Weights: tensor([[9.9902e-01, 8.0921e-04, 1.6481e-04, 4.0904e-06, 2.3909e-08, 3.3783e-09,\n",
      "         7.7476e-10, 1.7181e-10, 2.6655e-11, 3.1819e-11],\n",
      "        [1.5958e-01, 7.9455e-01, 3.6566e-02, 8.9698e-03, 2.5060e-04, 1.1176e-05,\n",
      "         6.3578e-05, 5.0204e-06, 4.1447e-06, 1.0137e-06],\n",
      "        [6.4349e-02, 1.9720e-01, 4.2082e-01, 2.7166e-01, 4.5176e-02, 2.7561e-04,\n",
      "         3.6768e-04, 9.9440e-05, 3.8063e-05, 1.4489e-05],\n",
      "        [1.1191e-02, 1.9655e-01, 2.9547e-01, 2.8989e-01, 1.8122e-01, 9.0648e-03,\n",
      "         9.9055e-03, 2.0084e-03, 4.2454e-03, 4.4908e-04],\n",
      "        [3.2699e-03, 2.7989e-02, 6.7137e-02, 8.1500e-02, 6.3988e-01, 1.3113e-01,\n",
      "         2.8591e-02, 3.4270e-03, 1.4962e-02, 2.1111e-03],\n",
      "        [1.7923e-02, 2.4869e-02, 3.3948e-02, 1.2559e-01, 2.9022e-01, 3.7460e-01,\n",
      "         1.0898e-01, 8.2127e-03, 1.1721e-02, 3.9345e-03],\n",
      "        [2.4514e-03, 2.9391e-03, 2.9803e-03, 3.8773e-03, 1.0817e-02, 5.1059e-02,\n",
      "         4.1695e-01, 9.5191e-02, 3.0081e-01, 1.1292e-01],\n",
      "        [6.0068e-04, 1.8199e-03, 2.7724e-03, 3.0908e-03, 1.7828e-03, 2.3680e-02,\n",
      "         3.4961e-01, 2.3163e-01, 2.3973e-01, 1.4529e-01],\n",
      "        [1.4345e-02, 3.5071e-03, 5.9303e-03, 1.0204e-02, 9.3980e-03, 2.0528e-02,\n",
      "         1.8577e-01, 2.0082e-01, 2.8808e-01, 2.6142e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: người nào sẽ sáng_chế ra cái công_nghệ cho cuộc cách_mạng\n",
      "Reference: who is going to invent the technology for the\n",
      "Model: <SOS> someone will provide to jobs the technology for the\n",
      "Attention Weights: tensor([[3.0705e-01, 6.7136e-01, 2.0208e-02, 1.2963e-03, 8.1613e-05, 5.3625e-06,\n",
      "         4.5773e-07, 5.9688e-08, 4.1784e-09, 1.4430e-09],\n",
      "        [7.2209e-04, 6.6972e-01, 3.0615e-01, 2.2832e-02, 4.9827e-04, 5.1798e-05,\n",
      "         1.9497e-05, 7.1138e-07, 7.9196e-07, 4.1306e-07],\n",
      "        [9.5126e-04, 4.9578e-02, 2.7990e-01, 5.0635e-01, 1.0625e-01, 4.4669e-02,\n",
      "         1.1923e-02, 3.0473e-04, 5.7399e-05, 2.5301e-05],\n",
      "        [6.0766e-05, 2.9104e-03, 1.9021e-02, 3.0965e-01, 1.3697e-01, 3.1109e-01,\n",
      "         1.9889e-01, 1.8793e-02, 2.0299e-03, 5.8072e-04],\n",
      "        [1.4486e-05, 8.0811e-04, 1.6519e-02, 2.2313e-01, 7.2992e-02, 1.3190e-01,\n",
      "         4.8483e-01, 5.5110e-02, 9.8777e-03, 4.8193e-03],\n",
      "        [5.1784e-06, 8.1348e-05, 1.0305e-03, 3.7705e-02, 8.9502e-02, 2.9348e-01,\n",
      "         4.4630e-01, 1.1261e-01, 1.4889e-02, 4.3946e-03],\n",
      "        [5.0904e-07, 1.6576e-05, 9.4258e-05, 1.9200e-03, 1.7299e-02, 1.9175e-01,\n",
      "         5.8312e-01, 1.3710e-01, 4.2246e-02, 2.6454e-02],\n",
      "        [2.2531e-09, 3.8436e-06, 8.3220e-05, 3.7523e-04, 2.0445e-03, 3.7209e-02,\n",
      "         1.2750e-01, 1.0984e-01, 4.1119e-01, 3.1175e-01],\n",
      "        [1.7057e-07, 1.5577e-05, 2.0237e-04, 1.9340e-03, 6.4738e-03, 1.1013e-02,\n",
      "         5.4266e-02, 1.0493e-01, 3.8032e-01, 4.4085e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9.67, Train Loss: 2.04, Val Loss: 4.29, Train BLEU: 22.35, Val BLEU: 10.85, Minutes Elapsed: 507.72\n",
      "Sampling from training predictions...\n",
      "Source: chúng_tôi làm_cho nhiều thứ phát_triển . <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: we make things grow . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> we make lots things . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.7552, 0.2394, 0.0047, 0.0007, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0056, 0.9896, 0.0046, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0170, 0.0976, 0.8560, 0.0246, 0.0046, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0007, 0.0046, 0.4753, 0.3740, 0.1404, 0.0044, 0.0005, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0011, 0.0514, 0.4460, 0.4017, 0.0878, 0.0119, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0001, 0.0043, 0.1356, 0.5216, 0.1320, 0.2064, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0011, 0.0005, 0.0050, 0.1493, 0.1705, 0.1161, 0.5574, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0063, 0.0175, 0.0294, 0.1524, 0.3957, 0.0931, 0.3056, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0014, 0.0044, 0.0358, 0.1137, 0.3642, 0.0894, 0.3912, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: một cây dưới gối chỗ giường ngủ của chúng_tôi cây\n",
      "Reference: he kept one under the pillows on our bed\n",
      "Model: <SOS> one night our our our our that our trees\n",
      "Attention Weights: tensor([[5.2485e-01, 4.7142e-01, 3.6594e-03, 6.4308e-05, 1.0884e-05, 5.7552e-07,\n",
      "         3.2804e-08, 3.4894e-10, 1.8378e-10, 1.0240e-09],\n",
      "        [4.2390e-03, 5.8857e-01, 2.5271e-01, 1.3270e-01, 1.0454e-02, 9.5577e-03,\n",
      "         1.7137e-03, 3.5531e-05, 2.8194e-06, 7.7205e-06],\n",
      "        [4.6943e-03, 6.5674e-02, 4.4805e-01, 2.4494e-01, 1.9422e-01, 3.7358e-02,\n",
      "         4.7363e-03, 2.4157e-04, 2.9648e-05, 5.9910e-05],\n",
      "        [1.3413e-02, 1.9778e-02, 2.6826e-01, 3.6864e-01, 1.1526e-01, 1.6824e-01,\n",
      "         4.3511e-02, 2.6083e-03, 8.5647e-05, 1.9998e-04],\n",
      "        [5.3066e-03, 1.0170e-02, 2.5697e-02, 3.9203e-01, 1.8434e-01, 2.4200e-01,\n",
      "         1.2842e-01, 9.4666e-03, 1.8020e-03, 7.6880e-04],\n",
      "        [2.1365e-04, 6.0302e-04, 3.3343e-03, 2.0254e-01, 1.2155e-01, 3.1936e-01,\n",
      "         3.2642e-01, 1.4743e-02, 2.7825e-03, 8.4424e-03],\n",
      "        [1.8383e-04, 5.5020e-04, 1.3852e-03, 6.9059e-02, 1.5497e-01, 3.0780e-01,\n",
      "         2.8407e-01, 6.7530e-02, 5.2689e-02, 6.1774e-02],\n",
      "        [1.1409e-03, 1.3130e-03, 3.6332e-03, 1.0231e-01, 1.3599e-01, 2.6396e-01,\n",
      "         2.1092e-01, 6.3968e-02, 4.6836e-02, 1.6993e-01],\n",
      "        [2.6945e-06, 2.4921e-06, 4.2453e-05, 2.5344e-03, 1.8351e-02, 2.2724e-01,\n",
      "         2.5264e-01, 7.3885e-02, 2.7805e-02, 3.9750e-01]])\n",
      "\n",
      "Epoch: 9.72, Train Loss: 2.08, Val Loss: 4.31, Train BLEU: 21.72, Val BLEU: 10.57, Minutes Elapsed: 510.28\n",
      "Sampling from training predictions...\n",
      "Source: chúng_ta cần là người can_đảm cho những gì mình tin\n",
      "Reference: we need to be the ones who are brave\n",
      "Model: <SOS> we need to be the who who the who\n",
      "Attention Weights: tensor([[1.8205e-03, 9.9786e-01, 3.0997e-04, 3.1005e-06, 1.4949e-06, 3.9073e-07,\n",
      "         8.2735e-09, 4.6088e-09, 3.5122e-09, 1.8338e-09],\n",
      "        [5.9014e-04, 9.9896e-01, 3.5705e-04, 7.9547e-05, 1.1251e-05, 2.2769e-06,\n",
      "         4.1455e-07, 1.0620e-07, 4.1172e-07, 1.6445e-07],\n",
      "        [1.7068e-02, 7.4607e-01, 9.5451e-02, 1.3204e-01, 6.8324e-03, 1.8180e-03,\n",
      "         6.1727e-04, 5.1569e-05, 3.8736e-05, 1.6322e-05],\n",
      "        [2.9530e-04, 5.0472e-02, 2.6516e-01, 3.7250e-01, 2.6161e-01, 4.4070e-02,\n",
      "         4.9288e-03, 3.2477e-04, 3.7230e-04, 2.7344e-04],\n",
      "        [3.2225e-05, 1.6671e-02, 5.0067e-02, 5.4092e-01, 2.8343e-01, 6.6310e-02,\n",
      "         3.4020e-02, 3.7038e-03, 3.3134e-03, 1.5251e-03],\n",
      "        [8.3273e-05, 1.0997e-02, 2.5221e-02, 1.4078e-01, 3.0249e-01, 3.6138e-01,\n",
      "         1.1489e-01, 1.8122e-02, 1.7945e-02, 8.0963e-03],\n",
      "        [1.7035e-05, 3.0991e-03, 2.7940e-03, 4.7922e-03, 4.6713e-02, 8.2821e-01,\n",
      "         5.7269e-02, 3.3862e-02, 1.3506e-02, 9.7395e-03],\n",
      "        [8.2490e-05, 5.0506e-03, 2.6505e-03, 4.8259e-03, 4.7833e-02, 7.3024e-01,\n",
      "         1.3165e-01, 5.0920e-02, 2.0279e-02, 6.4758e-03],\n",
      "        [2.1149e-04, 4.9488e-02, 9.0092e-03, 7.3451e-02, 2.2892e-01, 1.2095e-01,\n",
      "         2.1135e-01, 5.7635e-02, 1.5450e-01, 9.4487e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi sẽ nói cho bạn biết tại_sao . <EOS> <PAD>\n",
      "Reference: and i &apos;ll tell you why . <EOS> <PAD>\n",
      "Model: <SOS> i &apos;ll &apos;ll tell you why why <EOS> .\n",
      "Attention Weights: tensor([[0.0086, 0.9857, 0.0022, 0.0034, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0159, 0.9341, 0.0368, 0.0125, 0.0003, 0.0004, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0221, 0.4724, 0.2349, 0.1875, 0.0371, 0.0417, 0.0041, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0133, 0.7143, 0.1172, 0.0865, 0.0279, 0.0391, 0.0016, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0067, 0.0506, 0.6640, 0.0561, 0.1150, 0.1067, 0.0005, 0.0001,\n",
      "         0.0000],\n",
      "        [0.0004, 0.0032, 0.0140, 0.0862, 0.0482, 0.3020, 0.5239, 0.0191, 0.0030,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0007, 0.0016, 0.0187, 0.0285, 0.0762, 0.5668, 0.2673, 0.0403,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0013, 0.0042, 0.0270, 0.0214, 0.0438, 0.2452, 0.3672, 0.2898,\n",
      "         0.0000],\n",
      "        [0.0005, 0.0037, 0.0048, 0.0434, 0.0625, 0.0666, 0.0947, 0.2135, 0.5103,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 9.77, Train Loss: 2.03, Val Loss: 4.30, Train BLEU: 22.47, Val BLEU: 10.65, Minutes Elapsed: 512.84\n",
      "Sampling from training predictions...\n",
      "Source: người theo chủ_nghĩa thuần_tuý có_lẽ cảm_thấy rằng sự giả_tưởng xua_tan\n",
      "Reference: purists may feel that fiction dissipates the quest of\n",
      "Model: <SOS> the believes that that the the the the of\n",
      "Attention Weights: tensor([[7.7638e-01, 5.9690e-03, 2.1655e-01, 1.0812e-03, 1.4542e-05, 3.9644e-07,\n",
      "         5.3152e-09, 7.4733e-09, 5.8331e-10, 2.4333e-09],\n",
      "        [2.6235e-04, 1.4406e-02, 9.0010e-01, 7.9267e-02, 5.6936e-03, 2.4979e-04,\n",
      "         1.9620e-05, 2.1900e-06, 1.4043e-06, 2.5644e-06],\n",
      "        [2.2302e-04, 4.3665e-03, 4.7029e-01, 4.9094e-01, 3.0420e-02, 3.5411e-03,\n",
      "         1.7731e-04, 2.4970e-05, 9.5648e-06, 3.0404e-06],\n",
      "        [4.6659e-05, 4.4857e-04, 3.0535e-02, 2.7569e-01, 4.5684e-01, 2.0389e-01,\n",
      "         2.1446e-02, 8.6936e-03, 1.6020e-03, 8.0794e-04],\n",
      "        [2.6655e-04, 1.1561e-04, 1.9279e-02, 1.0563e-01, 2.6678e-01, 3.1688e-01,\n",
      "         1.6220e-01, 5.8982e-02, 5.6815e-02, 1.3053e-02],\n",
      "        [1.7320e-06, 1.8616e-06, 3.8738e-04, 5.6665e-03, 6.1919e-02, 2.1371e-01,\n",
      "         1.5378e-01, 1.1621e-01, 3.1107e-01, 1.3726e-01],\n",
      "        [6.6482e-06, 1.3043e-05, 7.3034e-04, 4.5456e-03, 2.2107e-02, 1.7883e-01,\n",
      "         1.2693e-01, 1.3747e-01, 3.1111e-01, 2.1826e-01],\n",
      "        [9.5896e-07, 6.5481e-06, 2.0301e-04, 5.5995e-03, 1.1633e-02, 5.5114e-02,\n",
      "         6.3533e-02, 1.8536e-01, 3.6124e-01, 3.1730e-01],\n",
      "        [4.7260e-06, 2.4646e-05, 1.3230e-03, 1.3307e-02, 2.1893e-02, 1.8354e-01,\n",
      "         6.1458e-02, 1.4657e-01, 3.6022e-01, 2.1166e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: thành_phố tới gặp tôi , và đại_khái là đưa cho\n",
      "Reference: the city came down on me , and basically\n",
      "Model: <SOS> the city of came me me , and the\n",
      "Attention Weights: tensor([[9.9997e-01, 2.5409e-05, 1.7911e-06, 8.8873e-09, 6.5800e-11, 4.3150e-12,\n",
      "         5.1832e-12, 9.4658e-13, 9.0397e-13, 5.9728e-14],\n",
      "        [9.6777e-01, 1.7940e-02, 1.3664e-02, 5.8075e-04, 3.9704e-05, 2.4277e-06,\n",
      "         4.2709e-06, 6.8823e-07, 1.9217e-07, 1.1956e-07],\n",
      "        [5.9414e-01, 1.1611e-01, 2.2665e-01, 4.4549e-02, 1.6904e-02, 7.0235e-04,\n",
      "         4.9432e-04, 3.1711e-04, 9.9538e-05, 3.6658e-05],\n",
      "        [1.9895e-01, 1.9518e-01, 3.2937e-01, 2.2469e-01, 4.8811e-02, 7.5676e-04,\n",
      "         1.6153e-03, 4.3541e-04, 1.4200e-04, 4.7475e-05],\n",
      "        [1.9723e-02, 5.5209e-02, 5.6708e-01, 1.8826e-01, 1.5350e-01, 8.0607e-03,\n",
      "         5.8835e-03, 1.1087e-03, 6.7658e-04, 5.0944e-04],\n",
      "        [3.7639e-04, 3.8409e-03, 2.0185e-01, 1.8740e-01, 5.1388e-01, 6.5695e-02,\n",
      "         2.1417e-02, 2.2266e-03, 1.9760e-03, 1.3423e-03],\n",
      "        [4.2322e-04, 7.2740e-04, 3.9171e-02, 9.5384e-02, 4.3950e-01, 2.6648e-01,\n",
      "         1.4333e-01, 7.7083e-03, 4.4719e-03, 2.8001e-03],\n",
      "        [1.5882e-04, 1.1908e-04, 4.6596e-03, 3.2408e-02, 2.4014e-01, 5.1308e-01,\n",
      "         1.5081e-01, 3.5211e-02, 1.7724e-02, 5.6915e-03],\n",
      "        [1.8568e-04, 1.9164e-04, 6.4322e-03, 4.0125e-03, 3.4062e-02, 1.5112e-01,\n",
      "         6.8224e-01, 7.9502e-02, 3.1775e-02, 1.0479e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9.82, Train Loss: 2.01, Val Loss: 4.29, Train BLEU: 22.33, Val BLEU: 10.86, Minutes Elapsed: 515.40\n",
      "Sampling from training predictions...\n",
      "Source: sau đó tôi không_thể tham_dự cuộc thi trong_vòng vài năm\n",
      "Reference: then i couldn &apos;t participate for a few years\n",
      "Model: <SOS> i i couldn &apos;t participate a next next for\n",
      "Attention Weights: tensor([[5.6867e-02, 9.4062e-01, 2.4217e-03, 9.0940e-05, 9.2080e-08, 7.0762e-10,\n",
      "         1.0115e-10, 3.3268e-11, 3.0326e-10, 2.5765e-12],\n",
      "        [1.8944e-03, 1.9802e-01, 3.5089e-01, 4.4881e-01, 3.7942e-04, 7.1519e-06,\n",
      "         4.0501e-06, 1.7409e-06, 3.9025e-07, 1.7107e-07],\n",
      "        [7.7965e-04, 3.1092e-03, 2.1918e-02, 9.5862e-01, 1.5258e-02, 2.3023e-04,\n",
      "         6.5450e-05, 2.0379e-05, 1.9419e-06, 2.2280e-06],\n",
      "        [1.1995e-04, 2.5551e-04, 2.9228e-03, 9.7233e-01, 2.4069e-02, 2.5632e-04,\n",
      "         3.5677e-05, 9.2986e-06, 5.9252e-07, 8.4662e-07],\n",
      "        [7.6387e-06, 3.6367e-05, 1.5484e-04, 5.4777e-03, 9.5548e-01, 3.3877e-02,\n",
      "         4.5824e-03, 3.6423e-04, 9.0355e-06, 1.1310e-05],\n",
      "        [3.2640e-07, 5.7228e-06, 9.8535e-05, 3.3534e-04, 2.2258e-01, 6.0837e-01,\n",
      "         9.6863e-02, 7.0354e-02, 1.0987e-03, 2.9454e-04],\n",
      "        [3.2384e-06, 1.7859e-05, 3.4274e-05, 2.1130e-04, 4.7348e-02, 4.1972e-01,\n",
      "         2.5505e-01, 2.6172e-01, 1.4182e-02, 1.7104e-03],\n",
      "        [1.3035e-06, 7.5124e-06, 9.3387e-06, 5.7207e-04, 3.7105e-03, 1.0484e-01,\n",
      "         9.4660e-02, 5.7448e-01, 2.0900e-01, 1.2725e-02],\n",
      "        [1.4826e-05, 2.6140e-05, 5.8636e-06, 2.0786e-03, 3.3372e-03, 7.3204e-02,\n",
      "         5.5587e-02, 4.1169e-01, 4.0086e-01, 5.3193e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: đường_lối <UNK> để lưu_trữ các thứ là không bền_vững .\n",
      "Reference: <UNK> way of maintaining things is not sustainable .\n",
      "Model: <SOS> the is the things is is not . .\n",
      "Attention Weights: tensor([[9.9212e-01, 6.6985e-03, 1.1497e-03, 2.8189e-05, 1.1465e-06, 4.5305e-07,\n",
      "         7.1140e-10, 1.5967e-09, 1.2087e-10, 7.6234e-11],\n",
      "        [6.7008e-01, 1.0305e-01, 8.0364e-02, 1.3030e-01, 1.0624e-02, 5.0754e-03,\n",
      "         2.2031e-04, 1.7078e-04, 9.5133e-05, 1.9995e-05],\n",
      "        [1.2686e-01, 4.1691e-02, 2.0085e-01, 4.2633e-01, 8.3053e-02, 8.8159e-02,\n",
      "         1.1810e-02, 1.7177e-02, 4.0022e-03, 7.0540e-05],\n",
      "        [3.8350e-04, 3.6031e-04, 1.1051e-02, 3.8324e-01, 1.4345e-01, 1.9145e-01,\n",
      "         9.7944e-02, 1.1330e-01, 5.7748e-02, 1.0787e-03],\n",
      "        [1.9792e-05, 2.9273e-05, 1.1984e-02, 6.4481e-02, 1.0040e-01, 1.7451e-01,\n",
      "         2.3195e-01, 1.5885e-01, 2.5410e-01, 3.6738e-03],\n",
      "        [2.7368e-05, 1.4935e-04, 1.6308e-02, 9.6167e-02, 6.2593e-02, 1.7725e-01,\n",
      "         1.9919e-01, 2.7402e-01, 1.6468e-01, 9.6174e-03],\n",
      "        [8.7025e-06, 4.1156e-05, 2.4814e-03, 3.1860e-02, 2.6056e-02, 1.0186e-01,\n",
      "         1.5835e-01, 3.7240e-01, 2.8985e-01, 1.7097e-02],\n",
      "        [3.6221e-06, 9.2851e-06, 2.3233e-04, 6.2191e-03, 1.4718e-02, 2.5935e-02,\n",
      "         6.8565e-02, 2.8236e-01, 5.6424e-01, 3.7719e-02],\n",
      "        [1.1012e-06, 7.0306e-06, 1.2916e-04, 2.0993e-03, 1.0275e-02, 3.5095e-02,\n",
      "         4.9486e-02, 2.6335e-01, 5.3423e-01, 1.0532e-01]])\n",
      "\n",
      "Epoch: 9.86, Train Loss: 1.98, Val Loss: 4.29, Train BLEU: 23.32, Val BLEU: 10.89, Minutes Elapsed: 517.94\n",
      "Sampling from training predictions...\n",
      "Source: xin_lỗi . tôi quên mất một điều . <EOS> <PAD>\n",
      "Reference: sorry . i forgot one thing . <EOS> <PAD>\n",
      "Model: <SOS> sorry . i forgot one one . <EOS> .\n",
      "Attention Weights: tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.6896, 0.2114, 0.0307, 0.0626, 0.0051, 0.0005, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0735, 0.2080, 0.2789, 0.3769, 0.0587, 0.0021, 0.0009, 0.0008, 0.0003,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0024, 0.0402, 0.8292, 0.1212, 0.0046, 0.0011, 0.0006, 0.0003,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0001, 0.0005, 0.3086, 0.6359, 0.0287, 0.0251, 0.0007, 0.0002,\n",
      "         0.0000],\n",
      "        [0.0020, 0.0008, 0.0001, 0.0179, 0.5479, 0.0670, 0.3485, 0.0141, 0.0017,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0006, 0.0012, 0.0898, 0.3523, 0.0834, 0.3128, 0.0994, 0.0604,\n",
      "         0.0000],\n",
      "        [0.0014, 0.0031, 0.0104, 0.0480, 0.1779, 0.1147, 0.3322, 0.1594, 0.1530,\n",
      "         0.0000],\n",
      "        [0.0024, 0.0021, 0.0026, 0.0838, 0.5233, 0.1168, 0.1243, 0.0659, 0.0788,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: bảo_hộ , là tôi đối_xử với bất_cứ người nào đến\n",
      "Reference: <UNK> , i treat anybody from a different culture\n",
      "Model: <SOS> so , i would all people i to of\n",
      "Attention Weights: tensor([[9.8195e-01, 1.6848e-02, 1.1926e-03, 1.0659e-05, 2.7105e-06, 2.1280e-07,\n",
      "         1.0338e-08, 1.8796e-10, 8.0337e-11, 5.4234e-11],\n",
      "        [1.0706e-01, 9.3088e-02, 7.5693e-01, 3.6991e-02, 5.2877e-03, 5.4090e-04,\n",
      "         6.0522e-05, 1.9788e-05, 1.1915e-05, 5.6927e-06],\n",
      "        [2.9892e-02, 2.3659e-02, 3.2464e-01, 1.9602e-01, 3.5248e-01, 6.7754e-02,\n",
      "         2.9925e-03, 1.2940e-03, 9.0581e-04, 3.5713e-04],\n",
      "        [3.2380e-04, 7.7316e-04, 2.6760e-02, 2.3515e-01, 3.5348e-01, 2.7153e-01,\n",
      "         4.9922e-02, 2.9810e-02, 2.5396e-02, 6.8592e-03],\n",
      "        [1.0212e-03, 1.0596e-03, 1.1542e-02, 1.0019e-02, 2.9745e-01, 5.6680e-01,\n",
      "         4.6985e-02, 2.9120e-02, 2.9159e-02, 6.8408e-03],\n",
      "        [1.9015e-04, 6.1335e-05, 2.7737e-04, 1.1516e-03, 5.6023e-02, 2.9048e-01,\n",
      "         1.9272e-01, 1.3926e-01, 2.9250e-01, 2.7325e-02],\n",
      "        [1.2904e-05, 7.3190e-06, 9.3436e-06, 2.9529e-05, 7.3805e-04, 1.2375e-02,\n",
      "         9.7137e-02, 2.2025e-01, 3.9211e-01, 2.7733e-01],\n",
      "        [3.0709e-05, 5.0383e-05, 2.2133e-05, 2.0897e-05, 2.0974e-04, 1.4374e-03,\n",
      "         1.7073e-02, 4.1272e-02, 2.9645e-01, 6.4344e-01],\n",
      "        [8.3189e-04, 2.0189e-03, 6.1372e-04, 6.6812e-05, 8.4072e-04, 1.0996e-02,\n",
      "         1.7808e-02, 2.9094e-02, 1.6902e-01, 7.6871e-01]])\n",
      "\n",
      "Epoch: 9.91, Train Loss: 1.92, Val Loss: 4.33, Train BLEU: 23.26, Val BLEU: 10.16, Minutes Elapsed: 520.51\n",
      "Sampling from training predictions...\n",
      "Source: nhưng với tôi , với phần_lớn cuộc_sống của tôi ,\n",
      "Reference: but for me , for a large part of\n",
      "Model: <SOS> but for me , for &apos;s part of of\n",
      "Attention Weights: tensor([[8.8141e-03, 9.9062e-01, 5.5425e-04, 7.5725e-07, 1.0042e-05, 6.9096e-07,\n",
      "         4.3363e-09, 2.5975e-10, 1.5652e-10, 7.8943e-13],\n",
      "        [2.2304e-03, 9.9655e-01, 1.1158e-03, 4.7036e-05, 4.4264e-05, 8.4177e-06,\n",
      "         2.9975e-07, 1.1462e-08, 3.0413e-09, 4.0997e-10],\n",
      "        [1.0640e-02, 8.5599e-01, 2.6251e-02, 6.5100e-02, 3.8995e-02, 2.8677e-03,\n",
      "         1.3091e-04, 1.7329e-05, 4.3842e-06, 7.5264e-06],\n",
      "        [1.1505e-02, 1.1805e-01, 1.4261e-02, 4.9065e-01, 3.1568e-01, 4.5014e-02,\n",
      "         4.0793e-03, 3.1728e-04, 2.1447e-04, 2.3994e-04],\n",
      "        [3.3032e-03, 2.8713e-02, 1.3310e-02, 2.7582e-01, 6.5189e-01, 2.4397e-02,\n",
      "         2.1894e-03, 7.5059e-05, 2.1144e-04, 8.9409e-05],\n",
      "        [1.2950e-04, 2.4100e-03, 2.8875e-03, 2.4744e-02, 2.3310e-01, 5.8114e-01,\n",
      "         1.4983e-01, 3.6337e-03, 1.3515e-03, 7.7525e-04],\n",
      "        [8.2420e-04, 9.0176e-03, 1.9342e-03, 1.9924e-02, 7.8423e-02, 7.0068e-01,\n",
      "         1.6866e-01, 8.4322e-03, 7.8774e-03, 4.2327e-03],\n",
      "        [5.4578e-05, 1.1551e-03, 6.8574e-04, 5.5879e-02, 2.2183e-01, 1.4875e-01,\n",
      "         3.4574e-01, 5.7103e-02, 6.1561e-02, 1.0724e-01],\n",
      "        [1.4151e-04, 7.3321e-03, 3.6506e-03, 7.3267e-02, 8.5652e-02, 1.0144e-01,\n",
      "         4.6480e-01, 8.7798e-02, 9.0876e-02, 8.5036e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: vậy_nên ở đồ_thị bên_dưới , bạn có_thể thấy một ví_dụ\n",
      "Reference: so on the bottom trace , you can see\n",
      "Model: <SOS> so in the single you , you can see\n",
      "Attention Weights: tensor([[9.9993e-01, 7.4441e-05, 6.9113e-08, 1.5177e-08, 1.3591e-12, 3.9118e-14,\n",
      "         8.1684e-14, 3.4467e-13, 4.1212e-13, 9.4186e-15],\n",
      "        [3.1273e-01, 5.4509e-01, 8.0982e-02, 6.0933e-02, 1.7126e-04, 1.7632e-05,\n",
      "         5.7092e-05, 2.2280e-05, 8.6615e-07, 3.3149e-07],\n",
      "        [2.1923e-01, 3.1786e-01, 2.5076e-01, 1.9795e-01, 8.0050e-03, 2.6564e-03,\n",
      "         2.0810e-03, 1.2940e-03, 1.1583e-04, 4.7579e-05],\n",
      "        [2.3203e-01, 3.0579e-01, 1.9933e-01, 2.3532e-01, 1.0534e-02, 5.5975e-03,\n",
      "         4.1845e-03, 6.5509e-03, 4.6186e-04, 1.9024e-04],\n",
      "        [4.8592e-02, 1.5073e-01, 3.3175e-01, 3.7915e-01, 5.1053e-02, 2.0744e-02,\n",
      "         8.3630e-03, 9.2748e-03, 2.4991e-04, 1.0096e-04],\n",
      "        [3.8122e-03, 5.9153e-02, 3.2130e-01, 4.6506e-01, 1.0006e-01, 3.6116e-02,\n",
      "         8.9077e-03, 5.4120e-03, 1.4459e-04, 3.5007e-05],\n",
      "        [3.9374e-04, 3.8952e-03, 3.4502e-02, 6.3434e-02, 1.1147e-01, 5.0600e-01,\n",
      "         2.0484e-01, 7.2510e-02, 1.7521e-03, 1.1997e-03],\n",
      "        [2.8390e-04, 9.9807e-04, 6.1361e-03, 1.5492e-02, 7.4209e-02, 5.4838e-01,\n",
      "         2.2164e-01, 1.2599e-01, 4.6331e-03, 2.2348e-03],\n",
      "        [4.1193e-03, 1.6009e-02, 3.5541e-03, 5.2953e-02, 1.3859e-02, 2.7861e-02,\n",
      "         1.8123e-01, 6.8591e-01, 1.1809e-02, 2.6956e-03]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9.96, Train Loss: 1.85, Val Loss: 4.32, Train BLEU: 25.60, Val BLEU: 10.31, Minutes Elapsed: 523.09\n",
      "Sampling from training predictions...\n",
      "Source: kevin breel : những thú_nhận của một nghệ_sĩ hài bị\n",
      "Reference: kevin breel : confessions of a depressed comic <EOS>\n",
      "Model: <SOS> kevin breel : confessions &apos;s an comic comic <EOS>\n",
      "Attention Weights: tensor([[9.9981e-01, 1.8180e-04, 1.0353e-05, 5.3810e-09, 1.4790e-09, 1.9407e-10,\n",
      "         7.2169e-12, 9.3463e-13, 6.8884e-13, 1.5278e-13],\n",
      "        [5.7606e-03, 9.8407e-01, 1.0170e-02, 7.0383e-07, 2.0740e-07, 1.1550e-07,\n",
      "         5.2417e-10, 2.6855e-11, 4.9896e-11, 1.8922e-11],\n",
      "        [3.0632e-05, 3.5498e-03, 9.9387e-01, 1.3147e-03, 1.2643e-04, 1.1026e-03,\n",
      "         2.4248e-06, 3.2722e-08, 7.3992e-08, 3.2889e-08],\n",
      "        [3.5388e-07, 2.0443e-05, 2.8661e-04, 5.6930e-01, 4.2454e-01, 5.0559e-03,\n",
      "         5.8346e-04, 1.0707e-04, 9.1548e-05, 1.7225e-05],\n",
      "        [6.9954e-06, 4.0286e-05, 1.8199e-04, 4.3167e-02, 8.8956e-01, 2.6050e-02,\n",
      "         1.3400e-02, 1.1332e-02, 1.5387e-02, 8.7653e-04],\n",
      "        [1.0259e-06, 1.1371e-05, 3.4238e-04, 1.5019e-02, 1.1910e-01, 1.1256e-01,\n",
      "         3.5236e-01, 1.3659e-01, 1.9153e-01, 7.2501e-02],\n",
      "        [2.1712e-08, 1.1702e-07, 2.9154e-06, 2.5877e-04, 1.1120e-02, 1.1145e-02,\n",
      "         1.2780e-01, 1.6445e-01, 3.3091e-01, 3.5431e-01],\n",
      "        [1.2919e-07, 3.1182e-06, 8.6255e-05, 2.4170e-04, 6.9669e-04, 8.3501e-03,\n",
      "         7.5312e-02, 1.3305e-01, 2.9294e-01, 4.8932e-01],\n",
      "        [9.4205e-07, 1.8245e-05, 1.3609e-04, 6.1365e-04, 7.9191e-04, 9.0080e-03,\n",
      "         8.3519e-02, 1.5306e-01, 2.8306e-01, 4.6979e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: em không quan_tâm về sự khác_biệt tôn_giáo , và hãy\n",
      "Reference: he doesn &apos;t care about religious differences , and\n",
      "Model: <SOS> i don &apos;t care about religion , , and\n",
      "Attention Weights: tensor([[9.8639e-01, 1.3342e-02, 2.6335e-04, 1.4993e-07, 1.6272e-08, 2.7214e-08,\n",
      "         6.8158e-09, 5.8270e-10, 1.1220e-10, 1.5028e-10],\n",
      "        [3.5977e-02, 9.4978e-01, 1.4165e-02, 3.8449e-05, 7.3197e-06, 2.6517e-05,\n",
      "         4.9540e-06, 2.7929e-07, 1.4413e-07, 3.9651e-07],\n",
      "        [4.5095e-02, 8.3623e-01, 1.1776e-01, 6.5425e-04, 1.0177e-04, 1.0812e-04,\n",
      "         4.6949e-05, 4.6622e-06, 1.8864e-06, 2.6990e-06],\n",
      "        [9.1171e-03, 1.8129e-02, 9.6937e-01, 2.8830e-03, 1.1101e-04, 2.9209e-04,\n",
      "         8.7380e-05, 5.3296e-06, 7.6063e-07, 9.1692e-07],\n",
      "        [6.0386e-04, 3.6424e-03, 7.5007e-01, 2.2084e-01, 1.2386e-02, 9.6631e-03,\n",
      "         2.7203e-03, 7.0569e-05, 3.5054e-06, 2.6789e-06],\n",
      "        [1.9130e-04, 5.6386e-04, 1.5359e-01, 1.7455e-01, 5.9317e-02, 3.8715e-01,\n",
      "         2.2189e-01, 2.4723e-03, 2.5150e-04, 2.5199e-05],\n",
      "        [1.7273e-06, 6.7153e-05, 4.4851e-04, 9.6896e-03, 3.6176e-02, 5.7391e-01,\n",
      "         2.4975e-01, 1.0140e-01, 2.6955e-02, 1.5938e-03],\n",
      "        [9.6901e-07, 1.7576e-04, 1.2274e-04, 1.1087e-03, 7.9311e-03, 7.8224e-02,\n",
      "         5.8021e-02, 5.5517e-01, 2.8284e-01, 1.6399e-02],\n",
      "        [2.9413e-06, 2.4282e-05, 5.0913e-05, 1.5909e-04, 2.2208e-03, 8.9530e-03,\n",
      "         1.1979e-02, 2.3949e-01, 6.6728e-01, 6.9837e-02]])\n",
      "\n",
      "Epoch: 10.00, Train Loss: 1.60, Val Loss: 4.31, Train BLEU: 31.69, Val BLEU: 10.09, Minutes Elapsed: 525.27\n",
      "Sampling from training predictions...\n",
      "Source: điều này có_thể làm bạn shock , nhưng thực_sự chúng_ta\n",
      "Reference: this may shock you , but we &apos;re literally\n",
      "Model: <SOS> this may be you , but we &apos;re actually\n",
      "Attention Weights: tensor([[8.5751e-01, 1.3956e-01, 2.6221e-03, 3.0171e-04, 1.0465e-05, 8.0102e-08,\n",
      "         6.5264e-09, 6.6736e-09, 2.8432e-09, 1.1684e-10],\n",
      "        [1.0635e-01, 1.5812e-01, 7.1919e-01, 1.5174e-02, 1.0592e-03, 6.8837e-05,\n",
      "         1.0716e-05, 7.3658e-06, 1.1409e-05, 6.8284e-07],\n",
      "        [3.8629e-02, 7.5948e-02, 4.3859e-01, 3.8490e-01, 5.1964e-02, 9.6740e-03,\n",
      "         1.5707e-04, 6.5301e-05, 6.5680e-05, 5.1208e-06],\n",
      "        [2.1509e-03, 6.1453e-03, 3.4553e-02, 3.4514e-01, 3.1935e-01, 2.8646e-01,\n",
      "         4.8887e-03, 4.3789e-04, 8.0606e-04, 6.7871e-05],\n",
      "        [4.6624e-04, 3.3410e-04, 4.6038e-03, 2.0875e-01, 3.8830e-01, 3.6294e-01,\n",
      "         2.2938e-02, 5.1153e-03, 5.3065e-03, 1.2472e-03],\n",
      "        [3.0995e-05, 1.3011e-04, 1.4764e-03, 4.4446e-03, 1.0327e-02, 5.8780e-02,\n",
      "         1.4699e-01, 6.5580e-01, 1.1832e-01, 3.7047e-03],\n",
      "        [1.0685e-05, 2.0700e-05, 1.0202e-04, 1.9844e-03, 7.5991e-03, 3.4207e-02,\n",
      "         7.6787e-02, 7.6969e-01, 1.0560e-01, 3.9963e-03],\n",
      "        [1.5582e-03, 6.6970e-04, 3.3118e-03, 9.4431e-03, 5.2809e-03, 3.9550e-03,\n",
      "         6.7192e-03, 8.3086e-02, 7.1819e-01, 1.6778e-01],\n",
      "        [7.9652e-04, 4.1352e-04, 1.4962e-03, 3.2782e-02, 7.5566e-03, 6.9436e-03,\n",
      "         1.1185e-02, 3.9545e-02, 5.7369e-01, 3.2559e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: nếu nhiếp_ảnh_gia đứng ở đây còn ánh_sáng thì ở kia\n",
      "Reference: so if the photographer is right there and the\n",
      "Model: <SOS> if the country were is still there long a\n",
      "Attention Weights: tensor([[8.9840e-01, 9.7865e-02, 3.7289e-03, 9.7304e-06, 1.8683e-07, 1.1618e-08,\n",
      "         1.2440e-08, 5.1929e-10, 2.2234e-10, 2.1647e-10],\n",
      "        [1.2912e-02, 9.8194e-01, 4.8638e-03, 1.5849e-04, 4.0349e-05, 3.5874e-05,\n",
      "         4.1960e-05, 9.4643e-07, 1.2041e-06, 1.0912e-06],\n",
      "        [2.8796e-03, 7.7805e-01, 1.9800e-01, 1.1991e-02, 2.0380e-03, 4.0168e-03,\n",
      "         2.7587e-03, 1.3497e-04, 6.6157e-05, 6.1305e-05],\n",
      "        [1.5939e-03, 3.2330e-01, 6.2858e-01, 2.4830e-02, 4.4137e-03, 7.9099e-03,\n",
      "         8.3209e-03, 6.6693e-04, 2.2520e-04, 1.5824e-04],\n",
      "        [2.6630e-04, 3.7298e-01, 6.1360e-01, 7.8445e-03, 1.4185e-03, 1.6937e-03,\n",
      "         1.9774e-03, 1.5316e-04, 3.5980e-05, 2.9520e-05],\n",
      "        [2.9334e-03, 3.2193e-01, 5.1636e-01, 8.6612e-02, 1.2971e-02, 2.4332e-02,\n",
      "         2.9287e-02, 3.9104e-03, 8.7510e-04, 7.8078e-04],\n",
      "        [2.0231e-06, 8.5241e-03, 1.0716e-01, 6.7322e-02, 2.4006e-02, 1.6062e-01,\n",
      "         6.0743e-01, 1.8865e-02, 2.6575e-03, 3.4120e-03],\n",
      "        [5.2328e-07, 4.3457e-04, 1.8514e-03, 9.9263e-03, 4.9088e-02, 2.1647e-01,\n",
      "         6.7784e-01, 2.6078e-02, 5.5006e-03, 1.2810e-02],\n",
      "        [5.6946e-08, 5.5621e-05, 3.8208e-04, 3.7104e-03, 2.6569e-02, 2.7643e-01,\n",
      "         5.4395e-01, 4.4123e-02, 3.2594e-02, 7.2187e-02]])\n",
      "\n",
      "Epoch: 10.05, Train Loss: 1.33, Val Loss: 4.33, Train BLEU: 38.03, Val BLEU: 10.19, Minutes Elapsed: 527.82\n",
      "Sampling from training predictions...\n",
      "Source: tôi đã quen với việc đó rồi . <EOS> <PAD>\n",
      "Reference: i &apos;m so used to that . <EOS> <PAD>\n",
      "Model: <SOS> i &apos;ve used to to that that . .\n",
      "Attention Weights: tensor([[0.0071, 0.9408, 0.0519, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0030, 0.1270, 0.8670, 0.0029, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0029, 0.3289, 0.6028, 0.0539, 0.0104, 0.0007, 0.0003, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0026, 0.0031, 0.2853, 0.2659, 0.4181, 0.0167, 0.0080, 0.0003, 0.0001,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0015, 0.0529, 0.2661, 0.6222, 0.0310, 0.0247, 0.0011, 0.0002,\n",
      "         0.0000],\n",
      "        [0.0011, 0.0008, 0.0217, 0.0534, 0.5289, 0.1837, 0.1857, 0.0202, 0.0045,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0001, 0.0019, 0.0085, 0.1989, 0.1599, 0.4431, 0.1241, 0.0633,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0001, 0.0007, 0.0065, 0.2281, 0.0721, 0.3534, 0.1419, 0.1971,\n",
      "         0.0000],\n",
      "        [0.0070, 0.0017, 0.0065, 0.0092, 0.1387, 0.0809, 0.1605, 0.1821, 0.4133,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: điều đó không tồn_tại <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: it doesn &apos;t exist . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> that doesn &apos;t work . <EOS> . &apos;t <EOS>\n",
      "Attention Weights: tensor([[0.6485, 0.3303, 0.0208, 0.0003, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0441, 0.0395, 0.8640, 0.0521, 0.0003, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0263, 0.0958, 0.6235, 0.2506, 0.0037, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0073, 0.0028, 0.0250, 0.9538, 0.0112, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0014, 0.0021, 0.0257, 0.2415, 0.7293, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0018, 0.0035, 0.0277, 0.4523, 0.5146, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0636, 0.0672, 0.4381, 0.1697, 0.2614, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0665, 0.3021, 0.4417, 0.1006, 0.0891, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0136, 0.0065, 0.0743, 0.6082, 0.2974, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10.10, Train Loss: 1.58, Val Loss: 4.35, Train BLEU: 31.36, Val BLEU: 10.79, Minutes Elapsed: 530.38\n",
      "Sampling from training predictions...\n",
      "Source: nếu họ thích một bản_nhạc , họ sẽ kêu_la và\n",
      "Reference: if they liked an aria , they would holler\n",
      "Model: <SOS> if they liked a aria , they would holler\n",
      "Attention Weights: tensor([[4.6426e-01, 4.6499e-01, 7.0678e-02, 6.9142e-05, 9.6596e-08, 2.4581e-08,\n",
      "         9.0755e-09, 1.9354e-08, 6.9592e-09, 7.9803e-10],\n",
      "        [4.5027e-02, 8.8841e-01, 6.6488e-02, 6.6365e-05, 1.0235e-05, 3.2406e-07,\n",
      "         3.5466e-07, 1.0996e-06, 2.2779e-07, 7.8261e-09],\n",
      "        [1.5799e-04, 1.1430e-02, 9.8753e-01, 7.4680e-04, 1.1046e-04, 1.4083e-06,\n",
      "         1.7067e-06, 2.3879e-05, 2.3893e-06, 1.1604e-07],\n",
      "        [7.9065e-04, 6.5089e-03, 5.6737e-01, 3.6438e-01, 6.0492e-02, 1.7086e-04,\n",
      "         2.4411e-05, 7.4509e-05, 1.7839e-04, 5.1297e-06],\n",
      "        [5.2133e-06, 2.8421e-04, 4.1847e-02, 3.8153e-02, 8.9502e-01, 2.1788e-02,\n",
      "         9.0499e-04, 4.4779e-04, 1.4045e-03, 1.4458e-04],\n",
      "        [4.1679e-04, 8.9534e-04, 4.6445e-03, 3.7659e-03, 5.8633e-02, 6.4015e-01,\n",
      "         2.0448e-01, 7.5827e-02, 7.6412e-03, 3.5448e-03],\n",
      "        [9.1694e-06, 4.3057e-04, 2.9805e-03, 2.1542e-04, 1.0123e-02, 2.9925e-01,\n",
      "         5.0828e-01, 1.5932e-01, 1.4796e-02, 4.5938e-03],\n",
      "        [1.9021e-06, 3.5049e-04, 1.7622e-02, 3.5124e-04, 1.0228e-03, 5.0204e-03,\n",
      "         2.1375e-02, 9.2035e-01, 3.1973e-02, 1.9311e-03],\n",
      "        [8.1369e-06, 1.7547e-04, 2.0937e-02, 7.1862e-03, 6.1421e-03, 2.7169e-03,\n",
      "         1.5155e-03, 4.9833e-01, 4.5017e-01, 1.2814e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: cũng giống_như <UNK> triệu người mĩ khác , tôi sống\n",
      "Reference: just like <UNK> million other americans , i live\n",
      "Model: <SOS> and like like other others , , lived lived\n",
      "Attention Weights: tensor([[9.9987e-01, 1.2742e-04, 5.3573e-07, 9.0327e-07, 2.6679e-08, 6.3660e-09,\n",
      "         1.0241e-09, 1.1204e-11, 1.4073e-11, 2.8411e-12],\n",
      "        [2.7820e-01, 7.1352e-01, 4.3786e-03, 3.2861e-03, 3.6864e-04, 1.5846e-04,\n",
      "         7.6420e-05, 2.0278e-06, 1.3891e-06, 5.2185e-06],\n",
      "        [2.2150e-01, 3.4735e-01, 3.0798e-01, 1.0052e-01, 1.8303e-02, 3.1707e-03,\n",
      "         8.3971e-04, 1.5790e-04, 8.4565e-05, 9.2839e-05],\n",
      "        [4.6763e-03, 7.0916e-02, 2.2329e-01, 4.3809e-01, 1.8321e-01, 6.6298e-02,\n",
      "         9.3270e-03, 3.0278e-03, 4.6082e-04, 7.0615e-04],\n",
      "        [7.7793e-04, 8.4245e-03, 5.1366e-02, 3.7491e-01, 3.2399e-01, 1.9468e-01,\n",
      "         3.2380e-02, 9.4837e-03, 2.1365e-03, 1.8540e-03],\n",
      "        [8.2060e-07, 1.0417e-04, 5.6162e-04, 4.2023e-03, 4.0978e-02, 2.7197e-01,\n",
      "         5.3456e-02, 2.1598e-01, 1.3756e-01, 2.7518e-01],\n",
      "        [1.6866e-07, 9.4601e-06, 7.0442e-05, 4.7330e-04, 1.2315e-03, 3.0920e-03,\n",
      "         7.4672e-04, 1.4385e-01, 4.9319e-01, 3.5734e-01],\n",
      "        [7.2787e-07, 2.6547e-05, 4.9764e-05, 6.1210e-04, 1.5968e-03, 1.9493e-03,\n",
      "         5.2635e-04, 5.1558e-02, 2.3374e-01, 7.0994e-01],\n",
      "        [5.1814e-05, 2.4156e-04, 1.8426e-04, 2.8411e-03, 4.3801e-03, 1.2433e-02,\n",
      "         6.1829e-03, 2.5259e-02, 3.8195e-02, 9.1023e-01]])\n",
      "\n",
      "Epoch: 10.14, Train Loss: 1.56, Val Loss: 4.34, Train BLEU: 32.09, Val BLEU: 11.42, Minutes Elapsed: 532.95\n",
      "Sampling from training predictions...\n",
      "Source: và chúng_tôi nghĩ có_thể có 2 lực đang diễn ra\n",
      "Reference: and we thought maybe what is happening is that\n",
      "Model: <SOS> and we think that maybe &apos;s is is is\n",
      "Attention Weights: tensor([[2.7973e-05, 1.1800e-02, 9.8646e-01, 1.6661e-03, 3.8465e-05, 7.3230e-07,\n",
      "         4.7973e-06, 9.7063e-07, 2.1828e-06, 5.0205e-07],\n",
      "        [2.3085e-03, 6.4549e-01, 3.5142e-01, 7.5583e-04, 2.3565e-05, 6.5549e-07,\n",
      "         2.1582e-07, 1.6255e-07, 2.8783e-08, 6.2915e-08],\n",
      "        [1.1272e-05, 3.7714e-03, 9.7497e-01, 1.8972e-02, 2.1391e-03, 8.9484e-05,\n",
      "         1.6112e-05, 2.4890e-05, 3.8775e-06, 5.8346e-06],\n",
      "        [1.0883e-05, 9.2199e-03, 7.1790e-01, 2.4059e-01, 3.0302e-02, 1.4419e-03,\n",
      "         2.1828e-04, 2.3424e-04, 4.6468e-05, 4.1453e-05],\n",
      "        [1.1907e-05, 8.2555e-03, 3.0845e-02, 5.2519e-01, 4.0550e-01, 2.0121e-02,\n",
      "         5.8961e-03, 3.1677e-03, 4.7631e-04, 5.4350e-04],\n",
      "        [3.6694e-06, 7.7381e-04, 5.7059e-02, 4.9453e-01, 3.1283e-01, 8.1480e-02,\n",
      "         3.7543e-02, 9.4783e-03, 3.4470e-03, 2.8503e-03],\n",
      "        [3.5845e-09, 1.4393e-06, 3.9594e-04, 2.1362e-02, 3.9379e-01, 3.0545e-01,\n",
      "         1.6410e-01, 8.2384e-02, 1.4241e-02, 1.8274e-02],\n",
      "        [7.2302e-09, 1.6588e-06, 4.3825e-05, 3.8150e-03, 9.8003e-02, 2.4245e-01,\n",
      "         3.2025e-01, 2.0342e-01, 6.5510e-02, 6.6505e-02],\n",
      "        [6.6836e-08, 7.8159e-06, 2.5594e-05, 7.0642e-04, 3.5530e-03, 2.2164e-01,\n",
      "         5.7036e-01, 1.3880e-01, 2.6076e-02, 3.8841e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: chúng_tôi đang hợp_tác với những cộng_đồng địa_phương <EOS> <PAD> <PAD>\n",
      "Reference: we &apos;re working with local communities . <EOS> <PAD>\n",
      "Model: <SOS> we are looking at the very . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0720, 0.9223, 0.0058, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0015, 0.9562, 0.0423, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0007, 0.3780, 0.6058, 0.0136, 0.0013, 0.0003, 0.0002, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0012, 0.0031, 0.3723, 0.4042, 0.0965, 0.0850, 0.0377, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0018, 0.0006, 0.0275, 0.2504, 0.2373, 0.3144, 0.1666, 0.0014, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0002, 0.0209, 0.0978, 0.7295, 0.1493, 0.0022, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0174, 0.0039, 0.0008, 0.0133, 0.0459, 0.8529, 0.0470, 0.0189, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0050, 0.0046, 0.0032, 0.0097, 0.0270, 0.3943, 0.1285, 0.4278, 0.0000,\n",
      "         0.0000],\n",
      "        [0.5336, 0.1012, 0.0071, 0.0171, 0.0182, 0.1450, 0.1123, 0.0655, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 10.19, Train Loss: 1.77, Val Loss: 4.37, Train BLEU: 26.90, Val BLEU: 10.41, Minutes Elapsed: 535.51\n",
      "Sampling from training predictions...\n",
      "Source: đó là không cách để giành chiến_thắng . <EOS> <PAD>\n",
      "Reference: that is not how you win . <EOS> <PAD>\n",
      "Model: <SOS> that is not way to win . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9515, 0.0480, 0.0004, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0341, 0.5914, 0.3006, 0.0644, 0.0083, 0.0009, 0.0002, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0356, 0.4796, 0.3482, 0.1005, 0.0251, 0.0072, 0.0036, 0.0001, 0.0001,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0312, 0.2040, 0.4414, 0.2723, 0.0305, 0.0198, 0.0004, 0.0001,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0014, 0.0616, 0.0713, 0.1668, 0.5671, 0.1234, 0.0056, 0.0026,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0001, 0.0013, 0.0077, 0.0135, 0.4750, 0.4917, 0.0080, 0.0027,\n",
      "         0.0000],\n",
      "        [0.0021, 0.0113, 0.0496, 0.0346, 0.0216, 0.4700, 0.4024, 0.0051, 0.0032,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0003, 0.0058, 0.0013, 0.0851, 0.8067, 0.0316, 0.0693,\n",
      "         0.0000],\n",
      "        [0.0056, 0.0119, 0.0021, 0.0016, 0.0092, 0.0911, 0.5142, 0.1073, 0.2571,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: đây nên đáng là nguyên_tắc đầu_tiên về viện_trợ . <EOS>\n",
      "Reference: this should be the first principle of aid .\n",
      "Model: <SOS> this is actually the first of of . .\n",
      "Attention Weights: tensor([[9.3981e-01, 5.4584e-02, 5.5664e-03, 3.5837e-05, 7.0566e-06, 4.7168e-07,\n",
      "         1.6046e-09, 5.3005e-10, 2.3009e-10, 3.0084e-11],\n",
      "        [1.7494e-02, 5.0980e-01, 4.6025e-01, 9.1232e-03, 2.8550e-03, 4.4648e-04,\n",
      "         1.3668e-05, 1.4081e-05, 5.0481e-07, 1.7835e-07],\n",
      "        [1.6041e-02, 3.7354e-01, 3.9061e-01, 1.4297e-01, 5.5612e-02, 1.8118e-02,\n",
      "         2.3350e-03, 7.1986e-04, 5.0833e-05, 1.3136e-05],\n",
      "        [5.9685e-05, 1.9855e-02, 1.7334e-01, 1.0094e-01, 5.0175e-01, 1.9035e-01,\n",
      "         6.0229e-03, 7.4082e-03, 2.1951e-04, 5.4363e-05],\n",
      "        [2.1263e-06, 7.4620e-04, 3.5338e-03, 3.2870e-02, 3.8539e-01, 4.4892e-01,\n",
      "         3.0954e-02, 9.4901e-02, 2.1745e-03, 5.1356e-04],\n",
      "        [1.1635e-05, 1.5519e-04, 1.3333e-03, 1.0439e-02, 6.0513e-01, 1.7595e-01,\n",
      "         1.0107e-01, 1.0212e-01, 2.2146e-03, 1.5748e-03],\n",
      "        [3.9148e-06, 1.1350e-04, 7.1746e-04, 1.7243e-02, 1.4546e-01, 5.1283e-02,\n",
      "         5.3501e-01, 2.2157e-01, 1.9572e-02, 9.0312e-03],\n",
      "        [1.4578e-06, 2.4493e-05, 1.1288e-04, 1.7461e-03, 4.0927e-03, 2.3867e-03,\n",
      "         2.4946e-01, 6.6341e-01, 5.4720e-02, 2.4043e-02],\n",
      "        [2.3061e-05, 3.1642e-05, 3.6731e-04, 3.7922e-04, 2.7539e-03, 2.2162e-03,\n",
      "         4.2498e-02, 8.1397e-01, 6.2185e-02, 7.5581e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10.24, Train Loss: 1.80, Val Loss: 4.37, Train BLEU: 26.25, Val BLEU: 11.02, Minutes Elapsed: 538.09\n",
      "Sampling from training predictions...\n",
      "Source: và xét trên một_vài phương_diện , nó giống_như hội_trường carnegie\n",
      "Reference: and in some ways it &apos;s like carnegie hall\n",
      "Model: <SOS> and in some of , it like carnegie <UNK>\n",
      "Attention Weights: tensor([[1.4829e-05, 9.9998e-01, 8.0656e-06, 1.9407e-08, 2.6784e-10, 3.4939e-13,\n",
      "         4.1596e-15, 7.9857e-16, 1.0790e-16, 9.3453e-17],\n",
      "        [9.6543e-04, 9.9151e-01, 7.3579e-03, 1.6161e-04, 4.8945e-06, 3.7308e-08,\n",
      "         4.2743e-09, 1.6507e-09, 1.7288e-10, 6.8493e-11],\n",
      "        [1.7977e-04, 8.9690e-02, 4.4989e-01, 4.3123e-01, 2.7510e-02, 1.2924e-03,\n",
      "         6.9888e-05, 1.0364e-04, 2.7669e-05, 7.7873e-06],\n",
      "        [4.9527e-04, 1.0527e-01, 1.7647e-01, 4.8953e-01, 1.7889e-01, 3.6872e-02,\n",
      "         2.6453e-03, 5.7206e-03, 2.7506e-03, 1.3613e-03],\n",
      "        [2.6313e-03, 1.5810e-02, 4.6380e-02, 1.1761e-01, 3.1905e-01, 3.7689e-01,\n",
      "         9.9693e-02, 1.3441e-02, 4.6487e-03, 3.8468e-03],\n",
      "        [1.6880e-05, 1.4128e-03, 4.5605e-03, 1.5394e-02, 2.8529e-02, 3.2185e-01,\n",
      "         5.7762e-01, 3.9252e-02, 6.3599e-03, 5.0020e-03],\n",
      "        [6.8949e-08, 2.1790e-05, 5.8498e-04, 3.9210e-03, 6.5317e-03, 3.4470e-02,\n",
      "         2.9945e-01, 4.6508e-01, 1.5271e-01, 3.7240e-02],\n",
      "        [9.9871e-07, 3.1602e-05, 2.4117e-03, 2.4859e-02, 3.0529e-02, 2.3020e-02,\n",
      "         1.1413e-01, 2.1089e-01, 3.3441e-01, 2.5972e-01],\n",
      "        [1.4705e-06, 1.2986e-04, 6.3807e-03, 4.7931e-02, 1.5440e-02, 2.5306e-02,\n",
      "         3.7839e-02, 5.2677e-02, 4.5283e-01, 3.6146e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: những chuyện này nghe thật tuyệt_vời phải không ? <EOS>\n",
      "Reference: don &apos;t they sound incredible ? <EOS> <PAD> <PAD>\n",
      "Model: <SOS> so stories hear like like ? <EOS> ? time\n",
      "Attention Weights: tensor([[5.7140e-01, 3.6682e-01, 4.2838e-02, 1.7232e-02, 1.4894e-03, 1.0758e-04,\n",
      "         1.0182e-04, 8.4211e-06, 4.2837e-07, 8.8072e-09],\n",
      "        [4.4345e-01, 3.5655e-01, 1.1879e-02, 1.1058e-01, 4.0155e-02, 3.1804e-02,\n",
      "         5.0563e-03, 3.3102e-04, 1.5807e-04, 2.9229e-05],\n",
      "        [1.2495e-01, 1.3818e-01, 5.0815e-02, 2.4714e-01, 1.8085e-01, 1.6881e-01,\n",
      "         7.4803e-02, 1.2045e-02, 1.6960e-03, 7.2041e-04],\n",
      "        [9.8815e-02, 1.0201e-01, 1.8765e-02, 1.2972e-01, 1.4986e-01, 3.2966e-01,\n",
      "         1.1469e-01, 2.8311e-02, 1.8547e-02, 9.6192e-03],\n",
      "        [3.7524e-02, 4.2079e-02, 6.0873e-03, 4.7043e-02, 6.9576e-02, 3.9578e-01,\n",
      "         2.2887e-01, 5.9085e-02, 7.9002e-02, 3.4960e-02],\n",
      "        [9.2114e-03, 5.3581e-02, 6.2059e-03, 2.9935e-02, 4.6810e-02, 2.5096e-01,\n",
      "         1.8086e-01, 5.7884e-02, 1.7524e-01, 1.8931e-01],\n",
      "        [1.3572e-02, 1.0386e-02, 1.1323e-02, 2.0635e-01, 7.4343e-02, 8.0217e-02,\n",
      "         1.4344e-01, 1.1647e-01, 1.3021e-01, 2.1370e-01],\n",
      "        [9.1665e-02, 4.6733e-02, 2.7061e-02, 1.7848e-01, 9.2385e-02, 1.1518e-01,\n",
      "         1.0764e-01, 1.2146e-01, 8.3316e-02, 1.3608e-01],\n",
      "        [1.2489e-02, 5.6087e-02, 2.7971e-03, 5.8406e-02, 6.6052e-02, 1.2179e-01,\n",
      "         9.3334e-02, 1.2249e-01, 1.6511e-01, 3.0145e-01]])\n",
      "\n",
      "Epoch: 10.29, Train Loss: 1.80, Val Loss: 4.38, Train BLEU: 25.70, Val BLEU: 10.64, Minutes Elapsed: 540.64\n",
      "Sampling from training predictions...\n",
      "Source: mà tôi có trong_suốt sáu năm trong cuộc_đời mình ,\n",
      "Reference: i have for the last six years of my\n",
      "Model: <SOS> i , the the years six years my prison\n",
      "Attention Weights: tensor([[8.8745e-01, 1.3925e-03, 1.1112e-01, 2.6591e-05, 1.1617e-05, 1.3067e-07,\n",
      "         1.7255e-08, 1.9145e-08, 1.5021e-08, 1.0809e-10],\n",
      "        [7.0988e-02, 4.3673e-01, 4.8210e-01, 9.8707e-03, 2.1478e-04, 5.7323e-05,\n",
      "         2.1962e-05, 9.2851e-06, 3.2308e-06, 2.6455e-07],\n",
      "        [1.8571e-02, 2.3857e-02, 2.5082e-01, 6.5908e-01, 4.0158e-02, 6.6542e-03,\n",
      "         5.4882e-04, 2.2562e-04, 7.4251e-05, 1.3927e-05],\n",
      "        [1.6941e-04, 1.4772e-04, 5.2823e-03, 6.8488e-01, 2.4031e-01, 6.4130e-02,\n",
      "         2.2664e-03, 2.3682e-03, 4.1809e-04, 2.5644e-05],\n",
      "        [6.4837e-05, 3.2327e-04, 6.9163e-03, 4.7133e-01, 3.8044e-01, 1.1013e-01,\n",
      "         1.1953e-02, 1.6805e-02, 1.7988e-03, 2.4785e-04],\n",
      "        [1.2883e-05, 4.0538e-05, 9.8093e-04, 4.0509e-02, 4.1894e-01, 2.3361e-01,\n",
      "         9.9904e-02, 1.6797e-01, 3.3933e-02, 4.0962e-03],\n",
      "        [1.8433e-05, 6.5620e-05, 1.2611e-03, 6.8949e-03, 1.0743e-01, 1.6977e-01,\n",
      "         2.0827e-01, 3.7985e-01, 1.0639e-01, 2.0041e-02],\n",
      "        [5.8083e-07, 5.0895e-06, 8.3673e-06, 4.0012e-04, 7.2988e-03, 3.1465e-02,\n",
      "         1.7465e-01, 4.9420e-01, 1.9849e-01, 9.3486e-02],\n",
      "        [7.5771e-07, 8.5540e-06, 5.6086e-06, 6.0992e-05, 7.7185e-04, 5.3903e-03,\n",
      "         3.0921e-02, 3.9440e-01, 2.1542e-01, 3.5302e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: và tôi đã quyết_định sẽ gửi đơn_kiện tới toà_án ,\n",
      "Reference: so i decided to start a lawsuit against them\n",
      "Model: <SOS> and i decided to take the the , ,\n",
      "Attention Weights: tensor([[2.7667e-04, 5.7420e-03, 2.3642e-01, 5.6191e-01, 1.8440e-01, 1.0791e-02,\n",
      "         2.9712e-04, 3.0444e-05, 1.0218e-04, 2.7147e-05],\n",
      "        [9.1035e-05, 2.9222e-02, 2.1036e-01, 7.5974e-01, 5.3100e-04, 5.0294e-05,\n",
      "         3.4136e-06, 8.7784e-07, 1.4401e-06, 2.3946e-07],\n",
      "        [1.7379e-07, 1.5844e-04, 7.9831e-03, 9.8172e-01, 8.7345e-03, 1.2578e-03,\n",
      "         1.4266e-04, 5.5273e-06, 4.1095e-07, 3.4112e-08],\n",
      "        [8.4715e-07, 4.3860e-05, 1.1465e-02, 8.4523e-01, 9.7193e-02, 4.0803e-02,\n",
      "         5.0928e-03, 1.6082e-04, 9.7271e-06, 1.3681e-06],\n",
      "        [1.0329e-05, 2.4593e-04, 1.3727e-03, 2.6571e-01, 2.9802e-01, 3.4118e-01,\n",
      "         7.7258e-02, 1.4447e-02, 1.6612e-03, 1.0499e-04],\n",
      "        [1.3936e-07, 7.5478e-06, 4.9640e-05, 3.1605e-02, 1.2237e-01, 5.9376e-01,\n",
      "         2.2753e-01, 2.0797e-02, 3.6927e-03, 1.9272e-04],\n",
      "        [7.2718e-08, 7.5566e-06, 2.2014e-05, 1.6402e-03, 2.6393e-02, 2.2493e-01,\n",
      "         2.9618e-01, 2.4545e-01, 1.8863e-01, 1.6754e-02],\n",
      "        [4.0448e-08, 1.6263e-06, 2.0502e-06, 4.8049e-05, 1.9361e-03, 4.9544e-02,\n",
      "         2.6480e-01, 3.3076e-01, 2.9301e-01, 5.9898e-02],\n",
      "        [1.9975e-06, 3.2986e-05, 2.8350e-05, 9.5617e-04, 1.4133e-02, 6.0833e-02,\n",
      "         9.1839e-02, 2.2931e-01, 2.8604e-01, 3.1683e-01]])\n",
      "\n",
      "Epoch: 10.34, Train Loss: 1.85, Val Loss: 4.38, Train BLEU: 24.55, Val BLEU: 10.08, Minutes Elapsed: 543.18\n",
      "Sampling from training predictions...\n",
      "Source: tôi đưa đề_bài cho họ . <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: i would pass their sheet of paper . <EOS>\n",
      "Model: <SOS> i just just them them . their . <EOS>\n",
      "Attention Weights: tensor([[0.0040, 0.3576, 0.5847, 0.0535, 0.0003, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0098, 0.8493, 0.1392, 0.0016, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0133, 0.2960, 0.5301, 0.1297, 0.0292, 0.0016, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0016, 0.6265, 0.3392, 0.0212, 0.0097, 0.0018, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0035, 0.3890, 0.3548, 0.0740, 0.0894, 0.0892, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0010, 0.0064, 0.0118, 0.1561, 0.0224, 0.1729, 0.6294, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0004, 0.0057, 0.0084, 0.0009, 0.0569, 0.9276, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0107, 0.0828, 0.0271, 0.1222, 0.0264, 0.0921, 0.6387, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0004, 0.0103, 0.0367, 0.0352, 0.0054, 0.1769, 0.7351, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: thuật_ngữ ngăn_cản chúng_tôi hiểu được ý_tưởng của anh . <EOS>\n",
      "Reference: jargon is a barrier to our understanding of your\n",
      "Model: <SOS> the brand our we of we that in <EOS>\n",
      "Attention Weights: tensor([[9.9926e-01, 7.3862e-04, 6.2739e-08, 5.2390e-09, 3.1910e-09, 8.7547e-10,\n",
      "         3.0276e-11, 1.9331e-11, 3.7855e-13, 1.3891e-13],\n",
      "        [1.8257e-01, 8.1678e-01, 4.8483e-04, 1.3736e-04, 1.7944e-05, 1.0629e-05,\n",
      "         2.7766e-07, 1.3330e-07, 1.0598e-08, 5.8066e-09],\n",
      "        [2.3940e-01, 7.2177e-01, 1.9082e-02, 1.6824e-02, 2.3830e-03, 4.8195e-04,\n",
      "         2.6114e-05, 2.6245e-05, 4.4574e-06, 2.5640e-06],\n",
      "        [1.8874e-02, 3.9067e-02, 1.0588e-02, 7.5102e-01, 1.1493e-01, 6.1734e-02,\n",
      "         2.7505e-03, 8.4687e-04, 1.1964e-04, 6.2425e-05],\n",
      "        [7.5181e-04, 2.8291e-02, 1.3363e-02, 3.7782e-01, 2.7908e-01, 2.5053e-01,\n",
      "         1.9859e-02, 2.6078e-02, 3.4595e-03, 7.6627e-04],\n",
      "        [9.9932e-04, 5.0559e-02, 9.1636e-02, 6.4434e-01, 1.2858e-01, 6.0820e-02,\n",
      "         1.0904e-02, 8.1670e-03, 3.0275e-03, 9.7034e-04],\n",
      "        [1.2505e-04, 7.6121e-04, 2.6682e-03, 6.5291e-01, 2.0982e-01, 1.1806e-01,\n",
      "         4.7717e-03, 9.8890e-03, 8.2187e-04, 1.7357e-04],\n",
      "        [4.3466e-05, 3.0165e-04, 3.1607e-04, 3.0497e-02, 5.3463e-02, 4.7012e-01,\n",
      "         4.1481e-02, 3.1106e-01, 6.1234e-02, 3.1479e-02],\n",
      "        [1.2267e-04, 1.5478e-03, 6.4804e-04, 3.8123e-02, 2.3656e-02, 1.0653e-01,\n",
      "         1.7585e-02, 2.0070e-01, 2.5396e-01, 3.5714e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10.38, Train Loss: 1.87, Val Loss: 4.37, Train BLEU: 25.23, Val BLEU: 10.70, Minutes Elapsed: 545.73\n",
      "Sampling from training predictions...\n",
      "Source: và đây là la scala . <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: this is la scala . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> so this a scala <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0132, 0.5844, 0.3687, 0.0337, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0121, 0.9690, 0.0179, 0.0011, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0005, 0.0686, 0.5584, 0.3595, 0.0128, 0.0002, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0002, 0.0129, 0.5501, 0.4101, 0.0235, 0.0032, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0001, 0.0014, 0.0301, 0.6692, 0.1838, 0.1155, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0017, 0.0016, 0.0017, 0.0020, 0.0102, 0.1221, 0.8606, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0394, 0.1831, 0.3725, 0.0644, 0.0897, 0.0613, 0.1895, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0266, 0.0384, 0.1981, 0.0925, 0.3568, 0.0889, 0.1988, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0038, 0.0029, 0.0058, 0.0268, 0.1007, 0.3107, 0.5492, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: \" trước_khi tôi chết , tôi muốn trồng một cái\n",
      "Reference: &quot; before i die , i want to plant\n",
      "Model: <SOS> &quot; i before i , i want to build\n",
      "Attention Weights: tensor([[8.4585e-01, 1.5415e-01, 4.1494e-07, 2.4526e-06, 3.1433e-09, 3.2901e-10,\n",
      "         1.2054e-09, 1.5526e-09, 1.3332e-10, 1.8109e-10],\n",
      "        [2.0535e-03, 9.9775e-01, 1.9720e-04, 3.4440e-06, 1.2463e-07, 2.5833e-07,\n",
      "         6.1062e-08, 1.6936e-08, 4.6483e-09, 5.4671e-10],\n",
      "        [1.2875e-03, 9.8326e-01, 6.9185e-03, 8.3444e-03, 5.4603e-05, 9.7951e-06,\n",
      "         1.0526e-04, 1.6881e-05, 1.7598e-06, 3.8029e-07],\n",
      "        [2.8503e-03, 3.9732e-01, 3.6974e-02, 5.4260e-01, 1.0642e-02, 9.1866e-04,\n",
      "         4.6277e-03, 3.6357e-03, 2.3019e-04, 1.9759e-04],\n",
      "        [1.8365e-03, 1.4644e-01, 3.0775e-02, 7.3571e-01, 3.5389e-02, 4.0762e-03,\n",
      "         2.3437e-02, 2.0708e-02, 7.7373e-04, 8.6053e-04],\n",
      "        [2.4256e-03, 8.0481e-02, 2.0318e-02, 1.0389e-01, 3.9233e-01, 1.7917e-01,\n",
      "         1.1601e-01, 6.0594e-02, 2.6115e-02, 1.8671e-02],\n",
      "        [1.7532e-06, 6.0875e-04, 7.2372e-04, 5.7255e-04, 6.3485e-03, 5.2435e-02,\n",
      "         8.9893e-01, 3.6740e-02, 1.7700e-03, 1.8663e-03],\n",
      "        [1.2861e-05, 8.6776e-04, 3.2058e-04, 3.3966e-03, 4.6259e-03, 2.2319e-03,\n",
      "         3.7189e-01, 5.8652e-01, 1.0304e-02, 1.9826e-02],\n",
      "        [1.1450e-07, 6.7720e-06, 8.0355e-06, 1.0153e-03, 5.7713e-03, 1.8746e-04,\n",
      "         9.4082e-03, 8.8822e-01, 2.8679e-02, 6.6699e-02]])\n",
      "\n",
      "Epoch: 10.43, Train Loss: 1.93, Val Loss: 4.34, Train BLEU: 23.56, Val BLEU: 10.66, Minutes Elapsed: 548.28\n",
      "Sampling from training predictions...\n",
      "Source: chiếc phi_cơ này , mẫu ba146 do faam sở_hữu thông_thường\n",
      "Reference: and this plane , the model , ba146 ,\n",
      "Model: <SOS> this this , , the , , <UNK> <UNK>\n",
      "Attention Weights: tensor([[9.9569e-01, 4.2971e-03, 1.3216e-05, 1.3139e-07, 1.4409e-07, 1.8289e-08,\n",
      "         3.5657e-10, 1.8619e-10, 1.2573e-10, 1.5331e-11],\n",
      "        [2.2582e-02, 9.6819e-01, 6.7075e-03, 1.9052e-03, 5.7366e-04, 2.0904e-05,\n",
      "         9.6588e-06, 5.0102e-06, 5.3795e-07, 3.4738e-07],\n",
      "        [8.0495e-02, 2.5530e-01, 9.6387e-02, 4.0150e-01, 1.5357e-01, 6.1425e-03,\n",
      "         5.6591e-03, 6.0491e-04, 2.8305e-04, 5.3805e-05],\n",
      "        [7.7054e-02, 1.1464e-01, 1.1887e-01, 3.8727e-01, 2.7746e-01, 1.3253e-02,\n",
      "         1.0335e-02, 6.3681e-04, 3.9798e-04, 8.7739e-05],\n",
      "        [2.5414e-03, 2.9014e-02, 3.5003e-02, 2.3157e-01, 6.6288e-01, 9.5938e-03,\n",
      "         2.6053e-02, 2.3994e-03, 7.6385e-04, 1.8686e-04],\n",
      "        [1.3288e-03, 4.6589e-02, 2.8423e-03, 1.5385e-01, 6.9758e-01, 2.9579e-02,\n",
      "         5.5403e-02, 7.9737e-03, 3.1105e-03, 1.7417e-03],\n",
      "        [2.0197e-03, 3.1834e-03, 2.0706e-03, 3.6022e-02, 4.4753e-01, 1.6908e-01,\n",
      "         2.2195e-01, 3.5468e-02, 7.5513e-02, 7.1635e-03],\n",
      "        [1.1244e-04, 1.7049e-03, 2.0215e-03, 8.2233e-02, 2.8982e-01, 2.7761e-01,\n",
      "         2.8682e-01, 1.9304e-02, 3.7653e-02, 2.7205e-03],\n",
      "        [4.1532e-05, 1.9948e-03, 1.7122e-04, 7.9945e-03, 2.8533e-01, 6.8953e-02,\n",
      "         1.9482e-01, 1.0724e-01, 3.0474e-01, 2.8713e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: như mọi người , tôi đeo 1 chiếc đèn_pin <UNK>\n",
      "Reference: like the others , i wear a flickering ,\n",
      "Model: <SOS> so , people , i like a <UNK> <UNK>\n",
      "Attention Weights: tensor([[5.6671e-01, 4.3299e-01, 2.9943e-04, 1.0296e-07, 5.8167e-09, 1.9546e-09,\n",
      "         7.3374e-11, 5.9895e-12, 8.8058e-12, 5.9044e-12],\n",
      "        [1.3106e-03, 9.5852e-01, 3.5718e-02, 4.1612e-03, 1.0167e-04, 1.8227e-04,\n",
      "         5.1841e-06, 2.7428e-06, 7.0337e-07, 3.5325e-07],\n",
      "        [1.7613e-02, 6.1013e-01, 2.4926e-01, 1.0211e-01, 5.8929e-03, 1.3449e-02,\n",
      "         7.9787e-04, 4.9755e-04, 1.7567e-04, 7.4870e-05],\n",
      "        [1.0806e-03, 1.2509e-01, 1.3636e-01, 4.8757e-01, 6.0668e-02, 1.4737e-01,\n",
      "         2.2716e-02, 1.4550e-02, 2.9021e-03, 1.6925e-03],\n",
      "        [3.2207e-03, 2.0471e-01, 1.2961e-01, 5.3255e-01, 1.0315e-01, 1.7904e-02,\n",
      "         5.4578e-03, 1.6791e-03, 1.1038e-03, 6.0721e-04],\n",
      "        [8.5721e-06, 9.8639e-04, 3.4646e-03, 8.2433e-02, 2.7513e-02, 8.4368e-01,\n",
      "         3.1221e-02, 7.6023e-03, 1.7126e-03, 1.3759e-03],\n",
      "        [1.2655e-05, 1.2019e-04, 9.6819e-04, 2.6590e-02, 1.5015e-03, 5.4311e-01,\n",
      "         2.7258e-01, 1.2737e-01, 1.3518e-02, 1.4224e-02],\n",
      "        [1.2872e-06, 3.6560e-05, 5.5178e-04, 1.2257e-02, 6.4561e-04, 1.2084e-02,\n",
      "         5.4357e-02, 5.1315e-01, 3.4830e-01, 5.8620e-02],\n",
      "        [1.4634e-06, 1.0874e-04, 4.7074e-04, 4.1721e-02, 3.8508e-03, 3.6187e-03,\n",
      "         7.7386e-02, 4.5376e-01, 3.2256e-01, 9.6530e-02]])\n",
      "\n",
      "Epoch: 10.48, Train Loss: 1.94, Val Loss: 4.34, Train BLEU: 23.75, Val BLEU: 10.58, Minutes Elapsed: 550.82\n",
      "Sampling from training predictions...\n",
      "Source: điều này có_thể làm bạn shock , nhưng thực_sự chúng_ta\n",
      "Reference: this may shock you , but we &apos;re literally\n",
      "Model: <SOS> this can be me , but we can really\n",
      "Attention Weights: tensor([[8.6328e-01, 1.2478e-01, 1.1644e-02, 2.8472e-04, 1.7749e-05, 2.7401e-07,\n",
      "         2.4146e-08, 5.6995e-09, 1.1445e-08, 4.4197e-10],\n",
      "        [1.7341e-02, 4.8812e-02, 8.8314e-01, 4.6588e-02, 3.1753e-03, 8.5620e-04,\n",
      "         3.0844e-05, 1.3002e-05, 4.1713e-05, 2.2910e-06],\n",
      "        [1.0302e-02, 2.1457e-02, 4.1725e-01, 4.4677e-01, 7.1539e-02, 3.1327e-02,\n",
      "         7.8395e-04, 2.6954e-04, 2.7162e-04, 2.8611e-05],\n",
      "        [2.7412e-04, 3.4410e-03, 1.7734e-02, 1.6880e-01, 3.9245e-01, 3.9847e-01,\n",
      "         1.6055e-02, 1.0905e-03, 1.3009e-03, 3.8295e-04],\n",
      "        [1.6015e-04, 1.2820e-04, 3.7696e-03, 5.0461e-02, 1.4610e-01, 6.3624e-01,\n",
      "         1.1192e-01, 3.1122e-02, 1.5920e-02, 4.1813e-03],\n",
      "        [9.2177e-06, 2.7963e-05, 6.3759e-04, 2.9026e-04, 6.9274e-04, 1.7296e-02,\n",
      "         1.3469e-01, 6.5450e-01, 1.8859e-01, 3.2657e-03],\n",
      "        [3.1812e-05, 9.0784e-05, 3.1566e-04, 8.0180e-04, 4.5260e-03, 2.4359e-02,\n",
      "         6.9230e-02, 6.0136e-01, 2.8478e-01, 1.4505e-02],\n",
      "        [1.6732e-04, 1.8434e-04, 2.3916e-03, 3.4879e-03, 1.3175e-03, 4.6976e-03,\n",
      "         6.2829e-03, 8.0887e-02, 7.1803e-01, 1.8255e-01],\n",
      "        [1.0976e-04, 2.5097e-04, 1.2642e-03, 1.3554e-02, 3.8976e-03, 1.3127e-02,\n",
      "         1.1444e-02, 4.4708e-02, 5.9038e-01, 3.2127e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: và tôi tự_hỏi , bạn cảm_thấy thế_nào khi không có\n",
      "Reference: and i was wondering , how would you feel\n",
      "Model: <SOS> and i wondered , , you felt you feel\n",
      "Attention Weights: tensor([[2.0552e-03, 9.6245e-02, 8.8729e-01, 3.4090e-03, 1.4207e-03, 1.5218e-03,\n",
      "         6.2417e-03, 4.6464e-04, 1.2875e-03, 6.9365e-05],\n",
      "        [8.7271e-04, 5.9446e-01, 4.0385e-01, 4.6123e-04, 2.0768e-04, 7.8195e-05,\n",
      "         6.2096e-05, 1.1452e-06, 3.8763e-06, 1.2968e-07],\n",
      "        [8.3386e-06, 4.3510e-02, 9.3392e-01, 1.2911e-02, 1.5227e-03, 6.8811e-03,\n",
      "         1.1348e-03, 3.9297e-05, 6.7719e-05, 9.6006e-06],\n",
      "        [2.5577e-05, 4.4196e-02, 8.2750e-01, 7.7037e-02, 2.8300e-02, 1.5229e-02,\n",
      "         5.3378e-03, 1.1525e-03, 9.0448e-04, 3.2174e-04],\n",
      "        [3.2956e-06, 2.4822e-03, 7.8294e-02, 1.5655e-01, 4.1556e-01, 1.1718e-01,\n",
      "         1.2361e-01, 8.5711e-02, 1.8089e-02, 2.5271e-03],\n",
      "        [9.7424e-05, 1.0786e-02, 3.2571e-02, 1.2345e-01, 6.5337e-01, 9.5530e-02,\n",
      "         2.4916e-02, 3.4699e-02, 2.2411e-02, 2.1646e-03],\n",
      "        [2.8812e-06, 1.5194e-03, 1.0868e-02, 3.2078e-02, 1.8805e-01, 5.6378e-01,\n",
      "         8.8638e-02, 4.3628e-02, 6.5344e-02, 6.0929e-03],\n",
      "        [2.6492e-06, 1.9523e-04, 1.3094e-02, 1.2777e-02, 3.0985e-02, 5.3941e-01,\n",
      "         2.1881e-01, 5.6141e-02, 1.0955e-01, 1.9029e-02],\n",
      "        [4.1847e-06, 6.1970e-04, 1.1745e-02, 3.6381e-03, 2.8519e-02, 5.8323e-01,\n",
      "         1.5818e-01, 4.4312e-02, 1.4749e-01, 2.2265e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10.53, Train Loss: 1.88, Val Loss: 4.35, Train BLEU: 24.14, Val BLEU: 10.86, Minutes Elapsed: 553.33\n",
      "Sampling from training predictions...\n",
      "Source: chính vì nó có ý_nghĩa quan_trọng với hệ_thống khí_quyển ,\n",
      "Reference: because it &apos;s important to the atmospheric system ,\n",
      "Model: <SOS> because it &apos;s important for the with of ,\n",
      "Attention Weights: tensor([[9.9982e-01, 7.7852e-05, 9.7710e-05, 5.5519e-08, 6.2829e-09, 1.1582e-09,\n",
      "         9.7665e-12, 2.9940e-12, 7.8959e-12, 2.0865e-13],\n",
      "        [4.0742e-01, 1.5501e-01, 4.3461e-01, 2.1509e-03, 7.3080e-04, 5.5200e-05,\n",
      "         2.0776e-05, 2.0638e-06, 3.7786e-06, 2.3538e-07],\n",
      "        [2.8268e-01, 1.3235e-01, 3.3668e-01, 1.4802e-01, 7.5884e-02, 2.1179e-02,\n",
      "         2.0788e-03, 7.4131e-04, 3.5697e-04, 2.9203e-05],\n",
      "        [7.0248e-02, 9.5088e-02, 9.1781e-02, 1.5524e-01, 4.3271e-01, 1.4376e-01,\n",
      "         8.1293e-03, 1.5214e-03, 1.4900e-03, 3.6164e-05],\n",
      "        [3.0429e-04, 2.4264e-03, 6.0339e-03, 2.0147e-02, 1.8292e-01, 7.3244e-01,\n",
      "         3.8750e-02, 5.4471e-03, 1.1245e-02, 2.9008e-04],\n",
      "        [4.8862e-05, 6.9759e-04, 4.7219e-02, 5.0705e-02, 2.3557e-01, 2.4668e-01,\n",
      "         3.8457e-01, 1.4279e-02, 1.7468e-02, 2.7597e-03],\n",
      "        [4.8771e-06, 2.6713e-05, 2.8253e-03, 1.6206e-02, 2.5657e-02, 2.0395e-01,\n",
      "         2.9862e-01, 2.2739e-01, 2.1912e-01, 6.2078e-03],\n",
      "        [1.6731e-06, 6.8572e-06, 2.8339e-04, 2.2098e-03, 9.3161e-03, 1.1825e-01,\n",
      "         3.1542e-01, 3.6297e-01, 1.4136e-01, 5.0189e-02],\n",
      "        [4.8105e-05, 2.0552e-05, 3.1932e-04, 2.3132e-03, 3.2304e-03, 1.2333e-02,\n",
      "         2.2711e-01, 6.2662e-01, 8.9341e-02, 3.8670e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: nhưng điều khiến trái_tim tôi nhẹ_nhõm hơn và tâm_hồn tôi\n",
      "Reference: but what lifted my heart and strengthened my soul\n",
      "Model: <SOS> but what it me to was more less me\n",
      "Attention Weights: tensor([[6.5030e-03, 9.9037e-01, 3.0630e-03, 6.1604e-05, 6.3610e-07, 4.3721e-06,\n",
      "         1.6220e-07, 2.3029e-10, 2.1357e-10, 3.5198e-10],\n",
      "        [9.1981e-04, 8.4793e-01, 1.4965e-01, 1.4767e-03, 1.4304e-05, 1.1856e-06,\n",
      "         1.5107e-07, 8.2722e-09, 3.7183e-08, 2.2004e-08],\n",
      "        [5.2711e-04, 1.3547e-01, 4.3944e-01, 4.2330e-01, 6.3847e-04, 5.5707e-04,\n",
      "         5.3875e-05, 7.3149e-06, 4.6662e-06, 1.4413e-06],\n",
      "        [3.1829e-02, 1.0458e-01, 6.8818e-01, 1.1488e-01, 2.6810e-02, 2.5433e-02,\n",
      "         7.8904e-03, 2.2370e-04, 1.5189e-04, 1.2802e-05],\n",
      "        [2.0513e-02, 2.0977e-02, 1.7178e-01, 3.5727e-01, 5.6123e-02, 1.2967e-01,\n",
      "         2.4076e-01, 1.7529e-03, 9.7397e-04, 1.7231e-04],\n",
      "        [8.1230e-04, 8.6217e-05, 4.7219e-03, 4.8434e-02, 4.2583e-02, 1.7550e-01,\n",
      "         7.0920e-01, 1.3125e-02, 5.0588e-03, 4.7690e-04],\n",
      "        [1.1385e-04, 2.3277e-05, 9.4619e-04, 2.4232e-02, 6.6536e-02, 4.0001e-01,\n",
      "         4.0139e-01, 5.3775e-02, 4.7126e-02, 5.8478e-03],\n",
      "        [5.0524e-05, 2.8910e-05, 3.5610e-04, 5.8493e-03, 3.7975e-02, 2.8354e-01,\n",
      "         2.4174e-01, 1.2412e-01, 2.6766e-01, 3.8677e-02],\n",
      "        [1.0086e-04, 1.0166e-04, 3.6934e-03, 6.4789e-03, 7.5942e-03, 2.1077e-01,\n",
      "         2.1560e-01, 6.0012e-02, 4.1111e-01, 8.4532e-02]])\n",
      "\n",
      "Epoch: 10.58, Train Loss: 1.88, Val Loss: 4.36, Train BLEU: 23.96, Val BLEU: 11.55, Minutes Elapsed: 555.92\n",
      "Sampling from training predictions...\n",
      "Source: chuyện gì sẽ xay ra khi bạn làm những việc\n",
      "Reference: what happens when you do other things , like\n",
      "Model: <SOS> what if when you do things things things you\n",
      "Attention Weights: tensor([[4.9350e-01, 3.1205e-02, 3.3706e-01, 6.1994e-02, 7.5021e-02, 1.2175e-03,\n",
      "         3.7941e-06, 1.3948e-06, 7.3756e-08, 1.0681e-07],\n",
      "        [4.7796e-02, 3.8898e-04, 1.3078e-01, 6.1771e-01, 1.4493e-01, 5.2334e-02,\n",
      "         4.5901e-03, 1.3818e-03, 6.1592e-05, 1.9011e-05],\n",
      "        [5.7041e-03, 1.7586e-04, 2.0124e-02, 2.7603e-01, 6.4849e-01, 4.1762e-02,\n",
      "         3.3578e-03, 3.7497e-03, 5.1529e-04, 8.8789e-05],\n",
      "        [5.6754e-04, 4.4198e-06, 1.3267e-03, 7.3577e-02, 1.3105e-01, 1.9564e-01,\n",
      "         4.4276e-01, 1.2459e-01, 2.4013e-02, 6.4682e-03],\n",
      "        [2.4409e-06, 5.9973e-08, 1.1480e-04, 6.3826e-04, 7.7074e-03, 2.4017e-02,\n",
      "         1.9564e-01, 6.5606e-01, 8.1420e-02, 3.4401e-02],\n",
      "        [5.5624e-06, 7.6423e-07, 2.0113e-04, 1.0956e-03, 2.1543e-02, 6.2118e-03,\n",
      "         5.5038e-02, 4.3514e-01, 4.0627e-01, 7.4490e-02],\n",
      "        [3.9525e-08, 1.9496e-09, 2.0656e-07, 7.6600e-05, 2.2267e-03, 9.2195e-03,\n",
      "         6.8383e-04, 8.5017e-03, 3.5875e-01, 6.2054e-01],\n",
      "        [4.1201e-06, 7.6149e-08, 1.5242e-05, 1.0623e-03, 9.1579e-02, 2.5754e-01,\n",
      "         2.7291e-02, 6.2467e-02, 6.2198e-02, 4.9784e-01],\n",
      "        [1.5880e-05, 9.7085e-07, 2.6691e-04, 3.2679e-03, 1.2246e-01, 4.5503e-01,\n",
      "         2.3336e-01, 9.5305e-02, 2.2489e-02, 6.7804e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: đọc nó từ một người phụ_nữ châu phi , những\n",
      "Reference: read it from an african woman , the damage\n",
      "Model: <SOS> this it from a woman woman , who who\n",
      "Attention Weights: tensor([[9.8747e-01, 1.2503e-02, 3.0768e-05, 2.1383e-07, 1.4763e-09, 1.9051e-09,\n",
      "         6.2454e-11, 1.1393e-11, 4.7518e-12, 2.1103e-11],\n",
      "        [4.6178e-01, 5.2631e-01, 1.1673e-02, 2.1282e-04, 7.0798e-06, 6.1647e-06,\n",
      "         2.3920e-06, 3.1171e-06, 3.7597e-07, 3.0570e-07],\n",
      "        [2.5605e-01, 3.9196e-01, 3.2498e-01, 2.3639e-02, 1.5843e-03, 1.4778e-03,\n",
      "         1.5860e-04, 1.1890e-04, 1.6286e-05, 1.8393e-05],\n",
      "        [8.7197e-04, 3.9490e-03, 5.9071e-02, 3.1400e-01, 3.1361e-01, 2.3252e-01,\n",
      "         4.7213e-02, 2.2555e-02, 3.7584e-03, 2.4514e-03],\n",
      "        [1.0566e-04, 2.2696e-04, 7.2632e-03, 8.8071e-02, 2.6243e-01, 2.4126e-01,\n",
      "         2.5360e-01, 1.3446e-01, 8.5138e-03, 4.0668e-03],\n",
      "        [4.1761e-05, 3.2556e-04, 1.5654e-03, 3.8821e-02, 1.7206e-01, 3.8624e-01,\n",
      "         1.4845e-01, 1.6526e-01, 5.2361e-02, 3.4884e-02],\n",
      "        [4.4812e-06, 1.0072e-04, 5.9990e-04, 1.1540e-02, 3.7528e-02, 3.9599e-02,\n",
      "         3.9629e-02, 1.3566e-01, 3.0317e-01, 4.3217e-01],\n",
      "        [2.8631e-06, 2.3397e-05, 6.7182e-05, 8.6697e-04, 6.2442e-03, 6.2467e-03,\n",
      "         3.8984e-03, 1.9209e-02, 6.4158e-02, 8.9928e-01],\n",
      "        [1.5574e-05, 2.0887e-05, 6.1636e-05, 1.9863e-04, 1.0646e-03, 1.3506e-03,\n",
      "         1.9692e-03, 6.9047e-03, 6.8142e-02, 9.2027e-01]])\n",
      "\n",
      "Epoch: 10.62, Train Loss: 1.95, Val Loss: 4.39, Train BLEU: 24.54, Val BLEU: 10.99, Minutes Elapsed: 558.45\n",
      "Sampling from training predictions...\n",
      "Source: nhưng nếu ai đó từ 1 nhóm khác , những\n",
      "Reference: but if it &apos;s somebody from another group ,\n",
      "Model: <SOS> but if somebody someone from another another group ,\n",
      "Attention Weights: tensor([[1.8943e-03, 2.6356e-02, 9.6403e-01, 7.6972e-03, 2.0961e-05, 5.8841e-07,\n",
      "         1.5362e-07, 4.6821e-07, 9.9856e-10, 1.8339e-09],\n",
      "        [5.3139e-04, 9.5857e-01, 4.0767e-02, 1.2744e-04, 1.1979e-06, 1.0503e-07,\n",
      "         4.7926e-08, 1.5462e-08, 5.3427e-10, 1.0511e-09],\n",
      "        [7.2540e-06, 1.9560e-02, 9.7114e-01, 8.2800e-03, 9.7471e-04, 3.5834e-05,\n",
      "         5.0819e-06, 1.0956e-06, 3.4782e-07, 7.1787e-07],\n",
      "        [2.3858e-05, 1.7694e-04, 7.9988e-01, 1.4368e-01, 5.3305e-02, 2.1601e-03,\n",
      "         5.8657e-04, 1.2233e-04, 3.6704e-05, 2.2932e-05],\n",
      "        [1.0861e-04, 1.2977e-04, 2.2506e-01, 4.0028e-01, 1.2649e-01, 1.4374e-01,\n",
      "         9.5595e-02, 7.9319e-03, 6.2857e-04, 4.3903e-05],\n",
      "        [1.2270e-04, 2.6150e-05, 3.1946e-02, 2.8334e-02, 3.6192e-02, 1.8682e-01,\n",
      "         5.7324e-01, 1.3403e-01, 8.0927e-03, 1.1976e-03],\n",
      "        [5.0398e-04, 3.6744e-05, 1.7515e-02, 1.3686e-02, 3.7499e-02, 2.4820e-01,\n",
      "         6.0974e-01, 4.8135e-02, 2.3239e-02, 1.4447e-03],\n",
      "        [4.0341e-06, 5.7758e-07, 5.3293e-04, 3.4169e-04, 3.7995e-03, 1.2907e-01,\n",
      "         8.2009e-01, 4.2974e-02, 2.7970e-03, 3.8596e-04],\n",
      "        [2.7274e-03, 2.2060e-03, 7.4075e-03, 1.1344e-03, 1.2822e-02, 1.2532e-01,\n",
      "         4.6944e-01, 5.5410e-02, 2.7658e-01, 4.6945e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi thấy cảnh giống_như 1 gia_đình đang đánh_cá trên thuyền\n",
      "Reference: i saw what seemed to be a family fishing\n",
      "Model: <SOS> i feel feel like a a family family family\n",
      "Attention Weights: tensor([[7.4247e-02, 8.8970e-01, 3.5971e-02, 7.6576e-05, 2.3268e-06, 3.4741e-08,\n",
      "         2.7295e-08, 1.6587e-09, 1.8049e-09, 6.5753e-10],\n",
      "        [4.1163e-04, 9.7055e-01, 2.8933e-02, 8.3238e-05, 1.5123e-05, 2.5660e-06,\n",
      "         4.1110e-07, 2.2892e-07, 4.8312e-08, 2.9805e-08],\n",
      "        [1.2279e-03, 4.3687e-01, 4.9727e-01, 6.2285e-02, 1.5297e-03, 5.8681e-04,\n",
      "         1.3154e-04, 7.2909e-05, 1.3333e-05, 1.2738e-05],\n",
      "        [1.6093e-03, 1.8187e-03, 4.5534e-01, 4.1353e-01, 9.8069e-02, 2.2709e-02,\n",
      "         3.2896e-03, 3.0071e-03, 3.5849e-04, 2.7101e-04],\n",
      "        [7.8135e-06, 8.0496e-05, 1.8691e-03, 1.0171e-01, 3.1810e-01, 5.0808e-01,\n",
      "         3.6537e-02, 2.6860e-02, 4.5148e-03, 2.2357e-03],\n",
      "        [3.8097e-04, 7.9900e-03, 4.4686e-02, 2.9960e-01, 2.6846e-01, 2.9145e-01,\n",
      "         3.2071e-02, 4.9588e-02, 4.4790e-03, 1.2990e-03],\n",
      "        [3.4665e-07, 6.6355e-07, 1.2862e-04, 2.7766e-02, 1.7852e-01, 5.0583e-01,\n",
      "         4.0716e-02, 1.9996e-01, 3.3187e-02, 1.3890e-02],\n",
      "        [7.7994e-07, 3.1352e-07, 1.1078e-05, 1.4351e-02, 1.2654e-01, 5.3030e-01,\n",
      "         5.5338e-02, 2.0812e-01, 5.3590e-02, 1.1747e-02],\n",
      "        [7.3209e-07, 1.1153e-07, 1.0981e-06, 4.4826e-03, 5.7772e-02, 3.7062e-01,\n",
      "         1.5251e-01, 3.1043e-01, 8.7682e-02, 1.6505e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10.67, Train Loss: 1.90, Val Loss: 4.37, Train BLEU: 24.59, Val BLEU: 10.67, Minutes Elapsed: 560.97\n",
      "Sampling from training predictions...\n",
      "Source: có_nhà khoa_học mọt_sách nào không , bạn có_thể chọn cái\n",
      "Reference: any science geeks , you get that one .\n",
      "Model: <SOS> calculating science science can you can choose your .\n",
      "Attention Weights: tensor([[9.9513e-01, 4.6501e-03, 2.1655e-04, 1.7385e-06, 1.5787e-07, 1.3172e-10,\n",
      "         2.1716e-11, 7.6014e-11, 1.6936e-10, 1.7959e-10],\n",
      "        [1.0515e-01, 6.4930e-01, 2.3705e-01, 7.1950e-03, 7.7975e-04, 4.4946e-04,\n",
      "         3.6995e-05, 2.3220e-05, 9.2927e-06, 2.7559e-06],\n",
      "        [1.0243e-01, 6.3556e-01, 2.0652e-01, 4.3022e-02, 8.8328e-03, 2.8194e-03,\n",
      "         3.1473e-04, 1.9060e-04, 2.3942e-04, 6.6962e-05],\n",
      "        [1.3404e-02, 1.1494e-01, 1.8261e-01, 3.9346e-01, 1.7771e-01, 1.0205e-01,\n",
      "         1.3121e-02, 9.6997e-04, 1.3479e-03, 3.8754e-04],\n",
      "        [1.0374e-03, 1.0122e-02, 9.9602e-02, 6.9816e-02, 8.7137e-02, 4.7546e-01,\n",
      "         1.6247e-01, 3.6320e-02, 4.0692e-02, 1.7343e-02],\n",
      "        [2.4291e-04, 1.0275e-03, 5.0339e-03, 6.6824e-03, 3.0666e-02, 2.1337e-01,\n",
      "         2.5105e-01, 3.4553e-01, 1.0234e-01, 4.4055e-02],\n",
      "        [1.4530e-04, 1.4158e-03, 1.4875e-03, 2.2438e-03, 4.2250e-03, 3.3513e-02,\n",
      "         3.0011e-02, 8.6511e-02, 8.1403e-01, 2.6417e-02],\n",
      "        [6.8770e-05, 5.3313e-04, 9.5071e-04, 2.5031e-04, 1.2332e-03, 1.9059e-02,\n",
      "         4.6041e-03, 5.3329e-03, 4.6943e-02, 9.2102e-01],\n",
      "        [7.3616e-04, 1.5621e-02, 3.1405e-02, 7.6266e-03, 1.2622e-02, 1.2019e-01,\n",
      "         6.5666e-02, 5.8751e-03, 3.8269e-02, 7.0199e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: vậy_thì con còn muốn tiếp_tục nữa không ? <EOS> <PAD>\n",
      "Reference: so do you still not want to continue ?\n",
      "Model: <SOS> so the want want to to go go surgery\n",
      "Attention Weights: tensor([[0.9734, 0.0265, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0415, 0.9402, 0.0114, 0.0065, 0.0004, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0844, 0.2505, 0.1545, 0.4558, 0.0517, 0.0027, 0.0003, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0303, 0.1584, 0.1894, 0.4686, 0.1431, 0.0087, 0.0014, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0077, 0.0033, 0.0244, 0.1578, 0.6427, 0.1597, 0.0035, 0.0007, 0.0002,\n",
      "         0.0000],\n",
      "        [0.0014, 0.0011, 0.0098, 0.0658, 0.4059, 0.5103, 0.0033, 0.0017, 0.0007,\n",
      "         0.0000],\n",
      "        [0.0008, 0.0004, 0.0148, 0.1189, 0.4695, 0.3862, 0.0043, 0.0029, 0.0021,\n",
      "         0.0000],\n",
      "        [0.0013, 0.0003, 0.0031, 0.0451, 0.4036, 0.5339, 0.0045, 0.0040, 0.0042,\n",
      "         0.0000],\n",
      "        [0.0023, 0.0001, 0.0015, 0.0426, 0.4887, 0.4252, 0.0121, 0.0126, 0.0149,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 10.72, Train Loss: 1.98, Val Loss: 4.41, Train BLEU: 22.82, Val BLEU: 10.39, Minutes Elapsed: 563.50\n",
      "Sampling from training predictions...\n",
      "Source: chúng như những đứa trẻ khác , đang thương_lượng với\n",
      "Reference: they are , like other young people , negotiating\n",
      "Model: <SOS> they &apos;re other , other other , are negotiating\n",
      "Attention Weights: tensor([[9.9524e-01, 2.8436e-03, 1.6201e-03, 1.2754e-04, 1.5711e-04, 1.1514e-05,\n",
      "         1.1490e-07, 8.7479e-08, 1.4254e-07, 2.2453e-08],\n",
      "        [1.1949e-01, 3.4426e-01, 3.9147e-01, 1.0705e-01, 3.1930e-02, 2.8512e-03,\n",
      "         5.7434e-04, 9.4267e-04, 1.3504e-03, 8.2822e-05],\n",
      "        [2.2840e-02, 1.0619e-01, 5.0428e-01, 1.7615e-01, 1.6443e-01, 1.6041e-02,\n",
      "         4.1943e-03, 1.1232e-03, 4.3827e-03, 3.6019e-04],\n",
      "        [1.4633e-03, 7.9840e-02, 2.1931e-01, 3.2016e-01, 2.5900e-01, 3.6316e-02,\n",
      "         6.9994e-02, 5.6227e-03, 6.9274e-03, 1.3614e-03],\n",
      "        [1.4730e-03, 1.2021e-02, 2.0458e-02, 2.8410e-01, 2.3885e-01, 4.9031e-02,\n",
      "         2.9007e-01, 7.9111e-02, 1.3075e-02, 1.1802e-02],\n",
      "        [1.0833e-02, 4.6126e-02, 1.0927e-01, 1.3166e-01, 2.9078e-01, 1.9622e-02,\n",
      "         1.2036e-01, 5.2197e-02, 1.3425e-01, 8.4901e-02],\n",
      "        [5.4429e-04, 2.5627e-03, 2.1744e-03, 1.4242e-03, 1.9239e-02, 3.2996e-03,\n",
      "         2.6591e-01, 3.5919e-01, 1.3301e-01, 2.1265e-01],\n",
      "        [2.9740e-05, 2.6300e-04, 7.1669e-05, 1.7763e-04, 1.5998e-03, 2.4742e-04,\n",
      "         6.9557e-02, 7.9377e-01, 5.1755e-02, 8.2533e-02],\n",
      "        [4.0738e-06, 8.0423e-05, 4.9000e-05, 2.6989e-04, 5.0162e-04, 2.6702e-04,\n",
      "         4.1275e-03, 3.6602e-01, 4.9134e-01, 1.3733e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: đầu_tiên tôi nhìn nó , và nói , được rồi\n",
      "Reference: at first i saw it , and i said\n",
      "Model: <SOS> and i looked looked at , and said said\n",
      "Attention Weights: tensor([[9.9957e-01, 1.2248e-05, 4.0698e-04, 7.3252e-06, 7.7355e-09, 9.0294e-09,\n",
      "         4.3750e-10, 4.2297e-11, 2.7315e-10, 1.3219e-10],\n",
      "        [9.6262e-01, 8.8571e-03, 2.8500e-02, 1.5086e-05, 3.4722e-06, 2.7722e-06,\n",
      "         8.7269e-07, 4.8410e-08, 6.3837e-08, 9.6550e-08],\n",
      "        [3.5562e-02, 1.5597e-02, 9.0093e-01, 4.7006e-02, 7.5517e-04, 2.3140e-05,\n",
      "         1.1049e-04, 1.1606e-05, 5.3355e-06, 4.9545e-06],\n",
      "        [1.3960e-02, 2.0178e-02, 8.9065e-01, 6.9465e-02, 5.3710e-03, 5.7143e-05,\n",
      "         2.1677e-04, 6.8568e-05, 1.9999e-05, 1.0760e-05],\n",
      "        [9.4605e-03, 7.0877e-02, 5.5247e-01, 2.6865e-01, 8.8853e-02, 6.0839e-03,\n",
      "         2.2542e-03, 6.9298e-04, 4.8600e-04, 1.7471e-04],\n",
      "        [6.9788e-04, 1.5197e-03, 9.6665e-03, 3.5282e-01, 4.8216e-01, 1.3263e-01,\n",
      "         1.1648e-02, 3.6544e-03, 3.9533e-03, 1.2455e-03],\n",
      "        [2.3887e-04, 1.6714e-03, 1.3025e-02, 1.6006e-02, 3.7835e-01, 4.5608e-01,\n",
      "         1.0970e-01, 7.3209e-03, 1.4827e-02, 2.7863e-03],\n",
      "        [2.1637e-04, 1.9838e-04, 3.9994e-03, 4.1112e-03, 1.6298e-01, 3.1094e-01,\n",
      "         3.4946e-01, 2.7916e-02, 1.1369e-01, 2.6485e-02],\n",
      "        [1.8382e-04, 2.1825e-04, 2.0293e-02, 1.3309e-03, 1.0206e-02, 2.5148e-02,\n",
      "         4.7375e-01, 7.4247e-02, 3.0798e-01, 8.6638e-02]])\n",
      "\n",
      "Epoch: 10.77, Train Loss: 1.90, Val Loss: 4.38, Train BLEU: 24.04, Val BLEU: 10.47, Minutes Elapsed: 566.01\n",
      "Sampling from training predictions...\n",
      "Source: và trên thực_tế , đó là những gì chúng_ta sẽ\n",
      "Reference: and in fact , that &apos;s what we &apos;re\n",
      "Model: <SOS> and in fact , that &apos;s what we will\n",
      "Attention Weights: tensor([[1.3366e-03, 9.2024e-01, 7.5762e-02, 2.5709e-03, 3.7720e-05, 5.0526e-05,\n",
      "         1.3093e-07, 1.9345e-06, 1.0224e-09, 1.8068e-07],\n",
      "        [1.0882e-03, 1.8273e-01, 8.1589e-01, 1.3135e-04, 1.5721e-04, 4.5960e-06,\n",
      "         3.0849e-07, 1.6695e-07, 2.5935e-08, 2.9736e-08],\n",
      "        [2.5402e-03, 2.0790e-01, 6.5675e-01, 7.7483e-02, 4.8811e-02, 5.3004e-03,\n",
      "         1.0580e-03, 1.1404e-04, 2.0255e-05, 2.8472e-05],\n",
      "        [1.6221e-02, 8.7233e-02, 2.3928e-01, 1.5722e-01, 4.0413e-01, 8.1842e-02,\n",
      "         8.4673e-03, 4.1218e-03, 5.6759e-04, 9.1853e-04],\n",
      "        [2.3376e-04, 6.9769e-03, 1.1147e-02, 5.3919e-02, 6.4610e-01, 2.4704e-01,\n",
      "         2.4456e-02, 8.3725e-03, 1.2943e-03, 4.6751e-04],\n",
      "        [4.0852e-06, 5.5962e-03, 2.4008e-02, 1.9504e-02, 3.2853e-01, 4.4889e-01,\n",
      "         1.2695e-01, 2.3273e-02, 9.0660e-03, 1.4178e-02],\n",
      "        [3.7256e-06, 3.9090e-03, 1.8699e-02, 1.1206e-02, 4.8172e-02, 4.4858e-01,\n",
      "         3.0501e-01, 8.9156e-02, 1.8880e-02, 5.6379e-02],\n",
      "        [1.9011e-07, 1.3804e-04, 2.8094e-03, 3.4061e-03, 7.5942e-03, 7.4687e-02,\n",
      "         4.6075e-01, 1.0467e-01, 1.7870e-01, 1.6724e-01],\n",
      "        [9.9013e-08, 2.3703e-05, 2.1431e-04, 6.6815e-04, 9.3125e-03, 8.6390e-02,\n",
      "         6.1101e-02, 2.9646e-02, 4.9091e-02, 7.6355e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: chúng giết gia_súc của chúng_tôi . <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: they kill our livestock . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> they kill our our . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.8131, 0.1869, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0018, 0.9954, 0.0028, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0130, 0.8635, 0.1194, 0.0022, 0.0009, 0.0010, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0060, 0.0090, 0.9599, 0.0102, 0.0101, 0.0039, 0.0009, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0007, 0.0015, 0.0476, 0.0835, 0.1579, 0.5053, 0.2036, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0002, 0.0016, 0.0103, 0.0437, 0.3062, 0.6379, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0049, 0.0054, 0.0431, 0.0901, 0.0548, 0.3019, 0.4999, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0296, 0.2055, 0.0914, 0.0370, 0.0581, 0.2570, 0.3214, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0623, 0.0553, 0.0224, 0.0234, 0.0608, 0.3898, 0.3859, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10.82, Train Loss: 1.87, Val Loss: 4.39, Train BLEU: 24.85, Val BLEU: 10.62, Minutes Elapsed: 568.52\n",
      "Sampling from training predictions...\n",
      "Source: những nốt_nhạc không_đổi , kéo_dài . gần_như chẳng có nhịp_điệu\n",
      "Reference: it doesn &apos;t change key , the notes are\n",
      "Model: <SOS> the nuclear &apos;t , , it , are are\n",
      "Attention Weights: tensor([[3.1558e-02, 9.6590e-01, 2.5323e-03, 5.7354e-06, 7.8892e-06, 1.5682e-08,\n",
      "         4.9764e-10, 1.8827e-10, 9.2810e-12, 1.2818e-11],\n",
      "        [6.4626e-03, 7.4527e-01, 2.1757e-01, 2.5022e-02, 5.2503e-03, 3.0578e-04,\n",
      "         6.2684e-05, 4.6739e-05, 6.4761e-06, 1.1665e-06],\n",
      "        [2.6965e-03, 7.8914e-02, 5.1520e-01, 2.2411e-01, 1.2802e-01, 4.0648e-02,\n",
      "         4.8463e-03, 4.4441e-03, 9.0469e-04, 2.1369e-04],\n",
      "        [4.4416e-02, 8.2094e-02, 2.4237e-01, 5.5326e-01, 6.1641e-02, 1.0941e-02,\n",
      "         4.3290e-03, 6.1130e-04, 2.1616e-04, 1.2605e-04],\n",
      "        [3.6052e-03, 2.1136e-02, 2.7704e-02, 3.5467e-01, 4.3328e-01, 8.5313e-02,\n",
      "         6.2014e-02, 6.9341e-03, 3.5071e-03, 1.8329e-03],\n",
      "        [1.3166e-03, 1.0833e-02, 7.2762e-03, 1.1352e-01, 7.5538e-01, 6.6210e-02,\n",
      "         3.9700e-02, 3.4202e-03, 1.3923e-03, 9.5490e-04],\n",
      "        [1.6998e-04, 1.3964e-02, 4.6458e-03, 5.2977e-02, 2.4248e-01, 3.3623e-01,\n",
      "         2.4732e-01, 8.0866e-02, 1.7372e-02, 3.9764e-03],\n",
      "        [1.0100e-05, 1.0972e-04, 2.8912e-04, 2.9089e-03, 2.1712e-01, 1.7406e-01,\n",
      "         4.9853e-01, 9.5702e-02, 9.0398e-03, 2.2352e-03],\n",
      "        [1.4939e-05, 3.1533e-04, 3.2779e-04, 1.4377e-03, 4.6855e-03, 5.2473e-02,\n",
      "         2.1815e-01, 5.0399e-01, 1.6516e-01, 5.3450e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: hôm_nay tôi 22 tuổi . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: today i am 22 . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> today , 22 22 years old . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.8562, 0.0914, 0.0508, 0.0016, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0026, 0.5307, 0.4587, 0.0079, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0033, 0.0268, 0.7995, 0.1680, 0.0021, 0.0003, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0056, 0.0955, 0.6302, 0.2648, 0.0036, 0.0003, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0017, 0.0120, 0.9119, 0.0657, 0.0085, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0032, 0.0219, 0.6198, 0.2793, 0.0757, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0001, 0.0040, 0.4631, 0.2201, 0.3126, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0047, 0.0402, 0.1580, 0.2646, 0.1488, 0.3837, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0016, 0.0520, 0.2264, 0.3328, 0.1834, 0.2038, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 10.86, Train Loss: 1.85, Val Loss: 4.36, Train BLEU: 25.55, Val BLEU: 10.95, Minutes Elapsed: 571.02\n",
      "Sampling from training predictions...\n",
      "Source: bạn huýt với cái tông giống tôi . <EOS> <PAD>\n",
      "Reference: you whistle the same tone as me . <EOS>\n",
      "Model: <SOS> you whistle the with with the me . .\n",
      "Attention Weights: tensor([[0.9657, 0.0342, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0043, 0.9925, 0.0030, 0.0001, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0725, 0.7222, 0.1830, 0.0185, 0.0029, 0.0009, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0019, 0.0217, 0.3193, 0.3402, 0.2480, 0.0636, 0.0048, 0.0005, 0.0001,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0000, 0.0024, 0.0911, 0.3631, 0.5339, 0.0049, 0.0029, 0.0014,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0001, 0.0012, 0.0967, 0.2475, 0.5566, 0.0461, 0.0347, 0.0168,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0001, 0.0003, 0.0149, 0.1342, 0.7612, 0.0487, 0.0253, 0.0152,\n",
      "         0.0000],\n",
      "        [0.0011, 0.0011, 0.0018, 0.0294, 0.1347, 0.6665, 0.0983, 0.0345, 0.0325,\n",
      "         0.0000],\n",
      "        [0.0234, 0.0086, 0.0059, 0.0475, 0.0907, 0.4678, 0.1391, 0.0989, 0.1180,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: thay vào đó , như anh - <UNK> đã nói\n",
      "Reference: instead , as einstein said , make everything as\n",
      "Model: <SOS> instead , as he said said a a a\n",
      "Attention Weights: tensor([[9.9463e-01, 5.1927e-03, 1.2128e-04, 4.9532e-05, 3.0067e-06, 3.9645e-08,\n",
      "         1.2190e-09, 4.3092e-10, 5.3090e-10, 3.3950e-11],\n",
      "        [7.6726e-03, 2.9474e-02, 1.9451e-01, 4.9595e-01, 2.6629e-01, 5.4728e-03,\n",
      "         5.2231e-04, 8.9981e-05, 1.1817e-05, 3.6213e-06],\n",
      "        [5.1977e-03, 8.5061e-04, 1.7083e-02, 7.4166e-02, 8.2823e-01, 5.4546e-02,\n",
      "         1.1528e-02, 6.7770e-03, 1.3354e-03, 2.9144e-04],\n",
      "        [1.4051e-04, 9.5214e-05, 3.5868e-04, 1.3265e-02, 1.9608e-01, 4.1090e-01,\n",
      "         1.9300e-01, 1.6323e-01, 1.7991e-02, 4.9395e-03],\n",
      "        [1.5691e-04, 2.8911e-04, 1.2132e-03, 2.9847e-03, 1.2082e-01, 8.3181e-02,\n",
      "         2.6115e-01, 1.7502e-01, 2.1053e-01, 1.4466e-01],\n",
      "        [3.8856e-05, 2.4789e-05, 2.8688e-04, 2.9942e-04, 1.7765e-03, 2.3989e-03,\n",
      "         2.2547e-02, 9.4413e-02, 4.2163e-01, 4.5659e-01],\n",
      "        [2.2613e-07, 3.1107e-07, 1.8926e-06, 4.1711e-06, 5.7985e-04, 1.7525e-03,\n",
      "         1.5454e-02, 2.4030e-02, 6.9755e-02, 8.8842e-01],\n",
      "        [1.2204e-06, 8.1833e-07, 5.8403e-06, 2.7703e-05, 1.4347e-03, 2.7529e-03,\n",
      "         3.6169e-02, 9.2228e-02, 1.1424e-01, 7.5314e-01],\n",
      "        [5.8553e-06, 1.4937e-06, 2.3342e-05, 1.9192e-04, 4.6889e-04, 7.4946e-04,\n",
      "         7.9060e-03, 2.1693e-02, 2.4589e-01, 7.2307e-01]])\n",
      "\n",
      "Epoch: 10.91, Train Loss: 1.78, Val Loss: 4.41, Train BLEU: 26.08, Val BLEU: 10.09, Minutes Elapsed: 573.57\n",
      "Sampling from training predictions...\n",
      "Source: sau_đó họ xé nó đi . không có bất_kỳ gian_lận\n",
      "Reference: then they shredded it . no cheating whatsoever .\n",
      "Model: <SOS> then they shredded it . . don whatsoever .\n",
      "Attention Weights: tensor([[1.0000e+00, 1.8410e-06, 5.4822e-07, 9.4163e-08, 5.1256e-09, 8.5584e-12,\n",
      "         1.7675e-12, 2.4969e-12, 2.7743e-13, 1.5715e-14],\n",
      "        [3.1003e-01, 9.4365e-02, 5.9474e-01, 5.9619e-04, 2.4960e-04, 6.6053e-06,\n",
      "         9.6578e-06, 1.0993e-06, 1.8986e-07, 4.1369e-08],\n",
      "        [8.0127e-03, 4.3711e-03, 8.7632e-01, 9.5237e-02, 1.5576e-02, 2.2524e-04,\n",
      "         2.0456e-04, 3.3173e-05, 1.7654e-05, 3.6427e-06],\n",
      "        [2.9994e-03, 7.9197e-04, 3.3217e-01, 5.3631e-01, 1.2641e-01, 9.1958e-04,\n",
      "         2.1403e-04, 7.6093e-05, 1.0116e-04, 1.1680e-05],\n",
      "        [2.9932e-04, 3.3758e-04, 2.0073e-02, 6.4833e-02, 8.4649e-01, 4.7781e-02,\n",
      "         1.5502e-02, 2.3716e-03, 1.0588e-03, 1.2508e-03],\n",
      "        [1.9806e-05, 5.6034e-05, 1.5435e-04, 8.9278e-04, 3.9466e-02, 7.9657e-02,\n",
      "         8.0231e-01, 6.5462e-02, 5.6545e-03, 6.3281e-03],\n",
      "        [3.1981e-05, 4.5384e-06, 1.9488e-04, 3.8109e-04, 3.1194e-03, 2.6167e-02,\n",
      "         7.2713e-01, 1.8449e-01, 4.2798e-02, 1.5688e-02],\n",
      "        [8.3422e-04, 1.1756e-04, 1.7737e-02, 2.5978e-02, 1.9031e-02, 3.5736e-02,\n",
      "         3.1765e-01, 9.9340e-02, 4.0128e-01, 8.2294e-02],\n",
      "        [4.4747e-06, 7.8280e-06, 7.1187e-05, 6.1744e-04, 1.8424e-03, 1.0506e-02,\n",
      "         4.3409e-01, 1.0235e-01, 2.2011e-01, 2.3040e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: nó là nhựa xốp , như tôi đã nói ,\n",
      "Reference: it &apos;s a porous asphalt , like i said\n",
      "Model: <SOS> it was a plastic , as as i said\n",
      "Attention Weights: tensor([[8.2251e-01, 1.7734e-01, 1.4826e-04, 2.3975e-06, 5.0776e-08, 1.2244e-07,\n",
      "         1.4623e-09, 1.6527e-09, 6.4096e-11, 5.8116e-12],\n",
      "        [2.5642e-02, 8.7723e-01, 8.8172e-02, 8.5380e-03, 1.9434e-04, 2.0805e-04,\n",
      "         4.4061e-06, 1.3403e-05, 2.3763e-06, 1.5612e-07],\n",
      "        [1.2890e-02, 2.0942e-01, 6.2275e-01, 1.4825e-01, 3.5134e-03, 2.0802e-03,\n",
      "         1.5539e-04, 7.8535e-04, 1.5008e-04, 7.5156e-06],\n",
      "        [6.8954e-05, 2.1564e-03, 2.3245e-01, 7.4058e-01, 1.4409e-02, 1.0123e-02,\n",
      "         9.4963e-05, 5.8909e-05, 4.1930e-05, 1.6826e-05],\n",
      "        [4.7126e-04, 3.5795e-03, 3.1278e-01, 1.4059e-01, 2.8025e-01, 2.5680e-01,\n",
      "         1.0755e-03, 2.9827e-03, 1.2758e-03, 1.9887e-04],\n",
      "        [4.9230e-05, 4.7927e-04, 5.7675e-03, 1.7327e-02, 1.5069e-01, 8.1368e-01,\n",
      "         3.9084e-03, 6.9149e-03, 9.5774e-04, 2.2137e-04],\n",
      "        [7.0473e-05, 2.9193e-04, 2.3909e-03, 1.3562e-02, 2.9121e-02, 7.1743e-01,\n",
      "         1.2572e-01, 9.8137e-02, 1.2444e-02, 8.3674e-04],\n",
      "        [6.0148e-04, 2.2978e-03, 4.2025e-03, 5.6134e-03, 1.5200e-02, 5.6249e-01,\n",
      "         2.2519e-01, 1.4220e-01, 4.0454e-02, 1.7413e-03],\n",
      "        [1.6670e-03, 3.3647e-02, 4.0675e-02, 1.4326e-02, 5.1938e-03, 3.2774e-02,\n",
      "         3.8340e-02, 5.1042e-01, 3.1268e-01, 1.0279e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10.96, Train Loss: 1.66, Val Loss: 4.39, Train BLEU: 29.14, Val BLEU: 10.32, Minutes Elapsed: 576.12\n",
      "Sampling from training predictions...\n",
      "Source: tôi đã xem bộ phim vào dịp sinh_nhật lần thứ\n",
      "Reference: i had seen the film on the occasion of\n",
      "Model: <SOS> i watched seen film film on a occasion of\n",
      "Attention Weights: tensor([[7.2422e-03, 9.2639e-01, 6.4803e-02, 1.5173e-03, 2.3074e-05, 1.8812e-05,\n",
      "         4.0667e-07, 1.8692e-08, 6.5528e-08, 9.5253e-09],\n",
      "        [5.2914e-04, 1.2236e-02, 9.8545e-01, 1.2359e-03, 5.4066e-04, 3.8464e-06,\n",
      "         6.6218e-07, 2.4202e-07, 5.0797e-08, 3.9448e-08],\n",
      "        [4.8218e-03, 1.6431e-01, 7.3919e-01, 5.5494e-02, 3.4724e-02, 1.3097e-03,\n",
      "         1.2084e-04, 1.8925e-05, 3.2312e-06, 2.1746e-06],\n",
      "        [5.8979e-04, 4.1218e-04, 1.8182e-02, 2.5586e-01, 6.5232e-01, 5.7439e-02,\n",
      "         1.2018e-02, 2.7848e-03, 2.1778e-04, 1.7556e-04],\n",
      "        [1.6821e-03, 6.0831e-04, 2.8850e-02, 1.3437e-01, 7.5216e-01, 5.5103e-02,\n",
      "         2.1858e-02, 3.8816e-03, 8.4801e-04, 6.4135e-04],\n",
      "        [4.3125e-04, 2.0866e-04, 1.6060e-03, 2.3106e-02, 2.5910e-01, 3.0521e-01,\n",
      "         3.3471e-01, 6.1439e-02, 1.0297e-02, 3.8891e-03],\n",
      "        [3.1210e-05, 7.8783e-05, 9.5058e-05, 7.5407e-04, 1.3232e-02, 2.1560e-01,\n",
      "         5.8635e-01, 1.3116e-01, 3.5119e-02, 1.7585e-02],\n",
      "        [7.7458e-05, 1.5733e-05, 1.8541e-04, 2.7716e-04, 8.7896e-03, 2.4411e-02,\n",
      "         3.2205e-01, 4.6874e-01, 9.7859e-02, 7.7587e-02],\n",
      "        [8.1079e-06, 1.9134e-04, 1.9735e-04, 2.0827e-04, 5.5242e-03, 3.7907e-02,\n",
      "         4.2391e-01, 1.5100e-01, 2.8649e-01, 9.4568e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: đúng vậy đấy , gần như_là tất_cả các tấm ảnh\n",
      "Reference: and yeah , they pretty much <UNK> all the\n",
      "Model: <SOS> that , , that is like of this of\n",
      "Attention Weights: tensor([[3.8659e-01, 6.1313e-01, 2.7421e-04, 1.5282e-06, 4.9842e-06, 6.4718e-10,\n",
      "         7.1416e-10, 2.3750e-12, 1.3117e-12, 6.3650e-13],\n",
      "        [4.3143e-02, 1.1238e-01, 7.5969e-01, 7.4894e-02, 9.7826e-03, 3.8262e-05,\n",
      "         6.8586e-05, 1.8814e-06, 1.0557e-06, 6.8700e-07],\n",
      "        [8.3759e-02, 5.8493e-02, 2.2978e-01, 2.0416e-01, 4.2036e-01, 2.6358e-03,\n",
      "         6.4968e-04, 5.9665e-05, 7.0228e-05, 3.3607e-05],\n",
      "        [1.0209e-01, 1.4408e-02, 1.4839e-01, 7.5631e-02, 6.3083e-01, 1.8669e-02,\n",
      "         8.2046e-03, 6.5074e-04, 8.2064e-04, 3.0543e-04],\n",
      "        [2.8294e-03, 1.9612e-03, 2.7276e-02, 1.6406e-02, 8.5727e-01, 1.6368e-02,\n",
      "         4.8135e-02, 1.0066e-02, 1.4574e-02, 5.1188e-03],\n",
      "        [1.9116e-02, 1.4625e-03, 1.2622e-02, 1.5846e-02, 3.2425e-01, 1.1624e-01,\n",
      "         3.4010e-01, 5.5631e-02, 6.4571e-02, 5.0162e-02],\n",
      "        [9.1080e-05, 1.1693e-04, 4.0486e-03, 4.3788e-03, 1.2094e-01, 4.5218e-02,\n",
      "         4.0941e-01, 1.3746e-01, 1.5166e-01, 1.2668e-01],\n",
      "        [1.1424e-04, 1.2436e-04, 4.8604e-04, 1.2055e-03, 7.2384e-02, 2.6110e-02,\n",
      "         2.9157e-01, 1.8666e-01, 2.3569e-01, 1.8566e-01],\n",
      "        [7.1082e-05, 5.8512e-05, 1.4086e-04, 1.0376e-04, 3.2561e-03, 1.2865e-02,\n",
      "         6.9858e-02, 1.2802e-01, 4.6710e-01, 3.1853e-01]])\n",
      "\n",
      "Epoch: 11.00, Train Loss: 1.44, Val Loss: 4.42, Train BLEU: 35.38, Val BLEU: 10.17, Minutes Elapsed: 578.27\n",
      "Sampling from training predictions...\n",
      "Source: tại pittsburgh có 2 trường đại_học lớn carnegie mellon và\n",
      "Reference: and at pittsburgh there are two big universities ,\n",
      "Model: <SOS> at was pittsburgh there are two big universities at\n",
      "Attention Weights: tensor([[9.7890e-01, 2.1096e-02, 6.9717e-06, 5.0444e-08, 4.1963e-09, 6.2279e-11,\n",
      "         6.9845e-12, 4.9335e-12, 5.0417e-12, 9.0003e-13],\n",
      "        [6.0692e-02, 9.2518e-01, 1.3559e-02, 4.1144e-04, 1.4338e-04, 1.0463e-05,\n",
      "         9.8425e-07, 4.6056e-07, 2.7971e-07, 1.8558e-08],\n",
      "        [1.2437e-01, 3.6263e-01, 4.8821e-01, 1.4363e-02, 8.5684e-03, 1.5831e-03,\n",
      "         2.1250e-04, 5.4863e-05, 1.5734e-05, 9.7729e-07],\n",
      "        [3.7783e-02, 1.1347e-01, 8.1306e-01, 1.3115e-02, 1.8591e-02, 3.1311e-03,\n",
      "         5.9809e-04, 2.0992e-04, 3.3927e-05, 2.1661e-06],\n",
      "        [2.3847e-03, 5.5251e-02, 7.4955e-01, 8.6885e-02, 8.4705e-02, 1.5127e-02,\n",
      "         4.3863e-03, 1.4086e-03, 2.8711e-04, 1.1426e-05],\n",
      "        [1.4546e-04, 8.2734e-03, 1.6537e-01, 1.4751e-01, 3.9225e-01, 2.0162e-01,\n",
      "         4.8087e-02, 2.6396e-02, 9.1125e-03, 1.2418e-03],\n",
      "        [1.6835e-05, 6.1642e-04, 1.1060e-02, 9.7051e-02, 4.1522e-01, 2.5619e-01,\n",
      "         1.0769e-01, 7.5064e-02, 3.6386e-02, 6.9932e-04],\n",
      "        [1.4356e-06, 3.3678e-05, 6.1547e-04, 1.0005e-03, 2.0830e-01, 3.1133e-01,\n",
      "         1.0346e-01, 1.7607e-01, 1.9758e-01, 1.6217e-03],\n",
      "        [1.2903e-07, 2.3010e-06, 3.4533e-05, 3.7694e-05, 1.5978e-02, 6.6321e-02,\n",
      "         9.9060e-02, 2.9807e-01, 5.1200e-01, 8.4987e-03]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: khi sắp tới sinh_nhật lần thứ 3 của con gái\n",
      "Reference: approaching my daughter &apos;s third birthday , my wife\n",
      "Model: <SOS> when i to to the was my the was\n",
      "Attention Weights: tensor([[9.6110e-01, 3.8867e-02, 2.8096e-05, 9.0965e-08, 3.5401e-07, 1.5487e-08,\n",
      "         1.8494e-09, 1.2694e-10, 9.8202e-12, 2.6886e-11],\n",
      "        [2.4502e-02, 8.5884e-01, 1.1467e-01, 1.4175e-03, 4.4803e-04, 8.0433e-05,\n",
      "         3.3239e-05, 4.1793e-06, 1.8373e-06, 1.2907e-06],\n",
      "        [9.5621e-03, 4.7399e-01, 4.8982e-01, 2.4837e-02, 1.4233e-03, 2.0048e-04,\n",
      "         1.2656e-04, 2.1650e-05, 7.1696e-06, 9.9105e-06],\n",
      "        [5.3980e-03, 2.5754e-02, 7.4883e-01, 1.4136e-01, 6.9518e-02, 7.7628e-03,\n",
      "         1.1170e-03, 1.2169e-04, 6.8295e-05, 7.4856e-05],\n",
      "        [2.3187e-04, 1.6423e-03, 9.8963e-02, 4.3655e-01, 4.2715e-01, 2.3080e-02,\n",
      "         8.2672e-03, 1.1952e-03, 1.5427e-03, 1.3829e-03],\n",
      "        [1.4947e-05, 4.1237e-03, 7.6921e-03, 3.8679e-01, 4.0472e-01, 8.6044e-02,\n",
      "         9.5609e-02, 8.0451e-03, 4.0761e-03, 2.8884e-03],\n",
      "        [9.8928e-06, 2.1310e-03, 1.4903e-02, 2.7179e-01, 5.0312e-01, 1.4229e-01,\n",
      "         5.3155e-02, 6.1465e-03, 3.5540e-03, 2.8981e-03],\n",
      "        [3.1240e-06, 1.1946e-03, 2.7614e-03, 2.0422e-01, 4.0199e-01, 1.9331e-01,\n",
      "         1.4178e-01, 2.5682e-02, 2.0691e-02, 8.3632e-03],\n",
      "        [2.8853e-07, 1.9362e-04, 6.6539e-04, 8.6249e-02, 3.2418e-01, 2.3250e-01,\n",
      "         2.8191e-01, 2.7834e-02, 3.1312e-02, 1.5157e-02]])\n",
      "\n",
      "Epoch: 11.05, Train Loss: 1.21, Val Loss: 4.41, Train BLEU: 41.23, Val BLEU: 10.57, Minutes Elapsed: 580.79\n",
      "Sampling from training predictions...\n",
      "Source: chúng_ta không thấy nó trên facebook . chúng_ta không thấy\n",
      "Reference: we don &apos;t see it on facebook . we\n",
      "Model: <SOS> we don &apos;t see it on facebook . we\n",
      "Attention Weights: tensor([[7.9039e-01, 2.0882e-01, 7.8186e-04, 1.4007e-05, 1.1287e-06, 2.4510e-07,\n",
      "         6.2812e-09, 4.6165e-09, 6.0910e-08, 1.4616e-08],\n",
      "        [5.0715e-02, 9.0546e-01, 4.3300e-02, 2.9347e-04, 1.7667e-04, 2.0393e-05,\n",
      "         4.2719e-06, 3.4469e-06, 2.9196e-05, 2.8906e-06],\n",
      "        [9.0355e-02, 7.8366e-01, 1.1385e-01, 1.0567e-02, 1.2016e-03, 2.5533e-04,\n",
      "         1.6365e-05, 1.3001e-05, 5.8982e-05, 2.4254e-05],\n",
      "        [1.2053e-03, 6.4090e-03, 9.8299e-01, 8.2482e-03, 9.4358e-04, 1.8205e-04,\n",
      "         4.6971e-06, 1.8403e-06, 4.9294e-06, 1.5220e-05],\n",
      "        [5.9483e-04, 3.0731e-03, 2.3046e-01, 4.3734e-01, 2.2120e-01, 1.0634e-01,\n",
      "         4.5602e-04, 4.0254e-05, 1.7336e-04, 3.3143e-04],\n",
      "        [3.3554e-05, 5.5816e-04, 6.3970e-03, 1.0786e-01, 6.2739e-01, 2.4866e-01,\n",
      "         7.4874e-03, 4.6354e-04, 2.6836e-04, 8.8153e-04],\n",
      "        [6.6122e-06, 2.1600e-04, 2.2028e-04, 6.1532e-03, 1.4790e-01, 7.7589e-01,\n",
      "         5.4504e-02, 9.2525e-03, 2.1586e-03, 3.7027e-03],\n",
      "        [1.1067e-05, 1.5772e-04, 5.0997e-04, 1.1971e-03, 3.9151e-02, 3.5396e-01,\n",
      "         4.1302e-01, 7.7263e-02, 5.1119e-02, 6.3605e-02],\n",
      "        [4.1624e-06, 7.2820e-05, 6.1217e-05, 7.4181e-05, 8.2484e-04, 1.6588e-03,\n",
      "         2.4281e-01, 5.3547e-01, 2.0567e-01, 1.3359e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi đã yêu_cầu họ hãy gửi cho tôi chỉ một\n",
      "Reference: and i asked them once , and i asked\n",
      "Model: <SOS> i asked asked my to let me me just\n",
      "Attention Weights: tensor([[2.2454e-03, 9.3852e-01, 5.8792e-02, 2.9804e-04, 1.1959e-04, 2.0812e-05,\n",
      "         1.2347e-06, 9.1499e-08, 2.6829e-07, 7.3703e-09],\n",
      "        [1.6165e-04, 1.5001e-02, 9.8394e-01, 8.0608e-04, 6.8153e-05, 1.5603e-05,\n",
      "         1.3517e-06, 3.2950e-07, 2.7563e-06, 8.0551e-08],\n",
      "        [1.0481e-03, 3.1877e-02, 8.7732e-01, 5.4493e-02, 1.7272e-02, 1.6250e-02,\n",
      "         1.1347e-03, 9.2127e-05, 4.3940e-04, 7.3918e-05],\n",
      "        [5.4234e-04, 4.4290e-02, 8.4818e-01, 3.9821e-02, 3.6284e-02, 2.7582e-02,\n",
      "         2.3947e-03, 8.4698e-05, 7.7225e-04, 4.4649e-05],\n",
      "        [6.4217e-05, 1.3403e-04, 1.7905e-01, 1.7365e-01, 2.0765e-01, 4.0170e-01,\n",
      "         3.1280e-02, 2.3253e-03, 3.6140e-03, 5.3329e-04],\n",
      "        [6.6549e-06, 3.9743e-05, 9.5940e-03, 9.2285e-02, 3.3977e-01, 3.7032e-01,\n",
      "         1.1802e-01, 2.4903e-02, 3.8613e-02, 6.4458e-03],\n",
      "        [9.7375e-07, 2.7899e-06, 3.4134e-03, 8.5646e-03, 3.3456e-02, 2.5414e-01,\n",
      "         2.1180e-01, 1.7988e-01, 1.8544e-01, 1.2331e-01],\n",
      "        [4.7902e-06, 2.0514e-06, 3.0803e-04, 2.6120e-03, 8.3511e-03, 1.0078e-01,\n",
      "         8.2640e-02, 1.6606e-01, 2.0372e-01, 4.3552e-01],\n",
      "        [6.3533e-04, 3.1837e-03, 4.0898e-02, 4.5078e-02, 8.5198e-02, 1.1922e-01,\n",
      "         1.5830e-01, 6.2447e-02, 3.9593e-01, 8.9110e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11.10, Train Loss: 1.47, Val Loss: 4.44, Train BLEU: 33.58, Val BLEU: 10.91, Minutes Elapsed: 583.30\n",
      "Sampling from training predictions...\n",
      "Source: đây là nhà_hát kịch mà wagner đã tự xây cho\n",
      "Reference: this is the opera house that wagner built for\n",
      "Model: <SOS> this is the opera that that wagner built the\n",
      "Attention Weights: tensor([[9.8827e-01, 1.1726e-02, 8.1398e-06, 6.9938e-09, 4.7917e-10, 9.6020e-12,\n",
      "         2.3211e-12, 6.5768e-13, 3.2918e-13, 2.3194e-13],\n",
      "        [3.4736e-01, 5.9970e-01, 5.1905e-02, 1.0223e-03, 1.2913e-05, 3.5103e-06,\n",
      "         2.8628e-07, 3.2672e-07, 6.9574e-08, 3.8627e-08],\n",
      "        [5.8208e-02, 4.0859e-01, 4.2567e-01, 1.0216e-01, 3.6080e-03, 1.3762e-03,\n",
      "         8.8172e-05, 1.7897e-04, 1.0488e-04, 2.2208e-05],\n",
      "        [1.1996e-03, 2.4595e-03, 5.8024e-01, 4.0095e-01, 1.2457e-02, 2.0863e-03,\n",
      "         2.4301e-04, 2.5544e-04, 7.2462e-05, 3.4690e-05],\n",
      "        [1.8326e-04, 2.2514e-03, 4.2461e-02, 2.5907e-01, 5.7464e-01, 9.4094e-02,\n",
      "         1.0791e-02, 1.1441e-02, 4.0411e-03, 1.0327e-03],\n",
      "        [4.4570e-04, 1.8105e-02, 3.4040e-02, 1.5450e-01, 6.9454e-01, 7.9008e-02,\n",
      "         1.5597e-02, 2.4951e-03, 9.9320e-04, 2.7615e-04],\n",
      "        [3.7941e-05, 3.0599e-04, 1.3221e-03, 6.4048e-02, 1.8066e-01, 4.6939e-01,\n",
      "         1.7192e-01, 8.2471e-02, 2.4866e-02, 4.9754e-03],\n",
      "        [1.8906e-04, 3.3547e-04, 7.9489e-05, 5.5366e-04, 3.7089e-03, 1.0451e-02,\n",
      "         5.7049e-02, 2.1989e-01, 6.1193e-01, 9.5815e-02],\n",
      "        [6.3118e-05, 1.0035e-03, 7.0508e-04, 4.0878e-03, 6.9488e-03, 5.5025e-03,\n",
      "         2.0939e-02, 1.7786e-01, 5.7373e-01, 2.0916e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi đã rất tự_hào về đất_nước tôi . <EOS> <PAD>\n",
      "Reference: and i was very proud . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> i &apos;ve was so proud about my me me\n",
      "Attention Weights: tensor([[0.0186, 0.2940, 0.6875, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0032, 0.1523, 0.8432, 0.0011, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0019, 0.1290, 0.7990, 0.0616, 0.0083, 0.0002, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0017, 0.1111, 0.7645, 0.1091, 0.0133, 0.0003, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0005, 0.0008, 0.2701, 0.5373, 0.1662, 0.0246, 0.0004, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0006, 0.0005, 0.0209, 0.2137, 0.6991, 0.0559, 0.0086, 0.0006, 0.0002,\n",
      "         0.0000],\n",
      "        [0.0054, 0.0004, 0.0133, 0.2355, 0.5167, 0.2138, 0.0122, 0.0022, 0.0005,\n",
      "         0.0000],\n",
      "        [0.0016, 0.0012, 0.0181, 0.1294, 0.2067, 0.6135, 0.0270, 0.0020, 0.0005,\n",
      "         0.0000],\n",
      "        [0.0007, 0.0443, 0.5419, 0.1592, 0.1159, 0.1270, 0.0039, 0.0060, 0.0011,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 11.14, Train Loss: 1.44, Val Loss: 4.45, Train BLEU: 34.80, Val BLEU: 10.92, Minutes Elapsed: 585.77\n",
      "Sampling from training predictions...\n",
      "Source: đau kinh_niên là một ví_dụ . nếu bạn phỏng ,\n",
      "Reference: chronic pain is an example . if you burn\n",
      "Model: <SOS> chronic is is an example . if you burn\n",
      "Attention Weights: tensor([[9.7991e-01, 1.8536e-02, 1.3815e-03, 1.6730e-04, 3.7122e-07, 9.8304e-10,\n",
      "         1.4198e-10, 1.9652e-10, 9.1694e-11, 5.7053e-13],\n",
      "        [1.1133e-01, 2.9773e-01, 5.7360e-01, 1.7083e-02, 2.0956e-04, 4.0870e-05,\n",
      "         4.6260e-06, 4.6597e-07, 8.0918e-07, 1.1852e-07],\n",
      "        [4.1890e-03, 7.8389e-02, 8.3109e-01, 5.7461e-02, 2.6218e-02, 2.4624e-03,\n",
      "         1.5485e-04, 1.6573e-05, 1.7995e-05, 1.3286e-06],\n",
      "        [2.6847e-04, 1.3776e-02, 1.4777e-01, 1.4677e-01, 4.4310e-01, 2.0145e-01,\n",
      "         3.5130e-02, 3.7062e-03, 7.7292e-03, 3.0130e-04],\n",
      "        [8.6285e-05, 5.7405e-03, 6.3254e-03, 6.2667e-02, 5.2970e-01, 3.3356e-01,\n",
      "         4.2112e-02, 7.8159e-03, 1.0952e-02, 1.0391e-03],\n",
      "        [8.9460e-06, 1.1968e-04, 5.3959e-04, 1.4507e-03, 1.7488e-02, 8.0135e-01,\n",
      "         1.7166e-01, 2.7124e-03, 2.6433e-03, 2.0272e-03],\n",
      "        [5.2953e-07, 1.6725e-05, 6.5850e-05, 3.9010e-05, 1.5444e-03, 1.5490e-01,\n",
      "         8.3128e-01, 9.9134e-03, 1.1529e-03, 1.0822e-03],\n",
      "        [7.2809e-05, 3.1092e-05, 9.8366e-05, 2.5374e-03, 4.4412e-03, 1.2774e-02,\n",
      "         2.2794e-01, 7.3404e-01, 1.6553e-02, 1.5093e-03],\n",
      "        [1.2592e-05, 2.8876e-04, 4.5089e-05, 3.5225e-05, 2.2782e-04, 6.2748e-04,\n",
      "         5.9056e-03, 2.5932e-01, 7.2962e-01, 3.9252e-03]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: và bạn có_thể thấy trên đây , giống_như 10000 người\n",
      "Reference: and here you can see , like 10 thousands\n",
      "Model: <SOS> and you can see , , we for ,\n",
      "Attention Weights: tensor([[1.3406e-03, 9.6635e-01, 3.0941e-02, 1.2222e-03, 1.3004e-04, 1.5496e-05,\n",
      "         1.0146e-08, 6.3988e-08, 2.4059e-08, 1.9829e-08],\n",
      "        [5.9060e-03, 9.8926e-01, 4.7182e-03, 9.7988e-05, 7.0940e-06, 4.3553e-06,\n",
      "         4.4670e-07, 1.1198e-06, 5.9522e-08, 1.0698e-08],\n",
      "        [6.7364e-04, 1.4569e-01, 3.8416e-01, 4.4074e-01, 2.2500e-02, 3.0553e-03,\n",
      "         1.3858e-03, 1.6067e-03, 1.3211e-04, 5.4827e-05],\n",
      "        [4.2210e-05, 4.8111e-03, 5.5785e-02, 7.9581e-01, 1.1191e-01, 1.6662e-02,\n",
      "         8.8410e-03, 4.6403e-03, 1.1109e-03, 3.8588e-04],\n",
      "        [9.3154e-06, 4.2279e-03, 1.1132e-01, 3.9246e-01, 3.6506e-01, 6.1608e-02,\n",
      "         2.6075e-02, 2.9818e-02, 7.0932e-03, 2.3263e-03],\n",
      "        [1.0372e-06, 1.1969e-04, 4.7474e-04, 5.5266e-03, 1.3222e-01, 2.4574e-01,\n",
      "         2.3084e-01, 3.3883e-01, 3.3131e-02, 1.3120e-02],\n",
      "        [1.6363e-06, 5.1951e-05, 2.1343e-04, 1.4123e-03, 8.7012e-02, 1.1360e-01,\n",
      "         1.0948e-01, 6.4350e-01, 2.8394e-02, 1.6335e-02],\n",
      "        [2.2673e-07, 2.0036e-05, 4.0118e-04, 6.0101e-04, 2.8889e-03, 1.1902e-02,\n",
      "         1.1983e-01, 7.9442e-01, 4.1274e-02, 2.8668e-02],\n",
      "        [4.1935e-06, 1.5434e-05, 3.0586e-04, 2.3144e-03, 2.2006e-03, 3.8331e-03,\n",
      "         4.1896e-02, 4.8819e-01, 2.0914e-01, 2.5210e-01]])\n",
      "\n",
      "Epoch: 11.19, Train Loss: 1.68, Val Loss: 4.48, Train BLEU: 28.50, Val BLEU: 10.06, Minutes Elapsed: 588.26\n",
      "Sampling from training predictions...\n",
      "Source: như một đứa trẻ 12 tuổi nói sau khi xem\n",
      "Reference: as one 12-year-old said after watching &quot; wizard of\n",
      "Model: <SOS> as a 12-year-old 12 ago when watch the watching\n",
      "Attention Weights: tensor([[9.5625e-01, 4.0409e-02, 2.8431e-03, 3.3450e-04, 1.3219e-04, 3.0751e-05,\n",
      "         8.0513e-07, 3.4216e-07, 5.4520e-09, 5.9182e-10],\n",
      "        [9.0757e-02, 2.6547e-01, 5.1604e-01, 9.8703e-02, 2.2513e-02, 6.3977e-03,\n",
      "         9.1193e-05, 8.1237e-06, 1.0220e-06, 1.2808e-05],\n",
      "        [8.1488e-03, 4.8046e-03, 6.4523e-01, 2.0057e-01, 6.6512e-02, 6.3632e-02,\n",
      "         9.0053e-03, 1.3426e-03, 1.2694e-04, 6.2971e-04],\n",
      "        [1.6830e-03, 1.0297e-03, 5.1524e-02, 2.3990e-01, 1.2706e-01, 3.7976e-01,\n",
      "         1.4338e-01, 4.6971e-02, 4.4614e-03, 4.2339e-03],\n",
      "        [2.2366e-06, 5.3321e-06, 2.8034e-04, 9.4833e-04, 1.1243e-02, 1.0477e-01,\n",
      "         4.3111e-01, 2.9918e-01, 5.7666e-02, 9.4792e-02],\n",
      "        [6.6275e-06, 1.0450e-05, 2.1627e-05, 4.1995e-05, 7.1714e-05, 2.5739e-03,\n",
      "         9.2069e-02, 5.1991e-01, 1.8786e-01, 1.9743e-01],\n",
      "        [1.4520e-06, 8.7219e-06, 3.3169e-05, 1.5774e-04, 3.3783e-04, 1.8597e-03,\n",
      "         1.1134e-02, 8.0241e-02, 1.3617e-01, 7.7006e-01],\n",
      "        [1.0723e-07, 4.8038e-08, 1.2867e-07, 6.6129e-06, 1.5410e-05, 1.9482e-04,\n",
      "         2.8597e-03, 1.6372e-02, 3.0498e-02, 9.5005e-01],\n",
      "        [8.3196e-07, 1.3884e-06, 1.5726e-06, 1.6397e-05, 7.2973e-05, 1.2577e-03,\n",
      "         4.6335e-03, 1.8818e-02, 6.4106e-02, 9.1109e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: đó là đức_tin của tôi , khi tôi nói với\n",
      "Reference: it &apos;s my gospel , when i &apos;m telling\n",
      "Model: <SOS> that that my job , when i talk to\n",
      "Attention Weights: tensor([[9.4546e-01, 5.4200e-02, 3.3102e-04, 1.0270e-05, 3.5659e-06, 1.5183e-09,\n",
      "         2.4487e-09, 6.2199e-10, 8.2588e-10, 1.6294e-09],\n",
      "        [4.7612e-02, 8.2258e-01, 1.2749e-01, 6.4158e-04, 6.9227e-04, 6.5587e-04,\n",
      "         2.3288e-04, 4.7243e-05, 2.8382e-05, 2.1990e-05],\n",
      "        [5.4145e-02, 4.3040e-01, 4.9223e-01, 3.8502e-03, 1.0910e-02, 5.3210e-03,\n",
      "         1.6509e-03, 1.7836e-04, 7.7627e-04, 5.3265e-04],\n",
      "        [1.9502e-04, 2.9622e-03, 8.3104e-01, 3.8473e-03, 1.8576e-02, 6.8059e-02,\n",
      "         6.8766e-02, 8.5611e-04, 2.6099e-03, 3.0830e-03],\n",
      "        [1.7550e-04, 3.8167e-03, 1.4111e-02, 2.4216e-03, 1.6466e-02, 5.4454e-01,\n",
      "         3.7855e-01, 4.5236e-03, 3.1617e-02, 3.7801e-03],\n",
      "        [7.3020e-06, 8.2381e-05, 5.3459e-04, 1.7202e-04, 1.4632e-03, 8.9636e-02,\n",
      "         8.6955e-01, 2.1073e-02, 1.4807e-02, 2.6790e-03],\n",
      "        [2.5402e-06, 7.7001e-05, 8.8276e-04, 1.3207e-04, 1.4136e-04, 9.4569e-03,\n",
      "         7.0152e-01, 1.8542e-01, 8.9124e-02, 1.3244e-02],\n",
      "        [6.3483e-06, 2.6899e-04, 6.1871e-04, 6.4797e-05, 3.6396e-05, 6.8388e-03,\n",
      "         3.7713e-02, 7.9091e-02, 7.2886e-01, 1.4650e-01],\n",
      "        [1.0632e-06, 1.2259e-05, 5.5915e-04, 1.0330e-05, 7.7089e-05, 7.6856e-03,\n",
      "         6.8727e-03, 8.9807e-03, 5.3309e-01, 4.4272e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11.24, Train Loss: 1.66, Val Loss: 4.45, Train BLEU: 29.05, Val BLEU: 10.30, Minutes Elapsed: 590.78\n",
      "Sampling from training predictions...\n",
      "Source: ngay sau khi bạn giành chiến_thắng , đột_nhiên ngừng lại\n",
      "Reference: as soon as you win , suddenly stop .\n",
      "Model: <SOS> as soon as you win to , of stop\n",
      "Attention Weights: tensor([[9.4746e-01, 5.2394e-02, 1.4335e-04, 8.3565e-07, 8.3881e-08, 1.4291e-07,\n",
      "         2.6894e-08, 9.5454e-09, 3.2147e-10, 2.5868e-10],\n",
      "        [8.3962e-01, 1.4290e-01, 1.0241e-02, 4.6285e-03, 2.1019e-03, 4.6259e-04,\n",
      "         2.1128e-05, 2.5516e-05, 3.5502e-06, 8.8230e-07],\n",
      "        [1.5040e-01, 2.5145e-01, 2.1113e-01, 1.0865e-01, 2.2136e-01, 5.1228e-02,\n",
      "         2.4215e-03, 2.3875e-03, 7.2666e-04, 2.5054e-04],\n",
      "        [6.7363e-03, 4.8692e-02, 1.2353e-01, 2.1685e-01, 4.1595e-01, 1.7644e-01,\n",
      "         6.0033e-03, 3.7384e-03, 1.6740e-03, 3.7730e-04],\n",
      "        [3.9261e-04, 2.0003e-03, 4.5943e-03, 2.9222e-02, 4.0329e-01, 5.5434e-01,\n",
      "         2.8492e-03, 9.4797e-04, 1.2941e-03, 1.0685e-03],\n",
      "        [6.9293e-04, 2.4570e-03, 6.5163e-03, 2.4009e-02, 3.9973e-01, 5.5081e-01,\n",
      "         1.2147e-02, 9.4709e-04, 1.3281e-03, 1.3721e-03],\n",
      "        [6.5580e-04, 1.6855e-03, 6.8877e-03, 2.1003e-03, 4.8064e-02, 5.9792e-01,\n",
      "         3.1008e-01, 2.5095e-02, 2.4703e-03, 5.0482e-03],\n",
      "        [5.5829e-05, 2.2543e-04, 2.1980e-03, 5.0161e-03, 3.2152e-03, 4.3760e-03,\n",
      "         2.3775e-02, 9.3370e-01, 2.5681e-02, 1.7573e-03],\n",
      "        [8.1029e-05, 7.6555e-04, 1.8330e-03, 1.4197e-02, 3.4022e-02, 1.8070e-02,\n",
      "         9.4172e-03, 9.5064e-02, 6.4270e-01, 1.8385e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: vì_vậy với sự giúp_đỡ của những người bạn cũ và\n",
      "Reference: so with help from old and new friends ,\n",
      "Model: <SOS> so with help help people and and friends and\n",
      "Attention Weights: tensor([[7.7937e-01, 2.2015e-01, 3.9030e-04, 7.6963e-05, 1.6408e-05, 1.1720e-08,\n",
      "         1.6928e-08, 1.1288e-09, 1.4422e-09, 3.4237e-10],\n",
      "        [3.1998e-03, 7.9283e-01, 7.4427e-02, 1.1646e-01, 8.3581e-03, 3.2345e-03,\n",
      "         1.4413e-03, 2.4536e-05, 1.7517e-05, 1.8536e-06],\n",
      "        [2.9858e-03, 2.0384e-02, 1.0321e-01, 7.6963e-01, 5.8628e-02, 2.6443e-02,\n",
      "         1.6858e-02, 5.7003e-04, 1.1099e-03, 1.8190e-04],\n",
      "        [2.5022e-02, 1.4110e-01, 3.7545e-02, 5.2171e-01, 1.5055e-01, 4.3569e-02,\n",
      "         5.3971e-02, 6.3347e-03, 1.9886e-02, 3.1392e-04],\n",
      "        [2.7855e-05, 1.1352e-04, 1.1331e-02, 9.1568e-02, 4.5512e-02, 1.0619e-01,\n",
      "         1.5733e-01, 6.5745e-02, 5.0928e-01, 1.2906e-02],\n",
      "        [3.4984e-06, 2.2306e-05, 1.0224e-03, 9.8584e-02, 1.0833e-02, 2.6080e-02,\n",
      "         2.0752e-01, 6.8780e-02, 5.2351e-01, 6.3638e-02],\n",
      "        [5.1765e-05, 7.5914e-05, 1.9789e-04, 5.2688e-03, 3.3415e-03, 2.3851e-02,\n",
      "         6.7193e-02, 1.0552e-01, 5.9474e-01, 1.9977e-01],\n",
      "        [2.8732e-05, 2.4797e-04, 2.4837e-04, 6.3669e-03, 1.9485e-03, 3.8995e-03,\n",
      "         5.7665e-02, 1.3182e-01, 5.2581e-01, 2.7197e-01],\n",
      "        [1.5347e-03, 2.7621e-03, 2.1316e-03, 4.9517e-02, 3.1304e-03, 6.2723e-03,\n",
      "         1.9586e-02, 7.4564e-02, 7.1441e-01, 1.2609e-01]])\n",
      "\n",
      "Epoch: 11.29, Train Loss: 1.70, Val Loss: 4.48, Train BLEU: 27.66, Val BLEU: 10.17, Minutes Elapsed: 593.30\n",
      "Sampling from training predictions...\n",
      "Source: và tại một thời_điểm - - và lúc đó tôi\n",
      "Reference: and at one point -- and i had some\n",
      "Model: <SOS> and at one point -- and i had some\n",
      "Attention Weights: tensor([[1.4385e-05, 9.9912e-01, 7.5049e-04, 1.1107e-04, 9.9439e-08, 2.7034e-08,\n",
      "         1.2163e-09, 1.5173e-09, 9.1022e-11, 9.1890e-12],\n",
      "        [4.9297e-04, 9.8648e-01, 1.2801e-02, 2.2563e-04, 1.0642e-06, 3.4760e-07,\n",
      "         3.4520e-08, 4.8558e-08, 1.1394e-08, 2.2932e-09],\n",
      "        [7.5195e-04, 3.3381e-01, 3.8342e-01, 2.7656e-01, 4.0465e-03, 1.1558e-03,\n",
      "         1.7134e-04, 6.2188e-05, 1.4756e-05, 8.8379e-06],\n",
      "        [2.1202e-05, 1.9787e-02, 2.1040e-02, 9.1284e-01, 3.2970e-02, 1.2131e-02,\n",
      "         6.7052e-04, 4.2215e-04, 8.0530e-05, 4.1841e-05],\n",
      "        [5.5390e-05, 1.2010e-03, 7.6689e-03, 4.8142e-01, 2.5394e-01, 1.9249e-01,\n",
      "         6.1834e-02, 1.2636e-03, 7.6852e-05, 5.1869e-05],\n",
      "        [6.2809e-06, 6.2669e-05, 4.0887e-04, 1.1893e-03, 6.0278e-03, 2.2395e-01,\n",
      "         7.2133e-01, 4.6347e-02, 4.8366e-04, 2.0160e-04],\n",
      "        [1.2174e-04, 3.5471e-03, 3.4658e-03, 5.8928e-04, 2.3617e-03, 3.9890e-02,\n",
      "         3.0621e-01, 6.2004e-01, 1.7233e-02, 6.5348e-03],\n",
      "        [1.7071e-05, 1.3043e-02, 1.4740e-02, 1.3922e-01, 8.7722e-03, 2.2536e-02,\n",
      "         3.7032e-02, 4.2008e-01, 2.0087e-01, 1.4370e-01],\n",
      "        [3.6240e-05, 4.6961e-03, 1.2647e-02, 1.5790e-01, 1.3008e-02, 2.6883e-02,\n",
      "         1.8013e-02, 1.8292e-01, 1.8786e-01, 3.9604e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: hãy giơ chiếc điện_thoại của bạn lên , hãy giơ\n",
      "Reference: hold your phones up , hold your phones up\n",
      "Model: <SOS> so your your to , , your , ,\n",
      "Attention Weights: tensor([[9.4387e-04, 9.8561e-01, 1.3149e-02, 2.9191e-04, 1.6208e-06, 4.1814e-07,\n",
      "         1.2386e-07, 7.7769e-10, 1.8574e-10, 7.3251e-09],\n",
      "        [2.2825e-04, 6.3151e-01, 3.1495e-01, 5.1495e-02, 2.6144e-04, 3.3708e-04,\n",
      "         1.1445e-03, 3.6157e-05, 7.5525e-06, 2.9420e-05],\n",
      "        [2.9744e-03, 2.7961e-01, 3.0805e-01, 3.7977e-01, 1.2799e-02, 4.1623e-03,\n",
      "         1.0920e-02, 7.8125e-04, 1.7647e-04, 7.5115e-04],\n",
      "        [3.7011e-05, 1.6055e-03, 1.2891e-01, 3.9906e-01, 4.7105e-02, 1.2069e-01,\n",
      "         2.4877e-01, 4.5856e-02, 4.9882e-03, 2.9778e-03],\n",
      "        [1.8695e-06, 4.5527e-04, 2.9148e-02, 9.8266e-02, 1.6817e-02, 7.2910e-02,\n",
      "         2.2850e-01, 2.7216e-01, 2.0856e-01, 7.3185e-02],\n",
      "        [1.7466e-06, 4.6038e-04, 5.2416e-03, 9.8901e-02, 1.2356e-02, 8.8486e-02,\n",
      "         1.1338e-01, 1.0271e-01, 3.1718e-01, 2.6128e-01],\n",
      "        [1.4309e-06, 3.3565e-04, 5.3788e-03, 1.5058e-01, 1.4926e-02, 2.7504e-02,\n",
      "         3.5844e-02, 7.2808e-02, 3.7584e-01, 3.1679e-01],\n",
      "        [4.7470e-05, 2.9075e-03, 1.3452e-02, 7.5653e-02, 7.8570e-03, 3.8115e-02,\n",
      "         4.5237e-02, 6.5159e-02, 1.0075e-01, 6.5082e-01],\n",
      "        [5.4409e-07, 1.3326e-04, 3.1504e-03, 4.3880e-02, 5.3525e-03, 5.2662e-02,\n",
      "         5.2119e-02, 2.8631e-01, 3.2210e-01, 2.3429e-01]])\n",
      "\n",
      "Epoch: 11.34, Train Loss: 1.76, Val Loss: 4.45, Train BLEU: 26.27, Val BLEU: 10.34, Minutes Elapsed: 595.79\n",
      "Sampling from training predictions...\n",
      "Source: khi_ấy tôi bị bỏng nặng . <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: i was burned very badly . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> my was burned in the . <EOS> was <UNK>\n",
      "Attention Weights: tensor([[0.9999, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.9558, 0.0207, 0.0218, 0.0017, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0311, 0.0057, 0.6598, 0.2635, 0.0392, 0.0007, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0122, 0.0008, 0.0536, 0.5818, 0.3468, 0.0042, 0.0006, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0264, 0.0029, 0.0091, 0.4011, 0.4214, 0.0993, 0.0398, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1017, 0.0180, 0.0444, 0.1101, 0.3328, 0.1411, 0.2518, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0208, 0.0086, 0.0279, 0.0483, 0.2480, 0.1144, 0.5320, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0496, 0.0520, 0.2862, 0.1525, 0.0962, 0.0503, 0.3132, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1179, 0.0514, 0.5846, 0.1690, 0.0542, 0.0077, 0.0152, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: điều mà tôi đã làm là trồng một rừng thực_phẩm\n",
      "Reference: so what i did , i planted a food\n",
      "Model: <SOS> what what i &apos;ve done was a a a\n",
      "Attention Weights: tensor([[9.9892e-01, 1.0374e-03, 6.4071e-06, 2.7394e-05, 1.3120e-05, 2.0739e-08,\n",
      "         8.3053e-10, 1.3809e-10, 5.7533e-11, 3.6776e-11],\n",
      "        [4.3023e-02, 5.5615e-01, 3.6958e-01, 2.9821e-02, 1.3001e-03, 8.2301e-05,\n",
      "         3.3018e-05, 4.6016e-06, 3.2849e-06, 2.8875e-06],\n",
      "        [7.6513e-03, 2.8017e-01, 1.4443e-01, 3.9742e-01, 1.5911e-01, 8.4562e-03,\n",
      "         2.4403e-03, 1.8874e-04, 9.6877e-05, 4.4149e-05],\n",
      "        [2.2726e-03, 5.3894e-02, 2.5681e-02, 4.3140e-01, 4.0515e-01, 7.2002e-02,\n",
      "         8.8612e-03, 2.7483e-04, 3.4619e-04, 1.1198e-04],\n",
      "        [1.3878e-04, 1.3788e-03, 2.3228e-03, 3.4258e-01, 5.6755e-01, 7.6243e-02,\n",
      "         9.1332e-03, 2.5943e-04, 3.3703e-04, 6.2017e-05],\n",
      "        [3.0166e-06, 3.8895e-06, 1.8785e-05, 3.2522e-04, 2.3673e-02, 4.1111e-01,\n",
      "         5.1287e-01, 3.4254e-02, 1.5254e-02, 2.4899e-03],\n",
      "        [4.4401e-05, 1.3680e-04, 2.4055e-04, 1.5792e-03, 5.1044e-02, 4.2481e-01,\n",
      "         4.6091e-01, 2.1134e-02, 3.3468e-02, 6.6300e-03],\n",
      "        [3.1893e-03, 1.9700e-02, 1.6698e-02, 4.4767e-02, 2.4933e-01, 1.3321e-01,\n",
      "         3.4836e-01, 2.7057e-02, 1.3662e-01, 2.1059e-02],\n",
      "        [7.3749e-06, 9.4136e-05, 2.0868e-05, 2.1486e-05, 2.0120e-03, 2.8830e-01,\n",
      "         5.2935e-01, 3.0651e-02, 1.2912e-01, 2.0431e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11.38, Train Loss: 1.77, Val Loss: 4.46, Train BLEU: 26.77, Val BLEU: 10.33, Minutes Elapsed: 598.30\n",
      "Sampling from training predictions...\n",
      "Source: đó là cả một cộng_đồng lớn , lớn đến_nỗi trên\n",
      "Reference: it &apos;s a big community . it &apos;s such\n",
      "Model: <SOS> it &apos;s a big community , it &apos;s a\n",
      "Attention Weights: tensor([[7.3922e-01, 2.3687e-01, 2.1217e-02, 2.6815e-03, 5.1065e-06, 6.4509e-06,\n",
      "         4.7166e-09, 6.7794e-09, 4.9451e-09, 1.3061e-09],\n",
      "        [4.5220e-03, 6.4462e-01, 3.0003e-01, 4.3572e-02, 6.4228e-03, 7.4522e-04,\n",
      "         5.8551e-05, 2.2730e-05, 7.1071e-06, 2.7605e-06],\n",
      "        [7.3676e-03, 2.3865e-01, 5.6943e-01, 8.3064e-02, 6.5585e-02, 3.0755e-02,\n",
      "         4.1684e-03, 4.7597e-04, 3.2448e-04, 1.8136e-04],\n",
      "        [4.5101e-05, 3.1669e-03, 9.8759e-02, 7.0474e-02, 6.9402e-01, 1.2771e-01,\n",
      "         4.8320e-03, 6.1261e-04, 1.8503e-04, 2.0109e-04],\n",
      "        [5.0979e-05, 1.5924e-03, 9.7217e-02, 5.7521e-02, 7.1574e-01, 8.7593e-02,\n",
      "         2.8952e-02, 8.6296e-03, 1.9593e-03, 7.4940e-04],\n",
      "        [1.3206e-04, 1.2444e-03, 6.1623e-03, 4.3342e-02, 1.8372e-01, 2.3724e-01,\n",
      "         3.0065e-01, 2.0861e-01, 1.0459e-02, 8.4431e-03],\n",
      "        [4.9039e-06, 5.0661e-05, 6.0192e-04, 3.0897e-03, 2.4069e-02, 2.3225e-02,\n",
      "         1.4580e-01, 6.9811e-01, 8.1945e-02, 2.3102e-02],\n",
      "        [7.6554e-06, 4.1066e-05, 3.3742e-04, 5.9859e-03, 3.6943e-02, 1.2606e-02,\n",
      "         4.5599e-02, 5.3420e-01, 2.5755e-01, 1.0673e-01],\n",
      "        [5.5921e-05, 1.0651e-03, 3.0847e-03, 6.8035e-03, 4.7898e-02, 2.0970e-02,\n",
      "         3.2618e-02, 1.0002e-01, 5.2947e-01, 2.5801e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: chúng_tôi có_thể thực_hiện tuyển_dụng nhân_sự hàng_loạt với chi_phí thấp để\n",
      "Reference: we can perform low-cost mass recruitment for clinical trials\n",
      "Model: <SOS> we can do it way to the the .\n",
      "Attention Weights: tensor([[5.9189e-01, 3.7375e-01, 3.3706e-02, 4.2257e-04, 2.2440e-04, 5.7470e-06,\n",
      "         7.6782e-07, 1.1787e-07, 1.7573e-07, 3.2955e-07],\n",
      "        [2.2736e-01, 2.6085e-01, 4.9627e-01, 1.3148e-02, 2.2865e-03, 7.4346e-05,\n",
      "         5.6954e-06, 2.9534e-06, 1.3720e-06, 3.0099e-07],\n",
      "        [2.4547e-02, 6.5218e-02, 5.9018e-01, 2.8191e-01, 3.0840e-02, 6.1038e-03,\n",
      "         8.7318e-04, 2.6572e-04, 3.8280e-05, 1.8016e-05],\n",
      "        [5.8700e-04, 1.1829e-03, 1.1948e-01, 3.6728e-01, 2.9870e-01, 1.9554e-01,\n",
      "         1.1422e-02, 5.2136e-03, 5.4065e-04, 5.9647e-05],\n",
      "        [6.6271e-04, 4.6138e-04, 7.1790e-03, 2.0642e-01, 2.7507e-01, 3.2027e-01,\n",
      "         1.2207e-01, 6.0339e-02, 6.8076e-03, 7.2924e-04],\n",
      "        [5.8544e-05, 7.1938e-05, 2.4351e-04, 9.7230e-03, 9.8680e-02, 2.4142e-01,\n",
      "         4.5906e-01, 1.2476e-01, 4.5041e-02, 2.0949e-02],\n",
      "        [6.6814e-05, 7.1434e-05, 1.1494e-04, 2.5821e-03, 3.7180e-02, 1.9287e-01,\n",
      "         3.8101e-01, 2.7025e-01, 8.0041e-02, 3.5816e-02],\n",
      "        [1.2937e-04, 3.2438e-04, 6.8180e-04, 6.1440e-04, 2.4123e-02, 1.6830e-01,\n",
      "         2.1938e-01, 3.6368e-01, 1.3975e-01, 8.3011e-02],\n",
      "        [7.3445e-04, 5.7793e-03, 1.1837e-03, 3.7917e-03, 2.6453e-02, 5.2852e-02,\n",
      "         6.4768e-02, 2.1313e-01, 1.5493e-01, 4.7638e-01]])\n",
      "\n",
      "Epoch: 11.43, Train Loss: 1.83, Val Loss: 4.43, Train BLEU: 25.43, Val BLEU: 10.78, Minutes Elapsed: 600.83\n",
      "Sampling from training predictions...\n",
      "Source: bé nhìn vào chúng_tôi . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: he was looking at us . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> he look at at us . <EOS> <EOS> us\n",
      "Attention Weights: tensor([[0.8932, 0.1015, 0.0053, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0010, 0.9710, 0.0279, 0.0001, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0058, 0.9416, 0.0516, 0.0007, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0046, 0.2314, 0.6706, 0.0686, 0.0207, 0.0043, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0024, 0.3700, 0.4610, 0.0937, 0.0607, 0.0123, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0701, 0.0406, 0.1520, 0.4909, 0.2465, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0062, 0.0040, 0.0223, 0.0967, 0.8708, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0005, 0.0642, 0.0467, 0.0192, 0.3089, 0.5605, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0090, 0.4950, 0.2507, 0.0143, 0.1264, 0.1046, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: hôm_nay tôi chỉ có một yêu_cầu mà thôi . <EOS>\n",
      "Reference: today i have just one request . <EOS> <PAD>\n",
      "Model: <SOS> i i i only a . . <EOS> .\n",
      "Attention Weights: tensor([[9.8776e-01, 8.2368e-03, 3.6663e-03, 3.1471e-04, 7.2989e-06, 1.2190e-05,\n",
      "         1.1728e-07, 8.3994e-08, 6.4115e-09, 7.6099e-10],\n",
      "        [2.6621e-03, 2.6188e-02, 9.6638e-01, 3.9437e-03, 6.5168e-04, 1.6172e-04,\n",
      "         3.5720e-06, 1.2034e-05, 1.3921e-06, 4.3408e-07],\n",
      "        [1.0075e-02, 3.2266e-02, 5.6165e-01, 3.5487e-01, 3.0798e-02, 9.0199e-03,\n",
      "         4.6452e-04, 7.6654e-04, 6.6566e-05, 2.0433e-05],\n",
      "        [7.6943e-03, 1.2215e-02, 8.5439e-01, 1.0620e-01, 1.3454e-02, 5.1726e-03,\n",
      "         2.4584e-04, 5.7793e-04, 3.4634e-05, 8.4476e-06],\n",
      "        [5.6413e-04, 4.9916e-04, 9.9700e-03, 1.7023e-01, 2.0262e-01, 5.3359e-01,\n",
      "         3.3834e-02, 4.7533e-02, 9.9173e-04, 1.6945e-04],\n",
      "        [1.5106e-05, 4.1019e-05, 4.1832e-05, 1.5420e-02, 1.8345e-02, 6.0553e-01,\n",
      "         2.1916e-01, 1.2475e-01, 1.3501e-02, 3.1973e-03],\n",
      "        [1.5765e-05, 1.2915e-03, 5.6722e-05, 1.2207e-03, 4.9270e-03, 1.5257e-01,\n",
      "         5.0324e-01, 1.8567e-01, 1.0690e-01, 4.4113e-02],\n",
      "        [5.6104e-05, 8.7750e-04, 4.7490e-05, 1.9534e-04, 5.0373e-04, 7.8696e-03,\n",
      "         1.4676e-01, 4.5039e-01, 2.0806e-01, 1.8524e-01],\n",
      "        [5.2508e-05, 5.7594e-04, 5.6981e-04, 3.0663e-03, 4.5118e-03, 2.2208e-02,\n",
      "         3.3384e-02, 1.7905e-01, 3.2297e-01, 4.3361e-01]])\n",
      "\n",
      "Epoch: 11.48, Train Loss: 1.85, Val Loss: 4.43, Train BLEU: 25.52, Val BLEU: 10.96, Minutes Elapsed: 603.34\n",
      "Sampling from training predictions...\n",
      "Source: và tôi cố sống giấc_mơ của tôi - - nhưng\n",
      "Reference: and i try to live my dream -- well\n",
      "Model: <SOS> and i was my sign my dreams -- but\n",
      "Attention Weights: tensor([[6.3344e-05, 3.7350e-03, 9.5739e-01, 3.8807e-02, 5.3909e-07, 1.4066e-06,\n",
      "         1.5023e-06, 1.9535e-08, 8.8859e-09, 1.2645e-08],\n",
      "        [5.1219e-05, 2.9241e-02, 9.5822e-01, 1.2435e-02, 5.2744e-05, 3.4670e-07,\n",
      "         1.4769e-07, 2.5935e-08, 2.2400e-08, 8.3779e-08],\n",
      "        [5.3684e-07, 1.2805e-03, 8.3439e-01, 1.5779e-01, 6.4799e-03, 3.1596e-05,\n",
      "         1.8119e-05, 5.5497e-06, 1.5663e-06, 3.2784e-06],\n",
      "        [4.3214e-06, 4.3168e-04, 1.6070e-01, 7.2829e-01, 1.0751e-01, 2.1351e-03,\n",
      "         5.9944e-04, 2.6306e-04, 3.8518e-05, 2.9739e-05],\n",
      "        [1.8723e-06, 3.4004e-05, 2.3977e-04, 3.2566e-01, 6.5443e-01, 8.7458e-03,\n",
      "         7.5541e-03, 1.6733e-03, 7.4072e-04, 9.1650e-04],\n",
      "        [3.3099e-06, 3.4457e-05, 8.8535e-05, 7.5433e-02, 5.1551e-01, 1.8884e-01,\n",
      "         1.1161e-01, 6.2601e-02, 2.6147e-02, 1.9736e-02],\n",
      "        [6.5023e-06, 1.2746e-04, 4.3082e-05, 1.8359e-02, 5.4695e-01, 9.9969e-02,\n",
      "         1.1839e-01, 5.1079e-02, 3.7626e-02, 1.2745e-01],\n",
      "        [1.8928e-07, 3.4387e-06, 8.1732e-06, 1.5157e-04, 2.1534e-04, 9.8342e-04,\n",
      "         8.8624e-03, 5.9859e-02, 2.6852e-01, 6.6140e-01],\n",
      "        [4.3363e-06, 4.7141e-04, 1.1338e-04, 2.1025e-03, 4.1066e-03, 2.7274e-03,\n",
      "         3.6723e-02, 9.8094e-02, 2.1716e-01, 6.3850e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: và khi trình_bày , đừng sử_dụng những <UNK> . <EOS>\n",
      "Reference: and when presenting your work , drop the bullet\n",
      "Model: <SOS> and the the finished , , don &apos;t .\n",
      "Attention Weights: tensor([[7.5508e-04, 9.9156e-01, 7.6647e-03, 1.6744e-05, 6.7944e-07, 2.8137e-08,\n",
      "         2.5598e-09, 7.7683e-10, 7.9528e-09, 5.5584e-10],\n",
      "        [4.7524e-05, 9.7877e-02, 9.0150e-01, 2.8753e-04, 2.7099e-04, 1.0765e-05,\n",
      "         6.5652e-07, 3.2891e-07, 8.4994e-07, 2.1246e-07],\n",
      "        [2.6729e-05, 3.1668e-03, 9.8340e-01, 9.9306e-03, 2.9720e-03, 3.2980e-04,\n",
      "         1.2629e-04, 3.4367e-05, 1.0738e-05, 4.7943e-06],\n",
      "        [2.3818e-05, 9.5567e-04, 7.2993e-01, 7.3372e-02, 1.8446e-01, 6.2025e-03,\n",
      "         2.5730e-03, 1.9950e-03, 3.4976e-04, 1.3733e-04],\n",
      "        [2.3734e-05, 2.1116e-03, 6.5807e-01, 6.9719e-02, 2.1982e-01, 2.4951e-02,\n",
      "         1.3163e-02, 8.7794e-03, 2.5542e-03, 8.0714e-04],\n",
      "        [8.8996e-08, 3.4282e-06, 5.3078e-02, 3.9115e-02, 7.7514e-01, 5.7568e-02,\n",
      "         4.6451e-02, 1.1464e-02, 1.0474e-02, 6.7089e-03],\n",
      "        [5.7044e-07, 4.6490e-05, 1.2788e-02, 7.9062e-03, 7.6692e-01, 1.5005e-01,\n",
      "         3.5731e-02, 1.2724e-02, 8.5764e-03, 5.2598e-03],\n",
      "        [2.7231e-07, 9.9481e-06, 3.8191e-02, 2.0861e-03, 2.6069e-01, 3.5672e-01,\n",
      "         2.3516e-01, 6.2687e-02, 2.8905e-02, 1.5557e-02],\n",
      "        [1.5771e-05, 6.7787e-05, 5.2675e-02, 3.0540e-03, 8.0457e-02, 2.1453e-01,\n",
      "         4.6595e-01, 7.6660e-02, 5.2248e-02, 5.4340e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11.53, Train Loss: 1.78, Val Loss: 4.45, Train BLEU: 25.71, Val BLEU: 10.32, Minutes Elapsed: 605.83\n",
      "Sampling from training predictions...\n",
      "Source: và 1 trong số các bài_học thú_vị nhất tôi đã\n",
      "Reference: and one of the most interesting lessons i learned\n",
      "Model: <SOS> and one of the most interesting i i &apos;ve\n",
      "Attention Weights: tensor([[8.7859e-03, 9.8905e-01, 1.3687e-03, 7.6167e-04, 1.6523e-05, 1.7576e-05,\n",
      "         1.4440e-06, 8.3387e-09, 5.7169e-10, 2.7946e-10],\n",
      "        [5.6909e-03, 8.7386e-01, 1.1615e-01, 3.1098e-03, 8.7239e-04, 1.6307e-04,\n",
      "         1.2975e-04, 2.1046e-05, 3.6059e-07, 2.4566e-07],\n",
      "        [1.2646e-04, 2.3877e-02, 8.5869e-01, 9.6920e-02, 8.9130e-03, 5.2590e-03,\n",
      "         5.5007e-03, 6.7882e-04, 1.4735e-05, 2.2012e-05],\n",
      "        [4.8057e-04, 8.0254e-02, 6.0903e-01, 1.5328e-01, 5.5917e-02, 7.0156e-02,\n",
      "         2.4551e-02, 5.9520e-03, 1.3680e-04, 2.4441e-04],\n",
      "        [5.9003e-07, 7.9372e-05, 4.1438e-02, 2.3171e-02, 8.9963e-02, 3.5342e-01,\n",
      "         3.8936e-01, 9.6560e-02, 2.7133e-03, 3.3029e-03],\n",
      "        [1.3637e-05, 3.2780e-05, 1.1185e-02, 2.8476e-03, 5.3513e-02, 7.2937e-01,\n",
      "         1.1701e-01, 5.8063e-02, 5.9839e-03, 2.1977e-02],\n",
      "        [1.8700e-04, 1.4300e-04, 1.8485e-03, 5.7282e-04, 1.7425e-02, 3.6697e-01,\n",
      "         6.2653e-02, 3.0432e-01, 7.3149e-02, 1.7273e-01],\n",
      "        [1.7722e-05, 2.6473e-05, 8.0304e-04, 1.6525e-04, 3.3871e-03, 6.9205e-02,\n",
      "         3.3449e-02, 1.7773e-01, 1.6842e-01, 5.4679e-01],\n",
      "        [3.8538e-08, 7.5611e-07, 3.7574e-05, 1.3004e-05, 4.2637e-04, 1.3377e-02,\n",
      "         2.6984e-02, 1.4690e-01, 8.6087e-02, 7.2617e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: bạn muốn đọc cuốn sách nào đó , hãy đọc\n",
      "Reference: you want to read the book , read &quot;\n",
      "Model: <SOS> you want to read read read read read read\n",
      "Attention Weights: tensor([[6.4129e-02, 9.1772e-01, 1.8091e-02, 1.3013e-05, 3.7932e-05, 8.1788e-06,\n",
      "         8.8226e-07, 3.2544e-09, 9.7418e-09, 1.7378e-08],\n",
      "        [2.0462e-03, 9.8493e-01, 1.1827e-02, 6.9228e-04, 3.9212e-04, 1.0040e-04,\n",
      "         7.1547e-06, 2.4587e-06, 2.5510e-06, 3.9336e-06],\n",
      "        [3.9713e-03, 8.4304e-01, 1.3845e-01, 1.1098e-02, 2.3627e-03, 9.4092e-04,\n",
      "         1.0326e-04, 1.4900e-05, 3.5011e-06, 1.0357e-05],\n",
      "        [5.4781e-04, 3.8429e-02, 8.1960e-01, 1.0835e-01, 1.3431e-02, 1.7820e-02,\n",
      "         1.2556e-03, 2.1821e-04, 1.4726e-04, 1.9264e-04],\n",
      "        [2.3012e-04, 2.6240e-02, 5.6948e-01, 1.2701e-01, 6.1174e-02, 1.9076e-01,\n",
      "         2.3707e-02, 7.4130e-04, 2.2060e-04, 4.3106e-04],\n",
      "        [1.3284e-05, 2.2404e-04, 3.8597e-02, 1.1395e-01, 3.0634e-01, 4.5705e-01,\n",
      "         5.9157e-02, 1.8422e-02, 2.6058e-03, 3.6371e-03],\n",
      "        [1.6027e-06, 9.0204e-05, 1.3065e-03, 2.2805e-02, 1.2663e-01, 2.7107e-01,\n",
      "         2.1117e-01, 1.2696e-01, 1.6136e-01, 7.8604e-02],\n",
      "        [5.2914e-06, 9.1283e-05, 1.8876e-03, 1.2523e-02, 4.0082e-02, 3.1448e-01,\n",
      "         1.1716e-01, 1.4498e-01, 3.2969e-01, 3.9106e-02],\n",
      "        [9.6164e-07, 1.0204e-05, 1.0103e-03, 3.9197e-03, 1.7327e-02, 6.6493e-02,\n",
      "         3.0173e-02, 1.2181e-01, 3.9914e-01, 3.6012e-01]])\n",
      "\n",
      "Epoch: 11.58, Train Loss: 1.78, Val Loss: 4.46, Train BLEU: 25.81, Val BLEU: 10.77, Minutes Elapsed: 608.34\n",
      "Sampling from training predictions...\n",
      "Source: các đối_tượng nghiên cứu_nhân đôi sự gian_lận của họ .\n",
      "Reference: our subjects doubled their cheating . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> the have are their their . <EOS> <EOS> .\n",
      "Attention Weights: tensor([[9.1213e-02, 8.0848e-01, 6.3349e-02, 3.6627e-02, 3.1226e-04, 1.5526e-05,\n",
      "         6.9423e-07, 5.9904e-09, 2.7869e-09, 3.0634e-10],\n",
      "        [4.1983e-04, 3.1667e-02, 4.1242e-01, 5.3958e-01, 1.4012e-02, 1.7750e-03,\n",
      "         1.2557e-04, 1.3453e-06, 8.0370e-07, 3.0426e-07],\n",
      "        [2.2498e-03, 6.1571e-02, 2.1341e-01, 2.4896e-01, 4.1503e-01, 5.5469e-02,\n",
      "         3.1361e-03, 5.8869e-05, 7.2796e-05, 3.6133e-05],\n",
      "        [5.1898e-06, 3.0720e-04, 5.4066e-03, 1.7661e-01, 5.1558e-01, 2.3018e-01,\n",
      "         6.8393e-02, 9.6256e-04, 1.9039e-03, 6.4691e-04],\n",
      "        [1.2619e-07, 7.3006e-05, 5.7727e-04, 2.3164e-03, 1.8752e-02, 1.2046e-01,\n",
      "         8.5111e-01, 3.1747e-03, 2.6670e-03, 8.6420e-04],\n",
      "        [9.1615e-07, 2.0747e-04, 1.6128e-04, 4.4183e-04, 5.3733e-03, 2.1621e-01,\n",
      "         7.3255e-01, 1.2825e-02, 8.7965e-03, 2.3428e-02],\n",
      "        [2.5283e-06, 4.3835e-04, 2.1803e-03, 4.2008e-03, 1.7149e-02, 3.6185e-02,\n",
      "         9.4851e-02, 2.8109e-02, 1.6744e-01, 6.4945e-01],\n",
      "        [4.5973e-04, 2.3133e-02, 9.8300e-03, 3.2211e-02, 2.9993e-02, 8.0192e-02,\n",
      "         5.0130e-01, 2.8973e-02, 9.0532e-02, 2.0338e-01],\n",
      "        [1.4265e-02, 1.0552e-01, 3.8993e-02, 2.0128e-02, 4.0067e-02, 1.2572e-01,\n",
      "         2.7790e-01, 2.6591e-02, 1.6594e-01, 1.8487e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: \" trước_khi tôi chết , tôi muốn trồng một cái\n",
      "Reference: &quot; before i die , i want to plant\n",
      "Model: <SOS> &quot; i before teach , i wanted to use\n",
      "Attention Weights: tensor([[8.0837e-01, 1.9162e-01, 4.4627e-07, 6.3348e-06, 1.3246e-09, 4.5351e-10,\n",
      "         6.1015e-09, 1.4071e-09, 2.4861e-10, 3.5621e-10],\n",
      "        [1.4844e-03, 9.9841e-01, 8.7853e-05, 1.4690e-05, 8.9011e-08, 5.3262e-08,\n",
      "         1.7048e-07, 1.3142e-08, 1.0286e-09, 2.2114e-10],\n",
      "        [3.8455e-04, 9.5942e-01, 2.1795e-02, 1.7742e-02, 7.9226e-05, 1.7206e-05,\n",
      "         5.2122e-04, 4.3652e-05, 1.0308e-06, 4.2111e-07],\n",
      "        [8.6552e-04, 3.9583e-01, 3.3193e-02, 5.3782e-01, 1.3309e-02, 1.0199e-03,\n",
      "         1.3797e-02, 3.9144e-03, 1.2594e-04, 1.1999e-04],\n",
      "        [7.2976e-04, 5.3909e-02, 3.4545e-02, 7.6446e-01, 9.8033e-02, 9.1087e-03,\n",
      "         2.9414e-02, 9.2582e-03, 2.9719e-04, 2.4887e-04],\n",
      "        [4.4541e-03, 1.4957e-01, 1.6105e-02, 8.4690e-02, 2.1166e-01, 3.6880e-01,\n",
      "         1.2371e-01, 1.9996e-02, 1.0783e-02, 1.0229e-02],\n",
      "        [6.5912e-07, 4.5348e-04, 3.1054e-04, 5.7182e-04, 4.2265e-03, 2.6819e-02,\n",
      "         9.5714e-01, 9.4920e-03, 4.0778e-04, 5.7570e-04],\n",
      "        [8.9290e-06, 2.1800e-03, 7.5567e-04, 2.3580e-02, 9.2859e-03, 1.3071e-03,\n",
      "         7.5481e-01, 2.0366e-01, 1.5181e-03, 2.8929e-03],\n",
      "        [1.7562e-07, 1.1750e-04, 4.5606e-05, 1.8363e-02, 1.8720e-02, 2.7796e-03,\n",
      "         6.4260e-02, 8.0380e-01, 1.9801e-02, 7.2116e-02]])\n",
      "\n",
      "Epoch: 11.62, Train Loss: 1.84, Val Loss: 4.47, Train BLEU: 26.34, Val BLEU: 11.27, Minutes Elapsed: 610.84\n",
      "Sampling from training predictions...\n",
      "Source: vậy_thì sao ? chúng_ta nhìn vào vấn_đề đó và chúng_ta\n",
      "Reference: so what ? we look at that , and\n",
      "Model: <SOS> so what ? we look at that , and\n",
      "Attention Weights: tensor([[8.8783e-01, 1.1216e-01, 9.1299e-06, 1.9035e-08, 1.4299e-07, 1.4855e-08,\n",
      "         1.3995e-09, 2.6062e-09, 1.4360e-10, 2.6500e-11],\n",
      "        [1.5188e-01, 7.1781e-01, 1.2994e-01, 2.8702e-04, 6.0404e-05, 5.6864e-06,\n",
      "         3.7435e-06, 4.5041e-06, 1.2233e-06, 1.1637e-06],\n",
      "        [4.8792e-02, 2.1637e-01, 5.6606e-01, 8.4439e-02, 7.6776e-02, 6.2486e-03,\n",
      "         6.7650e-04, 4.3526e-04, 1.4411e-04, 6.3948e-05],\n",
      "        [1.7444e-02, 8.0462e-02, 1.7488e-01, 2.7865e-01, 3.7537e-01, 6.4640e-02,\n",
      "         5.5619e-03, 2.0034e-03, 6.7828e-04, 3.1196e-04],\n",
      "        [2.7295e-04, 1.5036e-03, 1.1875e-02, 1.7851e-02, 9.0025e-01, 6.2329e-02,\n",
      "         4.3413e-03, 9.7331e-04, 4.6695e-04, 1.3918e-04],\n",
      "        [1.8300e-04, 1.0731e-03, 2.2016e-03, 4.8633e-03, 6.1527e-01, 2.8844e-01,\n",
      "         7.8060e-02, 8.7705e-03, 7.4159e-04, 3.9563e-04],\n",
      "        [2.4686e-05, 1.2319e-04, 1.9665e-03, 5.2130e-03, 1.2894e-02, 1.7003e-02,\n",
      "         7.2975e-01, 2.2279e-01, 9.5569e-03, 6.8230e-04],\n",
      "        [4.9209e-06, 2.6157e-05, 3.3693e-04, 1.9170e-03, 1.0783e-03, 2.0926e-03,\n",
      "         9.3345e-02, 4.1342e-01, 4.2427e-01, 6.3507e-02],\n",
      "        [4.1150e-05, 6.1853e-04, 6.6930e-03, 3.1806e-02, 3.3608e-03, 2.1583e-03,\n",
      "         1.5070e-02, 1.3884e-01, 6.2046e-01, 1.8094e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi không phải công_dân nước đó . <EOS> <PAD> <PAD>\n",
      "Reference: i wasn &apos;t a citizen of that country .\n",
      "Model: <SOS> i don &apos;t have to interview . . <EOS>\n",
      "Attention Weights: tensor([[0.0528, 0.4829, 0.4641, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0051, 0.9555, 0.0390, 0.0004, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0070, 0.8422, 0.1408, 0.0096, 0.0003, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0032, 0.0069, 0.6552, 0.3182, 0.0157, 0.0006, 0.0002, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0001, 0.0065, 0.9543, 0.0384, 0.0005, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0001, 0.0007, 0.6521, 0.3393, 0.0046, 0.0029, 0.0003, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0006, 0.0003, 0.0006, 0.1315, 0.7097, 0.0422, 0.0899, 0.0252, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0007, 0.0013, 0.0011, 0.0443, 0.5905, 0.1775, 0.1024, 0.0821, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0626, 0.0026, 0.0052, 0.0396, 0.2515, 0.2475, 0.2337, 0.1573, 0.0000,\n",
      "         0.0000]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11.67, Train Loss: 1.80, Val Loss: 4.44, Train BLEU: 25.15, Val BLEU: 10.59, Minutes Elapsed: 613.33\n",
      "Sampling from training predictions...\n",
      "Source: và tại một thời_điểm - - và lúc đó tôi\n",
      "Reference: and at one point -- and i had some\n",
      "Model: <SOS> and at one point -- and that had to\n",
      "Attention Weights: tensor([[1.2157e-05, 9.9863e-01, 1.2351e-03, 1.2254e-04, 2.5485e-08, 8.0874e-09,\n",
      "         1.2288e-09, 1.0816e-09, 1.0367e-10, 7.6515e-12],\n",
      "        [2.1165e-04, 9.9682e-01, 2.8334e-03, 1.3690e-04, 5.2572e-08, 1.5174e-08,\n",
      "         1.3495e-08, 1.3212e-08, 1.4761e-09, 2.5909e-10],\n",
      "        [6.7171e-05, 6.2524e-01, 2.1882e-01, 1.5517e-01, 3.8051e-04, 1.5435e-04,\n",
      "         1.0893e-04, 5.0156e-05, 9.8205e-06, 2.9678e-06],\n",
      "        [1.8433e-04, 4.8115e-02, 2.4128e-02, 8.5776e-01, 4.1959e-02, 1.6794e-02,\n",
      "         7.5165e-03, 2.9492e-03, 4.2754e-04, 1.6344e-04],\n",
      "        [1.5432e-04, 4.6243e-04, 5.7789e-03, 5.2220e-02, 1.5605e-01, 4.1545e-01,\n",
      "         3.5227e-01, 1.5906e-02, 1.3640e-03, 3.4015e-04],\n",
      "        [9.6286e-06, 9.4639e-05, 1.1819e-04, 2.7510e-04, 2.7543e-03, 7.1396e-02,\n",
      "         8.3131e-01, 9.0693e-02, 2.4607e-03, 8.8869e-04],\n",
      "        [2.1208e-05, 1.8394e-03, 2.3958e-03, 2.8550e-04, 1.6473e-03, 2.3221e-02,\n",
      "         2.9685e-01, 6.3836e-01, 2.9553e-02, 5.8327e-03],\n",
      "        [2.6684e-06, 1.3538e-03, 1.9123e-03, 9.8302e-03, 1.6485e-03, 5.2500e-03,\n",
      "         1.8278e-02, 5.8374e-01, 1.8482e-01, 1.9316e-01],\n",
      "        [1.3255e-05, 2.2300e-03, 3.7488e-03, 3.0812e-02, 4.9677e-03, 9.2704e-03,\n",
      "         1.5761e-02, 2.2713e-01, 2.3718e-01, 4.6888e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: mặc_dù để thích_ứng với cuộc_sống ở hàn_quốc thì không dễ\n",
      "Reference: even though adjusting to life in south korea was\n",
      "Model: <SOS> and to to the in the not is is\n",
      "Attention Weights: tensor([[9.9873e-01, 1.0139e-03, 2.4598e-04, 1.0175e-05, 4.4979e-07, 4.4582e-09,\n",
      "         8.6878e-09, 6.5213e-10, 2.7871e-10, 4.3200e-10],\n",
      "        [1.4855e-01, 1.9790e-01, 6.4116e-01, 9.5430e-03, 2.4728e-03, 9.2581e-05,\n",
      "         1.2321e-04, 7.6350e-05, 6.3550e-05, 2.3083e-05],\n",
      "        [3.1669e-02, 1.4938e-01, 5.8267e-01, 1.7020e-01, 5.3164e-02, 7.6101e-03,\n",
      "         3.7697e-03, 8.3760e-04, 5.4059e-04, 1.5962e-04],\n",
      "        [4.8040e-04, 2.5470e-02, 3.1028e-01, 2.2302e-01, 2.8345e-01, 9.3223e-02,\n",
      "         4.7167e-02, 6.7647e-03, 7.4189e-03, 2.7251e-03],\n",
      "        [3.8476e-04, 2.9525e-02, 2.1621e-01, 4.6289e-01, 1.7471e-01, 5.3262e-02,\n",
      "         4.1573e-02, 7.5082e-03, 9.9802e-03, 3.9518e-03],\n",
      "        [1.1487e-07, 9.8532e-06, 1.2506e-03, 3.7098e-03, 9.9577e-02, 9.9977e-02,\n",
      "         2.5879e-01, 1.6538e-01, 3.4745e-01, 2.3854e-02],\n",
      "        [2.7709e-06, 3.8697e-05, 5.0058e-03, 9.1561e-03, 6.3537e-02, 1.1061e-01,\n",
      "         2.8175e-01, 1.7746e-01, 2.7298e-01, 7.9454e-02],\n",
      "        [1.1957e-05, 4.8551e-04, 4.1830e-03, 3.7798e-03, 1.6936e-02, 5.8291e-02,\n",
      "         2.5462e-01, 1.0864e-01, 2.7717e-01, 2.7589e-01],\n",
      "        [3.5283e-05, 4.4030e-04, 1.5480e-03, 2.4739e-03, 4.4893e-03, 2.0460e-02,\n",
      "         1.2610e-01, 2.4138e-01, 5.3446e-01, 6.8618e-02]])\n",
      "\n",
      "Epoch: 11.72, Train Loss: 1.90, Val Loss: 4.50, Train BLEU: 23.76, Val BLEU: 10.78, Minutes Elapsed: 615.80\n",
      "Sampling from training predictions...\n",
      "Source: đây là một trong những cộng_đồng lớn nhất , và\n",
      "Reference: these are some of the biggest ones , and\n",
      "Model: <SOS> this is one of the biggest ones , and\n",
      "Attention Weights: tensor([[9.6077e-01, 2.8733e-02, 1.0498e-02, 1.0661e-07, 1.1503e-07, 2.1399e-09,\n",
      "         2.6910e-09, 4.2056e-10, 1.8097e-12, 2.7076e-12],\n",
      "        [3.4042e-02, 7.5993e-01, 1.8808e-01, 9.6689e-03, 6.4090e-03, 1.5495e-03,\n",
      "         1.4014e-04, 1.7291e-04, 5.9873e-06, 1.5415e-06],\n",
      "        [3.1636e-02, 4.0944e-01, 4.4155e-01, 1.0075e-01, 6.2301e-03, 6.8432e-03,\n",
      "         2.5216e-03, 9.8645e-04, 3.2964e-05, 4.2170e-06],\n",
      "        [7.4650e-04, 4.0704e-02, 5.8537e-02, 5.5450e-01, 1.9244e-01, 8.9112e-02,\n",
      "         4.4663e-02, 1.8833e-02, 4.3973e-04, 2.6537e-05],\n",
      "        [9.2934e-05, 5.8543e-03, 3.2701e-03, 3.3750e-01, 2.6834e-01, 2.0420e-01,\n",
      "         1.4904e-01, 2.2431e-02, 8.7648e-03, 5.0689e-04],\n",
      "        [6.1815e-06, 4.7691e-04, 1.5598e-04, 2.3346e-02, 6.4812e-02, 2.7034e-01,\n",
      "         4.7550e-01, 1.3410e-01, 2.8077e-02, 3.1755e-03],\n",
      "        [7.2263e-05, 4.9581e-03, 2.0955e-04, 4.4081e-02, 3.2277e-02, 1.4451e-01,\n",
      "         2.4099e-01, 5.5268e-02, 4.6108e-01, 1.6567e-02],\n",
      "        [3.4647e-05, 4.3361e-04, 1.8532e-05, 3.0077e-03, 1.3192e-02, 2.7012e-02,\n",
      "         6.3722e-02, 4.6393e-02, 6.8062e-01, 1.6557e-01],\n",
      "        [8.7547e-06, 1.0917e-05, 8.6637e-06, 1.9908e-04, 4.3490e-03, 1.2322e-02,\n",
      "         1.4922e-02, 9.4311e-03, 3.6182e-01, 5.9693e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: chúng đã được <UNK> với nền văn_hoá ai cập cổ_đại\n",
      "Reference: they have been associated in ancient egyptian culture .\n",
      "Model: <SOS> they &apos;ve been with to the that that who\n",
      "Attention Weights: tensor([[5.4930e-01, 4.4656e-01, 3.7914e-03, 3.1584e-04, 2.2834e-05, 1.0311e-06,\n",
      "         8.5372e-07, 1.4735e-07, 4.2747e-08, 8.4928e-08],\n",
      "        [7.4933e-02, 2.9229e-01, 6.0785e-01, 2.4379e-02, 2.7937e-04, 1.2141e-04,\n",
      "         7.3495e-05, 4.0571e-05, 5.7912e-06, 2.3244e-05],\n",
      "        [1.7014e-02, 8.2975e-02, 6.1325e-01, 2.5886e-01, 1.8167e-02, 6.6964e-03,\n",
      "         1.8845e-03, 6.5606e-04, 2.0540e-04, 2.9729e-04],\n",
      "        [1.0969e-03, 7.9142e-04, 1.3248e-02, 3.4146e-01, 3.0187e-01, 2.2450e-01,\n",
      "         7.7478e-02, 3.1604e-02, 6.2015e-03, 1.7450e-03],\n",
      "        [8.6902e-04, 2.1214e-04, 2.5732e-04, 1.9613e-02, 2.7494e-01, 4.6613e-01,\n",
      "         1.2950e-01, 8.6280e-02, 1.4752e-02, 7.4398e-03],\n",
      "        [1.8864e-03, 5.1891e-04, 1.7416e-04, 7.8448e-03, 2.5166e-01, 4.3705e-01,\n",
      "         1.7715e-01, 8.6559e-02, 2.8824e-02, 8.3279e-03],\n",
      "        [2.1174e-06, 2.3796e-05, 2.3315e-05, 9.1429e-05, 8.6725e-04, 3.3431e-02,\n",
      "         8.3297e-02, 3.4688e-01, 2.9681e-01, 2.3857e-01],\n",
      "        [1.0940e-05, 1.0873e-04, 4.3210e-05, 3.4877e-04, 1.9361e-03, 2.1513e-02,\n",
      "         2.1015e-02, 3.1274e-01, 5.3436e-01, 1.0793e-01],\n",
      "        [2.2072e-05, 7.3865e-05, 1.6510e-05, 1.4526e-04, 3.4079e-04, 4.5426e-03,\n",
      "         2.0468e-02, 2.1072e-01, 3.9507e-01, 3.6859e-01]])\n",
      "\n",
      "Epoch: 11.77, Train Loss: 1.78, Val Loss: 4.48, Train BLEU: 26.35, Val BLEU: 10.52, Minutes Elapsed: 618.31\n",
      "Sampling from training predictions...\n",
      "Source: liệu được trả bằng tiền_mặt hay bằng phiếu đổi_tiền có\n",
      "Reference: would being a step removed from cash for a\n",
      "Model: <SOS> is it pay by fund cash cash money ,\n",
      "Attention Weights: tensor([[9.5093e-01, 4.8652e-02, 2.4515e-04, 1.7304e-04, 1.1985e-06, 6.6766e-08,\n",
      "         2.0967e-08, 7.2721e-10, 2.7117e-11, 3.0132e-11],\n",
      "        [2.8273e-02, 7.2184e-01, 1.7938e-01, 6.7384e-02, 2.3909e-03, 6.2047e-04,\n",
      "         1.0484e-04, 9.1985e-06, 2.2972e-06, 1.7057e-07],\n",
      "        [1.1491e-02, 1.8676e-01, 4.3974e-01, 3.0070e-01, 3.9038e-02, 1.8836e-02,\n",
      "         2.8459e-03, 3.8210e-04, 1.7707e-04, 3.4573e-05],\n",
      "        [1.5687e-03, 9.1918e-03, 3.2113e-02, 3.4888e-01, 4.5698e-01, 1.2573e-01,\n",
      "         1.3456e-02, 5.0213e-03, 6.6701e-03, 3.9689e-04],\n",
      "        [1.9645e-03, 4.9643e-03, 4.3933e-02, 2.0590e-01, 2.9149e-01, 1.7594e-01,\n",
      "         1.2860e-01, 1.1744e-01, 2.7148e-02, 2.6216e-03],\n",
      "        [6.6599e-04, 2.6873e-02, 1.2056e-02, 1.4476e-01, 1.4176e-01, 3.1254e-01,\n",
      "         1.5527e-01, 1.4110e-01, 4.8268e-02, 1.6704e-02],\n",
      "        [3.8733e-05, 3.5014e-04, 7.7788e-03, 5.2209e-02, 2.0039e-01, 1.7028e-01,\n",
      "         1.7275e-01, 2.2427e-01, 1.5824e-01, 1.3679e-02],\n",
      "        [2.1244e-06, 1.0194e-05, 6.3174e-05, 1.0753e-03, 6.9717e-03, 4.7042e-02,\n",
      "         2.6001e-01, 3.6914e-01, 2.4139e-01, 7.4294e-02],\n",
      "        [6.3475e-06, 9.1955e-05, 1.3109e-04, 5.5743e-04, 6.9228e-03, 4.8253e-02,\n",
      "         1.4222e-01, 1.7216e-01, 2.3918e-01, 3.9048e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: nhưng lần này , tôi muốn thấy sự_thật đang được\n",
      "Reference: but this time , i would see the skeletons\n",
      "Model: <SOS> but this time , i &apos;d to to see\n",
      "Attention Weights: tensor([[1.4920e-03, 9.9586e-01, 2.6518e-03, 4.3464e-08, 2.1007e-08, 2.2660e-07,\n",
      "         2.8123e-08, 1.3961e-10, 8.3050e-12, 1.5816e-11],\n",
      "        [9.1975e-05, 9.9842e-01, 1.4724e-03, 4.6205e-06, 7.1443e-06, 8.4814e-07,\n",
      "         4.6189e-08, 2.2924e-09, 1.2903e-10, 1.2001e-10],\n",
      "        [1.0318e-03, 9.5421e-01, 1.1897e-02, 2.1592e-02, 4.5598e-03, 6.1293e-03,\n",
      "         5.3124e-04, 4.7842e-05, 3.6956e-06, 2.1874e-06],\n",
      "        [3.9796e-03, 1.0929e-01, 8.8078e-02, 3.9114e-01, 1.8031e-01, 1.9614e-01,\n",
      "         2.7123e-02, 3.2457e-03, 3.9424e-04, 2.9483e-04],\n",
      "        [6.9476e-05, 4.9112e-03, 6.3315e-03, 3.0377e-02, 4.3150e-01, 5.1255e-01,\n",
      "         1.1901e-02, 1.5104e-03, 5.5550e-04, 2.9001e-04],\n",
      "        [1.7277e-05, 1.1609e-02, 7.2978e-04, 1.8012e-03, 1.3149e-02, 9.2737e-01,\n",
      "         4.0676e-02, 3.5813e-03, 7.3582e-04, 3.3104e-04],\n",
      "        [6.7132e-04, 4.1775e-02, 1.6872e-02, 2.4542e-02, 7.6378e-03, 6.9816e-01,\n",
      "         1.6033e-01, 3.9581e-02, 7.2135e-03, 3.2129e-03],\n",
      "        [1.2997e-04, 4.4783e-02, 5.5540e-03, 1.4864e-02, 1.2232e-02, 6.5161e-02,\n",
      "         6.9751e-01, 1.3326e-01, 1.5197e-02, 1.1314e-02],\n",
      "        [2.4363e-05, 1.1369e-03, 5.5629e-04, 7.5398e-03, 1.3247e-03, 1.4167e-02,\n",
      "         6.2809e-01, 2.8772e-01, 3.2542e-02, 2.6900e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11.86, Train Loss: 1.76, Val Loss: 4.48, Train BLEU: 26.57, Val BLEU: 10.31, Minutes Elapsed: 623.34\n",
      "Sampling from training predictions...\n",
      "Source: vậy_là cuộc_sống đã phải thay_đổi . <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: so life had to change . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> the life had to change . <EOS> <EOS> .\n",
      "Attention Weights: tensor([[0.9691, 0.0308, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0233, 0.9665, 0.0027, 0.0073, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0089, 0.2338, 0.2689, 0.4752, 0.0127, 0.0005, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0430, 0.1309, 0.1321, 0.6442, 0.0462, 0.0030, 0.0005, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0005, 0.0052, 0.0109, 0.3275, 0.5100, 0.0738, 0.0721, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0046, 0.0078, 0.0176, 0.0309, 0.6064, 0.1349, 0.1978, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0061, 0.1216, 0.0275, 0.0364, 0.2688, 0.1074, 0.4323, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0173, 0.4742, 0.0619, 0.0559, 0.0205, 0.0494, 0.3207, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1734, 0.2646, 0.1851, 0.2087, 0.0696, 0.0177, 0.0810, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: nên tôi nghĩ : \" tuyệt . tôi có_thể làm\n",
      "Reference: so i &apos;m like , &quot; cool . i\n",
      "Model: <SOS> so i thought , , &quot; oh . i\n",
      "Attention Weights: tensor([[9.9872e-01, 1.9662e-04, 9.8708e-04, 6.3035e-05, 1.1679e-06, 3.2470e-05,\n",
      "         1.3784e-08, 3.0581e-09, 7.2253e-10, 1.9204e-10],\n",
      "        [4.4011e-01, 2.9670e-01, 2.5914e-01, 3.2180e-03, 4.9312e-04, 2.8553e-04,\n",
      "         4.3911e-05, 7.5737e-06, 9.6638e-07, 7.8305e-08],\n",
      "        [1.7460e-02, 4.5017e-02, 9.0002e-01, 1.5897e-02, 1.7402e-02, 3.7733e-03,\n",
      "         1.9177e-04, 4.7056e-05, 1.4466e-04, 4.5548e-05],\n",
      "        [2.9140e-03, 6.4169e-03, 8.5772e-01, 5.7911e-02, 5.0934e-02, 2.2864e-02,\n",
      "         8.0278e-04, 6.7963e-05, 1.8108e-04, 1.8577e-04],\n",
      "        [7.7421e-05, 1.4866e-03, 2.9312e-03, 1.0295e-01, 6.2731e-01, 2.4631e-01,\n",
      "         1.6242e-02, 2.1003e-03, 4.1754e-04, 1.7855e-04],\n",
      "        [8.7316e-04, 6.1718e-03, 4.2554e-03, 1.1774e-01, 3.7386e-01, 4.5663e-01,\n",
      "         3.4799e-02, 2.9686e-03, 2.4747e-03, 2.3159e-04],\n",
      "        [9.1940e-05, 8.9814e-04, 1.9325e-04, 1.3018e-02, 7.9595e-02, 8.4853e-01,\n",
      "         5.0777e-02, 4.4684e-03, 2.0847e-03, 3.4791e-04],\n",
      "        [1.7838e-04, 6.2856e-04, 7.4127e-04, 7.4739e-04, 3.5998e-02, 2.2949e-01,\n",
      "         4.2645e-01, 1.4921e-01, 1.4235e-01, 1.4207e-02],\n",
      "        [4.1832e-05, 1.9388e-04, 1.6556e-03, 8.0849e-04, 6.1840e-03, 7.9741e-03,\n",
      "         5.6668e-02, 4.9250e-01, 3.0743e-01, 1.2654e-01]])\n",
      "\n",
      "Epoch: 11.91, Train Loss: 1.67, Val Loss: 4.50, Train BLEU: 27.26, Val BLEU: 10.18, Minutes Elapsed: 625.86\n",
      "Sampling from training predictions...\n",
      "Source: ai đã đúng , ai sai ? <EOS> <PAD> <PAD>\n",
      "Reference: who was right , who wrong ? <EOS> <PAD>\n",
      "Model: <SOS> who &apos;s wrong , who ? wrong <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9508, 0.0338, 0.0146, 0.0005, 0.0002, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1165, 0.1347, 0.6873, 0.0262, 0.0126, 0.0225, 0.0002, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0154, 0.0811, 0.8232, 0.0384, 0.0096, 0.0318, 0.0005, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0029, 0.0316, 0.3229, 0.2225, 0.3007, 0.1125, 0.0059, 0.0010, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0013, 0.0110, 0.0382, 0.0621, 0.8544, 0.0217, 0.0094, 0.0020, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0016, 0.0060, 0.0065, 0.2715, 0.6645, 0.0391, 0.0108, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0004, 0.0047, 0.0618, 0.0054, 0.0175, 0.7605, 0.1184, 0.0312, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0084, 0.0542, 0.0113, 0.0900, 0.4692, 0.1723, 0.1944, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0010, 0.0069, 0.0084, 0.0147, 0.1945, 0.2430, 0.1817, 0.3498, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: rất nhiều người bị lừa bởi những lời_hứa <UNK> về\n",
      "Reference: many have been tricked by false promises of a\n",
      "Model: <SOS> a lot people people by by <UNK> of in\n",
      "Attention Weights: tensor([[9.4153e-01, 5.8305e-02, 1.5451e-04, 1.1157e-05, 1.0414e-06, 8.1820e-08,\n",
      "         2.3245e-08, 2.9349e-08, 4.6441e-09, 3.2673e-09],\n",
      "        [1.1837e-02, 3.2254e-01, 4.2562e-01, 1.5173e-01, 7.6766e-02, 5.6343e-03,\n",
      "         2.9468e-03, 2.7179e-03, 1.4349e-04, 5.8538e-05],\n",
      "        [4.1142e-02, 1.1998e-01, 1.5605e-01, 3.4973e-01, 2.7618e-01, 4.4195e-02,\n",
      "         3.6651e-03, 7.6158e-03, 1.2477e-03, 1.9935e-04],\n",
      "        [2.6958e-03, 1.7054e-02, 2.0258e-01, 2.8952e-01, 3.3919e-01, 8.5573e-02,\n",
      "         2.0577e-02, 3.5442e-02, 5.6523e-03, 1.7197e-03],\n",
      "        [2.3484e-03, 3.5836e-02, 5.5592e-02, 2.5104e-01, 2.9041e-01, 2.6234e-01,\n",
      "         1.5007e-02, 7.9044e-02, 6.0826e-03, 2.2884e-03],\n",
      "        [6.6325e-04, 2.9137e-02, 4.1687e-02, 1.7373e-01, 1.4293e-01, 3.4566e-01,\n",
      "         7.1324e-02, 1.5172e-01, 2.3661e-02, 1.9481e-02],\n",
      "        [3.3555e-06, 1.3907e-04, 3.1220e-03, 1.1521e-02, 1.0903e-02, 4.0986e-02,\n",
      "         1.4504e-01, 6.4789e-01, 8.0403e-02, 5.9996e-02],\n",
      "        [1.9402e-05, 8.3040e-05, 7.3821e-05, 4.7101e-04, 5.4601e-04, 4.6577e-03,\n",
      "         4.2531e-02, 6.1956e-01, 4.8027e-02, 2.8403e-01],\n",
      "        [1.1525e-04, 1.0621e-03, 1.2057e-03, 2.2923e-03, 9.5355e-04, 7.1110e-03,\n",
      "         7.8806e-02, 1.0097e-01, 3.8060e-02, 7.6942e-01]])\n",
      "\n",
      "Epoch: 11.96, Train Loss: 1.50, Val Loss: 4.46, Train BLEU: 32.63, Val BLEU: 10.06, Minutes Elapsed: 628.41\n",
      "Sampling from training predictions...\n",
      "Source: nhưng tôi cứ không_thể dừng được . <EOS> <PAD> <PAD>\n",
      "Reference: and i just couldn &apos;t . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> but i can couldn &apos;t get that <EOS> couldn\n",
      "Attention Weights: tensor([[0.0057, 0.1757, 0.8106, 0.0079, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0005, 0.3401, 0.6570, 0.0023, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0039, 0.9377, 0.0567, 0.0015, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0007, 0.1045, 0.8044, 0.0841, 0.0060, 0.0002, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0063, 0.0426, 0.2094, 0.6925, 0.0457, 0.0032, 0.0003, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0143, 0.0090, 0.0360, 0.6348, 0.2669, 0.0242, 0.0147, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0383, 0.0022, 0.0283, 0.3568, 0.2393, 0.1260, 0.2090, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0009, 0.0311, 0.0123, 0.0352, 0.2446, 0.2508, 0.1625, 0.2626, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0033, 0.0277, 0.0799, 0.6310, 0.1188, 0.0222, 0.0483, 0.0688, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: những tấm hình không phải là về bản_thân <UNK> .\n",
      "Reference: these images are not of issues . they are\n",
      "Model: <SOS> the are are not about the of the .\n",
      "Attention Weights: tensor([[9.1555e-02, 8.2714e-01, 7.9487e-02, 1.7693e-03, 4.5131e-05, 2.3660e-06,\n",
      "         2.5953e-07, 7.3073e-09, 8.7368e-09, 1.0853e-09],\n",
      "        [1.6516e-03, 4.0107e-02, 1.5945e-01, 7.5747e-01, 3.1347e-02, 6.8789e-03,\n",
      "         2.8842e-03, 1.9547e-04, 1.1218e-05, 5.6426e-06],\n",
      "        [5.7846e-03, 5.4266e-02, 1.2373e-01, 6.9745e-01, 4.7184e-02, 3.7604e-02,\n",
      "         2.9837e-02, 3.8628e-03, 2.0177e-04, 8.1364e-05],\n",
      "        [1.6461e-03, 6.0712e-03, 4.1219e-02, 3.4466e-01, 1.0596e-01, 2.0581e-01,\n",
      "         2.0877e-01, 7.7524e-02, 7.3827e-03, 9.4910e-04],\n",
      "        [1.3188e-03, 8.9738e-04, 1.2562e-02, 1.8836e-02, 2.5463e-02, 7.8417e-02,\n",
      "         4.2206e-01, 3.9937e-01, 3.8575e-02, 2.4999e-03],\n",
      "        [6.2380e-04, 1.9184e-03, 2.0308e-02, 2.5664e-03, 5.8296e-03, 3.1365e-02,\n",
      "         3.4655e-01, 4.6560e-01, 1.1376e-01, 1.1478e-02],\n",
      "        [2.3836e-04, 1.0132e-03, 9.0130e-03, 1.4179e-03, 2.9774e-03, 1.5103e-02,\n",
      "         2.5265e-01, 6.0006e-01, 8.9608e-02, 2.7915e-02],\n",
      "        [8.4111e-05, 2.6169e-04, 3.0334e-03, 2.0992e-03, 1.8297e-04, 2.6994e-03,\n",
      "         1.4971e-01, 5.1058e-01, 8.6126e-02, 2.4522e-01],\n",
      "        [2.5050e-04, 1.8681e-03, 1.3770e-02, 6.5278e-03, 2.4645e-03, 2.1501e-03,\n",
      "         1.9085e-02, 2.5816e-01, 1.6275e-01, 5.3298e-01]])\n",
      "\n",
      "Epoch: 12.00, Train Loss: 1.31, Val Loss: 4.51, Train BLEU: 37.90, Val BLEU: 9.97, Minutes Elapsed: 630.51\n",
      "Sampling from training predictions...\n",
      "Source: nhưng nó còn có_thể biến_tấu như thế_này . <EOS> <PAD>\n",
      "Reference: but it can also sound like this . <EOS>\n",
      "Model: <SOS> but it can also as as this . <EOS>\n",
      "Attention Weights: tensor([[0.0033, 0.3625, 0.6338, 0.0002, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0005, 0.5185, 0.4807, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0017, 0.0081, 0.8641, 0.0711, 0.0549, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0043, 0.7488, 0.0537, 0.1911, 0.0019, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0002, 0.0275, 0.0469, 0.9046, 0.0169, 0.0031, 0.0006, 0.0002,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0006, 0.0145, 0.0093, 0.3160, 0.4991, 0.1268, 0.0225, 0.0111,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0001, 0.0013, 0.0076, 0.1239, 0.1265, 0.2694, 0.3083, 0.1629,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0001, 0.0051, 0.0175, 0.0691, 0.0371, 0.3537, 0.2725, 0.2449,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0009, 0.0339, 0.0141, 0.0992, 0.0183, 0.1281, 0.2757, 0.4298,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi không_thể nói cụ_thể về việc mình đã trốn khỏi\n",
      "Reference: i can &apos;t reveal many details &#91; about &#93;\n",
      "Model: <SOS> i can &apos;t tell how about you my &#93;\n",
      "Attention Weights: tensor([[3.7648e-03, 9.9277e-01, 2.2660e-03, 1.1911e-03, 5.2426e-06, 1.7988e-06,\n",
      "         5.9742e-07, 9.6795e-07, 5.5885e-07, 6.8187e-08],\n",
      "        [3.5883e-03, 9.9383e-01, 2.3778e-03, 1.5865e-04, 1.5315e-05, 7.9131e-06,\n",
      "         1.0900e-05, 2.2051e-06, 2.9542e-06, 1.0042e-06],\n",
      "        [1.1440e-03, 9.6776e-01, 2.8896e-02, 1.4703e-03, 5.3185e-04, 9.6722e-05,\n",
      "         5.5112e-05, 1.3272e-05, 2.5701e-05, 8.9575e-06],\n",
      "        [1.0614e-03, 6.0736e-02, 7.7734e-01, 6.5853e-02, 7.9427e-02, 1.1428e-02,\n",
      "         2.7019e-03, 6.5549e-04, 6.3166e-04, 1.6356e-04],\n",
      "        [3.2458e-05, 4.4342e-03, 2.4057e-01, 2.3426e-01, 4.5207e-01, 4.9261e-02,\n",
      "         1.0076e-02, 3.6445e-03, 3.9712e-03, 1.6822e-03],\n",
      "        [8.9656e-06, 1.9710e-03, 4.8574e-02, 2.2606e-01, 5.4538e-01, 1.1457e-01,\n",
      "         3.8459e-02, 8.3016e-03, 1.1965e-02, 4.7169e-03],\n",
      "        [3.8937e-06, 2.9204e-04, 1.1550e-03, 1.8980e-02, 1.8311e-01, 3.8233e-01,\n",
      "         2.2503e-01, 8.4160e-02, 8.8454e-02, 1.6483e-02],\n",
      "        [2.0989e-06, 6.2117e-04, 4.0359e-04, 1.2386e-02, 8.7370e-02, 1.9501e-01,\n",
      "         1.6445e-01, 2.3903e-01, 2.8681e-01, 1.3919e-02],\n",
      "        [3.8134e-05, 7.2762e-03, 5.4068e-04, 3.1203e-02, 1.0523e-01, 1.1798e-01,\n",
      "         1.1897e-01, 2.6007e-01, 3.3913e-01, 1.9568e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12.05, Train Loss: 1.17, Val Loss: 4.51, Train BLEU: 42.27, Val BLEU: 10.04, Minutes Elapsed: 633.03\n",
      "Sampling from training predictions...\n",
      "Source: vâng , lý_thuyết neuron đối_chiếu nói một_cách đơn_giản rằng trong\n",
      "Reference: now , the theory of mirror neurons simply says\n",
      "Model: <SOS> well , the theory of mirror neurons says simply\n",
      "Attention Weights: tensor([[9.9507e-01, 4.9227e-03, 2.1441e-06, 3.2787e-07, 1.2066e-08, 4.6417e-11,\n",
      "         9.4501e-11, 2.3656e-11, 2.6539e-12, 4.1182e-12],\n",
      "        [2.0767e-01, 7.4566e-01, 4.4821e-02, 1.6743e-03, 1.6331e-04, 3.3932e-06,\n",
      "         4.6557e-06, 2.8259e-06, 3.2724e-07, 4.8184e-07],\n",
      "        [3.4055e-03, 6.1428e-02, 7.8755e-01, 1.1750e-01, 2.7082e-02, 1.8170e-03,\n",
      "         4.8324e-04, 5.9017e-04, 8.6424e-05, 6.4022e-05],\n",
      "        [2.7270e-05, 8.4798e-04, 8.3833e-01, 1.2041e-01, 3.6681e-02, 1.1414e-03,\n",
      "         8.0763e-04, 1.3902e-03, 1.5748e-04, 2.0990e-04],\n",
      "        [3.7397e-04, 8.5404e-04, 2.0823e-01, 2.8072e-01, 4.0119e-01, 5.9539e-02,\n",
      "         2.1987e-02, 2.1974e-02, 3.4233e-03, 1.7066e-03],\n",
      "        [2.4260e-05, 2.1962e-05, 1.2589e-02, 5.5837e-02, 5.9847e-01, 2.3605e-01,\n",
      "         4.0172e-02, 4.8034e-02, 7.2281e-03, 1.5730e-03],\n",
      "        [2.0004e-07, 1.2876e-06, 3.2792e-03, 2.7149e-02, 2.6444e-01, 2.4288e-01,\n",
      "         1.3332e-01, 2.2969e-01, 9.1436e-02, 7.7985e-03],\n",
      "        [1.3082e-07, 4.1749e-07, 4.4765e-04, 2.5807e-03, 5.1727e-02, 6.1863e-01,\n",
      "         1.5008e-01, 1.2222e-01, 4.7370e-02, 6.9409e-03],\n",
      "        [8.4852e-08, 4.2868e-07, 3.7289e-04, 1.0277e-03, 5.9943e-03, 1.1037e-01,\n",
      "         1.5958e-01, 3.8946e-01, 2.8779e-01, 4.5408e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: nếu người đó không muốn làm , vậy_thì bạn phải\n",
      "Reference: if that person doesn &apos;t want to do it\n",
      "Model: <SOS> if you don &apos;t &apos;t want to , ,\n",
      "Attention Weights: tensor([[8.0714e-01, 1.7594e-01, 1.6690e-02, 2.2778e-04, 3.1448e-06, 2.1780e-08,\n",
      "         2.6432e-09, 2.9295e-09, 6.8916e-10, 5.3411e-09],\n",
      "        [2.6578e-03, 9.4547e-01, 4.8758e-02, 2.6037e-03, 4.8337e-04, 4.5882e-06,\n",
      "         3.4253e-06, 7.9564e-06, 2.9822e-06, 5.3407e-06],\n",
      "        [2.3618e-03, 5.1021e-01, 2.1112e-01, 2.5161e-01, 2.0093e-02, 3.2502e-03,\n",
      "         1.8243e-04, 6.8638e-04, 2.2869e-04, 2.6458e-04],\n",
      "        [6.7845e-04, 2.0529e-02, 6.7364e-02, 5.8133e-01, 2.7436e-01, 5.3239e-02,\n",
      "         7.4416e-04, 9.9371e-04, 3.1979e-04, 4.4367e-04],\n",
      "        [1.2232e-03, 3.5558e-02, 4.9238e-02, 3.4911e-01, 5.0938e-01, 4.5993e-02,\n",
      "         2.1488e-03, 3.7565e-03, 2.1311e-03, 1.4647e-03],\n",
      "        [1.4749e-05, 2.1288e-03, 3.4861e-03, 5.7017e-02, 8.1090e-01, 1.1032e-01,\n",
      "         5.0948e-03, 5.5187e-03, 8.8863e-04, 4.6377e-03],\n",
      "        [3.3646e-06, 3.9696e-04, 1.3160e-03, 3.6181e-02, 1.7721e-01, 4.5323e-01,\n",
      "         1.1510e-01, 1.8728e-01, 1.0853e-02, 1.8436e-02],\n",
      "        [8.2232e-06, 1.6830e-04, 3.7552e-04, 2.9114e-03, 2.1264e-02, 1.5711e-01,\n",
      "         1.1251e-01, 6.7100e-01, 1.8037e-02, 1.6614e-02],\n",
      "        [4.4000e-05, 3.7946e-04, 1.0491e-04, 3.1650e-03, 1.2837e-02, 2.1528e-02,\n",
      "         1.5546e-01, 7.7224e-01, 8.3660e-03, 2.5874e-02]])\n",
      "\n",
      "Epoch: 12.10, Train Loss: 1.35, Val Loss: 4.53, Train BLEU: 35.95, Val BLEU: 10.63, Minutes Elapsed: 635.52\n",
      "Sampling from training predictions...\n",
      "Source: đó là cách giáo_dục thâm tuý và có khả_năng truyền_tải\n",
      "Reference: it was an education of the most profound and\n",
      "Model: <SOS> it &apos;s the education of the profound . and\n",
      "Attention Weights: tensor([[5.0218e-01, 4.9494e-01, 2.4842e-03, 3.7228e-04, 1.9271e-05, 1.4357e-06,\n",
      "         1.3081e-07, 8.9260e-09, 2.1135e-09, 1.6205e-09],\n",
      "        [5.7371e-03, 8.8929e-01, 5.4781e-02, 4.4349e-02, 5.3540e-03, 4.3446e-04,\n",
      "         2.1272e-05, 2.1711e-05, 6.2408e-06, 1.0222e-06],\n",
      "        [1.5297e-02, 4.1076e-01, 3.0948e-01, 2.0917e-01, 4.9299e-02, 5.7655e-03,\n",
      "         5.3517e-05, 9.1983e-05, 5.6166e-05, 2.5898e-05],\n",
      "        [2.5784e-05, 1.4518e-03, 1.2917e-02, 8.6350e-01, 1.0423e-01, 1.7560e-02,\n",
      "         1.9765e-04, 4.4786e-05, 4.0959e-05, 2.9773e-05],\n",
      "        [7.6380e-04, 8.1339e-03, 7.5919e-02, 1.3246e-01, 5.6766e-01, 2.1035e-01,\n",
      "         3.3634e-03, 6.9450e-04, 5.4875e-04, 1.1292e-04],\n",
      "        [3.6025e-04, 7.4963e-03, 2.2901e-02, 4.5774e-02, 5.2078e-01, 3.9229e-01,\n",
      "         5.5603e-03, 2.2236e-03, 1.4390e-03, 1.1793e-03],\n",
      "        [6.8605e-06, 8.2165e-05, 5.3397e-04, 5.2272e-03, 2.4526e-02, 3.1510e-01,\n",
      "         1.6580e-01, 3.0895e-01, 1.4418e-01, 3.5595e-02],\n",
      "        [1.2986e-03, 3.7651e-03, 1.1677e-03, 5.1314e-04, 7.6485e-03, 4.0992e-02,\n",
      "         1.6168e-01, 6.7888e-01, 9.2424e-02, 1.1637e-02],\n",
      "        [6.0237e-04, 1.5635e-03, 1.0392e-03, 1.0774e-03, 1.0354e-02, 1.6902e-01,\n",
      "         2.2163e-01, 5.1378e-01, 6.1610e-02, 1.9320e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: đó là những hình_ảnh được dựng lên , và nó\n",
      "Reference: they are constructions , and they are constructions by\n",
      "Model: <SOS> these are visual images , &apos;s , , ,\n",
      "Attention Weights: tensor([[3.8525e-01, 6.1328e-01, 1.3120e-03, 1.5806e-04, 4.9053e-06, 3.8794e-07,\n",
      "         8.3517e-08, 1.3896e-08, 1.7552e-09, 1.2695e-09],\n",
      "        [9.3909e-03, 7.3673e-01, 2.1951e-01, 3.2255e-02, 1.6383e-03, 3.9070e-04,\n",
      "         6.4655e-05, 1.4618e-05, 4.1878e-06, 7.9234e-06],\n",
      "        [2.4227e-02, 1.7634e-01, 2.9637e-01, 4.4478e-01, 2.2711e-02, 1.9229e-02,\n",
      "         1.6127e-02, 1.3380e-04, 2.2047e-05, 5.9384e-05],\n",
      "        [9.6951e-05, 6.5798e-04, 1.5214e-02, 6.8027e-01, 2.3857e-01, 4.5479e-02,\n",
      "         1.8186e-02, 1.3479e-03, 1.7580e-04, 6.0460e-06],\n",
      "        [4.8472e-05, 8.3055e-04, 4.6321e-03, 4.2946e-01, 4.4615e-01, 8.2194e-02,\n",
      "         2.4422e-02, 8.7693e-03, 2.3888e-03, 1.1058e-03],\n",
      "        [3.4247e-05, 2.7110e-03, 2.8134e-03, 5.7680e-02, 2.9646e-01, 3.0437e-01,\n",
      "         1.7491e-01, 9.2424e-02, 3.8285e-02, 3.0312e-02],\n",
      "        [1.5180e-03, 1.9143e-02, 3.1741e-01, 8.1121e-02, 1.7032e-01, 2.5380e-01,\n",
      "         1.0432e-01, 3.2249e-02, 6.4753e-03, 1.3635e-02],\n",
      "        [2.0461e-03, 1.6883e-02, 4.1431e-02, 1.3237e-01, 2.8362e-01, 3.8675e-01,\n",
      "         7.8181e-02, 3.8318e-02, 1.0691e-02, 9.7062e-03],\n",
      "        [1.2739e-05, 1.3139e-04, 1.2438e-03, 8.1467e-02, 4.9125e-02, 2.9860e-01,\n",
      "         2.3779e-01, 2.4135e-01, 6.8745e-02, 2.1539e-02]])\n",
      "\n",
      "Epoch: 12.14, Train Loss: 1.35, Val Loss: 4.52, Train BLEU: 36.53, Val BLEU: 10.64, Minutes Elapsed: 638.01\n",
      "Sampling from training predictions...\n",
      "Source: tại_sao ? tôi có_thể đi về được không ? \"\n",
      "Reference: why ? can i go away ? &quot; <EOS>\n",
      "Model: <SOS> why ? i i go away ? &quot; <EOS>\n",
      "Attention Weights: tensor([[9.9996e-01, 4.0435e-05, 2.8362e-07, 1.2236e-07, 1.0246e-07, 2.5453e-09,\n",
      "         5.9717e-09, 2.2408e-09, 5.4975e-10, 3.8215e-11],\n",
      "        [3.9827e-01, 3.5597e-01, 1.7995e-01, 6.4905e-02, 7.7523e-04, 5.9839e-05,\n",
      "         3.7770e-05, 2.5248e-05, 7.8831e-06, 5.9633e-06],\n",
      "        [2.9456e-02, 6.6307e-02, 7.9042e-01, 1.0941e-01, 3.4211e-03, 4.3448e-04,\n",
      "         3.2730e-04, 1.6699e-04, 2.8442e-05, 2.7585e-05],\n",
      "        [1.2106e-02, 5.8130e-02, 1.2230e-01, 4.6177e-01, 3.1627e-01, 1.7717e-02,\n",
      "         8.8621e-03, 2.0906e-03, 3.8142e-04, 3.7217e-04],\n",
      "        [7.7579e-04, 1.0381e-03, 1.4294e-03, 2.0142e-01, 7.1375e-01, 5.6827e-02,\n",
      "         2.1028e-02, 3.2686e-03, 3.3310e-04, 1.3289e-04],\n",
      "        [1.3781e-05, 3.6580e-05, 5.4023e-05, 8.8251e-04, 1.2884e-01, 7.5588e-01,\n",
      "         1.0054e-01, 7.7832e-03, 2.3527e-03, 3.6200e-03],\n",
      "        [1.0457e-05, 2.2990e-05, 1.7746e-04, 2.3209e-04, 1.3748e-02, 3.0871e-01,\n",
      "         2.7647e-01, 1.5770e-01, 7.1463e-02, 1.7147e-01],\n",
      "        [1.0176e-05, 3.4990e-05, 1.8954e-04, 2.4956e-04, 5.6614e-04, 1.1082e-02,\n",
      "         4.4832e-02, 8.0794e-02, 8.0306e-02, 7.8194e-01],\n",
      "        [7.8195e-04, 1.5767e-03, 3.3309e-03, 3.5969e-03, 1.9428e-03, 6.9743e-03,\n",
      "         3.5837e-02, 8.4329e-02, 3.1222e-02, 8.3041e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: em ấy không tham_lam . em không phân_biệt màu_da .\n",
      "Reference: he &apos;s not greedy . he doesn &apos;t see\n",
      "Model: <SOS> he didn &apos;t . . don don &apos;t plan\n",
      "Attention Weights: tensor([[5.5418e-01, 4.4390e-01, 1.6236e-03, 2.4723e-04, 4.5600e-05, 3.6328e-06,\n",
      "         6.3121e-07, 7.5953e-08, 2.2496e-08, 8.1048e-09],\n",
      "        [1.8491e-02, 2.3961e-01, 6.6712e-01, 7.0749e-02, 2.1434e-03, 3.5790e-04,\n",
      "         1.3491e-03, 1.4912e-04, 1.8734e-05, 1.3660e-05],\n",
      "        [4.4423e-02, 1.0301e-01, 5.7906e-01, 2.5636e-01, 1.2344e-02, 2.7546e-03,\n",
      "         1.8152e-03, 1.5837e-04, 6.5864e-05, 1.4060e-05],\n",
      "        [1.5553e-03, 9.0743e-03, 2.3151e-02, 9.0990e-01, 5.4255e-02, 1.2101e-03,\n",
      "         3.0060e-04, 4.7903e-04, 6.0987e-05, 1.0826e-05],\n",
      "        [4.3397e-03, 1.2359e-02, 1.8723e-02, 2.4350e-01, 5.9381e-01, 1.0773e-01,\n",
      "         4.7649e-03, 8.4290e-03, 5.4819e-03, 8.5982e-04],\n",
      "        [1.8024e-02, 8.2144e-03, 1.8397e-02, 1.1691e-02, 2.4356e-01, 6.0411e-01,\n",
      "         8.3773e-02, 4.8144e-03, 3.9492e-03, 3.4618e-03],\n",
      "        [9.8185e-04, 4.1497e-03, 1.8447e-02, 8.1057e-03, 6.6828e-02, 5.2113e-01,\n",
      "         3.5319e-01, 2.2415e-02, 3.3007e-03, 1.4518e-03],\n",
      "        [2.8550e-03, 1.2562e-02, 1.4607e-01, 1.1896e-01, 2.6928e-02, 1.6479e-01,\n",
      "         4.3051e-01, 7.8354e-02, 1.6581e-02, 2.3889e-03],\n",
      "        [5.9776e-05, 2.1608e-04, 9.6028e-03, 7.6569e-01, 1.0406e-01, 1.7532e-02,\n",
      "         1.3304e-02, 7.9705e-02, 9.1723e-03, 6.5979e-04]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12.19, Train Loss: 1.60, Val Loss: 4.59, Train BLEU: 30.37, Val BLEU: 10.77, Minutes Elapsed: 640.50\n",
      "Sampling from training predictions...\n",
      "Source: vậy_là cuộc_sống đã phải thay_đổi . <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: so life had to change . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> so life has to change . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9818, 0.0181, 0.0001, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0504, 0.9255, 0.0043, 0.0195, 0.0004, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0058, 0.1579, 0.1701, 0.6526, 0.0120, 0.0014, 0.0002, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0112, 0.0439, 0.0600, 0.8251, 0.0548, 0.0043, 0.0008, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0004, 0.0081, 0.0056, 0.1123, 0.5824, 0.1970, 0.0942, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0027, 0.0099, 0.0039, 0.0111, 0.1890, 0.2607, 0.5228, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0264, 0.5017, 0.0162, 0.0279, 0.2125, 0.0565, 0.1588, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0536, 0.6878, 0.0499, 0.1643, 0.0054, 0.0213, 0.0176, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0089, 0.0334, 0.1275, 0.7274, 0.0591, 0.0201, 0.0237, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: chúng_tôi có_thể thực_hiện sự quan_sát với tần_số cao để có\n",
      "Reference: we can do <UNK> monitoring to get objective data\n",
      "Model: <SOS> how can do high high high to high to\n",
      "Attention Weights: tensor([[2.4833e-01, 7.3421e-01, 1.5608e-02, 1.5619e-03, 1.5664e-04, 1.2981e-04,\n",
      "         2.2304e-06, 9.5226e-07, 9.2045e-07, 2.1066e-07],\n",
      "        [8.5704e-02, 5.6048e-02, 8.5531e-01, 2.0363e-03, 8.3901e-04, 4.3229e-05,\n",
      "         1.5220e-05, 5.5427e-06, 9.2735e-07, 3.3991e-07],\n",
      "        [1.4490e-03, 2.4655e-02, 8.9743e-01, 5.7811e-02, 1.7616e-02, 7.4725e-04,\n",
      "         2.5327e-04, 3.7758e-05, 2.4922e-06, 1.5714e-06],\n",
      "        [1.6043e-05, 3.0233e-04, 8.5201e-02, 6.1052e-01, 2.7027e-01, 2.9825e-02,\n",
      "         3.3448e-03, 4.6728e-04, 5.0088e-05, 6.8199e-06],\n",
      "        [1.1551e-04, 1.3862e-04, 1.0976e-02, 1.5630e-01, 4.5376e-01, 2.3036e-01,\n",
      "         1.0330e-01, 3.7985e-02, 6.4996e-03, 5.6741e-04],\n",
      "        [2.6898e-05, 3.0600e-05, 1.2503e-03, 1.0258e-02, 8.8115e-02, 4.6034e-01,\n",
      "         2.7109e-01, 9.7331e-02, 6.1572e-02, 9.9874e-03],\n",
      "        [2.2968e-06, 4.9284e-06, 1.0996e-04, 1.0075e-03, 1.5259e-03, 2.1183e-02,\n",
      "         3.1632e-02, 1.5976e-01, 5.1119e-01, 2.7359e-01],\n",
      "        [4.3647e-06, 2.9628e-05, 2.0067e-04, 3.1139e-04, 1.7215e-03, 3.2300e-03,\n",
      "         1.1256e-02, 5.8302e-02, 3.9977e-01, 5.2517e-01],\n",
      "        [2.7978e-06, 1.3087e-05, 6.0020e-04, 5.3521e-04, 4.6768e-03, 8.4734e-03,\n",
      "         4.4674e-02, 9.9336e-02, 2.9650e-01, 5.4519e-01]])\n",
      "\n",
      "Epoch: 12.24, Train Loss: 1.54, Val Loss: 4.53, Train BLEU: 31.23, Val BLEU: 10.51, Minutes Elapsed: 642.99\n",
      "Sampling from training predictions...\n",
      "Source: từ điểm này , tôi bắt_đầu suy_nghĩ liệu các y_tá\n",
      "Reference: and from that point on i started thinking ,\n",
      "Model: <SOS> from this this point , i started thinking think\n",
      "Attention Weights: tensor([[8.4595e-01, 1.3900e-01, 1.4976e-02, 1.5777e-05, 1.3944e-05, 4.4635e-05,\n",
      "         5.4112e-08, 4.8009e-08, 2.6312e-08, 1.1024e-08],\n",
      "        [1.7156e-02, 8.2842e-01, 5.5241e-02, 9.3866e-02, 9.8744e-04, 4.0720e-03,\n",
      "         1.4704e-04, 5.9452e-05, 1.4954e-05, 4.0031e-05],\n",
      "        [1.2220e-02, 7.9797e-01, 8.1538e-02, 6.9580e-02, 5.7200e-03, 2.4606e-02,\n",
      "         6.8812e-03, 9.2051e-04, 2.9699e-04, 2.6667e-04],\n",
      "        [3.3013e-02, 5.3161e-01, 1.3924e-01, 1.2287e-01, 2.6897e-02, 1.2626e-01,\n",
      "         1.5737e-02, 3.1952e-03, 7.7722e-04, 3.9870e-04],\n",
      "        [3.3568e-03, 4.5525e-02, 7.4783e-02, 5.6091e-01, 2.1924e-01, 7.2307e-02,\n",
      "         1.7832e-02, 4.0088e-03, 9.3720e-04, 1.0982e-03],\n",
      "        [6.4275e-04, 6.3596e-03, 2.7860e-03, 5.1399e-02, 1.2153e-01, 7.4224e-01,\n",
      "         5.7535e-02, 9.3499e-03, 4.7924e-03, 3.3669e-03],\n",
      "        [4.9672e-04, 3.3126e-03, 7.3375e-04, 6.5509e-03, 5.6393e-02, 6.5726e-01,\n",
      "         2.3794e-01, 2.3113e-02, 8.2639e-03, 5.9386e-03],\n",
      "        [3.6073e-04, 6.0017e-03, 2.1301e-03, 3.6566e-02, 3.1404e-02, 4.1821e-01,\n",
      "         3.0520e-01, 1.5644e-01, 2.3256e-02, 2.0434e-02],\n",
      "        [1.0637e-04, 2.5131e-03, 4.3858e-04, 2.8721e-03, 4.9904e-03, 2.1531e-02,\n",
      "         5.3292e-01, 2.6660e-01, 1.0782e-01, 6.0211e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: chúng_tôi đã gặp_may với việc lau ảnh bằng tay .\n",
      "Reference: now , we were lucky with our <UNK> .\n",
      "Model: <SOS> we &apos;ve &apos;ve had to with with with by\n",
      "Attention Weights: tensor([[9.1540e-02, 5.5403e-01, 3.5371e-01, 7.1826e-04, 3.0711e-06, 4.3976e-07,\n",
      "         8.0723e-07, 8.8665e-07, 5.9210e-08, 9.2924e-09],\n",
      "        [7.8957e-04, 1.5743e-02, 9.8263e-01, 7.9240e-04, 2.9315e-05, 8.4536e-06,\n",
      "         2.6240e-06, 1.2991e-06, 1.0438e-07, 1.9797e-08],\n",
      "        [2.2914e-04, 1.5754e-02, 8.7777e-01, 8.8680e-02, 1.1802e-02, 4.8059e-03,\n",
      "         7.6338e-04, 1.6438e-04, 2.8273e-05, 1.7894e-06],\n",
      "        [5.1835e-03, 6.6338e-02, 8.7083e-01, 5.0145e-02, 4.5939e-03, 2.2446e-03,\n",
      "         4.9854e-04, 1.3513e-04, 2.6565e-05, 1.1869e-06],\n",
      "        [6.3620e-03, 8.7644e-02, 7.3514e-01, 1.3706e-01, 1.9954e-02, 1.0194e-02,\n",
      "         2.6135e-03, 9.0495e-04, 1.1867e-04, 4.8218e-06],\n",
      "        [3.4502e-04, 1.3009e-04, 3.4046e-02, 2.6838e-01, 3.5175e-01, 2.3505e-01,\n",
      "         8.6685e-02, 2.1317e-02, 2.2512e-03, 4.3687e-05],\n",
      "        [5.5295e-04, 3.7988e-05, 1.7255e-02, 1.0544e-01, 3.1129e-01, 3.4761e-01,\n",
      "         1.6170e-01, 4.5725e-02, 9.7178e-03, 6.6969e-04],\n",
      "        [2.1363e-04, 1.5074e-04, 2.6546e-03, 6.4675e-03, 1.1307e-01, 4.1714e-01,\n",
      "         1.9164e-01, 1.8159e-01, 8.3376e-02, 3.7080e-03],\n",
      "        [5.3981e-05, 1.4227e-05, 3.8532e-04, 5.5775e-04, 9.8790e-03, 1.4324e-01,\n",
      "         1.6402e-01, 3.5488e-01, 2.8096e-01, 4.6009e-02]])\n",
      "\n",
      "Epoch: 12.29, Train Loss: 1.58, Val Loss: 4.56, Train BLEU: 29.50, Val BLEU: 10.00, Minutes Elapsed: 645.47\n",
      "Sampling from training predictions...\n",
      "Source: vấn_đề ở chỗ nào ? <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: and what went wrong ? <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> and problem problem the ? <EOS> ? ? <EOS>\n",
      "Attention Weights: tensor([[0.9716, 0.0283, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.8086, 0.1397, 0.0440, 0.0073, 0.0004, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.3688, 0.4313, 0.1488, 0.0492, 0.0014, 0.0004, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2784, 0.1883, 0.4326, 0.0928, 0.0054, 0.0024, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4359, 0.2086, 0.2180, 0.1131, 0.0171, 0.0073, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0505, 0.0646, 0.3282, 0.4395, 0.0640, 0.0533, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0096, 0.0374, 0.3812, 0.0711, 0.2773, 0.2234, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0716, 0.1241, 0.2863, 0.1061, 0.1601, 0.2518, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0068, 0.0498, 0.4202, 0.1209, 0.2040, 0.1983, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: mỗi đứa con_trai từ 6 đến 9 tuổi , trong\n",
      "Reference: so a boy , from six to nine years\n",
      "Model: <SOS> every child the of from six age in ,\n",
      "Attention Weights: tensor([[9.0974e-01, 8.3114e-02, 7.0369e-03, 8.5965e-05, 1.3918e-05, 2.3953e-06,\n",
      "         1.6894e-06, 1.0722e-06, 4.7468e-09, 1.1726e-09],\n",
      "        [3.1272e-01, 3.6740e-01, 3.1068e-01, 5.3129e-03, 3.3139e-03, 3.2626e-04,\n",
      "         1.6645e-04, 8.3805e-05, 5.2971e-06, 3.1341e-06],\n",
      "        [1.1532e-01, 1.8207e-01, 4.1661e-01, 1.8699e-01, 7.2767e-02, 1.4466e-02,\n",
      "         6.2588e-03, 5.1354e-03, 3.0546e-04, 7.6167e-05],\n",
      "        [1.8753e-01, 2.3530e-01, 3.5015e-01, 1.7433e-01, 3.1369e-02, 8.9684e-03,\n",
      "         5.7111e-03, 6.0952e-03, 4.1970e-04, 1.2601e-04],\n",
      "        [1.7785e-02, 2.2788e-02, 2.1152e-01, 2.2053e-01, 2.6086e-01, 1.2177e-01,\n",
      "         9.2541e-02, 3.9122e-02, 1.1096e-02, 2.0009e-03],\n",
      "        [4.1225e-04, 2.5198e-03, 1.7983e-01, 3.7818e-02, 3.5703e-01, 1.4481e-01,\n",
      "         1.6591e-01, 9.8101e-02, 1.1021e-02, 2.5350e-03],\n",
      "        [2.7060e-03, 3.2642e-03, 1.3798e-01, 5.2185e-02, 8.3485e-02, 2.3558e-01,\n",
      "         3.2381e-01, 1.4118e-01, 1.1767e-02, 8.0441e-03],\n",
      "        [7.9567e-06, 1.6141e-05, 1.7372e-03, 5.8380e-03, 8.0795e-02, 2.6690e-01,\n",
      "         3.6988e-01, 2.2923e-01, 3.0426e-02, 1.5170e-02],\n",
      "        [2.2152e-07, 1.6012e-06, 3.2588e-04, 7.0170e-04, 3.2143e-02, 1.5017e-01,\n",
      "         5.1287e-01, 1.8143e-01, 8.6240e-02, 3.6121e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12.38, Train Loss: 1.67, Val Loss: 4.57, Train BLEU: 28.56, Val BLEU: 10.27, Minutes Elapsed: 650.45\n",
      "Sampling from training predictions...\n",
      "Source: tôi đến gần với cái chết như thế_này <EOS> <PAD>\n",
      "Reference: i came this close to doing it . <EOS>\n",
      "Model: <SOS> i i to close to the . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.7116, 0.2875, 0.0007, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0156, 0.9758, 0.0080, 0.0004, 0.0001, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0914, 0.5238, 0.3501, 0.0126, 0.0093, 0.0123, 0.0004, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0008, 0.0235, 0.3875, 0.3020, 0.1308, 0.1344, 0.0145, 0.0060, 0.0004,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0037, 0.1647, 0.3795, 0.3011, 0.1279, 0.0147, 0.0072, 0.0011,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0014, 0.0122, 0.1385, 0.2048, 0.2115, 0.0745, 0.2662, 0.0909,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0002, 0.0004, 0.0058, 0.0383, 0.0508, 0.0650, 0.5632, 0.2762,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0001, 0.0002, 0.0018, 0.0188, 0.0329, 0.0466, 0.4995, 0.4002,\n",
      "         0.0000],\n",
      "        [0.0131, 0.0077, 0.0016, 0.0028, 0.0148, 0.0211, 0.0597, 0.4600, 0.4192,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: người bản_địa , những con_người khát_khao . đó là những\n",
      "Reference: local , passionate people . that &apos;s who you\n",
      "Model: <SOS> the , the people , they are are .\n",
      "Attention Weights: tensor([[9.6581e-01, 3.3931e-02, 2.5192e-04, 3.7937e-06, 6.3949e-08, 1.4965e-07,\n",
      "         1.3133e-08, 6.6398e-10, 4.4391e-10, 3.0941e-11],\n",
      "        [3.0669e-03, 1.6117e-01, 7.9788e-01, 2.4089e-02, 9.3832e-03, 4.0849e-03,\n",
      "         2.2789e-04, 4.7714e-05, 4.7068e-05, 9.1227e-06],\n",
      "        [1.5302e-03, 6.5820e-02, 2.1966e-01, 3.4291e-01, 2.8556e-01, 7.1110e-02,\n",
      "         9.8928e-03, 2.2035e-03, 9.4036e-04, 3.7137e-04],\n",
      "        [1.3490e-04, 1.8372e-03, 7.5134e-02, 4.2338e-01, 4.0823e-01, 7.8366e-02,\n",
      "         8.9534e-03, 2.7115e-03, 9.0450e-04, 3.4184e-04],\n",
      "        [2.0190e-05, 4.8233e-04, 2.0942e-02, 2.8540e-02, 5.4210e-02, 1.0143e-01,\n",
      "         6.3701e-01, 1.1508e-01, 3.7780e-02, 4.5031e-03],\n",
      "        [1.9571e-08, 2.0318e-06, 2.4939e-04, 1.0391e-02, 1.8507e-02, 1.9153e-02,\n",
      "         2.7051e-01, 3.9516e-01, 2.4047e-01, 4.5560e-02],\n",
      "        [2.3513e-07, 1.7933e-05, 9.8940e-05, 1.7794e-02, 3.1075e-01, 1.3679e-01,\n",
      "         1.2537e-01, 9.1410e-02, 1.8077e-01, 1.3700e-01],\n",
      "        [3.6185e-07, 2.0471e-05, 2.7953e-04, 1.9446e-03, 8.7139e-03, 1.1277e-02,\n",
      "         1.4590e-01, 7.2902e-02, 4.5834e-01, 3.0062e-01],\n",
      "        [2.6729e-07, 6.8259e-05, 1.3409e-04, 1.4555e-03, 1.4611e-02, 2.9005e-02,\n",
      "         5.4814e-01, 4.4525e-02, 2.2814e-01, 1.3392e-01]])\n",
      "\n",
      "Epoch: 12.43, Train Loss: 1.76, Val Loss: 4.52, Train BLEU: 25.69, Val BLEU: 10.06, Minutes Elapsed: 652.96\n",
      "Sampling from training predictions...\n",
      "Source: và đó sự khôi_hài với tôi , bởi_vì trầm_cảm là\n",
      "Reference: and that &apos;s ironic to me , because depression\n",
      "Model: <SOS> and that doesn , , me , because the\n",
      "Attention Weights: tensor([[9.3062e-04, 9.9322e-01, 3.2272e-03, 2.5998e-03, 2.2369e-05, 2.8608e-07,\n",
      "         4.4594e-09, 2.2847e-09, 1.5055e-09, 1.0067e-09],\n",
      "        [2.5565e-03, 8.8605e-01, 2.4122e-02, 8.6651e-02, 6.0509e-04, 8.1570e-06,\n",
      "         4.0887e-06, 1.1983e-06, 7.2724e-07, 4.2705e-08],\n",
      "        [1.4667e-04, 1.5223e-02, 2.6545e-01, 6.5987e-01, 5.7228e-02, 8.0956e-04,\n",
      "         7.3855e-04, 2.0474e-04, 3.1604e-04, 1.4583e-05],\n",
      "        [5.4182e-04, 4.6910e-02, 2.7882e-01, 4.9554e-01, 1.5123e-01, 7.7495e-03,\n",
      "         1.4587e-02, 1.5060e-03, 2.8647e-03, 2.4757e-04],\n",
      "        [5.9034e-05, 1.9951e-03, 1.2105e-02, 2.4713e-01, 4.0390e-01, 1.0247e-01,\n",
      "         1.4401e-01, 5.4547e-02, 2.9300e-02, 4.4814e-03],\n",
      "        [1.8839e-05, 8.3146e-04, 1.0365e-02, 2.2834e-01, 3.9841e-01, 1.0001e-01,\n",
      "         1.6189e-01, 8.3035e-02, 1.4605e-02, 2.4943e-03],\n",
      "        [2.8036e-06, 1.8693e-04, 1.8337e-04, 3.4120e-03, 1.4067e-02, 9.7439e-03,\n",
      "         2.6234e-01, 4.3239e-01, 2.6098e-01, 1.6687e-02],\n",
      "        [4.2196e-05, 2.0384e-04, 4.2525e-04, 1.3050e-02, 1.4078e-02, 6.8046e-03,\n",
      "         1.8924e-01, 7.1647e-01, 5.4157e-02, 5.5217e-03],\n",
      "        [1.5621e-05, 2.3541e-04, 4.8404e-04, 1.3593e-03, 1.1699e-02, 3.0364e-03,\n",
      "         4.7869e-02, 4.0124e-01, 5.0563e-01, 2.8429e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: cảm_ơn . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: thank you . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> thank you . <EOS> you <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0014, 0.0154, 0.9833, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1303, 0.8588, 0.0108, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1237, 0.7078, 0.1685, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0696, 0.2263, 0.7041, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2144, 0.6703, 0.1153, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1011, 0.1855, 0.7134, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0703, 0.7993, 0.1304, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0769, 0.8649, 0.0581, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0521, 0.9118, 0.0360, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 12.48, Train Loss: 1.74, Val Loss: 4.51, Train BLEU: 27.34, Val BLEU: 11.07, Minutes Elapsed: 655.44\n",
      "Sampling from training predictions...\n",
      "Source: cô nói , \" dĩ_nhiên , cháu biết đấy ,\n",
      "Reference: she said , &quot; of course , you know\n",
      "Model: <SOS> she said , &quot; of course , you know\n",
      "Attention Weights: tensor([[9.4427e-01, 4.4784e-02, 9.4171e-03, 4.3407e-04, 1.0928e-03, 5.5793e-06,\n",
      "         6.5711e-07, 2.0804e-07, 9.9081e-09, 8.6754e-10],\n",
      "        [6.5763e-03, 8.0019e-01, 1.1168e-01, 1.8419e-02, 6.2016e-02, 5.8310e-04,\n",
      "         3.4977e-04, 1.4694e-04, 3.9594e-05, 4.6021e-06],\n",
      "        [1.5889e-02, 3.4919e-01, 3.3722e-01, 2.3737e-01, 5.3211e-02, 2.7649e-03,\n",
      "         2.5872e-03, 1.0469e-03, 6.4184e-04, 8.8614e-05],\n",
      "        [1.8360e-04, 1.7343e-03, 3.0947e-02, 4.3809e-01, 5.2712e-01, 8.8923e-04,\n",
      "         8.0943e-04, 1.1823e-04, 6.8640e-05, 3.6806e-05],\n",
      "        [4.6574e-05, 3.8252e-05, 2.6619e-04, 9.5118e-03, 9.8310e-01, 3.7991e-03,\n",
      "         2.6409e-03, 5.3023e-04, 4.1015e-05, 2.2774e-05],\n",
      "        [7.5803e-05, 2.4203e-04, 3.3871e-04, 1.2203e-02, 7.0115e-01, 1.0330e-01,\n",
      "         1.4472e-01, 3.3641e-02, 3.3124e-03, 1.0145e-03],\n",
      "        [1.1303e-04, 1.3138e-04, 3.5196e-04, 2.9014e-03, 8.7512e-02, 1.2856e-01,\n",
      "         7.0379e-01, 5.7019e-02, 1.2242e-02, 7.3815e-03],\n",
      "        [6.4635e-05, 1.7899e-04, 4.8758e-04, 2.9351e-03, 4.5957e-02, 6.7543e-02,\n",
      "         7.5290e-01, 1.0780e-01, 1.5612e-02, 6.5133e-03],\n",
      "        [1.2533e-05, 2.3360e-04, 2.3938e-04, 2.5198e-03, 4.3199e-02, 2.8073e-02,\n",
      "         2.5722e-01, 4.9834e-01, 1.5714e-01, 1.3019e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: họ đều là nạn_nhân của tổn_thương , bệnh_tật và bạo_lực\n",
      "Reference: all of them are victim to injury , illness\n",
      "Model: <SOS> they &apos;re are are life victims the , and\n",
      "Attention Weights: tensor([[5.4680e-01, 4.3676e-01, 1.6429e-02, 1.6019e-05, 1.8725e-06, 3.8135e-08,\n",
      "         4.3952e-09, 3.1080e-09, 5.7771e-10, 1.9814e-09],\n",
      "        [2.0102e-03, 9.8749e-01, 9.6864e-03, 7.9653e-04, 4.0530e-06, 7.4483e-06,\n",
      "         2.1416e-07, 6.8941e-07, 7.6302e-08, 2.4823e-07],\n",
      "        [6.4436e-03, 3.5496e-01, 3.5343e-01, 2.5769e-01, 2.1117e-02, 6.0290e-03,\n",
      "         1.2429e-04, 1.4942e-04, 2.3499e-05, 2.7426e-05],\n",
      "        [8.5347e-04, 6.6435e-02, 3.9048e-01, 4.3475e-01, 5.1298e-02, 5.0671e-02,\n",
      "         3.2370e-03, 1.9867e-03, 1.1701e-04, 1.6991e-04],\n",
      "        [1.5569e-03, 3.1841e-02, 2.5681e-01, 2.9502e-01, 1.5916e-01, 2.0833e-01,\n",
      "         2.6056e-02, 2.0467e-02, 3.4989e-04, 4.0461e-04],\n",
      "        [9.2161e-05, 2.4374e-03, 4.4345e-02, 7.6588e-01, 7.7128e-02, 8.0375e-02,\n",
      "         1.8680e-02, 1.0628e-02, 2.0085e-04, 2.3702e-04],\n",
      "        [5.7370e-06, 9.4619e-05, 4.7458e-03, 7.7885e-02, 1.3158e-01, 3.3182e-01,\n",
      "         2.4334e-01, 2.0664e-01, 2.1278e-03, 1.7577e-03],\n",
      "        [4.0167e-05, 2.1758e-04, 1.3544e-03, 1.1419e-01, 1.0748e-01, 1.8253e-01,\n",
      "         1.3744e-01, 4.2459e-01, 1.3408e-02, 1.8753e-02],\n",
      "        [2.6652e-06, 1.0697e-05, 2.5088e-04, 5.5476e-03, 2.9853e-02, 5.2189e-02,\n",
      "         2.2117e-01, 6.7778e-01, 7.0774e-03, 6.1116e-03]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12.53, Train Loss: 1.67, Val Loss: 4.53, Train BLEU: 28.14, Val BLEU: 10.25, Minutes Elapsed: 657.95\n",
      "Sampling from training predictions...\n",
      "Source: đau kinh_niên là một ví_dụ . nếu bạn phỏng ,\n",
      "Reference: chronic pain is an example . if you burn\n",
      "Model: <SOS> chronic &apos;s is an example . if you burn\n",
      "Attention Weights: tensor([[9.9610e-01, 3.2720e-03, 4.7023e-04, 1.5724e-04, 4.4508e-07, 1.4864e-09,\n",
      "         2.2843e-10, 3.0600e-10, 2.7663e-10, 3.3207e-13],\n",
      "        [4.0978e-02, 4.0139e-01, 5.2354e-01, 3.3641e-02, 4.0736e-04, 3.8198e-05,\n",
      "         6.2248e-06, 1.5944e-06, 3.9065e-06, 2.8049e-07],\n",
      "        [4.2345e-02, 1.2801e-01, 5.9021e-01, 2.0849e-01, 2.7596e-02, 2.6339e-03,\n",
      "         5.8929e-04, 5.9805e-05, 6.8008e-05, 5.7872e-06],\n",
      "        [1.5981e-03, 4.3489e-02, 9.9943e-02, 1.1075e-01, 4.3586e-01, 1.6242e-01,\n",
      "         1.3199e-01, 8.7294e-03, 4.5372e-03, 6.8144e-04],\n",
      "        [1.5177e-04, 3.4217e-03, 9.6125e-03, 4.5335e-02, 5.0772e-01, 2.1807e-01,\n",
      "         1.5455e-01, 3.4159e-02, 2.3845e-02, 3.1261e-03],\n",
      "        [1.5725e-05, 1.8650e-04, 7.3040e-04, 2.7716e-03, 1.4543e-02, 4.2624e-01,\n",
      "         5.4162e-01, 7.0261e-03, 4.0481e-03, 2.8191e-03],\n",
      "        [5.4212e-07, 4.4457e-05, 1.6585e-04, 1.6146e-04, 4.5299e-03, 9.6279e-02,\n",
      "         8.6180e-01, 2.8163e-02, 6.7798e-03, 2.0721e-03],\n",
      "        [9.4845e-06, 4.2505e-05, 1.2817e-04, 1.1828e-03, 4.1917e-03, 1.0661e-02,\n",
      "         2.1167e-01, 6.7067e-01, 8.8370e-02, 1.3072e-02],\n",
      "        [1.1409e-05, 1.4867e-04, 5.2608e-05, 2.1827e-05, 3.2787e-04, 6.6899e-04,\n",
      "         6.3206e-03, 1.0869e-01, 8.7715e-01, 6.6072e-03]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tương_đương với 50.000 đô - la mỹ ngày_nay . <EOS>\n",
      "Reference: that equates to about $ 50,000 in today &apos;s\n",
      "Model: <SOS> it &apos;s a to third dollar . . .\n",
      "Attention Weights: tensor([[9.9921e-01, 7.8379e-04, 6.8533e-06, 1.2886e-06, 1.1129e-08, 5.2090e-09,\n",
      "         1.2920e-08, 1.0421e-10, 1.2982e-11, 4.8551e-12],\n",
      "        [8.5280e-01, 1.3311e-01, 1.0503e-02, 3.3246e-03, 9.6261e-05, 6.3894e-05,\n",
      "         9.9012e-05, 2.4625e-06, 6.5925e-07, 3.8633e-07],\n",
      "        [5.5215e-01, 2.9372e-01, 7.3184e-02, 6.4638e-02, 7.4234e-03, 4.8394e-03,\n",
      "         3.8536e-03, 1.5130e-04, 2.4335e-05, 1.2167e-05],\n",
      "        [2.5639e-01, 1.5964e-01, 2.6585e-01, 2.5579e-01, 2.6501e-02, 1.5729e-02,\n",
      "         1.8456e-02, 1.4000e-03, 1.7461e-04, 8.2934e-05],\n",
      "        [2.1954e-03, 1.1545e-02, 1.4322e-01, 5.6949e-01, 7.7805e-02, 6.9798e-02,\n",
      "         9.8468e-02, 2.5548e-02, 1.2130e-03, 7.1820e-04],\n",
      "        [1.1146e-04, 6.8418e-04, 5.2175e-02, 2.7554e-01, 1.4030e-01, 2.2212e-01,\n",
      "         2.1452e-01, 9.0362e-02, 3.2822e-03, 9.1128e-04],\n",
      "        [1.7670e-04, 4.8896e-04, 1.7231e-02, 1.0229e-01, 5.2757e-02, 3.0711e-01,\n",
      "         3.4097e-01, 1.6822e-01, 7.5199e-03, 3.2370e-03],\n",
      "        [1.2638e-05, 1.6346e-05, 7.8850e-04, 3.9227e-03, 1.0316e-02, 6.3554e-02,\n",
      "         1.7609e-01, 6.1352e-01, 6.1101e-02, 7.0671e-02],\n",
      "        [2.2139e-04, 8.0899e-04, 2.7622e-03, 2.5189e-02, 3.6243e-02, 1.9291e-01,\n",
      "         2.6959e-01, 2.3587e-01, 4.9195e-02, 1.8720e-01]])\n",
      "\n",
      "Epoch: 12.58, Train Loss: 1.66, Val Loss: 4.55, Train BLEU: 27.80, Val BLEU: 10.83, Minutes Elapsed: 660.47\n",
      "Sampling from training predictions...\n",
      "Source: đây là mức_độ khó_khăn nhất . đây là đỉnh của\n",
      "Reference: this is the hardest level . this is the\n",
      "Model: <SOS> this is the hardest level . this is the\n",
      "Attention Weights: tensor([[7.3675e-01, 1.3438e-01, 1.2808e-01, 7.7745e-04, 2.1626e-05, 1.2493e-08,\n",
      "         2.6687e-09, 2.3404e-10, 2.1543e-10, 1.3266e-11],\n",
      "        [2.2537e-02, 2.5800e-01, 5.9032e-01, 1.2425e-01, 4.8424e-03, 1.9259e-05,\n",
      "         8.4264e-06, 1.2852e-05, 8.4300e-06, 1.0166e-06],\n",
      "        [3.8122e-03, 3.8439e-02, 3.3537e-01, 5.7844e-01, 4.3545e-02, 2.4810e-04,\n",
      "         2.2372e-05, 5.7808e-05, 4.7791e-05, 1.1361e-05],\n",
      "        [8.9517e-05, 4.9444e-03, 4.2775e-02, 8.0794e-01, 1.3375e-01, 9.5002e-03,\n",
      "         2.1294e-04, 1.3370e-04, 6.0773e-04, 4.7189e-05],\n",
      "        [1.4637e-04, 1.3806e-02, 9.6981e-02, 6.7142e-01, 6.8541e-03, 1.7030e-01,\n",
      "         1.9088e-02, 3.8680e-03, 1.6272e-02, 1.2595e-03],\n",
      "        [8.5268e-04, 6.5036e-02, 3.5843e-02, 2.9073e-02, 3.6903e-02, 7.8081e-01,\n",
      "         4.4742e-02, 3.3879e-03, 1.8264e-03, 1.5254e-03],\n",
      "        [6.9194e-07, 1.8861e-05, 4.9210e-05, 4.6652e-05, 4.6948e-04, 3.0964e-01,\n",
      "         6.7462e-01, 1.3634e-02, 1.1423e-03, 3.7923e-04],\n",
      "        [9.5776e-07, 1.2258e-05, 6.5408e-05, 1.3547e-04, 2.7609e-04, 5.1091e-02,\n",
      "         5.9665e-01, 2.8860e-01, 5.9690e-02, 3.4810e-03],\n",
      "        [1.5383e-05, 8.1526e-04, 4.0873e-03, 4.5204e-03, 1.7925e-03, 1.0937e-02,\n",
      "         2.3759e-02, 2.3430e-01, 6.0292e-01, 1.1685e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: đây là vật mẫu được lấy ra . <EOS> <PAD>\n",
      "Reference: so this is the specimen coming out now .\n",
      "Model: <SOS> this is is the object object . . <EOS>\n",
      "Attention Weights: tensor([[0.5416, 0.4549, 0.0035, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0267, 0.5513, 0.3968, 0.0244, 0.0005, 0.0002, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0060, 0.3019, 0.3923, 0.2724, 0.0205, 0.0053, 0.0013, 0.0003, 0.0001,\n",
      "         0.0000],\n",
      "        [0.0052, 0.3299, 0.2531, 0.3734, 0.0234, 0.0116, 0.0030, 0.0005, 0.0001,\n",
      "         0.0000],\n",
      "        [0.0040, 0.1200, 0.1861, 0.5396, 0.0860, 0.0485, 0.0085, 0.0056, 0.0018,\n",
      "         0.0000],\n",
      "        [0.0005, 0.1116, 0.0484, 0.5393, 0.0916, 0.1225, 0.0529, 0.0248, 0.0085,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0101, 0.0020, 0.0259, 0.1733, 0.2324, 0.4361, 0.0935, 0.0267,\n",
      "         0.0000],\n",
      "        [0.0010, 0.0104, 0.0027, 0.0118, 0.0750, 0.3747, 0.3702, 0.0726, 0.0815,\n",
      "         0.0000],\n",
      "        [0.0010, 0.0027, 0.0022, 0.0144, 0.0512, 0.1452, 0.1858, 0.1087, 0.4889,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 12.67, Train Loss: 1.68, Val Loss: 4.53, Train BLEU: 27.43, Val BLEU: 10.56, Minutes Elapsed: 665.44\n",
      "Sampling from training predictions...\n",
      "Source: và đó là thực_sự tuyệt_vời và tuyệt_vời . <EOS> <PAD>\n",
      "Reference: and it &apos;s truly awesome and wondrous . <EOS>\n",
      "Model: <SOS> and that &apos;s truly wonderful and wondrous . <EOS>\n",
      "Attention Weights: tensor([[0.0008, 0.1592, 0.8372, 0.0029, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0089, 0.6974, 0.2619, 0.0318, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0052, 0.1555, 0.7693, 0.0692, 0.0002, 0.0004, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0003, 0.1458, 0.4079, 0.4433, 0.0008, 0.0019, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0001, 0.0033, 0.1499, 0.8308, 0.0078, 0.0079, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0002, 0.0035, 0.1520, 0.7682, 0.0457, 0.0279, 0.0019, 0.0005,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0003, 0.0019, 0.0214, 0.2645, 0.0986, 0.5218, 0.0567, 0.0348,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0001, 0.0002, 0.0024, 0.0063, 0.0466, 0.5265, 0.2805, 0.1374,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0004, 0.0030, 0.0108, 0.0234, 0.0230, 0.2568, 0.1272, 0.5552,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: cái quan_trọng nhất là khát_vọng . <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: the most important thing is passion . <EOS> <PAD>\n",
      "Model: <SOS> the most important thing the . . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.7585, 0.2398, 0.0017, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0127, 0.9540, 0.0324, 0.0007, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0696, 0.8832, 0.0198, 0.0248, 0.0025, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1013, 0.1191, 0.3726, 0.3165, 0.0821, 0.0061, 0.0023, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0024, 0.0066, 0.0414, 0.5200, 0.3667, 0.0489, 0.0140, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0014, 0.0030, 0.1443, 0.7802, 0.0400, 0.0311, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0094, 0.0082, 0.1250, 0.6945, 0.0647, 0.0979, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0010, 0.0093, 0.0240, 0.0655, 0.5382, 0.0854, 0.2766, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0063, 0.3014, 0.0385, 0.1258, 0.1364, 0.0871, 0.3046, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 12.72, Train Loss: 1.75, Val Loss: 4.56, Train BLEU: 26.94, Val BLEU: 10.38, Minutes Elapsed: 667.90\n",
      "Sampling from training predictions...\n",
      "Source: chúng_ta cần phải lên tiếng_nói và phá_tan sự im_lặng .\n",
      "Reference: we need to speak up and shatter the silence\n",
      "Model: <SOS> we need to be up and shatter . silence\n",
      "Attention Weights: tensor([[5.3721e-03, 4.9146e-01, 5.0244e-01, 7.2177e-04, 6.9825e-06, 1.8711e-08,\n",
      "         6.4826e-09, 2.4861e-08, 7.8085e-09, 3.1408e-10],\n",
      "        [4.5217e-04, 9.0176e-01, 9.2645e-02, 4.7176e-03, 4.0416e-04, 3.9582e-06,\n",
      "         8.2761e-06, 4.5612e-06, 4.7384e-06, 1.6409e-07],\n",
      "        [3.8605e-03, 3.2880e-01, 4.6687e-01, 1.7257e-01, 2.6969e-02, 2.6775e-04,\n",
      "         2.9789e-04, 1.8545e-04, 1.7062e-04, 1.3948e-05],\n",
      "        [3.4220e-05, 7.9313e-04, 6.9101e-02, 7.5866e-01, 1.7048e-01, 3.5464e-04,\n",
      "         3.4943e-04, 8.3474e-05, 1.4051e-04, 5.8469e-06],\n",
      "        [6.6090e-07, 6.3756e-05, 1.2552e-02, 5.4875e-01, 4.2362e-01, 6.1022e-03,\n",
      "         3.4080e-03, 2.8137e-03, 2.6561e-03, 3.7224e-05],\n",
      "        [1.2504e-05, 6.4899e-05, 9.4739e-04, 4.7267e-02, 6.6620e-01, 1.0428e-01,\n",
      "         8.2636e-02, 1.9877e-02, 7.8066e-02, 6.4738e-04],\n",
      "        [1.2855e-05, 4.7658e-04, 1.8835e-03, 1.2611e-02, 1.3956e-01, 2.0534e-01,\n",
      "         3.2440e-01, 1.4318e-01, 1.6736e-01, 5.1764e-03],\n",
      "        [2.3635e-05, 7.6889e-04, 3.2198e-03, 8.5354e-03, 2.2198e-02, 3.6382e-02,\n",
      "         2.7345e-01, 1.7927e-01, 4.6077e-01, 1.5386e-02],\n",
      "        [1.4633e-05, 6.3753e-05, 8.8422e-04, 4.9728e-03, 5.2438e-03, 1.4159e-02,\n",
      "         6.8270e-02, 2.1170e-01, 5.8257e-01, 1.1212e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: <UNK> dãy các thông_tin . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: <UNK> thousand eight hundred thirty lines of information .\n",
      "Model: <SOS> it &apos;re <EOS> . <EOS> <EOS> <EOS> <EOS> .\n",
      "Attention Weights: tensor([[0.4407, 0.5507, 0.0064, 0.0022, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0735, 0.4477, 0.3039, 0.1715, 0.0033, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0242, 0.1017, 0.6408, 0.2082, 0.0226, 0.0024, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0109, 0.1825, 0.0978, 0.2234, 0.2055, 0.2798, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0009, 0.0304, 0.0063, 0.0100, 0.1802, 0.7723, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0032, 0.1289, 0.0144, 0.0498, 0.4935, 0.3102, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0048, 0.1199, 0.0100, 0.0251, 0.2736, 0.5665, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0054, 0.1836, 0.0382, 0.1208, 0.2504, 0.4017, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0148, 0.3326, 0.1857, 0.0641, 0.1065, 0.2962, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12.77, Train Loss: 1.69, Val Loss: 4.57, Train BLEU: 28.25, Val BLEU: 10.58, Minutes Elapsed: 670.38\n",
      "Sampling from training predictions...\n",
      "Source: đó là cả một phòng_thí_nghiệm di_động để giúp chúng_tôi thực_hiện\n",
      "Reference: it &apos;s a flying laboratory that we took to\n",
      "Model: <SOS> it &apos;s a a laboratory laboratory we took to\n",
      "Attention Weights: tensor([[8.8250e-01, 1.1003e-01, 7.4348e-03, 3.7466e-05, 4.3364e-07, 5.7919e-08,\n",
      "         2.2443e-09, 1.9344e-09, 4.0625e-11, 5.0332e-11],\n",
      "        [5.4646e-03, 5.2878e-01, 4.3896e-01, 2.0571e-02, 5.4153e-03, 6.1283e-04,\n",
      "         1.0882e-04, 7.4828e-05, 5.0146e-06, 4.9749e-06],\n",
      "        [1.0144e-02, 2.2486e-01, 6.7821e-01, 4.1305e-02, 3.8304e-02, 6.3343e-03,\n",
      "         3.8727e-04, 3.2337e-04, 4.3928e-05, 8.5881e-05],\n",
      "        [7.0399e-05, 2.4180e-03, 2.4781e-01, 3.4912e-02, 5.8203e-01, 1.3146e-01,\n",
      "         7.8244e-04, 2.9743e-04, 9.4901e-05, 1.3087e-04],\n",
      "        [4.3101e-05, 4.2523e-03, 7.4159e-02, 5.3785e-02, 7.5348e-01, 9.9944e-02,\n",
      "         9.0298e-03, 4.4168e-03, 4.2615e-04, 4.6821e-04],\n",
      "        [9.1473e-04, 4.1407e-03, 1.9488e-02, 1.1602e-02, 5.4632e-01, 2.1360e-01,\n",
      "         1.1107e-01, 7.7742e-02, 5.5391e-03, 9.5802e-03],\n",
      "        [2.0457e-06, 1.1426e-04, 1.2620e-04, 1.0640e-03, 3.3164e-02, 2.8100e-02,\n",
      "         2.3267e-01, 6.3337e-01, 2.5006e-02, 4.6383e-02],\n",
      "        [2.3238e-06, 2.3226e-05, 5.5812e-05, 8.3410e-05, 6.7594e-04, 1.6815e-03,\n",
      "         5.0931e-02, 5.8120e-01, 9.0846e-02, 2.7451e-01],\n",
      "        [1.4569e-05, 1.9187e-04, 2.0306e-04, 9.0448e-04, 2.6280e-03, 2.6520e-03,\n",
      "         8.2843e-03, 6.3056e-02, 9.1165e-02, 8.3090e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: những việc các bạn làm là đun nóng thép ,\n",
      "Reference: then what you do is you heat up the\n",
      "Model: <SOS> what you you &apos;re is is <UNK> very ,\n",
      "Attention Weights: tensor([[2.0531e-02, 9.7942e-01, 3.7748e-05, 1.1807e-05, 2.5945e-06, 6.7440e-08,\n",
      "         4.7652e-09, 4.4474e-10, 1.6806e-10, 2.3201e-12],\n",
      "        [1.9743e-02, 7.3814e-01, 1.6001e-01, 3.8831e-02, 4.2714e-02, 4.1528e-04,\n",
      "         1.2527e-04, 1.9148e-05, 3.5341e-06, 1.7267e-07],\n",
      "        [7.5368e-02, 3.2884e-01, 1.7730e-01, 1.1530e-01, 2.3691e-01, 4.1346e-02,\n",
      "         2.0316e-02, 3.4384e-03, 1.1619e-03, 3.0704e-05],\n",
      "        [2.4231e-02, 1.5296e-01, 7.8277e-02, 2.0796e-01, 3.4886e-01, 1.5636e-01,\n",
      "         2.3149e-02, 5.9628e-03, 2.2018e-03, 2.9011e-05],\n",
      "        [5.4446e-03, 3.5735e-02, 4.1142e-03, 4.4351e-02, 4.4671e-01, 4.0041e-01,\n",
      "         4.9761e-02, 1.1451e-02, 1.9754e-03, 4.3505e-05],\n",
      "        [4.2268e-04, 3.0315e-04, 2.2335e-04, 2.1051e-03, 2.9249e-02, 4.4058e-01,\n",
      "         1.8672e-01, 1.3856e-01, 1.9989e-01, 1.9427e-03],\n",
      "        [3.4755e-04, 4.5387e-04, 5.7936e-04, 1.6569e-03, 3.5837e-02, 2.2912e-01,\n",
      "         3.7567e-01, 1.1093e-01, 2.3883e-01, 6.5797e-03],\n",
      "        [8.8750e-07, 1.7522e-05, 7.0427e-06, 1.5894e-04, 2.9852e-03, 1.2734e-02,\n",
      "         4.9480e-01, 2.6167e-01, 2.0198e-01, 2.5645e-02],\n",
      "        [2.3445e-07, 1.3931e-05, 1.6799e-06, 6.8435e-06, 3.2973e-04, 2.5773e-02,\n",
      "         4.3488e-01, 1.9565e-01, 2.0485e-01, 1.3850e-01]])\n",
      "\n",
      "Epoch: 12.82, Train Loss: 1.68, Val Loss: 4.58, Train BLEU: 28.12, Val BLEU: 11.00, Minutes Elapsed: 672.85\n",
      "Sampling from training predictions...\n",
      "Source: và âm_nhạc ở đó , tôi cho_rằng , những nhạc_cụ\n",
      "Reference: and the music there , i would say ,\n",
      "Model: <SOS> and it &apos;s there , i think , ,\n",
      "Attention Weights: tensor([[1.2940e-05, 9.9997e-01, 1.5746e-05, 2.6675e-07, 4.3776e-10, 1.3370e-09,\n",
      "         7.8214e-11, 8.9743e-13, 2.1257e-13, 9.3279e-14],\n",
      "        [1.7192e-03, 9.9816e-01, 8.7461e-05, 3.2233e-05, 1.4432e-06, 5.6021e-07,\n",
      "         2.7042e-08, 6.6032e-10, 6.7624e-10, 3.9032e-10],\n",
      "        [2.4356e-04, 8.8171e-01, 7.6566e-02, 2.5539e-02, 1.2622e-02, 2.0598e-03,\n",
      "         1.1974e-03, 2.4803e-05, 1.3045e-05, 1.9956e-05],\n",
      "        [5.5075e-04, 1.3335e-01, 3.3598e-01, 1.3326e-01, 2.9423e-01, 2.4194e-02,\n",
      "         7.3900e-02, 2.8531e-03, 6.4406e-04, 1.0379e-03],\n",
      "        [9.1202e-06, 2.6228e-02, 1.0879e-01, 1.3487e-01, 5.4676e-01, 1.4316e-01,\n",
      "         3.5234e-02, 2.4014e-03, 8.9744e-04, 1.6428e-03],\n",
      "        [3.7331e-06, 4.3383e-02, 7.7647e-02, 2.6042e-02, 2.7815e-01, 1.5210e-01,\n",
      "         3.9393e-01, 1.4358e-02, 8.4504e-03, 5.9345e-03],\n",
      "        [7.8013e-06, 7.6714e-03, 9.6355e-03, 3.4242e-03, 9.7617e-02, 2.7835e-01,\n",
      "         5.5957e-01, 1.4060e-02, 1.4136e-02, 1.5525e-02],\n",
      "        [5.2788e-06, 8.5905e-04, 8.3648e-03, 3.6409e-04, 5.8215e-03, 3.0224e-03,\n",
      "         8.2609e-01, 1.1427e-01, 9.9956e-03, 3.1209e-02],\n",
      "        [3.9903e-05, 4.6838e-04, 1.3355e-04, 2.7374e-04, 2.3997e-03, 1.0081e-03,\n",
      "         3.1466e-03, 1.4000e-01, 5.0088e-01, 3.5165e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: sáng nay , người tổ_chức buổi họp này đặt một\n",
      "Reference: this morning , the gentleman who opened this conference\n",
      "Model: <SOS> now , , his young man his a head\n",
      "Attention Weights: tensor([[9.9665e-01, 2.8377e-03, 4.8654e-04, 2.1162e-05, 1.0425e-07, 9.9159e-09,\n",
      "         8.8339e-09, 4.9961e-09, 8.1816e-10, 6.3768e-11],\n",
      "        [4.3638e-01, 3.4534e-01, 1.8670e-01, 2.5072e-02, 4.7314e-03, 1.1019e-03,\n",
      "         5.9850e-04, 3.3022e-05, 2.2167e-05, 1.1480e-05],\n",
      "        [9.0221e-02, 1.1318e-01, 2.0697e-01, 3.5783e-01, 1.6440e-01, 4.0401e-02,\n",
      "         1.7355e-02, 5.6223e-03, 2.5206e-03, 1.5064e-03],\n",
      "        [2.5542e-03, 7.8567e-04, 7.9528e-03, 2.3197e-01, 3.8568e-01, 1.4214e-01,\n",
      "         1.3665e-01, 2.5880e-02, 3.8212e-02, 2.8180e-02],\n",
      "        [3.7471e-05, 1.6150e-05, 5.5828e-05, 9.6662e-03, 1.8911e-01, 1.9182e-01,\n",
      "         2.6962e-01, 8.9165e-02, 1.8058e-01, 6.9928e-02],\n",
      "        [2.2262e-03, 1.5893e-03, 8.7357e-04, 1.7850e-03, 2.3174e-01, 1.3761e-01,\n",
      "         1.2270e-01, 1.8910e-01, 1.6858e-01, 1.4380e-01],\n",
      "        [8.7944e-05, 1.2832e-04, 3.9775e-04, 1.1708e-03, 7.4076e-02, 1.6623e-01,\n",
      "         8.7756e-02, 2.2694e-01, 3.4903e-01, 9.4181e-02],\n",
      "        [1.6542e-07, 4.1612e-07, 7.9030e-07, 2.6360e-06, 1.6588e-03, 5.4698e-02,\n",
      "         2.0546e-01, 4.7141e-02, 3.1768e-01, 3.7335e-01],\n",
      "        [1.3729e-07, 2.0962e-07, 6.0532e-07, 8.1459e-07, 1.1974e-03, 3.0081e-02,\n",
      "         4.7807e-01, 2.8376e-02, 2.0794e-01, 2.5434e-01]])\n",
      "\n",
      "Epoch: 12.86, Train Loss: 1.66, Val Loss: 4.56, Train BLEU: 28.30, Val BLEU: 10.34, Minutes Elapsed: 675.34\n",
      "Sampling from training predictions...\n",
      "Source: ngay khi thử_nghiệm kết_thúc , chúng_ta đã có tên của\n",
      "Reference: by the time the pilot had finished , we\n",
      "Model: <SOS> right the , of , , we , we\n",
      "Attention Weights: tensor([[9.8779e-01, 1.2204e-02, 7.5958e-06, 7.0605e-07, 4.3276e-10, 7.4764e-10,\n",
      "         5.1973e-11, 3.3465e-11, 1.1224e-11, 5.0514e-12],\n",
      "        [3.2876e-01, 2.0735e-01, 4.2571e-01, 3.7862e-02, 8.8136e-05, 9.6317e-05,\n",
      "         8.7277e-05, 2.3732e-05, 1.4343e-05, 5.8337e-06],\n",
      "        [2.2280e-02, 6.4752e-02, 7.9025e-01, 1.1222e-01, 3.0330e-03, 1.9833e-03,\n",
      "         3.6852e-03, 1.2180e-03, 4.5365e-04, 1.2314e-04],\n",
      "        [2.7519e-02, 5.2401e-02, 6.8118e-01, 1.5720e-01, 2.8447e-02, 1.8384e-02,\n",
      "         1.8497e-02, 1.1245e-02, 4.0773e-03, 1.0519e-03],\n",
      "        [9.7631e-03, 5.2423e-02, 4.2218e-01, 3.5668e-01, 6.5879e-02, 2.5348e-02,\n",
      "         5.4999e-02, 9.4318e-03, 2.5399e-03, 7.6071e-04],\n",
      "        [2.1123e-04, 3.3157e-03, 2.8478e-01, 1.9525e-01, 1.0739e-01, 1.2005e-01,\n",
      "         2.2734e-01, 3.7968e-02, 1.9822e-02, 3.8774e-03],\n",
      "        [1.8425e-03, 7.2636e-03, 5.0940e-02, 2.1608e-01, 2.0106e-01, 1.7425e-01,\n",
      "         2.5335e-01, 7.0043e-02, 2.0100e-02, 5.0641e-03],\n",
      "        [1.2272e-05, 8.2695e-04, 2.7200e-02, 1.7480e-02, 9.7190e-02, 1.4740e-01,\n",
      "         4.5159e-01, 2.0971e-01, 4.4939e-02, 3.6544e-03],\n",
      "        [5.6855e-06, 6.1393e-04, 4.8322e-02, 1.3503e-02, 1.2010e-01, 1.1903e-01,\n",
      "         3.6041e-01, 1.5804e-01, 1.5627e-01, 2.3712e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi trả_lời , \" tất_nhiên là không , tôi không\n",
      "Reference: and i &apos;m like , &quot; hell no ,\n",
      "Model: <SOS> i i said , , &quot; of course not\n",
      "Attention Weights: tensor([[6.8027e-01, 3.1185e-01, 4.8045e-03, 2.5116e-04, 2.7035e-03, 1.1378e-04,\n",
      "         1.1072e-05, 4.4774e-08, 3.8286e-08, 6.8754e-07],\n",
      "        [7.9810e-02, 9.0252e-01, 1.0230e-02, 2.5100e-03, 4.8108e-03, 6.7773e-05,\n",
      "         4.7786e-05, 3.0879e-06, 8.5052e-07, 3.1403e-06],\n",
      "        [1.9825e-02, 4.7592e-01, 4.5102e-01, 3.0613e-02, 1.6097e-02, 3.9400e-03,\n",
      "         2.4810e-03, 4.3081e-05, 1.3432e-05, 4.1138e-05],\n",
      "        [1.5288e-01, 4.9066e-01, 1.6553e-01, 9.7693e-02, 8.7572e-02, 3.8827e-03,\n",
      "         1.6359e-03, 6.4270e-05, 2.4209e-05, 5.3979e-05],\n",
      "        [5.7328e-03, 3.5791e-02, 1.5687e-01, 4.3133e-01, 3.6138e-01, 5.2403e-03,\n",
      "         3.0330e-03, 3.3827e-04, 1.1386e-04, 1.7008e-04],\n",
      "        [4.3323e-03, 4.4363e-03, 4.4869e-02, 3.3837e-01, 6.0219e-01, 3.6150e-03,\n",
      "         1.3137e-03, 2.5552e-04, 4.9902e-04, 1.2471e-04],\n",
      "        [2.7579e-03, 2.7119e-04, 2.4432e-03, 8.1008e-02, 8.3869e-01, 5.2153e-02,\n",
      "         1.9055e-02, 1.0786e-03, 1.8413e-03, 7.0370e-04],\n",
      "        [4.3230e-05, 1.0057e-04, 3.5116e-04, 9.6104e-03, 7.9532e-01, 1.0566e-01,\n",
      "         5.5644e-02, 1.4550e-02, 1.1536e-02, 7.1797e-03],\n",
      "        [5.4136e-05, 1.5104e-04, 1.8218e-04, 2.6239e-03, 1.7975e-01, 1.2536e-01,\n",
      "         3.1707e-01, 1.7579e-01, 1.3515e-01, 6.3870e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12.91, Train Loss: 1.55, Val Loss: 4.58, Train BLEU: 30.03, Val BLEU: 10.01, Minutes Elapsed: 677.82\n",
      "Sampling from training predictions...\n",
      "Source: bạn đã lầm . vì_thế tôi đã ngồi ở cạnh\n",
      "Reference: you would be wrong . so i sat there\n",
      "Model: <SOS> you have . . . so i sat in\n",
      "Attention Weights: tensor([[1.0239e-01, 8.4411e-01, 5.3452e-02, 5.3823e-05, 7.8691e-07, 1.1452e-07,\n",
      "         9.3878e-08, 6.9315e-08, 4.3250e-09, 9.0055e-10],\n",
      "        [2.2577e-02, 1.0252e-01, 8.5417e-01, 1.9616e-02, 5.9511e-04, 3.9010e-05,\n",
      "         1.3025e-04, 3.3491e-04, 1.1561e-05, 1.6175e-06],\n",
      "        [3.7882e-02, 2.4534e-01, 6.4096e-01, 5.9284e-02, 9.2543e-03, 3.7708e-04,\n",
      "         2.5581e-03, 4.0940e-03, 2.3656e-04, 1.4739e-05],\n",
      "        [8.6505e-04, 9.4829e-04, 4.5697e-02, 6.2426e-01, 3.1840e-01, 3.7229e-03,\n",
      "         9.7136e-04, 4.3294e-03, 6.0890e-04, 1.9633e-04],\n",
      "        [2.2399e-04, 2.2966e-03, 4.0282e-03, 3.1747e-01, 6.6731e-01, 3.2998e-03,\n",
      "         4.2729e-04, 3.5217e-03, 9.6643e-04, 4.5373e-04],\n",
      "        [2.1401e-03, 7.3403e-04, 7.0213e-04, 9.1216e-02, 8.6957e-01, 2.7699e-02,\n",
      "         4.1254e-03, 1.2291e-03, 1.2392e-03, 1.3412e-03],\n",
      "        [2.8835e-03, 2.1272e-03, 1.2860e-03, 9.2919e-03, 3.5620e-01, 1.8974e-01,\n",
      "         2.5397e-01, 1.6447e-01, 1.4734e-02, 5.3013e-03],\n",
      "        [9.2637e-05, 2.3536e-04, 4.5094e-03, 1.4097e-03, 4.5331e-03, 9.4127e-03,\n",
      "         2.2743e-01, 7.3079e-01, 2.0886e-02, 7.0781e-04],\n",
      "        [8.6740e-05, 2.2038e-04, 5.6427e-03, 3.1730e-03, 6.9642e-03, 2.1557e-03,\n",
      "         7.8644e-02, 6.2541e-01, 2.7185e-01, 5.8494e-03]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: chúng_tôi muốn có được sự tự_chủ trong thời đại công_nghệ\n",
      "Reference: we want <UNK> in the digital age , and\n",
      "Model: <SOS> we want to get better host of of <EOS>\n",
      "Attention Weights: tensor([[5.9750e-02, 9.3758e-01, 2.6527e-03, 1.9213e-05, 2.0242e-06, 5.4365e-07,\n",
      "         1.6089e-08, 1.8856e-08, 5.4903e-08, 1.6057e-09],\n",
      "        [8.5129e-05, 9.9965e-01, 1.7567e-04, 8.1597e-05, 3.1939e-06, 3.2656e-06,\n",
      "         2.8526e-07, 3.3020e-07, 1.3045e-07, 2.9188e-08],\n",
      "        [6.1531e-03, 8.0103e-01, 1.0537e-01, 8.1775e-02, 3.4529e-03, 1.5613e-03,\n",
      "         4.1342e-04, 1.2157e-04, 8.7239e-05, 2.7849e-05],\n",
      "        [2.4058e-03, 8.0642e-02, 3.0900e-01, 5.4469e-01, 2.4578e-02, 3.5245e-02,\n",
      "         2.4276e-03, 5.7427e-04, 1.8812e-04, 2.4804e-04],\n",
      "        [5.9417e-05, 3.9229e-03, 4.1406e-02, 4.1291e-01, 2.6186e-01, 2.3780e-01,\n",
      "         3.4912e-02, 4.2317e-03, 1.0238e-03, 1.8772e-03],\n",
      "        [3.2815e-07, 5.6307e-06, 6.6249e-05, 1.6874e-03, 7.2847e-03, 1.1723e-01,\n",
      "         2.4393e-01, 3.1382e-01, 1.8731e-01, 1.2867e-01],\n",
      "        [1.8319e-06, 4.6812e-06, 9.5773e-06, 4.5848e-04, 7.8947e-04, 2.2489e-03,\n",
      "         7.7830e-02, 5.8611e-01, 1.5559e-01, 1.7696e-01],\n",
      "        [3.9837e-05, 1.1187e-04, 2.8276e-05, 6.2843e-04, 7.9525e-04, 3.6799e-03,\n",
      "         6.9506e-02, 2.8096e-01, 2.5066e-01, 3.9358e-01],\n",
      "        [3.2359e-05, 2.1560e-04, 5.3032e-04, 2.8190e-03, 1.6212e-03, 5.0783e-03,\n",
      "         8.5336e-02, 2.5236e-01, 4.7132e-01, 1.8069e-01]])\n",
      "\n",
      "Epoch: 12.96, Train Loss: 1.41, Val Loss: 4.56, Train BLEU: 33.78, Val BLEU: 10.28, Minutes Elapsed: 680.32\n",
      "Sampling from training predictions...\n",
      "Source: tôi sẽ kiếm được bao_nhiêu nếu gian_lận ? <EOS> <PAD>\n",
      "Reference: how much do i stand to gain from cheating\n",
      "Model: <SOS> how much i i feel to if time ?\n",
      "Attention Weights: tensor([[0.1182, 0.8428, 0.0362, 0.0027, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0284, 0.4020, 0.5616, 0.0074, 0.0006, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0069, 0.4628, 0.3967, 0.0987, 0.0342, 0.0004, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0080, 0.3473, 0.4199, 0.1371, 0.0840, 0.0017, 0.0018, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0182, 0.8021, 0.0808, 0.0740, 0.0205, 0.0020, 0.0024, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0005, 0.0324, 0.1706, 0.3836, 0.3402, 0.0424, 0.0297, 0.0005, 0.0001,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0022, 0.0108, 0.1708, 0.4510, 0.2721, 0.0856, 0.0058, 0.0015,\n",
      "         0.0000],\n",
      "        [0.0005, 0.0033, 0.0003, 0.0023, 0.0041, 0.2837, 0.6625, 0.0376, 0.0056,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0007, 0.0004, 0.0034, 0.0093, 0.2298, 0.6463, 0.0897, 0.0202,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi nghĩ , trời ạ , tôi cảm_thấy rất tệ\n",
      "Reference: so i &apos;m like , man , it made\n",
      "Model: <SOS> and i thought , , , , i &apos;m\n",
      "Attention Weights: tensor([[1.6433e-01, 7.9253e-01, 2.9029e-02, 1.3459e-02, 6.5625e-04, 1.0402e-07,\n",
      "         1.3247e-07, 9.9881e-07, 6.7586e-07, 6.3352e-08],\n",
      "        [1.0609e-02, 9.7256e-01, 4.0218e-03, 1.2315e-02, 4.3500e-04, 1.7914e-05,\n",
      "         5.7714e-06, 3.4901e-05, 3.7505e-06, 4.1004e-07],\n",
      "        [5.1958e-02, 3.9198e-01, 3.2931e-01, 2.0313e-01, 1.9861e-02, 1.2498e-03,\n",
      "         3.4517e-04, 1.5881e-03, 4.8907e-04, 9.3576e-05],\n",
      "        [3.3393e-02, 6.7055e-01, 1.9359e-01, 8.2901e-02, 1.6934e-02, 1.1888e-03,\n",
      "         2.8826e-04, 7.4824e-04, 3.4920e-04, 5.4782e-05],\n",
      "        [3.3300e-03, 3.9560e-03, 2.8984e-02, 9.4447e-01, 1.4219e-02, 3.2172e-03,\n",
      "         8.8682e-04, 5.5063e-04, 2.5691e-04, 1.3321e-04],\n",
      "        [2.2211e-03, 2.7760e-03, 4.1657e-02, 9.4168e-01, 7.2043e-03, 2.6451e-03,\n",
      "         8.1332e-04, 5.6590e-04, 2.8584e-04, 1.5462e-04],\n",
      "        [2.7791e-03, 5.4107e-03, 9.8843e-02, 6.1300e-01, 1.6624e-01, 6.5933e-02,\n",
      "         2.8860e-02, 1.5160e-02, 2.4150e-03, 1.3519e-03],\n",
      "        [6.0560e-04, 1.8308e-03, 7.4685e-03, 1.6233e-01, 1.8740e-01, 1.6519e-01,\n",
      "         1.7228e-01, 2.5738e-01, 3.1564e-02, 1.3940e-02],\n",
      "        [2.6765e-05, 2.6741e-05, 5.8558e-05, 7.1480e-03, 5.8574e-03, 2.1058e-01,\n",
      "         3.5191e-01, 3.5329e-01, 5.0902e-02, 2.0198e-02]])\n",
      "\n",
      "Epoch: 13.00, Train Loss: 1.18, Val Loss: 4.59, Train BLEU: 41.34, Val BLEU: 10.36, Minutes Elapsed: 682.39\n",
      "Sampling from training predictions...\n",
      "Source: nhưng sự đối_nghịch trong quan_điểm này khá thú_vị . <EOS>\n",
      "Reference: but this conflict of views is kind of interesting\n",
      "Model: <SOS> but the in of views views really interesting interesting\n",
      "Attention Weights: tensor([[4.6936e-03, 9.5216e-01, 4.3130e-02, 1.3244e-05, 5.5730e-08, 2.4338e-08,\n",
      "         2.7193e-08, 6.9863e-10, 9.7485e-11, 6.4107e-13],\n",
      "        [2.7523e-03, 5.4208e-01, 4.5216e-01, 2.7860e-03, 2.0885e-04, 2.2763e-06,\n",
      "         3.2732e-06, 3.4743e-07, 2.0971e-08, 3.6841e-09],\n",
      "        [2.3487e-02, 3.9898e-02, 6.7232e-01, 2.4554e-01, 1.7189e-02, 2.3134e-04,\n",
      "         1.1946e-03, 1.2671e-04, 6.9038e-06, 3.9482e-06],\n",
      "        [2.7817e-02, 4.8410e-02, 4.2403e-01, 4.2942e-01, 5.4028e-02, 1.9552e-03,\n",
      "         1.3483e-02, 7.7763e-04, 4.2702e-05, 3.5345e-05],\n",
      "        [1.0263e-02, 7.5005e-04, 6.9187e-02, 3.4641e-01, 5.0801e-01, 8.7531e-03,\n",
      "         4.9317e-02, 6.0048e-03, 8.1945e-04, 4.8652e-04],\n",
      "        [1.9309e-04, 1.0829e-03, 4.7119e-02, 1.5048e-01, 6.5723e-01, 2.2576e-02,\n",
      "         1.0277e-01, 1.8028e-02, 3.0621e-04, 2.1195e-04],\n",
      "        [4.8107e-05, 1.1684e-04, 1.1228e-03, 1.0803e-02, 6.1459e-02, 8.4539e-02,\n",
      "         7.8142e-01, 5.4894e-02, 4.0860e-03, 1.5072e-03],\n",
      "        [2.7099e-05, 1.7336e-05, 9.3768e-04, 2.7934e-02, 2.7649e-01, 1.0553e-02,\n",
      "         4.3195e-01, 2.3454e-01, 1.2339e-02, 5.2169e-03],\n",
      "        [1.2978e-05, 9.0577e-05, 1.3815e-03, 7.4053e-03, 4.4447e-01, 1.9453e-02,\n",
      "         5.3559e-02, 7.6959e-02, 8.7623e-02, 3.0904e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: rất nhiều người bắc triều_tiên đang bị chia_cắt với gia_đình\n",
      "Reference: many north koreans are separated from their families ,\n",
      "Model: <SOS> many lot people people been by by young with\n",
      "Attention Weights: tensor([[9.5786e-01, 4.1999e-02, 9.6941e-05, 3.6885e-05, 2.8564e-06, 1.5856e-08,\n",
      "         1.8290e-09, 1.6868e-09, 1.3414e-10, 7.9989e-11],\n",
      "        [2.0727e-02, 2.9331e-01, 3.3118e-01, 3.1138e-01, 3.5640e-02, 6.8738e-03,\n",
      "         4.0658e-04, 3.4935e-04, 7.2403e-05, 6.5120e-05],\n",
      "        [1.3551e-01, 1.8297e-01, 1.4580e-01, 4.3217e-01, 8.2567e-02, 1.5138e-02,\n",
      "         4.6309e-03, 9.7057e-04, 1.7125e-04, 6.5378e-05],\n",
      "        [2.5613e-04, 5.4746e-03, 7.6495e-02, 6.2361e-01, 2.1318e-01, 4.3627e-02,\n",
      "         2.6335e-02, 9.2921e-03, 1.1441e-03, 5.8955e-04],\n",
      "        [6.5254e-06, 1.3947e-04, 3.2572e-03, 3.2292e-01, 2.4619e-01, 2.0957e-01,\n",
      "         1.6499e-01, 4.0488e-02, 1.0125e-02, 2.3198e-03],\n",
      "        [5.5502e-06, 4.5992e-04, 2.3405e-03, 9.9437e-02, 1.0982e-01, 1.6690e-01,\n",
      "         4.5057e-01, 1.3536e-01, 3.0445e-02, 4.6598e-03],\n",
      "        [4.7986e-06, 6.1360e-04, 2.5995e-03, 9.3341e-02, 3.3670e-01, 2.2532e-02,\n",
      "         1.3659e-01, 2.5124e-01, 1.3037e-01, 2.6008e-02],\n",
      "        [4.8345e-07, 1.4004e-04, 2.5535e-04, 5.0139e-03, 5.1716e-02, 8.7813e-02,\n",
      "         1.8189e-01, 2.3546e-01, 3.4982e-01, 8.7883e-02],\n",
      "        [5.8413e-06, 4.2264e-04, 4.3111e-04, 2.6492e-03, 1.5450e-02, 2.7717e-01,\n",
      "         1.8929e-01, 1.6743e-01, 2.3034e-01, 1.1682e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13.05, Train Loss: 1.07, Val Loss: 4.60, Train BLEU: 45.97, Val BLEU: 9.99, Minutes Elapsed: 684.87\n",
      "Sampling from training predictions...\n",
      "Source: chị ấy tìm trên google , và chị ấy tìm_thấy\n",
      "Reference: she googled , and she found this world whistling\n",
      "Model: <SOS> she googled , , she she me , ,\n",
      "Attention Weights: tensor([[8.0674e-02, 8.7125e-01, 4.7910e-02, 1.6432e-04, 3.1064e-06, 4.6539e-08,\n",
      "         2.3246e-09, 4.2047e-09, 6.0739e-10, 1.8925e-09],\n",
      "        [1.3794e-03, 3.5224e-03, 9.4538e-01, 4.9330e-02, 3.8253e-04, 6.4507e-06,\n",
      "         4.5387e-07, 8.0265e-07, 4.1321e-07, 6.7246e-07],\n",
      "        [1.2748e-02, 8.9117e-02, 4.9523e-01, 3.8726e-01, 1.5265e-02, 2.7503e-04,\n",
      "         3.9170e-05, 1.9619e-05, 2.3564e-05, 2.4544e-05],\n",
      "        [1.0902e-04, 3.4724e-04, 1.3242e-02, 2.1451e-01, 7.6665e-01, 4.0739e-03,\n",
      "         5.3205e-04, 1.6164e-04, 1.6459e-04, 2.1020e-04],\n",
      "        [6.2828e-05, 4.3698e-04, 1.6376e-03, 4.2774e-02, 1.2491e-01, 3.5878e-01,\n",
      "         3.8927e-01, 5.6294e-02, 1.8772e-02, 7.0586e-03],\n",
      "        [6.1683e-05, 2.1979e-04, 5.3727e-03, 8.3053e-03, 4.0005e-03, 2.0711e-02,\n",
      "         7.0967e-02, 2.8826e-01, 3.6857e-01, 2.3354e-01],\n",
      "        [1.0295e-04, 3.0136e-04, 6.5635e-03, 1.9098e-02, 3.7296e-03, 1.7853e-02,\n",
      "         9.3339e-03, 1.4556e-01, 2.6912e-01, 5.2834e-01],\n",
      "        [3.3887e-07, 5.1476e-06, 6.1427e-04, 2.7810e-02, 3.1544e-02, 4.5892e-02,\n",
      "         1.0862e-02, 2.2065e-02, 8.8076e-02, 7.7313e-01],\n",
      "        [9.5111e-07, 2.6670e-06, 3.4354e-05, 3.9840e-04, 6.5742e-03, 5.9001e-02,\n",
      "         1.3554e-01, 1.4679e-01, 1.5566e-01, 4.9600e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: cuộc hành_trình bằng xe_buýt kéo_dài khoảng 1 tuần , và\n",
      "Reference: the journey by bus took one week , and\n",
      "Model: <SOS> the is is about a a weeks , and\n",
      "Attention Weights: tensor([[9.8640e-01, 1.3215e-02, 3.2457e-04, 5.2121e-05, 5.9595e-06, 1.7868e-06,\n",
      "         1.1519e-07, 3.7154e-08, 7.4546e-10, 1.8177e-09],\n",
      "        [4.7065e-02, 7.7582e-01, 1.1945e-01, 4.7440e-02, 8.5431e-03, 1.3204e-03,\n",
      "         9.1320e-05, 2.5362e-04, 1.0269e-05, 3.0276e-06],\n",
      "        [3.7703e-02, 1.0432e-01, 4.6002e-01, 1.2646e-01, 2.3191e-01, 2.9321e-02,\n",
      "         2.6758e-03, 7.2381e-03, 2.9813e-04, 4.8835e-05],\n",
      "        [4.4125e-03, 2.4480e-02, 3.7443e-01, 2.1026e-01, 3.1406e-01, 4.2538e-02,\n",
      "         7.0144e-03, 2.1083e-02, 1.4315e-03, 2.8857e-04],\n",
      "        [2.1737e-04, 7.6038e-04, 1.3275e-02, 7.2092e-02, 4.1092e-01, 1.8886e-01,\n",
      "         1.0984e-01, 1.9220e-01, 1.0108e-02, 1.7370e-03],\n",
      "        [1.2724e-04, 3.8314e-04, 3.9881e-03, 4.6832e-02, 2.8207e-01, 1.4085e-01,\n",
      "         1.2350e-01, 2.6686e-01, 1.2535e-01, 1.0038e-02],\n",
      "        [2.3986e-05, 8.0476e-05, 2.5566e-04, 1.8388e-03, 1.0254e-02, 7.1522e-02,\n",
      "         1.0080e-01, 5.9053e-01, 2.0046e-01, 2.4241e-02],\n",
      "        [3.2177e-04, 7.2927e-04, 1.7633e-03, 7.2295e-03, 2.8474e-02, 8.7312e-02,\n",
      "         6.7203e-02, 2.3777e-01, 4.9310e-01, 7.6096e-02],\n",
      "        [3.4427e-04, 3.6708e-04, 7.9011e-04, 1.3387e-03, 3.6803e-03, 4.2128e-02,\n",
      "         1.0580e-01, 5.1882e-02, 3.2014e-01, 4.7353e-01]])\n",
      "\n",
      "Epoch: 13.10, Train Loss: 1.25, Val Loss: 4.60, Train BLEU: 39.08, Val BLEU: 10.33, Minutes Elapsed: 687.36\n",
      "Sampling from training predictions...\n",
      "Source: tôi nghĩ là tốt . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: i thought so . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> i think that good <EOS> . . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0128, 0.8720, 0.0972, 0.0178, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0146, 0.9787, 0.0058, 0.0009, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0481, 0.3425, 0.2229, 0.3800, 0.0059, 0.0005, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0243, 0.0766, 0.0671, 0.7208, 0.0703, 0.0409, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0195, 0.0672, 0.0523, 0.3120, 0.1900, 0.3591, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0573, 0.4508, 0.1189, 0.0939, 0.0854, 0.1938, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0317, 0.5322, 0.1973, 0.1047, 0.0404, 0.0936, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0971, 0.2351, 0.0868, 0.1674, 0.1001, 0.3135, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2072, 0.3479, 0.0223, 0.0946, 0.0802, 0.2478, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: vì_thế tôi lớn_lên với sự thù_ghét sư_tử . <EOS> <PAD>\n",
      "Reference: so i grew up hating lions so much .\n",
      "Model: <SOS> so i went went with message . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9717, 0.0151, 0.0132, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0006, 0.9930, 0.0064, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0035, 0.9690, 0.0266, 0.0007, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0007, 0.0035, 0.6099, 0.3377, 0.0439, 0.0042, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0005, 0.0199, 0.2156, 0.3864, 0.1387, 0.2360, 0.0012, 0.0015, 0.0003,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0003, 0.0009, 0.0062, 0.0348, 0.9312, 0.0078, 0.0174, 0.0015,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0014, 0.0009, 0.0065, 0.0750, 0.8193, 0.0241, 0.0638, 0.0088,\n",
      "         0.0000],\n",
      "        [0.0007, 0.0027, 0.0004, 0.0008, 0.0026, 0.0096, 0.1245, 0.2269, 0.6318,\n",
      "         0.0000],\n",
      "        [0.0044, 0.0139, 0.0032, 0.0013, 0.0044, 0.0196, 0.1099, 0.1307, 0.7126,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 13.14, Train Loss: 1.27, Val Loss: 4.61, Train BLEU: 37.67, Val BLEU: 10.37, Minutes Elapsed: 689.84\n",
      "Sampling from training predictions...\n",
      "Source: bắt_chước những gì bạn nhìn thấy . <EOS> <PAD> <PAD>\n",
      "Reference: you can mimic what you can see . <EOS>\n",
      "Model: <SOS> and everything mimic see . see . . <EOS>\n",
      "Attention Weights: tensor([[0.9999, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.6089, 0.0750, 0.3107, 0.0032, 0.0016, 0.0005, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4543, 0.1600, 0.1918, 0.0800, 0.0795, 0.0311, 0.0026, 0.0007, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2488, 0.1314, 0.0280, 0.0346, 0.1967, 0.2532, 0.0924, 0.0149, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0710, 0.1737, 0.0671, 0.0228, 0.0934, 0.3011, 0.1809, 0.0899, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0062, 0.0179, 0.1060, 0.0426, 0.0885, 0.1010, 0.1388, 0.4991, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0043, 0.0031, 0.0154, 0.1415, 0.3709, 0.2311, 0.0609, 0.1727, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0019, 0.0029, 0.0021, 0.0021, 0.0381, 0.4074, 0.1082, 0.4373, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0055, 0.0125, 0.0124, 0.0050, 0.0430, 0.2667, 0.0864, 0.5685, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: và bởi_vì tử_cung bao_bọc hoàn_toàn phôi_thai đang phát_triển trong lòng\n",
      "Reference: and so just as the womb entirely envelopes the\n",
      "Model: <SOS> and because it &apos;s is that of is the\n",
      "Attention Weights: tensor([[1.7755e-06, 9.8723e-01, 1.2762e-02, 2.5508e-06, 1.1423e-08, 1.0170e-09,\n",
      "         9.4800e-10, 1.3371e-09, 3.0985e-10, 2.9886e-11],\n",
      "        [1.3190e-05, 9.8963e-01, 1.0346e-02, 7.8144e-06, 8.4290e-08, 3.6792e-08,\n",
      "         2.0662e-09, 1.3181e-10, 1.9246e-10, 1.3999e-10],\n",
      "        [1.3537e-05, 1.4572e-01, 8.1363e-01, 3.9310e-02, 1.1067e-03, 2.0981e-04,\n",
      "         1.0170e-05, 2.7692e-06, 8.0062e-07, 7.0715e-07],\n",
      "        [1.3422e-05, 2.7102e-02, 6.7179e-01, 2.4514e-01, 4.7484e-02, 7.8362e-03,\n",
      "         4.4598e-04, 1.3128e-04, 3.0458e-05, 2.6204e-05],\n",
      "        [1.4603e-04, 5.3777e-02, 3.4303e-01, 3.8081e-01, 1.8702e-01, 3.0561e-02,\n",
      "         3.1618e-03, 1.0710e-03, 2.8144e-04, 1.3398e-04],\n",
      "        [2.3184e-05, 6.3682e-03, 1.1182e-01, 3.7286e-01, 3.7431e-01, 1.1179e-01,\n",
      "         1.4362e-02, 6.8296e-03, 1.1113e-03, 5.2445e-04],\n",
      "        [9.8774e-07, 7.6604e-05, 1.1610e-02, 2.8641e-01, 4.2953e-01, 2.4259e-01,\n",
      "         2.1061e-02, 5.9732e-03, 1.2485e-03, 1.5021e-03],\n",
      "        [4.3019e-07, 7.9435e-05, 4.2524e-03, 1.9826e-01, 2.3767e-01, 5.2237e-01,\n",
      "         2.6451e-02, 6.5538e-03, 1.8530e-03, 2.5050e-03],\n",
      "        [2.2896e-08, 8.3807e-06, 7.0357e-04, 4.7253e-03, 2.9151e-01, 3.4158e-01,\n",
      "         2.7905e-01, 4.5906e-02, 1.9227e-02, 1.7295e-02]])\n",
      "\n",
      "Epoch: 13.19, Train Loss: 1.47, Val Loss: 4.67, Train BLEU: 32.63, Val BLEU: 10.50, Minutes Elapsed: 692.35\n",
      "Sampling from training predictions...\n",
      "Source: 10 điều răn rất khó để đưa_vào hệ_thống giáo_dục ,\n",
      "Reference: now , ten commandments is something that is hard\n",
      "Model: <SOS> it was ten commandments is something that to really\n",
      "Attention Weights: tensor([[1.3946e-01, 8.3731e-01, 2.3051e-02, 1.7481e-04, 9.2452e-06, 5.9347e-08,\n",
      "         9.6755e-09, 6.9526e-10, 1.2382e-09, 2.8481e-11],\n",
      "        [2.8546e-02, 7.9294e-01, 1.6422e-01, 1.3685e-02, 5.0569e-04, 5.0593e-05,\n",
      "         3.3318e-05, 1.4110e-05, 7.3502e-06, 8.0594e-07],\n",
      "        [2.0978e-02, 3.4144e-01, 4.6938e-01, 1.3822e-01, 2.2004e-02, 5.6906e-03,\n",
      "         1.8073e-03, 2.0291e-04, 2.6054e-04, 2.0901e-05],\n",
      "        [6.5851e-02, 3.5105e-01, 3.5612e-01, 1.6580e-01, 5.2299e-02, 6.1998e-03,\n",
      "         2.2082e-03, 1.9812e-04, 2.7247e-04, 1.1499e-05],\n",
      "        [7.9996e-02, 4.8907e-01, 2.6840e-01, 9.2467e-02, 6.1207e-02, 5.7392e-03,\n",
      "         2.5494e-03, 2.4744e-04, 3.0306e-04, 1.8472e-05],\n",
      "        [1.6368e-03, 1.2052e-01, 3.3249e-01, 3.8024e-01, 1.2233e-01, 3.0001e-02,\n",
      "         8.8328e-03, 1.4675e-03, 2.2214e-03, 2.5102e-04],\n",
      "        [1.1928e-04, 1.3249e-02, 2.0734e-01, 3.5606e-01, 1.9204e-01, 1.3941e-01,\n",
      "         6.1636e-02, 1.4634e-02, 1.4710e-02, 7.9882e-04],\n",
      "        [7.2939e-04, 7.4853e-03, 6.4540e-02, 4.7647e-02, 2.5567e-02, 2.4382e-01,\n",
      "         4.0304e-01, 4.1821e-02, 1.5955e-01, 5.8022e-03],\n",
      "        [1.0236e-05, 4.1944e-04, 1.4546e-02, 6.5981e-02, 6.6504e-02, 8.5302e-02,\n",
      "         4.1607e-01, 1.0526e-01, 2.3843e-01, 7.4734e-03]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: cái ý_tưởng tìm_kiếm một công_nghệ khác_biệt đã hoàn_toàn vượt lên\n",
      "Reference: the idea of finding a different technology had absolutely\n",
      "Model: <SOS> the technology is to is technology is has has\n",
      "Attention Weights: tensor([[9.9654e-01, 3.4255e-03, 3.2423e-05, 1.1893e-07, 1.2524e-08, 1.4683e-08,\n",
      "         4.2280e-09, 1.0431e-10, 1.3763e-10, 4.9485e-11],\n",
      "        [1.0728e-02, 8.2907e-01, 1.3996e-01, 1.2293e-02, 6.9178e-03, 9.4442e-04,\n",
      "         7.1496e-05, 1.1044e-05, 4.9881e-06, 8.8603e-07],\n",
      "        [1.3396e-02, 5.1118e-01, 2.3186e-01, 1.1981e-01, 9.9204e-02, 1.9274e-02,\n",
      "         4.7899e-03, 4.2950e-04, 4.3143e-05, 1.3056e-05],\n",
      "        [6.5211e-03, 2.2701e-01, 4.8755e-01, 7.6523e-02, 1.5618e-01, 3.8052e-02,\n",
      "         6.7211e-03, 1.1887e-03, 1.8753e-04, 7.1890e-05],\n",
      "        [9.0305e-04, 8.3624e-02, 1.4324e-01, 1.9016e-01, 3.0763e-01, 2.3440e-01,\n",
      "         3.3735e-02, 4.0531e-03, 1.8331e-03, 4.3262e-04],\n",
      "        [2.1520e-06, 1.6282e-03, 3.6898e-03, 1.4653e-02, 4.8704e-01, 3.1599e-01,\n",
      "         1.3358e-01, 3.5264e-02, 6.4161e-03, 1.7350e-03],\n",
      "        [1.6826e-07, 3.1475e-04, 7.2843e-04, 3.4881e-03, 2.5274e-01, 3.4121e-01,\n",
      "         1.7867e-01, 1.3834e-01, 6.5785e-02, 1.8726e-02],\n",
      "        [7.5375e-08, 3.4703e-05, 9.5538e-04, 7.2507e-04, 4.0058e-02, 9.9769e-02,\n",
      "         2.1541e-01, 4.9629e-01, 1.1740e-01, 2.9356e-02],\n",
      "        [1.1195e-08, 6.1735e-06, 2.6886e-04, 1.6245e-04, 8.4466e-03, 1.8278e-02,\n",
      "         5.5231e-02, 4.7575e-01, 3.0195e-01, 1.3991e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13.24, Train Loss: 1.47, Val Loss: 4.62, Train BLEU: 32.32, Val BLEU: 10.38, Minutes Elapsed: 694.85\n",
      "Sampling from training predictions...\n",
      "Source: chúng_tôi phải thay_đổi kế_hoạch của mình . <EOS> <PAD> <PAD>\n",
      "Reference: we needed to change our schedule . <EOS> <PAD>\n",
      "Model: <SOS> we have to change our schedule . <EOS> .\n",
      "Attention Weights: tensor([[0.0149, 0.9848, 0.0004, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0007, 0.9971, 0.0021, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0005, 0.9343, 0.0529, 0.0118, 0.0002, 0.0003, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0046, 0.6004, 0.3914, 0.0016, 0.0017, 0.0001, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0011, 0.1430, 0.7490, 0.0435, 0.0609, 0.0020, 0.0003, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0004, 0.0271, 0.7822, 0.0827, 0.0981, 0.0084, 0.0011, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0006, 0.0141, 0.0027, 0.0277, 0.0291, 0.2780, 0.5112, 0.1368, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0007, 0.0038, 0.0058, 0.0089, 0.0060, 0.1114, 0.4412, 0.4223, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1072, 0.2666, 0.0031, 0.0069, 0.0059, 0.1288, 0.2384, 0.2431, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: hơn 85 phần_trăm kẻ bạo_hành là đàn_ông , và bạo_lực\n",
      "Reference: over 85 percent of <UNK> are men , and\n",
      "Model: <SOS> over 85 percent of people are is , men\n",
      "Attention Weights: tensor([[9.8670e-01, 1.1382e-02, 1.9207e-03, 7.3719e-07, 1.9605e-07, 5.1515e-10,\n",
      "         1.8678e-09, 2.2307e-10, 5.9411e-11, 7.0636e-11],\n",
      "        [1.2483e-01, 6.8709e-01, 1.7679e-01, 8.8078e-03, 2.3225e-03, 3.7945e-05,\n",
      "         8.9040e-05, 1.1746e-05, 3.9761e-06, 8.7142e-06],\n",
      "        [3.7040e-02, 5.2983e-01, 3.9969e-01, 2.2862e-02, 7.6911e-03, 1.0494e-03,\n",
      "         1.4089e-03, 3.1286e-04, 5.8371e-05, 5.4515e-05],\n",
      "        [2.8409e-03, 1.2319e-02, 8.3694e-01, 6.4882e-02, 7.2156e-02, 4.6546e-03,\n",
      "         5.0595e-03, 6.2424e-04, 2.0161e-04, 3.2762e-04],\n",
      "        [5.3621e-03, 2.5508e-02, 6.5343e-01, 1.6687e-01, 1.1452e-01, 1.4670e-02,\n",
      "         1.4056e-02, 3.1176e-03, 8.8036e-04, 1.5823e-03],\n",
      "        [4.2514e-05, 7.8647e-05, 1.4099e-02, 4.4536e-01, 3.5391e-01, 5.5591e-02,\n",
      "         1.0925e-01, 1.1617e-02, 4.0247e-03, 6.0310e-03],\n",
      "        [4.5282e-05, 1.4815e-04, 6.9630e-02, 6.6709e-02, 5.9134e-01, 1.3063e-01,\n",
      "         9.1263e-02, 3.6981e-02, 6.8621e-03, 6.3901e-03],\n",
      "        [9.6027e-07, 2.2622e-06, 8.0466e-04, 2.8183e-02, 1.3680e-01, 3.2855e-01,\n",
      "         4.5385e-01, 3.1958e-02, 9.7060e-03, 1.0141e-02],\n",
      "        [4.3727e-07, 2.5439e-06, 2.8127e-04, 3.3263e-02, 5.5201e-02, 3.6791e-02,\n",
      "         4.4771e-01, 2.5814e-01, 7.0891e-02, 9.7717e-02]])\n",
      "\n",
      "Epoch: 13.29, Train Loss: 1.50, Val Loss: 4.66, Train BLEU: 31.73, Val BLEU: 10.09, Minutes Elapsed: 697.33\n",
      "Sampling from training predictions...\n",
      "Source: một_vài đứa trẻ của chúng_tôi đã bắt_đầu nói_chuyện với bố_mẹ\n",
      "Reference: some of our kids started talking with their parents\n",
      "Model: <SOS> some of our kids started talking with parents parents\n",
      "Attention Weights: tensor([[9.9991e-01, 8.5739e-05, 7.3189e-07, 3.3249e-09, 8.9697e-10, 4.4429e-10,\n",
      "         6.6942e-10, 8.4170e-11, 1.2874e-11, 7.6626e-13],\n",
      "        [7.4740e-01, 1.5440e-01, 9.4712e-02, 2.3189e-03, 4.9057e-04, 2.2414e-04,\n",
      "         4.4068e-04, 1.4109e-05, 1.6672e-06, 2.0976e-06],\n",
      "        [1.7787e-01, 2.3345e-01, 4.7549e-01, 3.1929e-02, 7.6671e-03, 2.8272e-02,\n",
      "         4.2597e-02, 2.1660e-03, 3.0096e-04, 2.4982e-04],\n",
      "        [1.8424e-02, 1.8035e-01, 4.2194e-01, 2.0044e-02, 1.3830e-02, 8.4395e-02,\n",
      "         2.4007e-01, 1.9330e-02, 9.7354e-04, 6.3732e-04],\n",
      "        [3.4316e-04, 1.3755e-03, 5.6520e-03, 8.2790e-03, 1.9845e-02, 8.3151e-02,\n",
      "         8.6499e-01, 1.4429e-02, 1.7624e-03, 1.7478e-04],\n",
      "        [1.1477e-05, 4.1393e-05, 1.5512e-03, 3.7337e-03, 2.1860e-03, 5.9385e-02,\n",
      "         7.9019e-01, 1.2584e-01, 1.2795e-02, 4.2655e-03],\n",
      "        [2.1728e-06, 6.3134e-05, 1.7358e-03, 8.3520e-05, 2.5461e-04, 1.1525e-03,\n",
      "         7.1173e-02, 2.8377e-01, 3.1186e-01, 3.2991e-01],\n",
      "        [4.5399e-07, 6.6170e-06, 5.4382e-04, 2.2967e-05, 4.4884e-05, 1.9970e-04,\n",
      "         2.5562e-03, 4.2014e-02, 1.6708e-01, 7.8753e-01],\n",
      "        [1.7373e-04, 1.5583e-04, 4.9943e-03, 1.8326e-03, 2.6552e-03, 3.4128e-03,\n",
      "         1.7038e-02, 8.8895e-02, 1.1163e-01, 7.6921e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: nhưng vào một ngày của năm 1995 , mẹ tôi\n",
      "Reference: but one day , in 1995 , my mom\n",
      "Model: <SOS> but in was of 2008 mother mother i mother\n",
      "Attention Weights: tensor([[3.1414e-02, 8.4562e-01, 1.2261e-01, 2.9790e-04, 5.2273e-05, 9.1456e-07,\n",
      "         7.9088e-07, 2.3693e-07, 3.8412e-08, 2.7873e-08],\n",
      "        [6.4230e-03, 9.7372e-01, 1.8278e-02, 1.3978e-03, 1.5408e-04, 8.5899e-06,\n",
      "         1.3606e-05, 8.9925e-08, 7.2022e-07, 7.9327e-08],\n",
      "        [1.5379e-02, 2.2425e-02, 5.2288e-01, 3.6138e-01, 4.4922e-02, 2.6677e-02,\n",
      "         4.9663e-03, 4.0752e-04, 8.3193e-04, 1.2564e-04],\n",
      "        [4.2930e-02, 9.6884e-03, 9.9434e-02, 5.5123e-01, 1.0948e-01, 1.2492e-01,\n",
      "         3.7726e-02, 1.5965e-02, 7.2593e-03, 1.3660e-03],\n",
      "        [1.9748e-04, 2.3544e-04, 7.5531e-03, 2.0290e-01, 3.0438e-01, 3.0010e-01,\n",
      "         1.0151e-01, 5.5973e-02, 2.3428e-02, 3.7261e-03],\n",
      "        [4.6487e-05, 1.0114e-04, 2.7301e-04, 2.5592e-02, 1.7584e-02, 1.5149e-01,\n",
      "         2.5265e-01, 2.7814e-01, 2.5619e-01, 1.7936e-02],\n",
      "        [1.0549e-04, 4.0311e-04, 2.1640e-04, 1.9363e-03, 1.3828e-03, 6.3329e-03,\n",
      "         8.2434e-03, 9.0330e-02, 7.7143e-01, 1.1962e-01],\n",
      "        [9.6846e-04, 8.9547e-05, 1.7704e-03, 4.0275e-02, 1.5601e-02, 7.5313e-02,\n",
      "         2.8826e-02, 3.5085e-01, 4.2302e-01, 6.3293e-02],\n",
      "        [6.4344e-04, 5.5680e-04, 3.2499e-04, 1.3062e-02, 6.5561e-03, 8.3925e-02,\n",
      "         3.0344e-02, 4.0980e-01, 4.3311e-01, 2.1682e-02]])\n",
      "\n",
      "Epoch: 13.34, Train Loss: 1.61, Val Loss: 4.62, Train BLEU: 29.03, Val BLEU: 9.95, Minutes Elapsed: 699.80\n",
      "Sampling from training predictions...\n",
      "Source: mỗi một mảnh của nghệ_thuật đáng nhớ , mỗi_một viên\n",
      "Reference: each a piece of memorable art , each a\n",
      "Model: <SOS> each a piece of art , , has has\n",
      "Attention Weights: tensor([[9.9979e-01, 2.0520e-04, 4.9408e-07, 6.9191e-08, 8.6328e-09, 4.1790e-09,\n",
      "         6.2198e-10, 3.5936e-12, 1.4414e-12, 1.2659e-12],\n",
      "        [3.3119e-01, 3.5468e-01, 3.0691e-01, 2.0705e-03, 4.1879e-03, 9.0130e-04,\n",
      "         4.8601e-05, 4.0663e-06, 5.2824e-06, 3.5913e-06],\n",
      "        [1.3790e-01, 1.1907e-01, 5.1485e-01, 1.0955e-01, 6.9147e-02, 4.4937e-02,\n",
      "         4.1479e-03, 2.1433e-04, 9.1793e-05, 9.2887e-05],\n",
      "        [1.0192e-04, 4.8941e-04, 5.6622e-02, 3.7254e-02, 6.0966e-01, 2.7396e-01,\n",
      "         1.8335e-02, 2.1726e-03, 7.5063e-04, 6.5264e-04],\n",
      "        [4.5300e-04, 5.2604e-04, 3.2043e-02, 1.7441e-02, 7.0846e-01, 1.9404e-01,\n",
      "         3.2056e-02, 8.5959e-03, 3.9308e-03, 2.4576e-03],\n",
      "        [8.2704e-04, 1.7432e-03, 8.0449e-03, 1.2832e-02, 2.3068e-01, 3.7698e-01,\n",
      "         1.0966e-01, 8.3580e-02, 1.1705e-01, 5.8603e-02],\n",
      "        [4.8668e-04, 4.2816e-04, 3.7523e-03, 2.3303e-02, 1.1807e-01, 5.1678e-02,\n",
      "         4.9257e-02, 3.2259e-01, 3.2228e-01, 1.0815e-01],\n",
      "        [2.7085e-05, 1.1455e-05, 3.4340e-04, 3.3484e-04, 3.6021e-02, 1.0976e-02,\n",
      "         2.0577e-02, 1.7565e-01, 6.0925e-01, 1.4681e-01],\n",
      "        [4.4827e-04, 4.8406e-04, 1.5983e-02, 5.4795e-03, 9.1753e-02, 8.2286e-02,\n",
      "         1.1883e-01, 4.9687e-02, 3.2601e-01, 3.0904e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: và vì_thế các động_vật ăn_thịt như sư_tử theo sau chúng\n",
      "Reference: so predators like lions follow them , and this\n",
      "Model: <SOS> and so the are , they they they they\n",
      "Attention Weights: tensor([[3.3573e-04, 4.6954e-03, 8.9403e-02, 3.9554e-01, 4.7738e-01, 3.2258e-02,\n",
      "         1.7354e-04, 2.0628e-04, 8.2374e-06, 6.3066e-07],\n",
      "        [3.3254e-05, 9.9856e-01, 1.3676e-03, 3.5120e-05, 3.0127e-07, 4.8602e-09,\n",
      "         2.9905e-09, 3.3799e-10, 1.8461e-10, 1.6481e-10],\n",
      "        [6.4101e-06, 8.6288e-04, 4.8854e-01, 4.9751e-01, 1.2869e-02, 1.5341e-04,\n",
      "         1.7663e-05, 3.1559e-05, 1.9960e-06, 3.5139e-06],\n",
      "        [1.3014e-05, 2.2934e-04, 5.6158e-02, 8.0419e-01, 1.3452e-01, 3.6403e-03,\n",
      "         2.1265e-04, 9.6368e-04, 5.0141e-05, 1.7542e-05],\n",
      "        [3.4587e-08, 4.3482e-07, 1.6847e-04, 3.0998e-02, 2.6246e-01, 1.4269e-01,\n",
      "         1.0828e-01, 3.2134e-01, 1.2300e-01, 1.1061e-02],\n",
      "        [3.0009e-07, 3.3104e-06, 2.0785e-04, 1.2465e-02, 5.1113e-02, 9.2388e-02,\n",
      "         1.3520e-01, 3.4465e-01, 3.4148e-01, 2.2493e-02],\n",
      "        [8.3517e-08, 1.4143e-06, 1.0551e-04, 6.1203e-04, 1.5127e-03, 6.4881e-03,\n",
      "         2.3076e-02, 2.8392e-01, 5.8240e-01, 1.0188e-01],\n",
      "        [1.1838e-07, 1.8337e-06, 1.9993e-04, 2.2086e-03, 3.6525e-03, 5.5889e-03,\n",
      "         2.2405e-02, 2.3886e-01, 6.5879e-01, 6.8296e-02],\n",
      "        [1.8198e-07, 1.4839e-06, 9.3638e-05, 1.4163e-03, 3.2942e-03, 5.1989e-03,\n",
      "         1.1679e-02, 2.4483e-01, 5.9197e-01, 1.4152e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13.38, Train Loss: 1.54, Val Loss: 4.62, Train BLEU: 30.85, Val BLEU: 10.30, Minutes Elapsed: 702.30\n",
      "Sampling from training predictions...\n",
      "Source: chúng_tôi hack phần_cứng , phần_mềm , phần ướt , và\n",
      "Reference: we hack hardware , software , wetware , and\n",
      "Model: <SOS> we hack the , software , and , and\n",
      "Attention Weights: tensor([[5.1041e-01, 4.8372e-01, 5.8345e-03, 2.2049e-05, 7.4265e-06, 6.4632e-09,\n",
      "         1.4862e-08, 4.9839e-09, 1.8588e-10, 2.8692e-10],\n",
      "        [8.2316e-04, 6.8602e-01, 3.1267e-01, 3.6957e-04, 1.0874e-04, 1.2700e-06,\n",
      "         1.1046e-06, 9.9787e-07, 7.7929e-08, 1.6437e-08],\n",
      "        [1.4964e-03, 3.4804e-01, 6.0087e-01, 4.4891e-02, 4.1570e-03, 3.0750e-04,\n",
      "         1.0375e-04, 1.2352e-04, 1.0602e-05, 1.8381e-06],\n",
      "        [3.5728e-05, 1.1727e-02, 2.4070e-01, 6.0890e-01, 1.3602e-01, 1.2432e-03,\n",
      "         4.3600e-04, 7.2047e-04, 2.0267e-04, 1.8738e-05],\n",
      "        [2.3142e-05, 1.4684e-03, 3.1986e-03, 2.0579e-01, 7.6183e-01, 1.7672e-02,\n",
      "         3.0174e-03, 4.7671e-03, 1.3341e-03, 8.9885e-04],\n",
      "        [8.1758e-06, 1.3030e-04, 1.5768e-03, 9.8536e-03, 5.5955e-01, 1.5147e-01,\n",
      "         1.3398e-01, 1.2037e-01, 1.4262e-02, 8.7941e-03],\n",
      "        [2.5878e-06, 2.6446e-04, 1.6736e-04, 1.6713e-03, 4.6413e-02, 1.6925e-01,\n",
      "         2.8630e-01, 3.7578e-01, 6.6088e-02, 5.4064e-02],\n",
      "        [5.4584e-05, 1.6594e-04, 1.3169e-03, 3.8188e-03, 5.8193e-02, 1.4908e-02,\n",
      "         4.0886e-01, 2.8467e-01, 1.1654e-01, 1.1148e-01],\n",
      "        [2.5572e-05, 3.9362e-03, 1.5329e-03, 5.3296e-03, 4.4103e-02, 5.1917e-02,\n",
      "         2.5814e-01, 4.0130e-01, 1.1327e-01, 1.2044e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi lúc_nào cũng tự_hỏi là tại_sao họ lại có điện\n",
      "Reference: i always wondered why they had lights but we\n",
      "Model: <SOS> i &apos;m , the why is they idea .\n",
      "Attention Weights: tensor([[4.5489e-02, 5.4339e-01, 4.1017e-01, 9.4138e-04, 5.9211e-06, 4.3787e-06,\n",
      "         7.6130e-08, 3.8371e-07, 4.7021e-08, 2.8752e-08],\n",
      "        [8.7436e-03, 9.5580e-01, 3.4304e-02, 1.1255e-03, 1.3474e-05, 1.3907e-05,\n",
      "         1.6276e-07, 1.5263e-06, 4.0346e-07, 1.6086e-07],\n",
      "        [9.6510e-03, 3.8456e-01, 4.7480e-01, 1.2093e-01, 7.3377e-03, 2.4459e-03,\n",
      "         4.1642e-05, 1.7900e-04, 3.4569e-05, 2.0475e-05],\n",
      "        [1.2805e-03, 8.0207e-02, 3.6111e-01, 4.6245e-01, 5.0575e-02, 3.6254e-02,\n",
      "         2.8693e-03, 3.8351e-03, 6.3101e-04, 7.8811e-04],\n",
      "        [9.8499e-04, 9.1656e-03, 8.8141e-02, 4.6592e-01, 1.4584e-01, 2.6264e-01,\n",
      "         1.3084e-02, 7.8624e-03, 3.0934e-03, 3.2737e-03],\n",
      "        [4.0316e-05, 1.0251e-03, 8.9885e-03, 1.2926e-01, 1.2429e-01, 4.4244e-01,\n",
      "         1.3750e-01, 1.1630e-01, 2.8793e-02, 1.1365e-02],\n",
      "        [2.8182e-06, 1.2958e-04, 8.0737e-04, 1.4352e-02, 3.9121e-02, 3.2291e-01,\n",
      "         1.3122e-01, 3.5295e-01, 1.0704e-01, 3.1463e-02],\n",
      "        [9.1775e-07, 1.3532e-05, 7.8541e-04, 1.1350e-02, 4.9571e-02, 3.1490e-01,\n",
      "         3.1556e-01, 7.3219e-02, 6.5213e-02, 1.6938e-01],\n",
      "        [5.0595e-07, 2.5948e-05, 1.0004e-03, 7.0340e-03, 3.1845e-02, 3.8541e-01,\n",
      "         4.0149e-02, 1.3683e-01, 1.0599e-01, 2.9171e-01]])\n",
      "\n",
      "Epoch: 13.43, Train Loss: 1.66, Val Loss: 4.61, Train BLEU: 27.15, Val BLEU: 10.49, Minutes Elapsed: 704.78\n",
      "Sampling from training predictions...\n",
      "Source: những loài chim khác , như loài tanager , cũng\n",
      "Reference: other birds , like this tanager , have adapted\n",
      "Model: <SOS> other birds , like the tanager , which have\n",
      "Attention Weights: tensor([[3.8676e-01, 3.8060e-01, 1.8566e-01, 4.6728e-02, 2.4758e-04, 3.7100e-06,\n",
      "         1.2184e-06, 4.3206e-06, 1.0020e-07, 1.2777e-07],\n",
      "        [7.7545e-03, 3.2698e-01, 5.8022e-01, 2.5034e-02, 5.7023e-02, 1.0502e-03,\n",
      "         6.9782e-04, 1.1134e-03, 1.1721e-04, 1.6154e-05],\n",
      "        [3.6524e-03, 4.3125e-02, 7.5991e-02, 4.9322e-02, 7.3779e-01, 6.3634e-02,\n",
      "         1.7974e-02, 7.0753e-03, 1.0909e-03, 3.4884e-04],\n",
      "        [2.0948e-05, 5.4444e-04, 6.1453e-03, 1.8956e-02, 5.1960e-01, 3.5623e-01,\n",
      "         5.3066e-02, 3.5773e-02, 5.5762e-03, 4.0889e-03],\n",
      "        [7.0480e-07, 4.4635e-05, 1.0923e-03, 8.6651e-04, 9.7678e-03, 2.2831e-01,\n",
      "         4.4377e-01, 2.6353e-01, 1.8131e-02, 3.4479e-02],\n",
      "        [1.0799e-06, 2.6022e-04, 1.3967e-03, 1.0933e-03, 4.9352e-03, 2.2947e-02,\n",
      "         4.2025e-01, 3.3442e-01, 1.3214e-01, 8.2550e-02],\n",
      "        [2.0636e-08, 5.0560e-06, 1.4740e-05, 3.3681e-05, 5.1236e-04, 3.7260e-03,\n",
      "         3.6083e-02, 1.2048e-02, 4.3772e-01, 5.0986e-01],\n",
      "        [1.6450e-07, 4.2839e-06, 1.5325e-05, 6.9607e-05, 6.5840e-03, 2.3694e-02,\n",
      "         4.5728e-02, 2.5485e-02, 3.2737e-01, 5.7105e-01],\n",
      "        [7.4695e-08, 3.1334e-06, 3.2808e-05, 3.9759e-05, 4.9361e-04, 4.1116e-03,\n",
      "         2.2611e-02, 4.3048e-02, 8.1010e-02, 8.4865e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: chúng_ta có 8 loài kền_kền xuất_hiện tại kenya , trong\n",
      "Reference: we have eight species of vultures that occur in\n",
      "Model: <SOS> we have eight 60,000 of in , in in\n",
      "Attention Weights: tensor([[7.2208e-01, 2.4275e-01, 3.4941e-02, 1.9302e-04, 2.9416e-05, 6.0079e-06,\n",
      "         8.6382e-07, 5.6365e-08, 1.6350e-08, 9.1220e-09],\n",
      "        [2.1090e-02, 8.1754e-01, 1.5645e-01, 3.8852e-03, 7.9330e-04, 2.1393e-04,\n",
      "         1.5916e-05, 1.1277e-05, 8.0415e-07, 1.0101e-06],\n",
      "        [3.7273e-03, 3.5671e-02, 7.8569e-01, 1.5432e-01, 1.3890e-02, 4.9365e-03,\n",
      "         8.4260e-04, 8.4980e-04, 4.2648e-05, 2.9203e-05],\n",
      "        [1.0272e-04, 1.0669e-04, 2.3438e-01, 6.8322e-01, 5.0659e-02, 1.5586e-02,\n",
      "         8.7851e-03, 6.7346e-03, 3.6552e-04, 6.2744e-05],\n",
      "        [5.7177e-06, 2.1910e-05, 1.0920e-02, 3.6587e-01, 4.1531e-01, 1.6346e-01,\n",
      "         3.1633e-02, 1.0326e-02, 2.0134e-03, 4.3297e-04],\n",
      "        [9.5368e-07, 3.1616e-06, 5.9909e-05, 9.5094e-03, 2.6897e-01, 3.9133e-01,\n",
      "         1.3096e-01, 9.4728e-02, 8.7776e-02, 1.6659e-02],\n",
      "        [2.1381e-06, 1.4622e-06, 1.0198e-04, 2.3806e-03, 7.6248e-02, 2.8000e-01,\n",
      "         1.4438e-01, 8.8948e-02, 2.1701e-01, 1.9093e-01],\n",
      "        [1.5430e-05, 1.1244e-05, 3.9207e-05, 8.8088e-04, 1.8621e-02, 3.4248e-02,\n",
      "         6.5865e-02, 3.2616e-02, 3.5650e-01, 4.9121e-01],\n",
      "        [3.0314e-06, 5.6894e-06, 1.6751e-04, 3.3876e-03, 2.4496e-02, 2.9449e-02,\n",
      "         2.9287e-02, 2.2641e-02, 1.2348e-01, 7.6708e-01]])\n",
      "\n",
      "Epoch: 13.48, Train Loss: 1.66, Val Loss: 4.59, Train BLEU: 27.79, Val BLEU: 10.44, Minutes Elapsed: 707.29\n",
      "Sampling from training predictions...\n",
      "Source: chúng_ta nói chúng_ta rất buồn và nói chúng_ta rất làm\n",
      "Reference: we say we &apos;re sad and we say we\n",
      "Model: <SOS> we say we &apos;re sad , we say we\n",
      "Attention Weights: tensor([[2.4923e-01, 7.3864e-01, 4.6011e-03, 7.3352e-03, 1.8740e-04, 4.3352e-06,\n",
      "         3.8040e-07, 1.5363e-07, 4.2210e-07, 9.5467e-08],\n",
      "        [8.2637e-04, 9.8638e-01, 5.4932e-03, 5.1030e-03, 2.0512e-03, 6.1907e-05,\n",
      "         4.7475e-05, 2.7650e-06, 3.2881e-05, 4.0681e-06],\n",
      "        [3.1913e-03, 4.1675e-01, 1.3753e-01, 3.5712e-01, 8.4409e-02, 5.1176e-04,\n",
      "         3.5055e-04, 2.0065e-05, 1.0059e-04, 1.5291e-05],\n",
      "        [1.9092e-04, 2.9723e-02, 6.7465e-02, 2.4230e-01, 6.5102e-01, 2.9370e-03,\n",
      "         5.0484e-03, 5.3926e-04, 5.7196e-04, 2.0493e-04],\n",
      "        [4.5603e-05, 1.6769e-02, 2.8367e-02, 1.1961e-01, 7.7452e-01, 2.3264e-02,\n",
      "         3.2893e-02, 1.0022e-03, 2.9228e-03, 6.0742e-04],\n",
      "        [7.0071e-05, 2.9787e-03, 1.5763e-02, 4.9696e-02, 2.0975e-01, 3.6223e-01,\n",
      "         3.0948e-01, 1.8104e-02, 2.6514e-02, 5.4107e-03],\n",
      "        [8.4327e-05, 4.3305e-03, 3.2916e-02, 6.1903e-02, 3.8538e-01, 3.1254e-01,\n",
      "         1.8819e-01, 6.6775e-03, 4.7895e-03, 3.1948e-03],\n",
      "        [2.9689e-05, 3.7746e-03, 4.1632e-03, 1.0383e-02, 2.6620e-02, 5.7614e-02,\n",
      "         8.0475e-01, 2.1004e-02, 5.9511e-02, 1.2154e-02],\n",
      "        [3.9124e-05, 1.7284e-03, 3.6838e-03, 2.8454e-02, 1.1893e-01, 2.5998e-02,\n",
      "         4.5201e-01, 3.3639e-02, 3.0268e-01, 3.2841e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: và tôi có được một công_tắc để có_thể tắt và\n",
      "Reference: and i got a switch where i can switch\n",
      "Model: <SOS> and i had a chance to be be be\n",
      "Attention Weights: tensor([[1.1478e-04, 5.7658e-03, 7.2349e-01, 2.6275e-01, 6.7576e-03, 3.5722e-04,\n",
      "         6.9111e-04, 4.1424e-05, 2.6917e-05, 2.8037e-06],\n",
      "        [2.9214e-03, 9.4509e-01, 4.6061e-02, 5.8586e-03, 5.1440e-05, 1.3400e-05,\n",
      "         1.9789e-06, 6.6789e-07, 1.0328e-07, 8.5271e-09],\n",
      "        [4.8581e-05, 4.4354e-02, 1.9274e-01, 7.4841e-01, 4.8580e-03, 8.7721e-03,\n",
      "         4.0430e-04, 2.3027e-04, 1.7929e-04, 3.5442e-06],\n",
      "        [5.3714e-05, 3.6879e-03, 2.5051e-02, 8.3964e-01, 5.5019e-02, 7.3105e-02,\n",
      "         2.0692e-03, 7.7741e-04, 5.6922e-04, 2.3680e-05],\n",
      "        [9.5164e-07, 3.5899e-06, 6.7655e-05, 1.9337e-02, 1.3323e-02, 9.4923e-01,\n",
      "         1.1250e-02, 3.3795e-03, 3.3127e-03, 9.2717e-05],\n",
      "        [6.4432e-06, 7.8632e-05, 1.6900e-03, 1.0792e-02, 7.4659e-02, 1.2229e-01,\n",
      "         6.4218e-01, 1.1912e-01, 2.7219e-02, 1.9621e-03],\n",
      "        [2.5077e-06, 4.1111e-04, 5.3258e-04, 2.6942e-03, 3.0007e-03, 3.7833e-02,\n",
      "         5.1356e-01, 3.6179e-01, 7.6067e-02, 4.1025e-03],\n",
      "        [1.0297e-07, 4.9415e-05, 5.2719e-05, 6.3666e-03, 9.1494e-04, 4.0465e-02,\n",
      "         2.0479e-01, 4.3085e-01, 3.0127e-01, 1.5240e-02],\n",
      "        [1.3519e-06, 1.0167e-04, 3.5643e-05, 4.2043e-03, 2.0304e-03, 3.5717e-02,\n",
      "         6.6756e-02, 2.2465e-01, 6.4503e-01, 2.1473e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13.53, Train Loss: 1.58, Val Loss: 4.61, Train BLEU: 29.13, Val BLEU: 10.06, Minutes Elapsed: 709.79\n",
      "Sampling from training predictions...\n",
      "Source: kết_quả là nó phụ_thuộc vào loại áo nào họ đang\n",
      "Reference: it turns out it depends on what kind of\n",
      "Model: <SOS> and result in , depends on the kind of\n",
      "Attention Weights: tensor([[9.9991e-01, 6.8709e-05, 1.6240e-05, 4.5395e-07, 4.0051e-08, 3.2924e-09,\n",
      "         5.1042e-09, 6.2621e-10, 1.3587e-10, 9.2132e-11],\n",
      "        [9.8903e-01, 7.0858e-03, 2.1603e-03, 1.6615e-03, 3.1971e-05, 2.5271e-05,\n",
      "         4.9503e-06, 2.8797e-06, 3.0630e-07, 5.3251e-07],\n",
      "        [5.5959e-01, 1.5151e-01, 5.9316e-02, 1.9856e-01, 2.2882e-02, 6.0746e-03,\n",
      "         1.4758e-03, 4.2147e-04, 5.5233e-05, 1.2358e-04],\n",
      "        [1.6772e-01, 2.2544e-01, 9.8769e-02, 2.8698e-01, 7.1014e-02, 1.0157e-01,\n",
      "         4.1520e-02, 5.7202e-03, 9.3889e-04, 3.2977e-04],\n",
      "        [6.0699e-03, 2.9288e-02, 1.1200e-01, 3.5999e-01, 1.0807e-01, 2.7408e-01,\n",
      "         7.8269e-02, 2.7885e-02, 3.5627e-03, 7.8070e-04],\n",
      "        [2.6515e-03, 1.5645e-02, 3.2589e-02, 3.1352e-01, 2.0934e-01, 2.4948e-01,\n",
      "         1.1189e-01, 6.0023e-02, 2.9031e-03, 1.9599e-03],\n",
      "        [3.2693e-04, 3.7285e-03, 4.3508e-03, 6.2945e-02, 1.6596e-01, 5.5972e-01,\n",
      "         1.4198e-01, 5.3965e-02, 4.7558e-03, 2.2672e-03],\n",
      "        [2.5402e-04, 2.8431e-03, 8.3334e-03, 4.8183e-02, 6.0020e-02, 4.0022e-01,\n",
      "         2.4380e-01, 2.1561e-01, 7.0806e-03, 1.3652e-02],\n",
      "        [6.5697e-04, 8.2249e-03, 2.7833e-02, 3.5573e-02, 5.4705e-02, 1.9828e-01,\n",
      "         2.7238e-01, 3.2036e-01, 2.6433e-02, 5.5554e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: chúng_tôi thực_sự ngạc_nhiên về những người bản_địa , tại thung_lũng\n",
      "Reference: and we were amazed that the local people ,\n",
      "Model: <SOS> we actually actually really fascinated the people , ,\n",
      "Attention Weights: tensor([[5.7094e-01, 4.2867e-01, 3.8818e-04, 1.5144e-06, 3.9475e-08, 5.3744e-08,\n",
      "         1.7186e-07, 2.4110e-10, 6.3450e-10, 6.1894e-10],\n",
      "        [9.8189e-04, 9.9232e-01, 6.6827e-03, 1.0386e-05, 5.7839e-06, 1.9312e-06,\n",
      "         1.5265e-06, 6.1573e-08, 2.1502e-07, 2.9888e-07],\n",
      "        [3.0422e-03, 5.6366e-01, 4.0980e-01, 1.8656e-02, 3.6710e-03, 4.6401e-04,\n",
      "         5.9533e-04, 5.5341e-05, 3.4698e-05, 2.3824e-05],\n",
      "        [5.8235e-03, 4.7313e-01, 4.9231e-01, 1.9955e-02, 5.8956e-03, 8.9572e-04,\n",
      "         1.8297e-03, 7.5313e-05, 2.7863e-05, 5.2145e-05],\n",
      "        [4.1888e-03, 7.8297e-02, 7.0362e-01, 1.2079e-01, 6.3509e-02, 1.9627e-02,\n",
      "         8.4407e-03, 1.3797e-03, 7.8043e-05, 7.1453e-05],\n",
      "        [7.0722e-03, 1.0573e-02, 7.1630e-01, 1.6020e-01, 6.0966e-02, 1.8824e-02,\n",
      "         2.0446e-02, 4.6324e-03, 7.7110e-04, 2.1015e-04],\n",
      "        [3.3227e-04, 1.7961e-04, 4.1490e-02, 1.7695e-01, 4.3375e-01, 9.5371e-02,\n",
      "         1.0618e-01, 5.5326e-02, 8.2982e-02, 7.4369e-03],\n",
      "        [3.5386e-05, 9.2264e-05, 2.6488e-03, 5.6648e-02, 1.4954e-01, 1.9499e-01,\n",
      "         3.2949e-01, 1.1337e-01, 1.0801e-01, 4.5165e-02],\n",
      "        [4.5395e-05, 2.1783e-05, 2.3749e-04, 1.9469e-03, 1.5174e-02, 1.1444e-02,\n",
      "         2.3931e-02, 3.1760e-01, 4.9891e-01, 1.3068e-01]])\n",
      "\n",
      "Epoch: 13.58, Train Loss: 1.57, Val Loss: 4.62, Train BLEU: 30.00, Val BLEU: 10.65, Minutes Elapsed: 712.28\n",
      "Sampling from training predictions...\n",
      "Source: \" gửi ngài , với sự yêu_mến \" đốt_cháy khán_giả\n",
      "Reference: &quot; to sir , with love &quot; ignited its\n",
      "Model: <SOS> &quot; <UNK> , , with god . ignited .\n",
      "Attention Weights: tensor([[8.2242e-01, 1.4499e-01, 3.1943e-02, 6.4371e-04, 7.1971e-06, 9.4259e-08,\n",
      "         9.1362e-08, 4.6342e-09, 5.2582e-09, 4.2008e-08],\n",
      "        [2.7806e-03, 7.0464e-01, 2.9017e-01, 2.2514e-03, 1.4095e-04, 1.1509e-05,\n",
      "         3.3692e-06, 6.1775e-07, 1.0745e-06, 3.2355e-07],\n",
      "        [7.7821e-04, 8.9733e-02, 5.4304e-01, 1.9221e-01, 1.5321e-01, 1.0805e-02,\n",
      "         9.1133e-03, 6.1634e-04, 3.6291e-04, 1.2534e-04],\n",
      "        [1.3106e-04, 2.1305e-02, 6.6219e-02, 6.6736e-02, 6.7199e-01, 9.9305e-02,\n",
      "         6.5495e-02, 5.1290e-03, 2.8852e-03, 8.0417e-04],\n",
      "        [2.0659e-05, 3.1177e-04, 8.5852e-04, 1.0322e-02, 7.3274e-01, 7.6192e-02,\n",
      "         1.5238e-01, 2.1057e-02, 3.8140e-03, 2.2967e-03],\n",
      "        [1.2307e-05, 1.0229e-03, 2.4109e-04, 7.0918e-04, 1.1601e-01, 1.4594e-01,\n",
      "         2.5969e-01, 1.9316e-01, 1.9101e-01, 9.2215e-02],\n",
      "        [1.9784e-05, 9.5836e-04, 1.6147e-03, 1.1024e-03, 3.4568e-02, 3.2976e-02,\n",
      "         9.3248e-02, 6.5595e-02, 5.2895e-01, 2.4097e-01],\n",
      "        [2.0972e-05, 3.5583e-04, 2.0772e-04, 3.9871e-04, 1.1343e-02, 1.3701e-02,\n",
      "         1.6506e-02, 1.0091e-01, 6.9105e-01, 1.6551e-01],\n",
      "        [8.7779e-06, 2.2466e-04, 9.8528e-05, 4.4564e-04, 6.6943e-03, 6.0433e-03,\n",
      "         8.2239e-03, 5.0391e-02, 5.9875e-01, 3.2912e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: và những điều đó là sự_thật , nhưng đó chỉ\n",
      "Reference: and those things are true , but they &apos;re\n",
      "Model: <SOS> and the are often , , but that &apos;s\n",
      "Attention Weights: tensor([[2.0207e-03, 7.5908e-01, 2.3427e-01, 4.4101e-03, 1.9622e-04, 2.1767e-05,\n",
      "         7.3362e-07, 2.6576e-07, 8.8325e-08, 1.5792e-08],\n",
      "        [9.9376e-03, 8.2343e-01, 1.6035e-01, 5.7274e-03, 4.5912e-04, 9.1930e-05,\n",
      "         3.8064e-06, 4.9379e-07, 5.3472e-07, 2.4573e-07],\n",
      "        [8.5421e-05, 6.3823e-02, 3.7712e-01, 1.7249e-01, 3.5563e-01, 2.8803e-02,\n",
      "         1.0238e-03, 8.2341e-04, 1.3443e-04, 6.2116e-05],\n",
      "        [1.5530e-05, 4.5411e-03, 2.8129e-02, 2.9716e-02, 6.0985e-01, 2.8213e-01,\n",
      "         3.1198e-02, 8.0512e-03, 3.2875e-03, 3.0866e-03],\n",
      "        [1.8172e-08, 3.1113e-05, 9.7831e-04, 1.0298e-03, 1.2401e-01, 2.9307e-01,\n",
      "         5.0758e-01, 6.7102e-02, 4.5962e-03, 1.5984e-03],\n",
      "        [2.5089e-06, 3.0858e-04, 4.3827e-04, 4.3072e-04, 3.0266e-03, 6.1604e-03,\n",
      "         9.3492e-02, 8.6513e-01, 2.3193e-02, 7.8219e-03],\n",
      "        [1.0117e-05, 7.3949e-04, 8.3905e-04, 1.0451e-03, 4.2768e-03, 1.1462e-02,\n",
      "         4.3365e-02, 8.5051e-01, 6.4966e-02, 2.2782e-02],\n",
      "        [3.3487e-04, 2.4197e-02, 2.8305e-03, 4.9032e-04, 1.4705e-03, 1.4939e-03,\n",
      "         1.0524e-02, 1.3193e-01, 6.0600e-01, 2.2073e-01],\n",
      "        [1.3863e-06, 3.8914e-04, 2.2897e-03, 7.6250e-04, 4.3785e-03, 2.4042e-03,\n",
      "         4.8021e-03, 9.5527e-02, 5.1062e-01, 3.7883e-01]])\n",
      "\n",
      "Epoch: 13.62, Train Loss: 1.63, Val Loss: 4.62, Train BLEU: 29.51, Val BLEU: 10.63, Minutes Elapsed: 714.79\n",
      "Sampling from training predictions...\n",
      "Source: đây là nó . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: here is the thing . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> this is what . . <EOS> . . <EOS>\n",
      "Attention Weights: tensor([[0.6740, 0.3209, 0.0045, 0.0005, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2623, 0.5729, 0.1542, 0.0105, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0142, 0.5201, 0.3445, 0.1154, 0.0058, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0032, 0.0848, 0.4889, 0.3337, 0.0893, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0028, 0.0240, 0.0940, 0.2631, 0.6160, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0129, 0.0710, 0.0974, 0.1289, 0.6898, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1243, 0.1744, 0.2323, 0.2036, 0.2654, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0109, 0.3382, 0.1194, 0.2768, 0.2548, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0023, 0.0302, 0.0399, 0.2163, 0.7114, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: nhưng nếu không_ai cho chúng thấy việc đó , nếu\n",
      "Reference: but when none of this is presented to them\n",
      "Model: <SOS> but if if you them for they they of\n",
      "Attention Weights: tensor([[1.6066e-04, 5.2423e-01, 4.7500e-01, 5.7854e-04, 1.1677e-05, 3.3735e-06,\n",
      "         5.4667e-06, 7.3377e-06, 2.5356e-07, 6.1737e-08],\n",
      "        [2.3823e-04, 4.2313e-01, 5.7490e-01, 1.6157e-03, 1.0811e-04, 6.4565e-06,\n",
      "         4.0689e-06, 1.4372e-06, 4.0970e-07, 5.5271e-07],\n",
      "        [3.5791e-06, 1.5359e-03, 9.7641e-01, 2.1755e-02, 2.0696e-04, 6.7788e-05,\n",
      "         1.9334e-05, 3.3774e-06, 9.6930e-07, 7.8491e-08],\n",
      "        [4.5815e-05, 7.6834e-04, 2.9653e-01, 6.3466e-01, 3.7390e-02, 2.4239e-02,\n",
      "         5.7915e-03, 4.1602e-04, 1.1432e-04, 3.8118e-05],\n",
      "        [1.9144e-05, 2.9290e-04, 4.5843e-01, 4.4433e-01, 4.8562e-02, 3.8861e-02,\n",
      "         8.5839e-03, 6.6359e-04, 2.3880e-04, 1.9373e-05],\n",
      "        [1.2252e-06, 1.5203e-05, 5.0389e-02, 3.1256e-01, 2.2789e-01, 3.1196e-01,\n",
      "         8.4024e-02, 8.3334e-03, 4.3114e-03, 5.2131e-04],\n",
      "        [2.7467e-06, 1.4229e-04, 5.8603e-02, 7.9703e-02, 4.2228e-01, 2.3480e-01,\n",
      "         1.6814e-01, 2.4407e-02, 1.0631e-02, 1.2860e-03],\n",
      "        [4.2323e-06, 4.1396e-05, 1.5568e-02, 1.3344e-01, 2.3559e-01, 3.2835e-01,\n",
      "         2.2914e-01, 2.9081e-02, 2.5461e-02, 3.3317e-03],\n",
      "        [4.0578e-06, 1.7979e-05, 1.6856e-02, 6.0632e-02, 1.6769e-01, 3.0836e-01,\n",
      "         3.1716e-01, 4.7231e-02, 7.0173e-02, 1.1875e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13.67, Train Loss: 1.61, Val Loss: 4.64, Train BLEU: 28.44, Val BLEU: 10.26, Minutes Elapsed: 717.28\n",
      "Sampling from training predictions...\n",
      "Source: và đó là thực_sự tuyệt_vời và tuyệt_vời . <EOS> <PAD>\n",
      "Reference: and it &apos;s truly awesome and wondrous . <EOS>\n",
      "Model: <SOS> and that was truly wonderful , wondrous . <EOS>\n",
      "Attention Weights: tensor([[0.0068, 0.4493, 0.5275, 0.0164, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0091, 0.7973, 0.1606, 0.0330, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0040, 0.2731, 0.6832, 0.0392, 0.0001, 0.0003, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0008, 0.2358, 0.5005, 0.2584, 0.0011, 0.0030, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0002, 0.0018, 0.1784, 0.7991, 0.0128, 0.0074, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0003, 0.0062, 0.2104, 0.7306, 0.0344, 0.0167, 0.0012, 0.0003,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0006, 0.0044, 0.0100, 0.2248, 0.1861, 0.4739, 0.0571, 0.0430,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0006, 0.0007, 0.0024, 0.0067, 0.1272, 0.5057, 0.2131, 0.1433,\n",
      "         0.0000],\n",
      "        [0.0004, 0.0021, 0.0096, 0.0115, 0.0304, 0.0270, 0.3218, 0.1299, 0.4672,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: làm thế_nào chúng_ta chia_sẻ nhiều hơn những kí_ức của chúng_ta\n",
      "Reference: how can we share more of our memories of\n",
      "Model: <SOS> how do we escape more more that that that\n",
      "Attention Weights: tensor([[9.9916e-01, 8.3347e-04, 8.8748e-06, 8.4055e-08, 2.9430e-07, 1.8841e-07,\n",
      "         3.2513e-10, 6.1727e-10, 4.1857e-11, 1.7293e-10],\n",
      "        [9.6105e-01, 2.0651e-02, 1.1750e-02, 5.9574e-03, 5.3615e-04, 5.1662e-05,\n",
      "         4.2678e-06, 1.6255e-06, 1.0897e-06, 3.4158e-07],\n",
      "        [1.9230e-01, 6.3341e-02, 2.1307e-01, 3.9797e-01, 1.2436e-01, 8.1003e-03,\n",
      "         4.8440e-04, 2.6497e-04, 6.5444e-05, 3.6849e-05],\n",
      "        [6.0034e-02, 4.9721e-03, 1.5421e-02, 8.0351e-01, 1.0412e-01, 1.0933e-02,\n",
      "         7.4862e-04, 1.6584e-04, 3.2867e-05, 5.5714e-05],\n",
      "        [3.1632e-04, 6.3034e-05, 5.0279e-05, 1.1610e-02, 1.1037e-01, 7.6971e-01,\n",
      "         9.1488e-02, 1.4461e-02, 1.7567e-03, 1.7692e-04],\n",
      "        [1.1722e-03, 4.6265e-04, 1.1897e-04, 7.8961e-03, 1.7525e-01, 5.1170e-01,\n",
      "         1.3493e-01, 1.5277e-01, 1.3520e-02, 2.1792e-03],\n",
      "        [6.1586e-05, 6.5901e-05, 1.1840e-04, 1.7707e-03, 2.1929e-03, 3.1217e-02,\n",
      "         2.7997e-01, 5.5322e-01, 9.6325e-02, 3.5064e-02],\n",
      "        [1.0428e-04, 1.6038e-04, 1.2662e-04, 1.0175e-03, 1.2743e-03, 3.7619e-03,\n",
      "         6.2223e-02, 7.3340e-01, 1.5161e-01, 4.6321e-02],\n",
      "        [4.5547e-03, 2.2897e-03, 2.0494e-03, 6.1823e-03, 5.9724e-03, 8.8194e-03,\n",
      "         7.9640e-02, 3.6104e-01, 3.0649e-01, 2.2296e-01]])\n",
      "\n",
      "Epoch: 13.72, Train Loss: 1.63, Val Loss: 4.65, Train BLEU: 27.76, Val BLEU: 10.33, Minutes Elapsed: 719.76\n",
      "Sampling from training predictions...\n",
      "Source: vậy_thì rất nhỏ , nhưng rất hữu_dụng . <EOS> <PAD>\n",
      "Reference: so very small , but very useful . <EOS>\n",
      "Model: <SOS> so very small , but clear useful . <EOS>\n",
      "Attention Weights: tensor([[0.9752, 0.0229, 0.0018, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0284, 0.5471, 0.4130, 0.0106, 0.0006, 0.0001, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0381, 0.1943, 0.5312, 0.1829, 0.0191, 0.0173, 0.0167, 0.0002, 0.0001,\n",
      "         0.0000],\n",
      "        [0.0123, 0.1023, 0.2515, 0.3554, 0.2186, 0.0270, 0.0317, 0.0010, 0.0002,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0014, 0.0199, 0.1604, 0.7252, 0.0725, 0.0150, 0.0044, 0.0012,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0014, 0.0188, 0.0459, 0.1314, 0.4344, 0.2505, 0.0895, 0.0277,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0026, 0.0059, 0.0053, 0.0094, 0.3908, 0.5629, 0.0149, 0.0077,\n",
      "         0.0000],\n",
      "        [0.0006, 0.0162, 0.0197, 0.0093, 0.0078, 0.0584, 0.7178, 0.1037, 0.0666,\n",
      "         0.0000],\n",
      "        [0.0004, 0.0221, 0.0211, 0.0415, 0.1121, 0.0329, 0.0865, 0.2058, 0.4776,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi biết rằng có một_vài người trong quý vị đang\n",
      "Reference: and i know there are people in the audience\n",
      "Model: <SOS> i know know that some of of you are\n",
      "Attention Weights: tensor([[3.3616e-02, 5.0738e-01, 4.4716e-01, 1.1626e-02, 1.9036e-04, 1.2619e-05,\n",
      "         5.4131e-06, 4.8022e-07, 3.1377e-07, 1.6681e-07],\n",
      "        [4.8130e-03, 4.4657e-01, 5.3913e-01, 6.9240e-03, 2.1458e-03, 1.8701e-04,\n",
      "         2.1064e-04, 1.1161e-05, 2.1064e-06, 5.6232e-06],\n",
      "        [3.1651e-03, 1.4413e-01, 7.0890e-01, 7.5743e-02, 5.0022e-02, 1.5269e-02,\n",
      "         2.3165e-03, 2.8102e-04, 7.0560e-05, 1.0982e-04],\n",
      "        [5.9676e-03, 3.9651e-01, 4.9880e-01, 4.0447e-02, 4.3536e-02, 1.0132e-02,\n",
      "         4.2508e-03, 2.3615e-04, 3.8892e-05, 8.3025e-05],\n",
      "        [8.2058e-05, 1.8928e-03, 4.6136e-02, 4.2919e-01, 3.6272e-01, 1.1952e-01,\n",
      "         2.9891e-02, 8.3730e-03, 1.7445e-03, 4.5325e-04],\n",
      "        [2.8465e-05, 1.3686e-03, 1.8311e-02, 8.1917e-02, 2.6309e-01, 1.8193e-01,\n",
      "         3.7276e-01, 6.5334e-02, 9.2912e-03, 5.9794e-03],\n",
      "        [2.6301e-06, 4.1375e-04, 2.8084e-03, 4.3083e-02, 1.7221e-01, 2.0210e-01,\n",
      "         4.4993e-01, 1.0923e-01, 1.2228e-02, 7.9909e-03],\n",
      "        [5.2954e-07, 2.4574e-05, 3.9688e-04, 1.0403e-02, 6.0049e-02, 6.0519e-02,\n",
      "         3.1451e-01, 4.6430e-01, 7.4685e-02, 1.5108e-02],\n",
      "        [7.3170e-07, 1.3760e-05, 3.0635e-04, 6.0003e-03, 3.2934e-02, 1.8572e-02,\n",
      "         3.0561e-01, 3.5533e-01, 1.7242e-01, 1.0881e-01]])\n",
      "\n",
      "Epoch: 13.77, Train Loss: 1.58, Val Loss: 4.65, Train BLEU: 29.33, Val BLEU: 10.28, Minutes Elapsed: 722.20\n",
      "Sampling from training predictions...\n",
      "Source: ngay_lập_tức , như francesca đã nói , chúng_tôi thay đổi_đời\n",
      "Reference: so immediately , as francesca said , we changed\n",
      "Model: <SOS> immediately , as as francesca said , we &apos;re\n",
      "Attention Weights: tensor([[9.9351e-01, 6.3949e-03, 9.4400e-05, 5.5941e-06, 1.1436e-07, 3.0308e-09,\n",
      "         6.5433e-12, 6.0461e-11, 2.7821e-10, 3.7990e-11],\n",
      "        [1.9919e-01, 3.0294e-01, 4.9187e-01, 5.8452e-03, 1.4099e-04, 6.8219e-06,\n",
      "         5.9848e-07, 7.5013e-07, 6.3392e-07, 2.7631e-07],\n",
      "        [1.5131e-02, 2.9435e-02, 9.1713e-01, 3.5887e-02, 1.7564e-03, 5.6779e-04,\n",
      "         1.9794e-05, 3.6567e-05, 2.8015e-05, 1.3439e-05],\n",
      "        [1.5221e-03, 1.9707e-03, 6.2855e-01, 3.5192e-01, 8.9244e-03, 5.9532e-03,\n",
      "         1.5807e-04, 6.3485e-04, 2.2856e-04, 1.4451e-04],\n",
      "        [1.1828e-04, 2.9926e-04, 1.8562e-01, 4.6377e-01, 2.0672e-01, 1.3112e-01,\n",
      "         1.5738e-03, 4.8501e-03, 5.1192e-03, 8.0382e-04],\n",
      "        [5.0813e-05, 1.0122e-04, 5.1645e-02, 1.4809e-01, 4.5008e-01, 3.1169e-01,\n",
      "         1.0825e-02, 5.2063e-03, 1.6483e-02, 5.8217e-03],\n",
      "        [2.6916e-05, 6.5365e-05, 2.0563e-02, 1.2453e-02, 3.6320e-02, 7.3760e-01,\n",
      "         1.4443e-01, 1.6344e-02, 2.1525e-02, 1.0672e-02],\n",
      "        [3.9447e-07, 3.5196e-06, 2.6390e-04, 1.3336e-03, 3.1473e-03, 6.1588e-02,\n",
      "         2.8041e-01, 5.6472e-01, 6.8600e-02, 1.9933e-02],\n",
      "        [9.4267e-07, 2.9802e-06, 2.5607e-04, 2.7745e-04, 3.6389e-04, 1.5145e-03,\n",
      "         2.7922e-02, 4.4299e-01, 4.2443e-01, 1.0224e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: bạn có sức_mạnh để kết_thúc bạo_lực gia_đình đơn_giản bằng cách\n",
      "Reference: you have the power to end domestic violence simply\n",
      "Model: <SOS> you &apos;re going to to ended the the by\n",
      "Attention Weights: tensor([[8.3480e-01, 1.6442e-01, 5.0462e-04, 2.7248e-04, 4.9583e-06, 5.2164e-07,\n",
      "         2.1488e-08, 5.6261e-09, 4.8121e-10, 5.2098e-11],\n",
      "        [5.2126e-03, 3.3862e-01, 6.5289e-01, 2.3986e-03, 8.1459e-04, 4.0637e-05,\n",
      "         1.5715e-05, 7.2583e-06, 1.6074e-06, 7.4105e-07],\n",
      "        [2.5699e-03, 3.1149e-02, 9.1205e-01, 4.5224e-02, 8.2984e-03, 5.9301e-04,\n",
      "         6.8174e-05, 3.6042e-05, 7.6327e-06, 3.3525e-06],\n",
      "        [6.5569e-03, 5.6031e-03, 4.2799e-01, 4.4172e-01, 1.1434e-01, 2.9028e-03,\n",
      "         4.9069e-04, 3.7149e-04, 1.7886e-05, 8.4734e-06],\n",
      "        [4.4450e-03, 7.6094e-03, 9.8778e-02, 1.9069e-01, 6.4421e-01, 4.0632e-02,\n",
      "         6.5652e-03, 5.6367e-03, 1.1822e-03, 2.4880e-04],\n",
      "        [8.7290e-03, 3.7765e-03, 1.5176e-02, 5.0487e-02, 7.5642e-01, 1.3879e-01,\n",
      "         1.3181e-02, 1.0319e-02, 1.9691e-03, 1.1526e-03],\n",
      "        [2.8036e-03, 1.0881e-03, 1.2690e-02, 3.5442e-02, 4.6087e-01, 3.5615e-01,\n",
      "         6.5676e-02, 4.4937e-02, 1.6111e-02, 4.2251e-03],\n",
      "        [5.1300e-06, 1.7939e-06, 3.6891e-04, 5.5899e-04, 5.9384e-02, 2.1811e-01,\n",
      "         1.4722e-01, 3.8987e-01, 1.3126e-01, 5.3216e-02],\n",
      "        [2.5179e-06, 1.8563e-06, 4.7438e-05, 3.6803e-04, 2.5514e-02, 1.3224e-01,\n",
      "         2.1579e-01, 4.7768e-01, 8.7986e-02, 6.0365e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13.82, Train Loss: 1.55, Val Loss: 4.67, Train BLEU: 29.38, Val BLEU: 10.13, Minutes Elapsed: 724.70\n",
      "Sampling from training predictions...\n",
      "Source: xin chào . tôi đề_nghị các bạn giơ tay và\n",
      "Reference: hi . i &apos;m going to ask you to\n",
      "Model: <SOS> hi . i &apos;m going to give you to\n",
      "Attention Weights: tensor([[7.8622e-04, 9.9909e-01, 1.1294e-04, 1.6945e-06, 1.2405e-06, 4.3749e-07,\n",
      "         3.0419e-07, 4.1263e-06, 5.9204e-07, 1.0682e-07],\n",
      "        [1.2465e-04, 1.6465e-02, 9.8050e-01, 2.1628e-03, 7.0633e-04, 1.8020e-05,\n",
      "         1.0991e-05, 7.7897e-06, 1.0738e-06, 1.4172e-07],\n",
      "        [4.4212e-05, 1.2457e-02, 4.7303e-01, 4.9306e-01, 1.7224e-02, 1.7538e-03,\n",
      "         4.7542e-04, 1.7427e-03, 1.7254e-04, 3.7312e-05],\n",
      "        [7.9557e-05, 1.9179e-02, 2.5784e-01, 6.2775e-01, 7.8674e-02, 1.1584e-02,\n",
      "         2.9727e-03, 1.4885e-03, 2.3140e-04, 1.9465e-04],\n",
      "        [1.0821e-05, 6.8777e-04, 1.0605e-02, 2.9602e-01, 4.3901e-01, 1.8949e-01,\n",
      "         3.3386e-02, 2.7452e-02, 3.0471e-03, 2.9185e-04],\n",
      "        [4.1651e-06, 1.7812e-04, 3.1624e-03, 6.1448e-02, 4.2108e-01, 1.1311e-01,\n",
      "         5.9400e-02, 3.0485e-01, 3.4048e-02, 2.7214e-03],\n",
      "        [1.4983e-07, 1.7600e-05, 1.1763e-02, 3.6219e-02, 9.2506e-02, 1.8952e-02,\n",
      "         3.0370e-02, 6.9236e-01, 1.0483e-01, 1.2982e-02],\n",
      "        [2.9581e-07, 6.4115e-06, 1.6554e-03, 4.0339e-03, 1.6670e-02, 1.6263e-01,\n",
      "         3.0335e-01, 3.9210e-01, 1.1694e-01, 2.6195e-03],\n",
      "        [4.2655e-08, 6.0367e-06, 5.1295e-04, 1.5756e-03, 4.9763e-03, 1.0235e-02,\n",
      "         4.7939e-02, 6.5325e-01, 2.5569e-01, 2.5817e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: cảm_ơn . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: thank you . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> thank you . <EOS> . <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.0004, 0.0082, 0.9914, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1427, 0.8373, 0.0200, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2210, 0.6187, 0.1604, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0434, 0.5079, 0.4487, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0382, 0.9164, 0.0454, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0817, 0.6352, 0.2831, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0155, 0.9704, 0.0141, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0224, 0.9605, 0.0171, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0173, 0.9729, 0.0098, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 13.86, Train Loss: 1.56, Val Loss: 4.64, Train BLEU: 30.22, Val BLEU: 9.85, Minutes Elapsed: 727.18\n",
      "Sampling from training predictions...\n",
      "Source: vậy , có_thể vấn_đề ở đây là 1 mức_độ gian_lận\n",
      "Reference: so , maybe what is happening is that there\n",
      "Model: <SOS> so , maybe the matter happening is that there\n",
      "Attention Weights: tensor([[9.3398e-01, 5.7662e-02, 8.3016e-03, 6.0109e-05, 1.4513e-07, 1.4799e-08,\n",
      "         1.1244e-10, 9.8488e-11, 3.0949e-11, 2.9190e-11],\n",
      "        [4.0465e-03, 7.3262e-01, 2.5046e-01, 1.2581e-02, 2.6835e-04, 2.4992e-05,\n",
      "         5.3292e-07, 6.7551e-07, 2.4398e-07, 2.0938e-07],\n",
      "        [7.0413e-05, 1.5556e-02, 9.5054e-01, 2.8090e-02, 4.9085e-03, 6.5362e-04,\n",
      "         1.2528e-04, 3.4064e-05, 1.3615e-05, 8.6696e-06],\n",
      "        [4.4905e-05, 6.4544e-03, 6.6681e-01, 2.5049e-01, 6.6875e-02, 6.7908e-03,\n",
      "         1.8960e-03, 2.8983e-04, 2.6752e-04, 8.9436e-05],\n",
      "        [1.0962e-04, 3.5787e-03, 2.0264e-01, 6.2571e-01, 1.3798e-01, 6.1674e-03,\n",
      "         1.6812e-02, 3.7193e-03, 2.9572e-03, 3.3305e-04],\n",
      "        [9.3879e-06, 3.0901e-05, 1.0237e-02, 3.4878e-01, 3.6325e-01, 8.7245e-02,\n",
      "         8.9288e-02, 3.9819e-02, 5.1035e-02, 1.0312e-02],\n",
      "        [3.1273e-05, 8.5861e-05, 4.9580e-04, 2.7423e-02, 2.1362e-01, 1.0424e-01,\n",
      "         3.6052e-01, 1.0018e-01, 1.3357e-01, 5.9834e-02],\n",
      "        [5.2282e-05, 1.3274e-05, 2.0301e-04, 1.3885e-03, 2.3472e-02, 1.4547e-01,\n",
      "         1.2495e-01, 1.5986e-01, 4.1679e-01, 1.2780e-01],\n",
      "        [2.1964e-05, 5.7982e-05, 1.9158e-03, 6.5910e-03, 1.5107e-02, 1.2140e-01,\n",
      "         3.1218e-01, 1.4890e-01, 2.4542e-01, 1.4841e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi có rất nhiều đôi giầy cao gót <UNK> mà\n",
      "Reference: i do have too many <UNK> heels which i\n",
      "Model: <SOS> i have a lot high <UNK> <UNK> high all\n",
      "Attention Weights: tensor([[3.1218e-01, 6.7921e-01, 8.4579e-03, 1.4170e-04, 1.5168e-05, 2.8673e-07,\n",
      "         4.2205e-07, 5.0412e-08, 1.7722e-08, 8.0300e-09],\n",
      "        [3.4047e-03, 9.5266e-01, 4.0546e-02, 2.6071e-03, 4.7473e-04, 2.6520e-04,\n",
      "         3.0156e-05, 8.2678e-06, 4.2335e-06, 1.5283e-06],\n",
      "        [4.3674e-03, 1.3697e-01, 6.4632e-01, 1.5931e-01, 3.0750e-02, 1.9744e-02,\n",
      "         1.8777e-03, 4.9986e-04, 1.3319e-04, 3.7123e-05],\n",
      "        [4.5656e-05, 4.2767e-04, 3.0649e-01, 6.4111e-01, 3.5814e-02, 1.4071e-02,\n",
      "         1.6090e-03, 3.9513e-04, 2.9206e-05, 6.0299e-06],\n",
      "        [8.0913e-05, 1.1881e-03, 8.3714e-02, 3.4751e-01, 3.3569e-01, 1.5255e-01,\n",
      "         5.8208e-02, 1.7126e-02, 2.3515e-03, 1.5929e-03],\n",
      "        [1.5775e-05, 7.3962e-05, 9.7880e-03, 2.3615e-01, 2.4113e-01, 3.7763e-01,\n",
      "         9.8795e-02, 3.0429e-02, 2.9293e-03, 3.0544e-03],\n",
      "        [4.5443e-06, 1.8036e-05, 8.7749e-04, 5.0242e-02, 6.0250e-02, 3.0133e-01,\n",
      "         2.1361e-01, 3.0133e-01, 4.0398e-02, 3.1944e-02],\n",
      "        [1.5883e-06, 8.8389e-07, 3.9951e-05, 1.5177e-03, 1.5473e-02, 5.8109e-02,\n",
      "         1.8556e-01, 4.8846e-01, 1.1591e-01, 1.3494e-01],\n",
      "        [7.4903e-06, 4.4419e-06, 1.0866e-04, 9.3518e-04, 1.3044e-03, 3.9341e-03,\n",
      "         3.1173e-02, 3.0233e-01, 1.7896e-01, 4.8124e-01]])\n",
      "\n",
      "Epoch: 13.91, Train Loss: 1.43, Val Loss: 4.68, Train BLEU: 32.52, Val BLEU: 9.67, Minutes Elapsed: 729.66\n",
      "Sampling from training predictions...\n",
      "Source: vậy_nên âm_nhạc phải đủ vang để có_thể át những tiếng_ồn\n",
      "Reference: so the music has to be loud enough to\n",
      "Model: <SOS> so music music has to be loud enough learn\n",
      "Attention Weights: tensor([[9.9996e-01, 3.8367e-05, 1.5027e-06, 4.6835e-08, 5.4586e-10, 6.6908e-10,\n",
      "         9.9929e-12, 1.0217e-13, 3.7810e-14, 4.8087e-14],\n",
      "        [1.5454e-01, 7.8116e-01, 6.3016e-02, 9.7570e-04, 2.2461e-04, 7.6206e-05,\n",
      "         7.9000e-06, 3.4109e-07, 1.0319e-07, 6.9485e-07],\n",
      "        [4.0463e-02, 7.5074e-01, 1.9459e-01, 1.2950e-02, 1.0564e-03, 1.2223e-04,\n",
      "         5.1926e-05, 2.3392e-05, 2.2945e-06, 5.0524e-06],\n",
      "        [4.1619e-02, 3.5112e-01, 4.2662e-01, 1.6534e-01, 1.1294e-02, 2.1821e-03,\n",
      "         8.5444e-04, 8.3434e-04, 6.7998e-05, 7.2898e-05],\n",
      "        [3.2377e-03, 2.4216e-01, 6.1354e-01, 1.1833e-01, 1.8483e-02, 2.7003e-03,\n",
      "         8.6408e-04, 5.5768e-04, 4.2545e-05, 8.5329e-05],\n",
      "        [1.7959e-04, 1.5633e-02, 4.4055e-01, 3.0797e-01, 1.3485e-01, 5.7029e-02,\n",
      "         2.5756e-02, 1.5243e-02, 1.5206e-03, 1.2734e-03],\n",
      "        [4.6331e-05, 8.4562e-04, 1.3990e-02, 4.8581e-01, 2.1046e-01, 7.3699e-02,\n",
      "         9.6069e-02, 1.0411e-01, 7.3086e-03, 7.6624e-03],\n",
      "        [1.6366e-05, 1.4680e-03, 9.3351e-03, 1.9851e-01, 2.4001e-01, 1.9766e-01,\n",
      "         1.4184e-01, 1.5926e-01, 1.3296e-02, 3.8600e-02],\n",
      "        [1.0927e-04, 7.3124e-03, 7.1417e-03, 5.1144e-02, 6.8784e-02, 3.3120e-01,\n",
      "         2.9520e-01, 1.7706e-01, 2.7222e-02, 3.4827e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: ông ấy nở một nụ cười rất lớn , điều\n",
      "Reference: there was a big smile on his face which\n",
      "Model: <SOS> he actually a very , , , , ,\n",
      "Attention Weights: tensor([[9.6573e-01, 3.0225e-02, 3.9499e-03, 8.8434e-05, 8.4852e-06, 1.0637e-06,\n",
      "         1.4394e-07, 1.5820e-08, 2.7014e-11, 5.8738e-10],\n",
      "        [5.1016e-04, 1.8703e-03, 9.9356e-01, 2.7641e-03, 1.0494e-03, 2.1143e-04,\n",
      "         2.7334e-05, 2.7492e-06, 1.3080e-07, 2.0431e-07],\n",
      "        [9.0853e-04, 6.3690e-03, 8.2044e-01, 6.5024e-02, 6.6176e-02, 3.5783e-02,\n",
      "         4.8435e-03, 4.3624e-04, 1.1069e-05, 9.0986e-06],\n",
      "        [2.1509e-03, 8.4819e-03, 1.8744e-01, 1.0281e-01, 3.6474e-01, 2.0450e-01,\n",
      "         9.7611e-02, 3.1770e-02, 2.8639e-04, 2.1922e-04],\n",
      "        [7.6559e-04, 5.4850e-03, 1.5006e-01, 2.4415e-02, 4.6261e-01, 2.9136e-01,\n",
      "         5.5344e-02, 8.0161e-03, 1.4449e-03, 5.0168e-04],\n",
      "        [6.5099e-03, 2.4183e-03, 7.5383e-02, 2.4149e-02, 1.8961e-01, 1.7338e-01,\n",
      "         7.8202e-02, 1.4628e-01, 9.7387e-02, 2.0668e-01],\n",
      "        [2.1656e-05, 3.7526e-05, 8.7572e-04, 1.2132e-03, 2.0114e-02, 2.4121e-02,\n",
      "         1.6058e-02, 8.8357e-02, 2.1587e-01, 6.3333e-01],\n",
      "        [2.5618e-05, 2.6304e-05, 2.1153e-04, 1.5658e-03, 6.7907e-03, 3.1835e-02,\n",
      "         5.3398e-02, 9.3438e-02, 6.5950e-02, 7.4676e-01],\n",
      "        [7.2076e-05, 7.4744e-05, 2.7363e-04, 6.8161e-04, 2.1433e-02, 1.4829e-02,\n",
      "         9.3487e-03, 2.4533e-02, 1.1878e-01, 8.0998e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13.96, Train Loss: 1.31, Val Loss: 4.63, Train BLEU: 36.80, Val BLEU: 10.01, Minutes Elapsed: 732.16\n",
      "Sampling from training predictions...\n",
      "Source: đó là cách làm thế_nào bạn trở_thành một đại kiện_tướng\n",
      "Reference: that &apos;s how you become a legendary grandmaster of\n",
      "Model: <SOS> that &apos;s how you become a legendary grandmaster of\n",
      "Attention Weights: tensor([[5.3195e-01, 4.6758e-01, 1.3581e-04, 3.0256e-04, 1.9007e-05, 2.5300e-06,\n",
      "         8.6497e-07, 1.7959e-07, 7.9037e-09, 1.0455e-08],\n",
      "        [4.2300e-03, 7.7837e-01, 1.7106e-01, 3.5097e-02, 9.0248e-03, 6.5812e-04,\n",
      "         1.4850e-03, 3.2515e-05, 1.9826e-05, 2.0114e-05],\n",
      "        [7.5034e-03, 4.3297e-01, 3.8174e-01, 1.1085e-01, 5.3215e-02, 4.9439e-03,\n",
      "         7.1560e-03, 8.2390e-04, 3.5863e-04, 4.4347e-04],\n",
      "        [1.0042e-04, 3.4928e-02, 2.5251e-01, 2.9744e-01, 2.2537e-01, 6.1261e-02,\n",
      "         1.1458e-01, 7.6276e-03, 3.5852e-03, 2.5963e-03],\n",
      "        [1.0120e-04, 7.5812e-03, 4.5608e-02, 8.7150e-02, 1.3523e-01, 1.6139e-01,\n",
      "         5.4052e-01, 1.3634e-02, 6.0859e-03, 2.7041e-03],\n",
      "        [3.0066e-04, 1.3567e-03, 6.7304e-03, 1.2925e-02, 5.4682e-02, 8.6463e-02,\n",
      "         6.4849e-01, 1.3232e-01, 4.6098e-02, 1.0625e-02],\n",
      "        [6.1849e-07, 1.0743e-05, 5.8619e-04, 3.8086e-03, 2.2827e-02, 8.5940e-04,\n",
      "         2.0390e-02, 4.7600e-02, 4.4342e-01, 4.6050e-01],\n",
      "        [1.9260e-05, 6.5412e-05, 2.7854e-04, 5.3506e-02, 2.6163e-02, 8.8744e-04,\n",
      "         1.8184e-03, 2.9807e-02, 3.3735e-01, 5.5010e-01],\n",
      "        [4.9017e-04, 1.7201e-03, 3.7189e-04, 2.7718e-02, 2.7999e-02, 4.8589e-03,\n",
      "         1.0843e-03, 4.4630e-02, 3.7300e-01, 5.1813e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: sao_vậy ? bởi_vì họ nhìn vào đường_cong trên phác_đồ và\n",
      "Reference: why ? because they looked at the curve and\n",
      "Model: <SOS> why ? because they look into the and and\n",
      "Attention Weights: tensor([[9.9998e-01, 1.8978e-05, 6.6884e-07, 1.3412e-08, 5.2163e-09, 6.6231e-10,\n",
      "         7.7596e-11, 3.0518e-11, 1.0777e-11, 7.8870e-13],\n",
      "        [1.8716e-02, 5.3250e-01, 4.4733e-01, 1.2216e-03, 1.9190e-04, 2.8137e-05,\n",
      "         4.6838e-06, 5.9196e-06, 1.0991e-06, 1.4359e-07],\n",
      "        [1.6215e-03, 1.3695e-02, 8.5839e-01, 1.2498e-01, 5.8845e-04, 4.4220e-04,\n",
      "         1.9881e-04, 5.0792e-05, 2.3989e-05, 3.1078e-06],\n",
      "        [3.6369e-04, 2.8495e-03, 2.1093e-01, 6.2827e-01, 1.4473e-01, 9.8057e-03,\n",
      "         2.0162e-03, 6.3146e-04, 3.5120e-04, 5.2822e-05],\n",
      "        [6.5197e-04, 3.7513e-03, 1.3108e-02, 1.0962e-01, 7.2581e-01, 1.1882e-01,\n",
      "         2.3204e-02, 4.1130e-03, 8.8648e-04, 3.5906e-05],\n",
      "        [1.0936e-04, 1.8863e-03, 3.7150e-03, 7.3591e-02, 5.6854e-01, 1.3322e-01,\n",
      "         1.6977e-01, 4.0627e-02, 8.2676e-03, 2.7645e-04],\n",
      "        [3.0262e-07, 3.0021e-05, 5.3861e-04, 6.5501e-04, 1.5032e-02, 1.4984e-01,\n",
      "         5.2048e-01, 9.1172e-02, 2.2107e-01, 1.1852e-03],\n",
      "        [1.7760e-06, 9.7030e-06, 1.0133e-03, 4.9473e-04, 1.4169e-03, 6.5695e-03,\n",
      "         1.7771e-01, 2.4190e-01, 5.3905e-01, 3.1833e-02],\n",
      "        [6.9232e-05, 2.5559e-04, 5.7941e-03, 1.0926e-03, 1.0552e-03, 1.4047e-03,\n",
      "         1.0260e-01, 2.1037e-01, 3.0201e-01, 3.7535e-01]])\n",
      "\n",
      "Epoch: 14.00, Train Loss: 1.06, Val Loss: 4.69, Train BLEU: 46.08, Val BLEU: 10.06, Minutes Elapsed: 734.24\n",
      "Sampling from training predictions...\n",
      "Source: nó tồn_tại . nó ở đó , và bạn biết\n",
      "Reference: well , it is there . it is there\n",
      "Model: <SOS> it is it &apos;s it . it &apos;s there\n",
      "Attention Weights: tensor([[6.5133e-01, 3.4823e-01, 4.0405e-04, 2.0575e-05, 9.3902e-06, 4.1417e-07,\n",
      "         1.3524e-09, 2.2413e-10, 3.3384e-09, 1.6671e-09],\n",
      "        [6.9991e-02, 9.1711e-01, 1.0762e-02, 5.4008e-04, 1.5317e-03, 5.3575e-05,\n",
      "         5.2686e-06, 3.2441e-07, 9.6414e-07, 1.7693e-06],\n",
      "        [1.3754e-02, 8.4406e-01, 1.3171e-01, 3.4946e-03, 6.3974e-03, 4.2097e-04,\n",
      "         1.1944e-04, 5.6778e-06, 1.5212e-05, 2.7143e-05],\n",
      "        [3.4691e-02, 8.5959e-01, 8.5159e-02, 8.9965e-03, 1.0614e-02, 6.0526e-04,\n",
      "         2.4346e-04, 2.4973e-05, 2.8891e-05, 4.7556e-05],\n",
      "        [5.7357e-02, 5.2243e-01, 2.3345e-01, 4.0428e-02, 1.3809e-01, 5.4008e-03,\n",
      "         2.3660e-03, 8.7917e-05, 1.3792e-04, 2.5686e-04],\n",
      "        [7.0821e-04, 6.6553e-02, 5.7518e-01, 2.5867e-01, 8.6448e-02, 6.2615e-03,\n",
      "         5.2521e-03, 5.7993e-04, 1.4171e-04, 1.9927e-04],\n",
      "        [6.3441e-05, 6.3971e-04, 7.5858e-03, 8.4668e-01, 9.8362e-02, 2.0270e-02,\n",
      "         1.4073e-02, 8.7096e-03, 1.8681e-03, 1.7443e-03],\n",
      "        [2.4637e-05, 1.2330e-04, 4.1196e-04, 2.3642e-01, 7.0687e-01, 1.5836e-02,\n",
      "         2.1531e-02, 3.7477e-03, 7.1605e-03, 7.8674e-03],\n",
      "        [1.9096e-04, 8.7039e-03, 7.1032e-04, 1.0278e-02, 7.2132e-01, 4.7636e-02,\n",
      "         3.0104e-02, 2.2621e-03, 3.4043e-02, 1.4475e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: bởi_vì nó rất rỗng , tất_cả tiếng_ồn sẽ biến mất\n",
      "Reference: because it &apos;s very hollow , all the noise\n",
      "Model: <SOS> because it &apos;s very , , it &apos;s it\n",
      "Attention Weights: tensor([[9.9866e-01, 1.3185e-03, 2.3548e-05, 8.9981e-07, 6.1343e-10, 2.9577e-10,\n",
      "         1.2705e-11, 1.4765e-11, 2.2177e-12, 1.1614e-12],\n",
      "        [3.9163e-02, 8.4942e-01, 9.7973e-02, 1.3304e-02, 8.4253e-05, 4.7215e-05,\n",
      "         2.9939e-06, 4.2192e-07, 8.9595e-08, 8.6957e-08],\n",
      "        [1.2900e-02, 2.4771e-01, 5.9729e-01, 1.4032e-01, 8.9224e-04, 5.0465e-04,\n",
      "         3.5936e-04, 1.6538e-05, 8.7811e-06, 2.5717e-06],\n",
      "        [1.1547e-02, 2.8612e-02, 3.3252e-01, 6.1785e-01, 6.4644e-03, 1.8633e-03,\n",
      "         9.9251e-04, 9.5299e-05, 4.8808e-05, 7.0447e-06],\n",
      "        [3.6357e-03, 1.1975e-02, 5.4915e-02, 8.5456e-01, 4.9119e-02, 2.1996e-02,\n",
      "         3.2050e-03, 3.1456e-04, 2.2250e-04, 6.0927e-05],\n",
      "        [1.2487e-03, 7.4354e-03, 3.4249e-02, 8.3065e-02, 1.5975e-01, 6.8997e-01,\n",
      "         1.8373e-02, 3.0449e-03, 1.7329e-03, 1.1320e-03],\n",
      "        [4.0788e-05, 9.0424e-04, 4.4896e-03, 2.1486e-02, 4.0245e-02, 7.6875e-01,\n",
      "         1.5134e-01, 8.1346e-03, 3.1790e-03, 1.4353e-03],\n",
      "        [5.1837e-06, 6.7981e-05, 8.5220e-04, 5.0390e-03, 1.9575e-02, 3.2374e-01,\n",
      "         6.1994e-01, 1.9233e-02, 8.2305e-03, 3.3208e-03],\n",
      "        [2.4933e-05, 4.5196e-04, 6.1558e-03, 9.3523e-03, 1.0679e-02, 1.0973e-01,\n",
      "         5.1775e-01, 1.7488e-01, 1.3589e-01, 3.5087e-02]])\n",
      "\n",
      "Epoch: 14.05, Train Loss: 0.99, Val Loss: 4.67, Train BLEU: 49.54, Val BLEU: 9.90, Minutes Elapsed: 736.70\n",
      "Sampling from training predictions...\n",
      "Source: điện_ảnh đáng được tranh_cãi là dạng nghệ_thuật ảnh_hưởng nhất trong\n",
      "Reference: cinema is arguably the 20th century &apos;s most influential\n",
      "Model: <SOS> cinema is arguably the 20th century century most most\n",
      "Attention Weights: tensor([[9.8614e-01, 1.3055e-02, 2.4884e-04, 5.2923e-04, 2.7896e-05, 1.2078e-06,\n",
      "         3.4180e-07, 6.2842e-07, 2.4704e-07, 1.0874e-08],\n",
      "        [3.6212e-01, 3.0665e-01, 1.8147e-01, 1.3715e-01, 9.8538e-03, 9.0454e-04,\n",
      "         8.3268e-04, 6.4672e-04, 3.5595e-04, 1.7631e-05],\n",
      "        [1.3231e-01, 3.4287e-01, 2.3617e-01, 1.5961e-01, 9.4937e-02, 9.8655e-03,\n",
      "         1.0781e-02, 1.0434e-02, 2.4986e-03, 5.3297e-04],\n",
      "        [1.9694e-05, 3.8433e-03, 2.6975e-02, 1.2652e-01, 5.0718e-01, 2.0759e-01,\n",
      "         7.0624e-02, 3.8941e-02, 1.2930e-02, 5.3735e-03],\n",
      "        [3.7935e-06, 2.4705e-04, 3.4037e-03, 1.9254e-02, 3.4544e-02, 2.7262e-01,\n",
      "         2.2012e-01, 3.6784e-01, 6.5320e-02, 1.6647e-02],\n",
      "        [1.1080e-05, 3.0244e-04, 2.4118e-03, 6.8416e-03, 4.8612e-03, 8.2760e-02,\n",
      "         4.4035e-01, 1.8913e-01, 6.7876e-03, 2.6653e-01],\n",
      "        [1.6887e-03, 7.1116e-04, 6.2583e-03, 5.0244e-02, 2.4779e-02, 1.0742e-01,\n",
      "         1.9274e-01, 3.1619e-02, 4.8494e-03, 5.7970e-01],\n",
      "        [1.8235e-05, 4.4191e-04, 2.2970e-03, 1.6831e-02, 7.9107e-03, 7.4447e-02,\n",
      "         4.3355e-01, 5.3525e-02, 2.2821e-02, 3.8816e-01],\n",
      "        [8.4644e-07, 1.6944e-04, 2.5615e-04, 1.3296e-03, 7.7687e-03, 4.0423e-02,\n",
      "         4.4658e-01, 8.1060e-02, 2.3234e-02, 3.9918e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: <UNK> 22 tuổi , <UNK> và rất đẹp_trai , <EOS>\n",
      "Reference: <UNK> is 22 , tall and very handsome .\n",
      "Model: <SOS> it &apos;s of , and and and , .\n",
      "Attention Weights: tensor([[3.1571e-02, 9.6834e-01, 8.4901e-05, 2.8816e-08, 3.1879e-09, 1.7408e-08,\n",
      "         3.0501e-09, 7.2153e-12, 1.2818e-11, 8.2187e-12],\n",
      "        [5.8131e-02, 8.5945e-01, 8.0935e-02, 1.1072e-03, 2.2529e-04, 5.6178e-05,\n",
      "         6.8660e-05, 2.7683e-05, 1.5420e-06, 1.3185e-06],\n",
      "        [1.7391e-02, 2.7187e-01, 6.8732e-01, 1.7328e-02, 3.9792e-03, 8.9522e-04,\n",
      "         6.3019e-04, 4.2698e-04, 9.5185e-05, 6.1905e-05],\n",
      "        [2.3284e-05, 1.7250e-03, 8.1545e-02, 5.0428e-01, 2.5958e-01, 5.7895e-02,\n",
      "         7.8221e-02, 1.3579e-02, 2.3050e-03, 8.4521e-04],\n",
      "        [3.1070e-05, 3.0082e-03, 4.4917e-02, 6.2798e-01, 1.9675e-01, 5.5944e-02,\n",
      "         5.4381e-02, 8.2386e-03, 5.5326e-03, 3.2178e-03],\n",
      "        [1.3262e-04, 7.8661e-02, 2.3165e-02, 1.6510e-01, 4.1988e-01, 1.3458e-01,\n",
      "         1.4998e-01, 1.6314e-02, 1.0458e-02, 1.7249e-03],\n",
      "        [1.8599e-05, 4.8555e-04, 1.3702e-03, 1.1937e-02, 6.7997e-02, 7.9670e-02,\n",
      "         6.9589e-01, 1.1412e-01, 1.6949e-02, 1.1560e-02],\n",
      "        [1.8789e-06, 4.5314e-04, 1.1072e-02, 2.2758e-02, 8.5042e-02, 6.4509e-02,\n",
      "         6.3272e-01, 1.4425e-01, 3.3377e-02, 5.8082e-03],\n",
      "        [8.9372e-06, 4.1455e-04, 1.0987e-03, 3.1230e-02, 3.9270e-02, 5.3215e-02,\n",
      "         2.7775e-01, 3.8564e-01, 1.8979e-01, 2.1574e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14.10, Train Loss: 1.17, Val Loss: 4.69, Train BLEU: 43.03, Val BLEU: 10.19, Minutes Elapsed: 739.18\n",
      "Sampling from training predictions...\n",
      "Source: chúng_tôi phải thay_đổi những ảnh_hưởng của việc sinh_nở này với\n",
      "Reference: we needed to change the impact that this birth\n",
      "Model: <SOS> we needed to change the impact of birth with\n",
      "Attention Weights: tensor([[4.8822e-02, 9.5049e-01, 6.8900e-04, 1.2311e-06, 2.0925e-07, 2.1641e-08,\n",
      "         9.7472e-09, 2.9643e-09, 2.8792e-09, 1.0725e-09],\n",
      "        [9.8756e-04, 9.9338e-01, 5.6112e-03, 7.6315e-06, 1.2777e-05, 3.3763e-07,\n",
      "         2.9012e-07, 1.2642e-07, 1.1697e-08, 2.1637e-08],\n",
      "        [7.5097e-04, 8.2912e-01, 1.6317e-01, 5.9166e-03, 9.7890e-04, 3.4322e-05,\n",
      "         1.6185e-05, 1.3070e-05, 1.2018e-06, 2.0316e-06],\n",
      "        [9.8852e-05, 8.7673e-04, 7.1407e-01, 2.2149e-01, 6.2469e-02, 6.9521e-04,\n",
      "         1.6668e-04, 1.0121e-04, 2.0074e-05, 2.1744e-05],\n",
      "        [3.2907e-04, 1.0074e-03, 1.7016e-02, 3.6860e-01, 5.6542e-01, 4.2963e-02,\n",
      "         3.3191e-03, 8.4512e-04, 3.7697e-04, 1.2352e-04],\n",
      "        [3.8156e-04, 1.0803e-03, 8.4898e-03, 1.1022e-01, 8.4933e-01, 2.1084e-02,\n",
      "         4.9533e-03, 3.7586e-03, 4.0540e-04, 3.0154e-04],\n",
      "        [6.4157e-06, 9.2401e-04, 9.8502e-04, 9.3180e-02, 4.2527e-01, 1.0957e-01,\n",
      "         2.6641e-01, 6.7112e-02, 9.3038e-03, 2.7238e-02],\n",
      "        [1.9540e-05, 1.0302e-03, 4.7792e-04, 2.8273e-02, 1.9522e-01, 8.9894e-02,\n",
      "         4.1331e-01, 1.3615e-01, 3.2861e-02, 1.0277e-01],\n",
      "        [1.2451e-04, 1.2824e-03, 1.4684e-04, 2.1691e-03, 8.5857e-02, 4.7463e-02,\n",
      "         1.3728e-01, 3.1792e-01, 1.5265e-01, 2.5510e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: một phần ba phụ_nữ mỹ trải_qua bạo_lực gia_đình hoặc bị\n",
      "Reference: one in three american women experiences domestic violence or\n",
      "Model: <SOS> a million million million who who out a ,\n",
      "Attention Weights: tensor([[8.3428e-01, 1.6357e-01, 1.8594e-03, 2.8095e-04, 6.4410e-06, 3.1667e-07,\n",
      "         2.7690e-08, 4.8216e-09, 3.0499e-10, 1.6938e-10],\n",
      "        [1.0967e-02, 9.3993e-01, 4.1680e-02, 6.8001e-03, 5.6130e-04, 5.5740e-05,\n",
      "         5.7069e-06, 1.7029e-06, 3.8792e-07, 1.4506e-07],\n",
      "        [1.4031e-02, 2.7296e-01, 3.5139e-01, 2.9670e-01, 6.0350e-02, 4.0361e-03,\n",
      "         4.1408e-04, 9.4835e-05, 1.5290e-05, 5.2073e-06],\n",
      "        [2.1633e-04, 1.7419e-03, 4.6061e-02, 2.7877e-01, 6.0469e-01, 6.1433e-02,\n",
      "         5.0300e-03, 1.4395e-03, 4.8950e-04, 1.2863e-04],\n",
      "        [5.3419e-04, 4.4932e-03, 6.7571e-02, 1.5164e-01, 5.9527e-01, 1.6012e-01,\n",
      "         1.5243e-02, 3.1510e-03, 1.1481e-03, 8.3129e-04],\n",
      "        [2.6189e-05, 4.6266e-04, 7.4934e-03, 7.2558e-02, 2.4458e-01, 6.2222e-01,\n",
      "         3.8663e-02, 6.5568e-03, 4.9947e-03, 2.4440e-03],\n",
      "        [3.5118e-06, 7.1450e-04, 6.5251e-03, 4.3094e-02, 1.3360e-01, 6.5722e-01,\n",
      "         1.0792e-01, 3.1903e-02, 1.5963e-02, 3.0546e-03],\n",
      "        [2.8337e-06, 1.3909e-04, 1.9143e-03, 7.3427e-03, 1.0956e-01, 2.5913e-01,\n",
      "         3.5557e-01, 1.7277e-01, 7.2336e-02, 2.1237e-02],\n",
      "        [2.5424e-05, 8.9098e-05, 2.5208e-04, 1.6825e-03, 1.1985e-02, 2.2502e-01,\n",
      "         2.3055e-01, 1.5310e-01, 2.1303e-01, 1.6427e-01]])\n",
      "\n",
      "Epoch: 14.14, Train Loss: 1.18, Val Loss: 4.70, Train BLEU: 39.92, Val BLEU: 10.34, Minutes Elapsed: 741.64\n",
      "Sampling from training predictions...\n",
      "Source: trong đầu tôi liệu có_một địa_điểm , một không_gian ,\n",
      "Reference: do i have a place , a venue ,\n",
      "Model: <SOS> i i have a one , a venue ,\n",
      "Attention Weights: tensor([[2.0186e-01, 7.9760e-01, 2.1150e-04, 3.2197e-04, 1.6661e-06, 6.3037e-07,\n",
      "         8.2942e-09, 2.2267e-08, 3.0626e-09, 4.8032e-11],\n",
      "        [5.8485e-03, 9.8874e-01, 2.8421e-03, 2.5093e-03, 4.1698e-05, 1.4380e-05,\n",
      "         1.8696e-06, 1.0582e-06, 7.1195e-07, 5.1775e-08],\n",
      "        [3.7102e-02, 1.6746e-01, 6.3155e-02, 4.9415e-01, 1.9279e-01, 3.6362e-02,\n",
      "         6.7315e-03, 1.3907e-03, 7.4937e-04, 1.0716e-04],\n",
      "        [8.0889e-03, 8.2331e-03, 1.5978e-02, 3.3437e-01, 3.5137e-01, 2.2050e-01,\n",
      "         3.8019e-02, 1.5504e-02, 7.3327e-03, 5.9487e-04],\n",
      "        [4.5371e-03, 2.9533e-02, 3.8919e-03, 6.9443e-02, 2.4184e-01, 5.0398e-01,\n",
      "         8.0636e-02, 4.6631e-02, 1.8050e-02, 1.4520e-03],\n",
      "        [2.6647e-02, 3.4953e-02, 1.5667e-02, 1.0007e-01, 1.1048e-01, 1.2071e-01,\n",
      "         3.1354e-01, 1.5864e-01, 9.5676e-02, 2.3603e-02],\n",
      "        [2.1441e-04, 6.9409e-04, 2.5331e-03, 2.3798e-02, 1.1950e-02, 5.3389e-02,\n",
      "         2.3415e-01, 4.7726e-01, 1.3926e-01, 5.6748e-02],\n",
      "        [9.6536e-05, 2.4216e-03, 9.8544e-04, 1.2538e-02, 9.7377e-03, 1.6660e-02,\n",
      "         5.0795e-02, 2.3753e-01, 5.7881e-01, 9.0428e-02],\n",
      "        [1.4551e-02, 7.4338e-02, 2.4940e-03, 3.1673e-02, 3.3253e-02, 1.4421e-02,\n",
      "         5.1768e-02, 8.3636e-02, 2.3683e-01, 4.5704e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: nghĩ thử xem nhé ? <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: guess what ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> think about it <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.9872, 0.0090, 0.0037, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.7326, 0.1366, 0.1158, 0.0136, 0.0013, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2474, 0.2610, 0.2557, 0.1745, 0.0523, 0.0091, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0581, 0.0966, 0.2957, 0.2853, 0.1727, 0.0917, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0141, 0.0701, 0.0480, 0.0587, 0.0741, 0.7349, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0791, 0.0401, 0.0579, 0.0522, 0.1623, 0.6085, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0498, 0.1044, 0.0525, 0.0469, 0.0952, 0.6513, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0431, 0.0382, 0.0272, 0.0244, 0.2752, 0.5919, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.3236, 0.0217, 0.0233, 0.0186, 0.2543, 0.3585, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 14.19, Train Loss: 1.36, Val Loss: 4.75, Train BLEU: 34.58, Val BLEU: 10.50, Minutes Elapsed: 744.11\n",
      "Sampling from training predictions...\n",
      "Source: đó là một vấn_đề lớn . <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: it &apos;s a massive problem . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> it &apos;s a huge problem . <EOS> . <EOS>\n",
      "Attention Weights: tensor([[0.9641, 0.0306, 0.0048, 0.0001, 0.0005, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2622, 0.3831, 0.3081, 0.0143, 0.0321, 0.0003, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0241, 0.0708, 0.1292, 0.3262, 0.4434, 0.0052, 0.0011, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0007, 0.0102, 0.2156, 0.3302, 0.4325, 0.0084, 0.0023, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0022, 0.0540, 0.1051, 0.7067, 0.0994, 0.0210, 0.0116, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0145, 0.0521, 0.0762, 0.3342, 0.1255, 0.2256, 0.1718, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0039, 0.0068, 0.0026, 0.0657, 0.1295, 0.0883, 0.7033, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.2242, 0.1223, 0.0584, 0.0267, 0.0442, 0.1557, 0.3686, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0439, 0.1605, 0.0955, 0.1922, 0.1418, 0.0772, 0.2890, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: sự bình_thường bỏ_lỡ vẻ đẹp mà sự khác_biệt ban cho\n",
      "Reference: normality <UNK> the beauty that differences give us ,\n",
      "Model: <SOS> the &apos;s beauty the that you helped us the\n",
      "Attention Weights: tensor([[6.2071e-01, 3.0140e-01, 7.7697e-02, 1.9119e-04, 4.0898e-06, 1.6808e-07,\n",
      "         6.3139e-08, 1.3347e-07, 1.0192e-08, 7.7185e-09],\n",
      "        [6.9540e-03, 6.2541e-01, 3.1764e-01, 3.5858e-02, 1.1328e-02, 1.1859e-03,\n",
      "         6.3099e-04, 8.5640e-04, 5.3901e-05, 7.9349e-05],\n",
      "        [5.3634e-03, 3.7837e-02, 4.1018e-01, 3.4385e-01, 1.4441e-01, 3.9507e-02,\n",
      "         1.1249e-02, 5.4901e-03, 8.9798e-04, 1.2176e-03],\n",
      "        [2.4991e-05, 1.1745e-04, 9.9451e-03, 1.3382e-01, 3.8240e-01, 1.7883e-01,\n",
      "         1.1013e-01, 1.4765e-01, 2.1478e-02, 1.5603e-02],\n",
      "        [2.4893e-07, 4.4502e-06, 1.3880e-03, 1.7607e-02, 7.3442e-02, 1.1294e-01,\n",
      "         9.1453e-02, 3.9258e-01, 9.6669e-02, 2.1392e-01],\n",
      "        [5.3227e-07, 3.9871e-06, 4.0887e-04, 2.3533e-02, 2.5576e-02, 1.4789e-01,\n",
      "         1.5177e-01, 2.8887e-01, 1.4612e-01, 2.1583e-01],\n",
      "        [7.9901e-07, 2.5136e-05, 3.9587e-04, 7.9032e-03, 1.4661e-02, 5.3889e-02,\n",
      "         2.0933e-01, 2.6882e-01, 1.2476e-01, 3.2022e-01],\n",
      "        [3.1394e-05, 1.0814e-03, 8.6011e-04, 7.8135e-03, 1.4070e-02, 3.1143e-02,\n",
      "         6.1887e-02, 5.9377e-02, 1.0954e-01, 7.1419e-01],\n",
      "        [1.5647e-06, 2.0733e-05, 2.7780e-04, 6.3747e-03, 2.5853e-02, 7.1726e-02,\n",
      "         1.6785e-01, 7.4610e-02, 1.9701e-01, 4.5628e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14.24, Train Loss: 1.38, Val Loss: 4.72, Train BLEU: 34.28, Val BLEU: 10.32, Minutes Elapsed: 746.58\n",
      "Sampling from training predictions...\n",
      "Source: và thật vui vô_cùng khi chúng_tôi thấy những bạn trẻ\n",
      "Reference: and it was with great delight that we found\n",
      "Model: <SOS> and it &apos;s hard that that that we found\n",
      "Attention Weights: tensor([[1.4373e-04, 9.8899e-01, 1.0045e-02, 7.8035e-04, 4.1811e-05, 2.2466e-08,\n",
      "         2.1476e-08, 1.9463e-08, 3.3439e-09, 4.4210e-08],\n",
      "        [1.3269e-04, 8.9561e-01, 1.0036e-01, 3.6871e-03, 1.9068e-04, 4.9212e-06,\n",
      "         1.0023e-05, 1.6885e-06, 2.9585e-07, 7.9280e-07],\n",
      "        [1.9004e-04, 1.3792e-01, 6.5309e-01, 1.9197e-01, 1.3364e-02, 9.6431e-04,\n",
      "         1.6621e-03, 5.2191e-04, 1.3071e-04, 1.8759e-04],\n",
      "        [4.1468e-04, 8.3780e-02, 4.5228e-01, 3.8746e-01, 3.4389e-02, 8.7193e-03,\n",
      "         2.1459e-02, 8.9366e-03, 1.0198e-03, 1.5327e-03],\n",
      "        [2.6375e-05, 2.0117e-03, 2.3504e-01, 6.3242e-01, 9.4477e-02, 8.8480e-03,\n",
      "         1.2377e-02, 8.2703e-03, 3.0698e-03, 3.4564e-03],\n",
      "        [1.8978e-04, 1.8613e-03, 3.7276e-02, 4.4993e-01, 3.4907e-01, 2.6476e-02,\n",
      "         8.3834e-02, 3.0744e-02, 1.0145e-02, 1.0471e-02],\n",
      "        [3.8113e-06, 1.4022e-04, 4.0651e-03, 7.5372e-02, 4.9767e-01, 8.7127e-02,\n",
      "         1.9707e-01, 8.5491e-02, 1.8008e-02, 3.5049e-02],\n",
      "        [2.0058e-07, 1.8497e-05, 2.9622e-04, 5.4997e-03, 1.3444e-01, 9.4882e-02,\n",
      "         4.6787e-01, 1.5431e-01, 3.3321e-02, 1.0936e-01],\n",
      "        [4.9528e-08, 6.2019e-06, 9.9483e-05, 2.0035e-04, 1.8983e-02, 8.7291e-02,\n",
      "         4.3063e-01, 1.7443e-01, 8.2583e-02, 2.0577e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: nếu không , bé gái trong hình sẽ không còn\n",
      "Reference: otherwise , that little girl isn &apos;t going to\n",
      "Model: <SOS> if you , , your in your she any\n",
      "Attention Weights: tensor([[7.2547e-03, 9.8473e-01, 7.7872e-03, 5.0683e-05, 6.8257e-05, 1.0989e-04,\n",
      "         6.7883e-07, 3.4724e-08, 1.9235e-07, 1.2294e-08],\n",
      "        [9.4923e-03, 8.0564e-01, 1.8390e-01, 5.0140e-04, 2.9976e-04, 1.5678e-04,\n",
      "         3.6493e-06, 1.2072e-06, 1.0829e-06, 1.3422e-06],\n",
      "        [1.9011e-02, 5.2400e-01, 3.8505e-01, 4.1893e-02, 1.3391e-02, 1.3819e-02,\n",
      "         2.0969e-03, 5.1209e-04, 1.5138e-04, 7.0783e-05],\n",
      "        [2.2281e-02, 1.8872e-01, 4.9637e-01, 6.8741e-02, 1.1192e-01, 9.3923e-02,\n",
      "         1.3008e-02, 3.0989e-03, 1.4814e-03, 4.6296e-04],\n",
      "        [7.7057e-04, 1.2814e-01, 1.6528e-01, 8.7232e-02, 2.1776e-01, 2.9279e-01,\n",
      "         5.3196e-02, 3.1998e-02, 1.6568e-02, 6.2655e-03],\n",
      "        [6.3650e-05, 1.8838e-02, 3.6513e-02, 2.3953e-02, 4.5135e-02, 7.7292e-01,\n",
      "         3.9893e-02, 3.1038e-02, 1.8495e-02, 1.3153e-02],\n",
      "        [1.1915e-05, 5.2093e-04, 1.5247e-03, 2.8327e-03, 1.3150e-02, 4.3958e-01,\n",
      "         1.3155e-01, 2.0756e-01, 1.2326e-01, 8.0020e-02],\n",
      "        [6.3946e-07, 4.7080e-04, 1.4772e-03, 2.4114e-03, 3.5393e-03, 1.1532e-01,\n",
      "         3.3915e-01, 1.0376e-01, 1.7072e-01, 2.6314e-01],\n",
      "        [7.4486e-06, 2.1767e-04, 4.0608e-03, 2.1497e-04, 2.4102e-03, 1.6625e-01,\n",
      "         5.2608e-02, 4.3507e-02, 3.1790e-01, 4.1282e-01]])\n",
      "\n",
      "Epoch: 14.29, Train Loss: 1.44, Val Loss: 4.75, Train BLEU: 33.03, Val BLEU: 10.55, Minutes Elapsed: 749.04\n",
      "Sampling from training predictions...\n",
      "Source: tôi nghĩ tất_cả chúng_ta đều khá yên_tâm khi người này\n",
      "Reference: i think we &apos;d all be pretty comfortable with\n",
      "Model: <SOS> i think we all all pretty pretty with with\n",
      "Attention Weights: tensor([[3.7155e-02, 9.6053e-01, 2.3108e-03, 8.6465e-07, 5.2095e-07, 8.1476e-08,\n",
      "         2.3764e-08, 2.0392e-09, 2.2224e-09, 7.7336e-09],\n",
      "        [1.3051e-02, 9.8512e-01, 1.8080e-03, 5.3622e-06, 1.6950e-05, 1.1574e-06,\n",
      "         2.7626e-07, 5.6167e-08, 1.0258e-07, 3.2976e-08],\n",
      "        [1.0296e-02, 4.7154e-01, 4.8693e-01, 1.6425e-02, 1.3605e-02, 6.4299e-04,\n",
      "         4.6525e-04, 5.0622e-05, 3.4396e-05, 9.0919e-06],\n",
      "        [1.4585e-03, 2.5922e-02, 2.5696e-01, 1.4922e-01, 5.4066e-01, 1.9110e-02,\n",
      "         5.0409e-03, 6.7128e-04, 7.6891e-04, 1.9503e-04],\n",
      "        [6.0519e-05, 6.8170e-03, 1.0560e-01, 2.4044e-02, 8.1176e-01, 3.6893e-02,\n",
      "         1.2679e-02, 1.0195e-03, 8.2349e-04, 3.0541e-04],\n",
      "        [4.8663e-07, 3.7684e-04, 8.1034e-04, 1.0828e-02, 1.8408e-01, 3.2119e-01,\n",
      "         2.8406e-01, 1.9144e-01, 5.6182e-03, 1.5954e-03],\n",
      "        [3.6132e-07, 1.5845e-04, 5.2028e-04, 2.1002e-03, 3.6148e-02, 3.2870e-01,\n",
      "         3.5351e-01, 2.6604e-01, 1.1698e-02, 1.1232e-03],\n",
      "        [4.1844e-07, 3.3289e-05, 1.0584e-04, 1.0200e-03, 1.5409e-02, 7.3844e-02,\n",
      "         2.0148e-01, 5.9065e-01, 9.9387e-02, 1.8068e-02],\n",
      "        [4.3670e-06, 2.8940e-04, 4.3609e-04, 1.3023e-02, 2.8336e-02, 5.9974e-02,\n",
      "         1.1174e-01, 5.2918e-01, 2.2939e-01, 2.7619e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tại nhật , tới tháng_bảy , chúng_tôi đã mở_rộng ra\n",
      "Reference: within japan , by july , we &apos;d <UNK>\n",
      "Model: <SOS> in , , the the , we tried to\n",
      "Attention Weights: tensor([[9.6901e-01, 3.0778e-02, 1.9719e-04, 9.4718e-06, 4.1227e-06, 3.4094e-09,\n",
      "         6.9704e-11, 4.7262e-11, 5.1528e-09, 5.9843e-10],\n",
      "        [4.5586e-01, 4.6622e-01, 6.4499e-02, 4.6346e-03, 8.7539e-03, 1.7299e-05,\n",
      "         2.8742e-07, 1.3559e-06, 9.7354e-06, 9.4473e-07],\n",
      "        [2.3982e-01, 7.0056e-02, 3.7266e-01, 2.3560e-01, 8.0180e-02, 5.4266e-04,\n",
      "         7.5969e-05, 4.8094e-04, 4.9132e-04, 9.0914e-05],\n",
      "        [5.3779e-03, 4.7332e-03, 1.0204e-01, 6.2428e-01, 1.3032e-01, 3.5893e-02,\n",
      "         1.9492e-02, 5.1932e-02, 2.2665e-02, 3.2640e-03],\n",
      "        [1.6853e-02, 4.2166e-03, 3.4724e-03, 3.5904e-01, 5.8344e-01, 3.0171e-03,\n",
      "         5.2181e-04, 2.9982e-03, 2.5275e-02, 1.1739e-03],\n",
      "        [1.7622e-03, 2.5838e-03, 6.8136e-03, 1.5680e-01, 2.7744e-01, 9.5582e-02,\n",
      "         1.6079e-02, 6.6684e-02, 3.2852e-01, 4.7733e-02],\n",
      "        [8.3719e-04, 2.0226e-03, 8.5549e-03, 2.3088e-02, 2.2378e-02, 1.1249e-01,\n",
      "         9.1656e-02, 3.5926e-01, 3.3115e-01, 4.8554e-02],\n",
      "        [4.1337e-04, 4.9988e-04, 1.0681e-04, 1.4091e-03, 2.5723e-03, 6.6712e-03,\n",
      "         1.2848e-02, 2.2488e-01, 7.2013e-01, 3.0464e-02],\n",
      "        [2.5093e-04, 4.9996e-04, 5.8183e-04, 2.7942e-03, 9.9249e-03, 7.4169e-03,\n",
      "         4.5566e-03, 1.1803e-01, 7.6122e-01, 9.4732e-02]])\n",
      "\n",
      "Epoch: 14.34, Train Loss: 1.49, Val Loss: 4.72, Train BLEU: 31.23, Val BLEU: 9.92, Minutes Elapsed: 751.55\n",
      "Sampling from training predictions...\n",
      "Source: giờ đây , những đứa trẻ sâu_sắc , có chính_kiến\n",
      "Reference: by now , these thoughtful , opinionated , curious\n",
      "Model: <SOS> now now , every of , opinionated are personal\n",
      "Attention Weights: tensor([[9.9980e-01, 1.9768e-04, 4.6660e-06, 1.2361e-07, 1.6922e-07, 1.6655e-08,\n",
      "         2.7195e-09, 3.7007e-12, 1.5262e-12, 7.6008e-12],\n",
      "        [4.8766e-01, 3.4683e-01, 1.0643e-01, 5.2321e-02, 5.0532e-03, 1.1218e-03,\n",
      "         5.4599e-04, 6.3568e-06, 1.1178e-05, 1.5953e-05],\n",
      "        [1.4245e-02, 6.7521e-02, 2.7573e-01, 3.3758e-01, 2.6538e-01, 2.2404e-02,\n",
      "         1.2635e-02, 6.8929e-04, 2.6007e-03, 1.2105e-03],\n",
      "        [2.2455e-03, 2.3605e-03, 9.1185e-02, 4.1218e-01, 2.9976e-01, 7.9558e-02,\n",
      "         3.1854e-02, 1.1911e-02, 5.7353e-02, 1.1588e-02],\n",
      "        [7.7398e-03, 1.3396e-04, 3.6277e-02, 5.4809e-02, 3.3887e-01, 2.3506e-01,\n",
      "         2.5603e-01, 3.4082e-02, 2.1520e-02, 1.5480e-02],\n",
      "        [1.4315e-03, 4.3949e-05, 9.2093e-03, 9.3589e-03, 1.0904e-01, 3.0379e-01,\n",
      "         2.1495e-01, 1.9608e-01, 1.0325e-01, 5.2848e-02],\n",
      "        [2.8055e-05, 4.0854e-06, 1.8556e-04, 1.0610e-03, 1.0967e-02, 2.9234e-02,\n",
      "         3.9503e-02, 5.4084e-01, 2.7689e-01, 1.0128e-01],\n",
      "        [6.4823e-06, 3.1052e-06, 8.2570e-06, 3.8467e-04, 1.4465e-03, 1.2341e-03,\n",
      "         2.5015e-03, 1.2197e-01, 5.4527e-01, 3.2717e-01],\n",
      "        [2.5779e-05, 1.6835e-05, 9.6916e-05, 6.0569e-04, 1.3277e-02, 1.9819e-02,\n",
      "         1.7748e-02, 2.1723e-01, 2.2246e-01, 5.0872e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: thế nên ngay bây_giờ bạn đang tái dựng lại christchurch\n",
      "Reference: so now you &apos;re rebuilding christchurch without knowing what\n",
      "Model: <SOS> so now you you talking to all a your\n",
      "Attention Weights: tensor([[3.4908e-01, 2.4956e-01, 3.2329e-01, 7.4405e-02, 6.3733e-05, 1.4502e-04,\n",
      "         3.3949e-03, 5.5193e-05, 7.8405e-06, 1.2762e-07],\n",
      "        [9.9141e-04, 8.9815e-02, 2.9925e-01, 6.0831e-01, 1.5444e-03, 6.7674e-05,\n",
      "         1.5253e-05, 1.5333e-06, 3.1163e-07, 2.0138e-07],\n",
      "        [2.8195e-03, 8.7048e-03, 5.4191e-01, 3.8462e-01, 4.2101e-02, 1.6066e-02,\n",
      "         3.5459e-03, 1.6473e-04, 3.9237e-05, 3.1273e-05],\n",
      "        [2.1857e-03, 3.4194e-03, 7.8979e-02, 2.5420e-01, 2.3590e-01, 2.5905e-01,\n",
      "         1.4191e-01, 1.5929e-02, 4.6628e-03, 3.7699e-03],\n",
      "        [4.3374e-04, 3.5956e-03, 9.7905e-03, 2.9194e-02, 4.2926e-02, 4.8489e-01,\n",
      "         3.7624e-01, 4.7898e-02, 2.9670e-03, 2.0665e-03],\n",
      "        [5.9769e-04, 4.9510e-05, 1.2667e-03, 3.7444e-03, 3.1641e-03, 3.7613e-03,\n",
      "         1.3670e-01, 7.3053e-01, 6.5010e-02, 5.5176e-02],\n",
      "        [8.5971e-05, 9.1158e-05, 9.9647e-04, 1.1200e-02, 1.4412e-03, 1.0618e-03,\n",
      "         2.8178e-02, 2.3671e-01, 1.9949e-01, 5.2074e-01],\n",
      "        [2.5398e-04, 5.0405e-05, 2.9046e-03, 5.0576e-03, 3.6951e-03, 3.3306e-04,\n",
      "         5.8513e-03, 2.4276e-01, 3.4455e-01, 3.9455e-01],\n",
      "        [2.1456e-03, 1.0840e-03, 3.2949e-02, 1.0917e-01, 2.3665e-02, 4.6838e-03,\n",
      "         1.7853e-02, 1.3874e-01, 1.8371e-01, 4.8600e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14.38, Train Loss: 1.44, Val Loss: 4.72, Train BLEU: 33.20, Val BLEU: 10.02, Minutes Elapsed: 754.06\n",
      "Sampling from training predictions...\n",
      "Source: nếu ai đó từ nhóm chúng_tôi gian_lận và chúng_tôi thấy\n",
      "Reference: if somebody from our in-group cheats and we see\n",
      "Model: <SOS> if somebody from our in-group cheats , we see\n",
      "Attention Weights: tensor([[1.2276e-02, 9.4744e-01, 4.0056e-02, 2.1060e-04, 1.1507e-05, 5.8060e-07,\n",
      "         1.1647e-06, 4.0425e-08, 4.9537e-09, 2.7211e-08],\n",
      "        [1.9147e-03, 9.7792e-01, 1.9224e-02, 6.7608e-04, 1.2414e-04, 4.5174e-05,\n",
      "         8.8435e-05, 5.5712e-06, 3.4169e-06, 1.4440e-06],\n",
      "        [6.6098e-04, 2.1240e-01, 4.9609e-01, 2.3653e-01, 3.5917e-02, 4.7362e-03,\n",
      "         1.2005e-02, 2.0725e-04, 3.0391e-04, 1.1599e-03],\n",
      "        [1.4634e-04, 3.1477e-02, 1.5260e-01, 1.8680e-01, 4.8971e-01, 3.3141e-02,\n",
      "         1.0061e-01, 7.2474e-04, 4.8676e-04, 4.3040e-03],\n",
      "        [3.6254e-06, 3.1327e-04, 2.1776e-03, 7.5874e-02, 6.4016e-01, 8.3877e-02,\n",
      "         1.9497e-01, 1.2868e-03, 4.4311e-04, 8.8991e-04],\n",
      "        [2.2338e-06, 2.3508e-05, 1.4582e-04, 5.6677e-03, 1.7517e-01, 1.4986e-01,\n",
      "         6.0702e-01, 3.3531e-02, 2.8245e-03, 2.5753e-02],\n",
      "        [1.8947e-06, 1.0601e-05, 5.8426e-05, 2.2093e-04, 9.0113e-03, 8.8431e-03,\n",
      "         1.7854e-01, 1.9511e-01, 4.1116e-02, 5.6708e-01],\n",
      "        [1.0083e-06, 2.8306e-05, 3.0629e-05, 2.2788e-04, 1.3752e-02, 6.1338e-03,\n",
      "         1.1626e-01, 1.2207e-01, 2.2195e-01, 5.1955e-01],\n",
      "        [5.8838e-08, 1.3328e-05, 1.3622e-05, 1.3023e-04, 2.3272e-03, 1.2547e-03,\n",
      "         1.6161e-02, 2.6595e-02, 8.9472e-02, 8.6403e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: và tôi nhận ra : một trong những thứ quan_trọng\n",
      "Reference: and it hit me : one of the most\n",
      "Model: <SOS> and i i to me one one the most\n",
      "Attention Weights: tensor([[2.5172e-05, 1.2660e-03, 8.1112e-02, 6.7970e-01, 2.1904e-01, 1.8831e-02,\n",
      "         1.6675e-05, 7.5944e-06, 4.9241e-06, 1.3944e-06],\n",
      "        [2.0802e-02, 2.2227e-01, 7.2424e-01, 2.9396e-02, 3.0307e-03, 2.5084e-04,\n",
      "         9.2948e-06, 2.3809e-06, 8.3248e-07, 2.8203e-07],\n",
      "        [3.8102e-04, 4.2106e-01, 5.5142e-01, 2.2271e-02, 3.2888e-03, 1.2633e-03,\n",
      "         2.2978e-04, 3.0712e-05, 1.7894e-05, 4.1768e-05],\n",
      "        [1.4745e-04, 9.0246e-02, 6.5442e-01, 2.0804e-01, 3.4122e-02, 6.7630e-03,\n",
      "         3.6626e-03, 7.3149e-04, 5.2011e-04, 1.3463e-03],\n",
      "        [1.5816e-05, 7.5063e-02, 4.5007e-01, 2.2786e-01, 1.7283e-01, 3.6399e-02,\n",
      "         1.8747e-02, 6.8517e-03, 3.3669e-03, 8.7882e-03],\n",
      "        [1.8201e-05, 1.0268e-01, 4.4416e-01, 5.7367e-02, 1.7768e-01, 1.4659e-01,\n",
      "         5.5809e-02, 6.2014e-03, 4.4598e-03, 5.0381e-03],\n",
      "        [1.1181e-06, 6.6980e-04, 2.5229e-02, 1.3362e-02, 2.3173e-01, 5.1475e-01,\n",
      "         1.2982e-01, 4.1301e-02, 2.6068e-02, 1.7067e-02],\n",
      "        [7.8497e-07, 1.0656e-04, 2.5167e-02, 1.2573e-02, 3.8474e-02, 1.1264e-01,\n",
      "         5.3511e-01, 1.0378e-01, 5.7102e-02, 1.1505e-01],\n",
      "        [1.6604e-08, 1.5674e-06, 1.5313e-04, 1.1201e-04, 5.1912e-04, 4.9354e-03,\n",
      "         9.9724e-02, 9.9232e-02, 3.9322e-01, 4.0210e-01]])\n",
      "\n",
      "Epoch: 14.43, Train Loss: 1.58, Val Loss: 4.70, Train BLEU: 28.48, Val BLEU: 10.41, Minutes Elapsed: 756.57\n",
      "Sampling from training predictions...\n",
      "Source: tương_lai nào những con_người trẻ có_thể xây_dựng với những nắm_bắt\n",
      "Reference: what future could the young build with so little\n",
      "Model: <SOS> the future the could build with with stuff stuff\n",
      "Attention Weights: tensor([[9.9925e-01, 6.9470e-04, 3.8392e-05, 6.5948e-06, 1.4030e-05, 2.6773e-07,\n",
      "         4.0634e-09, 2.7296e-09, 1.9639e-10, 3.7412e-10],\n",
      "        [7.4772e-01, 9.6379e-02, 1.9362e-02, 2.5947e-02, 1.0793e-01, 2.2407e-03,\n",
      "         3.6442e-04, 3.4339e-05, 1.3734e-05, 7.8153e-06],\n",
      "        [4.7741e-02, 2.4668e-01, 1.3162e-01, 1.4735e-01, 3.8506e-01, 2.2785e-02,\n",
      "         1.6384e-02, 1.8784e-03, 2.9549e-04, 2.0957e-04],\n",
      "        [8.0573e-02, 1.0600e-01, 8.0560e-02, 8.3199e-02, 4.3489e-01, 9.8794e-02,\n",
      "         9.6679e-02, 1.7296e-02, 1.4965e-03, 5.1250e-04],\n",
      "        [7.2240e-04, 2.9387e-03, 9.7113e-03, 2.7721e-02, 2.0234e-01, 2.4552e-01,\n",
      "         4.4129e-01, 6.3190e-02, 4.3600e-03, 2.2088e-03],\n",
      "        [3.3825e-06, 3.6983e-05, 1.0167e-03, 1.4297e-03, 8.0107e-03, 1.6034e-02,\n",
      "         2.9858e-01, 5.2657e-01, 8.8820e-02, 5.9502e-02],\n",
      "        [4.7754e-07, 6.7481e-05, 3.5235e-04, 3.7623e-03, 2.3427e-02, 4.1988e-02,\n",
      "         1.3753e-01, 4.3573e-01, 2.2760e-01, 1.2954e-01],\n",
      "        [5.8941e-07, 3.2900e-06, 2.2011e-05, 2.1305e-04, 3.2709e-03, 1.5643e-02,\n",
      "         1.2281e-01, 1.9417e-01, 2.6332e-01, 4.0055e-01],\n",
      "        [4.1929e-07, 4.1377e-06, 8.2614e-05, 4.3266e-04, 1.7080e-03, 3.3492e-03,\n",
      "         1.4038e-02, 7.9079e-02, 4.9771e-01, 4.0360e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: nhiều phụ_nữ địu con trên lưng trong_khi đãi vàng ,\n",
      "Reference: many women had children strapped to their backs while\n",
      "Model: <SOS> oceans women are in the the inner , ,\n",
      "Attention Weights: tensor([[9.9781e-01, 1.5493e-03, 5.8996e-04, 5.1908e-05, 2.9423e-06, 1.7637e-07,\n",
      "         4.7704e-08, 3.2333e-08, 1.1855e-07, 8.3819e-09],\n",
      "        [3.3227e-02, 7.8701e-01, 1.4047e-01, 2.2611e-02, 1.0637e-02, 3.1983e-03,\n",
      "         1.3072e-03, 1.1178e-03, 3.9759e-04, 2.5028e-05],\n",
      "        [9.1823e-02, 1.8644e-01, 3.5713e-01, 1.5985e-01, 1.3249e-01, 4.3088e-02,\n",
      "         2.2167e-02, 4.3292e-03, 2.4215e-03, 2.5882e-04],\n",
      "        [2.6606e-04, 5.6972e-02, 1.8255e-01, 1.7181e-01, 4.0106e-01, 1.0925e-01,\n",
      "         5.2824e-02, 2.0517e-02, 4.1798e-03, 5.8162e-04],\n",
      "        [1.9807e-06, 8.3957e-04, 6.7990e-03, 1.1148e-01, 3.0595e-01, 3.8032e-01,\n",
      "         8.2287e-02, 8.2029e-02, 2.9265e-02, 1.0259e-03],\n",
      "        [1.7832e-06, 1.7293e-04, 6.8097e-04, 1.5370e-02, 8.9793e-02, 4.4577e-01,\n",
      "         1.2624e-01, 2.2187e-01, 9.4225e-02, 5.8815e-03],\n",
      "        [3.4285e-06, 5.0834e-05, 4.3503e-05, 2.8675e-04, 5.5924e-03, 1.5327e-01,\n",
      "         2.6625e-01, 3.4058e-01, 2.1622e-01, 1.7699e-02],\n",
      "        [9.4077e-06, 1.1965e-05, 6.0988e-05, 6.7994e-05, 1.3033e-03, 5.9587e-02,\n",
      "         2.4276e-01, 3.0107e-01, 3.4668e-01, 4.8455e-02],\n",
      "        [1.8289e-04, 8.4907e-05, 1.7078e-04, 1.8441e-04, 8.3721e-03, 6.8025e-02,\n",
      "         2.2113e-01, 2.6331e-01, 3.0330e-01, 1.3523e-01]])\n",
      "\n",
      "Epoch: 14.48, Train Loss: 1.57, Val Loss: 4.68, Train BLEU: 30.13, Val BLEU: 10.13, Minutes Elapsed: 759.06\n",
      "Sampling from training predictions...\n",
      "Source: tôi sẽ kiếm được bao_nhiêu nếu gian_lận ? <EOS> <PAD>\n",
      "Reference: how much do i stand to gain from cheating\n",
      "Model: <SOS> how how i i get for game a game\n",
      "Attention Weights: tensor([[0.0876, 0.8818, 0.0259, 0.0045, 0.0001, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0249, 0.4438, 0.5061, 0.0220, 0.0030, 0.0001, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0209, 0.2854, 0.4494, 0.1958, 0.0468, 0.0012, 0.0003, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0077, 0.4368, 0.3486, 0.1682, 0.0369, 0.0012, 0.0006, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0038, 0.4150, 0.3110, 0.2115, 0.0554, 0.0020, 0.0012, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0071, 0.2470, 0.3160, 0.3656, 0.0554, 0.0084, 0.0001, 0.0001,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0004, 0.0383, 0.3236, 0.3767, 0.1900, 0.0696, 0.0009, 0.0004,\n",
      "         0.0000],\n",
      "        [0.0004, 0.0006, 0.0005, 0.0210, 0.0349, 0.2870, 0.6371, 0.0151, 0.0033,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0001, 0.0005, 0.0182, 0.0189, 0.1718, 0.7604, 0.0217, 0.0084,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: dưới tác_động của thời_tiết , bức_xạ mặt_trời , tình_trạng oxy\n",
      "Reference: due to <UNK> , due to <UNK> light ,\n",
      "Model: <SOS> the the , , , , , , ,\n",
      "Attention Weights: tensor([[9.9978e-01, 2.1786e-04, 9.5498e-07, 3.1277e-07, 1.7561e-09, 7.2879e-11,\n",
      "         4.4881e-10, 9.7937e-13, 5.6622e-13, 1.6621e-12],\n",
      "        [3.0155e-02, 9.4036e-01, 7.5396e-03, 2.1212e-02, 6.6073e-04, 2.1926e-05,\n",
      "         4.5251e-05, 1.2914e-06, 3.1768e-07, 1.4631e-07],\n",
      "        [7.6801e-02, 4.8225e-01, 6.8218e-02, 2.6704e-01, 8.7092e-02, 1.2704e-02,\n",
      "         5.3356e-03, 3.7431e-04, 1.2083e-04, 5.9581e-05],\n",
      "        [7.6371e-03, 9.0829e-02, 2.0429e-01, 1.3992e-01, 3.4850e-01, 1.7460e-01,\n",
      "         2.5079e-02, 4.6331e-03, 4.0951e-03, 4.1918e-04],\n",
      "        [1.9089e-02, 9.4139e-02, 1.6361e-01, 3.3811e-01, 1.5920e-01, 1.8184e-01,\n",
      "         3.5981e-02, 4.1430e-03, 3.3235e-03, 5.7431e-04],\n",
      "        [6.0473e-06, 3.7429e-04, 1.2424e-04, 3.3007e-03, 5.2058e-03, 3.4150e-01,\n",
      "         5.7144e-01, 3.1901e-02, 3.9450e-02, 6.6962e-03],\n",
      "        [9.3738e-03, 3.1227e-02, 1.8882e-02, 1.1837e-02, 1.1010e-02, 1.2001e-01,\n",
      "         1.1500e-01, 2.5166e-01, 3.3587e-01, 9.5130e-02],\n",
      "        [7.9162e-05, 1.9561e-04, 7.1844e-04, 1.2727e-03, 1.9443e-02, 2.7899e-02,\n",
      "         6.8954e-03, 8.9982e-02, 7.8659e-01, 6.6930e-02],\n",
      "        [1.9780e-05, 5.9525e-05, 9.4662e-05, 2.2072e-03, 4.8655e-03, 3.3998e-02,\n",
      "         3.3980e-02, 1.1319e-01, 7.2095e-01, 9.0639e-02]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14.53, Train Loss: 1.48, Val Loss: 4.70, Train BLEU: 31.44, Val BLEU: 10.27, Minutes Elapsed: 761.56\n",
      "Sampling from training predictions...\n",
      "Source: những bộ phim được biên_đạo và bối cảnh_hoá . <EOS>\n",
      "Reference: the films were curated and contextualized . <EOS> <PAD>\n",
      "Model: <SOS> the films are curated and contextualized . . .\n",
      "Attention Weights: tensor([[1.1686e-01, 1.7098e-01, 5.7486e-01, 8.7688e-02, 4.9517e-02, 5.8668e-05,\n",
      "         3.4642e-05, 9.9788e-07, 5.5266e-08, 1.2494e-08],\n",
      "        [5.6533e-03, 3.8434e-02, 5.6836e-01, 2.8986e-01, 9.4861e-02, 5.2127e-04,\n",
      "         1.2786e-03, 1.0201e-03, 1.4017e-05, 3.2783e-06],\n",
      "        [2.6683e-03, 8.6395e-03, 1.0865e-01, 4.7925e-01, 2.8593e-01, 6.2187e-02,\n",
      "         3.0043e-02, 2.2336e-02, 2.2105e-04, 7.2673e-05],\n",
      "        [2.6859e-04, 2.0826e-03, 4.5566e-02, 3.1785e-01, 3.6520e-01, 1.5346e-01,\n",
      "         6.2438e-02, 5.2441e-02, 4.5518e-04, 2.3869e-04],\n",
      "        [2.0880e-04, 6.0486e-04, 1.6947e-01, 2.9734e-01, 3.2074e-01, 6.2007e-02,\n",
      "         7.3729e-02, 7.4174e-02, 1.4971e-03, 2.3155e-04],\n",
      "        [5.5548e-05, 1.2154e-04, 4.3299e-03, 8.9741e-02, 2.6186e-01, 2.9906e-01,\n",
      "         2.4753e-01, 9.2423e-02, 3.8697e-03, 1.0132e-03],\n",
      "        [1.6820e-05, 1.0852e-05, 4.6568e-04, 7.6720e-03, 2.3791e-02, 2.1759e-02,\n",
      "         3.7530e-01, 5.3885e-01, 1.9980e-02, 1.2153e-02],\n",
      "        [1.4609e-05, 1.0684e-04, 1.0634e-03, 1.3042e-02, 6.7596e-03, 9.3747e-03,\n",
      "         1.4986e-01, 5.9547e-01, 9.0275e-02, 1.3403e-01],\n",
      "        [4.7934e-05, 1.1489e-04, 1.9426e-03, 1.9900e-02, 1.8037e-02, 2.8533e-02,\n",
      "         2.5860e-01, 3.8595e-01, 8.4100e-02, 2.0278e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: thật kinh_ngạc , chế_độ nô_lệ tạo ra lợi_nhuận hơn 13\n",
      "Reference: astonishingly , slavery generates profits of more than $\n",
      "Model: <SOS> it &apos;s that mortality put more more , ,\n",
      "Attention Weights: tensor([[9.5616e-01, 4.3817e-02, 8.2394e-06, 2.1754e-06, 8.5290e-06, 1.1500e-06,\n",
      "         3.5277e-07, 4.9089e-08, 6.8321e-09, 2.3026e-09],\n",
      "        [3.7280e-01, 5.8849e-01, 1.1338e-02, 1.4548e-02, 1.1331e-02, 1.0245e-03,\n",
      "         2.1790e-04, 2.1391e-04, 2.5678e-05, 5.6793e-06],\n",
      "        [3.5242e-01, 2.3095e-01, 1.1017e-01, 1.2535e-01, 1.4258e-01, 1.8513e-02,\n",
      "         1.2231e-02, 5.5435e-03, 1.8268e-03, 4.1334e-04],\n",
      "        [9.3137e-05, 1.4565e-04, 2.6154e-03, 3.8797e-01, 4.8563e-01, 7.9717e-02,\n",
      "         2.4117e-02, 1.5106e-02, 2.7278e-03, 1.8852e-03],\n",
      "        [7.2225e-04, 4.1832e-05, 9.8289e-04, 9.7934e-02, 7.9119e-02, 1.7157e-01,\n",
      "         2.9848e-01, 2.3643e-01, 9.9124e-02, 1.5599e-02],\n",
      "        [2.5273e-06, 3.2029e-06, 4.6380e-06, 2.7178e-04, 3.7501e-03, 5.3333e-03,\n",
      "         4.4048e-02, 2.1812e-01, 4.7202e-01, 2.5644e-01],\n",
      "        [7.7974e-06, 2.1015e-05, 1.9589e-04, 4.6788e-03, 1.0149e-02, 1.6292e-02,\n",
      "         3.7279e-02, 8.1508e-02, 3.6940e-01, 4.8047e-01],\n",
      "        [5.3672e-04, 6.8265e-04, 2.1751e-04, 1.2206e-02, 1.5923e-01, 4.0287e-02,\n",
      "         3.2679e-02, 5.4728e-02, 1.0532e-01, 5.9411e-01],\n",
      "        [3.7182e-05, 4.8782e-05, 2.3217e-03, 1.4070e-02, 7.6573e-03, 2.3569e-02,\n",
      "         3.3793e-02, 5.5593e-02, 2.4800e-01, 6.1491e-01]])\n",
      "\n",
      "Epoch: 14.58, Train Loss: 1.52, Val Loss: 4.74, Train BLEU: 29.62, Val BLEU: 10.83, Minutes Elapsed: 764.09\n",
      "Sampling from training predictions...\n",
      "Source: tất_cả đều rất thú_vị . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: and it &apos;s been very exciting . <EOS> <PAD>\n",
      "Model: <SOS> it it &apos;s very , exciting . <EOS> .\n",
      "Attention Weights: tensor([[0.0296, 0.9167, 0.0536, 0.0002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0279, 0.6310, 0.3160, 0.0248, 0.0003, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1856, 0.4790, 0.2661, 0.0624, 0.0059, 0.0009, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0776, 0.2185, 0.5323, 0.1647, 0.0053, 0.0016, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0423, 0.2635, 0.1878, 0.2972, 0.1809, 0.0283, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0654, 0.1379, 0.1162, 0.0950, 0.3007, 0.2847, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0158, 0.1225, 0.1877, 0.0625, 0.3297, 0.2819, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0210, 0.1044, 0.1862, 0.0767, 0.0852, 0.5266, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0825, 0.1614, 0.2031, 0.1568, 0.1584, 0.2378, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: cảm_ơn rất nhiều . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "Reference: thank you very much . <EOS> <PAD> <PAD> <PAD>\n",
      "Model: <SOS> thank you very much . <EOS> . . <EOS>\n",
      "Attention Weights: tensor([[0.0572, 0.8884, 0.0528, 0.0012, 0.0003, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0226, 0.9656, 0.0099, 0.0016, 0.0003, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.1569, 0.6865, 0.1110, 0.0383, 0.0074, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0158, 0.1929, 0.6012, 0.1535, 0.0366, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0048, 0.0180, 0.6441, 0.1794, 0.1537, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0045, 0.0662, 0.1834, 0.4338, 0.3122, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0073, 0.0973, 0.4462, 0.3489, 0.1003, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0522, 0.5446, 0.2364, 0.1155, 0.0513, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0123, 0.0718, 0.2451, 0.4938, 0.1770, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 14.62, Train Loss: 1.58, Val Loss: 4.73, Train BLEU: 29.95, Val BLEU: 10.30, Minutes Elapsed: 766.57\n",
      "Sampling from training predictions...\n",
      "Source: hãy đồng_ý rằng \" những cậu_bé và khu dân_cư \"\n",
      "Reference: agree that &quot; boyz n the hood , &quot;\n",
      "Model: <SOS> imagine you &quot; boyz n , &quot; &quot; &quot;\n",
      "Attention Weights: tensor([[8.3427e-02, 6.8812e-01, 2.2744e-01, 8.5963e-04, 1.1730e-04, 4.0707e-05,\n",
      "         2.0159e-07, 1.7242e-08, 8.9848e-09, 7.5153e-10],\n",
      "        [4.2337e-03, 5.9142e-02, 9.2262e-01, 9.9637e-03, 3.1254e-03, 8.8038e-04,\n",
      "         2.2818e-05, 8.1970e-06, 2.7595e-06, 4.8811e-07],\n",
      "        [6.8639e-03, 1.5150e-01, 2.9488e-01, 3.8168e-01, 1.2370e-01, 3.1189e-02,\n",
      "         5.3482e-03, 3.2918e-03, 1.2507e-03, 2.8815e-04],\n",
      "        [1.4060e-05, 8.9136e-06, 6.2474e-04, 6.6085e-02, 7.7005e-01, 1.2517e-01,\n",
      "         3.5599e-02, 1.6804e-03, 4.9710e-04, 2.7070e-04],\n",
      "        [1.3670e-06, 7.7027e-07, 4.2531e-05, 1.7818e-02, 4.6918e-01, 2.7211e-01,\n",
      "         2.1811e-01, 1.0062e-02, 9.8329e-03, 2.8454e-03],\n",
      "        [9.4531e-06, 1.2049e-05, 3.4862e-04, 3.9309e-03, 4.5761e-02, 6.3854e-02,\n",
      "         3.0268e-01, 2.3038e-01, 3.2844e-01, 2.4586e-02],\n",
      "        [2.8665e-07, 1.3797e-06, 8.9396e-05, 2.2348e-03, 2.8183e-02, 9.8994e-03,\n",
      "         6.2646e-02, 2.6673e-01, 3.4899e-01, 2.8122e-01],\n",
      "        [3.5466e-06, 3.0830e-06, 1.0246e-04, 3.5142e-03, 2.3017e-02, 7.8668e-03,\n",
      "         6.4996e-02, 2.6081e-01, 2.6548e-01, 3.7421e-01],\n",
      "        [5.4103e-06, 7.2899e-06, 4.6477e-04, 1.0291e-02, 3.9340e-02, 1.2775e-02,\n",
      "         4.0509e-02, 2.6260e-01, 3.4572e-01, 2.8829e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: có_lẽ các bạn đều đồng_ý với tôi đây là một\n",
      "Reference: you probably all agree with me that this is\n",
      "Model: <SOS> you you agree agree me me as a i\n",
      "Attention Weights: tensor([[9.9712e-01, 7.1282e-04, 6.1562e-04, 1.5159e-03, 1.8354e-05, 2.1753e-05,\n",
      "         2.4954e-07, 1.1563e-08, 2.2350e-10, 3.0773e-10],\n",
      "        [8.2517e-01, 2.0999e-02, 1.2181e-02, 1.1874e-01, 2.2783e-02, 1.1033e-04,\n",
      "         1.1972e-05, 2.3786e-06, 3.5256e-07, 1.4147e-07],\n",
      "        [1.2303e-02, 2.1299e-03, 5.9765e-03, 7.1139e-01, 2.4122e-01, 2.2252e-02,\n",
      "         3.7695e-03, 8.4898e-04, 9.0020e-05, 1.8425e-05],\n",
      "        [2.0068e-03, 4.9880e-05, 1.9843e-04, 1.2133e-01, 3.8334e-01, 4.3969e-01,\n",
      "         4.8993e-02, 3.4850e-03, 7.1185e-04, 1.9967e-04],\n",
      "        [1.5349e-04, 1.7389e-05, 9.2594e-05, 2.9298e-02, 1.1240e-01, 3.6535e-01,\n",
      "         3.2670e-01, 1.2913e-01, 2.8846e-02, 8.0074e-03],\n",
      "        [3.4459e-05, 1.0938e-05, 5.0213e-05, 6.7536e-03, 8.3901e-03, 1.4149e-01,\n",
      "         4.5902e-01, 2.9655e-01, 7.1340e-02, 1.6354e-02],\n",
      "        [1.3660e-05, 5.9277e-06, 1.7541e-05, 5.2714e-04, 2.8848e-04, 4.4318e-03,\n",
      "         6.8218e-02, 4.5262e-01, 3.3082e-01, 1.4306e-01],\n",
      "        [1.0220e-05, 7.4000e-07, 3.2337e-05, 1.5912e-03, 9.7908e-04, 8.4693e-03,\n",
      "         1.9921e-02, 2.4304e-01, 5.3867e-01, 1.8729e-01],\n",
      "        [2.6298e-05, 1.1115e-06, 7.4483e-06, 4.6036e-04, 2.6927e-03, 3.5357e-03,\n",
      "         2.7207e-02, 2.3642e-01, 4.3841e-01, 2.9124e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14.67, Train Loss: 1.53, Val Loss: 4.74, Train BLEU: 31.03, Val BLEU: 10.42, Minutes Elapsed: 769.06\n",
      "Sampling from training predictions...\n",
      "Source: mọi người thấy cách cư_xử của nhau <EOS> <PAD> <PAD>\n",
      "Reference: people see each other behaving . <EOS> <PAD> <PAD>\n",
      "Model: <SOS> people see how behavior behaving . <EOS> <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.1520, 0.7971, 0.0499, 0.0010, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0017, 0.9958, 0.0024, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0105, 0.0042, 0.2831, 0.6752, 0.0247, 0.0016, 0.0007, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0001, 0.0060, 0.6412, 0.3452, 0.0036, 0.0033, 0.0003, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0004, 0.0006, 0.0157, 0.1445, 0.4698, 0.1660, 0.1662, 0.0369, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0002, 0.0030, 0.0048, 0.0131, 0.1211, 0.3461, 0.5117, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0011, 0.0324, 0.0028, 0.0030, 0.0452, 0.1300, 0.7854, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0028, 0.1320, 0.8234, 0.0051, 0.0035, 0.0064, 0.0139, 0.0129, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0044, 0.0315, 0.9284, 0.0185, 0.0021, 0.0031, 0.0024, 0.0096, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: nếu không , bé gái trong hình sẽ không còn\n",
      "Reference: otherwise , that little girl isn &apos;t going to\n",
      "Model: <SOS> if no , , my in the the the\n",
      "Attention Weights: tensor([[1.6699e-03, 9.9614e-01, 1.9786e-03, 4.5513e-05, 1.4778e-04, 1.5312e-05,\n",
      "         1.3072e-07, 4.4326e-08, 3.8913e-08, 1.1630e-09],\n",
      "        [1.4697e-02, 8.5947e-01, 1.2408e-01, 8.1266e-04, 8.7890e-04, 5.3761e-05,\n",
      "         2.0969e-06, 1.2301e-06, 1.5014e-06, 6.0786e-07],\n",
      "        [5.7004e-03, 6.2193e-01, 2.8314e-01, 4.3697e-02, 3.6591e-02, 7.7702e-03,\n",
      "         9.6905e-04, 1.0341e-04, 8.0451e-05, 2.3417e-05],\n",
      "        [1.4046e-02, 1.7736e-01, 2.6928e-01, 1.5121e-01, 2.8163e-01, 8.6696e-02,\n",
      "         1.5695e-02, 1.9372e-03, 1.3171e-03, 8.2965e-04],\n",
      "        [1.2890e-03, 8.5057e-02, 1.7482e-01, 1.0370e-01, 2.7874e-01, 2.9910e-01,\n",
      "         3.0626e-02, 1.4214e-02, 7.5054e-03, 4.9589e-03],\n",
      "        [6.8288e-05, 5.8801e-03, 4.2046e-02, 4.1095e-02, 1.5196e-01, 6.3950e-01,\n",
      "         8.1053e-02, 1.7567e-02, 5.7505e-03, 1.5075e-02],\n",
      "        [4.9037e-05, 5.3230e-03, 1.2143e-02, 1.2792e-02, 3.3931e-02, 7.2120e-01,\n",
      "         9.6149e-02, 3.3173e-02, 4.7105e-02, 3.8136e-02],\n",
      "        [2.3297e-06, 8.2706e-04, 2.7235e-03, 8.0354e-03, 2.3990e-02, 2.5900e-01,\n",
      "         3.5134e-01, 7.6820e-02, 1.0042e-01, 1.7684e-01],\n",
      "        [1.0193e-05, 3.5700e-04, 1.7526e-03, 5.0287e-04, 3.2659e-03, 5.8444e-02,\n",
      "         5.7294e-02, 3.9847e-02, 1.4044e-01, 6.9809e-01]])\n",
      "\n",
      "Epoch: 14.72, Train Loss: 1.57, Val Loss: 4.76, Train BLEU: 29.95, Val BLEU: 10.54, Minutes Elapsed: 771.57\n",
      "Sampling from training predictions...\n",
      "Source: đó là cảm_xúc tự_nhiên của con_người . <EOS> <PAD> <PAD>\n",
      "Reference: that &apos;s a natural human emotion . <EOS> <PAD>\n",
      "Model: <SOS> it &apos;s the natural nature emotion . <EOS> <EOS>\n",
      "Attention Weights: tensor([[0.8491, 0.0711, 0.0791, 0.0006, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0060, 0.6361, 0.3253, 0.0321, 0.0004, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0160, 0.2679, 0.5452, 0.1647, 0.0051, 0.0007, 0.0002, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0025, 0.2643, 0.7232, 0.0077, 0.0017, 0.0005, 0.0001, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0017, 0.0234, 0.3236, 0.4941, 0.1235, 0.0097, 0.0205, 0.0036, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0038, 0.0363, 0.4644, 0.1941, 0.2104, 0.0695, 0.0214, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0018, 0.0026, 0.0049, 0.0892, 0.0649, 0.2831, 0.4067, 0.1469, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0148, 0.0116, 0.0062, 0.0363, 0.0561, 0.0300, 0.3968, 0.4482, 0.0000,\n",
      "         0.0000],\n",
      "        [0.3690, 0.0368, 0.2999, 0.0166, 0.0139, 0.0402, 0.1330, 0.0905, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: rồi bạn cần một cái máy , như bạn thấy\n",
      "Reference: then you need a machine , like you see\n",
      "Model: <SOS> and you need a <UNK> , as you see\n",
      "Attention Weights: tensor([[9.9638e-01, 2.8337e-04, 3.2108e-03, 3.1964e-05, 3.0580e-05, 6.0422e-05,\n",
      "         2.6899e-07, 1.0153e-08, 2.4160e-08, 2.7945e-08],\n",
      "        [8.1968e-01, 1.0663e-01, 7.3005e-02, 3.8202e-04, 1.3078e-04, 1.1561e-04,\n",
      "         3.5709e-05, 6.9638e-06, 6.0026e-06, 2.5846e-06],\n",
      "        [2.3494e-03, 1.1144e-02, 9.6108e-01, 8.2187e-03, 7.3645e-03, 7.6690e-03,\n",
      "         1.4123e-03, 2.8313e-04, 1.1012e-04, 3.7036e-04],\n",
      "        [1.7995e-03, 2.0039e-03, 3.3327e-01, 2.3935e-01, 3.3311e-01, 7.6873e-02,\n",
      "         1.0849e-02, 6.1487e-04, 2.1937e-04, 1.9043e-03],\n",
      "        [1.9146e-03, 1.6008e-05, 3.2227e-03, 1.6756e-02, 4.8232e-01, 4.0570e-01,\n",
      "         8.5148e-02, 2.3882e-03, 2.6721e-04, 2.2625e-03],\n",
      "        [7.4367e-03, 2.9982e-05, 1.7471e-03, 1.7355e-02, 1.7728e-01, 2.3093e-01,\n",
      "         4.5581e-01, 9.3391e-02, 3.8571e-03, 1.2159e-02],\n",
      "        [4.9495e-03, 1.8932e-05, 4.4913e-05, 2.8345e-04, 8.7696e-03, 5.1249e-02,\n",
      "         5.3620e-01, 3.6456e-01, 1.7619e-02, 1.6307e-02],\n",
      "        [8.0194e-04, 8.8368e-05, 9.5542e-04, 2.6221e-04, 5.3876e-04, 8.1574e-04,\n",
      "         5.4594e-02, 1.7476e-01, 1.9586e-01, 5.7133e-01],\n",
      "        [4.4216e-06, 1.6107e-06, 5.1975e-03, 3.4360e-04, 7.2744e-04, 6.1014e-04,\n",
      "         1.4895e-03, 1.1146e-03, 2.1130e-02, 9.6938e-01]])\n",
      "\n",
      "Epoch: 14.77, Train Loss: 1.51, Val Loss: 4.77, Train BLEU: 31.15, Val BLEU: 9.96, Minutes Elapsed: 774.07\n",
      "Sampling from training predictions...\n",
      "Source: 1/3 người tham_gia nhận tờ giấy chúng_tôi phát , họ\n",
      "Reference: a third of the people we passed the sheet\n",
      "Model: <SOS> a third of the people we passed the sheet\n",
      "Attention Weights: tensor([[9.9481e-01, 5.1644e-03, 2.1027e-05, 1.3961e-06, 4.2404e-07, 2.3090e-07,\n",
      "         2.8960e-08, 1.7942e-08, 3.9836e-09, 9.5861e-10],\n",
      "        [9.3672e-01, 5.4726e-02, 6.1351e-03, 1.8119e-03, 2.4957e-04, 3.0456e-04,\n",
      "         2.6797e-05, 1.9313e-05, 3.1756e-06, 1.6220e-06],\n",
      "        [5.1100e-01, 4.0514e-01, 6.4993e-02, 1.1901e-02, 4.5178e-03, 2.1281e-03,\n",
      "         1.4891e-04, 1.4617e-04, 1.8328e-05, 6.9038e-06],\n",
      "        [7.5933e-02, 4.0039e-01, 3.1804e-01, 6.2084e-02, 9.1447e-02, 4.3894e-02,\n",
      "         4.4804e-03, 3.0253e-03, 5.1122e-04, 1.8829e-04],\n",
      "        [8.3873e-03, 6.0474e-02, 2.4420e-01, 2.8838e-01, 1.9136e-01, 1.8435e-01,\n",
      "         5.1171e-03, 1.6158e-02, 1.3477e-03, 2.2609e-04],\n",
      "        [2.6606e-03, 4.1885e-03, 3.6134e-02, 1.3010e-01, 5.2862e-01, 2.0599e-01,\n",
      "         3.1486e-02, 5.2802e-02, 7.4053e-03, 6.0496e-04],\n",
      "        [1.1034e-03, 4.9549e-03, 9.2283e-02, 2.0538e-01, 3.2838e-01, 2.4392e-01,\n",
      "         2.2080e-02, 9.6302e-02, 4.7953e-03, 8.0565e-04],\n",
      "        [8.2351e-04, 4.1037e-02, 1.1711e-01, 1.5752e-01, 3.1614e-01, 2.2287e-01,\n",
      "         3.8705e-02, 9.5507e-02, 8.5372e-03, 1.7581e-03],\n",
      "        [1.2789e-03, 5.9002e-03, 4.6427e-02, 1.2728e-01, 3.9407e-01, 3.2699e-01,\n",
      "         1.3340e-02, 6.4159e-02, 1.7014e-02, 3.5412e-03]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: động_cơ đốt trong không bền_vững . <EOS> <PAD> <PAD> <PAD>\n",
      "Reference: the internal combustion engine is not sustainable . <EOS>\n",
      "Model: <SOS> the , in is not &apos;t . . <EOS>\n",
      "Attention Weights: tensor([[0.9496, 0.0503, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.3601, 0.3836, 0.2485, 0.0070, 0.0007, 0.0001, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0438, 0.0245, 0.7688, 0.1474, 0.0152, 0.0002, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0054, 0.0214, 0.5587, 0.3706, 0.0425, 0.0012, 0.0001, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0063, 0.0062, 0.2413, 0.6584, 0.0864, 0.0013, 0.0002, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0014, 0.0014, 0.0252, 0.0441, 0.9245, 0.0027, 0.0007, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0002, 0.0010, 0.0248, 0.0801, 0.8719, 0.0183, 0.0037, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0005, 0.0574, 0.0884, 0.2360, 0.2666, 0.3508, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0006, 0.0007, 0.0309, 0.0439, 0.1346, 0.3040, 0.4852, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "\n",
      "Epoch: 14.82, Train Loss: 1.47, Val Loss: 4.79, Train BLEU: 32.41, Val BLEU: 10.42, Minutes Elapsed: 776.56\n",
      "Sampling from training predictions...\n",
      "Source: mà những gì chúng_tôi quan_sát được là rất nhiều người\n",
      "Reference: instead , what we saw is a lot of\n",
      "Model: <SOS> instead what what we saw is a a of\n",
      "Attention Weights: tensor([[9.8788e-01, 1.9418e-03, 1.0111e-02, 6.2796e-05, 7.7714e-06, 2.3248e-07,\n",
      "         3.7373e-08, 2.3085e-08, 2.3723e-08, 2.0570e-08],\n",
      "        [3.7737e-01, 2.5270e-01, 2.6711e-01, 6.4820e-02, 3.7213e-02, 7.2389e-04,\n",
      "         3.1017e-05, 1.7617e-05, 1.1320e-05, 1.3431e-06],\n",
      "        [1.2653e-01, 2.1865e-01, 2.5446e-01, 1.0653e-01, 2.2636e-01, 6.5084e-02,\n",
      "         1.6542e-03, 4.5898e-04, 2.0976e-04, 6.8818e-05],\n",
      "        [3.9812e-02, 2.9445e-02, 1.1390e-02, 5.6222e-02, 6.5733e-01, 1.9825e-01,\n",
      "         5.9516e-03, 1.3348e-03, 2.1236e-04, 5.3138e-05],\n",
      "        [1.5323e-01, 6.9758e-02, 1.2966e-02, 1.4867e-02, 6.0037e-01, 1.4130e-01,\n",
      "         6.5682e-03, 7.8662e-04, 1.2011e-04, 3.3631e-05],\n",
      "        [1.3298e-02, 6.2484e-03, 4.2763e-04, 1.5017e-03, 2.4683e-01, 5.7104e-01,\n",
      "         1.4393e-01, 1.5757e-02, 7.7277e-04, 1.8596e-04],\n",
      "        [1.9138e-05, 4.9735e-05, 5.0541e-06, 6.3626e-06, 1.8850e-03, 1.2669e-01,\n",
      "         3.6125e-01, 4.9008e-01, 1.7918e-02, 2.1004e-03],\n",
      "        [2.0549e-06, 2.0343e-05, 7.9174e-06, 7.5618e-06, 1.8143e-03, 6.4902e-03,\n",
      "         1.3497e-01, 6.6743e-01, 1.5850e-01, 3.0764e-02],\n",
      "        [1.1471e-06, 2.6820e-06, 5.0415e-06, 5.1561e-06, 2.1567e-03, 1.5861e-02,\n",
      "         6.7214e-02, 3.8203e-01, 4.6803e-01, 6.4690e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: nhưng từ khi xuất_bản \" <UNK> love \" tôi đã\n",
      "Reference: but since publishing &quot; crazy love , &quot; i\n",
      "Model: <SOS> but at word word &quot; &quot; &quot; &quot; we\n",
      "Attention Weights: tensor([[7.4092e-01, 2.5785e-01, 1.1671e-03, 5.6333e-05, 1.6578e-06, 1.9589e-07,\n",
      "         1.9613e-06, 1.1741e-07, 1.2183e-08, 9.0704e-09],\n",
      "        [8.0054e-03, 9.6020e-01, 1.8586e-02, 1.2301e-02, 6.9175e-04, 1.0207e-04,\n",
      "         9.5251e-05, 8.2599e-06, 4.8519e-06, 1.9093e-06],\n",
      "        [5.7758e-03, 4.0784e-02, 1.0886e-01, 7.6303e-01, 5.7019e-02, 1.2308e-02,\n",
      "         1.1065e-02, 7.8782e-04, 6.9467e-05, 2.9930e-04],\n",
      "        [1.6845e-02, 2.4866e-02, 1.1086e-01, 5.4958e-01, 1.7271e-01, 6.3648e-02,\n",
      "         5.4146e-02, 4.9163e-03, 5.8349e-04, 1.8417e-03],\n",
      "        [2.4517e-04, 1.6845e-03, 9.0111e-02, 2.0299e-01, 3.3853e-01, 1.4670e-01,\n",
      "         1.8413e-01, 1.8943e-02, 4.3867e-03, 1.2286e-02],\n",
      "        [1.1673e-07, 2.6127e-05, 3.3684e-03, 5.7856e-03, 8.3118e-02, 2.6965e-01,\n",
      "         2.8363e-01, 2.2074e-01, 7.2277e-02, 6.1410e-02],\n",
      "        [5.0752e-07, 3.6359e-05, 2.6443e-04, 2.2854e-04, 6.1832e-03, 3.5729e-02,\n",
      "         8.7157e-02, 3.1854e-01, 2.6586e-01, 2.8600e-01],\n",
      "        [6.9618e-08, 1.0328e-05, 2.8734e-05, 3.1099e-05, 5.5566e-04, 3.4241e-03,\n",
      "         1.1881e-02, 1.0442e-01, 4.3579e-01, 4.4386e-01],\n",
      "        [1.4129e-06, 6.7455e-06, 5.0688e-05, 3.9884e-05, 7.0776e-04, 2.0060e-03,\n",
      "         4.8398e-03, 7.1253e-02, 1.0492e-01, 8.1618e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14.86, Train Loss: 1.49, Val Loss: 4.76, Train BLEU: 31.32, Val BLEU: 10.17, Minutes Elapsed: 779.09\n",
      "Sampling from training predictions...\n",
      "Source: không có nhiều phản âm trong căn phòng . <EOS>\n",
      "Reference: and there wasn &apos;t a lot of reverberation in\n",
      "Model: <SOS> there wasn wasn &apos;t many lot of in in\n",
      "Attention Weights: tensor([[9.6811e-01, 3.1736e-02, 1.3836e-04, 7.7478e-06, 3.5106e-06, 1.9661e-07,\n",
      "         2.1297e-08, 2.1370e-08, 3.5395e-09, 8.4842e-10],\n",
      "        [5.6354e-01, 1.3287e-01, 1.8418e-01, 1.0339e-01, 1.2358e-02, 1.7665e-03,\n",
      "         2.9900e-04, 1.4145e-03, 1.3026e-04, 4.6860e-05],\n",
      "        [7.6229e-01, 4.6675e-02, 5.5061e-02, 9.1996e-02, 3.3797e-02, 5.9332e-03,\n",
      "         1.7911e-03, 1.9537e-03, 3.2465e-04, 1.7819e-04],\n",
      "        [5.7315e-01, 2.1906e-02, 7.1757e-02, 2.3495e-01, 6.9802e-02, 1.9206e-02,\n",
      "         2.2101e-03, 5.8655e-03, 7.2914e-04, 4.2409e-04],\n",
      "        [8.2559e-03, 1.6053e-02, 7.4544e-01, 2.1154e-01, 1.3739e-02, 3.1251e-03,\n",
      "         5.9629e-04, 1.1950e-03, 3.8059e-05, 1.9371e-05],\n",
      "        [4.7118e-04, 1.2640e-03, 2.1413e-01, 4.5213e-01, 1.8797e-01, 1.0968e-01,\n",
      "         1.2835e-02, 2.0698e-02, 5.7106e-04, 2.5341e-04],\n",
      "        [3.9164e-05, 6.5851e-05, 1.9464e-02, 3.9011e-01, 3.1635e-01, 2.0102e-01,\n",
      "         2.9236e-02, 4.0016e-02, 2.8741e-03, 8.2623e-04],\n",
      "        [1.2437e-04, 5.3546e-05, 2.7129e-03, 1.6258e-01, 1.3592e-01, 5.4696e-01,\n",
      "         4.7886e-02, 7.0275e-02, 2.6952e-02, 6.5349e-03],\n",
      "        [1.5765e-05, 4.0968e-05, 8.9250e-03, 2.9502e-02, 1.0806e-01, 3.7724e-01,\n",
      "         9.1770e-02, 3.6399e-01, 1.8411e-02, 2.0406e-03]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: tôi muốn chia_sẻ vài bí_quyết để làm được thế để\n",
      "Reference: i want to share a few keys on how\n",
      "Model: <SOS> i &apos;d like share a of of of to\n",
      "Attention Weights: tensor([[4.7731e-03, 9.8843e-01, 6.7506e-03, 4.5319e-05, 2.8668e-06, 8.5271e-08,\n",
      "         8.2334e-08, 5.3683e-08, 8.8098e-09, 9.1430e-09],\n",
      "        [4.8992e-04, 9.9885e-01, 6.1528e-04, 3.4231e-05, 8.0605e-06, 1.0653e-06,\n",
      "         6.4619e-07, 3.4124e-07, 1.4377e-07, 2.0489e-07],\n",
      "        [3.8912e-03, 9.8062e-01, 1.2559e-02, 2.0666e-03, 6.0046e-04, 1.0036e-04,\n",
      "         7.3334e-05, 6.0195e-05, 1.8418e-05, 1.4570e-05],\n",
      "        [1.5922e-04, 1.0236e-02, 9.0441e-01, 6.7134e-02, 1.2648e-02, 1.7147e-03,\n",
      "         1.3930e-03, 1.5932e-03, 4.2689e-04, 2.8991e-04],\n",
      "        [1.4030e-05, 5.8300e-04, 1.0519e-01, 8.7118e-01, 1.9552e-02, 1.3119e-03,\n",
      "         1.1482e-03, 7.9458e-04, 1.3391e-04, 9.6255e-05],\n",
      "        [3.2631e-05, 3.7934e-04, 1.4498e-01, 3.7386e-01, 4.5110e-01, 1.7667e-02,\n",
      "         5.2365e-03, 4.9628e-03, 9.7950e-04, 8.0578e-04],\n",
      "        [3.8070e-06, 1.0234e-05, 2.3498e-03, 5.0327e-01, 3.5505e-01, 5.9230e-02,\n",
      "         4.6014e-02, 2.6840e-02, 3.1589e-03, 4.0728e-03],\n",
      "        [2.4571e-07, 4.8551e-07, 7.9422e-04, 1.0903e-01, 5.6196e-01, 1.2694e-01,\n",
      "         1.2514e-01, 6.1094e-02, 8.7725e-03, 6.2678e-03],\n",
      "        [5.9107e-09, 1.3299e-08, 2.6548e-05, 4.6351e-02, 1.9358e-01, 2.5528e-01,\n",
      "         2.9054e-01, 1.8650e-01, 1.2217e-02, 1.5507e-02]])\n",
      "\n",
      "Epoch: 14.91, Train Loss: 1.34, Val Loss: 4.79, Train BLEU: 35.11, Val BLEU: 9.20, Minutes Elapsed: 781.19\n",
      "Sampling from training predictions...\n",
      "Source: tôi huýt_gió một_mình , tôi huýt_gió trong lớp_học , <EOS>\n",
      "Reference: i whistled alone . i whistled in the classroom\n",
      "Model: <SOS> i do alone . i whistled in the classroom\n",
      "Attention Weights: tensor([[7.2465e-02, 9.2661e-01, 9.2679e-04, 1.8519e-07, 2.9267e-08, 1.6985e-07,\n",
      "         1.3403e-08, 2.4178e-09, 6.6008e-10, 5.3162e-10],\n",
      "        [2.8085e-03, 9.7622e-01, 2.0924e-02, 3.8539e-05, 1.3149e-06, 1.0257e-05,\n",
      "         1.0535e-06, 2.5933e-07, 6.8398e-08, 3.5963e-08],\n",
      "        [1.7525e-02, 3.9225e-01, 5.2238e-01, 5.4369e-02, 1.3937e-03, 1.0410e-02,\n",
      "         1.3815e-03, 2.0017e-04, 7.4224e-05, 1.6816e-05],\n",
      "        [9.8071e-03, 5.7186e-01, 2.9475e-01, 7.6688e-02, 1.6842e-02, 8.9408e-03,\n",
      "         1.6381e-02, 4.0879e-03, 4.6997e-04, 1.6634e-04],\n",
      "        [1.1001e-03, 8.2622e-03, 2.3975e-02, 3.7772e-01, 3.5410e-01, 6.9156e-02,\n",
      "         7.5887e-02, 7.5462e-02, 1.1591e-02, 2.7457e-03],\n",
      "        [2.6049e-04, 3.4345e-03, 7.3168e-04, 5.4133e-02, 1.7990e-01, 5.8138e-01,\n",
      "         1.5240e-01, 2.4245e-02, 2.7626e-03, 7.4682e-04],\n",
      "        [5.6412e-04, 9.0081e-03, 2.6012e-03, 2.2135e-02, 7.3361e-03, 1.2828e-01,\n",
      "         6.7943e-01, 1.3386e-01, 1.4853e-02, 1.9356e-03],\n",
      "        [1.0602e-05, 2.9670e-04, 2.7081e-03, 2.7876e-03, 7.0408e-03, 2.1202e-02,\n",
      "         5.0553e-01, 4.4373e-01, 1.3728e-02, 2.9723e-03],\n",
      "        [3.9114e-05, 8.1398e-04, 1.0239e-03, 1.8507e-02, 5.2348e-02, 6.7610e-02,\n",
      "         1.5027e-01, 6.6983e-01, 2.7037e-02, 1.2519e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: rồi tờ l. a. times nhận được tin , steve\n",
      "Reference: so l.a. times got <UNK> of it . steve\n",
      "Model: <SOS> and the little another realized believe , , steve\n",
      "Attention Weights: tensor([[9.8648e-01, 1.3504e-02, 1.2290e-05, 8.6186e-07, 3.5169e-08, 5.0845e-10,\n",
      "         6.2132e-12, 3.7470e-13, 3.8626e-14, 1.7267e-13],\n",
      "        [1.9470e-01, 6.6587e-01, 1.3618e-01, 8.9032e-04, 1.9813e-03, 3.4010e-04,\n",
      "         2.1567e-05, 1.4653e-05, 9.3424e-07, 9.4043e-07],\n",
      "        [4.5369e-02, 3.4559e-01, 5.4652e-01, 7.0420e-03, 4.7524e-02, 6.7589e-03,\n",
      "         3.5553e-04, 6.9043e-04, 6.4601e-05, 8.4000e-05],\n",
      "        [3.6050e-02, 1.5128e-01, 5.3917e-01, 3.8650e-02, 1.4773e-01, 4.3864e-02,\n",
      "         1.5965e-02, 2.4905e-02, 1.4062e-03, 9.7394e-04],\n",
      "        [5.6442e-05, 1.9282e-04, 1.6050e-02, 1.1510e-02, 2.4011e-01, 5.2253e-01,\n",
      "         4.3282e-02, 1.1980e-01, 3.6342e-02, 1.0122e-02],\n",
      "        [2.9916e-06, 2.8149e-05, 5.1439e-03, 3.7289e-03, 1.0953e-02, 2.9575e-01,\n",
      "         1.5390e-01, 4.2795e-01, 7.8069e-02, 2.4474e-02],\n",
      "        [7.5223e-05, 6.7310e-05, 9.3364e-03, 1.8508e-03, 2.5311e-02, 3.3744e-02,\n",
      "         2.4701e-02, 2.1418e-01, 5.4606e-01, 1.4467e-01],\n",
      "        [6.1224e-06, 1.9207e-05, 5.6969e-04, 1.9737e-04, 2.7485e-03, 2.3047e-02,\n",
      "         1.2995e-02, 1.4250e-02, 3.9183e-01, 5.5434e-01],\n",
      "        [2.4250e-05, 1.0005e-05, 2.0807e-04, 4.0627e-04, 2.0335e-03, 1.8678e-02,\n",
      "         8.2026e-03, 7.5228e-03, 1.7916e-01, 7.8375e-01]])\n",
      "\n",
      "Epoch: 14.96, Train Loss: 1.22, Val Loss: 4.74, Train BLEU: 38.93, Val BLEU: 10.06, Minutes Elapsed: 782.96\n",
      "Sampling from training predictions...\n",
      "Source: đây là orchid lounge ở tootsie ở nashville . <EOS>\n",
      "Reference: this is tootsie &apos;s orchid lounge in nashville .\n",
      "Model: <SOS> this &apos;s tootsie <UNK> orchid lounge in nashville .\n",
      "Attention Weights: tensor([[4.0406e-01, 5.9584e-01, 9.5370e-05, 3.2947e-06, 1.9833e-08, 1.5138e-10,\n",
      "         5.1070e-10, 2.3462e-10, 1.1257e-10, 6.2370e-11],\n",
      "        [8.3826e-03, 8.3859e-01, 1.3750e-01, 1.4715e-02, 6.0664e-04, 1.1669e-04,\n",
      "         7.3933e-05, 6.8350e-06, 3.4233e-06, 9.2074e-07],\n",
      "        [1.7507e-02, 2.5684e-01, 4.5163e-01, 2.4521e-01, 2.1395e-02, 5.0123e-03,\n",
      "         1.7193e-03, 5.9773e-04, 5.4267e-05, 3.7305e-05],\n",
      "        [7.8163e-05, 1.8101e-03, 1.6387e-01, 6.2456e-01, 1.6460e-01, 2.9955e-02,\n",
      "         1.1812e-02, 2.8996e-03, 3.8383e-04, 3.1308e-05],\n",
      "        [2.0292e-05, 1.3359e-03, 5.0200e-02, 1.3337e-01, 6.4891e-01, 7.4166e-02,\n",
      "         8.8023e-02, 3.0068e-03, 8.9878e-04, 7.3420e-05],\n",
      "        [7.5415e-08, 1.0931e-06, 2.8917e-05, 3.0765e-04, 3.3387e-02, 6.4047e-02,\n",
      "         3.5483e-01, 4.6613e-01, 6.9600e-02, 1.1664e-02],\n",
      "        [4.2705e-05, 3.9318e-04, 5.4587e-05, 3.4125e-04, 6.1246e-02, 9.2291e-02,\n",
      "         5.3636e-01, 1.4071e-01, 1.3620e-01, 3.2366e-02],\n",
      "        [3.1001e-05, 5.5731e-05, 9.3930e-05, 4.0882e-04, 2.0060e-02, 3.7788e-02,\n",
      "         8.8261e-02, 7.4675e-01, 6.7647e-02, 3.8906e-02],\n",
      "        [8.2248e-02, 2.2182e-01, 6.3385e-03, 5.0234e-03, 7.9257e-02, 1.5060e-02,\n",
      "         1.7714e-01, 1.7971e-01, 1.5454e-01, 7.8863e-02]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: chẳng có cửa_sổ đủ lớn mà <UNK> . <EOS> <PAD>\n",
      "Reference: there were no windows large enough to climb through\n",
      "Model: <SOS> there are are extreme that are are . .\n",
      "Attention Weights: tensor([[0.9985, 0.0015, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4553, 0.2415, 0.2839, 0.0162, 0.0024, 0.0004, 0.0003, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.8895, 0.0383, 0.0362, 0.0229, 0.0057, 0.0046, 0.0026, 0.0002, 0.0001,\n",
      "         0.0000],\n",
      "        [0.1575, 0.0399, 0.4801, 0.2102, 0.0912, 0.0110, 0.0089, 0.0009, 0.0002,\n",
      "         0.0000],\n",
      "        [0.0003, 0.0005, 0.0108, 0.0711, 0.3764, 0.4085, 0.1156, 0.0135, 0.0033,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0001, 0.0004, 0.0145, 0.0737, 0.6047, 0.2355, 0.0414, 0.0297,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0001, 0.0004, 0.0061, 0.0346, 0.4430, 0.3296, 0.0541, 0.1321,\n",
      "         0.0000],\n",
      "        [0.0001, 0.0001, 0.0003, 0.0131, 0.0292, 0.3424, 0.1267, 0.2088, 0.2793,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0003, 0.0023, 0.0129, 0.0182, 0.1461, 0.3901, 0.1253, 0.3047,\n",
      "         0.0000]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15.00, Train Loss: 0.95, Val Loss: 4.76, Train BLEU: 49.63, Val BLEU: 10.28, Minutes Elapsed: 784.45\n",
      "Sampling from training predictions...\n",
      "Source: và tôi cũng tham_gia cuộc_thi huýt_gió thế_giới và tôi đã\n",
      "Reference: and i also entered the world championship , and\n",
      "Model: <SOS> and i &apos;m entered the world championship and and\n",
      "Attention Weights: tensor([[2.0958e-05, 1.4819e-02, 9.8516e-01, 4.3959e-07, 4.9695e-09, 8.4242e-09,\n",
      "         1.4446e-10, 1.3598e-12, 2.9466e-12, 6.2865e-12],\n",
      "        [1.4721e-04, 2.2206e-02, 9.7751e-01, 1.3425e-04, 1.2055e-06, 7.2985e-07,\n",
      "         3.2599e-07, 5.1402e-08, 1.1643e-08, 2.3999e-08],\n",
      "        [4.0338e-06, 2.0952e-04, 9.2837e-01, 7.0687e-02, 6.2083e-04, 5.2692e-05,\n",
      "         5.0535e-05, 3.6643e-06, 9.5056e-07, 4.3284e-06],\n",
      "        [9.0775e-05, 9.7104e-04, 1.9505e-01, 7.6003e-01, 4.0665e-02, 2.4908e-03,\n",
      "         5.6382e-04, 2.9032e-05, 2.1995e-05, 8.2952e-05],\n",
      "        [3.3701e-06, 3.5613e-05, 1.2204e-04, 3.3048e-01, 5.3059e-01, 1.2848e-01,\n",
      "         1.0148e-02, 7.8292e-05, 2.2372e-05, 3.8182e-05],\n",
      "        [3.7945e-07, 6.0013e-06, 1.4837e-05, 1.8628e-02, 3.4624e-01, 4.1055e-01,\n",
      "         2.2297e-01, 1.0823e-03, 3.4828e-04, 1.5513e-04],\n",
      "        [1.5163e-06, 5.8354e-05, 1.8146e-04, 1.3524e-03, 1.2565e-01, 6.3433e-01,\n",
      "         2.3074e-01, 5.7557e-03, 1.3390e-03, 5.9102e-04],\n",
      "        [7.1913e-05, 4.6123e-03, 2.1260e-03, 4.5988e-03, 1.3574e-02, 1.0896e-01,\n",
      "         8.0708e-01, 4.9587e-02, 5.2580e-03, 4.1337e-03],\n",
      "        [2.7457e-06, 5.7961e-04, 8.1735e-05, 6.1458e-04, 1.0327e-02, 1.1607e-01,\n",
      "         3.3806e-01, 1.4889e-01, 2.4720e-01, 1.3817e-01]])\n",
      "\n",
      "Sampling from val predictions...\n",
      "Source: chúng là cách để chúng_tôi dừng thời_gian trong một tuần\n",
      "Reference: they &apos;re also ways for us to freeze time\n",
      "Model: <SOS> they &apos;re the way way we we expect in\n",
      "Attention Weights: tensor([[8.4153e-01, 1.5791e-01, 5.4603e-04, 4.3110e-06, 2.2550e-07, 5.0022e-08,\n",
      "         1.9492e-07, 2.0128e-09, 1.6367e-09, 7.9782e-10],\n",
      "        [1.6820e-01, 7.3082e-01, 9.9534e-02, 9.6159e-04, 2.9807e-05, 3.8545e-04,\n",
      "         6.3563e-05, 6.3890e-06, 1.0700e-06, 1.6194e-06],\n",
      "        [7.4450e-02, 2.8953e-01, 6.1302e-01, 1.8765e-02, 7.2475e-04, 2.6943e-03,\n",
      "         6.1543e-04, 1.4107e-04, 1.7160e-05, 3.9154e-05],\n",
      "        [1.0707e-03, 3.7953e-02, 7.4574e-01, 1.5589e-01, 1.3840e-02, 2.5287e-02,\n",
      "         1.5106e-02, 3.8732e-03, 6.5259e-04, 5.8310e-04],\n",
      "        [5.6053e-04, 1.0374e-02, 1.4739e-02, 5.5397e-01, 9.7116e-02, 2.7358e-01,\n",
      "         2.8326e-02, 1.4077e-02, 3.4549e-03, 3.8026e-03],\n",
      "        [4.9793e-05, 9.6081e-04, 9.8390e-03, 2.1323e-01, 1.8511e-01, 5.5824e-01,\n",
      "         2.2925e-02, 7.6106e-03, 8.6957e-04, 1.1650e-03],\n",
      "        [1.0051e-04, 2.1469e-03, 1.4899e-03, 1.3557e-02, 7.4065e-02, 6.4751e-01,\n",
      "         2.3298e-01, 2.1485e-02, 2.5351e-03, 4.1306e-03],\n",
      "        [5.2807e-05, 2.5263e-04, 2.4500e-04, 1.3391e-02, 1.5334e-01, 5.5535e-01,\n",
      "         1.9435e-01, 3.9281e-02, 2.2400e-02, 2.1346e-02],\n",
      "        [9.5673e-07, 1.3895e-05, 4.0271e-04, 2.4140e-04, 1.5836e-03, 5.3037e-01,\n",
      "         2.6270e-01, 1.1917e-01, 3.3790e-02, 5.1722e-02]])\n",
      "\n",
      "Experiment completed in 784 minutes with 4.02 best validation loss and 11.75 best validation BLEU.\n"
     ]
    }
   ],
   "source": [
    "model, results = train_and_eval(\n",
    "    model=model, loaders_full=loaders_full, loaders_minibatch=loaders_minibatch, loaders_minitrain=loaders_minitrain, \n",
    "    params=params, vocab=vocab, print_intermediate=100, save_checkpoint=True, save_to_log=True, \n",
    "    lazy_eval=False, print_attn=True, inspect_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_single_learning_curve(load_experiment_log(experiment_name=MODEL_NAME)[0]['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>best_val_loss</th>\n",
       "      <th>best_val_bleu</th>\n",
       "      <th>runtime</th>\n",
       "      <th>dt_created</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>enc_hidden_dim</th>\n",
       "      <th>dec_hidden_dim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vi-rnn-additive-attn</td>\n",
       "      <td>4.024504</td>\n",
       "      <td>0.267568</td>\n",
       "      <td>784.446536</td>\n",
       "      <td>2018-12-09 21:04:07</td>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model_name  best_val_loss  best_val_bleu     runtime  \\\n",
       "0  vi-rnn-additive-attn       4.024504       0.267568  784.446536   \n",
       "\n",
       "            dt_created  num_layers  enc_hidden_dim  dec_hidden_dim  \n",
       "0  2018-12-09 21:04:07           2             512            1024  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_results(load_experiment_log(experiment_name=MODEL_NAME))[[\n",
    "    'model_name', 'best_val_loss', 'best_val_bleu', 'runtime', 'dt_created', \n",
    "    'num_layers', 'enc_hidden_dim', 'dec_hidden_dim']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload model and test \n",
    "encoder = EncoderRNN(rnn_cell_type=RNN_CELL_TYPE, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS, \n",
    "                     src_max_sentence_len=SRC_MAX_SENTENCE_LEN, enc_dropout=ENC_DROPOUT, \n",
    "                     pretrained_word2vec=get_pretrained_emb(vocab[SRC_LANG]['word2vec'], vocab[SRC_LANG]['token2id']))\n",
    "\n",
    "# # without attention \n",
    "# decoder = DecoderRNN(dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, num_layers=NUM_LAYERS,\n",
    "#                      targ_vocab_size=TARG_VOCAB_SIZE, targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, \n",
    "#                      pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "# model = EncoderDecoder(encoder, decoder, vocab[TARG_LANG]['token2id']).to(device)\n",
    "\n",
    "# with additive attention \n",
    "decoder = DecoderAttnRNN(rnn_cell_type=RNN_CELL_TYPE, dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, \n",
    "                         num_layers=NUM_LAYERS, targ_vocab_size=TARG_VOCAB_SIZE, src_max_sentence_len=SRC_MAX_SENTENCE_LEN, \n",
    "                         targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, dec_dropout=DEC_DROPOUT, attention_type=ATTENTION_TYPE,\n",
    "                         pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "model = EncoderDecoderAttn(encoder, decoder, vocab[TARG_LANG]['token2id'])\n",
    "\n",
    "# # with multiplicative attention \n",
    "# decoder = DecoderAttnRNN(rnn_cell_type=RNN_CELL_TYPE, dec_hidden_dim=DEC_HIDDEN_DIM, enc_hidden_dim=ENC_HIDDEN_DIM, \n",
    "#                          num_layers=NUM_LAYERS, targ_vocab_size=TARG_VOCAB_SIZE, src_max_sentence_len=SRC_MAX_SENTENCE_LEN, \n",
    "#                          targ_max_sentence_len=TARG_MAX_SENTENCE_LEN, dec_dropout=DEC_DROPOUT, attention_type=ATTENTION_TYPE,\n",
    "#                          pretrained_word2vec=get_pretrained_emb(vocab[TARG_LANG]['word2vec'], vocab[TARG_LANG]['token2id']))\n",
    "# model = EncoderDecoderAttn(encoder, decoder, vocab[TARG_LANG]['token2id']).to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('model_checkpoints/{}.pth.tar'.format(MODEL_NAME), map_location=device)\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
